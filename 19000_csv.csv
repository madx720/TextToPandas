source_text,target_text
how many heads of the departments are older than 56 ?,(head['age'] > 56).sum()
"list the name, born state and age of the heads of departments ordered by age.","head[['name', 'born_state', 'age']].sort_values('age')"
"list the creation year, name and budget of each department.","department[['creation', 'name', 'budget_in_billions']]"
what are the maximum and minimum budget of the departments?,"department['budget_in_billions'].agg(['max', 'min'])"
what is the average number of employees of the departments whose rank is between 10 and 15?,"department.loc[lambda x: x['ranking'].between(10,15), 'num_employees'].mean()"
what are the names of the heads who are born outside the california state?,"head.loc[lambda x: x['born_state'] != 'california', 'name']"
what are the distinct creation years of the departments managed by a secretary born in state 'alabama'?,"pd.merge(pd.merge(department, management, on='department_id'), head, on='head_id').loc[lambda x: x['born_state']=='alabama', 'creation'].unique()"
what are the names of the states where at least 3 heads were born?,head.groupby('born_state').filter(lambda x: len(x) >= 3)['born_state'].unique()
in which year were most departments established?,department.groupby('creation').size().sort_values(ascending=false).index[0]
show the name and number of employees for the departments managed by heads whose temporary acting value is 'yes'?,"pd.merge(department, management, on='department_id').loc[lambda x: x['temporary_acting']=='yes', ['name', 'num_employees']]"
how many acting statuses are there?,management['temporary_acting'].nunique()
how many departments are led by heads who are not mentioned?,department[~department['department_id'].isin(management['department_id'])].shape[0]
what are the distinct ages of the heads who are acting?,"pd.merge(head, management, on='head_id').loc[lambda x: x['temporary_acting']=='yes', 'age'].unique()"
list the states where both the secretary of 'treasury' department and the secretary of 'homeland security' were born.,"pd.merge(pd.merge(department.loc[lambda x: x['name']=='treasury'], management, on='department_id'), head, on='head_id')['born_state'].unique() & pd.merge(pd.merge(department.loc[lambda x: x['name']=='homeland security'], management, on='department_id'), head, on='head_id')['born_state'].unique()"
"which department has more than 1 head at a time? list the id, name and the number of heads.","management.merge(department, on='department_id').groupby(['department_id', 'name']).size().reset_index(name='count').loc[lambda x: x['count']>1, ['department_id', 'name', 'count']]"
which head's name has the substring 'ha'? list the id and name.,"head.loc[head['name'].str.contains('ha'), ['head_id', 'name']]"
how many farms are there?,farm.shape[0]
count the number of farms.,farm.shape[0]
list the total number of horses on farms in ascending order.,farm.sort_values('total_horses')['total_horses']
"what is the total horses record for each farm, sorted ascending?",farm.sort_values('total_horses')['total_horses']
"what are the hosts of competitions whose theme is not ""aliens""?","farm_competition.loc[lambda x: x['theme'] != 'aliens', 'hosts']"
return the hosts of competitions for which the theme is not aliens?,"farm_competition.loc[lambda x: x['theme'] != 'aliens', 'hosts']"
what are the themes of farm competitions sorted by year in ascending order?,farm_competition.sort_values('year')['theme']
"return the themes of farm competitions, sorted by year ascending.",farm_competition.sort_values('year')['theme']
what is the average number of working horses of farms with more than 5000 total number of horses?,"farm.loc[lambda x: x['total_horses'] > 5000, 'working_horses'].mean()"
give the average number of working horses on farms with more than 5000 total horses.,"farm.loc[lambda x: x['total_horses'] > 5000, 'working_horses'].mean()"
what are the maximum and minimum number of cows across all farms.,"farm['cows'].agg(['max', 'min'])"
return the maximum and minimum number of cows across all farms.,"farm['cows'].agg(['max', 'min'])"
how many different statuses do cities have?,city['status'].nunique()
count the number of different statuses.,city['status'].nunique()
list official names of cities in descending order of population.,"city.sort_values('population', ascending=false)['official_name']"
"what are the official names of cities, ordered descending by population?","city.sort_values('population', ascending=false)['official_name']"
list the official name and status of the city with the largest population.,"city[['official_name', 'status']].sort_values('population', ascending=false).head(1)"
what is the official name and status of the city with the most residents?,"city[['official_name', 'status']].sort_values('population', ascending=false).head(1)"
show the years and the official names of the host cities of competitions.,"pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id')[['year', 'official_name']]"
give the years and official names of the cities of each competition.,"pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id')[['year', 'official_name']]"
show the official names of the cities that have hosted more than one competition.,"pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id').groupby('host_city_id').filter(lambda x: len(x) > 1)['official_name']"
what are the official names of cities that have hosted more than one competition?,"pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id').groupby('host_city_id').filter(lambda x: len(x) > 1)['official_name']"
show the status of the city that has hosted the greatest number of competitions.,"pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id').groupby('host_city_id')['status'].count().sort_values(ascending=false).head(1)"
what is the status of the city that has hosted the most competitions?,"pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id').groupby('host_city_id')['status'].count().sort_values(ascending=false).head(1)"
please show the themes of competitions with host cities having populations larger than 1000.,"city.merge(farm_competition, left_on='city_id', right_on='host_city_id').loc[lambda x: x['population'] > 1000, 'theme']"
what are the themes of competitions that have corresponding host cities with more than 1000 residents?,"city.merge(farm_competition, left_on='city_id', right_on='host_city_id').loc[lambda x: x['population'] > 1000, 'theme']"
please show the different statuses of cities and the average population of cities with each status.,city.groupby('status')['population'].mean()
what are the statuses and average populations of each city?,city.groupby('status')['population'].mean()
"please show the different statuses, ordered by the number of cities that have each.",city.groupby('status').size().sort_values().index
"return the different statuses of cities, ascending by frequency.",city.groupby('status').size().sort_values().index
list the most common type of status across cities.,city.groupby('status').size().sort_values(ascending=false).index[0]
what is the most common status across all cities?,city.groupby('status').size().sort_values(ascending=false).index[0]
list the official names of cities that have not held any competition.,"city.loc[~city['city_id'].isin(farm_competition['host_city_id']), 'official_name']"
what are the official names of cities that have not hosted a farm competition?,"city.loc[~city['city_id'].isin(farm_competition['host_city_id']), 'official_name']"
show the status shared by cities with population bigger than 1500 and smaller than 500.,"set(city.loc[city['population'] > 1500, 'status']).intersection(set(city.loc[city['population'] < 500, 'status']))"
which statuses correspond to both cities that have a population over 1500 and cities that have a population lower than 500?,"set(city.loc[city['population'] > 1500, 'status']).intersection(set(city.loc[city['population'] < 500, 'status']))"
find the official names of cities with population bigger than 1500 or smaller than 500.,"city.loc[(city['population']>1500) | (city['population']<500), 'official_name']"
what are the official names of cities that have population over 1500 or less than 500?,"city.loc[(city['population']>1500) | (city['population']<500), 'official_name']"
"show the census ranking of cities whose status are not ""village"".","city.loc[lambda x: x['status']!='village', 'census_ranking']"
"what are the census rankings of cities that do not have the status ""village""?","city.loc[lambda x: x['status']!='village', 'census_ranking']"
which course has most number of registered students?,"pd.merge(courses, student_course_registrations, on='course_id').groupby('course_id')['course_name'].count().sort_values(ascending=false).head(1)"
what is the name of the course with the most registered students?,"pd.merge(courses, student_course_registrations, on='course_id').groupby('course_id')['course_name'].count().sort_values(ascending=false).head(1)"
what is id of students who registered some courses but the least number of courses in these students?,student_course_registrations.groupby('student_id').size().nsmallest(1).index[0]
what are the ids of the students who registered for some courses but had the least number of courses for all students?,student_course_registrations.groupby('student_id').size().nsmallest(1).index[0]
what are the first name and last name of all candidates?,"pd.merge(candidates, people, left_on='candidate_id', right_on='person_id')[['first_name', 'last_name']]"
what are the first and last names of all the candidates?,"pd.merge(candidates, people, left_on='candidate_id', right_on='person_id')[['first_name', 'last_name']]"
list the id of students who never attends courses?,"students.loc[~students['student_id'].isin(student_course_attendance['student_id']), 'student_id']"
what are the  ids of every student who has never attended a course?,"students.loc[~students['student_id'].isin(student_course_attendance['student_id']), 'student_id']"
list the id of students who attended some courses?,student_course_attendance['student_id']
what are the ids of all students who have attended at least one course?,student_course_attendance['student_id']
what are the ids of all students for courses and what are the names of those courses?,"pd.merge(student_course_registrations, courses, on='course_id')[['student_id', 'course_name']]"
what is detail of the student who most recently registered course?,"pd.merge(student_course_registrations, students, on='student_id').sort_values('registration_date', ascending=false).iloc[0]['student_details']"
what details do we have on the students who registered for courses most recently?,"pd.merge(student_course_registrations, students, on='student_id').sort_values('registration_date', ascending=false).iloc[0]['student_details']"
how many students attend course english?,"pd.merge(courses[courses['course_name']=='english'], student_course_attendance, on='course_id').shape[0]"
how many students are attending english courses?,"pd.merge(courses[courses['course_name']=='english'], student_course_attendance, on='course_id').shape[0]"
how many courses do the student whose id is 171 attend?,"pd.merge(courses, student_course_attendance, on='course_id').loc[lambda x: x['student_id'] == 171].shape[0]"
how many courses does the student with id 171 actually attend?,"pd.merge(courses, student_course_attendance, on='course_id').loc[lambda x: x['student_id'] == 171].shape[0]"
find id of the candidate whose email is stanley.monahan@example.org?,"candidates.merge(people, left_on='candidate_id', right_on='person_id').loc[lambda x: x['email_address']=='stanley.monahan@example.org', 'candidate_id']"
what is the id of the candidate whose email is stanley.monahan@example.org?,"candidates.merge(people, left_on='candidate_id', right_on='person_id').loc[lambda x: x['email_address']=='stanley.monahan@example.org', 'candidate_id']"
find id of the candidate who most recently accessed the course?,"candidate_assessments.sort_values('assessment_date', ascending=false).iloc[0]['candidate_id']"
what is the id of the candidate who most recently accessed the course?,"candidate_assessments.sort_values('assessment_date', ascending=false).iloc[0]['candidate_id']"
what is detail of the student who registered the most number of courses?,"students.merge(student_course_registrations, on='student_id').groupby('student_id')['student_details'].unique().sort_values(ascending=false).iloc[0]"
what are the details of the student who registered for the most number of courses?,"students.merge(student_course_registrations, on='student_id').groupby('student_id')['student_details'].unique().sort_values(ascending=false).iloc[0]"
list the id of students who registered some courses and the number of their registered courses?,"student_course_registrations.groupby('student_id').size().reset_index(name='count').merge(students, on='student_id')[['student_id', 'count']]"
"for every student who is registered for some course, how many courses are they registered for?","student_course_registrations.groupby('student_id').size().reset_index(name='count').merge(students, on='student_id')[['student_id', 'count']]"
how many registed students do each course have? list course name and the number of their registered students?,"pd.merge(pd.merge(students, student_course_registrations, on='student_id'), courses, on='course_id').groupby('course_name').size()"
"for each course id, how many students are registered and what are the course names?","pd.merge(pd.merge(students, student_course_registrations, on='student_id'), courses, on='course_id').groupby('course_name').size()"
"find id of candidates whose assessment code is ""pass""?","candidate_assessments.loc[candidate_assessments['asessment_outcome_code']=='pass', 'candidate_id']"
what are the ids of the candidates that have an outcome code of pass?,"candidate_assessments.loc[candidate_assessments['asessment_outcome_code']=='pass', 'candidate_id']"
"find the cell mobile number of the candidates whose assessment code is ""fail""?","pd.merge(pd.merge(candidates, candidate_assessments, on='candidate_id'), people, left_on='candidate_id', right_on='person_id').loc[lambda x: x['asessment_outcome_code']=='fail', 'cell_mobile_number']"
"what are the cell phone numbers of the candidates that received an assessment code of ""fail""?","pd.merge(pd.merge(candidates, candidate_assessments, on='candidate_id'), people, left_on='candidate_id', right_on='person_id').loc[lambda x: x['asessment_outcome_code']=='fail', 'cell_mobile_number']"
what are the id of students who registered course 301?,"student_course_attendance.loc[lambda x: x['course_id']==301, 'student_id']"
what are the ids of the students who registered for course 301?,"student_course_attendance.loc[lambda x: x['course_id']==301, 'student_id']"
what is the id of the student who most recently registered course 301?,"student_course_attendance.loc[lambda x: x['course_id']==301].sort_values('date_of_attendance', ascending=false)['student_id'].iloc[0]"
what are the ids of the students who registered for course 301 most recently?,"student_course_attendance.loc[lambda x: x['course_id']==301].sort_values('date_of_attendance', ascending=false)['student_id'].iloc[0]"
find distinct cities of addresses of people?,"pd.merge(addresses, people_addresses, on='address_id')['city'].unique()"
what are the different cities where people live?,"pd.merge(addresses, people_addresses, on='address_id')['city'].unique()"
find distinct cities of address of students?,"pd.merge(pd.merge(addresses, people_addresses, on='address_id'), students, left_on='person_id', right_on='student_id')['city'].unique()"
what are the different cities where students live?,"pd.merge(pd.merge(addresses, people_addresses, on='address_id'), students, left_on='person_id', right_on='student_id')['city'].unique()"
list the names of courses in alphabetical order?,courses['course_name'].sort_values()
what are the names of the courses in alphabetical order?,courses['course_name'].sort_values()
list the first names of people in alphabetical order?,people['first_name'].sort_values()
what are the first names of the people in alphabetical order?,people['first_name'].sort_values()
what are the id of students who registered courses or attended courses?,"pd.concat([student_course_registrations['student_id'], student_course_attendance['student_id']]).drop_duplicates()"
what are the ids of the students who either registered or attended a course?,"pd.concat([student_course_registrations['student_id'], student_course_attendance['student_id']]).drop_duplicates()"
find the id of courses which are registered or attended by student whose id is 121?,"pd.concat([student_course_registrations.loc[student_course_registrations['student_id']==121, 'course_id'], student_course_attendance.loc[student_course_attendance['student_id']==121, 'course_id']]).drop_duplicates()"
what are the ids of the courses that are registered or attended by the student whose id is 121?,"pd.concat([student_course_registrations.loc[student_course_registrations['student_id']==121, 'course_id'], student_course_attendance.loc[student_course_attendance['student_id']==121, 'course_id']]).drop_duplicates()"
what are all info of students who registered courses but not attended courses?,student_course_registrations.loc[~student_course_registrations['student_id'].isin(student_course_attendance['student_id'])]
what are all details of the students who registered but did not attend any course?,student_course_registrations.loc[~student_course_registrations['student_id'].isin(student_course_attendance['student_id'])]
list the id of students who registered course statistics in the order of registration date.,"student_course_registrations.merge(courses, on='course_id').loc[lambda x: x['course_name']=='statistics'].sort_values('registration_date')['student_id']"
what are the ids of the students who registered course statistics by order of registration date?,"student_course_registrations.merge(courses, on='course_id').loc[lambda x: x['course_name']=='statistics'].sort_values('registration_date')['student_id']"
list the id of students who attended  statistics courses in the order of attendance date.,"pd.merge(courses.loc[courses['course_name']=='statistics', ['course_id']], student_course_attendance, on='course_id').sort_values('date_of_attendance')['student_id']"
what are the ids of the students who attended courses in the statistics department in order of attendance date.,"pd.merge(courses.loc[courses['course_name']=='statistics', ['course_id']], student_course_attendance, on='course_id').sort_values('date_of_attendance')['student_id']"
give me the dates when the max temperature was higher than 85.,"weather.loc[lambda x: x['max_temperature_f'] > 85, 'date']"
what are the dates with a maximum temperature higher than 85?,"weather.loc[lambda x: x['max_temperature_f'] > 85, 'date']"
what are the names of stations that have latitude lower than 37.5?,"station.loc[lambda x: x['lat']<37.5, 'name']"
what are the names of all stations with a latitude smaller than 37.5?,"station.loc[lambda x: x['lat']<37.5, 'name']"
"for each city, return the highest latitude among its stations.",station.groupby('city')['lat'].max()
"for each city, what is the highest latitude for its stations?",station.groupby('city')['lat'].max()
give me the start station and end station for the trips with the three oldest id.,"trip[['start_station_name', 'end_station_name']].sort_values('id').head(3)"
what is the station station and end station for the trips with the three smallest ids?,"trip[['start_station_name', 'end_station_name']].sort_values('id').head(3)"
what is the average latitude and longitude of stations located in san jose city?,"station.loc[lambda x: x['city'] == 'san jose', ['lat', 'long']].mean()"
what is the average latitude and longitude in san jose?,"station.loc[lambda x: x['city'] == 'san jose', ['lat', 'long']].mean()"
what is the id of the trip that has the shortest duration?,trip.sort_values('duration')['id'].iloc[0]
what is the id of the shortest trip?,trip.sort_values('duration')['id'].iloc[0]
what is the total and maximum duration of trips with bike id 636?,"trip.loc[trip['bike_id']==636, 'duration'].agg(['sum', 'max'])"
what is the total and maximum duration for all trips with the bike id 636?,"trip.loc[trip['bike_id']==636, 'duration'].agg(['sum', 'max'])"
"for each zip code, return the average mean temperature of august there.","weather.loc[weather['date'].str.startswith('8/'), ['zip_code', 'mean_temperature_f']].groupby('zip_code').mean()"
"for each zip code, what is the average mean temperature for all dates that start with '8'?","weather.loc[weather['date'].str.startswith('8/'), ['zip_code', 'mean_temperature_f']].groupby('zip_code').mean()"
"from the trip record, find the number of unique bikes.",trip['bike_id'].nunique()
how many different bike ids are there?,trip['bike_id'].nunique()
what is the number of distinct cities the stations are located at?,station['city'].nunique()
how many different cities have these stations?,station['city'].nunique()
how many stations does mountain view city has?,(station['city'] == 'mountain view').sum()
how many stations are in mountain view?,(station['city'] == 'mountain view').sum()
return the unique name for stations that have ever had 7 bikes available.,"pd.merge(station, status, left_on='id', right_on='station_id').loc[lambda x: x['bikes_available'] == 7, 'name'].unique()"
what are the different names for each station that has ever had 7 bikes available?,"pd.merge(station, status, left_on='id', right_on='station_id').loc[lambda x: x['bikes_available'] == 7, 'name'].unique()"
which start station had the most trips starting from august? give me the name and id of the station.,"trip.loc[lambda x: x['start_date'].str.startswith('8/'), ['start_station_name', 'start_station_id']].groupby('start_station_name').size().sort_values(ascending=false).head(1).reset_index()[['start_station_name', 'start_station_id']]"
what are the start station's name and id for the one that had the most start trips in august?,"trip.loc[lambda x: x['start_date'].str.startswith('8/'), ['start_station_name', 'start_station_id']].groupby('start_station_name').size().sort_values(ascending=false).head(1).reset_index()[['start_station_name', 'start_station_id']]"
which bike traveled the most often in zip code 94002?,trip.loc[lambda x: x['zip_code']==94002].groupby('bike_id').size().sort_values(ascending=false).index[0]
what is the id of the bike that traveled the most in 94002?,trip.loc[lambda x: x['zip_code']==94002].groupby('bike_id').size().sort_values(ascending=false).index[0]
how many days had both mean humidity above 50 and mean visibility above 8?,(weather['mean_humidity'] > 50 & weather['mean_visibility_miles'] > 8).sum()
what is the number of days that had an average humity above 50 and an average visibility above 8?,(weather['mean_humidity'] > 50 & weather['mean_visibility_miles'] > 8).sum()
"what is the latitude, longitude, city of the station from which the shortest trip started?","pd.merge(station, trip, left_on='id', right_on='start_station_id').sort_values('duration').iloc[0][['lat', 'long', 'city']]"
"what is the latitude, longitude, and city of the station from which the trip with smallest duration started?","pd.merge(station, trip, left_on='id', right_on='start_station_id').sort_values('duration').iloc[0][['lat', 'long', 'city']]"
what are the ids of stations that are located in san francisco and have average bike availability above 10.,"station.loc[station['city'] == 'san francisco', 'id'].tolist() & status.groupby('station_id').filter(lambda x: x['bikes_available'].mean() > 10)['station_id'].tolist()"
what are the ids of the stations in san francisco that normally have more than 10 bikes available?,"station.loc[station['city'] == 'san francisco', 'id'].tolist() & status.groupby('station_id').filter(lambda x: x['bikes_available'].mean() > 10)['station_id'].tolist()"
what are the names and ids of stations that had more than 14 bikes available on average or were installed in december?,"pd.concat([pd.merge(station, status, on='id').groupby('id').filter(lambda x: x['bikes_available'].mean() > 14)[['name', 'id']],station.loc[lambda x: x['installation_date'].str.startswith('12/'), ['name', 'id']]])"
what are the names and ids of all stations that have more than 14 bikes available on average or had bikes installed in december?,"pd.concat([pd.merge(station, status, on='id').groupby('id').filter(lambda x: x['bikes_available'].mean() > 14)[['name', 'id']],station.loc[lambda x: x['installation_date'].str.startswith('12/'), ['name', 'id']]])"
what is the 3 most common cloud cover rates in the region of zip code 94107?,weather.loc[lambda x: x['zip_code']==94107].groupby('cloud_cover').size().sort_values(ascending=false).head(3).reset_index()['cloud_cover']
what are the 3 most common cloud covers in the zip code of 94107?,weather.loc[lambda x: x['zip_code']==94107].groupby('cloud_cover').size().sort_values(ascending=false).head(3).reset_index()['cloud_cover']
what is the zip code in which the average mean sea level pressure is the lowest?,weather.groupby('zip_code')['mean_sea_level_pressure_inches'].mean().sort_values().head(1).index[0]
what is the zip code that has the lowest average mean sea level pressure?,weather.groupby('zip_code')['mean_sea_level_pressure_inches'].mean().sort_values().head(1).index[0]
what is the average bike availability in stations that are not located in palo alto?,"status[~status['station_id'].isin(station.loc[station['city']=='palo alto', 'id'])]['bikes_available'].mean()"
what is the average bike availablility for stations not in palo alto?,"status[~status['station_id'].isin(station.loc[station['city']=='palo alto', 'id'])]['bikes_available'].mean()"
what is the average longitude of stations that never had bike availability more than 10?,"station.loc[~station['id'].isin(status.groupby('station_id').filter(lambda x: x['bikes_available'].max() > 10)['station_id']), 'long'].mean()"
what is the mean longitude for all stations that have never had more than 10 bikes available?,"station.loc[~station['id'].isin(status.groupby('station_id').filter(lambda x: x['bikes_available'].max() > 10)['station_id']), 'long'].mean()"
when and in what zip code did max temperature reach 80?,"weather.loc[lambda x: x['max_temperature_f'] >= 80, ['date', 'zip_code']]"
what zip codes have a station with a max temperature greater than or equal to 80 and when did it reach that temperature?,"weather.loc[lambda x: x['max_temperature_f'] >= 80, ['date', 'zip_code']]"
give me ids for all the trip that took place in a zip code area with average mean temperature above 60.,"trip.merge(weather, on='zip_code').groupby('zip_code').filter(lambda x: x['mean_temperature_f'].mean() > 60)['id']"
"for each zip code, find the ids of all trips that have a higher average mean temperature above 60?","trip.merge(weather, on='zip_code').groupby('zip_code').filter(lambda x: x['mean_temperature_f'].mean() > 60)['id']"
"for each zip code, return how many times max wind speed reached 25?",weather.loc[lambda x: x['max_wind_speed_mph']>=25].groupby('zip_code').size()
"for each zip code, how many times has the maximum wind speed reached 25 mph?",weather.loc[lambda x: x['max_wind_speed_mph']>=25].groupby('zip_code').size()
on which day and in which zip code was the min dew point lower than any day in zip code 94107?,"weather.loc[weather['min_dew_point_f'] < weather.loc[weather['zip_code'] == 94107, 'min_dew_point_f'].min(), ['date', 'zip_code']]"
"which days had a minimum dew point smaller than any day in zip code 94107, and in which zip codes were those measurements taken?","weather.loc[weather['min_dew_point_f'] < weather.loc[weather['zip_code'] == 94107, 'min_dew_point_f'].min(), ['date', 'zip_code']]"
"for each trip, return its ending station's installation date.","pd.merge(trip, station, left_on='end_station_id', right_on='id')[['id', 'installation_date']]"
what is the installation date for each ending station on all the trips?,"pd.merge(trip, station, left_on='end_station_id', right_on='id')[['id', 'installation_date']]"
which trip started from the station with the largest dock count? give me the trip id.,"trip.merge(station, left_on='start_station_id', right_on='id').sort_values('dock_count', ascending=false).iloc[0]['id']"
what is the id of the trip that started from the station with the highest dock count?,"trip.merge(station, left_on='start_station_id', right_on='id').sort_values('dock_count', ascending=false).iloc[0]['id']"
count the number of trips that did not end in san francisco city.,"pd.merge(trip, station, left_on='end_station_id', right_on='id').loc[lambda x: x['city']!='san francisco'].shape[0]"
how many trips did not end in san francisco?,"pd.merge(trip, station, left_on='end_station_id', right_on='id').loc[lambda x: x[""city""] != ""san francisco""].shape[0]"
"in zip code 94107, on which day neither fog nor rain was not observed?","weather.loc[(weather['zip_code']==94107) & (weather['events']!='fog') & (weather['events']!='rain'), 'date']"
on which day has it neither been foggy nor rained in the zip code of 94107?,"weather.loc[(weather['zip_code']==94107) & (weather['events']!='fog') & (weather['events']!='rain'), 'date']"
what are the ids of stations that have latitude above 37.4 and never had bike availability below 7?,"station.loc[lambda x: x['lat'] > 37.4].merge(status, on='station_id').groupby('station_id').min().loc[lambda x: x['bikes_available']>=7].reset_index()['station_id']"
what are the ids of all stations that have a latitude above 37.4 and have never had less than 7 bikes available?,"station.loc[lambda x: x['lat'] > 37.4].merge(status, on='station_id').groupby('station_id').min().loc[lambda x: x['bikes_available']>=7].reset_index()['station_id']"
what are names of stations that have average bike availability above 10 and are not located in san jose city?,"station.merge(status, on='id').groupby('station_id').filter(lambda x: x['bikes_available'].mean() > 10)['name'].drop_duplicates().loc[lambda x: x!='san jose']"
what are the names of all stations that have more than 10 bikes available and are not located in san jose?,"station.merge(status, on='id').groupby('station_id').filter(lambda x: x['bikes_available'].mean() > 10)['name'].drop_duplicates().loc[lambda x: x!='san jose']"
"what are the name, latitude, and city of the station with the lowest latitude?","station[['name', 'lat', 'city']].sort_values('lat').head(1)"
"what is the name, latitude, and city of the station that is located the furthest south?","station[['name', 'lat', 'city']].sort_values('lat').head(1)"
"what are the date, mean temperature and mean humidity for the top 3 days with the largest max gust speeds?","weather[['date', 'mean_temperature_f', 'mean_humidity']].sort_values('max_gust_speed_mph', ascending=false).head(3)"
"what is the date, average temperature and mean humidity for the days with the 3 largest maximum gust speeds?","weather[['date', 'mean_temperature_f', 'mean_humidity']].sort_values('max_gust_speed_mph', ascending=false).head(3)"
list the name and the number of stations for all the cities that have at least 15 stations.,station.groupby('city').filter(lambda x: len(x) >= 15).groupby('city').size()
what is the name of every city that has at least 15 stations and how many stations does it have?,station.groupby('city').filter(lambda x: len(x) >= 15).groupby('city').size()
find the ids and names of stations from which at least 200 trips started.,"trip.groupby(['start_station_id', 'start_station_name']).filter(lambda x: len(x) >= 200)['start_station_id', 'start_station_name'].drop_duplicates(subset='start_station_id')"
what are the ids and names of all start stations that were the beginning of at least 200 trips?,"trip.groupby(['start_station_id', 'start_station_name']).filter(lambda x: len(x) >= 200)['start_station_id', 'start_station_name'].drop_duplicates(subset='start_station_id')"
find the zip code in which the average mean visibility is lower than 10.,weather.groupby('zip_code').filter(lambda x: x['mean_visibility_miles'].mean() < 10)['zip_code'].unique()
"for each zip code, select all those that have an average mean visiblity below 10.",weather.groupby('zip_code').filter(lambda x: x['mean_visibility_miles'].mean() < 10)['zip_code'].unique()
list all the cities in a decreasing order of each city's stations' highest latitude.,station.groupby('city')['lat'].max().sort_values(ascending=false).index.tolist()
"for each city, list their names in decreasing order by their highest station latitude.",station.groupby('city')['lat'].max().sort_values(ascending=false).index.tolist()
what are the dates that had the top 5 cloud cover rates? also tell me the cloud cover rate.,"weather[['date', 'cloud_cover']].sort_values('cloud_cover',ascending=false).head(5)"
what are the dates that have the 5 highest cloud cover rates and what are the rates?,"weather[['date', 'cloud_cover']].sort_values('cloud_cover',ascending=false).head(5)"
what are the ids and durations of the trips with the top 3 durations?,"trip[['id', 'duration']].sort_values('duration', ascending=false).head(3)"
what are the ids of the trips that lasted the longest and how long did they last?,"trip[['id', 'duration']].sort_values('duration', ascending=false).head(3)"
"for each station, return its longitude and the average duration of trips that started from the station.","trip.groupby('start_station_id').agg(avg_duration=('duration','mean')).reset_index().merge(station[['id','name','long']], left_on='start_station_id', right_on='id')[['name','long','avg_duration']]"
"for each start station id, what is its name, longitude and average duration of trips started there?","trip.groupby('start_station_id').agg(avg_duration=('duration','mean')).reset_index().merge(station[['id','name','long']], left_on='start_station_id', right_on='id')[['name','long','avg_duration']]"
"for each station, find its latitude and the minimum duration of trips that ended at the station.","pd.merge(station, trip, left_on='id', right_on='end_station_id').groupby('end_station_id').agg({'name': 'first', 'lat': 'first', 'duration': 'min'})[['name', 'lat', 'duration']]"
"for each end station id, what is its name, latitude, and minimum duration for trips ended there?","pd.merge(station, trip, left_on='id', right_on='end_station_id').groupby('end_station_id').agg({'name': 'first', 'lat': 'first', 'duration': 'min'})[['name', 'lat', 'duration']]"
list all the distinct stations from which a trip of duration below 100 started.,"trip.loc[lambda x: x['duration'] < 100, 'start_station_name'].unique()"
what are all the different start station names for a trip that lasted less than 100?,"trip.loc[lambda x: x['duration'] < 100, 'start_station_name'].unique()"
find all the zip codes in which the max dew point have never reached 70.,"weather.loc[lambda x: x['max_dew_point_f'] < 70, 'zip_code'].unique()"
what are all the different zip codes that have a maximum dew point that was always below 70?,"weather.loc[lambda x: x['max_dew_point_f'] < 70, 'zip_code'].unique()"
find the id for the trips that lasted at least as long as the average duration of trips in zip code 94103.,"trip.loc[lambda x: x['duration'] >= trip.loc[lambda y: y['zip_code'] == 94103, 'duration'].mean(), 'id']"
what are the ids of all trips that had a duration as long as the average trip duration in the zip code 94103?,"trip.loc[lambda x: x['duration'] >= trip.loc[lambda y: y['zip_code'] == 94103, 'duration'].mean(), 'id']"
what are the dates in which the mean sea level pressure was between 30.3 and 31?,"weather.loc[(weather['mean_sea_level_pressure_inches'] > 30.3) & (weather['mean_sea_level_pressure_inches'] < 31), 'date']"
what are the dates that have an average sea level pressure between 30.3 and 31?,"weather.loc[(weather['mean_sea_level_pressure_inches'] > 30.3) & (weather['mean_sea_level_pressure_inches'] < 31), 'date']"
find the day in which the difference between the max temperature and min temperature was the smallest. also report the difference.,"weather.assign(temp_range=weather['max_temperature_f'] - weather['min_temperature_f']).sort_values('temp_range').iloc[0][['date', 'temp_range']]"
"what are the days that had the smallest temperature range, and what was that range?","weather.assign(temp_range=weather['max_temperature_f'] - weather['min_temperature_f']).sort_values('temp_range').iloc[0][['date', 'temp_range']]"
what are the id and name of the stations that have ever had more than 12 bikes available?,"pd.merge(station, status.query('bikes_available > 12')[['station_id']], left_on='id', right_on='station_id')[['id', 'name']].drop_duplicates()"
what are the different ids and names of the stations that have had more than 12 bikes available?,"pd.merge(station, status.query('bikes_available > 12')[['station_id']], left_on='id', right_on='station_id')[['id', 'name']].drop_duplicates()"
give me the zip code where the average mean humidity is below 70 and at least 100 trips took place.,weather.groupby('zip_code').mean().loc[lambda x: x['mean_humidity'] < 70].reset_index()['zip_code'].isin(trip['zip_code'].value_counts().loc[lambda x: x >= 100].index).values
what are the zip codes that have an average mean humidity below 70 and had at least 100 trips come through there?,weather.groupby('zip_code').mean().loc[lambda x: x['mean_humidity'] < 70].reset_index()['zip_code'].isin(trip['zip_code'].value_counts().loc[lambda x: x >= 100].index).values
what are the names of stations that are located in palo alto city but have never been the ending point of trips more than 100 times?,"station.loc[lambda x: x['city']=='palo alto', 'name'].loc[lambda x: ~x.isin(trip.groupby('end_station_name').filter(lambda x: len(x)>100).end_station_name.unique())]"
what are the names of the stations that are located in palo alto but have never been the ending point of the trips,"station.loc[lambda x: x['city']=='palo alto', 'name'].loc[lambda x: ~x.isin(trip.groupby('end_station_name').filter(lambda x: len(x)>100).end_station_name.unique())]"
how many trips started from mountain view city and ended at palo alto city?,"pd.merge(pd.merge(pd.merge(station, trip, left_on='id', right_on='start_station_id'), station, left_on='end_station_id', right_on='id', suffixes=('_start', '_end')),trip, on='id').loc[lambda x: (x['city_start'] == 'mountain view') & (x['city_end'] == 'palo alto'), :].shape[0]"
how many trips stated from  a station in mountain view and ended at one in palo alto?,"pd.merge(pd.merge(pd.merge(station, trip, left_on='id', right_on='start_station_id'), station, left_on='end_station_id', right_on='id', suffixes=('_start', '_end')),trip, on='id').loc[lambda x: (x['city_start'] == 'mountain view') & (x['city_end'] == 'palo alto'), :].shape[0]"
what is the average latitude and longitude of the starting points of all trips?,"pd.merge(station, trip, left_on='id', right_on='start_station_id').agg({'lat': 'mean', 'long': 'mean'})"
what is the average latitude and longitude of all starting stations for the trips?,"pd.merge(station, trip, left_on='id', right_on='start_station_id').agg({'lat': 'mean', 'long': 'mean'})"
how many books are there?,book.shape[0]
list the writers of the books in ascending alphabetical order.,book.sort_values('writer')['writer']
list the titles of the books in ascending order of issues.,book.sort_values('issues')['title']
"what are the titles of the books whose writer is not ""elaine lee""?","book.loc[lambda x: x['writer'] != 'elaine lee', 'title']"
what are the title and issues of the books?,"book[['title', 'issues']]"
what are the dates of publications in descending order of price?,"publication.sort_values('price', ascending=false)['publication_date']"
what are the distinct publishers of publications with price higher than 5000000?,"publication.loc[lambda x: x['price'] > 5000000, 'publisher'].unique()"
list the publisher of the publication with the highest price.,"publication.sort_values('price', ascending=false).iloc[0]['publisher']"
list the publication dates of publications with 3 lowest prices.,publication.sort_values('price').head(3)['publication_date']
show the title and publication dates of books.,"pd.merge(book, publication, on='book_id')[['title', 'publication_date']]"
show writers who have published a book with price more than 4000000.,"book.merge(publication, on='book_id').loc[lambda x: x['price'] > 4000000, 'writer']"
show the titles of books in descending order of publication price.,"pd.merge(book, publication, on='book_id').sort_values('price', ascending=false)['title']"
show publishers that have more than one publication.,publication.groupby('publisher').filter(lambda x: len(x) > 1)['publisher'].unique()
show different publishers together with the number of publications they have.,publication.groupby('publisher').size().reset_index(name='count')
please show the most common publication date.,publication.groupby('publication_date').size().sort_values(ascending=false).index[0]
list the writers who have written more than one book.,book.groupby('writer').filter(lambda x: len(x) > 1)['writer']
list the titles of books that are not published.,"book.loc[~book['book_id'].isin(publication['book_id']), 'title']"
show the publishers that have publications with price higher than 10000000 and publications with price lower than 5000000.,"pd.merge(publication.loc[lambda x: x['price'] > 10000000, 'publisher'], publication.loc[lambda x: x['price'] < 5000000, 'publisher']).drop_duplicates()"
what is the number of distinct publication dates?,publication['publication_date'].nunique()
how many distinct publication dates are there in our record?,publication['publication_date'].nunique()
"show the prices of publications whose publisher is either ""person"" or ""wiley""","publication.loc[lambda x: x['publisher'].isin(['person', 'wiley']), 'price']"
how many actors are there?,actor.shape[0]
count the number of actors.,actor.shape[0]
list the name of actors in ascending alphabetical order.,actor.sort_values('name')['name']
"what are the names of actors, ordered alphabetically?",actor.sort_values('name')['name']
what are the characters and duration of actors?,"actor[['character', 'duration']]"
return the characters and durations for each actor.,"actor[['character', 'duration']]"
list the name of actors whose age is not 20.,"actor.loc[lambda x: x['age'] != 20, 'name']"
what are the names of actors who are not 20 years old?,"actor.loc[lambda x: x['age'] != 20, 'name']"
what are the characters of actors in descending order of age?,"actor.sort_values('age', ascending=false)['character']"
"return the characters for actors, ordered by age descending.","actor.sort_values('age', ascending=false)['character']"
what is the duration of the oldest actor?,"actor.sort_values('age', ascending=false).iloc[0]['duration']"
return the duration of the actor with the greatest age.,"actor.sort_values('age', ascending=false).iloc[0]['duration']"
"what are the names of musicals with nominee ""bob fosse""?","musical.loc[musical['nominee']=='bob fosse', 'name']"
return the names of musicals who have the nominee bob fosse.,"musical.loc[musical['nominee']=='bob fosse', 'name']"
"what are the distinct nominees of the musicals with the award that is not ""tony award""?","musical.loc[lambda x: x['award'] != 'tony award', 'nominee'].unique()"
return the different nominees of musicals that have an award that is not the tony award.,"musical.loc[lambda x: x['award'] != 'tony award', 'nominee'].unique()"
show names of actors and names of musicals they are in.,"pd.merge(actor, musical, on='musical_id')[['name_x', 'name_y']]"
what are the names of actors and the musicals that they are in?,"pd.merge(actor, musical, on='musical_id')[['name_x', 'name_y']]"
"show names of actors that have appeared in musical with name ""the phantom of the opera"".","actor.merge(musical.loc[musical['name'] == 'the phantom of the opera', ['musical_id']], on='musical_id')['name']"
what are the names of actors who have been in the musical titled the phantom of the opera?,"actor.merge(musical.loc[musical['name'] == 'the phantom of the opera', ['musical_id']], on='musical_id')['name']"
show names of actors in descending order of the year their musical is awarded.,"pd.merge(actor, musical, on='musical_id').sort_values('year', ascending=false)['name']"
what are the names of actors ordered descending by the year in which their musical was awarded?,"pd.merge(actor, musical, on='musical_id').sort_values('year', ascending=false)['name']"
show names of musicals and the number of actors who have appeared in the musicals.,"actor.merge(musical, on='musical_id').groupby('musical_id')['name'].count().reset_index().rename(columns={'name': 'count'}).merge(musical, on='musical_id')[['name', 'count']]"
how many actors have appeared in each musical?,"actor.merge(musical, on='musical_id').groupby('musical_id')['name'].agg(['count', 'first'])"
show names of musicals which have at least three actors.,"pd.merge(actor, musical, on='musical_id').groupby(['musical_id', 'name']).size().loc[lambda x: x>=3].reset_index().loc[:, 'name']"
what are the names of musicals who have at 3 or more actors?,"pd.merge(actor, musical, on='musical_id').groupby(['musical_id', 'name']).size().loc[lambda x: x>=3].reset_index().loc[:, 'name']"
show different nominees and the number of musicals they have been nominated.,musical.groupby('nominee').size().reset_index(name='count')
how many musicals has each nominee been nominated for?,musical.groupby('nominee').size().reset_index(name='count')
please show the nominee who has been nominated the greatest number of times.,musical.groupby('nominee').size().sort_values(ascending=false).index[0]
who is the nominee who has been nominated for the most musicals?,musical.groupby('nominee').size().sort_values(ascending=false).index[0]
list the most common result of the musicals.,musical.groupby('result').size().sort_values(ascending=false).index[0]
return the most frequent result across all musicals.,musical.groupby('result').size().sort_values(ascending=false).index[0]
list the nominees that have been nominated more than two musicals.,musical.groupby('nominee').filter(lambda x: len(x) > 2)['nominee'].unique()
who are the nominees who have been nominated more than two times?,musical.groupby('nominee').filter(lambda x: len(x) > 2)['nominee'].unique()
list the name of musicals that do not have actors.,"musical.loc[~musical['musical_id'].isin(actor['musical_id']), 'name']"
what are the names of musicals who have no actors?,"musical.loc[~musical['musical_id'].isin(actor['musical_id']), 'name']"
"show the nominees that have nominated musicals for both ""tony award"" and ""drama desk award"".","musical.loc[musical['award']=='tony award', 'nominee'].interesect(musical.loc[musical['award']=='drama desk award', 'nominee'])"
who are the nominees who have been nominated for both a tony award and a drama desk award?,"musical.loc[musical['award']=='tony award', 'nominee'].interesect(musical.loc[musical['award']=='drama desk award', 'nominee'])"
"show the musical nominee with award ""bob fosse"" or ""cleavant derricks"".","musical.loc[musical['award'].isin(['tony award', 'cleavant derricks']), 'nominee']"
who are the nominees who were nominated for either of the bob fosse or cleavant derricks awards?,"musical.loc[musical['award'].isin(['tony award', 'cleavant derricks']), 'nominee']"
"find the emails of the user named ""mary"".","user_profiles.loc[lambda x: x['name']=='mary', 'email']"
"what is the partition id of the user named ""iron man"".","user_profiles.loc[lambda x: x['name']=='iron man', 'partitionid']"
how many users are there?,user_profiles.shape[0]
how many followers does each user have?,follows.shape[0]
find the number of followers for each user.,follows.groupby('f1').size()
find the number of tweets in record.,tweets.shape[0]
find the number of users who posted some tweets.,tweets['uid'].nunique()
find the name and email of the user whose name contains the word ‘swift’.,"user_profiles.loc[user_profiles['name'].str.contains('swift'), ['name', 'email']]"
find the names of users whose emails contain ‘superstar’ or ‘edu’.,"user_profiles.loc[user_profiles['email'].str.contains('superstar|edu'), 'name']"
return the text of tweets about the topic 'intern'.,"tweets.loc[tweets['text'].str.contains('intern', case=false), 'text']"
find the name and email of the users who have more than 1000 followers.,"user_profiles.loc[user_profiles['followers'] > 1000, ['name', 'email']]"
"find the names of the users whose number of followers is greater than that of the user named ""tyler swift"".","user_profiles.loc[lambda x: x['uid'].isin(follows['f1'].groupby(follows['f1']).count().pipe(lambda s:s[s > user_profiles['name'].eq('tyler swift').sum()]).index), 'name']"
find the name and email for the users who have more than one follower.,"user_profiles.merge(follows, left_on='uid', right_on='f1').groupby(['uid', 'name', 'email']).filter(lambda x: len(x) > 1).loc[:, ['name', 'email']].drop_duplicates()"
find the names of users who have more than one tweet.,"pd.merge(user_profiles, tweets, on='uid').groupby('uid').filter(lambda x: len(x) > 1)['name']"
find the id of users who are followed by mary and susan.,"follows.merge(user_profiles[user_profiles['name'] == 'mary'], left_on='f2', right_on='uid')['f1'].intersec‌t(follows.merge(user_profiles[user_profiles['name'] == 'susan'], left_on='f2', right_on='uid')['f1'])"
find the id of users who are followed by mary or susan.,"pd.merge(user_profiles[user_profiles['name'].isin(['mary', 'susan'])], follows, left_on='uid', right_on='f2')['f1']"
find the name of the user who has the largest number of followers.,"user_profiles.sort_values('followers', ascending=false).iloc[0]['name']"
find the name and email of the user followed by the least number of people.,"user_profiles[['name', 'email', 'followers']].sort_values('followers').iloc[0, :2]"
"list the name and number of followers for each user, and sort the results by the number of followers in descending order.","user_profiles[['name', 'followers']].sort_values('followers', ascending=false)"
list the names of 5 users followed by the largest number of other users.,"user_profiles.sort_values('followers', ascending=false).iloc[:5]['name']"
list the text of all tweets in the order of date.,tweets.sort_values('createdate')['text']
find the name of each user and number of tweets tweeted by each of them.,"tweets.merge(user_profiles, on='uid').groupby('uid')['name'].count().reset_index()"
find the name and partition id for users who tweeted less than twice.,"pd.merge(user_profiles, tweets, on='uid').groupby(['uid', 'name', 'partitionid']).filter(lambda x: len(x)<2)[['name', 'partitionid']].drop_duplicates()"
"find the name of the user who tweeted more than once, and number of tweets tweeted by them.","pd.merge(user_profiles, tweets, on='uid').groupby('uid')['name'].count().loc[lambda x: x > 1]"
find the average number of followers for the users who do not have any tweet.,"user_profiles.loc[~user_profiles['uid'].isin(tweets['uid']), 'followers'].mean()"
find the average number of followers for the users who had some tweets.,user_profiles.loc[user_profiles['uid'].isin(tweets['uid'])]['followers'].mean()
find the maximum and total number of followers of all users.,"user_profiles['followers'].agg(['max', 'sum'])"
find the names of all the catalog entries.,catalog_contents['catalog_entry_name'].unique()
what are all the catalog entry names?,catalog_contents['catalog_entry_name'].unique()
find the list of attribute data types possessed by more than 3 attribute definitions.,attribute_definitions.groupby('attribute_data_type').filter(lambda x: len(x) > 3)['attribute_data_type'].unique()
what are the attribute data types with more than 3 attribute definitions?,attribute_definitions.groupby('attribute_data_type').filter(lambda x: len(x) > 3)['attribute_data_type'].unique()
"what is the attribute data type of the attribute with name ""green""?","attribute_definitions.loc[lambda x: x['attribute_name']=='green', 'attribute_data_type']"
"find the attribute data type for the attribute named ""green"".","attribute_definitions.loc[lambda x: x['attribute_name']=='green', 'attribute_data_type']"
find the name and level of catalog structure with level between 5 and 10.,"catalog_structure.loc[(catalog_structure['catalog_level_number'] >= 5) & (catalog_structure['catalog_level_number'] <= 10), ['catalog_level_name', 'catalog_level_number']]"
what are the name and level of catalog structure with level number between 5 and 10,"catalog_structure.loc[(catalog_structure['catalog_level_number'] >= 5) & (catalog_structure['catalog_level_number'] <= 10), ['catalog_level_name', 'catalog_level_number']]"
"find all the catalog publishers whose name contains ""murray""","catalogs.loc[catalogs['catalog_publisher'].str.contains('murray', case=false), 'catalog_publisher'].unique()"
"which catalog publishers have substring ""murray"" in their names?","catalogs.loc[catalogs['catalog_publisher'].str.contains('murray', case=false), 'catalog_publisher'].unique()"
which catalog publisher has published the most catalogs?,catalogs.groupby('catalog_publisher').size().sort_values(ascending=false).index[0]
find the catalog publisher that has the most catalogs.,catalogs.groupby('catalog_publisher').size().sort_values(ascending=false).index[0]
find the names and publication dates of all catalogs that have catalog level number greater than 5.,"pd.merge(catalogs, catalog_structure, on='catalog_id').loc[lambda x: x['catalog_level_number'] > 5, ['catalog_name', 'date_of_publication']]"
what are the name and publication date of the catalogs with catalog level number above 5?,"pd.merge(catalogs, catalog_structure, on='catalog_id').loc[lambda x: x['catalog_level_number'] > 5, ['catalog_name', 'date_of_publication']]"
what are the entry names of catalog with the attribute possessed by most entries.,"catalog_contents.merge(catalog_contents_additional_attributes[catalog_contents_additional_attributes['attribute_value'] == catalog_contents_additional_attributes['attribute_value'].value_counts().index[0]], on='catalog_entry_id')['catalog_entry_name']"
find the entry names of the catalog with the attribute that have the most entries.,"catalog_contents.merge(catalog_contents_additional_attributes.query(""attribute_value == @catalog_contents_additional_attributes['attribute_value'].value_counts().index[0]""), on='catalog_entry_id')['catalog_entry_name']"
what is the entry name of the most expensive catalog (in usd)?,"catalog_contents.sort_values('price_in_dollars', ascending=false).iloc[0]['catalog_entry_name']"
find the entry name of the catalog with the highest price (in usd).,"catalog_contents.sort_values('price_in_dollars', ascending=false).iloc[0]['catalog_entry_name']"
what is the level name of the cheapest catalog (in usd)?,"pd.merge(catalog_contents, catalog_structure, on='catalog_level_number').sort_values('price_in_dollars').iloc[0]['catalog_level_name']"
find the level name of the catalog with the lowest price (in usd).,"pd.merge(catalog_contents, catalog_structure, on='catalog_level_number').sort_values('price_in_dollars').iloc[0]['catalog_level_name']"
what are the average and minimum price (in euro) of all products?,"catalog_contents['price_in_euros'].agg(['mean', 'min'])"
give me the average and minimum price (in euro) of the products.,"catalog_contents['price_in_euros'].agg(['mean', 'min'])"
what is the product with the highest height? give me the catalog entry name.,"catalog_contents.sort_values('height', ascending=false).iloc[0]['catalog_entry_name']"
which catalog content has the highest height? give me the catalog entry name.,"catalog_contents.sort_values('height', ascending=false).iloc[0]['catalog_entry_name']"
find the name of the product that has the smallest capacity.,catalog_contents.sort_values('capacity').iloc[0]['catalog_entry_name']
which catalog content has the smallest capacity? return the catalog entry name.,catalog_contents.sort_values('capacity').iloc[0]['catalog_entry_name']
"find the names of all the products whose stock number starts with ""2"".","catalog_contents.loc[lambda x: x['product_stock_number'].str.startswith('2'), 'catalog_entry_name']"
"which catalog contents have a product stock number that starts from ""2""? show the catalog entry names.","catalog_contents.loc[lambda x: x['product_stock_number'].str.startswith('2'), 'catalog_entry_name']"
find the names of catalog entries with level number 8.,"pd.merge(catalog_contents, catalog_contents_additional_attributes, on='catalog_entry_id').loc[lambda x: x['catalog_level_number']=='8', 'catalog_entry_name']"
what are the names of catalog entries with level number 8?,"pd.merge(catalog_contents, catalog_contents_additional_attributes, on='catalog_entry_id').loc[lambda x: x['catalog_level_number']=='8', 'catalog_entry_name']"
find the names of the products with length smaller than 3 or height greater than 5.,"catalog_contents.loc[(catalog_contents['length'] < 3) | (catalog_contents['width'] > 5), 'catalog_entry_name']"
which catalog contents have length below 3 or above 5? find the catalog entry names.,"catalog_contents.loc[(catalog_contents['length'] < 3) | (catalog_contents['width'] > 5), 'catalog_entry_name']"
find the name and attribute id of the attribute definitions with attribute value 0.,"pd.merge(attribute_definitions, catalog_contents_additional_attributes.loc[lambda x: x['attribute_value']==0], on='attribute_id')[['attribute_name', 'attribute_id']]"
which attribute definitions have attribute value 0? give me the attribute name and attribute id.,"pd.merge(attribute_definitions, catalog_contents_additional_attributes.loc[lambda x: x['attribute_value']==0], on='attribute_id')[['attribute_name', 'attribute_id']]"
find the name and capacity of products with price greater than 700 (in usd).,"catalog_contents.loc[lambda x: x['price_in_dollars']>700, ['catalog_entry_name', 'capacity']]"
which catalog contents has price above 700 dollars? show their catalog entry names and capacities.,"catalog_contents.loc[lambda x: x['price_in_dollars']>700, ['catalog_entry_name', 'capacity']]"
find the dates on which more than one revisions were made.,catalogs.groupby('date_of_latest_revision').filter(lambda x: len(x) > 1)['date_of_latest_revision'].unique()
on which days more than one revisions were made on catalogs.,catalogs.groupby('date_of_latest_revision').filter(lambda x: len(x) > 1)['date_of_latest_revision'].unique()
how many products are there in the records?,catalog_contents.shape[0]
find the total number of catalog contents.,catalog_contents.shape[0]
name all the products with next entry id greater than 8.,"catalog_contents.loc[lambda x: x['next_entry_id'] > 8, 'catalog_entry_name']"
what are the catalog entry names of the products with next entry id above 8?,"catalog_contents.loc[lambda x: x['next_entry_id'] > 8, 'catalog_entry_name']"
how many aircrafts do we have?,len(aircraft)
how many aircrafts exist in the database?,len(aircraft)
show name and distance for all aircrafts.,"aircraft[['name', 'distance']]"
what are the names and distances for all airplanes?,"aircraft[['name', 'distance']]"
show ids for all aircrafts with more than 1000 distance.,"aircraft.loc[aircraft['distance'] > 1000, 'aid']"
what are the ids of all aircrafts that can cover a distance of more than 1000?,"aircraft.loc[aircraft['distance'] > 1000, 'aid']"
how many aircrafts have distance between 1000 and 5000?,"aircraft.loc[aircraft['distance'].between(1000, 5000)].shape[0]"
what is the count of aircrafts that have a distance between 1000 and 5000?,"aircraft.loc[aircraft['distance'].between(1000, 5000)].shape[0]"
what is the name and distance for aircraft with id 12?,"aircraft.loc[aircraft['aid']==12, ['name', 'distance']]"
what is the name and distance for the aircraft that has an id of 12?,"aircraft.loc[aircraft['aid']==12, ['name', 'distance']]"
"what is the minimum, average, and maximum distance of all aircrafts.","aircraft['distance'].agg(['min', 'mean', 'max'])"
"return the minimum, average and maximum distances traveled across all aircrafts.","aircraft['distance'].agg(['min', 'mean', 'max'])"
show the id and name of the aircraft with the maximum distance.,"aircraft[['aid', 'name']].sort_values('distance', ascending=false).head(1)"
what is the id and name of the aircraft that can cover the maximum distance?,"aircraft[['aid', 'name']].sort_values('distance', ascending=false).head(1)"
show the name of aircrafts with top three lowest distances.,aircraft.sort_values('distance').head(3)['name']
what are the aircrafts with top 3 shortest lengthes? list their names.,aircraft.sort_values('distance').head(3)['name']
show names for all aircrafts with distances more than the average.,"aircraft.loc[aircraft['distance'] > aircraft['distance'].mean(), 'name']"
what are the names of all aircrafts that can cover more distances than average?,"aircraft.loc[aircraft['distance'] > aircraft['distance'].mean(), 'name']"
how many employees do we have?,employee.shape[0]
what is the number of employees?,employee.shape[0]
show name and salary for all employees sorted by salary.,"employee[['name', 'salary']].sort_values('salary')"
what is the name and salary of all employees in order of salary?,"employee[['name', 'salary']].sort_values('salary')"
show ids for all employees with at least 100000 salary.,"employee.loc[lambda x: x['salary'] > 100000, 'eid']"
what is the id of every employee who has at least a salary of  100000?,"employee.loc[lambda x: x['salary'] > 100000, 'eid']"
how many employees have salary between 100000 and 200000?,employee.loc[(employee['salary']>=100000) & (employee['salary']<=200000)].shape[0]
what is the number of employees that have a salary between 100000 and 200000?,employee.loc[(employee['salary']>=100000) & (employee['salary']<=200000)].shape[0]
what is the name and salary for employee with id 242518965?,"employee.loc[lambda x: x['eid']==242518965, ['name', 'salary']]"
what is the name and salary of the employee with the id 242518965?,"employee.loc[lambda x: x['eid']==242518965, ['name', 'salary']]"
what is average and maximum salary of all employees.,"employee['salary'].agg(['mean', 'max'])"
what is the average and largest salary of all employees?,"employee['salary'].agg(['mean', 'max'])"
show the id and name of the employee with maximum salary.,"employee[['eid', 'name']].sort_values('salary', ascending=false).head(1)"
what is the id and name of the employee with the highest salary?,"employee[['eid', 'name']].sort_values('salary', ascending=false).head(1)"
show the name of employees with three lowest salaries.,employee.sort_values('salary')['name'].head(3)
what is the name of the 3 employees who get paid the least?,employee.sort_values('salary')['name'].head(3)
show names for all employees with salary more than the average.,"employee.loc[lambda x: x['salary'] > employee['salary'].mean(), 'name']"
what are the names of all employees who have a salary higher than average?,"employee.loc[lambda x: x['salary'] > employee['salary'].mean(), 'name']"
show the id and salary of mark young.,"employee.loc[lambda x: x['name']=='mark young', ['eid', 'salary']]"
what is the id and salary of the employee named mark young?,"employee.loc[lambda x: x['name']=='mark young', ['eid', 'salary']]"
how many flights do we have?,len(flight)
what is the number of flights?,len(flight)
"show flight number, origin, destination of all flights in the alphabetical order of the departure cities.","flight[['flno', 'origin', 'destination']].sort_values('origin')"
"what is the flight number, origin, and destination for all flights in alphabetical order by departure cities?","flight[['flno', 'origin', 'destination']].sort_values('origin')"
show all flight number from los angeles.,"flight.loc[lambda x: x['origin']=='los angeles', 'flno']"
what are the numbers of all flights coming from los angeles?,"flight.loc[lambda x: x['origin']=='los angeles', 'flno']"
show origins of all flights with destination honolulu.,"flight.loc[lambda x: x['destination'] == 'honolulu', 'origin']"
what are the origins of all flights that are headed to honolulu?,"flight.loc[lambda x: x['destination'] == 'honolulu', 'origin']"
show me the departure date and arrival date for all flights from los angeles to honolulu.,"flight.loc[(flight['origin'] == 'los angeles') & (flight['destination'] == 'honolulu'), ['departure_date', 'arrival_date']]"
what are the departure and arrival dates of all flights from la to honolulu?,"flight.loc[(flight['origin'] == 'los angeles') & (flight['destination'] == 'honolulu'), ['departure_date', 'arrival_date']]"
show flight number for all flights with more than 2000 distance.,"flight.loc[lambda x: x['distance'] > 2000, 'flno']"
what are the numbers of all flights that can cover a distance of more than 2000?,"flight.loc[lambda x: x['distance'] > 2000, 'flno']"
what is the average price for flights from los angeles to honolulu.,"flight.loc[(flight['origin']=='los angeles') & (flight['destination']=='honolulu'), 'price'].mean()"
what is the average price for flights from la to honolulu?,"flight.loc[(flight['origin']=='los angeles') & (flight['destination']=='honolulu'), 'price'].mean()"
show origin and destination for flights with price higher than 300.,"flight.loc[lambda x: x['price'] > 300, ['origin', 'destination']]"
what is the origin and destination for all flights whose price is higher than 300?,"flight.loc[lambda x: x['price'] > 300, ['origin', 'destination']]"
show the flight number and distance of the flight with maximum price.,"flight[['flno', 'distance', 'price']].sort_values('price', ascending=false).iloc[0, :2]"
what is the flight number and its distance for the one with the maximum price?,"flight[['flno', 'distance', 'price']].sort_values('price', ascending=false).iloc[0, :2]"
show the flight number of flights with three lowest distances.,flight.sort_values('distance').iloc[:3]['flno']
what are the numbers of the shortest flights?,flight.sort_values('distance').iloc[:3]['flno']
what is the average distance and average price for flights from los angeles.,"flight.loc[lambda x: x['origin']=='los angeles', ['distance', 'price']].mean()"
what is the average distance and price for all flights from la?,"flight.loc[lambda x: x['origin']=='los angeles', ['distance', 'price']].mean()"
show all origins and the number of flights from each origin.,flight.groupby('origin').size()
"for each origin, how many flights came from there?",flight.groupby('origin').size()
show all destinations and the number of flights to each destination.,flight.groupby('destination').size()
what are the destinations and number of flights to each one?,flight.groupby('destination').size()
which origin has most number of flights?,flight.groupby('origin').size().sort_values(ascending=false).index[0]
what place has the most flights coming from there?,flight.groupby('origin').size().sort_values(ascending=false).index[0]
which destination has least number of flights?,flight.groupby('destination').size().sort_values().index[0]
what destination has the fewest number of flights?,flight.groupby('destination').size().sort_values().index[0]
what is the aircraft name for the flight with number 99,"pd.merge(flight.loc[lambda x: x['flno'] == 99], aircraft, on='aid')['name']"
what is the name of the aircraft that was on flight number 99?,"pd.merge(flight.loc[lambda x: x['flno'] == 99], aircraft, on='aid')['name']"
show all flight numbers with aircraft airbus a340-300.,"pd.merge(flight, aircraft, on='aid').loc[lambda x: x['name']=='airbus a340-300', 'flno']"
what are the flight numbers for the aircraft airbus a340-300?,"pd.merge(flight, aircraft, on='aid').loc[lambda x: x['name']=='airbus a340-300', 'flno']"
show aircraft names and number of flights for each aircraft.,"flight.merge(aircraft, on='aid').groupby('aid')['name'].agg(['count'])"
what is the name of each aircraft and how many flights does each one complete?,"flight.merge(aircraft, on='aid').groupby('aid')['name'].agg(['count'])"
show names for all aircraft with at least two flights.,"flight.merge(aircraft, on='aid').groupby('aid')['name'].filter(lambda x: len(x) >= 2)"
what are the names for all aircrafts with at least 2 flights?,"flight.merge(aircraft, on='aid').groupby('aid')['name'].filter(lambda x: len(x) >= 2)"
how many employees have certificate.,certificate['eid'].nunique()
what is the count of distinct employees with certificates?,certificate['eid'].nunique()
show ids for all employees who don't have a certificate.,employee[~employee['eid'].isin(certificate['eid'])]['eid']
what are the ids of all employees that don't have certificates?,employee[~employee['eid'].isin(certificate['eid'])]['eid']
show names for all aircrafts of which john williams has certificates.,"pd.merge(pd.merge(employee, certificate, on='eid'), aircraft, on='aid').loc[lambda x: x['name']=='john williams', 'name']"
what are the names of all aircrafts that john williams have certificates to be able to fly?,"pd.merge(pd.merge(employee, certificate, on='eid'), aircraft, on='aid').loc[lambda x: x['name']=='john williams', 'name']"
show names for all employees who have certificate of boeing 737-800.,"pd.merge(pd.merge(employee, certificate, on='eid'), aircraft, on='aid').loc[lambda x: x['name']=='boeing 737-800', 'name']"
what are the names of all employees who have a certificate to fly boeing 737-800?,"pd.merge(pd.merge(employee, certificate, on='eid'), aircraft, on='aid').loc[lambda x: x['name']=='boeing 737-800', 'name']"
show names for all employees who have certificates on both boeing 737-800 and airbus a340-300.,"set(employee.loc[pd.merge(pd.merge(certificate, aircraft.loc[aircraft['name']=='boeing 737-800'], on='aid'), employee, on='eid')['name']].tolist()).intersection(set(employee.loc[pd.merge(pd.merge(certificate, aircraft.loc[aircraft['name']=='airbus a340-300'], on='aid'), employee, on='eid')['name']].tolist()))"
what are the names of all employees who can fly both the boeing 737-800 and the airbus a340-300?,"set(employee.loc[pd.merge(pd.merge(certificate, aircraft.loc[aircraft['name']=='boeing 737-800'], on='aid'), employee, on='eid')['name']].tolist()).intersection(set(employee.loc[pd.merge(pd.merge(certificate, aircraft.loc[aircraft['name']=='airbus a340-300'], on='aid'), employee, on='eid')['name']].tolist()))"
show names for all employees who do not have certificate of boeing 737-800.,"employee[~employee['name'].isin(pd.merge(pd.merge(employee, certificate, on='eid'), aircraft, on='aid').loc[lambda x: x['name']=='boeing 737-800', 'name'])]['name']"
what are the names of all employees who are not certified to fly boeing 737-800s?,"employee[~employee['name'].isin(pd.merge(pd.merge(employee, certificate, on='eid'), aircraft, on='aid').loc[lambda x: x['name']=='boeing 737-800', 'name'])]['name']"
show the name of aircraft which fewest people have its certificate.,"pd.merge(certificate, aircraft, on='aid').groupby('aid')['name'].count().idxmax()"
what are the names of the aircraft that the least people are certified to fly?,"pd.merge(certificate, aircraft, on='aid').groupby('aid')['name'].count().idxmax()"
show the name and distance of the aircrafts with more than 5000 distance and which at least 5 people have its certificate.,"pd.merge(certificate, aircraft, on='aid').loc[lambda x: x['distance']>5000].groupby('aid')['name'].first().value_counts().loc[lambda x: x>=5].index.tolist()"
what is the name and distance of every aircraft that can cover a distance of more than 5000 and which at least 5 people can fly?,"pd.merge(certificate, aircraft, on='aid').loc[lambda x: x['distance']>5000].groupby('aid')['name'].first().value_counts().loc[lambda x: x>=5].index.tolist()"
what is the salary and name of the employee who has the most number of aircraft certificates?,"employee.merge(certificate, on='eid').groupby(['eid', 'name', 'salary']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'salary']]"
what is the salaray and name of the employee that is certified to fly the most planes?,"employee.merge(certificate, on='eid').groupby(['eid', 'name', 'salary']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'salary']]"
what is the salary and name of the employee who has the most number of certificates on aircrafts with distance more than 5000?,"employee.merge(certificate).merge(aircraft).loc[lambda x: x['distance'] > 5000].groupby('eid').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0].name"
what is the salaray and name of the employee with the most certificates to fly planes more than 5000?,"employee.merge(certificate).merge(aircraft).loc[lambda x: x['distance'] > 5000].groupby('eid').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0].name"
how many allergies are there?,allergy_type['allergy'].nunique()
how many allergy entries are there?,allergy_type['allergy'].nunique()
how many different allergy types exist?,allergy_type['allergytype'].nunique()
how many distinct allergies are there?,allergy_type['allergytype'].nunique()
show all allergy types.,allergy_type['allergytype'].unique()
what are the different allergy types?,allergy_type['allergytype'].unique()
show all allergies and their types.,"allergy_type[['allergy', 'allergytype']]"
what are the allergies and their types?,"allergy_type[['allergy', 'allergytype']]"
show all allergies with type food.,"allergy_type.loc[lambda x: x['allergytype']=='food', 'allergy'].unique()"
what are all the different food allergies?,"allergy_type.loc[lambda x: x['allergytype']=='food', 'allergy'].unique()"
what is the type of allergy cat?,"allergy_type.loc[lambda x: x['allergy']=='cat', 'allergytype']"
what is allergy type of a cat allergy?,"allergy_type.loc[lambda x: x['allergy']=='cat', 'allergytype']"
how many allergies have type animal?,(allergy_type['allergytype']=='animal').sum()
how many animal type allergies exist?,(allergy_type['allergytype']=='animal').sum()
show all allergy types and the number of allergies in each type.,allergy_type.groupby('allergytype').size().reset_index(name='count')
what are the allergy types and how many allergies correspond to each one?,allergy_type.groupby('allergytype').size().reset_index(name='count')
which allergy type has most number of allergies?,"allergy_type.groupby('allergytype').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['allergytype']"
which allergy type is most common?,"allergy_type.groupby('allergytype').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['allergytype']"
which allergy type has least number of allergies?,allergy_type.groupby('allergytype').size().sort_values().index[0]
which allergy type is the least common?,allergy_type.groupby('allergytype').size().sort_values().index[0]
how many students are there?,student.shape[0]
what is the total number of students?,student.shape[0]
show first name and last name for all students.,"student[['fname', 'lname']]"
what are the full names of all students,"student[['fname', 'lname']]"
how many different advisors are listed?,student['advisor'].nunique()
how many advisors are there?,student['advisor'].nunique()
show all majors.,student['major'].unique()
what are the different majors?,student['major'].unique()
show all cities where students live.,student['city_code'].unique()
what cities do students live in?,student['city_code'].unique()
"show first name, last name, age for all female students. their sex is f.","student.loc[student['sex']=='f', ['fname', 'lname', 'age']]"
what are the full names and ages for all female students whose sex is f?,"student.loc[student['sex']=='f', ['fname', 'lname', 'age']]"
show student ids for all male students.,"student.loc[lambda x : x['sex'] == 'm', 'stuid']"
what are the student ids for all male students?,"student.loc[lambda x : x['sex'] == 'm', 'stuid']"
how many students are age 18?,(student['age']==18).sum()
how many students are 18 years old?,(student['age']==18).sum()
show all student ids who are older than 20.,"student.loc[lambda x: x['age']>20, 'stuid']"
what are the student ids for students over 20 years old?,"student.loc[lambda x: x['age']>20, 'stuid']"
"which city does the student whose last name is ""kim"" live in?","student.loc[lambda x: x['lname'] == 'kim', 'city_code']"
give the city that the student whose family name is kim lives in.,"student.loc[lambda x: x['lname'] == 'kim', 'city_code']"
who is the advisor of student with id 1004?,"student.loc[lambda x: x['stuid']==1004, 'advisor']"
who advises student 1004?,"student.loc[lambda x: x['stuid']==1004, 'advisor']"
how many students live in hkg or chi?,((student['city_code'] == 'hkg') | (student['city_code'] == 'chi')).sum()
give the number of students living in either hkg or chi.,((student['city_code'] == 'hkg') | (student['city_code'] == 'chi')).sum()
"show the minimum, average, and maximum age of all students.","student['age'].agg(['min', 'mean', 'max'])"
"what is the minimum, mean, and maximum age across all students?","student['age'].agg(['min', 'mean', 'max'])"
what is the last name of the youngest student?,"student.loc[student['age'] == student['age'].min(), 'lname']"
provide the last name of the youngest student.,"student.loc[student['age'] == student['age'].min(), 'lname']"
show the student id of the oldest student.,"student.loc[student['age'] == student['age'].max(), 'stuid']"
what student id corresponds to the oldest student?,"student.loc[student['age'] == student['age'].max(), 'stuid']"
show all majors and corresponding number of students.,student.groupby('major').size()
how many students are there for each major?,student.groupby('major').size()
which major has most number of students?,student.groupby('major').size().sort_values(ascending=false).index[0]
what is the largest major?,student.groupby('major').size().sort_values(ascending=false).index[0]
show all ages and corresponding number of students.,student.groupby('age').size().reset_index(name='count')
how old is each student and how many students are each age?,student.groupby('age').size().reset_index(name='count')
show the average age for male and female students.,student.groupby('sex')['age'].mean()
what are the average ages for male and female students?,student.groupby('sex')['age'].mean()
show all cities and corresponding number of students.,student.groupby('city_code').size().reset_index(name='count')
how many students live in each city?,student.groupby('city_code').size().reset_index(name='count')
show all advisors and corresponding number of students.,student.groupby('advisor').size()
how many students does each advisor have?,student.groupby('advisor').size()
which advisor has most number of students?,student.groupby('advisor').size().sort_values(ascending=false).index[0]
give the advisor with the most students.,student.groupby('advisor').size().sort_values(ascending=false).index[0]
how many students have cat allergies?,"(has_allergy['allergy'] == ""cat"").sum()"
how many students are affected by cat allergies?,"(has_allergy['allergy'] == ""cat"").sum()"
show all student ids who have at least two allergies.,has_allergy.groupby('stuid').filter(lambda x: len(x)>=2)['stuid'].unique()
what are the students ids of students who have more than one allergy?,has_allergy.groupby('stuid').filter(lambda x: len(x)>=2)['stuid'].unique()
what are the student ids of students who don't have any allergies?,student[~student['stuid'].isin(has_allergy['stuid'])]['stuid']
which students are unaffected by allergies?,student[~student['stuid'].isin(has_allergy['stuid'])]['stuid']
how many female students have milk or egg allergies?,"pd.merge(has_allergy, student, on='stuid').loc[lambda x: (x['sex']=='f') & (x['allergy'].isin(['milk', 'eggs']))].shape[0]"
how many students who are female are allergic to milk or eggs?,"pd.merge(has_allergy, student, on='stuid').loc[lambda x: (x['sex']=='f') & (x['allergy'].isin(['milk', 'eggs']))].shape[0]"
how many students have a food allergy?,"pd.merge(has_allergy, allergy_type.loc[lambda x: x['allergytype']=='food'], on='allergy').shape[0]"
how many students are affected by food related allergies?,"pd.merge(has_allergy, allergy_type.loc[lambda x: x['allergytype']=='food'], on='allergy').shape[0]"
which allergy has most number of students affected?,has_allergy.groupby('allergy').size().sort_values(ascending=false).index[0]
which allergy is the most common?,has_allergy.groupby('allergy').size().sort_values(ascending=false).index[0]
show all allergies with number of students affected.,has_allergy['allergy'].value_counts()
how many students have each different allergy?,has_allergy['allergy'].value_counts()
show all allergy type with number of students affected.,"has_allergy.merge(allergy_type, left_on='allergy', right_on='allergy').groupby('allergytype').size()"
how many students are affected by each allergy type?,"has_allergy.merge(allergy_type, left_on='allergy', right_on='allergy').groupby('allergytype').size()"
find the last name and age of the student who has allergy to both milk and cat.,"student.loc[lambda x: x['stuid'].isin(has_allergy.query('allergy in [""milk"", ""cat""]').stuid), ['lname', 'age']]"
what are the last names and ages of the students who are allergic to milk and cat?,"student.loc[lambda x: x['stuid'].isin(has_allergy.query('allergy in [""milk"", ""cat""]').stuid), ['lname', 'age']]"
what are the allergies and their types that the student with first name lisa has? and order the result by name of allergies.,"pd.merge(pd.merge(allergy_type, has_allergy, on='allergy'), student.loc[lambda x:x['fname']=='lisa'], on='stuid').sort_values('allergy')[['allergy', 'allergytype']]"
what are the allergies the girl named lisa has? and what are the types of them? order the result by allergy names.,"pd.merge(pd.merge(allergy_type, has_allergy, on='allergy'), student.loc[lambda x:x['fname']=='lisa'], on='stuid').sort_values('allergy')[['allergy', 'allergytype']]"
find the first name and gender of the student who has allergy to milk but not cat.,"student.loc[student['stuid'].isin(has_allergy.loc[has_allergy['allergy']=='milk', 'stuid'].values).difference(has_allergy.loc[has_allergy['allergy']=='cat', 'stuid'].values),['fname', 'sex']]"
what are the first name and gender of the students who have allergy to milk but can put up with cats?,"student.loc[student['stuid'].isin(has_allergy.loc[has_allergy['allergy']=='milk', 'stuid'].values).difference(has_allergy.loc[has_allergy['allergy']=='cat', 'stuid'].values),['fname', 'sex']]"
find the average age of the students who have allergies with food and animal types.,"student.loc[student['stuid'].isin(has_allergy.merge(allergy_type.query('allergytype==""food""'), on='allergy')['stuid'].interesect(has_allergy.merge(allergy_type.query('allergytype==""animal""'), on='allergy')['stuid']))]['age'].mean()"
how old are the students with allergies to food and animal types on average?,"student.loc[student['stuid'].isin(has_allergy.merge(allergy_type.query('allergytype==""food""'), on='allergy')['stuid'].interesect(has_allergy.merge(allergy_type.query('allergytype==""animal""'), on='allergy')['stuid']))]['age'].mean()"
list the first and last name of the students who do not have any food type allergy.,"student.loc[~student['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda x: x['allergytype'] == ""food""], on='allergy', how='inner')['stuid']), ['fname', 'lname']]"
what is the full name of each student who is not allergic to any type of food.,"student.loc[~student['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda x: x['allergytype'] == ""food""], on='allergy', how='inner')['stuid']), ['fname', 'lname']]"
find the number of male (sex is 'm') students who have some food type allery.,student.loc[lambda x: (x['sex']=='m') & (x['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda x: x['allergytype']=='food'])['stuid']))].shape[0]
how many male students (sex is 'm') are allergic to any type of food?,student.loc[lambda x: (x['sex']=='m') & (x['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda x: x['allergytype']=='food'])['stuid']))].shape[0]
find the different first names and cities of the students who have allergy to milk or cat.,"pd.merge(student, has_allergy.query('allergy==""milk"" or allergy==""cat""'), on='stuid')[['fname', 'city_code']].drop_duplicates()"
what are the distinct first names and cities of the students who have allergy either to milk or to cat?,"pd.merge(student, has_allergy.query('allergy==""milk"" or allergy==""cat""'), on='stuid')[['fname', 'city_code']].drop_duplicates()"
find the number of students who are older than 18 and do not have allergy to either food or animal.,"student.loc[lambda x: (x['age'] > 18) & (~x['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda y: (y['allergytype']=='food') | (y['allergytype']=='animal')], on='allergy', how='inner')['stuid']))].shape[0]"
how many students are over 18 and do not have allergy to food type or animal type?,"student.loc[lambda x: (x['age'] > 18) & (~x['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda y: (y['allergytype']=='food') | (y['allergytype']=='animal')], on='allergy', how='inner')['stuid']))].shape[0]"
find the first name and major of the students who are not allegry to soy.,"student.loc[~student['stuid'].isin(has_allergy.loc[has_allergy['allergy']=='soy', 'stuid']), ['fname', 'major']]"
what are the first name and major of the students who are able to consume soy?,"student.loc[~student['stuid'].isin(has_allergy.loc[has_allergy['allergy']=='soy', 'stuid']), ['fname', 'major']]"
a list of the top 5 countries by number of invoices. list country name and number of invoices.,invoices.groupby('billing_country').size().sort_values(ascending=false).head(5)
what are the top 5 countries by number of invoices and how many do they have?,invoices.groupby('billing_country').size().sort_values(ascending=false).head(5)
a list of the top 8 countries by gross/total invoice size. list country name and gross invoice size.,invoices.groupby('billing_country')['total'].sum().sort_values(ascending=false).head(8)
what are the names of the top 8 countries by total invoice size and what are those sizes?,invoices.groupby('billing_country')['total'].sum().sort_values(ascending=false).head(8)
a list of the top 10 countries by average invoice size. list country name and average invoice size.,invoices.groupby('billing_country')['total'].mean().sort_values(ascending=false).head(10)
what are the names of the countries and average invoice size of the top countries by size?,invoices.groupby('billing_country')['total'].mean().sort_values(ascending=false).head(10)
find out 5 customers who most recently purchased something. list customers' first and last name.,"customers.merge(invoices, on='customer_id')[['first_name', 'last_name']].sort_values('invoice_date', ascending=false).head(5)"
what are the first and last names of the 5 customers who purchased something most recently?,"customers.merge(invoices, on='customer_id')[['first_name', 'last_name']].sort_values('invoice_date', ascending=false).head(5)"
find out the top 10 customers by total number of orders. list customers' first and last name and the number of total orders.,"customers.merge(invoices, left_on='id', right_on='customer_id').groupby(['id','first_name','last_name']).size().reset_index(name='count').sort_values('count', ascending=false)[:10][['first_name', 'last_name', 'count']]"
what are the top 10 customers' first and last names by total number of orders and how many orders did they make?,"customers.merge(invoices, left_on='id', right_on='customer_id').groupby(['id','first_name','last_name']).size().reset_index(name='count').sort_values('count', ascending=false)[:10][['first_name', 'last_name', 'count']]"
list the top 10 customers by total gross sales. list customers' first and last name and total gross sales.,"invoices.merge(customers, left_on='customer_id', right_on='id').groupby(['first_name', 'last_name'], as_index=false)['total'].sum().sort_values('total', ascending=false).head(10)[['first_name', 'last_name', 'total']]"
"what are the top 10 customers' first and last names with the highest gross sales, and also what are the sales?","invoices.merge(customers, left_on='customer_id', right_on='id').groupby(['first_name', 'last_name'], as_index=false)['total'].sum().sort_values('total', ascending=false).head(10)[['first_name', 'last_name', 'total']]"
list the top 5 genres by number of tracks. list genres name and total tracks.,"genres.merge(tracks, left_on='id', right_on='genre_id').groupby('name').size().reset_index(name='count').sort_values(by='count', ascending=false).head(5)"
how many tracks does each genre have and what are the names of the top 5?,"genres.merge(tracks, left_on='id', right_on='genre_id').groupby('name').size().reset_index(name='count').sort_values(by='count', ascending=false).head(5)"
list every album's title.,albums['title']
what are the titles of all the albums?,albums['title']
list every album ordered by album title in ascending order.,albums.sort_values('title')['title']
what are the titles of all the albums alphabetically ascending?,albums.sort_values('title')['title']
list every album whose title starts with a in alphabetical order.,albums.loc[lambda x: x['title'].str.startswith('a')].sort_values('title')['title']
what are the titles of all albums that start with a in alphabetical order?,albums.loc[lambda x: x['title'].str.startswith('a')].sort_values('title')['title']
list the customers first and last name of 10 least expensive invoices.,"pd.merge(customers, invoices, on='id').sort_values('total')[['first_name', 'last_name']].head(10)"
what are the first and last names of the customers with the 10 cheapest invoices?,"pd.merge(customers, invoices, on='id').sort_values('total')[['first_name', 'last_name']].head(10)"
"list total amount of  invoice from chicago, il.","invoices.loc[(invoices['billing_city']=='chicago') & (invoices['billing_state']=='il'), 'total'].sum()"
"what are the total amount of money in the invoices billed from chicago, illinois?","invoices.loc[(invoices['billing_city']=='chicago') & (invoices['billing_state']=='il'), 'total'].sum()"
"list the number of invoices from chicago, il.",invoices[(invoices['billing_city'] == 'chicago') & (invoices['billing_state'] == 'il')].shape[0]
"how many invoices were billed from chicago, il?",invoices[(invoices['billing_city'] == 'chicago') & (invoices['billing_state'] == 'il')].shape[0]
"list the number of invoices from the us, grouped by state.","invoices.loc[invoices['billing_country']=='usa', 'billing_state'].value_counts()"
how many invoices were billed from each state?,"invoices.loc[invoices['billing_country']=='usa', 'billing_state'].value_counts()"
list the state in the us with the most invoices.,"(invoices.loc[invoices['billing_country']=='usa', :].groupby('billing_state').size().sort_values(ascending=false).head(1).reset_index(name='count')).iloc[0]"
what are the states with the most invoices?,"(invoices.loc[invoices['billing_country']=='usa', :].groupby('billing_state').size().sort_values(ascending=false).head(1).reset_index(name='count')).iloc[0]"
list the number of invoices and the invoice total from california.,"invoices.loc[invoices['billing_state']=='ca'].agg({'billing_state': 'first', 'total': 'sum', 'billing_state': 'count'})"
what is the number of invoices and total money billed in them from ca?,"invoices.loc[invoices['billing_state']=='ca'].agg({'billing_state': 'first', 'total': 'sum', 'billing_state': 'count'})"
list aerosmith's albums.,"albums.loc[lambda x: x['artist_id'].isin(artists.loc[lambda y: y['name']=='aerosmith', 'id']), 'title']"
what are the titles of all the aerosmith albums?,"albums.loc[lambda x: x['artist_id'].isin(artists.loc[lambda y: y['name']=='aerosmith', 'id']), 'title']"
how many albums does billy cobham has?,"pd.merge(albums, artists, left_on='artist_id', right_on='id').loc[lambda x: x['name']=='billy cobham'].shape[0]"
how many albums has billy cobam released?,"pd.merge(albums, artists, left_on='artist_id', right_on='id').loc[lambda x: x['name']=='billy cobham'].shape[0]"
eduardo martins is a customer at which company?,"customers.loc[(customers['first_name'] == 'eduardo') & (customers['last_name'] == 'martins'), 'company']"
what is the company where eduardo martins is a customer?,"customers.loc[(customers['first_name'] == 'eduardo') & (customers['last_name'] == 'martins'), 'company']"
what is astrid gruber's email and phone number?,"customers.loc[(customers['first_name']=='astrid') & (customers['last_name']=='gruber'), ['email', 'phone']]"
what is the email and phone number of astrid gruber the customer?,"customers.loc[(customers['first_name']=='astrid') & (customers['last_name']=='gruber'), ['email', 'phone']]"
how many customers live in prague city?,(customers['city'] == 'prague').sum()
how many customers live in the city of prague?,(customers['city'] == 'prague').sum()
how many customers in state of ca?,(customers['state'] == 'ca').sum()
how many customers are from california?,(customers['state'] == 'ca').sum()
what country does roberto almeida live?,"customers.loc[(customers['first_name'] == 'roberto') & (customers['last_name'] == 'almeida'), 'country']"
in which country does roberto almeida?,"customers.loc[(customers['first_name'] == 'roberto') & (customers['last_name'] == 'almeida'), 'country']"
list the name of albums that are released by aritist whose name has 'led',"pd.merge(artists.loc[lambda x: x['name'].str.contains('led', case=false)], albums, on='artist_id')['title']"
what is the title of the album that was released by the artist whose name has the phrase 'led'?,"pd.merge(artists.loc[lambda x: x['name'].str.contains('led', case=false)], albums, on='artist_id')['title']"
how many customers does steve johnson support?,"employees.merge(customers, left_on='id', right_on='support_rep_id').query('first_name == ""steve"" and last_name == ""johnson""').shape[0]"
what is the count of customers that steve johnson supports?,"employees.merge(customers, left_on='id', right_on='support_rep_id').query('first_name == ""steve"" and last_name == ""johnson""').shape[0]"
"what is the title, phone and hire date of nancy edwards?","employees.loc[(employees['first_name'] == 'nancy') & (employees['last_name'] == 'edwards'), ['title', 'phone', 'hire_date']]"
"what is the title, phone number and hire date for the employee named nancy edwards?","employees.loc[(employees['first_name'] == 'nancy') & (employees['last_name'] == 'edwards'), ['title', 'phone', 'hire_date']]"
find the full name of employees who report to nancy edwards?,"employees.merge(employees[['id', 'first_name', 'last_name']].rename(columns={'id': 'reports_to'}), on='reports_to',suffixes=('', '_manager')).query('first_name_manager == ""nancy"" & last_name_manager == ""edwards""')[['first_name', 'last_name']]"
what is the first and last name of the employee who reports to nancy edwards?,"employees.merge(employees[['id', 'first_name', 'last_name']].rename(columns={'id': 'reports_to'}), on='reports_to',suffixes=('', '_manager')).query('first_name_manager == ""nancy"" & last_name_manager == ""edwards""')[['first_name', 'last_name']]"
what is the address of employee nancy edwards?,"employees.loc[(employees['first_name'] == 'nancy') & (employees['last_name'] == 'edwards'), 'address']"
what is nancy edwards's address?,"employees.loc[(employees['first_name'] == 'nancy') & (employees['last_name'] == 'edwards'), 'address']"
find the full name of employee who supported the most number of customers.,"pd.merge(employees, customers, left_on='id', right_on='support_rep_id').groupby(['id', 'first_name', 'last_name']).size().reset_index(name='counts').sort_values('counts', ascending=false).iloc[0][['first_name', 'last_name']]"
what is the full name of the employee who has the most customers?,"pd.merge(employees, customers, left_on='id', right_on='support_rep_id').groupby(['id', 'first_name', 'last_name']).size().reset_index(name='counts').sort_values('counts', ascending=false).iloc[0][['first_name', 'last_name']]"
how many employees are living in canada?,(employees['country'] == 'canada').sum()
how many employees live in canada?,(employees['country'] == 'canada').sum()
what is employee nancy edwards's phone number?,"employees.loc[(employees['first_name']=='nancy') & (employees['last_name']=='edwards'), 'phone']"
what is the the phone number of nancy edwards?,"employees.loc[(employees['first_name']=='nancy') & (employees['last_name']=='edwards'), 'phone']"
who is the youngest employee in the company? list employee's first and last name.,"employees.sort_values('birth_date', ascending=false).iloc[:1, ['first_name', 'last_name']]"
what si the youngest employee's first and last name?,"employees.sort_values('birth_date', ascending=false).iloc[:1, ['first_name', 'last_name']]"
list top 10 employee work longest in the company. list employee's first and last name.,"employees[['first_name', 'last_name']].sort_values('hire_date').head(10)"
what are the first and last names of the top 10 longest-serving employees?,"employees[['first_name', 'last_name']].sort_values('hire_date').head(10)"
find the number of employees whose title is it staff from each city?,employees.loc[lambda x: x['title']=='it staff'].groupby('city').size().reset_index(name='count(*)')
how many employees who are it staff are from each city?,employees.loc[lambda x: x['title']=='it staff'].groupby('city').size().reset_index(name='count(*)')
"which employee manage most number of peoples? list employee's first and last name, and number of people report to that employee.","employees.merge(employees, left_on='reports_to', right_on='id', suffixes=('', '_manager')).groupby(by=['id_manager', 'first_name_manager', 'last_name_manager']).size().reset_index(name='count_reports_to').sort_values(by='count_reports_to', ascending=false).head(1)[['first_name_manager', 'last_name_manager', 'count_reports_to']]"
what are the first and last names of all the employees and how many people report to them?,"employees.merge(employees, left_on='reports_to', right_on='id', suffixes=('', '_manager')).groupby(by=['id_manager', 'first_name_manager', 'last_name_manager']).size().reset_index(name='count_reports_to').sort_values(by='count_reports_to', ascending=false).head(1)[['first_name_manager', 'last_name_manager', 'count_reports_to']]"
how many orders does lucas mancini has?,"pd.merge(customers.loc[lambda x: (x['first_name']=='lucas') & (x['last_name']=='mancini')], invoices, on='customer_id').shape[0]"
how many orders does luca mancini have in his invoices?,"pd.merge(customers.loc[lambda x: (x['first_name']=='lucas') & (x['last_name']=='mancini')], invoices, on='customer_id').shape[0]"
what is the total amount of money spent by lucas mancini?,"pd.merge(customers[customers['first_name']=='lucas'][customers['last_name']=='mancini'], invoices, on='customer_id')['total'].sum()"
how much money did lucas mancini spend?,"pd.merge(customers[customers['first_name']=='lucas'][customers['last_name']=='mancini'], invoices, on='customer_id')['total'].sum()"
list all media types.,media_types['name']
what are the names of all the media types?,media_types['name']
list all different genre types.,genres['name'].unique()
what are the different names of the genres?,genres['name'].unique()
list the name of all playlist.,playlists['name']
what are the names of all the playlists?,playlists['name']
who is the composer of track fast as a shark?,"tracks.loc[lambda x: x['name'] == 'fast as a shark', 'composer']"
"what is the composer who created the track ""fast as a shark""?","tracks.loc[lambda x: x['name'] == 'fast as a shark', 'composer']"
how long does track fast as a shark has?,"tracks.loc[lambda x: x['name'] == 'fast as a shark', 'milliseconds']"
how many milliseconds long is fast as a shark?,"tracks.loc[lambda x: x['name'] == 'fast as a shark', 'milliseconds']"
what is the name of tracks whose genre is rock?,"tracks.merge(genres, left_on='genre_id', right_on='id').loc[lambda x: x['name']=='rock', 'name_y']"
what is the name of all tracks in the rock genre?,"tracks.merge(genres, left_on='genre_id', right_on='id').loc[lambda x: x['name']=='rock', 'name_y']"
what is title of album which track balls to the wall belongs to?,"albums.loc[lambda x: x['id'].isin(tracks.loc[lambda y: y['name']=='balls to the wall', 'genre_id']), 'title']"
what is the name of the album that has the track ball to the wall?,"albums.loc[lambda x: x['id'].isin(tracks.loc[lambda y: y['name']=='balls to the wall', 'genre_id']), 'title']"
list name of all tracks in balls to the wall.,"pd.merge(albums.loc[lambda x: x['title']=='balls to the wall'], tracks, left_on='id', right_on='genre_id')['name']"
what is the name of all tracks in the album named balls to the wall?,"pd.merge(albums.loc[lambda x: x['title']=='balls to the wall'], tracks, left_on='id', right_on='genre_id')['name']"
list title of albums have the number of tracks greater than 10.,"albums.merge(tracks, on='album_id').groupby('id').filter(lambda x: len(x) > 10)['title']"
what are the names of the albums that have more than 10 tracks?,"albums.merge(tracks, on='album_id').groupby('id').filter(lambda x: len(x) > 10)['title']"
list the name of tracks belongs to genre rock and whose media type is mpeg audio file.,"pd.merge(pd.merge(genres[genres['name']=='rock'], tracks, on='genre_id'), media_types[media_types['name']=='mpeg audio file'], on='media_type_id')['name']"
what are the names of all rock tracks that are stored on mpeg audio files?,"pd.merge(pd.merge(genres[genres['name']=='rock'], tracks, on='genre_id'), media_types[media_types['name']=='mpeg audio file'], on='media_type_id')['name']"
list the name of tracks belongs to genre rock or media type is mpeg audio file.,"pd.merge(pd.merge(genres.loc[genres['name']==""rock""], tracks, on='genre_id'), media_types.loc[media_types['name']=='mpeg audio file'], on='media_type_id')['name']"
what are the names of all tracks that belong to the rock genre and whose media type is mpeg?,"pd.merge(pd.merge(genres.loc[genres['name']==""rock""], tracks, on='genre_id'), media_types.loc[media_types['name']=='mpeg audio file'], on='media_type_id')['name']"
list the name of tracks belongs to genre rock or genre jazz.,"pd.merge(genres.loc[lambda x: x['name'].isin(['rock', 'jazz'])], tracks, on='genre_id')['name_y']"
what are the names of the tracks that are rock or jazz songs?,"pd.merge(genres.loc[lambda x: x['name'].isin(['rock', 'jazz'])], tracks, on='genre_id')['name_y']"
list the name of all tracks in the playlists of movies.,"pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='movies', 'name']"
what are the names of all tracks that are on playlists titled movies?,"pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='movies', 'name']"
list the name of playlist which has number of tracks greater than 100.,"pd.merge(playlist_tracks, playlists, on='id').groupby('playlist_id').filter(lambda x: x['track_id'].count() > 100)['name']"
what are the names of all playlists that have more than 100 tracks?,"pd.merge(playlist_tracks, playlists, on='id').groupby('playlist_id').filter(lambda x: x['track_id'].count() > 100)['name']"
list all tracks bought by customer daan peeters.,"tracks.merge(invoice_lines, left_on='id', right_on='track_id').merge(invoices, on='invoice_id').merge(customers, on='customer_id').loc[(customers['first_name']=='daan') & (customers['last_name']=='peeters'), 'name']"
what are the tracks that dean peeters bought?,"tracks.merge(invoice_lines, left_on='id', right_on='track_id').merge(invoices, on='invoice_id').merge(customers, on='customer_id').loc[(customers['first_name']=='daan') & (customers['last_name']=='peeters'), 'name']"
how much is the track fast as a shark?,"tracks.loc[lambda x: x['name']=='fast as a shark', 'unit_price']"
"what is the unit price of the tune ""fast as a shark""?","tracks.loc[lambda x: x['name']=='fast as a shark', 'unit_price']"
find the name of tracks which are in movies playlist but not in music playlist.,"set(tracks.merge(playlist_tracks, left_on='id', right_on='track_id').merge(playlists, left_on='playlist_id', right_on='id').loc[lambda x: x['name']=='movies', 'name']).difference(tracks.merge(playlist_tracks, left_on='id', right_on='track_id').merge(playlists, left_on='playlist_id', right_on='id').loc[lambda x: x['name']=='music', 'name'])"
what are the names of all tracks that are on the movies playlist but not in the music playlist?,"set(tracks.merge(playlist_tracks, left_on='id', right_on='track_id').merge(playlists, left_on='playlist_id', right_on='id').loc[lambda x: x['name']=='movies', 'name']).difference(tracks.merge(playlist_tracks, left_on='id', right_on='track_id').merge(playlists, left_on='playlist_id', right_on='id').loc[lambda x: x['name']=='music', 'name'])"
find the name of tracks which are in both movies and music playlists.,"pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='movies', 'name'].isin(pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='music', 'name']).unique()"
what are the names of all the tracks that are in both the movies and music playlists?,"pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='movies', 'name'].isin(pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='music', 'name']).unique()"
find number of tracks in each genre?,"pd.merge(genres, tracks, on='genre_id').groupby('name').size().reset_index(name='count')"
how many tracks are in each genre?,"pd.merge(genres, tracks, on='genre_id').groupby('name').size().reset_index(name='count')"
how many editors are there?,editor['editor_id'].count()
list the names of editors in ascending order of age.,editor.sort_values('age')['name']
what are the names and ages of editors?,"editor[['name', 'age']]"
list the names of editors who are older than 25.,"editor.loc[lambda x: x['age'] > 25, 'name']"
show the names of editors of age either 24 or 25.,"editor.loc[lambda x: x['age'].isin([24, 25]), 'name']"
what is the name of the youngest editor?,editor.sort_values('age').iloc[0]['name']
what are the different ages of editors? show each age along with the number of editors of that age.,editor.groupby('age').size().reset_index(name='count')
please show the most common age of editors.,editor.groupby('age').size().sort_values(ascending=false).index[0]
show the distinct themes of journals.,journal['theme'].unique()
show the names of editors and the theme of journals for which they serve on committees.,"pd.merge(pd.merge(journal_committee, editor, on='editor_id'), journal, on='journal_id')[['name', 'theme']]"
"for each journal_committee, find the editor name and the journal theme.","pd.merge(pd.merge(journal_committee, editor, on='editor_id'), journal, on='journal_id')[['name', 'theme']]"
"show the names and ages of editors and the theme of journals for which they serve on committees, in ascending alphabetical order of theme.","pd.merge(pd.merge(journal_committee, editor, on='editor_id'), journal, on='journal_id').sort_values('theme')[['name', 'age', 'theme']]"
show the names of editors that are on the committee of journals with sales bigger than 3000.,"pd.merge(pd.merge(journal_committee, editor, on='editor_id'), journal, on='journal_id').loc[lambda x: x['sales'] > 3000, 'name']"
"show the id, name of each editor and the number of journal committees they are on.","editor.merge(journal_committee, on='editor_id').groupby(['editor_id', 'name']).size().reset_index(name='count')"
show the names of editors that are on at least two journal committees.,"pd.merge(editor, journal_committee, on='editor_id').groupby('name').filter(lambda x: len(x) >= 2)['name']"
list the names of editors that are not on any journal committee.,"editor.loc[~editor['editor_id'].isin(journal_committee['editor_id']), 'name']"
"list the date, theme and sales of the journal which did not have any of the listed editors serving on committee.","journal[~journal.merge(journal_committee, on='journal_id').set_index(['date', 'theme', 'sales']).index.isin(journal.set_index(['date', 'theme', 'sales']).index)]"
what is the average sales of the journals that have an editor whose work type is 'photo'?,"journal_committee[journal_committee['work_type'] == 'photo'].merge(journal, on='journal_id')['sales'].mean()"
how many accounts do we have?,accounts.shape[0]
count the number of accounts.,accounts.shape[0]
"show ids, customer ids, names for all accounts.","accounts[['account_id', 'customer_id', 'account_name']]"
"what are the account ids, customer ids, and account names for all the accounts?","accounts[['account_id', 'customer_id', 'account_name']]"
show other account details for account with name 338.,"accounts.loc[lambda x: x['account_name']=='338', 'other_account_details']"
what are the other account details for the account with the name 338?,"accounts.loc[lambda x: x['account_name']=='338', 'other_account_details']"
"what is the first name, last name, and phone of the customer with account name 162?","pd.merge(accounts.loc[lambda x: x['account_name']=='162'], customers, on='customer_id')[['customer_first_name', 'customer_last_name', 'customer_phone']]"
give the full name and phone of the customer who has the account name 162.,"pd.merge(accounts.loc[lambda x: x['account_name']=='162'], customers, on='customer_id')[['customer_first_name', 'customer_last_name', 'customer_phone']]"
how many accounts does the customer with first name art and last name turcotte have?,"pd.merge(accounts, customers).loc[lambda x: (x['customer_first_name']=='art') & (x['customer_last_name']=='turcotte'), :].shape[0]"
return the number of accounts that the customer with the first name art and last name turcotte has.,"pd.merge(accounts, customers).loc[lambda x: (x['customer_first_name']=='art') & (x['customer_last_name']=='turcotte'), :].shape[0]"
show all customer ids and the number of accounts for each customer.,accounts.groupby('customer_id').size().reset_index(name='count')
how many accounts are there for each customer id?,accounts.groupby('customer_id').size().reset_index(name='count')
show the customer id and number of accounts with most accounts.,"accounts.groupby('customer_id').size().nlargest(1).reset_index(name='count').loc[0, ['customer_id', 'count']]"
"what is the customer id of the customer with the most accounts, and how many accounts does this person have?","accounts.groupby('customer_id').size().nlargest(1).reset_index(name='count').loc[0, ['customer_id', 'count']]"
"what is the customer first, last name and id with least number of accounts.","pd.merge(accounts, customers, on='customer_id').groupby('customer_id').agg({'customer_first_name': 'first', 'customer_last_name': 'first', 'customer_id': 'count'}).sort_values('customer_id').iloc[0][['customer_first_name', 'customer_last_name', 'customer_id']]"
give the full name and customer id of the customer with the fewest accounts.,"pd.merge(accounts, customers, on='customer_id').groupby('customer_id').agg({'customer_first_name': 'first', 'customer_last_name': 'first', 'customer_id': 'count'}).sort_values('customer_id').iloc[0][['customer_first_name', 'customer_last_name', 'customer_id']]"
show the number of all customers without an account.,customers['customer_id'].isin(accounts['customer_id']).value_counts()[false]
how many customers do not have an account?,customers['customer_id'].isin(accounts['customer_id']).value_counts()[false]
show the first names and last names of customers without any account.,"customers.loc[~customers['customer_id'].isin(accounts['customer_id']), ['customer_first_name', 'customer_last_name']]"
what are the full names of customers who do not have any accounts?,"customers.loc[~customers['customer_id'].isin(accounts['customer_id']), ['customer_first_name', 'customer_last_name']]"
show distinct first and last names for all customers with an account.,"pd.merge(customers, accounts, on='customer_id')[['customer_first_name', 'customer_last_name']].drop_duplicates()"
what are the full names of customers who have accounts?,"pd.merge(customers, accounts, on='customer_id')[['customer_first_name', 'customer_last_name']].drop_duplicates()"
how many customers have an account?,accounts['customer_id'].nunique()
count the number of customers who hold an account.,accounts['customer_id'].nunique()
how many customers do we have?,customers.shape[0]
count the number of customers.,customers.shape[0]
"show ids, first names, last names, and phones for all customers.","customers[['customer_id', 'customer_first_name', 'customer_last_name', 'customer_phone']]"
"what are the ids, full names, and phones of each customer?","customers[['customer_id', 'customer_first_name', 'customer_last_name', 'customer_phone']]"
what is the phone and email for customer with first name aniyah and last name feest?,"customers.loc[(customers['customer_first_name'] == 'aniyah') & (customers['customer_last_name'] == 'feest'), ['customer_phone', 'customer_email']]"
return the phone and email of the customer with the first name aniyah and last name feest.,"customers.loc[(customers['customer_first_name'] == 'aniyah') & (customers['customer_last_name'] == 'feest'), ['customer_phone', 'customer_email']]"
show the number of customer cards.,customers_cards.shape[0]
how many customer cards are there?,customers_cards.shape[0]
"show ids, customer ids, card type codes, card numbers for all cards.","customers_cards[['card_id', 'customer_id', 'card_type_code', 'card_number']]"
"what are card ids, customer ids, card types, and card numbers for each customer card?","customers_cards[['card_id', 'customer_id', 'card_type_code', 'card_number']]"
show the date valid from and the date valid to for the card with card number '4560596484842'.,"customers_cards.loc[lambda x: x['card_number']=='4560596484842', ['date_valid_from', 'date_valid_to']]"
what are the valid from and valid to dates for the card with the number 4560596484842?,"customers_cards.loc[lambda x: x['card_number']=='4560596484842', ['date_valid_from', 'date_valid_to']]"
"what is the first name, last name, and phone of the customer with card 4560596484842.","pd.merge(customers_cards, customers, on='customer_id').loc[lambda x: x['card_number']=='4560596484842', ['customer_first_name', 'customer_last_name', 'customer_phone']]"
return the full name and phone of the customer who has card number 4560596484842.,"pd.merge(customers_cards, customers, on='customer_id').loc[lambda x: x['card_number']=='4560596484842', ['customer_first_name', 'customer_last_name', 'customer_phone']]"
how many cards does customer art turcotte have?,"pd.merge(customers_cards, customers.loc[(customers['customer_first_name']=='art') & (customers['customer_last_name']=='turcotte')], on='customer_id')['customer_id'].count()"
count the number of cards the customer with the first name art and last name turcotte has.,"pd.merge(customers_cards, customers.loc[(customers['customer_first_name']=='art') & (customers['customer_last_name']=='turcotte')], on='customer_id')['customer_id'].count()"
how many debit cards do we have?,(customers_cards['card_type_code'] == 'debit').sum()
count the number of customer cards of the type debit.,(customers_cards['card_type_code'] == 'debit').sum()
how many credit cards does customer blanche huels have?,"pd.merge(customers_cards, customers, on='customer_id').loc[(customers['customer_first_name']=='blanche') & (customers['customer_last_name']=='huels') & (customers_cards['card_type_code']=='credit'),:].shape[0]"
count the number of credit cards that the customer with first name blanche and last name huels has.,"pd.merge(customers_cards, customers, on='customer_id').loc[(customers['customer_first_name']=='blanche') & (customers['customer_last_name']=='huels') & (customers_cards['card_type_code']=='credit'),:].shape[0]"
show all customer ids and the number of cards owned by each customer.,customers_cards.groupby('customer_id').size().reset_index(name='count')
"what are the different customer ids, and how many cards does each one hold?",customers_cards.groupby('customer_id').size().reset_index(name='count')
"what is the customer id with most number of cards, and how many does he have?",customers_cards.groupby('customer_id').size().idxmax()
"return the id of the customer who has the most cards, as well as the number of cards.",customers_cards.groupby('customer_id').size().idxmax()
"show id, first and last names for all customers with at least two cards.","pd.merge(customers_cards, customers, on='customer_id').groupby('customer_id').filter(lambda x: len(x) >= 2)[['customer_id', 'customer_first_name', 'customer_last_name']].drop_duplicates('customer_id')"
what are the ids and full names of customers who hold two or more cards?,"pd.merge(customers_cards, customers, on='customer_id').groupby('customer_id').filter(lambda x: len(x) >= 2)[['customer_id', 'customer_first_name', 'customer_last_name']].drop_duplicates('customer_id')"
"what is the customer id, first and last name with least number of accounts.","pd.merge(customers_cards, customers, on='customer_id').groupby('customer_id').agg({'customer_first_name': 'first', 'customer_last_name': 'first'}).sort_values(by='count').head(1)"
return the id and full name of the customer who has the fewest accounts.,"pd.merge(customers_cards, customers, on='customer_id').groupby('customer_id').agg({'customer_first_name': 'first', 'customer_last_name': 'first'}).sort_values(by='count').head(1)"
show all card type codes and the number of cards in each type.,customers_cards.groupby('card_type_code').size().reset_index(name='count')
"what are the different card types, and how many cards are there of each?",customers_cards.groupby('card_type_code').size().reset_index(name='count')
what is the card type code with most number of cards?,customers_cards.groupby('card_type_code').size().sort_values(ascending=false).index[0]
return the code of the card type that is most common.,customers_cards.groupby('card_type_code').size().sort_values(ascending=false).index[0]
show card type codes with at least 5 cards.,customers_cards.groupby('card_type_code').filter(lambda x: len(x) >= 5)['card_type_code'].unique()
what are the codes of card types that have 5 or more cards?,customers_cards.groupby('card_type_code').filter(lambda x: len(x) >= 5)['card_type_code'].unique()
show all card type codes and the number of customers holding cards in each type.,customers_cards.groupby('card_type_code')['customer_id'].nunique()
"what are the different card type codes, and how many different customers hold each type?",customers_cards.groupby('card_type_code')['customer_id'].nunique()
show the customer ids and firstname without a credit card.,"customers[['customer_id', 'customer_first_name']].merge(customers_cards[lambda x: x['card_type_code'] == 'credit'][['customer_id']],how='left',on='customer_id',indicator=true).query(""_merge == 'left_only'"").drop('_merge', axis=1)"
what are the ids and first names of customers who do not hold a credit card?,"customers[['customer_id', 'customer_first_name']].merge(customers_cards[lambda x: x['card_type_code'] == 'credit'][['customer_id']],how='left',on='customer_id',indicator=true).query(""_merge == 'left_only'"").drop('_merge', axis=1)"
show all card type codes.,customers_cards['card_type_code'].unique()
what are the different card type codes?,customers_cards['card_type_code'].unique()
show the number of card types.,customers_cards['card_type_code'].nunique()
how many different card types are there?,customers_cards['card_type_code'].nunique()
show all transaction types.,financial_transactions['transaction_type'].unique()
what are the different types of transactions?,financial_transactions['transaction_type'].unique()
show the number of transaction types.,financial_transactions['transaction_type'].nunique()
how many different types of transactions are there?,financial_transactions['transaction_type'].nunique()
what is the average and total transaction amount?,"financial_transactions['transaction_amount'].agg(['mean', 'sum'])"
"return the average transaction amount, as well as the total amount of all transactions.","financial_transactions['transaction_amount'].agg(['mean', 'sum'])"
show the card type codes and the number of transactions.,"pd.merge(financial_transactions, customers_cards, on='card_id').groupby('card_type_code').size()"
"what are the different card types, and how many transactions have been made with each?","pd.merge(financial_transactions, customers_cards, on='card_id').groupby('card_type_code').size()"
show the transaction type and the number of transactions.,financial_transactions.groupby('transaction_type').size().reset_index(name='count')
"what are the different transaction types, and how many transactions of each have taken place?",financial_transactions.groupby('transaction_type').size().reset_index(name='count')
what is the transaction type that has processed the greatest total amount in transactions?,financial_transactions.groupby('transaction_type').sum()['transaction_amount'].sort_values(ascending=false).index[0]
return the type of transaction with the highest total amount.,financial_transactions.groupby('transaction_type').sum()['transaction_amount'].sort_values(ascending=false).index[0]
show the account id and the number of transactions for each account,financial_transactions.groupby('account_id').size().reset_index(name='count')
"what are the different account ids that have made financial transactions, as well as how many transactions correspond to each?",financial_transactions.groupby('account_id').size().reset_index(name='count')
how many tracks do we have?,track.shape[0]
count the number of tracks.,track.shape[0]
show the name and location for all tracks.,"track[['name', 'location']]"
what are the names and locations of all tracks?,"track[['name', 'location']]"
"show names and seatings, ordered by seating for all tracks opened after 2000.","track.loc[lambda x: x['year_opened']>2000, ['name', 'seating']].sort_values('seating')"
"what are the names and seatings for all tracks opened after 2000, ordered by seating?","track.loc[lambda x: x['year_opened']>2000, ['name', 'seating']].sort_values('seating')"
"what is the name, location and seating for the most recently opened track?","track.sort_values('year_opened', ascending=false).iloc[0][['name', 'location', 'seating']]"
"return the name, location, and seating of the track that was opened in the most recent year.","track.sort_values('year_opened', ascending=false).iloc[0][['name', 'location', 'seating']]"
"what is the minimum, maximum, and average seating for all tracks.","track['seating'].agg(['min', 'max', 'mean'])"
"return the minimum, maximum, and average seating across all tracks.","track['seating'].agg(['min', 'max', 'mean'])"
"show the name, location, open year for all tracks with a seating higher than the average.","track.loc[lambda x: x['seating'] > track['seating'].mean(), ['name', 'location', 'year_opened']]"
"what are the names, locations, and years of opening for tracks with seating higher than average?","track.loc[lambda x: x['seating'] > track['seating'].mean(), ['name', 'location', 'year_opened']]"
what are distinct locations where tracks are located?,track['location'].unique()
give the different locations of tracks.,track['location'].unique()
how many races are there?,race.shape[0]
count the number of races.,race.shape[0]
what are the distinct classes that races can have?,race['class'].unique()
return the different classes of races.,race['class'].unique()
"show name, class, and date for all races.","race[['name', 'class', 'date']]"
"what are the names, classes, and dates for all races?","race[['name', 'class', 'date']]"
show the race class and number of races in each class.,race.groupby('class').size().reset_index(name='count')
"what are the different classes of races, and how many races correspond to each?",race.groupby('class').size().reset_index(name='count')
what is the race class with most number of races.,race.groupby('class').size().sort_values(ascending=false).index[0]
give the class of races that is most common.,race.groupby('class').size().sort_values(ascending=false).index[0]
list the race class with at least two races.,race.groupby('class').filter(lambda x: len(x) >= 2)['class'].drop_duplicates()
what are the classes of races that have two or more corresponding races?,race.groupby('class').filter(lambda x: len(x) >= 2)['class'].drop_duplicates()
what are the names for tracks without a race in class 'gt'.,"track.loc[~track['name'].isin(race.loc[race['class']=='gt', 'name'])]['name']"
give the names of tracks that do not have a race in the class 'gt'.,"track.loc[~track['name'].isin(race.loc[race['class']=='gt', 'name'])]['name']"
show all track names that have had no races.,"track.loc[~track['track_id'].isin(race['track_id']), 'name']"
return the names of tracks that have no had any races.,"track.loc[~track['track_id'].isin(race['track_id']), 'name']"
show year where a track with a seating at least 5000 opened and a track with seating no more than 4000 opened.,"track.loc[lambda x: (x['seating'] >= 4000) & (x['seating'] <= 5000), 'year_opened']"
what are the years of opening for tracks with seating between 4000 and 5000?,"track.loc[lambda x: (x['seating'] >= 4000) & (x['seating'] <= 5000), 'year_opened']"
show the name of track and the number of races in each track.,"race.merge(track, on='track_id').groupby('name').size()"
"what are the names of different tracks, and how many races has each had?","race.merge(track, on='track_id').groupby('name').size()"
show the name of track with most number of races.,"pd.merge(race, track, on='track_id').groupby('track_id')['name'].agg(['count']).sort_values('count', ascending=false).iloc[:1]['name']"
what is the name of the track that has had the greatest number of races?,"pd.merge(race, track, on='track_id').groupby('track_id')['name'].agg(['count']).sort_values('count', ascending=false).iloc[:1]['name']"
show the name and date for each race and its track name.,"pd.merge(race, track, on='track_id')[['name_x', 'date', 'name_y']]"
"what are the names and dates of races, and the names of the tracks where they are held?","pd.merge(race, track, on='track_id')[['name_x', 'date', 'name_y']]"
show the name and location of track with 1 race.,"pd.merge(race, track, on='track_id').groupby(['track_id', 'name', 'location']).size().reset_index(name='count').loc[lambda x: x['count']==1, ['name', 'location']]"
what are the names and locations of tracks that have had exactly 1 race?,"pd.merge(race, track, on='track_id').groupby(['track_id', 'name', 'location']).size().reset_index(name='count').loc[lambda x: x['count']==1, ['name', 'location']]"
find the locations where have both tracks with more than 90000 seats and tracks with less than 70000 seats.,"pd.merge(track.loc[lambda x: x['seating'] > 90000, 'location'].to_frame(),track.loc[lambda x: x['seating'] < 70000, 'location'].to_frame(),on='location')['location']"
"what are the locations that have both tracks with more than 90000 seats, and tracks with fewer than 70000 seats?","pd.merge(track.loc[lambda x: x['seating'] > 90000, 'location'].to_frame(),track.loc[lambda x: x['seating'] < 70000, 'location'].to_frame(),on='location')['location']"
how many members have the black membership card?,(member['membership_card'] == 'black').sum()
find the number of members living in each address.,member.groupby('address').size().reset_index(name='count')
give me the names of members whose address is in harford or waterbury.,"member.loc[lambda x: x['address'].isin(['harford', 'waterbury']), 'name']"
find the ids and names of members who are under age 30 or with black membership card.,"member.loc[(member['membership_card']=='black') | (member['age']<30), ['name', 'member_id']]"
"find the purchase time, age and address of each member, and show the results in the order of purchase time.","member[['time_of_purchase', 'age', 'address']].sort_values('time_of_purchase')"
which membership card has more than 5 members?,member.groupby('membership_card').filter(lambda x: len(x) > 5)['membership_card'].unique()
which address has both members younger than 30 and members older than 40?,"pd.merge(member.loc[lambda x: x['age']<30, 'address'], member.loc[lambda x: x['age']>40, 'address'])"
what is the membership card held by both members living in hartford and ones living in waterbury address?,"pd.merge(member.loc[lambda x: x['address']=='hartford', 'membership_card'], member.loc[lambda x: x['address']=='waterbury', 'membership_card'], how='inner')"
how many members are not living in hartford?,(member['address'] != 'hartford').sum()
which address do not have any member with the black membership card?,"member.loc[~(member['membership_card'] == 'black'), 'address']"
show the shop addresses ordered by their opening year.,shop.sort_values('open_year')['address']
what are the average score and average staff number of all shops?,"shop[['num_of_staff', 'score']].mean()"
find the id and address of the shops whose score is below the average score.,"shop.loc[lambda x: x['score'] < x['score'].mean(), ['shop_id', 'address']]"
find the address and staff number of the shops that do not have any happy hour.,"shop.loc[~shop['shop_id'].isin(happy_hour['shop_id']), ['address', 'num_of_staff']]"
what are the id and address of the shops which have a happy hour in may?,"pd.merge(shop, happy_hour, on='shop_id').loc[lambda x: x['month']=='may', ['address', 'shop_id']]"
which shop has happy hour most frequently? list its id and number of happy hours.,happy_hour.groupby('shop_id').size().sort_values(ascending=false).iloc[[0]]
which month has the most happy hours?,happy_hour['month'].value_counts().index[0]
which months have more than 2 happy hours?,happy_hour.groupby('month').filter(lambda x: len(x) > 2)['month'].unique()
how many albums are there?,len(album)
find the number of albums.,len(album)
list the names of all music genres.,genre['name']
what are the names of different music genres?,genre['name']
find all the customer information in state ny.,"customer.loc[lambda x: x['state']=='ny', :]"
what is all the customer information for customers in ny state?,"customer.loc[lambda x: x['state']=='ny', :]"
what are the first names and last names of the employees who live in calgary city.,"employee.loc[lambda x: x['city']=='calgary', ['firstname', 'lastname']]"
find the full names of employees living in the city of calgary.,"employee.loc[lambda x: x['city']=='calgary', ['firstname', 'lastname']]"
what are the distinct billing countries of the invoices?,invoice['billingcountry'].unique()
find the different billing countries for all invoices.,invoice['billingcountry'].unique()
"find the names of all artists that have ""a"" in their names.","artist.loc[artist['name'].str.contains('a', case=false), 'name']"
what are the names of artist who have the letter 'a' in their names?,"artist.loc[artist['name'].str.contains('a', case=false), 'name']"
"find the title of all the albums of the artist ""ac/dc"".","pd.merge(album, artist, on='artistid').loc[lambda x: x['name']=='ac/dc', 'title']"
"what are the titles of albums by the artist ""ac/dc""?","pd.merge(album, artist, on='artistid').loc[lambda x: x['name']=='ac/dc', 'title']"
"hom many albums does the artist ""metallica"" have?","pd.merge(album, artist, on='artistid').loc[lambda x: x['name']=='metallica'].shape[0]"
"find the number of albums by the artist ""metallica"".","pd.merge(album, artist, on='artistid').loc[lambda x: x['name']=='metallica'].shape[0]"
"which artist does the album ""balls to the wall"" belong to?","pd.merge(album, artist, on='artistid').loc[lambda x: x['title']=='balls to the wall', 'name']"
"find the name of the artist who made the album ""balls to the wall"".","pd.merge(album, artist, on='artistid').loc[lambda x: x['title']=='balls to the wall', 'name']"
which artist has the most albums?,"pd.merge(album, artist, on='artistid').groupby('name').size().idxmax()"
what is the name of the artist with the greatest number of albums?,"pd.merge(album, artist, on='artistid').groupby('name').size().idxmax()"
"find the names of all the tracks that contain the word ""you"".","track.loc[lambda x: x['name'].str.contains('you'), 'name']"
what are the names of tracks that contain the the word you in them?,"track.loc[lambda x: x['name'].str.contains('you'), 'name']"
what is the average unit price of all the tracks?,track['unitprice'].mean()
find the average unit price for a track.,track['unitprice'].mean()
what are the durations of the longest and the shortest tracks in milliseconds?,"track['milliseconds'].agg(['max', 'min'])"
find the maximum and minimum durations of tracks in milliseconds.,"track['milliseconds'].agg(['max', 'min'])"
"show the album names, ids and the number of tracks for each album.","album.merge(track, on='albumid').groupby(['title', 'albumid']).size().reset_index(name='count')"
"what are the names and ids of the different albums, and how many tracks are on each?","album.merge(track, on='albumid').groupby(['title', 'albumid']).size().reset_index(name='count')"
what is the name of the most common genre in all tracks?,"pd.merge(genre, track, on='genreid').groupby('genreid')['name'].count().idxmax()"
find the name of the genre that is most frequent across all tracks.,"pd.merge(genre, track, on='genreid').groupby('genreid')['name'].count().idxmax()"
what is the least common media type in all tracks?,"pd.merge(media_type, track, on='mediatypeid').groupby('mediatypeid').size().sort_values().iloc[:1].index.map(lambda x: media_type.loc[x, 'name'])"
what is the name of the media type that is least common across all tracks?,"pd.merge(media_type, track, on='mediatypeid').groupby('mediatypeid').size().sort_values().iloc[:1].index.map(lambda x: media_type.loc[x, 'name'])"
show the album names and ids for albums that contain tracks with unit price bigger than 1.,"track.merge(album, on='albumid').query('unitprice > 1').groupby('albumid').agg({'title': 'first', 'albumid': 'count'}).rename(columns={'albumid':'count_of_tracks'})[['title', 'count_of_tracks']].reset_index()"
what are the titles and ids for albums containing tracks with unit price greater than 1?,"track.merge(album, on='albumid').query('unitprice > 1').groupby('albumid').agg({'title': 'first', 'albumid': 'count'}).rename(columns={'albumid':'count_of_tracks'})[['title', 'count_of_tracks']].reset_index()"
how many tracks belong to rock genre?,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='rock'].shape[0]"
count the number of tracks that are part of the rock genre.,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='rock'].shape[0]"
what is the average unit price of tracks that belong to jazz genre?,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='jazz', 'unitprice'].mean()"
find the average unit price of jazz tracks.,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='jazz', 'unitprice'].mean()"
"what is the first name and last name of the customer that has email ""luisg@embraer.com.br""?","customer.loc[lambda x: x['email']=='luisg@embraer.com.br', ['firstname', 'lastname']]"
"find the full name of the customer with the email ""luisg@embraer.com.br"".","customer.loc[lambda x: x['email']=='luisg@embraer.com.br', ['firstname', 'lastname']]"
"how many customers have email that contains ""gmail.com""?",customer['email'].str.contains('gmail.com').sum()
"count the number of customers that have an email containing ""gmail.com"".",customer['email'].str.contains('gmail.com').sum()
what is the first name and last name employee helps the customer with first name leonie?,"employee.loc[lambda x: x['employeeid'].isin(customer.loc[lambda y: y['firstname']=='leonie', 'supportrepid']), ['firstname', 'lastname']]"
find the full names of employees who help customers with the first name leonie.,"employee.loc[lambda x: x['employeeid'].isin(customer.loc[lambda y: y['firstname']=='leonie', 'supportrepid']), ['firstname', 'lastname']]"
what city does the employee who helps the customer with postal code 70174 live in?,"pd.merge(customer.loc[lambda x: x['postalcode']=='70174'], employee, left_on='supportrepid', right_on='employeeid')['city']"
find the cities corresponding to employees who help customers with the postal code 70174.,"pd.merge(customer.loc[lambda x: x['postalcode']=='70174'], employee, left_on='supportrepid', right_on='employeeid')['city']"
how many distinct cities does the employees live in?,employee['city'].nunique()
find the number of different cities that employees live in.,employee['city'].nunique()
find all invoice dates corresponding to customers with first name astrid and last name gruber.,"pd.merge(customer.loc[lambda x: (x['firstname']=='astrid') & (x['lastname']=='gruber')], invoice, on='customerid')['invoicedate']"
what are the invoice dates for customers with the first name astrid and the last name gruber?,"pd.merge(customer.loc[lambda x: (x['firstname']=='astrid') & (x['lastname']=='gruber')], invoice, on='customerid')['invoicedate']"
find all the customer last names that do not have invoice totals larger than 20.,"customer.loc[~customer['lastname'].isin(pd.merge(customer, invoice.loc[lambda x: x['total']>20], on='customerid')['lastname'])]['lastname']"
what are the last names of customers without invoice totals exceeding 20?,"customer.loc[~customer['lastname'].isin(pd.merge(customer, invoice.loc[lambda x: x['total']>20], on='customerid')['lastname'])]['lastname']"
find the first names of all customers that live in brazil and have an invoice.,"pd.merge(customer, invoice, on='customerid').loc[lambda x: x['country']=='brazil', 'firstname'].unique()"
what are the different first names for customers from brazil who have also had an invoice?,"pd.merge(customer, invoice, on='customerid').loc[lambda x: x['country']=='brazil', 'firstname'].unique()"
find the address of all customers that live in germany and have invoice.,"pd.merge(customer.loc[lambda x: x['country']=='germany'], invoice, on='customerid')['address'].unique()"
what are the addresses of customers living in germany who have had an invoice?,"pd.merge(customer.loc[lambda x: x['country']=='germany'], invoice, on='customerid')['address'].unique()"
list the phone numbers of all employees.,employee['phone']
what are the phone numbers for each employee?,employee['phone']
how many tracks are in the aac audio file media type?,"pd.merge(mediatype, track, on='mediatypeid').loc[lambda x: x['name']=='aac audio file'].shape[0]"
"count the number of tracks that are of the media type ""aac audio file"".","pd.merge(mediatype, track, on='mediatypeid').loc[lambda x: x['name']=='aac audio file'].shape[0]"
what is the average duration in milliseconds of tracks that belong to latin or pop genre?,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name'].isin(['latin', 'pop']), 'milliseconds'].mean()"
find the average millisecond length of latin and pop tracks.,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name'].isin(['latin', 'pop']), 'milliseconds'].mean()"
please show the employee first names and ids of employees who serve at least 10 customers.,"customer.merge(employee, left_on='supportrepid', right_on='employeeid').groupby(['firstname', 'supportrepid']).filter(lambda x: len(x) >= 10)[['firstname', 'supportrepid']].drop_duplicates()"
what are the first names and support rep ids for employees serving 10 or more customers?,"customer.merge(employee, left_on='supportrepid', right_on='employeeid').groupby(['firstname', 'supportrepid']).filter(lambda x: len(x) >= 10)[['firstname', 'supportrepid']].drop_duplicates()"
please show the employee last names that serves no more than 20 customers.,"customer.merge(employee, left_on='supportrepid', right_on='employeeid').groupby('supportrepid').filter(lambda g: len(g) <= 20)['lastname']"
what are the last names of employees who serve at most 20 customers?,"customer.merge(employee, left_on='supportrepid', right_on='employeeid').groupby('supportrepid').filter(lambda g: len(g) <= 20)['lastname']"
please list all album titles in alphabetical order.,album['title'].sort_values()
"what are all the album titles, in alphabetical order?",album['title'].sort_values()
please list the name and id of all artists that have at least 3 albums in alphabetical order.,"pd.merge(album, artist, on='artistid').groupby(['name', 'artistid']).filter(lambda x: len(x) >= 3).sort_values('name')[['name', 'artistid']]"
"what are the names and ids of artists with 3 or more albums, listed in alphabetical order?","pd.merge(album, artist, on='artistid').groupby(['name', 'artistid']).filter(lambda x: len(x) >= 3).sort_values('name')[['name', 'artistid']]"
find the names of artists that do not have any albums.,"artist[~artist['name'].isin(pd.merge(album, artist, on='artistid')['name'])]['name']"
what are the names of artists who have not released any albums?,"artist[~artist['name'].isin(pd.merge(album, artist, on='artistid')['name'])]['name']"
what is the average unit price of rock tracks?,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='rock', 'unitprice'].mean()"
find the average unit price of tracks from the rock genre.,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='rock', 'unitprice'].mean()"
what are the duration of the longest and shortest pop tracks in milliseconds?,"pd.merge(genre.loc[lambda x: x['name']=='pop'], track, on='genreid').agg({'milliseconds': ['max', 'min']})"
find the maximum and minimum millisecond lengths of pop tracks.,"pd.merge(genre.loc[lambda x: x['name']=='pop'], track, on='genreid').agg({'milliseconds': ['max', 'min']})"
what are the birth dates of employees living in edmonton?,"employee.loc[lambda x: x['city']=='edmonton', 'birthdate']"
find the birth dates corresponding to employees who live in the city of edmonton.,"employee.loc[lambda x: x['city']=='edmonton', 'birthdate']"
what are the distinct unit prices of all tracks?,track['unitprice'].unique()
find the distinct unit prices for tracks.,track['unitprice'].unique()
how many artists do not have any album?,artist[~artist['artistid'].isin(album['artistid'])].shape[0]
cound the number of artists who have not released an album.,artist[~artist['artistid'].isin(album['artistid'])].shape[0]
what are the album titles for albums containing both 'reggae' and 'rock' genre tracks?,"album.merge(track.merge(genre[genre['name'] == 'reggae'], on='genreid', how='inner'), on='albumid', how='inner')['title'].intersec‌t(album.merge(track.merge(genre[genre['name'] == 'rock'], on='genreid', how='inner'), on='albumid', how='inner')['title'])"
find the titles of albums that contain tracks of both the reggae and rock genres.,"pd.merge(pd.merge(album, track, on='albumid'), genre, on='genreid').query(""name=='reggae'"")['title'].intersec(pd.merge(pd.merge(album, track, on='albumid'), genre, on='genreid').query(""name=='rock'"")['title'])"
find all the phone numbers.,available_policies['customer_phone']
what are all the phone numbers?,available_policies['customer_phone']
"what are the customer phone numbers under the policy ""life insurance""?","available_policies.loc[lambda x: x['policy_type_code'] == 'life insurance', 'customer_phone']"
"what are the phone numbers of customers using the policy with the code ""life insurance""?","available_policies.loc[lambda x: x['policy_type_code'] == 'life insurance', 'customer_phone']"
which policy type has the most records in the database?,available_policies.groupby('policy_type_code').size().sort_values(ascending=false).index[0]
which policy type appears most frequently in the available policies?,available_policies.groupby('policy_type_code').size().sort_values(ascending=false).index[0]
what are all the customer phone numbers under the most popular policy type?,"available_policies.loc[lambda x: x['policy_type_code']==available_policies['policy_type_code'].value_counts().index[0], 'customer_phone']"
find the phone numbers of customers using the most common policy type among the available policies.,"available_policies.loc[lambda x: x['policy_type_code']==available_policies['policy_type_code'].value_counts().index[0], 'customer_phone']"
find the policy type used by more than 4 customers.,available_policies.groupby('policy_type_code').filter(lambda x: len(x) > 4)['policy_type_code'].unique()
find the policy types more than 4 customers use. show their type code.,available_policies.groupby('policy_type_code').filter(lambda x: len(x) > 4)['policy_type_code'].unique()
find the total and average amount of settlements.,"settlements['settlement_amount'].agg(['sum', 'mean'])"
return the sum and average of all settlement amounts.,"settlements['settlement_amount'].agg(['sum', 'mean'])"
find the name of services that have been used for more than 2 times in first notification of loss.,"pd.merge(first_notification_of_loss, services, on='service_id').groupby('service_id').filter(lambda x: len(x) > 2)['service_name'].unique()"
which services have been used more than twice in first notification of loss? return the service name.,"pd.merge(first_notification_of_loss, services, on='service_id').groupby('service_id').filter(lambda x: len(x) > 2)['service_name'].unique()"
what is the effective date of the claim that has the largest amount of total settlement?,"pd.merge(claims, settlements, on='claim_id').groupby('claim_id')['settlement_amount'].sum().idxmax()"
find the claim that has the largest total settlement amount. return the effective date of the claim.,"pd.merge(claims, settlements, on='claim_id').groupby('claim_id')['settlement_amount'].sum().idxmax()"
"how many policies are listed for the customer named ""dayana robel""?","(customers.merge(customers_policies, on='customer_id').loc[lambda x: x['customer_name']=='dayana robel', :].shape[0])"
"count the total number of policies used by the customer named ""dayana robel"".","(customers.merge(customers_policies, on='customer_id').loc[lambda x: x['customer_name']=='dayana robel', :].shape[0])"
what is the name of the customer who has the most policies listed?,"customers.merge(customers_policies, on='customer_id').groupby('customer_name').size().sort_values(ascending=false).index[0]"
which customer uses the most policies? give me the customer name.,"customers.merge(customers_policies, on='customer_id').groupby('customer_name').size().sort_values(ascending=false).index[0]"
"what are all the policy types of the customer named ""dayana robel""?","customers_policies.merge(customers, on='customer_id').merge(available_policies, on='policy_id').loc[lambda x: x['customer_name']=='dayana robel', 'policy_type_code'].unique()"
"tell me the types of the policy used by the customer named ""dayana robel"".","customers_policies.merge(customers, on='customer_id').merge(available_policies, on='policy_id').loc[lambda x: x['customer_name']=='dayana robel', 'policy_type_code'].unique()"
what are all the policy types of the customer that has the most policies listed?,"available_policies[np.in1d(available_policies['policy_id'], customers_policies[customers_policies['customer_id'].isin(customers[customers['customer_name']==customers['customer_name'].value_counts().index[0]]['customer_id'])]['policy_id'].unique())]['policy_type_code'].unique()"
list all the policy types used by the customer enrolled in the most policies.,"available_policies[np.in1d(available_policies['policy_id'], customers_policies[customers_policies['customer_id'].isin(customers[customers['customer_name']==customers['customer_name'].value_counts().index[0]]['customer_id'])]['policy_id'].unique())]['policy_type_code'].unique()"
list all the services in the alphabetical order.,services['service_name'].sort_values()
give me a list of all the service names sorted alphabetically.,services['service_name'].sort_values()
how many services are there?,services.shape[0]
count the total number of available services.,services.shape[0]
find the names of users who do not have a first notification of loss record.,"customers.loc[~customers['customer_id'].isin(first_notification_of_loss['customer_id']), 'customer_name']"
which customers do not have a first notification of loss record? give me the customer names.,"customers.loc[~customers['customer_id'].isin(first_notification_of_loss['customer_id']), 'customer_name']"
"find the names of customers who have used either the service ""close a policy"" or the service ""upgrade a policy"".","pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: (x['service_name']=='close a policy') | (x['service_name']=='upgrade a policy'), 'customer_name']"
"which customers have used the service named ""close a policy"" or ""upgrade a policy""? give me the customer names.","pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: (x['service_name']=='close a policy') | (x['service_name']=='upgrade a policy'), 'customer_name']"
"find the names of customers who have used both the service ""close a policy"" and the service ""new policy application"".","pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: x['service_name']=='close a policy', 'customer_name'].intersect(pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: x['service_name']=='new policy application', 'customer_name'])"
"which customers have used both the service named ""close a policy"" and the service named ""upgrade a policy""? give me the customer names.","pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: x['service_name']=='close a policy', 'customer_name'].intersect(pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: x['service_name']=='new policy application', 'customer_name'])"
"find the ids of customers whose name contains ""diana"".","customers.loc[customers['customer_name'].str.contains('diana'), 'customer_id']"
"what are the ids of customers who have ""diana"" in part of their names?","customers.loc[customers['customer_name'].str.contains('diana'), 'customer_id']"
what are the maximum and minimum settlement amount on record?,"settlements['settlement_amount'].agg(['max', 'min'])"
find the maximum and minimum settlement amount.,"settlements['settlement_amount'].agg(['max', 'min'])"
list all the customers in increasing order of ids.,"customers[['customer_id', 'customer_name']].sort_values('customer_id')"
what is the ordered list of customer ids?,"customers[['customer_id', 'customer_name']].sort_values('customer_id')"
"retrieve the open and close dates of all the policies associated with the customer whose name contains ""diana""","customers.merge(customers_policies, on='customer_id').loc[lambda x: x['customer_name'].str.contains('diana'), ['date_opened', 'date_closed']]"
"what are the open and close dates of all the policies used by the customer who have ""diana"" in part of their names?","customers.merge(customers_policies, on='customer_id').loc[lambda x: x['customer_name'].str.contains('diana'), ['date_opened', 'date_closed']]"
how many kinds of enzymes are there?,enzyme.shape[0]
what is the total count of enzymes?,enzyme.shape[0]
list the name of enzymes in descending lexicographical order.,"enzyme.sort_values('name', ascending=false)['name']"
what are the names of enzymes in descending order?,"enzyme.sort_values('name', ascending=false)['name']"
list the names and the locations that the enzymes can make an effect.,"enzyme[['name', 'location']]"
what are the names and locations of all enzymes listed?,"enzyme[['name', 'location']]"
what is the maximum online mendelian inheritance in man (omim) value of the enzymes?,enzyme['omim'].max()
what is the maximum omim value in the database?,enzyme['omim'].max()
"what is the product, chromosome and porphyria related to the enzymes which take effect at the location 'cytosol'?","enzyme.loc[lambda x: x['location']=='cytosol', ['product', 'chromosome', 'porphyria']]"
"what is the product, chromosome, and porphyria of the enzymes located at 'cytosol'?","enzyme.loc[lambda x: x['location']=='cytosol', ['product', 'chromosome', 'porphyria']]"
what are the names of enzymes who does not produce 'heme'?,"enzyme.loc[lambda x: x['product']!='heme', 'name']"
what are the names of enzymes whose product is not 'heme'?,"enzyme.loc[lambda x: x['product']!='heme', 'name']"
what are the names and trade names of the medicines which has 'yes' value in the fda record?,"medicine.loc[medicine['fda_approved']=='yes', ['name', 'trade_name']]"
what are the names and trade names of the medcines that are fda approved?,"medicine.loc[medicine['fda_approved']=='yes', ['name', 'trade_name']]"
what are the names of enzymes in the medicine named 'amisulpride' that can serve as an 'inhibitor'?,"enzyme.loc[(enzyme.merge(medicine_enzyme_interaction.loc[lambda x: x['interaction_type']=='inhibitor'], on='id').merge(medicine.loc[lambda x: x['name']=='amisulpride'], on='id'))['name']]"
what are the names of the enzymes used in the medicine  amisulpride that acts as inhibitors?,"enzyme.loc[(enzyme.merge(medicine_enzyme_interaction.loc[lambda x: x['interaction_type']=='inhibitor'], on='id').merge(medicine.loc[lambda x: x['name']=='amisulpride'], on='id'))['name']]"
what are the ids and names of the medicine that can interact with two or more enzymes?,"medicine_enzyme_interaction.groupby('medicine_id').filter(lambda x: len(x) >= 2).merge(medicine[['id', 'name']], on='id')[['id', 'name']].drop_duplicates()"
"for every medicine id, what are the names of the medicines that can interact with more than one enzyme?","medicine_enzyme_interaction.groupby('medicine_id').filter(lambda x: len(x) >= 2).merge(medicine[['id', 'name']], on='id')[['id', 'name']].drop_duplicates()"
"what are the ids, names and fda approval status of medicines in descending order of the number of enzymes that it can interact with.","medicine.merge(medicine_enzyme_interaction, on='medicine_id').groupby(['id', 'name', 'fda_approved']).size().reset_index(name='count').sort_values('count', ascending=false)[['id', 'name', 'fda_approved']]"
"what are the ids, names, and fda approval status for medicines ordered by descending number of possible enzyme interactions?","medicine.merge(medicine_enzyme_interaction, on='medicine_id').groupby(['id', 'name', 'fda_approved']).size().reset_index(name='count').sort_values('count', ascending=false)[['id', 'name', 'fda_approved']]"
what is the id and name of the enzyme with most number of medicines that can interact as 'activator'?,"medicine_enzyme_interaction.loc[lambda x: x['interaction_type']=='activitor'].merge(enzyme, on='id', how='inner').groupby(['id', 'name']).size().sort_values(ascending=false).head(1).reset_index()[['id', 'name']]"
what is the id and name of the enzyme that can interact with the most medicines as an activator?,"medicine_enzyme_interaction.loc[lambda x: x['interaction_type']=='activitor'].merge(enzyme, on='id', how='inner').groupby(['id', 'name']).size().sort_values(ascending=false).head(1).reset_index()[['id', 'name']]"
what is the interaction type of the enzyme named 'ala synthase' and the medicine named 'aripiprazole'?,"pd.merge(pd.merge(medicine_enzyme_interaction, medicine, left_on='medicine_id', right_on='id'), enzyme, left_on='enzyme_id', right_on='id').loc[(lambda x: (x['name_x']=='aripiprazole') & (x['name_y']=='ala synthase')),['interaction_type']]"
what is the type of interaction for the enzyme named 'ala synthase' and the medicine named 'aripiprazole'?,"pd.merge(pd.merge(medicine_enzyme_interaction, medicine, left_on='medicine_id', right_on='id'), enzyme, left_on='enzyme_id', right_on='id').loc[(lambda x: (x['name_x']=='aripiprazole') & (x['name_y']=='ala synthase')),['interaction_type']]"
what is the most common interaction type between enzymes and medicine? and how many are there?,medicine_enzyme_interaction.groupby('interaction_type').size().sort_values(ascending=false).head(1)
"what are the most common types of interactions between enzymes and medicine, and how many types are there?",medicine_enzyme_interaction.groupby('interaction_type').size().sort_values(ascending=false).head(1)
how many medicines have the fda approval status 'no' ?,(medicine['fda_approved']=='no').sum()
how many medicines were not approved by the fda?,(medicine['fda_approved']=='no').sum()
how many enzymes do not have any interactions?,enzyme['id'].isin(medicine_enzyme_interaction['enzyme_id']).value_counts()[false]
what is the count of enzymes without any interactions?,enzyme['id'].isin(medicine_enzyme_interaction['enzyme_id']).value_counts()[false]
what is the id and trade name of the medicines can interact with at least 3 enzymes?,"pd.merge(medicine, medicine_enzyme_interaction, on='id').groupby(['id', 'trade_name']).filter(lambda x: x['id'].count() >= 3).loc[:, ['id', 'trade_name']].drop_duplicates()"
what are the ids and trade names of the medicine that can interact with at least 3 enzymes?,"pd.merge(medicine, medicine_enzyme_interaction, on='id').groupby(['id', 'trade_name']).filter(lambda x: x['id'].count() >= 3).loc[:, ['id', 'trade_name']].drop_duplicates()"
"what are the distinct name, location and products of the enzymes which has any 'inhibitor' interaction?","pd.merge(enzyme, medicine_enzyme_interaction.loc[lambda x: x['interaction_type']=='inhibitor'], left_on='id', right_on='enzyme_id')[['name', 'location', 'product']].drop_duplicates()"
"what are the different names, locations, and products of the enzymes that are capable inhibitor interactions?","pd.merge(enzyme, medicine_enzyme_interaction.loc[lambda x: x['interaction_type']=='inhibitor'], left_on='id', right_on='enzyme_id')[['name', 'location', 'product']].drop_duplicates()"
list the medicine name and trade name which can both interact as 'inhibitor' and 'activitor' with enzymes.,"medicine_enzyme_interaction.merge(medicine, on='id').loc[lambda x: x['interaction_type'] == 'inhibitor', ['name', 'trade_name']].merge(medicine_enzyme_interaction.merge(medicine, on='id').loc[lambda x: x['interaction_type'] == 'activitor', ['name', 'trade_name']]).drop_duplicates()"
what are the medicine and trade names that can interact as an inhibitor and activitor with enzymes?,"medicine_enzyme_interaction.merge(medicine, on='id').loc[lambda x: x['interaction_type'] == 'inhibitor', ['name', 'trade_name']].merge(medicine_enzyme_interaction.merge(medicine, on='id').loc[lambda x: x['interaction_type'] == 'activitor', ['name', 'trade_name']]).drop_duplicates()"
show the medicine names and trade names that cannot interact with the enzyme with product 'heme'.,"medicine[['name', 'trade_name']].loc[~medicine.id.isin(medicine_enzyme_interaction.merge(enzyme.loc[lambda x: x['product'] == 'protoporphyrinogen ix'], left_on='enzyme_id', right_index=true)['medicine_id'])]"
what are the medicine and trade names that cannot interact with the enzyme with the product 'heme'?,"medicine[['name', 'trade_name']].loc[~medicine.id.isin(medicine_enzyme_interaction.merge(enzyme.loc[lambda x: x['product'] == 'protoporphyrinogen ix'], left_on='enzyme_id', right_index=true)['medicine_id'])]"
how many distinct fda approval statuses are there for the medicines?,medicine['fda_approved'].nunique()
how many different fda approval statuses exist for medicines?,medicine['fda_approved'].nunique()
"which enzyme names have the substring ""ala""?","enzyme.loc[enzyme['name'].str.contains('ala'), 'name']"
what are the names of enzymes that include the string 'ala'?,"enzyme.loc[enzyme['name'].str.contains('ala'), 'name']"
find the number of medicines offered by each trade.,medicine.groupby('trade_name').size().reset_index(name='count')
how many medicines are offered by each trade name?,medicine.groupby('trade_name').size().reset_index(name='count')
list all schools and their nicknames in the order of founded year.,"university[['school', 'nickname']].sort_values('founded')"
"what are the different schools and their nicknames, ordered by their founding years?","university[['school', 'nickname']].sort_values('founded')"
list all public schools and their locations.,"university.loc[lambda x: x['affiliation']=='public', ['school', 'location']]"
what are the public schools and what are their locations?,"university.loc[lambda x: x['affiliation']=='public', ['school', 'location']]"
when was the school with the largest enrollment founded?,"university.sort_values('enrollment', ascending=false).iloc[0]['founded']"
return the founded year for the school with the largest enrollment.,"university.sort_values('enrollment', ascending=false).iloc[0]['founded']"
find the founded year of the newest non public school.,"university.loc[lambda x: x['affiliation'] != 'public', 'founded'].sort_values(ascending=false).iloc[0]"
what is the founded year of the non public school that was founded most recently?,"university.loc[lambda x: x['affiliation'] != 'public', 'founded'].sort_values(ascending=false).iloc[0]"
how many schools are in the basketball match?,basketball_match['school_id'].nunique()
count the number of schools that have had basketball matches.,basketball_match['school_id'].nunique()
what is the highest acc percent score in the competition?,basketball_match['acc_percent'].sort_values(ascending=false).iloc[0]
return the highest acc percent across all basketball matches.,basketball_match['acc_percent'].sort_values(ascending=false).iloc[0]
what is the primary conference of the school that has the lowest acc percent score in the competition?,"university.merge(basketball_match, on='school_id').sort_values('acc_percent')['primary_conference'].iloc[0]"
return the primary conference of the school with the lowest acc percentage score.,"university.merge(basketball_match, on='school_id').sort_values('acc_percent')['primary_conference'].iloc[0]"
what is the team name and acc regular season score of the school that was founded for the longest time?,"pd.merge(university, basketball_match, on='school_id').sort_values('founded').iloc[0][['team_name', 'acc_regular_season']]"
return the name of the team and the acc during the regular season for the school that was founded the earliest.,"pd.merge(university, basketball_match, on='school_id').sort_values('founded').iloc[0][['team_name', 'acc_regular_season']]"
find the location and all games score of the school that has clemson as its team name.,"pd.merge(university, basketball_match, on='school_id').loc[lambda x: x['team_name']=='clemson', ['all_games', 'location']]"
what are the all games score and location of the school called clemson?,"pd.merge(university, basketball_match, on='school_id').loc[lambda x: x['team_name']=='clemson', ['all_games', 'location']]"
what are the average enrollment size of the universities that are founded before 1850?,"university.loc[lambda x: x['founded'] < 1850, 'enrollment'].mean()"
return the average enrollment of universities founded before 1850.,"university.loc[lambda x: x['founded'] < 1850, 'enrollment'].mean()"
show the enrollment and primary_conference of the oldest college.,"university[['enrollment', 'primary_conference', 'founded']].sort_values('founded').iloc[0, [0, 1]]"
what are the enrollment and primary conference for the university which was founded the earliest?,"university[['enrollment', 'primary_conference', 'founded']].sort_values('founded').iloc[0, [0, 1]]"
what is the total and minimum enrollment of all schools?,"university['enrollment'].agg(['sum', 'min'])"
return the total and minimum enrollments across all schools.,"university['enrollment'].agg(['sum', 'min'])"
find the total student enrollment for different affiliation type schools.,university.groupby('affiliation')['enrollment'].sum()
what are the total enrollments of universities of each affiliation type?,university.groupby('affiliation')['enrollment'].sum()
how many schools do not participate in the basketball match?,university['school_id'].loc[~university['school_id'].isin(basketball_match['school_id'])].count()
count the number of universities that do not participate in the baketball match.,university['school_id'].loc[~university['school_id'].isin(basketball_match['school_id'])].count()
find the schools that were either founded after 1850 or public.,"university.loc[(university['founded'] > 1850) | (university['affiliation'] == 'public'), 'school']"
what are the schools that were either founded before 1850 or are public?,"university.loc[(university['founded'] > 1850) | (university['affiliation'] == 'public'), 'school']"
find how many different affiliation types there are.,university['affiliation'].nunique()
count the number of different affiliation types.,university['affiliation'].nunique()
find how many school locations have the word 'ny'.,university['location'].str.contains('ny').sum()
how many universities have a location that contains ny?,university['location'].str.contains('ny').sum()
find the team names of the universities whose enrollments are smaller than the average enrollment size.,"university.merge(basketball_match, on='school_id').loc[lambda x: x['enrollment']<university['enrollment'].mean(), 'team_name']"
what are the names of teams from universities that have a below average enrollment?,"university.merge(basketball_match, on='school_id').loc[lambda x: x['enrollment']<university['enrollment'].mean(), 'team_name']"
find the number of universities that have over a 20000 enrollment size for each affiliation type.,university.loc[lambda x: x['enrollment'] > 20000].groupby('affiliation').size()
"what are the different affiliations, and how many schools with each have an enrollment size of above 20000?",university.loc[lambda x: x['enrollment'] > 20000].groupby('affiliation').size()
find the total number of students enrolled in the colleges that were founded after the year of 1850 for each affiliation type.,university.loc[lambda x: x['founded'] > 1850].groupby('affiliation').agg({'enrollment': 'sum'})
"what are the different affiliations, and what is the total enrollment of schools founded after 1850 for each enrollment type?",university.loc[lambda x: x['founded'] > 1850].groupby('affiliation').agg({'enrollment': 'sum'})
what is the maximum enrollment across all schools?,university['enrollment'].max()
return the maximum enrollment across all schools.,university['enrollment'].max()
list all information regarding the basketball match.,basketball_match
what is all the information about the basketball match?,basketball_match
"list names of all teams in the basketball competition, ordered by all home scores in descending order.","basketball_match.sort_values('all_home', ascending=false)['team_name']"
"what are the names of all the teams in the basketball competition, sorted by all home scores in descending order?","basketball_match.sort_values('all_home', ascending=false)['team_name']"
the names of models that launched between 2002 and 2004.,"chip_model.loc[lambda x: x['launch_year'].between(2002, 2004), 'model_name']"
which model has the least amount of ram? list the model name and the amount of ram.,"chip_model[['model_name', 'ram_mib']].sort_values('ram_mib').head(1)"
"what are the chip model and screen mode of the phone with hardware model name ""lg-p760""?","phone.loc[lambda x: x['hardware_model_name']=='lg-p760', ['chip_model', 'screen_mode']]"
"how many phone hardware models are produced by the company named ""nokia corporation""?","(phone['company_name'] == ""nokia corporation"").sum()"
"what is maximum and minimum ram size of phone produced by company named ""nokia corporation""?","pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model').loc[lambda x: x['company_name'] == ""nokia corporation"", 'ram_mib'].agg(['max', 'min'])"
"what is the average rom size of phones produced by the company named ""nokia corporation""?","pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model').loc[lambda x: x['company_name'] == ""nokia corporation"", 'rom_mib'].mean()"
list the hardware model name and company name for all the phones that were launched in year 2002 or have ram size greater than 32.,"pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model').loc[(chip_model['launch_year']==2002) | (chip_model['ram_mib']>32), ['hardware_model_name', 'company_name']]"
find all phones that have word 'full' in their accreditation types. list the hardware model name and company name.,"phone.loc[phone['accreditation_type'].str.contains('full'), ['hardware_model_name', 'company_name']]"
"find the char cells, pixels and hardware colours for the screen of the phone whose hardware model name is ""lg-p760"".","pd.merge(screen_mode, phone, left_on='graphics_mode', right_on='screen_mode').loc[lambda x: x['hardware_model_name']=='lg-p760', ['char_cells', 'pixels', 'hardware_colours']]"
"list the hardware model name and company name for the phone whose screen mode type is ""graphics.""","pd.merge(screen_mode[screen_mode['type'] == 'graphics'], phone, left_on='graphics_mode', right_on='screen_mode')[['hardware_model_name', 'company_name']]"
find the name of the company that has the least number of phone models. list the company name and the number of phone model produced by that company.,"phone.groupby('company_name').size().sort_values().head(1).reset_index().rename(columns={'company_name': 'company_name', 0: 'count(*)'})[['company_name', 'count(*)']]"
list the name of the company that produced more than one phone model.,phone.groupby('company_name').filter(lambda x: len(x) > 1)['company_name']
"list the maximum, minimum and average number of used kb in screen mode.","screen_mode['used_kb'].agg(['max', 'min', 'mean'])"
list the name of the phone model launched in year 2002 and with the highest ram size.,"phone.merge(chip_model[chip_model['launch_year'] == 2002], left_on='chip_model', right_on='model_name').sort_values('ram_mib', ascending=false).iloc[0]['hardware_model_name']"
"what are the wifi and screen mode type of the hardware model named ""lg-p760""?","pd.merge(pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model'), screen_mode, left_on='screen_mode', right_on='graphics_mode').loc[lambda x: x['hardware_model_name']=='lg-p760', ['wifi', 'type']]"
"list the hardware model name for the phones that have screen mode type ""text"" or ram size greater than 32.","pd.merge(pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model'), screen_mode, left_on='screen_mode', right_on='graphics_mode').loc[(lambda x:x['type']=='text')|(lambda x:x['ram_mib']>32), 'hardware_model_name']"
"list the hardware model name for the phones that were produced by ""nokia corporation"" or whose screen mode type is ""graphics.""","pd.merge(screen_mode[screen_mode['type']=='graphics'], phone, left_on='graphics_mode', right_on='screen_mode').loc[lambda x: (x['type']=='graphics') | (x['company_name']=='nokia corporation'), 'hardware_model_name'].unique()"
"list the hardware model name for the phons that were produced by ""nokia corporation"" but whose screen mode type is not text.","pd.merge(screen_mode.query('type!=""text""'), phone.query('company_name==""nokia corporation""'), left_on='graphics_mode', right_on='screen_mode').loc[:, 'hardware_model_name'].unique()"
list the phone hardware model and company name for the phones whose screen usage in kb is between 10 and 15.,"pd.merge(screen_mode.loc[(screen_mode['used_kb'] >= 10) & (screen_mode['used_kb'] <= 15)], phone, left_on='graphics_mode', right_on='screen_mode')[['hardware_model_name', 'company_name']].drop_duplicates()"
find the number of phones for each accreditation type.,phone.groupby('accreditation_type').size().reset_index(name='count')
how many phones belongs to each accreditation type?,phone.groupby('accreditation_type').size().reset_index(name='count')
find the accreditation level that more than 3 phones use.,phone.groupby('accreditation_level').filter(lambda x: len(x) > 3)['accreditation_level'].unique()
find the details for all chip models.,chip_model
how many models do not have the wifi function?,(chip_model['wifi'] == 'no').sum()
count the number of chip model that do not have wifi.,(chip_model['wifi'] == 'no').sum()
list all the model names sorted by their launch year.,chip_model.sort_values('launch_year')['model_name']
find the average ram mib size of the chip models that are never used by any phone.,chip_model[~chip_model['model_name'].isin(phone['chip_model'])]['ram_mib'].mean()
find the names of the chip models that are not used by any phone with full accreditation type.,"chip_model[~chip_model['model_name'].isin(phone.loc[phone['accreditation_type']=='full', 'chip_model'].unique())]['model_name']"
find the pixels of the screen modes that are used by both phones with full accreditation types and phones with provisional accreditation types.,"pd.merge(screen_mode.merge(phone.query('accreditation_type == ""provisional""'), left_on='graphics_mode', right_on='screen_mode', suffixes=('_l', '_r')), screen_mode.merge(phone.query('accreditation_type == ""full""'), left_on='graphics_mode', right_on='screen_mode', suffixes=('_l', '_r')))['pixels'].unique()"
how many countries are there in total?,country.shape[0]
count the number of countries.,country.shape[0]
show the country name and capital of all countries.,"country[['country_name', 'capital']]"
what are the names and capitals of each country?,"country[['country_name', 'capital']]"
"show all official native languages that contain the word ""english"".","country.loc[country['official_native_language'].str.contains('english'), 'official_native_language']"
"what are the official native languages that contain the string ""english"".","country.loc[country['official_native_language'].str.contains('english'), 'official_native_language']"
show all distinct positions of matches.,match_season['position'].unique()
what are the different positions for match season?,match_season['position'].unique()
show the players from college ucla.,"match_season.loc[lambda x: x['college']=='ucla', 'player']"
who are the players from ucla?,"match_season.loc[lambda x: x['college']=='ucla', 'player']"
show the distinct position of players from college ucla or duke.,"match_season.loc[lambda x: x['college'].isin(['ucla', 'duke']), 'position'].unique()"
what are the different positions of players from ucla or duke colleges?,"match_season.loc[lambda x: x['college'].isin(['ucla', 'duke']), 'position'].unique()"
show the draft pick numbers and draft classes of players whose positions are defenders.,"match_season.loc[lambda x: x['position']=='defender', ['draft_pick_number', 'draft_class']]"
what are the draft pick numbers and draft classes for players who play the defender position?,"match_season.loc[lambda x: x['position']=='defender', ['draft_pick_number', 'draft_class']]"
how many distinct teams are involved in match seasons?,match_season['team'].nunique()
count the number of different teams involved in match season.,match_season['team'].nunique()
show the players and the years played.,"player[['player', 'years_played']]"
who are the different players and how many years has each played?,"player[['player', 'years_played']]"
show all team names.,team['name']
what are the names of all teams?,team['name']
"show the season, the player, and the name of the country that player belongs to.","pd.merge(country, match_season, left_on='country_id', right_on='country')[['season', 'player', 'country_name']]"
"for each player, what are their name, season, and country that they belong to?","pd.merge(country, match_season, left_on='country_id', right_on='country')[['season', 'player', 'country_name']]"
which players are from indonesia?,"match_season.merge(country, left_on='country', right_on='country_id').loc[lambda x: x['country_name']=='indonesia', 'player']"
who are the players from indonesia?,"match_season.merge(country, left_on='country', right_on='country_id').loc[lambda x: x['country_name']=='indonesia', 'player']"
what are the distinct positions of the players from a country whose capital is dublin?,"pd.merge(country, match_season, left_on='country_id', right_on='country').loc[lambda x: x['capital']=='dublin', 'position'].unique()"
give the different positions of players who play for the country with the capital dublin.,"pd.merge(country, match_season, left_on='country_id', right_on='country').loc[lambda x: x['capital']=='dublin', 'position'].unique()"
what are the official languages of the countries of players from maryland or duke college?,"pd.merge(country, match_season, how='inner', left_on='country_id', right_on='country').loc[lambda x: x['college'].isin(['maryland', 'duke']), 'official_native_language']"
return the official native languages of countries who have players from maryland or duke colleges.,"pd.merge(country, match_season, how='inner', left_on='country_id', right_on='country').loc[lambda x: x['college'].isin(['maryland', 'duke']), 'official_native_language']"
how many distinct official languages are there among countries of players whose positions are defenders.,"pd.merge(country, match_season, left_on='country_id', right_on='country').loc[lambda x: x['position']=='defender', 'official_native_language'].nunique()"
count the number of different official languages corresponding to countries that players who play defender are from.,"pd.merge(country, match_season, left_on='country_id', right_on='country').loc[lambda x: x['position']=='defender', 'official_native_language'].nunique()"
"show the season, the player, and the name of the team that players belong to.","pd.merge(match_season, team, left_on='team', right_on='team_id')[['season', 'player', 'name']]"
"who are the different players, what season do they play in, and what is the name of the team they are on?","pd.merge(match_season, team, left_on='team', right_on='team_id')[['season', 'player', 'name']]"
"show the positions of the players from the team with name ""ryley goldner"".","match_season.merge(team, left_on='team', right_on='team_id').loc[lambda x: x['name']=='ryley goldner', 'position']"
return the positions of players on the team ryley goldner.,"match_season.merge(team, left_on='team', right_on='team_id').loc[lambda x: x['name']=='ryley goldner', 'position']"
"how many distinct colleges are associated with players from the team with name ""columbus crew"".","pd.merge(match_season, team, left_on='team', right_on='team_id').loc[lambda x: x['name']=='columbus crew', 'college'].nunique()"
count the number of different colleges that players who play for columbus crew are from.,"pd.merge(match_season, team, left_on='team', right_on='team_id').loc[lambda x: x['name']=='columbus crew', 'college'].nunique()"
"show the players and years played for players from team ""columbus crew"".","player.merge(team, left_on='team', right_on='team_id').loc[lambda x: x['name']=='columbus crew', ['player', 'years_played']]"
"what are the players who played for columbus crew, and how many years did each play for?","player.merge(team, left_on='team', right_on='team_id').loc[lambda x: x['name']=='columbus crew', ['player', 'years_played']]"
show the position of players and the corresponding number of players.,match_season.groupby('position').size().reset_index(name='count')
how many players played each position?,match_season.groupby('position').size().reset_index(name='count')
show the country names and the corresponding number of players.,"pd.merge(country, match_season, left_on='country_id', right_on='country').groupby('country_name').size()"
how many players are from each country?,"pd.merge(country, match_season, left_on='country_id', right_on='country').groupby('country_name').size()"
return all players sorted by college in ascending alphabetical order.,match_season.sort_values('college')['player']
"what are all the players who played in match season, sorted by college in ascending alphabetical order?",match_season.sort_values('college')['player']
show the most common position of players in match seasons.,match_season.groupby('position').size().sort_values(ascending=false).head(1).reset_index()['position']
what is the position that is most common among players in match seasons?,match_season.groupby('position').size().sort_values(ascending=false).head(1).reset_index()['position']
show the top 3 most common colleges of players in match seasons.,match_season.groupby('college').size().sort_values(ascending=false).head(3).reset_index()['college']
what are the three colleges from which the most players are from?,match_season.groupby('college').size().sort_values(ascending=false).head(3).reset_index()['college']
show the name of colleges that have at least two players.,match_season.groupby('college').filter(lambda x: len(x) >= 2)['college'].unique()
what are the names of all colleges that have two or more players?,match_season.groupby('college').filter(lambda x: len(x) >= 2)['college'].unique()
show the name of colleges that have at least two players in descending alphabetical order.,"match_season.groupby('college').filter(lambda x: len(x) >= 2).sort_values('college', ascending=false)['college'].drop_duplicates()"
"what are the names of colleges that have two or more players, listed in descending alphabetical order?","match_season.groupby('college').filter(lambda x: len(x) >= 2).sort_values('college', ascending=false)['college'].drop_duplicates()"
what are the names of teams that do no have match season record?,"team.loc[~team['team_id'].isin(match_season['team']), 'name']"
return the names of teams that have no match season record.,"team.loc[~team['team_id'].isin(match_season['team']), 'name']"
what are the names of countries that have both players with position forward and players with position defender?,"pd.merge(country.loc[lambda x: pd.merge(x, match_season.loc[lambda x: x['position']=='forward'], left_on='country_id', right_on='country')['country_id'], 'country_name'], country.loc[lambda x: pd.merge(x, match_season.loc[lambda x: x['position']=='defender'], left_on='country_id', right_on='country')['country_id'], 'country_name'])['country_name']"
"return the names of countries that have players that play the forward position, as well as players who play the defender position.","pd.merge(country.loc[lambda x: pd.merge(x, match_season.loc[lambda x: x['position']=='forward'], left_on='country_id', right_on='country')['country_id'], 'country_name'], country.loc[lambda x: pd.merge(x, match_season.loc[lambda x: x['position']=='defender'], left_on='country_id', right_on='country')['country_id'], 'country_name'])['country_name']"
which college have both players with position midfielder and players with position defender?,"match_season.loc[match_season['position']=='midfielder', 'college'].to_frame().merge(match_season.loc[match_season['position']=='defender', 'college'].to_frame(), on='college')['college']"
"return the colleges that have players who play the midfielder position, as well as players who play the defender position.","match_season.loc[match_season['position']=='midfielder', 'college'].to_frame().merge(match_season.loc[match_season['position']=='defender', 'college'].to_frame(), on='college')['college']"
how many climbers are there?,len(climber)
count the number of climbers.,climber.shape[0] or len(climber)
list the names of climbers in descending order of points.,"climber.sort_values('points', ascending=false)['name']"
"what are the names of the climbers, ordered by points descending?","climber.sort_values('points', ascending=false)['name']"
list the names of climbers whose country is not switzerland.,"climber.loc[lambda x: x['country'] != 'switzerland', 'name']"
what are the names of climbers who are not from the country of switzerland?,"climber.loc[lambda x: x['country'] != 'switzerland', 'name']"
what is the maximum point for climbers whose country is united kingdom?,"climber.loc[lambda x: x['country']=='united kingdom', 'points'].max()"
return the maximum number of points for climbers from the united kingdom.,"climber.loc[lambda x: x['country']=='united kingdom', 'points'].max()"
how many distinct countries are the climbers from?,climber['country'].nunique()
count the number of different countries that climbers are from.,climber['country'].nunique()
what are the names of mountains in ascending alphabetical order?,mountain.sort_values('name')['name']
give the names of mountains in alphabetical order.,mountain.sort_values('name')['name']
what are the countries of mountains with height bigger than 5000?,"mountain.loc[mountain['height'] > 5000, 'country']"
return the countries of the mountains that have a height larger than 5000.,"mountain.loc[mountain['height'] > 5000, 'country']"
what is the name of the highest mountain?,"mountain.sort_values('height', ascending=false)['name'].iloc[0]"
return the name of the mountain with the greatest height.,"mountain.sort_values('height', ascending=false)['name'].iloc[0]"
list the distinct ranges of the mountains with the top 3 prominence.,"mountain['range'].unique()[mountain.sort_values('prominence', ascending=false)['range'].unique()][:3]"
what are the different ranges of the 3 mountains with the highest prominence?,"mountain['range'].unique()[mountain.sort_values('prominence', ascending=false)['range'].unique()][:3]"
show names of climbers and the names of mountains they climb.,"pd.merge(climber, mountain, on='mountain_id')[['name_x', 'name_y']]"
what are the names of climbers and the corresponding names of mountains that they climb?,"pd.merge(climber, mountain, on='mountain_id')[['name_x', 'name_y']]"
show the names of climbers and the heights of mountains they climb.,"pd.merge(climber, mountain, on='mountain_id')[['name', 'height']]"
what are the names of climbers and the corresponding heights of the mountains that they climb?,"pd.merge(climber, mountain, on='mountain_id')[['name', 'height']]"
show the height of the mountain climbed by the climber with the maximum points.,"climber.merge(mountain, on='mountain_id').sort_values('points', ascending=false).iloc[0]['height']"
what is the height of the mountain climbined by the climbing who had the most points?,"climber.merge(mountain, on='mountain_id').sort_values('points', ascending=false).iloc[0]['height']"
"show the distinct names of mountains climbed by climbers from country ""west germany"".","pd.merge(climber.loc[lambda x: x['country']=='west germany'], mountain, on='mountain_id')['name'].unique()"
what are the different names of mountains ascended by climbers from the country of west germany?,"pd.merge(climber.loc[lambda x: x['country']=='west germany'], mountain, on='mountain_id')['name'].unique()"
show the times used by climbers to climb mountains in country uganda.,"climber.merge(mountain, on='mountain_id').loc[lambda x: x['country']=='uganda', 'time']"
what are the times used by climbers who climbed mountains in the country of uganda?,"climber.merge(mountain, on='mountain_id').loc[lambda x: x['country']=='uganda', 'time']"
please show the countries and the number of climbers from each country.,climber.groupby('country').size()
how many climbers are from each country?,climber.groupby('country').size()
list the countries that have more than one mountain.,mountain.groupby('country').filter(lambda x: len(x) > 1)['country'].unique()
which countries have more than one mountain?,mountain.groupby('country').filter(lambda x: len(x) > 1)['country'].unique()
list the names of mountains that do not have any climber.,"mountain.loc[~mountain['mountain_id'].isin(climber['mountain_id']), 'name']"
what are the names of countains that no climber has climbed?,"mountain.loc[~mountain['mountain_id'].isin(climber['mountain_id']), 'name']"
show the countries that have mountains with height more than 5600 stories and mountains with height less than 5200.,"set(mountain.loc[mountain['height'] > 5600, 'country']) & set(mountain.loc[mountain['height'] < 5200, 'country'])"
what are the countries that have both mountains that are higher than 5600 and lower than 5200?,"set(mountain.loc[mountain['height'] > 5600, 'country']) & set(mountain.loc[mountain['height'] < 5200, 'country'])"
show the range that has the most number of mountains.,mountain.groupby('range').size().sort_values(ascending=false).index.values[0]
which range contains the most mountains?,mountain.groupby('range').size().sort_values(ascending=false).index.values[0]
show the names of mountains with height more than 5000 or prominence more than 1000.,"mountain.loc[(mountain['height'] > 5000) | (mountain['prominence'] > 1000), 'name']"
what are the names of mountains that have a height of over 5000 or a prominence of over 1000?,"mountain.loc[(mountain['height'] > 5000) | (mountain['prominence'] > 1000), 'name']"
how many body builders are there?,body_builder.shape[0]
list the total scores of body builders in ascending order.,body_builder.sort_values('total')['total']
list the snatch score and clean jerk score of body builders in ascending order of snatch score.,"body_builder.sort_values('snatch')[['snatch', 'clean_jerk']]"
what is the average snatch score of body builders?,body_builder['snatch'].mean()
what are the clean and jerk score of the body builder with the highest total score?,"body_builder.sort_values('total', ascending=false).iloc[0]['clean_jerk']"
what are the birthdays of people in ascending order of height?,people.sort_values('height')['birth_date']
what are the names of body builders?,"pd.merge(body_builder, people, on='people_id')['name']"
what are the names of body builders whose total score is higher than 300?,"pd.merge(body_builder, people, on='people_id').loc[lambda x: x['total'] > 300, 'name']"
what is the name of the body builder with the greatest body weight?,"pd.merge(body_builder, people, on='people_id').sort_values('weight', ascending=false)['name'].iloc[0]"
what are the birth date and birth place of the body builder with the highest total points?,"pd.merge(people, body_builder, on='people_id').sort_values('total', ascending=false).iloc[0][['birth_date', 'birth_place']]"
what are the heights of body builders with total score smaller than 315?,"pd.merge(body_builder, people, on='people_id').loc[lambda x: x['total']<315, 'height']"
what is the average total score of body builders with height bigger than 200?,"pd.merge(body_builder, people, on='people_id').loc[lambda x: x['height']>200, 'total'].mean()"
what are the names of body builders in descending order of total scores?,"pd.merge(body_builder, people, on='people_id').sort_values('total', ascending=false)['name']"
list each birth place along with the number of people from there.,people.groupby('birth_place').size().reset_index(name='count')
what is the most common birth place of people?,people.groupby('birth_place').size().sort_values(ascending=false).index[0]
what are the birth places that are shared by at least two people?,people.groupby('birth_place').filter(lambda x: len(x)>=2)['birth_place'].unique()
list the height and weight of people in descending order of height.,"people[['height', 'weight']].sort_values('height', ascending=false)"
show all information about each body builder.,body_builder
list the names and origins of people who are not body builders.,"people[['name', 'birth_place']].merge(body_builder['people_id'], how='outer', indicator=true).loc[lambda x : x['_merge']=='left_only'][['name', 'birth_place']]"
how many distinct birth places are there?,people['birth_place'].nunique()
how many persons are not body builders?,people[~people['people_id'].isin(body_builder['people_id'])].shape[0]
list the weight of the body builders who have snatch score higher than 140 or have the height greater than 200.,"pd.merge(body_builder, people, on='people_id').loc[(lambda x: x['snatch']>140) | (lambda x: x['height']>200), 'weight']"
"what are the total scores of the body builders whose birthday contains the string ""january"" ?","pd.merge(body_builder, people.loc[lambda x: x['birth_date'].str.contains(""january"")], on='people_id')['total']"
what is the minimum snatch score?,body_builder['snatch'].min()
how many elections are there?,election.shape[0]
list the votes of elections in descending order.,"election.sort_values('votes', ascending=false)['votes']"
list the dates and vote percents of elections.,"election[['date', 'vote_percent']]"
what are the minimum and maximum vote percents of elections?,"election['vote_percent'].agg(['min', 'max'])"
what are the names and parties of representatives?,"representative[['name', 'party']]"
"what are the names of representatives whose party is not ""republican""?","representative.loc[lambda x: x['party'] != 'republican', 'name']"
what are the life spans of representatives from new york state or indiana state?,"representative.loc[lambda x: x['state'].isin(['new york', 'indiana']), 'lifespan']"
what are the names of representatives and the dates of elections they participated in.,"pd.merge(election, representative, on='representative_id')[['name', 'date']]"
what are the names of representatives with more than 10000 votes in election?,"pd.merge(election, representative, on='representative_id').loc[lambda x: x['votes']>10000, 'name']"
what are the names of representatives in descending order of votes?,"pd.merge(election, representative, on='representative_id').sort_values('votes', ascending=false)['name']"
what is the party of the representative that has the smallest number of votes.,"pd.merge(election, representative, on='representative_id').sort_values('votes')['party'].iloc[0]"
what are the lifespans of representatives in descending order of vote percent?,"pd.merge(election, representative, on='representative_id').sort_values('vote_percent', ascending=false)['lifespan']"
"what is the average number of votes of representatives from party ""republican""?","pd.merge(election, representative, on='representative_id').loc[lambda x: x['party'] == 'republican', 'votes'].mean()"
what are the different parties of representative? show the party name and the number of representatives in each party.,representative['party'].value_counts()
what is the party that has the largest number of representatives?,representative.groupby('party').size().sort_values(ascending=false).head(1)
what parties have at least three representatives?,representative.groupby('party').filter(lambda x: len(x) >= 3)['party'].drop_duplicates()
what states have at least two representatives?,representative.groupby('state').filter(lambda x: len(x) >= 2)['state'].unique()
list the names of representatives that have not participated in elections listed here.,representative[~representative['representative_id'].isin(election['representative_id'])]['name']
show the parties that have both representatives in new york state and representatives in pennsylvania state.,"representative.loc[representative['state']=='new york', 'party'].isin(representative.loc[representative['state']=='pennsylvania', 'party'])"
how many distinct parties are there for representatives?,representative['party'].nunique()
how many apartment bookings are there in total?,apartment_bookings.shape[0]
count the total number of apartment bookings.,apartment_bookings.shape[0]
show the start dates and end dates of all the apartment bookings.,"apartment_bookings[['booking_start_date', 'booking_end_date']]"
what are the start date and end date of each apartment booking?,"apartment_bookings[['booking_start_date', 'booking_end_date']]"
show all distinct building descriptions.,apartment_buildings['building_description'].unique()
give me a list of all the distinct building descriptions.,apartment_buildings['building_description'].unique()
"show the short names of the buildings managed by ""emma"".","apartment_buildings.loc[lambda x: x['building_manager']=='emma', 'building_short_name']"
"which buildings does ""emma"" manage? give me the short names of the buildings.","apartment_buildings.loc[lambda x: x['building_manager']=='emma', 'building_short_name']"
"show the addresses and phones of all the buildings managed by ""brenden"".","apartment_buildings.loc[lambda x: x['building_manager'] == 'brenden', ['building_address', 'building_phone']]"
"what are the address and phone number of the buildings managed by ""brenden""?","apartment_buildings.loc[lambda x: x['building_manager'] == 'brenden', ['building_address', 'building_phone']]"
"what are the building full names that contain the word ""court""?","apartment_buildings.loc[apartment_buildings['building_full_name'].str.contains('court', case=false), 'building_full_name']"
"find all the building full names containing the word ""court"".","apartment_buildings.loc[apartment_buildings['building_full_name'].str.contains('court', case=false), 'building_full_name']"
what is the minimum and maximum number of bathrooms of all the apartments?,"apartments['bathroom_count'].agg(['min', 'max'])"
give me the minimum and maximum bathroom count among all the apartments.,"apartments['bathroom_count'].agg(['min', 'max'])"
what is the average number of bedrooms of all apartments?,apartments['bedroom_count'].mean()
find the average number of bedrooms of all the apartments.,apartments['bedroom_count'].mean()
return the apartment number and the number of rooms for each apartment.,"apartments[['apt_number', 'room_count']]"
what are the apartment number and the room count of each apartment?,"apartments[['apt_number', 'room_count']]"
"what is the average number of rooms of apartments with type code ""studio""?","apartments.loc[apartments['apt_type_code']=='studio', 'room_count'].mean()"
"find the average room count of the apartments that have the ""studio"" type code.","apartments.loc[apartments['apt_type_code']=='studio', 'room_count'].mean()"
"return the apartment numbers of the apartments with type code ""flat"".","apartments.loc[apartments['apt_type_code'] == ""flat"", 'apt_number']"
"which apartments have type code ""flat""? give me their apartment numbers.","apartments.loc[apartments['apt_type_code'] == ""flat"", 'apt_number']"
return the first names and last names of all guests,"guests[['guest_first_name', 'guest_last_name']]"
what are the first names and last names of all the guests?,"guests[['guest_first_name', 'guest_last_name']]"
"return the date of birth for all the guests with gender code ""male"".","guests.loc[lambda x: x['gender_code']=='male', 'date_of_birth']"
"what are dates of birth of all the guests whose gender is ""male""?","guests.loc[lambda x: x['gender_code']=='male', 'date_of_birth']"
"show the apartment numbers, start dates, and end dates of all the apartment bookings.","pd.merge(apartment_bookings[['apt_id', 'booking_start_date', 'booking_end_date']], apartments[['apt_id', 'apt_number']], on='apt_id')[['apt_number', 'booking_start_date', 'booking_end_date']]"
"what are the apartment number, start date, and end date of each apartment booking?","pd.merge(apartment_bookings[['apt_id', 'booking_start_date', 'booking_end_date']], apartments[['apt_id', 'apt_number']], on='apt_id')[['apt_number', 'booking_start_date', 'booking_end_date']]"
"what are the booking start and end dates of the apartments with type code ""duplex""?","pd.merge(apartment_bookings, apartments[apartments['apt_type_code']=='duplex'], on='apt_id')[['booking_start_date', 'booking_start_date']]"
"return the booking start date and end date for the apartments that have type code ""duplex"".","pd.merge(apartment_bookings, apartments[apartments['apt_type_code']=='duplex'], on='apt_id')[['booking_start_date', 'booking_start_date']]"
what are the booking start and end dates of the apartments with more than 2 bedrooms?,"pd.merge(apartment_bookings, apartments, on='apt_id').loc[lambda x: x['bedroom_count'] > 2, ['booking_start_date', 'booking_end_date']]"
find the booking start date and end date for the apartments that have more than two bedrooms.,"pd.merge(apartment_bookings, apartments, on='apt_id').loc[lambda x: x['bedroom_count'] > 2, ['booking_start_date', 'booking_end_date']]"
"what is the booking status code of the apartment with apartment number ""suite 634""?","pd.merge(apartment_bookings, apartments, on='apt_id').loc[lambda x: x['apt_number']=='suite 634', 'booking_status_code']"
"tell me the booking status code for the apartment with number ""suite 634"".","pd.merge(apartment_bookings, apartments, on='apt_id').loc[lambda x: x['apt_number']=='suite 634', 'booking_status_code']"
"show the distinct apartment numbers of the apartments that have bookings with status code ""confirmed"".","pd.merge(apartment_bookings.loc[lambda x: x['booking_status_code']=='confirmed'], apartments, on='apt_id')['apt_number'].unique()"
"which apartments have bookings with status code ""confirmed""? return their apartment numbers.","pd.merge(apartment_bookings.loc[lambda x: x['booking_status_code']=='confirmed'], apartments, on='apt_id')['apt_number'].unique()"
"show the average room count of the apartments that have booking status code ""provisional"".","pd.merge(apartment_bookings.loc[lambda x: x['booking_status_code']=='provisional'], apartments, on='apt_id')['room_count'].mean()"
"what is the average room count of the apartments whose booking status code is ""provisional""?","pd.merge(apartment_bookings.loc[lambda x: x['booking_status_code']=='provisional'], apartments, on='apt_id')['room_count'].mean()"
"show the guest first names, start dates, and end dates of all the apartment bookings.","pd.merge(apartment_bookings, guests, on='guest_id')[['guest_first_name', 'booking_start_date']]"
"what are the guest first name, start date, and end date of each apartment booking?","pd.merge(apartment_bookings, guests, on='guest_id')[['guest_first_name', 'booking_start_date']]"
"show the start dates and end dates of all the apartment bookings made by guests with gender code ""female"".","pd.merge(apartment_bookings, guests, on='guest_id').loc[lambda x: x['gender_code']=='female', ['booking_start_date', 'booking_start_date']]"
"what are the start date and end date of the apartment bookings made by female guests (gender code ""female"")?","pd.merge(apartment_bookings, guests, on='guest_id').loc[lambda x: x['gender_code']=='female', ['booking_start_date', 'booking_start_date']]"
"show the first names and last names of all the guests that have apartment bookings with status code ""confirmed"".","pd.merge(apartment_bookings.query('booking_status_code == ""confirmed""'), guests, on='guest_id')[['guest_first_name', 'guest_last_name']]"
"which guests have apartment bookings with status code ""confirmed""? return their first names and last names.","pd.merge(apartment_bookings.query('booking_status_code == ""confirmed""'), guests, on='guest_id')[['guest_first_name', 'guest_last_name']]"
show the facility codes of apartments with more than 4 bedrooms.,"apartment_facilities.merge(apartments, on='apt_id').loc[lambda x: x['bedroom_count'] > 4, 'facility_code']"
what are the facility codes of the apartments with more than four bedrooms?,"apartment_facilities.merge(apartments, on='apt_id').loc[lambda x: x['bedroom_count'] > 4, 'facility_code']"
"show the total number of rooms of all apartments with facility code ""gym"".","pd.merge(apartment_facilities, apartments, on='apt_id').loc[lambda x: x['facility_code']=='gym', 'room_count'].sum()"
"find the total number of rooms in the apartments that have facility code ""gym"".","pd.merge(apartment_facilities, apartments, on='apt_id').loc[lambda x: x['facility_code']=='gym', 'room_count'].sum()"
"show the total number of rooms of the apartments in the building with short name ""columbus square"".","pd.merge(apartment_buildings.loc[lambda x: x['building_short_name'] == 'columbus square'], apartments, on='building_id')['room_count'].sum()"
"how many rooms in total are there in the apartments in the building with short name ""columbus square""?","pd.merge(apartment_buildings.loc[lambda x: x['building_short_name'] == 'columbus square'], apartments, on='building_id')['room_count'].sum()"
show the addresses of the buildings that have apartments with more than 2 bathrooms.,"pd.merge(apartment_buildings, apartments, on='building_id').loc[lambda x: x['bathroom_count'] > 2, 'building_address']"
which buildings have apartments that have more than two bathrooms? give me the addresses of the buildings.,"pd.merge(apartment_buildings, apartments, on='building_id').loc[lambda x: x['bathroom_count'] > 2, 'building_address']"
"show the apartment type codes and apartment numbers in the buildings managed by ""kyle"".","pd.merge(apartment_buildings, apartments, on='building_id').loc[lambda x: x['building_manager']=='kyle', ['apt_type_code', 'apt_number']]"
"what apartment type codes and apartment numbers do the buildings managed by ""kyle"" have?","pd.merge(apartment_buildings, apartments, on='building_id').loc[lambda x: x['building_manager']=='kyle', ['apt_type_code', 'apt_number']]"
show the booking status code and the corresponding number of bookings.,apartment_bookings.groupby('booking_status_code').size()
how many bookings does each booking status have? list the booking status code and the number of corresponding bookings.,apartment_bookings.groupby('booking_status_code').size()
return all the apartment numbers sorted by the room count in ascending order.,apartments.sort_values('room_count')['apt_number']
sort the apartment numbers in ascending order of room count.,apartments.sort_values('room_count')['apt_number']
return the apartment number with the largest number of bedrooms.,"apartments.sort_values('bedroom_count', ascending=false).iloc[0]['apt_number']"
what is the apartment number of the apartment with the most beds?,"apartments.sort_values('bedroom_count', ascending=false).iloc[0]['apt_number']"
show the apartment type codes and the corresponding number of apartments sorted by the number of apartments in ascending order.,apartments.groupby('apt_type_code').size().sort_values()
"return each apartment type code with the number of apartments having that apartment type, in ascending order of the number of apartments.",apartments.groupby('apt_type_code').size().sort_values()
show the top 3 apartment type codes sorted by the average number of rooms in descending order.,apartments.groupby('apt_type_code')['room_count'].mean().sort_values(ascending=false).head(3).index.tolist()
what are the top three apartment types in terms of the average room count? give me the,apartments.groupby('apt_type_code')['room_count'].mean().sort_values(ascending=false).head(3).index.tolist()
"show the apartment type code that has the largest number of total rooms, together with the number of bathrooms and number of bedrooms.","(apartments.groupby('apt_type_code').agg({'bathroom_count': 'first', 'bedroom_count': 'first', 'room_count': 'sum'}).sort_values('room_count', ascending=false).iloc[0][['bathroom_count', 'bedroom_count']])"
"which apartment type has the largest number of total rooms? return the apartment type code, its number of bathrooms and number of bedrooms.","(apartments.groupby('apt_type_code').agg({'bathroom_count': 'first', 'bedroom_count': 'first', 'room_count': 'sum'}).sort_values('room_count', ascending=false).iloc[0][['bathroom_count', 'bedroom_count']])"
show the most common apartment type code.,apartments.groupby('apt_type_code').size().sort_values(ascending=false).index[0]
which apartment type code appears the most often?,apartments.groupby('apt_type_code').size().sort_values(ascending=false).index[0]
show the most common apartment type code among apartments with more than 1 bathroom.,apartments.loc[lambda x: x['bathroom_count']>1].groupby('apt_type_code').size().sort_values(ascending=false).index[0]
which apartment type code is the most common among apartments with more than one bathroom?,apartments.loc[lambda x: x['bathroom_count']>1].groupby('apt_type_code').size().sort_values(ascending=false).index[0]
"show each apartment type code, and the maximum and minimum number of rooms for each type.","apartments.groupby('apt_type_code')['room_count'].agg(['max', 'min'])"
return each apartment type code along with the maximum and minimum number of rooms among each type.,"apartments.groupby('apt_type_code')['room_count'].agg(['max', 'min'])"
show each gender code and the corresponding count of guests sorted by the count in descending order.,guests.groupby('gender_code').size().sort_values(ascending=false)
sort the gender codes in descending order of their corresponding number of guests. return both the gender codes and counts.,guests.groupby('gender_code').size().sort_values(ascending=false)
how many apartments do not have any facility?,len(apartments[~apartments['apt_id'].isin(apartment_facilities['apt_id'])])
find the number of apartments that have no facility.,len(apartments[~apartments['apt_id'].isin(apartment_facilities['apt_id'])])
"show the apartment numbers of apartments with bookings that have status code both ""provisional"" and ""confirmed""","apartments.merge(apartment_bookings[apartment_bookings['booking_status_code'] == 'confirmed'], on='apt_id', how='inner')['apt_number'].intersec‌t(apartments.merge(apartment_bookings[apartment_bookings['booking_status_code'] == 'provisional'], on='apt_id', how='inner')['apt_number'])"
"which apartments have bookings with both status codes ""provisional"" and ""confirmed""? give me the apartment numbers.","pd.merge(apartment_bookings[apartment_bookings['booking_status_code']=='confirmed'], apartments, on='apt_id')['apt_number'].tolist() and pd.merge(apartment_bookings[apartment_bookings['booking_status_code']=='provisional'], apartments, on='apt_id')['apt_number'].tolist()"
show the apartment numbers of apartments with unit status availability of both 0 and 1.,"set(apartments.merge(view_unit_status.loc[lambda x: x['available_yn']==0], on='apt_id')['apt_number']).intersection(set(apartments.merge(view_unit_status.loc[lambda x: x['available_yn']==1], on='apt_id')['apt_number']))"
which apartments have unit status availability of both 0 and 1? return their apartment numbers.,"set(apartments.merge(view_unit_status.loc[lambda x: x['available_yn']==0], on='apt_id')['apt_number']).intersection(set(apartments.merge(view_unit_status.loc[lambda x: x['available_yn']==1], on='apt_id')['apt_number']))"
how many games are held after season 2007?,(game['season'] > 2007).sum()
list the dates of games by the home team name in descending order.,"game.sort_values('home_team', ascending=false)['date']"
"list the season, home team, away team of all the games.","game[['season', 'home_team', 'away_team']]"
"what are the maximum, minimum and average home games each stadium held?","stadium['home_games'].agg(['max', 'min', 'mean'])"
what is the average attendance of stadiums with capacity percentage higher than 100%?,"stadium.loc[lambda x: x['capacity_percentage'] > 100, 'average_attendance']"
"what are the player name, number of matches, and information source for players who do not suffer from injury of 'knee problem'?","injury_accident.query(""injury != 'knee problem'"")[['player', 'number_of_matches', 'source']]"
what is the season of the game which causes the player 'walter samuel' to get injured?,"pd.merge(game, injury_accident, on='id').loc[lambda x: x['player'] == 'walter samuel', 'season']"
"what are the ids, scores, and dates of the games which caused at least two injury accidents?","(game.merge(injury_accident, on='id').groupby(['id', 'score', 'date']).filter(lambda x: len(x) >= 2)[['id', 'score', 'date']])"
what are the id and name of the stadium where the most injury accidents happened?,"pd.merge(pd.merge(stadium, game, on='id'), injury_accident, on='game_id').groupby('id').size().sort_values(ascending=false).reset_index(name='count').iloc[0][['id', 'name']]"
find the id and name of the stadium where the largest number of injury accidents occurred.,"pd.merge(pd.merge(stadium, game, on='id'), injury_accident, on='game_id').groupby('id').size().sort_values(ascending=false).reset_index(name='count').iloc[0][['id', 'name']]"
in which season and which stadium did any player have an injury of 'foot injury' or 'knee problem'?,"pd.merge(pd.merge(game, stadium, left_on='stadium_id', right_on='id'), injury_accident, on='game_id').loc[lambda x: x['injury'].isin(['foot injury', 'knee problem']), ['season', 'name']]"
how many different kinds of information sources are there for injury accidents?,injury_accident['source'].nunique()
how many games are free of injury accidents?,"game.loc[~game['id'].isin(injury_accident['game_id']), :].shape[0]"
how many distinct kinds of injuries happened after season 2010?,"pd.merge(injury_accident, game, left_on='game_id', right_on='id').loc[lambda x: x['season'] > 2010, 'injury'].nunique()"
list the name of the stadium where both the player 'walter samuel' and the player 'thiago motta' got injured.,"(pd.merge(pd.merge(game, stadium, left_on='stadium_id', right_on='id'), injury_accident, left_on='id', right_on='game_id').loc[lambda x: x['player'].isin(['walter samuel', 'thiago motta'])].groupby('name').filter(lambda x: x['player'].nunique() == 2))['name']"
"show the name, average attendance, total attendance for stadiums where no accidents happened.","stadium[['name', 'average_attendance', 'total_attendance']].merge(game[['stadium_id']], left_index=true, right_on='stadium_id', how='left').merge(injury_accident[['game_id']], left_on='id', right_on='game_id', how='left').loc[lambda x: x['game_id'].isna()].drop('game_id', axis=1)"
"which stadium name contains the substring ""bank""?","stadium.loc[stadium['name'].str.contains('bank'), 'name']"
how many games has each stadium held?,"game.groupby('stadium_id').size().reset_index(name='count').rename(columns={'stadium_id': 'id'})[['id', 'count']].merge(stadium, on='id', how='right')[['id', 'count']].fillna(0)"
"for each injury accident, find the date of the game and the name of the injured player in the game, and sort the results in descending order of game season.","pd.merge(game, injury_accident, on='game_id')[['date', 'player']].sort_values('season', ascending=false)"
list all country and league names.,"pd.merge(country, league, left_on='id', right_on='country_id')[['name_x', 'name_y']]"
how many leagues are there in england?,"pd.merge(country, league, left_on='id', right_on='country_id').loc[lambda x: x['name']=='england'].shape[0]"
what is the average weight of all players?,player['weight'].mean()
what is the maximum and minimum height of all players?,"player['weight'].agg(['max', 'min'])"
list all player names who have an overall rating higher than the average.,"player.merge(player_attributes, on='player_api_id').loc[lambda x: x['overall_rating'] > player_attributes['overall_rating'].mean(), 'player_name'].nunique()"
what are the names of players who have the best dribbling?,"pd.merge(player, player_attributes, on='player_api_id').loc[lambda x: x['dribbling'] == player_attributes['overall_rating'].max(), 'player_name'].unique()"
list the names of all players who have a crossing score higher than 90 and prefer their right foot.,"pd.merge(player, player_attributes, on='player_api_id').loc[(lambda x: x['crossing']>90)&(lambda x: x['preferred_foot']=='right'), 'player_name'].unique()"
list the names of all left-footed players who have overall rating between 85 and 90.,"pd.merge(player, player_attributes, on='player_api_id').loc[(lambda x: x['preferred_foot']=='left') & (x['overall_rating'] >= 85) & (x['overall_rating'] <= 90), 'player_name'].unique()"
what is the average rating for right-footed players and left-footed players?,player_attributes.groupby('preferred_foot')['overall_rating'].mean()
"of all players with an overall rating greater than 80, how many are right-footed and left-footed?",player_attributes.loc[player_attributes['overall_rating'] > 80].groupby('preferred_foot').size()
list all of the player ids with a height of at least 180cm and an overall rating higher than 85.,"pd.merge(player.loc[lambda x: x['height']>=180, 'player_api_id'], player_attributes.loc[lambda x: x['overall_rating']>85, 'player_api_id']).squeeze()"
list all of the ids for left-footed players with a height between 180cm and 190cm.,"pd.merge(player.loc[(player['height']>=180) & (player['height']<=190), ['player_api_id']], player_attributes.loc[player_attributes['preferred_foot']=='left', ['player_api_id']]).drop_duplicates()['player_api_id']"
who are the top 3 players in terms of overall rating?,"pd.merge(player, player_attributes, on='player_api_id').sort_values('overall_rating', ascending=false).drop_duplicates('player_name')['player_name'][:3]"
list the names and birthdays of the top five players in terms of potential.,"player.merge(player_attributes, on='player_api_id').loc[:, ['player_name', 'birthday']].sort_values('potential', ascending=false).drop_duplicates(subset=['player_name', 'birthday']).head(5)"
how many performances are there?,performance.shape[0]
list the hosts of performances in ascending order of attendance.,performance.sort_values('attendance')['host']
what are the dates and locations of performances?,"performance[['date', 'location']]"
"show the attendances of the performances at location ""td garden"" or ""bell centre""","performance.loc[performance['location'].isin(['td garden', 'bell centre']), 'attendance']"
what is the average number of attendees for performances?,performance['attendance'].mean()
what is the date of the performance with the highest number of attendees?,"performance.sort_values('attendance', ascending=false)['date'].iloc[0]"
show different locations and the number of performances at each location.,performance.groupby('location').size()
show the most common location of performances.,performance.groupby('location').size().sort_values(ascending=false).index[0]
show the locations that have at least two performances.,performance.groupby('location').filter(lambda x: len(x) >= 2)['location'].unique()
show the locations that have both performances with more than 2000 attendees and performances with less than 1000 attendees.,"pd.merge(performance.loc[lambda x: x['attendance'] > 2000, ['location']], performance.loc[lambda x: x['attendance'] < 1000, ['location']]).drop_duplicates()['location']"
show the names of members and the location of the performances they attended.,"pd.merge(pd.merge(member_attendance, member, on='member_id'), performance, on='performance_id')[['name', 'location']]"
show the names of members and the location of performances they attended in ascending alphabetical order of their names.,"pd.merge(pd.merge(member_attendance, member, on='member_id'), performance, on='performance_id').sort_values('name')[['name', 'location']]"
"show the dates of performances with attending members whose roles are ""violin"".","pd.merge(pd.merge(member_attendance, member, on='member_id'), performance, on='performance_id').loc[lambda x: x['role']=='violin', 'date']"
show the names of members and the dates of performances they attended in descending order of attendance of the performances.,"pd.merge(pd.merge(member_attendance, member, on='member_id'), performance, on='performance_id').sort_values('attendance', ascending=false)[['name', 'date']]"
list the names of members who did not attend any performance.,"member.loc[~member['member_id'].isin(member_attendance['member_id']), 'name']"
find the buildings which have rooms with capacity more than 50.,"classroom.loc[lambda x: x['capacity'] > 50, 'building'].unique()"
what are the distinct buildings with capacities of greater than 50?,"classroom.loc[lambda x: x['capacity'] > 50, 'building'].unique()"
count the number of rooms that are not in the lamberton building.,"classroom.query(""building != 'lamberton'"")['building'].count()"
how many classrooms are not in lamberton?,"classroom.query(""building != 'lamberton'"")['building'].count()"
what is the name and building of the departments whose budget is more than the average budget?,"department.loc[lambda x: x['budget'] > x['budget'].mean(), ['dept_name', 'building']]"
give the name and building of the departments with greater than average budget.,"department.loc[lambda x: x['budget'] > x['budget'].mean(), ['dept_name', 'building']]"
find the room number of the rooms which can sit 50 to 100 students and their buildings.,"classroom.loc[lambda x: x['capacity'].between(50, 100), ['building', 'room_number']]"
what are the room numbers and corresponding buildings for classrooms which can seat between 50 to 100 students?,"classroom.loc[lambda x: x['capacity'].between(50, 100), ['building', 'room_number']]"
find the name and building of the department with the highest budget.,"department.sort_values('budget', ascending=false).head(1)[['dept_name', 'building']]"
what is the department name and corresponding building for the department with the greatest budget?,"department.sort_values('budget', ascending=false).head(1)[['dept_name', 'building']]"
what is the name of the student who has the highest total credits in the history department.,"student.loc[lambda x: x['dept_name'] == 'history'].sort_values('tot_cred', ascending=false)['name'].iloc[0]"
give the name of the student in the history department with the most credits.,"student.loc[lambda x: x['dept_name'] == 'history'].sort_values('tot_cred', ascending=false)['name'].iloc[0]"
how many rooms does the lamberton building have?,(classroom['building'] == 'lamberton').sum()
count the number of classrooms in lamberton.,(classroom['building'] == 'lamberton').sum()
how many students have advisors?,advisor['s_id'].nunique()
count the number of students who have advisors.,advisor['s_id'].nunique()
how many departments offer courses?,course['dept_name'].nunique()
count the number of departments which offer courses.,course['dept_name'].nunique()
how many different courses offered by physics department?,"course.loc[lambda x: x['dept_name']=='physics', 'course_id'].nunique()"
count the number of courses in the physics department.,"course.loc[lambda x: x['dept_name']=='physics', 'course_id'].nunique()"
find the title of courses that have two prerequisites?,"course.merge(prereq, on='course_id').groupby('course_id').filter(lambda x: len(x) == 2)['title']"
what are the titles for courses with two prerequisites?,"course.merge(prereq, on='course_id').groupby('course_id').filter(lambda x: len(x) == 2)['title']"
"find the title, credit, and department name of courses that have more than one prerequisites?","pd.merge(course, prereq, on='course_id').groupby('course_id').filter(lambda x: len(x) > 1)[['title', 'credits', 'dept_name']].drop_duplicates()"
"what is the title, credit value, and department name for courses with more than one prerequisite?","pd.merge(course, prereq, on='course_id').groupby('course_id').filter(lambda x: len(x) > 1)[['title', 'credits', 'dept_name']].drop_duplicates()"
how many courses that do not have prerequisite?,course['course_id'].isin(prereq['course_id']).value_counts()[false]
count the number of courses without prerequisites.,course['course_id'].isin(prereq['course_id']).value_counts()[false]
find the name of the courses that do not have any prerequisite?,"course.loc[~course['course_id'].isin(prereq['course_id']), 'title']"
what are the titles of courses without prerequisites?,"course.loc[~course['course_id'].isin(prereq['course_id']), 'title']"
how many different instructors have taught some course?,teaches['id'].nunique()
count the number of distinct instructors who have taught a course.,teaches['id'].nunique()
find the total budgets of the marketing or finance department.,"department.loc[department['dept_name'].isin(['marketing', 'finance']), 'budget'].sum()"
what is the sum of budgets of the marketing and finance departments?,"department.loc[department['dept_name'].isin(['marketing', 'finance']), 'budget'].sum()"
find the department name of the instructor whose name contains 'soisalon'.,"instructor.loc[instructor['name'].str.contains('soisalon', case=false), 'dept_name']"
what is the name of the department with an instructure who has a name like 'soisalon'?,"instructor.loc[instructor['name'].str.contains('soisalon', case=false), 'dept_name']"
how many rooms whose capacity is less than 50 does the lamberton building have?,classroom.loc[(classroom['building'] == 'lamberton') & (classroom['capacity'] < 50)].shape[0]
count the number of rooms in lamberton with capacity lower than 50.,classroom.loc[(classroom['building'] == 'lamberton') & (classroom['capacity'] < 50)].shape[0]
find the name and budget of departments whose budgets are more than the average budget.,"department.loc[lambda x: x['budget'] > x['budget'].mean(), ['dept_name', 'budget']]"
what are the names and budgets of departments with budgets greater than the average?,"department.loc[lambda x: x['budget'] > x['budget'].mean(), ['dept_name', 'budget']]"
what is the name of the instructor who is in statistics department and earns the lowest salary?,instructor.loc[lambda x: x['dept_name']=='statistics'].sort_values('salary').iloc[0]['name']
give the name of the lowest earning instructor in the statistics department.,instructor.loc[lambda x: x['dept_name']=='statistics'].sort_values('salary').iloc[0]['name']
find the title of course that is provided by both statistics and psychology departments.,"pd.merge(course.query(""dept_name == 'statistics'""),course.query(""dept_name == 'psychology'""),on='title')['title']"
what is the title of a course that is listed in both the statistics and psychology departments?,"pd.merge(course.query(""dept_name == 'statistics'""),course.query(""dept_name == 'psychology'""),on='title')['title']"
find the title of course that is provided by statistics but not psychology departments.,"course.loc[lambda x: x['dept_name']=='statistics', 'title'].drop_duplicates().reset_index(drop=true).append(course.loc[lambda x: x['dept_name']=='psychology', 'title']).drop_duplicates(keep=false).reset_index(drop=true)"
what are the titles of courses that are in the statistics department but not the psychology department?,"course.loc[lambda x: x['dept_name']=='statistics', 'title'].drop_duplicates().reset_index(drop=true).append(course.loc[lambda x: x['dept_name']=='psychology', 'title']).drop_duplicates(keep=false).reset_index(drop=true)"
find the id of instructors who taught a class in fall 2009 but not in spring 2010.,"teaches.loc[(teaches['semester']=='fall') & (teaches['year']==2009), 'id'].drop(teaches.loc[(teaches['semester']=='spring') & (teaches['year']==2010), 'id']).reset_index(drop=true)"
what are the ids of instructors who taught in the fall of 2009 but not in the spring of 2010?,"teaches.loc[(teaches['semester']=='fall') & (teaches['year']==2009), 'id'].drop(teaches.loc[(teaches['semester']=='spring') & (teaches['year']==2010), 'id']).reset_index(drop=true)"
find the name of students who took any class in the years of 2009 and 2010.,"pd.merge(student, takes, on='id').loc[lambda x: x['year'].isin([2009, 2010]), 'name'].unique()"
what are the names of the students who took classes in 2009 or 2010?,"pd.merge(student, takes, on='id').loc[lambda x: x['year'].isin([2009, 2010]), 'name'].unique()"
find the names of the top 3 departments that provide the largest amount of courses?,course.groupby('dept_name').size().sort_values(ascending=false).head(3).reset_index()['dept_name']
what are the names of the 3 departments with the most courses?,course.groupby('dept_name').size().sort_values(ascending=false).head(3).reset_index()['dept_name']
find the name of the department that offers the highest total credits?,"course.groupby('dept_name').sum().sort_values('credits', ascending=false).reset_index().loc[0, 'dept_name']"
what is the name of the department with the most credits?,"course.groupby('dept_name').sum().sort_values('credits', ascending=false).reset_index().loc[0, 'dept_name']"
list the names of all courses ordered by their titles and credits.,"course.sort_values(['title', 'credits'])['title']"
"given the titles of all courses, in order of titles and credits.","course.sort_values(['title', 'credits'])['title']"
which department has the lowest budget?,department.sort_values('budget').iloc[0]['dept_name']
give the name of the department with the lowest budget.,department.sort_values('budget').iloc[0]['dept_name']
list the names and buildings of all departments sorted by the budget from large to small.,"department[['dept_name', 'building']].sort_values('budget', ascending=false)"
"what are the names and buildings of the deparments, sorted by budget descending?","department[['dept_name', 'building']].sort_values('budget', ascending=false)"
who is the instructor with the highest salary?,"instructor.sort_values('salary', ascending=false).iloc[0]['name']"
give the name of the highest paid instructor.,"instructor.sort_values('salary', ascending=false).iloc[0]['name']"
list the information of all instructors ordered by their salary in ascending order.,instructor.sort_values('salary')
"give all information regarding instructors, in order of salary from least to greatest.",instructor.sort_values('salary')
find the name of the students and their department names sorted by their total credits in ascending order.,"student[['name', 'dept_name']].sort_values('tot_cred')"
"what are the names of students and their respective departments, ordered by number of credits from least to greatest?","student[['name', 'dept_name']].sort_values('tot_cred')"
list in alphabetic order all course names and their instructors' names in year 2008.,"pd.merge(pd.merge(course, teaches, on='course_id'), instructor, on='id').loc[lambda x: x['year']==2008].sort_values('title')[['title', 'name']]"
"show all titles and their instructors' names for courses in 2008, in alphabetical order by title.","pd.merge(pd.merge(course, teaches, on='course_id'), instructor, on='id').loc[lambda x: x['year']==2008].sort_values('title')[['title', 'name']]"
find the name of instructors who are advising more than one student.,"pd.merge(instructor, advisor, left_on='id', right_on='i_id').groupby('i_id').filter(lambda x: len(x) > 1)['name']"
what are the names of instructors who advise more than one student?,"pd.merge(instructor, advisor, left_on='id', right_on='i_id').groupby('i_id').filter(lambda x: len(x) > 1)['name']"
find the name of the students who have more than one advisor?,"student.merge(advisor, left_on='id', right_on='s_id').groupby('s_id').filter(lambda x: len(x) > 1)['name']"
what are the names of students who have more than one advisor?,"student.merge(advisor, left_on='id', right_on='s_id').groupby('s_id').filter(lambda x: len(x) > 1)['name']"
find the number of rooms with more than 50 capacity for each building.,classroom.loc[classroom['capacity'] > 50].groupby('building').size().reset_index(name='count(*)')
how many rooms in each building have a capacity of over 50?,classroom.loc[classroom['capacity'] > 50].groupby('building').size().reset_index(name='count(*)')
find the maximum and average capacity among rooms in each building.,"classroom.groupby('building')['capacity'].agg(['max', 'mean'])"
what are the greatest and average capacity for rooms in each building?,"classroom.groupby('building')['capacity'].agg(['max', 'mean'])"
find the title of the course that is offered by more than one department.,course.groupby('title').filter(lambda x: len(x) > 1)['title'].unique()
what are the titles of courses that are offered in more than one department?,course.groupby('title').filter(lambda x: len(x) > 1)['title'].unique()
find the total credits of courses provided by different department.,course.groupby('dept_name')['credits'].sum()
how many total credits are offered by each department?,course.groupby('dept_name')['credits'].sum()
find the minimum salary for the departments whose average salary is above the average payment of all instructors.,instructor.groupby('dept_name').filter(lambda x: x['salary'].mean() > instructor['salary'].mean()).groupby('dept_name')['salary'].min()
what is the lowest salary in departments with average salary greater than the overall average.,instructor.groupby('dept_name').filter(lambda x: x['salary'].mean() > instructor['salary'].mean()).groupby('dept_name')['salary'].min()
find the number of courses provided in each semester and year.,"section.groupby(['semester', 'year']).size().reset_index(name='count(*)')"
how many courses are provided in each semester and year?,"section.groupby(['semester', 'year']).size().reset_index(name='count(*)')"
find the year which offers the largest number of courses.,section.groupby('year').size().sort_values(ascending=false).index[0]
which year had the greatest number of courses?,section.groupby('year').size().sort_values(ascending=false).index[0]
find the year and semester when offers the largest number of courses.,"section.groupby(['semester', 'year']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['semester', 'year']]"
what is the year and semester with the most courses?,"section.groupby(['semester', 'year']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['semester', 'year']]"
find the name of department has the highest amount of students?,student.groupby('dept_name').size().sort_values(ascending=false).index[0]
what is the name of the deparment with the highest enrollment?,student.groupby('dept_name').size().sort_values(ascending=false).index[0]
find the total number of students in each department.,student.groupby('dept_name').size().reset_index(name='count(*)')
how many students are in each department?,student.groupby('dept_name').size().reset_index(name='count(*)')
find the semester and year which has the least number of student taking any class.,"takes.groupby(['semester', 'year']).size().sort_values().head(1).reset_index()[['semester', 'year']]"
which semeseter and year had the fewest students?,"takes.groupby(['semester', 'year']).size().sort_values().head(1).reset_index()[['semester', 'year']]"
what is the id of the instructor who advises of all students from history department?,"pd.merge(advisor, student, left_on='s_id', right_on='id').loc[lambda x: x['dept_name']=='history', 'i_id']"
give id of the instructor who advises students in the history department.,"pd.merge(advisor, student, left_on='s_id', right_on='id').loc[lambda x: x['dept_name']=='history', 'i_id']"
find the name and salary of the instructors who are advisors of any student from history department?,"pd.merge(pd.merge(advisor, instructor, left_on='i_id', right_on='id'), student, left_on='s_id', right_on='id').loc[lambda x: x['dept_name']=='history', ['name', 'salary']]"
what are the names and salaries of instructors who advises students in the history department?,"pd.merge(pd.merge(advisor, instructor, left_on='i_id', right_on='id'), student, left_on='s_id', right_on='id').loc[lambda x: x['dept_name']=='history', ['name', 'salary']]"
find the id of the courses that do not have any prerequisite?,course[~course['course_id'].isin(prereq['course_id'])]['course_id']
what are the ids of courses without prerequisites?,course[~course['course_id'].isin(prereq['course_id'])]['course_id']
what are the names of courses without prerequisites?,"course.loc[~course['course_id'].isin(prereq['course_id']), 'title']"
what is the title of the prerequisite class of international finance course?,"course.loc[lambda x: x['course_id'].isin(prereq.merge(course, on='course_id').loc[lambda x: x['title']=='international finance', 'prereq_id']), 'title']"
give the title of the prerequisite to the course international finance.,"course.loc[lambda x: x['course_id'].isin(prereq.merge(course, on='course_id').loc[lambda x: x['title']=='international finance', 'prereq_id']), 'title']"
find the title of course whose prerequisite is course differential geometry.,"course.loc[lambda x: x['course_id'].isin(prereq.merge(course, left_on='prereq_id', right_on='course_id').loc[lambda x: x['title']=='differential geometry', 'course_id']), 'title']"
what is the title of the course with differential geometry as a prerequisite?,"course.loc[lambda x: x['course_id'].isin(prereq.merge(course, left_on='prereq_id', right_on='course_id').loc[lambda x: x['title']=='differential geometry', 'course_id']), 'title']"
find the names of students who have taken any course in the fall semester of year 2003.,"student.loc[student['id'].isin(takes.loc[(takes['semester']=='fall')&(takes['year']==2003), 'id']), 'name']"
what are the names of students who took a course in the fall of 2003?,"student.loc[student['id'].isin(takes.loc[(takes['semester']=='fall')&(takes['year']==2003), 'id']), 'name']"
what is the title of the course that was offered at building chandler during the fall semester in the year of 2010?,"course.merge(section.query(""building=='chandler' and semester=='fall' and year==2010""), on='course_id')['title']"
give the title of the course offered in chandler during the fall of 2010.,"course.merge(section.query(""building=='chandler' and semester=='fall' and year==2010""), on='course_id')['title']"
find the name of the instructors who taught c programming course before.,"pd.merge(pd.merge(instructor, teaches, on='id'), course, on='course_id').loc[lambda x: x['title']=='c programming', 'name']"
what are the names of instructors who have taught c programming courses?,"pd.merge(pd.merge(instructor, teaches, on='id'), course, on='course_id').loc[lambda x: x['title']=='c programming', 'name']"
find the name and salary of instructors who are advisors of the students from the math department.,"pd.merge(pd.merge(advisor, instructor, left_on='i_id', right_on='id'), student, left_on='s_id', right_on='id').loc[lambda x: x['dept_name']=='math', ['name', 'salary']]"
what are the names and salaries of instructors who advise students in the math department?,"pd.merge(pd.merge(advisor, instructor, left_on='i_id', right_on='id'), student, left_on='s_id', right_on='id').loc[lambda x: x['dept_name']=='math', ['name', 'salary']]"
"find the name of instructors who are advisors of the students from the math department, and sort the results by students' total credit.","pd.merge(pd.merge(advisor, instructor, left_on='i_id', right_on='id'), student, left_on='s_id', right_on='id').loc[lambda x: x['dept_name']=='math'].sort_values('tot_cred')['name_y']"
what are the names of all instructors who advise students in the math depart sorted by total credits of the student.,"pd.merge(pd.merge(advisor, instructor, left_on='i_id', right_on='id'), student, left_on='s_id', right_on='id').loc[lambda x: x['dept_name']=='math'].sort_values('tot_cred')['name_y']"
what is the course title of the prerequisite of course mobile computing?,"course.loc[course['course_id'].isin(prereq.merge(course, on='course_id').loc[lambda x: x['title']=='mobile computing', 'prereq_id']), 'title']"
what is the title of the course that is a prerequisite for mobile computing?,"course.loc[course['course_id'].isin(prereq.merge(course, on='course_id').loc[lambda x: x['title']=='mobile computing', 'prereq_id']), 'title']"
find the name of instructor who is the advisor of the student who has the highest number of total credits.,"pd.merge(pd.merge(advisor, instructor, left_on='i_id', right_on='id'), student, left_on='s_id', right_on='id').sort_values('tot_cred', ascending=false).iloc[0]['name']"
what is the name of the instructor who advises the student with the greatest number of total credits?,"pd.merge(pd.merge(advisor, instructor, left_on='i_id', right_on='id'), student, left_on='s_id', right_on='id').sort_values('tot_cred', ascending=false).iloc[0]['name']"
find the name of instructors who didn't teach any courses?,"instructor.loc[~instructor['id'].isin(teaches['id']), 'name']"
what are the names of instructors who didn't teach?,"instructor.loc[~instructor['id'].isin(teaches['id']), 'name']"
find the id of instructors who didn't teach any courses?,instructor[~instructor['id'].isin(teaches['id'])]['id']
what are the ids of instructors who didnt' teach?,instructor[~instructor['id'].isin(teaches['id'])]['id']
find the names of instructors who didn't each any courses in any spring semester.,"instructor.loc[~instructor['id'].isin(teaches.loc[teaches['semester']=='spring', 'id']), 'name']"
what are the names of instructors who didn't teach courses in the spring?,"instructor.loc[~instructor['id'].isin(teaches.loc[teaches['semester']=='spring', 'id']), 'name']"
find the name of the department which has the highest average salary of professors.,instructor.groupby('dept_name')['salary'].mean().sort_values(ascending=false).index[0]
which department has the highest average instructor salary?,instructor.groupby('dept_name')['salary'].mean().sort_values(ascending=false).index[0]
find the number and averaged salary of all instructors who are in the department with the highest budget.,"pd.merge(instructor, department, on='dept_name').groupby('dept_name').agg(avg_salary=('salary', 'mean'), count=('dept_name', 'size')).sort_values('budget', ascending=false).iloc[:1]"
"how many instructors are in the department with the highest budget, and what is their average salary?","pd.merge(instructor, department, on='dept_name').groupby('dept_name').agg(avg_salary=('salary', 'mean'), count=('dept_name', 'size')).sort_values('budget', ascending=false).iloc[:1]"
what is the title and credits of the course that is taught in the largest classroom (with the highest capacity)?,"classroom.merge(section, on=['building', 'room_number']).merge(course, on='course_id').loc[lambda x: x['capacity'] == classroom['capacity'].max(), ['title', 'credits']]"
give the title and credits for the course that is taught in the classroom with the greatest capacity.,"classroom.merge(section, on=['building', 'room_number']).merge(course, on='course_id').loc[lambda x: x['capacity'] == classroom['capacity'].max(), ['title', 'credits']]"
find the name of students who didn't take any course from biology department.,"student[~student['id'].isin(takes.merge(course.query(""dept_name == 'biology'""), on='course_id')['id'])]['name']"
what are the names of students who haven't taken any biology courses?,"student[~student['id'].isin(takes.merge(course.query(""dept_name == 'biology'""), on='course_id')['id'])]['name']"
find the total number of students and total number of instructors for each department.,"pd.merge(pd.merge(student, department, on='dept_name'), instructor, on='dept_name').groupby('dept_name').agg({'id_x':'nunique', 'id_y':'nunique', 'dept_name':'first'}).rename(columns={'id_x':'students_count', 'id_y':'instructors_count', 'dept_name':'dept_name'})[['students_count', 'instructors_count', 'dept_name']]"
how many students and instructors are in each department?,"pd.merge(pd.merge(student, department, on='dept_name'), instructor, on='dept_name').groupby('dept_name').agg({'id_x':'nunique', 'id_y':'nunique', 'dept_name':'first'}).rename(columns={'id_x':'students_count', 'id_y':'instructors_count', 'dept_name':'dept_name'})[['students_count', 'instructors_count', 'dept_name']]"
find the name of students who have taken the prerequisite course of the course with title international finance.,"pd.merge(student, takes, on='id').loc[lambda x: x['course_id'].isin(pd.merge(course.loc[lambda x: x['title']=='international finance'], prereq, on='course_id')['prereq_id']), 'name']"
what are the names of students who have taken the prerequisite for the course international finance?,"pd.merge(student, takes, on='id').loc[lambda x: x['course_id'].isin(pd.merge(course.loc[lambda x: x['title']=='international finance'], prereq, on='course_id')['prereq_id']), 'name']"
find the name and salary of instructors whose salary is below the average salary of the instructors in the physics department.,"instructor.loc[lambda x: x['salary'] < instructor.loc[lambda x: x['dept_name']=='physics', 'salary'].mean(), ['name', 'salary']]"
what are the names and salaries for instructors who earn less than the average salary of instructors in the physics department?,"instructor.loc[lambda x: x['salary'] < instructor.loc[lambda x: x['dept_name']=='physics', 'salary'].mean(), ['name', 'salary']]"
find the name of students who took some course offered by statistics department.,"pd.merge(pd.merge(course, takes, on='course_id'), student, on='id').loc[lambda x: x['dept_name']=='statistics', 'name']"
what are the names of students who have taken statistics courses?,"pd.merge(pd.merge(course, takes, on='course_id'), student, on='id').loc[lambda x: x['dept_name']=='statistics', 'name']"
"find the building, room number, semester and year of all courses offered by psychology department sorted by course titles.","pd.merge(course.loc[lambda x: x['dept_name']=='psychology'], section, on='course_id').sort_values('title')[['building', 'room_number', 'semester', 'year']]"
"what are the building, room number, semester and year of courses in the psychology department, sorted using course title?","pd.merge(course.loc[lambda x: x['dept_name']=='psychology'], section, on='course_id').sort_values('title')[['building', 'room_number', 'semester', 'year']]"
find the names of all instructors in computer science department,"instructor.loc[lambda x: x['dept_name']=='comp. sci.', 'name']"
what are the names of all instructors in the comp. sci. department?,"instructor.loc[lambda x: x['dept_name']=='comp. sci.', 'name']"
find the names of all instructors in comp. sci. department with salary > 80000.,"instructor.loc[(instructor['dept_name']=='comp. sci.') & (instructor['salary']>80000), 'name']"
what are the names of the instructors in the comp. sci. department who earn more than 80000?,"instructor.loc[(instructor['dept_name']=='comp. sci.') & (instructor['salary']>80000), 'name']"
find the names of all instructors who have taught some course and the course_id.,"pd.merge(instructor, teaches, on='id')[['name', 'course_id']]"
"what are the names of all instructors who have taught a course, as well as the corresponding course id?","pd.merge(instructor, teaches, on='id')[['name', 'course_id']]"
find the names of all instructors in the art department who have taught some course and the course_id.,"pd.merge(instructor, teaches, on='id').loc[lambda x: x['dept_name']=='art', ['name', 'course_id']]"
"what are the names of art instructors who have taught a course, and the corresponding course id?","pd.merge(instructor, teaches, on='id').loc[lambda x: x['dept_name']=='art', ['name', 'course_id']]"
find the names of all instructors whose name includes the substring “dar”.,"instructor.loc[instructor['name'].str.contains('dar'), 'name']"
"what are the names of all instructors with names that include ""dar""?","instructor.loc[instructor['name'].str.contains('dar'), 'name']"
list in alphabetic order the names of all distinct instructors.,instructor['name'].sort_values().unique()
"list the distinct names of the instructors, ordered by name.",instructor['name'].sort_values().unique()
find courses that ran in fall 2009 or in spring 2010.,"pd.concat([section.query(""semester=='fall' and year==2009"")['course_id'], section.query(""semester=='spring' and year==2010"")['course_id']]).unique()"
what are the ids for courses in the fall of 2009 or the spring of 2010?,"pd.concat([section.query(""semester=='fall' and year==2009"")['course_id'], section.query(""semester=='spring' and year==2010"")['course_id']]).unique()"
find courses that ran in fall 2009 and in spring 2010.,"pd.merge(section.query(""semester=='fall' and year==2009"")['course_id'], section.query(""semester=='spring' and year==2010"")['course_id'], how='inner')"
what are the ids for courses that were offered in both fall of 2009 and spring of 2010?,"pd.merge(section.query(""semester=='fall' and year==2009"")['course_id'], section.query(""semester=='spring' and year==2010"")['course_id'], how='inner')"
find courses that ran in fall 2009 but not in spring 2010.,"section.loc[(section['semester']=='fall')&(section['year']==2009), 'course_id'].drop(section.loc[(section['semester']=='spring')&(section['year']==2010), 'course_id'].index).unique()"
what are the ids of courses offered in fall of 2009 but not in spring of 2010?,"section.loc[(section['semester']=='fall')&(section['year']==2009), 'course_id'].drop(section.loc[(section['semester']=='spring')&(section['year']==2010), 'course_id'].index).unique()"
find the salaries of all distinct instructors that are less than the largest salary.,"instructor.loc[lambda x: x['salary'] < instructor['salary'].max(), 'salary'].unique()"
what are the distinct salaries of all instructors who earned less than the maximum salary?,"instructor.loc[lambda x: x['salary'] < instructor['salary'].max(), 'salary'].unique()"
find the total number of instructors who teach a course in the spring 2010 semester.,"teaches.loc[(teaches['semester']=='spring') & (teaches['year']==2010), 'id'].nunique()"
how many instructors teach a course in the spring of 2010?,"teaches.loc[(teaches['semester']=='spring') & (teaches['year']==2010), 'id'].nunique()"
find the names and average salaries of all departments whose average salary is greater than 42000.,instructor.groupby('dept_name').filter(lambda x: x['salary'].mean() > 42000).groupby('dept_name')['salary'].mean()
what are the names and average salaries for departments with average salary higher than 42000?,instructor.groupby('dept_name').filter(lambda x: x['salary'].mean() > 42000).groupby('dept_name')['salary'].mean()
find names of instructors with salary greater than that of some (at least one) instructor in the biology department.,"instructor.loc[lambda x: x['salary'] > instructor.loc[lambda y: y['dept_name']=='biology', 'salary'].min(), 'name']"
what are the names of instructors who earn more than at least one instructor from the biology department?,"instructor.loc[lambda x: x['salary'] > instructor.loc[lambda y: y['dept_name']=='biology', 'salary'].min(), 'name']"
find the names of all instructors whose salary is greater than the salary of all instructors in the biology department.,"instructor.loc[lambda x: x['salary'] > instructor.loc[instructor['dept_name'] == 'biology', 'salary'].max(), 'name']"
what are the names of all instructors with a higher salary than any of the instructors in the biology department?,"instructor.loc[lambda x: x['salary'] > instructor.loc[instructor['dept_name'] == 'biology', 'salary'].max(), 'name']"
how many debates are there?,debate.shape[0]
list the venues of debates in ascending order of the number of audience.,debate.sort_values('num_of_audience')['venue']
what are the date and venue of each debate?,"debate[['date', 'venue']]"
list the dates of debates with number of audience bigger than 150,"debate.loc[lambda x: x['num_of_audience'] > 150, 'date']"
show the names of people aged either 35 or 36.,"people.loc[lambda x: x['age'].isin([35, 36]), 'name']"
what is the party of the youngest people?,people.sort_values('age').iloc[0]['party']
show different parties of people along with the number of people in each party.,people.groupby('party').size()
show the party that has the most people.,people.groupby('party').size().sort_values(ascending=false).index[0]
show the distinct venues of debates,debate['venue'].unique()
"show the names of people, and dates and venues of debates they are on the affirmative side.","pd.merge(pd.merge(debate_people, debate, on='debate_id'), people, left_on='affirmative', right_on='people_id')[['name', 'date', 'venue']]"
"show the names of people, and dates and venues of debates they are on the negative side, ordered in ascending alphabetical order of name.","pd.merge(pd.merge(debate_people, debate, on='debate_id'), people, left_on='negative', right_on='people_id').sort_values('name')[['name', 'date', 'venue']]"
show the names of people that are on affirmative side of debates with number of audience bigger than 200.,"pd.merge(pd.merge(debate_people, debate, on='debate_id'), people, left_on='affirmative', right_on='people_id').loc[lambda x: x['num_of_audience'] > 200, 'name']"
show the names of people and the number of times they have been on the affirmative side of debates.,"debate_people.merge(people, left_on='affirmative', right_on='people_id').groupby('name').size().reset_index(name='count')"
show the names of people who have been on the negative side of debates at least twice.,"pd.merge(debate_people, people, left_on='negative', right_on='people_id').groupby('name').filter(lambda x: len(x) >= 2)['name'].unique()"
list the names of people that have not been on the affirmative side of debates.,"people.loc[~people['people_id'].isin(debate_people['affirmative']), 'name']"
list the names of all the customers in alphabetical order.,customers['customer_details'].sort_values()
sort the customer names in alphabetical order.,customers['customer_details'].sort_values()
"find all the policy type codes associated with the customer ""dayana robel""","policies.merge(customers, on='customer_id').loc[lambda x: x['customer_details']=='dayana robel', 'policy_type_code']"
"what are the type codes of the policies used by the customer ""dayana robel""?","policies.merge(customers, on='customer_id').loc[lambda x: x['customer_details']=='dayana robel', 'policy_type_code']"
which type of policy is most frequently used? give me the policy type code.,policies.groupby('policy_type_code').size().sort_values(ascending=false).index[0]
find the type code of the most frequently used policy.,policies.groupby('policy_type_code').size().sort_values(ascending=false).index[0]
find all the policy types that are used by more than 2 customers.,policies.groupby('policy_type_code').filter(lambda x: len(x) > 2)['policy_type_code'].unique()
which types of policy are chosen by more than 2 customers? give me the policy type codes.,policies.groupby('policy_type_code').filter(lambda x: len(x) > 2)['policy_type_code'].unique()
find the total and average amount paid in claim headers.,"claim_headers['amount_piad'].agg(['sum', 'mean'])"
what are the total amount and average amount paid in claim headers?,"claim_headers['amount_piad'].agg(['sum', 'mean'])"
find the total amount claimed in the most recently created document.,"claim_headers.merge(claims_documents, left_on='claim_header_id', right_on='claim_id').loc[lambda x: x['created_date']==claims_documents.sort_values('created_date')['created_date'].iloc[0], 'amount_claimed'].sum()"
how much amount in total were claimed in the most recently created document?,"claim_headers.merge(claims_documents, left_on='claim_header_id', right_on='claim_id').loc[lambda x: x['created_date']==claims_documents.sort_values('created_date')['created_date'].iloc[0], 'amount_claimed'].sum()"
what is the name of the customer who has made the largest amount of claim in a single claim?,"claim_headers.merge(policies, on='policy_id').merge(customers, on='customer_id').loc[lambda x: x['amount_claimed']==x['amount_claimed'].max(), 'customer_details']"
which customer made the largest amount of claim in a single claim? return the customer details.,"claim_headers.merge(policies, on='policy_id').merge(customers, on='customer_id').loc[lambda x: x['amount_claimed']==x['amount_claimed'].max(), 'customer_details']"
what is the name of the customer who has made the minimum amount of payment in one claim?,"customers.merge(policies.merge(claim_headers.query(""amount_piad==amount_piad.min()""), on='policy_id'), on='customer_id')['customer_details']"
which customer made the smallest amount of claim in one claim? return the customer details.,"customers.merge(policies.merge(claim_headers.query(""amount_piad==amount_piad.min()""), on='policy_id'), on='customer_id')['customer_details']"
find the names of customers who have no policies associated.,"customers.loc[~customers['customer_details'].isin(pd.merge(policies, customers, on='customer_id')['customer_details'])]"
what are the names of customers who do not have any policies?,"customers.loc[~customers['customer_details'].isin(pd.merge(policies, customers, on='customer_id')['customer_details'])]"
how many claim processing stages are there in total?,claims_processing_stages.shape[0]
find the number of distinct stages in claim processing.,claims_processing_stages.shape[0]
what is the name of the claim processing stage that most of the claims are on?,"pd.merge(claims_processing, claims_processing_stages, on='claim_stage_id').groupby('claim_stage_id')['claim_status_name'].count().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['claim_status_name']"
which claim processing stage has the most claims? show the claim status name.,"pd.merge(claims_processing, claims_processing_stages, on='claim_stage_id').groupby('claim_stage_id')['claim_status_name'].count().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['claim_status_name']"
"find the names of customers whose name contains ""diana"".","customers.loc[customers['customer_details'].str.contains('diana'), 'customer_details']"
"which customers have the substring ""diana"" in their names? return the customer details.","customers.loc[customers['customer_details'].str.contains('diana'), 'customer_details']"
find the names of the customers who have an deputy policy.,"pd.merge(policies, customers, on='customer_id').loc[lambda x: x['policy_type_code']=='deputy', 'customer_details'].unique()"
"which customers have an insurance policy with the type code ""deputy""? give me the customer details.","pd.merge(policies, customers, on='customer_id').loc[lambda x: x['policy_type_code']=='deputy', 'customer_details'].unique()"
find the names of customers who either have an deputy policy or uniformed policy.,"pd.merge(policies[policies['policy_type_code'].isin(['deputy', 'uniform'])], customers, on='customer_id')['customer_details'].unique()"
"which customers have an insurance policy with the type code ""deputy"" or ""uniform""? return the customer details.","pd.merge(policies[policies['policy_type_code'].isin(['deputy', 'uniform'])], customers, on='customer_id')['customer_details'].unique()"
find the names of all the customers and staff members.,"pd.concat([customers['customer_details'], staff['staff_details']]).reset_index(drop=true)"
what are the names of the customers and staff members?,"pd.concat([customers['customer_details'], staff['staff_details']]).reset_index(drop=true)"
find the number of records of each policy type and its type code.,policies.groupby('policy_type_code').size()
"for each policy type, return its type code and its count in the record.",policies.groupby('policy_type_code').size()
find the name of the customer that has been involved in the most policies.,"pd.merge(policies, customers, on='customer_id').groupby('customer_details').size().reset_index(name='counts').sort_values('counts', ascending=false).iloc[0]['customer_details']"
which customer have the most policies? give me the customer details.,"pd.merge(policies, customers, on='customer_id').groupby('customer_details').size().reset_index(name='counts').sort_values('counts', ascending=false).iloc[0]['customer_details']"
"what is the description of the claim status ""open""?","claims_processing_stages.loc[lambda x: x['claim_status_name']=='open', 'claim_status_description']"
"find the description of the claim status ""open"".","claims_processing_stages.loc[lambda x: x['claim_status_name']=='open', 'claim_status_description']"
how many distinct claim outcome codes are there?,claims_processing['claim_outcome_code'].nunique()
count the number of distinct claim outcome codes.,claims_processing['claim_outcome_code'].nunique()
which customer is associated with the latest policy?,"policies.merge(customers, on='customer_id').loc[lambda x: x['start_date']==policies['start_date'].max(), 'customer_details']"
find the customer who started a policy most recently.,"policies.merge(customers, on='customer_id').loc[lambda x: x['start_date']==policies['start_date'].max(), 'customer_details']"
show the number of accounts.,accounts.shape[0]
how many accounts are there?,accounts.shape[0]
how many customers have opened an account?,accounts['customer_id'].nunique()
count the number of customers who have an account.,accounts['customer_id'].nunique()
"show the id, the date of account opened, the account name, and other account detail for all accounts.","accounts[['account_id', 'date_account_opened', 'account_name', 'other_account_details']]"
"what are the ids, date opened, name, and other details for all accounts?","accounts[['account_id', 'date_account_opened', 'account_name', 'other_account_details']]"
"show the id, the account name, and other account details for all accounts by the customer with first name 'meaghan'.","pd.merge(accounts, customers, on='customer_id').loc[lambda x: x['customer_first_name']=='meaghan', ['account_id', 'date_account_opened', 'account_name', 'other_account_details']]"
"what are the ids, names, dates of opening, and other details for accounts corresponding to the customer with the first name ""meaghan""?","pd.merge(accounts, customers, on='customer_id').loc[lambda x: x['customer_first_name']=='meaghan', ['account_id', 'date_account_opened', 'account_name', 'other_account_details']]"
show the account name and other account detail for all accounts by the customer with first name meaghan and last name keeling.,"pd.merge(accounts, customers.loc[(customers['customer_first_name']=='meaghan')&(customers['customer_last_name']=='keeling'), ['customer_id']], on='customer_id')[['account_name', 'other_account_details']]"
what are the names and other details for accounts corresponding to the customer named meaghan keeling?,"pd.merge(accounts, customers.loc[(customers['customer_first_name']=='meaghan')&(customers['customer_last_name']=='keeling'), ['customer_id']], on='customer_id')[['account_name', 'other_account_details']]"
show the first name and last name for the customer with account name 900.,"pd.merge(accounts.loc[lambda x : x['account_name'] == '900'], customers, on='customer_id')[['customer_first_name', 'customer_last_name']]"
what are the full names of customers with the account name 900?,"pd.merge(accounts.loc[lambda x : x['account_name'] == '900'], customers, on='customer_id')[['customer_first_name', 'customer_last_name']]"
how many customers don't have an account?,customers['customer_id'].isin(accounts['customer_id']).value_counts()[false]
count the number of customers who do not have an account.,customers['customer_id'].isin(accounts['customer_id']).value_counts()[false]
"show the unique first names, last names, and phone numbers for all customers with any account.","pd.merge(customers, accounts, on='customer_id')[['customer_first_name', 'customer_last_name', 'phone_number']].drop_duplicates()"
"what are the distinct first names, last names, and phone numbers for customers with accounts?","pd.merge(customers, accounts, on='customer_id')[['customer_first_name', 'customer_last_name', 'phone_number']].drop_duplicates()"
show customer ids who don't have an account.,customers[~customers['customer_id'].isin(accounts['customer_id'])]['customer_id']
what are the customer ids for customers who do not have an account?,customers[~customers['customer_id'].isin(accounts['customer_id'])]['customer_id']
how many accounts does each customer have? list the number and customer id.,accounts.groupby('customer_id').size().reset_index(name='count(*)')
count the number of accounts corresponding to each customer id.,accounts.groupby('customer_id').size().reset_index(name='count(*)')
"what is the customer id, first and last name with most number of accounts.","pd.merge(accounts, customers, on='customer_id').groupby(['customer_id', 'customer_first_name', 'customer_last_name']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[:1, :3]"
return the id and full name of the customer with the most accounts.,"pd.merge(accounts, customers, on='customer_id').groupby(['customer_id', 'customer_first_name', 'customer_last_name']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[:1, :3]"
"show id, first name and last name for all customers and the number of accounts.","pd.merge(accounts, customers, on='customer_id').groupby(['customer_id', 'customer_first_name', 'customer_last_name']).size().reset_index(name='count')"
"what are the the full names and ids for all customers, and how many accounts does each have?","pd.merge(accounts, customers, on='customer_id').groupby(['customer_id', 'customer_first_name', 'customer_last_name']).size().reset_index(name='count')"
show first name and id for all customers with at least 2 accounts.,"accounts.merge(customers, on='customer_id').groupby(['customer_id', 'customer_first_name']).size().loc[lambda x: x>=2].reset_index().loc[:, ['customer_first_name', 'customer_id']]"
what are the first names and ids for customers who have two or more accounts?,"accounts.merge(customers, on='customer_id').groupby(['customer_id', 'customer_first_name']).size().loc[lambda x: x>=2].reset_index().loc[:, ['customer_first_name', 'customer_id']]"
show the number of customers.,customers.shape[0]
show the number of customers for each gender.,customers.groupby('gender').size()
how many customers are there of each gender?,customers.groupby('gender').size()
how many transactions do we have?,financial_transactions.shape[0]
count the number of transactions.,financial_transactions.shape[0]
how many transaction does each account have? show the number and account id.,financial_transactions.groupby('account_id').size().reset_index(name='count')
count the number of financial transactions that correspond to each account id.,financial_transactions.groupby('account_id').size().reset_index(name='count')
how many transaction does account with name 337 have?,"pd.merge(financial_transactions, accounts, on='account_id').loc[lambda x: x['account_name']==""337""].shape[0]"
count the number of financial transactions that the account with the name 337 has.,"pd.merge(financial_transactions, accounts, on='account_id').loc[lambda x: x['account_name']==""337""].shape[0]"
"what is the average, minimum, maximum, and total transaction amount?","financial_transactions.agg({'transaction_amount': ['mean', 'min', 'max', 'sum']})"
"return the average, minimum, maximum, and total transaction amounts.","financial_transactions.agg({'transaction_amount': ['mean', 'min', 'max', 'sum']})"
show ids for all transactions whose amounts are greater than the average.,"financial_transactions.loc[lambda x: x['transaction_amount'] > x['transaction_amount'].mean(), 'transaction_id']"
what are the ids for transactions that have an amount greater than the average amount of a transaction?,"financial_transactions.loc[lambda x: x['transaction_amount'] > x['transaction_amount'].mean(), 'transaction_id']"
show the transaction types and the total amount of transactions.,financial_transactions.groupby('transaction_type')['transaction_amount'].sum()
what are total transaction amounts for each transaction type?,financial_transactions.groupby('transaction_type')['transaction_amount'].sum()
"show the account name, id and the number of transactions for each account.","pd.merge(financial_transactions, accounts, on='account_id').groupby(['account_name', 'account_id']).size().reset_index(name='count')"
"return the names and ids of each account, as well as the number of transactions.","pd.merge(financial_transactions, accounts, on='account_id').groupby(['account_name', 'account_id']).size().reset_index(name='count')"
show the account id with most number of transactions.,financial_transactions.groupby('account_id').size().sort_values(ascending=false).index[0]
what is the id of the account with the most transactions?,financial_transactions.groupby('account_id').size().sort_values(ascending=false).index[0]
show the account id and name with at least 4 transactions.,"pd.merge(financial_transactions, accounts, on='account_id').groupby(['account_id', 'account_name']).filter(lambda x: len(x) >= 4).loc[:, ['account_id', 'account_name']].drop_duplicates()"
what are the ids and names of accounts with 4 or more transactions?,"pd.merge(financial_transactions, accounts, on='account_id').groupby(['account_id', 'account_name']).filter(lambda x: len(x) >= 4).loc[:, ['account_id', 'account_name']].drop_duplicates()"
show all product sizes.,products['product_size'].unique()
what are the different product sizes?,products['product_size'].unique()
show all product colors.,products['product_color'].unique()
what are the different product colors?,products['product_color'].unique()
show the invoice number and the number of transactions for each invoice.,financial_transactions.groupby('invoice_number').size().reset_index(name='count')
how many transactions correspond to each invoice number?,financial_transactions.groupby('invoice_number').size().reset_index(name='count')
what is the invoice number and invoice date for the invoice with most number of transactions?,"pd.merge(financial_transactions, invoices, on='invoice_number').groupby('invoice_number')[['invoice_number', 'invoice_date']].count().sort_values(ascending=false).iloc[0]"
what is the invoice number and invoice date corresponding to the invoice with the greatest number of transactions?,"pd.merge(financial_transactions, invoices, on='invoice_number').groupby('invoice_number')[['invoice_number', 'invoice_date']].count().sort_values(ascending=false).iloc[0]"
how many invoices do we have?,len(invoices)
count the number of invoices.,len(invoices)
show invoice dates and order id and details for all invoices.,"pd.merge(invoices, orders, on='order_id')[['invoice_date', 'order_id', 'order_details']]"
"what are the invoice dates, order ids, and order details for all invoices?","pd.merge(invoices, orders, on='order_id')[['invoice_date', 'order_id', 'order_details']]"
show the order ids and the number of invoices for each order.,invoices.groupby('order_id').size().reset_index(name='count')
how many invoices correspond to each order id?,invoices.groupby('order_id').size().reset_index(name='count')
what is the order id and order details for the order more than two invoices.,"invoices.merge(orders, on='order_id').groupby(['order_id', 'order_details']).filter(lambda x: len(x) > 2)[['order_id', 'order_details']].drop_duplicates()"
return the order ids and details for orderes with two or more invoices.,"invoices.merge(orders, on='order_id').groupby(['order_id', 'order_details']).filter(lambda x: len(x) > 2)[['order_id', 'order_details']].drop_duplicates()"
"what is the customer last name, id and phone number with most number of orders?","pd.merge(orders, customers, on='customer_id').groupby(['customer_id', 'customer_last_name', 'phone_number']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['customer_last_name', 'customer_id', 'phone_number']]"
"return the last name, id and phone number of the customer who has made the greatest number of orders.","pd.merge(orders, customers, on='customer_id').groupby(['customer_id', 'customer_last_name', 'phone_number']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['customer_last_name', 'customer_id', 'phone_number']]"
show all product names without an order.,"products.loc[lambda x: ~x['product_name'].isin(pd.merge(products, order_items, on='product_id')['product_name'])]['product_name']"
what are the names of products that have never been ordered?,"products.loc[lambda x: ~x['product_name'].isin(pd.merge(products, order_items, on='product_id')['product_name'])]['product_name']"
show all product names and the total quantity ordered for each product name.,"pd.merge(order_items, products, on='product_id').groupby('product_name')['product_quantity'].sum()"
"what are the different product names, and what is the sum of quantity ordered for each product?","pd.merge(order_items, products, on='product_id').groupby('product_name')['product_quantity'].sum()"
show the order ids and the number of items in each order.,order_items.groupby('order_id').size().reset_index(name='count')
how many order items correspond to each order id?,order_items.groupby('order_id').size().reset_index(name='count')
show the product ids and the number of unique orders containing each product.,order_items.groupby('product_id')['order_id'].nunique()
how many distinct order ids correspond to each product?,order_items.groupby('product_id')['order_id'].nunique()
show all product names and the number of customers having an order on each product.,"order_items.merge(products, on='product_id').merge(orders, on='order_id').groupby('product_name').size().reset_index(name='count')"
"what are teh names of the different products, as well as the number of customers who have ordered each product.","order_items.merge(products, on='product_id').merge(orders, on='order_id').groupby('product_name').size().reset_index(name='count')"
show order ids and the number of products in each order.,order_items.groupby('order_id')['product_id'].nunique().reset_index(name='count')
how many different products correspond to each order id?,order_items.groupby('order_id')['product_id'].nunique().reset_index(name='count')
show order ids and the total quantity in each order.,order_items.groupby('order_id')['product_quantity'].sum()
"give the order ids for all orders, as well as the total product quantity in each.",order_items.groupby('order_id')['product_quantity'].sum()
how many products were not included in any order?,products['product_id'].isin(order_items['product_id']).value_counts()[false]
count the number of products that were never ordered.,products['product_id'].isin(order_items['product_id']).value_counts()[false]
how many churches opened before 1850 are there?,(church['open_date'] < 1850).sum()
"show the name, open date, and organizer for all churches.","church[['name', 'open_date', 'organized_by']]"
list all church names in descending order of opening date.,"church.sort_values('open_date', ascending=false)['name']"
show the opening year in whcih at least two churches opened.,church.groupby('open_date').filter(lambda x: len(x) >= 2)['open_date']
show the organizer and name for churches that opened between 1830 and 1840.,"church.loc[lambda x: x['open_date'].between(1830, 1840), ['organized_by', 'name']]"
show all opening years and the number of churches that opened in that year.,church.groupby('open_date').size().reset_index(name='count')
show the name and opening year for three churches that opened most recently.,"church[['name', 'open_date']].sort_values('open_date', ascending=false).head(3)"
how many female people are older than 30 in our record?,people.loc[(people['is_male']=='f') & (people['age'] > 30)].shape[0]
show the country where people older than 30 and younger than 25 are from.,"people.loc[people['age'] < 25, 'country'].unique() & people.loc[people['age'] > 30, 'country'].unique()"
"show the minimum, maximum, and average age for all people.","people['age'].agg(['min', 'max', 'mean'])"
show the name and country for all people whose age is smaller than the average.,"people.loc[lambda x: x['age'] < x['age'].mean(), ['name', 'country']]"
show the pair of male and female names in all weddings after year 2014,"pd.merge(pd.merge(wedding, people.rename(columns={'people_id':'male_id', 'name':'name_1'}), on='male_id'),people.rename(columns={'people_id':'female_id', 'name':'name_2'}), on='female_id').loc[lambda x: x['year']>2014,['name_1', 'name_2']]"
show the name and age for all male people who don't have a wedding.,"people.loc[(people['is_male']=='t') & (~people['people_id'].isin(wedding['male_id'])), ['name', 'age']]"
show all church names except for those that had a wedding in year 2015.,"church.loc[~church['church_id'].isin(wedding.loc[wedding['year']==2015, 'church_id']), 'name']"
show all church names that have hosted least two weddings.,"pd.merge(church, wedding, on='church_id').groupby('church_id').agg({'name': 'first', 'church_id': 'count'}).loc[lambda x: x['church_id']>=2, 'name']"
show the names for all females from canada having a wedding in year 2016.,"pd.merge(wedding[wedding['year'] == 2016], people[people['is_male']=='f'][people['country']=='canada'], left_on='female_id', right_on='people_id')['name']"
how many weddings are there in year 2016?,(wedding['year'] == 2016).sum()
show the church names for the weddings of all people older than 30.,"pd.merge(pd.merge(pd.merge(wedding, people, left_on='male_id', right_on='people_id'), people, left_on='female_id', right_on='people_id'), church, on='church_id').loc[lambda x: (x['age_x']>30) | (x['age_y']>30), 'name']"
show all countries and the number of people from each country.,people.groupby('country').size()
how many churches have a wedding in year 2016?,"wedding.loc[lambda x: x['year']==2016, 'church_id'].nunique()"
how many artists do we have?,artist.shape[0]
count the number of artists.,artist.shape[0]
"show all artist name, age, and country ordered by the yeared they joined.","artist[['name', 'age', 'country']].sort_values('year_join')"
"what are the names, ages, and countries of artists, sorted by the year they joined?","artist[['name', 'age', 'country']].sort_values('year_join')"
what are all distinct country for artists?,artist['country'].unique()
return the different countries for artists.,artist['country'].unique()
show all artist names and the year joined who are not from united states.,"artist.loc[lambda x: x['country']!='united states', ['name', 'year_join']]"
"what are the names and year of joining for artists that do not have the country ""united states""?","artist.loc[lambda x: x['country']!='united states', ['name', 'year_join']]"
how many artists are above age 46 and joined after 1990?,(artist['age'] > 46 & artist['year_join'] > 1990).sum()
count the number of artists who are older than 46 and joined after 1990.,(artist['age'] > 46 & artist['year_join'] > 1990).sum()
what is the average and minimum age of all artists from united states.,"artist.loc[lambda x: x['country'] == 'united states', 'age'].agg(['mean', 'min'])"
return the average and minimum ages across artists from the united states.,"artist.loc[lambda x: x['country'] == 'united states', 'age'].agg(['mean', 'min'])"
what is the name of the artist who joined latest?,"artist.sort_values('year_join', ascending=false).iloc[0]['name']"
return the name of the artist who has the latest join year.,"artist.sort_values('year_join', ascending=false).iloc[0]['name']"
how many exhibition are there in year 2005 or after?,(exhibition['year'] >= 2005).sum()
count the number of exhibitions that happened in or after 2005.,(exhibition['year'] >= 2005).sum()
show theme and year for all exhibitions with ticket prices lower than 15.,"exhibition.loc[lambda x: x['ticket_price'] < 15, ['theme', 'year']]"
what are the theme and year for all exhibitions that have a ticket price under 15?,"exhibition.loc[lambda x: x['ticket_price'] < 15, ['theme', 'year']]"
show all artist names and the number of exhibitions for each artist.,"exhibition.groupby('artist_id').size().rename('count').reset_index().merge(artist[['artist_id', 'name']], on='artist_id')[['name', 'count']]"
how many exhibitions has each artist had?,"exhibition.groupby('artist_id').size().rename('count').reset_index().merge(artist[['artist_id', 'name']], on='artist_id')[['name', 'count']]"
what is the name and country for the artist with most number of exhibitions?,"exhibition.merge(artist, on='artist_id').groupby(['artist_id', 'name', 'country']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'country']]"
return the name and country corresponding to the artist who has had the most exhibitions.,"exhibition.merge(artist, on='artist_id').groupby(['artist_id', 'name', 'country']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'country']]"
show names for artists without any exhibition.,"artist.loc[~artist['artist_id'].isin(exhibition['artist_id']), 'name']"
what are the names of artists that have not had any exhibitions?,"artist.loc[~artist['artist_id'].isin(exhibition['artist_id']), 'name']"
what is the theme and artist name for the exhibition with a ticket price higher than the average?,"exhibition.loc[lambda x: x['ticket_price'] > exhibition['ticket_price'].mean(), ['theme', 'name']].merge(artist, on='artist_id')"
return the names of artists and the themes of their exhibitions that had a ticket price higher than average.,"exhibition.loc[lambda x: x['ticket_price'] > exhibition['ticket_price'].mean(), ['theme', 'name']].merge(artist, on='artist_id')"
"show the average, minimum, and maximum ticket prices for exhibitions for all years before 2009.","exhibition.loc[lambda x: x['year'] < 2009, 'ticket_price'].agg(['mean', 'min', 'max'])"
"what are the average, minimum, and maximum ticket prices for exhibitions that happened prior to 2009?","exhibition.loc[lambda x: x['year'] < 2009, 'ticket_price'].agg(['mean', 'min', 'max'])"
show theme and year for all exhibitions in an descending order of ticket price.,"exhibition[['theme', 'year']].sort_values('ticket_price', ascending=false)"
"what are the themes and years for exhibitions, sorted by ticket price descending?","exhibition[['theme', 'year']].sort_values('ticket_price', ascending=false)"
"what is the theme, date, and attendance for the exhibition in year 2004?","exhibition_record.merge(exhibition.query(""year==2004""), on='exhibition_id')[['theme', 'date', 'attendance']]"
"return the themes, dates, and attendance for exhibitions that happened in 2004.","exhibition_record.merge(exhibition.query(""year==2004""), on='exhibition_id')[['theme', 'date', 'attendance']]"
show all artist names who didn't have an exhibition in 2004.,"artist['name'].loc[~artist['artist_id'].isin(pd.merge(exhibition.loc[exhibition['year'] == 2004], artist)['artist_id'])]"
what are the names of artists who did not have an exhibition in 2004?,"artist['name'].loc[~artist['artist_id'].isin(pd.merge(exhibition.loc[exhibition['year'] == 2004], artist)['artist_id'])]"
show the theme for exhibitions with both records of an attendance below 100 and above 500.,exhibition_record.merge(exhibition).query('attendance < 100')['theme'].interesect(exhibition_record.merge(exhibition).query('attendance > 500')['theme'])
which themes have had corresponding exhibitions that have had attendance both below 100 and above 500?,exhibition_record.merge(exhibition).query('attendance < 100')['theme'].interesect(exhibition_record.merge(exhibition).query('attendance > 500')['theme'])
how many exhibitions have a attendance more than 100 or have a ticket price below 10?,"pd.merge(exhibition_record, exhibition, on='exhibition_id').loc[lambda x: (x['attendance'] > 100) | (x['ticket_price'] < 10), :].shape[0]"
count the number of exhibitions that have had an attendnance of over 100 or a ticket prices under 10.,"pd.merge(exhibition_record, exhibition, on='exhibition_id').loc[lambda x: (x['attendance'] > 100) | (x['ticket_price'] < 10), :].shape[0]"
show all artist names with an average exhibition attendance over 200.,"pd.merge(pd.merge(exhibition_record, exhibition, on='exhibition_id'), artist, on='artist_id').groupby('artist_id').filter(lambda x: x['attendance'].mean() > 200)['name'].unique()"
what are the names of artist whose exhibitions draw over 200 attendees on average?,"pd.merge(pd.merge(exhibition_record, exhibition, on='exhibition_id'), artist, on='artist_id').groupby('artist_id').filter(lambda x: x['attendance'].mean() > 200)['name'].unique()"
"find the id of the item whose title is ""orange"".","item.loc[lambda x: x['title']=='orange', 'i_id']"
list all information in the item table.,item
find the number of reviews.,review.shape[0]
find the average and maximum rating of all reviews.,"review['rating'].agg(['mean', 'max'])"
find the highest rank of all reviews.,review['rank'].min()
how many different users wrote some reviews?,review['u_id'].nunique()
how many different items were reviewed by some users?,review['i_id'].nunique()
find the number of items that did not receive any review.,len(item[~item['i_id'].isin(review['i_id'])])
find the names of users who did not leave any review.,useracct[~useracct['u_id'].isin(review['u_id'])]['name']
find the names of goods that receive a rating of 10.,"pd.merge(item, review, on='i_id').loc[lambda x: x['rating']==10, 'title']"
find the titles of items whose rating is higher than the average review rating of all items.,"item.loc[lambda x: x['i_id'].isin(review.loc[lambda x: x['rating'] > review['rating'].mean(), 'i_id']), 'title']"
find the titles of items that received any rating below 5.,"item.merge(review, on='i_id').loc[lambda x: x['rating'] < 5, 'title']"
find the titles of items that received both a rating higher than 8 and a rating below 5.,"pd.merge(review.loc[lambda x: x['rating'] > 8], item, on='i_id')['title'].intersect(pd.merge(review.loc[lambda x: x['rating'] < 5], item, on='i_id')['title'])"
find the names of items whose rank is higher than 3 and whose average rating is above 5.,"pd.merge(item, review.loc[lambda x: x['rank']>3], on=""i_id"").groupby('i_id')['rating'].mean().loc[lambda x: x>5].index.intersection(pd.merge(item, review.loc[lambda x: x['rank']>3], on=""i_id"")['title'])"
find the name of the item with the lowest average rating.,"pd.merge(item, review, on='i_id').groupby('i_id')['rating'].mean().sort_values().index[0]"
list the titles of all items in alphabetic order .,item.sort_values('title')['title']
find the name of the user who gives the most reviews.,"pd.merge(useracct, review, on='u_id').groupby('u_id')['name'].count().reset_index().sort_values(0, ascending=false).iloc[0]['name']"
find the name and id of the item with the highest average rating.,"pd.merge(item, review, on='i_id').groupby('i_id').agg({'title': 'first', 'rating': 'mean'}).reset_index().sort_values('rating', ascending=false).iloc[0][['title', 'i_id']]"
find the name and id of the good with the highest average rank.,"(pd.merge(item, review, on='i_id').groupby('i_id').agg({'title': 'first', 'rank': 'mean'}).reset_index().sort_values('rank', ascending=false).iloc[0][['title', 'i_id']])"
"for each user, return the name and the average rating of reviews given by them.","useracct.merge(review, on='u_id').groupby('name')['rating'].mean()"
"for each user, find their name and the number of reviews written by them.","review.groupby('u_id').size().reset_index(name='count').merge(useracct[['u_id', 'name']], on='u_id')['name', 'count']"
find the name of the user who gave the highest rating.,"useracct.merge(review, on='u_id').sort_values('rating', ascending=false).iloc[0]['name']"
find the name of the source user with the highest average trust score.,"useracct.merge(trust, left_on='u_id', right_on='source_u_id').groupby('source_u_id').mean().sort_values('trust', ascending=false).iloc[[0]]['name']"
find each target user's name and average trust score.,"pd.merge(useracct, trust, left_on='u_id', right_on='target_u_id').groupby('target_u_id')['name', 'trust'].mean()"
find the name of the target user with the lowest trust score.,useracct.loc[useracct['u_id'].isin(trust['target_u_id'])].sort_values('trust').iloc[0]['name']
find the names of the items that did not receive any review.,item[~item['i_id'].isin(review['i_id'])]['title']
find the number of users who did not write any review.,useracct[~useracct['u_id'].isin(review['u_id'])].shape[0]
find the number of items without any review.,len(item[~item['i_id'].isin(review['i_id'])])
how many players are there?,player.shape[0] or len(player)
list the names of players in ascending order of votes.,player.sort_values('votes')['player_name']
what are the gender and occupation of players?,"player[['gender', 'occupation']]"
"list the name and residence for players whose occupation is not ""researcher"".","player.loc[player['occupation'] != 'researcher', ['player_name', 'residence']]"
"show the names of sponsors of players whose residence is either ""brandon"" or ""birtle"".","player.loc[player['residence'].isin(['brandon', 'birtle']), 'sponsor_name']"
what is the name of the player with the largest number of votes?,"player.sort_values('votes', ascending=false)['player_name'].iloc[0]"
show different occupations along with the number of players in each occupation.,player.groupby('occupation').size().reset_index(name='count')
please show the most common occupation of players.,player.groupby('occupation').size().sort_values(ascending=false).index[0]
show the residences that have at least two players.,player.groupby('residence').filter(lambda x: len(x) >= 2)['residence'].unique()
show the names of players and names of their coaches.,"pd.merge(pd.merge(player_coach, coach, on='coach_id'), player, on='player_id')[['player_name', 'coach_name']]"
show the names of players coached by the rank 1 coach.,"pd.merge(pd.merge(player_coach, coach, on='coach_id'), player, on='player_id').loc[lambda x: x['rank']==1, 'player_name']"
show the names and genders of players with a coach starting after 2011.,"pd.merge(pd.merge(player_coach, coach, on='coach_id'), player, on='player_id').loc[lambda x: x['starting_year']>2011, ['player_name','gender']]"
show the names of players and names of their coaches in descending order of the votes of players.,"pd.merge(pd.merge(player_coach, coach, on='coach_id'), player, on='player_id').sort_values('votes', ascending=false)[['player_name', 'coach_name']]"
list the names of players that do not have coaches.,"player.loc[~player['player_id'].isin(player_coach['player_id']), 'player_name']"
"show the residences that have both a player of gender ""m"" and a player of gender ""f"".","set(player.loc[player['gender']=='m', 'residence']).intersection(set(player.loc[player['gender']=='f', 'residence']))"
"how many coaches does each club has? list the club id, name and the number of coaches.","coach.groupby('club_id').size().reset_index(name='count').merge(club, on='club_id')[['club_id', 'club_name', 'count']]"
how many gold medals has the club with the most coaches won?,"match_result.merge(coach, on='club_id').groupby('club_id')['gold'].sum().sort_values(ascending=false).nlargest(1).reset_index()"
how many gymnasts are there?,gymnast.shape[0]
count the number of gymnasts.,gymnast.shape[0]
list the total points of gymnasts in descending order.,"gymnast.sort_values('total_points', ascending=false)['total_points']"
"what are the total points for all gymnasts, ordered by total points descending?","gymnast.sort_values('total_points', ascending=false)['total_points']"
list the total points of gymnasts in descending order of floor exercise points.,"gymnast.sort_values('floor_exercise_points', ascending=false)['total_points']"
"what are the total points of gymnasts, ordered by their floor exercise points descending?","gymnast.sort_values('floor_exercise_points', ascending=false)['total_points']"
what is the average horizontal bar points for all gymnasts?,gymnast['horizontal_bar_points'].mean()
return the average horizontal bar points across all gymnasts.,gymnast['horizontal_bar_points'].mean()
what are the names of people in ascending alphabetical order?,people.sort_values('name')['name']
"return the names of people, ordered alphabetically.",people.sort_values('name')['name']
what are the names of gymnasts?,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')['name']"
return the names of the gymnasts.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')['name']"
"what are the names of gymnasts whose hometown is not ""santo domingo""?","pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').loc[lambda x: x['hometown']!='santo domingo', 'name']"
return the names of gymnasts who did not grow up in santo domingo.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').loc[lambda x: x['hometown']!='santo domingo', 'name']"
what is the age of the tallest person?,"people.sort_values('height', ascending=false)['age'].iloc[0]"
return the age of the person with the greatest height.,"people.sort_values('height', ascending=false)['age'].iloc[0]"
list the names of the top 5 oldest people.,"people.sort_values('age', ascending=false).iloc[:5]['name']"
what are the names of the five oldest people?,"people.sort_values('age', ascending=false).iloc[:5]['name']"
what is the total point count of the youngest gymnast?,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').sort_values('age').iloc[0]['total_points']"
return the total points of the gymnast with the lowest age.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').sort_values('age').iloc[0]['total_points']"
what is the average age of all gymnasts?,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')['age'].mean()"
return the average age across all gymnasts.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')['age'].mean()"
what are the distinct hometowns of gymnasts with total points more than 57.5?,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').loc[lambda x: x['total_points'] > 57.5, 'hometown'].unique()"
give the different hometowns of gymnasts that have a total point score of above 57.5.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').loc[lambda x: x['total_points'] > 57.5, 'hometown'].unique()"
what are the hometowns of gymnasts and the corresponding number of gymnasts?,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').groupby('hometown').size()"
how many gymnasts are from each hometown?,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').groupby('hometown').size()"
what is the most common hometown of gymnasts?,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').groupby('hometown').size().sort_values(ascending=false).index[0]"
return the hometown that is most common among gymnasts.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').groupby('hometown').size().sort_values(ascending=false).index[0]"
what are the hometowns that are shared by at least two gymnasts?,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').groupby('hometown').filter(lambda x: len(x) >= 2)['hometown'].unique()"
give the hometowns from which two or more gymnasts are from.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').groupby('hometown').filter(lambda x: len(x) >= 2)['hometown'].unique()"
list the names of gymnasts in ascending order by their heights.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').sort_values('height')['name']"
"what are the names of gymnasts, ordered by their heights ascending?","pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').sort_values('height')['name']"
list the distinct hometowns that are not associated with any gymnast.,"people['hometown'].unique().tolist() - pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')['hometown'].unique().tolist()"
from which hometowns did no gymnasts come from?,"people['hometown'].unique().tolist() - pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')['hometown'].unique().tolist()"
show the hometowns shared by people older than 23 and younger than 20.,"pd.series(list(set(people.loc[people['age']>23, 'hometown']).intersection(set(people.loc[people['age']<20, 'hometown']))))"
from which hometowns did both people older than 23 and younger than 20 come from?,"pd.series(list(set(people.loc[people['age']>23, 'hometown']).intersection(set(people.loc[people['age']<20, 'hometown']))))"
how many distinct hometowns did these people have?,people['hometown'].nunique()
count the number of different hometowns of these people.,people['hometown'].nunique()
show the ages of gymnasts in descending order of total points.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').sort_values('total_points', ascending=false)['age']"
"what are the ages of the gymnasts, ordered descending by their total points?","pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').sort_values('total_points', ascending=false)['age']"
find the total savings balance of all accounts except the account with name ‘brown’.,"pd.merge(accounts, savings, on='custid').loc[lambda x: x['name']!='brown', 'balance'].sum()"
what is the total balance of savings accounts not belonging to someone with the name brown?,"pd.merge(accounts, savings, on='custid').loc[lambda x: x['name']!='brown', 'balance'].sum()"
how many accounts are there in total?,accounts.shape[0]
what is the total checking balance in all accounts?,checking['balance'].sum()
find the total balance across checking accounts.,checking['balance'].sum()
find the average checking balance.,checking['balance'].mean()
what is the average balance in checking accounts?,checking['balance'].mean()
how many accounts have a savings balance above the average savings balance?,(savings['balance'] > savings['balance'].mean()).sum()
find the number of accounts with a savings balance that is higher than the average savings balance.,(savings['balance'] > savings['balance'].mean()).sum()
find the name and id of accounts whose checking balance is below the maximum checking balance.,"accounts.merge(checking, on='custid').loc[lambda x: x['balance']<checking['balance'].max(), ['custid', 'name']]"
what are the customer id and name corresponding to accounts with a checking balance less than the largest checking balance?,"accounts.merge(checking, on='custid').loc[lambda x: x['balance']<checking['balance'].max(), ['custid', 'name']]"
what is the checking balance of the account whose owner’s name contains the substring ‘ee’?,"accounts.merge(checking, on='custid').loc[lambda x: x['name'].str.contains('ee', case=false), 'balance']"
find the balance of the checking account belonging to an owner whose name contains 'ee'.,"accounts.merge(checking, on='custid').loc[lambda x: x['name'].str.contains('ee', case=false), 'balance']"
find the checking balance and saving balance in the brown’s account.,"pd.merge(accounts[accounts['name']=='brown'], checking, on='custid').merge(savings, on='custid')[['balance_x', 'balance_y']]"
what are the checking and savings balances in accounts belonging to brown?,"pd.merge(accounts[accounts['name']=='brown'], checking, on='custid').merge(savings, on='custid')[['balance_x', 'balance_y']]"
"find the names of accounts whose checking balance is above the average checking balance, but savings balance is below the average savings balance.","pd.merge(accounts.loc[checking['balance'] > checking['balance'].mean(), 'name'], accounts.loc[savings['balance'] < savings['balance'].mean(), 'name'], on='name')"
what are the names of accounts with checking balances greater than the average checking balance and savings balances below the average savings balance?,"pd.merge(accounts.loc[checking['balance'] > checking['balance'].mean(), 'name'], accounts.loc[savings['balance'] < savings['balance'].mean(), 'name'], on='name')"
find the checking balance of the accounts whose savings balance is higher than the average savings balance.,"accounts.merge(checking, on='custid').loc[lambda x: x['name'].isin(accounts.merge(savings, on='custid').loc[lambda y: y['balance'] > savings['balance'].mean(), 'name']), 'balance']"
what are the balances of checking accounts belonging to people with savings balances greater than the average savings balance?,"accounts.merge(checking, on='custid').loc[lambda x: x['name'].isin(accounts.merge(savings, on='custid').loc[lambda y: y['balance'] > savings['balance'].mean(), 'name']), 'balance']"
list all customers’ names in the alphabetical order.,accounts.sort_values('name')['name']
what are the names of all the customers in alphabetical order?,accounts.sort_values('name')['name']
find the name of account that has the lowest total checking and saving balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').assign(total_balance=lambda x: x['balance_x'] + x['balance_y']).sort_values('total_balance').iloc[0]['name']"
what is the name corresponding to the accoung with the lowest sum of checking and savings balances?,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').assign(total_balance=lambda x: x['balance_x'] + x['balance_y']).sort_values('total_balance').iloc[0]['name']"
find the names and total checking and savings balances of accounts whose savings balance is higher than the average savings balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').loc[lambda x: x['balance_y'] > savings['balance'].mean(), ['name', 'balance_x', 'balance_y']].assign(balance_sum=lambda x: x['balance_x']+x['balance_y']).loc[:, ['name', 'balance_sum']]"
what are the names and sum of checking and savings balances for accounts with savings balances higher than the average savings balance?,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').loc[lambda x: x['balance_y'] > savings['balance'].mean(), ['name', 'balance_x', 'balance_y']].assign(balance_sum=lambda x: x['balance_x']+x['balance_y']).loc[:, ['name', 'balance_sum']]"
find the name and checking balance of the account with the lowest savings balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').sort_values('balance').iloc[0][['name', 'balance']]"
what are the names and balances of checking accounts belonging to the customer with the lowest savings balance?,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').sort_values('balance').iloc[0][['name', 'balance']]"
find the number of checking accounts for each account name.,"pd.merge(accounts, checking, on='custid').groupby('name').size().reset_index(name='count')"
"what are the names of customers with accounts, and how many checking accounts do each of them have?","pd.merge(accounts, checking, on='custid').groupby('name').size().reset_index(name='count')"
find the total saving balance for each account name.,"pd.merge(accounts, savings, on='custid').groupby('name')['balance_y'].sum()"
"what are the names of customers with accounts, and what are the total savings balances for each?","pd.merge(accounts, savings, on='custid').groupby('name')['balance_y'].sum()"
find the name of accounts whose checking balance is below the average checking balance.,"accounts.merge(checking, on='custid').loc[lambda x: x['balance'] < checking['balance'].mean(), 'name']"
what are the names of customers with checking balances lower than the average checking balance?,"accounts.merge(checking, on='custid').loc[lambda x: x['balance'] < checking['balance'].mean(), 'name']"
find the saving balance of the account with the highest checking balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').sort_values('balance_x', ascending=false).iloc[0]['balance_y']"
what is the savings balance of the account belonging to the customer with the highest checking balance?,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').sort_values('balance_x', ascending=false).iloc[0]['balance_y']"
find the total checking and saving balance of all accounts sorted by the total balance in ascending order.,"pd.merge(checking, savings, on='custid').assign(total_balance=lambda x: x['balance_x'] + x['balance_y']).sort_values('total_balance')['total_balance']"
"what is the sum of checking and savings balances for all customers, ordered by the total balance?","pd.merge(checking, savings, on='custid').assign(total_balance=lambda x: x['balance_x'] + x['balance_y']).sort_values('total_balance')['total_balance']"
find the name and checking balance of the account with the lowest saving balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').sort_values('balance').iloc[0][['balance', 'name']]"
what is the name and checking balance of the account which has the lowest savings balance?,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').sort_values('balance').iloc[0][['balance', 'name']]"
"find the name, checking balance and saving balance of all accounts in the bank.","pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid')[['balance_x', 'balance_y', 'name']]"
"what are the names, checking balances, and savings balances for all customers?","pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid')[['balance_x', 'balance_y', 'name']]"
"find the name, checking balance and savings balance of all accounts in the bank sorted by their total checking and savings balance in descending order.","pd.merge(checking, savings, on='custid').merge(accounts, on='custid')[['balance_x', 'balance_y', 'name']].sort_values(by=['balance_x', 'balance_y'], ascending=false)"
"what are the names, checking balances, and savings balances of customers, ordered by the total of checking and savings balances descending?","pd.merge(checking, savings, on='custid').merge(accounts, on='custid')[['balance_x', 'balance_y', 'name']].sort_values(by=['balance_x', 'balance_y'], ascending=false)"
find the name of accounts whose checking balance is higher than corresponding saving balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').loc[lambda x: x['balance_x'] > x['balance_y'], 'name']"
what are the names of customers with a higher checking balance than savings balance?,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').loc[lambda x: x['balance_x'] > x['balance_y'], 'name']"
find the name and total checking and savings balance of the accounts whose savings balance is lower than corresponding checking balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').loc[lambda x: x['balance_x'] > x['balance_y'], ['name', 'balance_x']+['balance_y']]"
"what are the names of customers who have a savings balance lower than their checking balance, and what is the total of their checking and savings balances?","pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').loc[lambda x: x['balance_x'] > x['balance_y'], ['name', 'balance_x']+['balance_y']]"
find the name and savings balance of the top 3 accounts with the highest saving balance sorted by savings balance in descending order.,"pd.merge(accounts, savings, on='custid').sort_values('balance', ascending=false)[['name', 'balance']].iloc[:3]"
what are names and savings balances of the three accounts with the highest savings balances?,"pd.merge(accounts, savings, on='custid').sort_values('balance', ascending=false)[['name', 'balance']].iloc[:3]"
how many main stream browsers whose market share is at least 5 exist?,(browser['market_share'] >= 5).sum()
list the name of browsers in descending order by market share.,"browser.sort_values('market_share', ascending=false)['name']"
"list the ids, names and market shares of all browsers.","browser[['id', 'name', 'market_share']]"
"what is the maximum, minimum and average market share of the listed browsers?","browser['market_share'].agg(['max', 'min', 'mean'])"
what is the id and market share of the browser safari?,"browser.loc[browser['name']=='safari', ['id', 'market_share']]"
what are the name and os of web client accelerators that do not work with only a 'broadband' type connection?,"web_client_accelerator.loc[lambda x: x['connection'] != 'broadband', ['name', 'operating_system']]"
what is the name of the browser that became compatible with the accelerator 'cproxy' after year 1998 ?,"pd.merge(pd.merge(browser, accelerator_compatible_browser, on='id'), web_client_accelerator, left_on='accelerator_id', right_on='id').loc[(lambda x: (x['name_x']=='cproxy') & (x['compatible_since_year']>1998))(x), 'name_x']"
what are the ids and names of the web accelerators that are compatible with two or more browsers?,"pd.merge(web_client_accelerator, accelerator_compatible_browser, on='id').groupby(['id', 'name']).filter(lambda x: len(x) >= 2)[['id', 'name']].drop_duplicates()"
what is the id and name of the browser that is compatible with the most web accelerators?,"pd.merge(browser, accelerator_compatible_browser, on='id').groupby(['id', 'name']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0, [0, 1]]"
when did the web accelerator 'cachebox' and browser 'internet explorer' become compatible?,"pd.merge(pd.merge(accelerator_compatible_browser, browser, left_on='browser_id', right_on='id'), web_client_accelerator, left_on='accelerator_id', right_on='id').loc[lambda x: (x['name_x']=='internet explorer') & (x['name_y']=='cachebox'), 'compatible_since_year']"
how many different kinds of clients are supported by the web clients accelerators?,web_client_accelerator['client'].nunique()
how many accelerators are not compatible with the browsers listed ?,web_client_accelerator[~web_client_accelerator['id'].isin(accelerator_compatible_browser['accelerator_id'])].shape[0]
what distinct accelerator names are compatible with the browswers that have market share higher than 15?,"pd.merge(pd.merge(web_client_accelerator, accelerator_compatible_browser, left_on='id', right_on='accelerator_id'), browser, left_on='browser_id', right_on='id').loc[lambda x: x['market_share']>15, 'name'].unique()"
list the names of the browser that are compatible with both 'cachebox' and 'fasterfox'.,"pd.merge(pd.merge(web_client_accelerator.loc[lambda x: x['name'] == 'cachebox'], accelerator_compatible_browser, on='accelerator_id'), browser, on='id')['name'].loc[lambda x: x.isin(pd.merge(pd.merge(web_client_accelerator.loc[lambda x: x['name'] == 'fasterfox'], accelerator_compatible_browser, on='accelerator_id'), browser, on='id')['name'])]"
show the accelerator names and supporting operating systems that are not compatible with the browser named 'opera'.,"web_client_accelerator[['name', 'operating_system']].merge(accelerator_compatible_browser[['accelerator_id', 'browser_id']]).merge(browser[browser['name'] == 'opera'][['id']],left_on='browser_id', right_on='id', how='left', indicator=true).query('_merge == ""left_only""')[['name', 'operating_system']]"
"which accelerator name contains substring ""opera""?","web_client_accelerator.loc[web_client_accelerator['name'].str.contains('opera'), 'name']"
find the number of web accelerators used for each operating system.,web_client_accelerator.groupby('operating_system').size().reset_index(name='count')
give me names of all compatible browsers and accelerators in the descending order of compatible year,"pd.merge(pd.merge(accelerator_compatible_browser, browser, left_on='browser_id', right_on='id'), web_client_accelerator, left_on='accelerator_id', right_on='id')[['name_x', 'name_y']].sort_values('compatible_since_year', ascending=false)"
how many wrestlers are there?,wrestler.shape[0]
count the number of wrestlers.,wrestler.shape[0]
list the names of wrestlers in descending order of days held.,"wrestler.sort_values('days_held', ascending=false)['name']"
"what are the names of the wrestlers, ordered descending by days held?","wrestler.sort_values('days_held', ascending=false)['name']"
what is the name of the wrestler with the fewest days held?,wrestler.sort_values('days_held').iloc[0]['name']
return the name of the wrestler who had the lowest number of days held.,wrestler.sort_values('days_held').iloc[0]['name']
"what are the distinct reigns of wrestlers whose location is not ""tokyo,japan"" ?","wrestler.loc[lambda x: x['location'] != 'tokyo , japan', 'reign'].unique()"
"give the different reigns of wrestlers who are not located in tokyo, japan.","wrestler.loc[lambda x: x['location'] != 'tokyo , japan', 'reign'].unique()"
what are the names and location of the wrestlers?,"wrestler[['name', 'location']]"
give the names and locations of all wrestlers.,"wrestler[['name', 'location']]"
"what are the elimination moves of wrestlers whose team is ""team orton""?","elimination.loc[lambda x: x['team'] == 'team orton', 'elimination_move']"
return the elimination movies of wrestlers on team orton.,"elimination.loc[lambda x: x['team'] == 'team orton', 'elimination_move']"
what are the names of wrestlers and the elimination moves?,"pd.merge(elimination, wrestler, on='wrestler_id')[['name', 'elimination_move']]"
give the names of wrestlers and their elimination moves.,"pd.merge(elimination, wrestler, on='wrestler_id')[['name', 'elimination_move']]"
list the names of wrestlers and the teams in elimination in descending order of days held.,"pd.merge(elimination, wrestler, on='wrestler_id').sort_values('days_held', ascending=false)[['name', 'team']]"
"what are the names of wrestlers and their teams in elimination, ordered descending by days held?","pd.merge(elimination, wrestler, on='wrestler_id').sort_values('days_held', ascending=false)[['name', 'team']]"
list the time of elimination of the wrestlers with largest days held.,"pd.merge(elimination, wrestler, on='wrestler_id').sort_values('days_held', ascending=false).iloc[0]['time']"
what is the time of elimination for the wrestler with the most days held?,"pd.merge(elimination, wrestler, on='wrestler_id').sort_values('days_held', ascending=false).iloc[0]['time']"
show times of elimination of wrestlers with days held more than 50.,"pd.merge(elimination, wrestler, on='wrestler_id').loc[lambda x: x['days_held'] > 50, 'time']"
what are the times of elimination for wrestlers with over 50 days held?,"pd.merge(elimination, wrestler, on='wrestler_id').loc[lambda x: x['days_held'] > 50, 'time']"
show different teams in eliminations and the number of eliminations from each team.,elimination.groupby('team').size()
how many eliminations did each team have?,elimination.groupby('team').size()
show teams that have suffered more than three eliminations.,elimination.groupby('team').filter(lambda x: len(x) > 3)['team'].unique()
which teams had more than 3 eliminations?,elimination.groupby('team').filter(lambda x: len(x) > 3)['team'].unique()
show the reign and days held of wrestlers.,"wrestler[['reign', 'days_held']]"
what are the reigns and days held of all wrestlers?,"wrestler[['reign', 'days_held']]"
what are the names of wrestlers days held less than 100?,"wrestler.loc[wrestler['days_held'] < 100, 'name']"
return the names of wrestlers with fewer than 100 days held.,"wrestler.loc[wrestler['days_held'] < 100, 'name']"
please show the most common reigns of wrestlers.,wrestler.groupby('reign').size().sort_values(ascending=false).reset_index(name='count').iloc[0]['reign']
which reign is the most common among wrestlers?,wrestler.groupby('reign').size().sort_values(ascending=false).reset_index(name='count').iloc[0]['reign']
list the locations that are shared by more than two wrestlers.,wrestler.groupby('location').filter(lambda x: len(x) > 2)['location'].unique()
which locations are shared by more than two wrestlers?,wrestler.groupby('location').filter(lambda x: len(x) > 2)['location'].unique()
list the names of wrestlers that have not been eliminated.,wrestler[~wrestler['wrestler_id'].isin(elimination['wrestler_id'])]['name']
what are the names of wrestlers who have never been eliminated?,wrestler[~wrestler['wrestler_id'].isin(elimination['wrestler_id'])]['name']
"show the teams that have both wrestlers eliminated by ""orton"" and wrestlers eliminated by ""benjamin"".","elimination.loc[elimination['eliminated_by']=='orton', 'team'].isin(elimination.loc[elimination['eliminated_by']=='benjamin', 'team'])"
what are the teams that have both wrestlers eliminated by orton and wrestlers eliminated by benjamin?,"elimination.loc[elimination['eliminated_by']=='orton', 'team'].isin(elimination.loc[elimination['eliminated_by']=='benjamin', 'team'])"
what is the number of distinct teams that suffer elimination?,elimination['team'].nunique()
how many different teams have had eliminated wrestlers?,elimination['team'].nunique()
"show the times of elimination by ""punk"" or ""orton"".","elimination.loc[lambda x: x['eliminated_by'].isin(['punk', 'orton']), 'time']"
what are the times of elimination for any instances in which the elimination was done by punk or orton?,"elimination.loc[lambda x: x['eliminated_by'].isin(['punk', 'orton']), 'time']"
how many schools are there?,school.shape[0]
count the number of schools.,school.shape[0]
show all school names in alphabetical order.,school.sort_values('school_name')['school_name']
"list the name, location, mascot for all schools.","school[['school_name', 'location', 'mascot']]"
what are the total and average enrollment of all schools?,"school['enrollment'].agg(['sum', 'mean'])"
what are the mascots for schools with enrollments above the average?,"school.loc[school['enrollment'] > school['enrollment'].mean(), 'mascot']"
list the name of the school with the smallest enrollment.,school.sort_values('enrollment').iloc[0]['school_name']
"show the average, maximum, minimum enrollment of all schools.","school['enrollment'].agg(['mean', 'max', 'min'])"
show each county along with the number of schools and total enrollment in each county.,"school.groupby('county').agg(count=('enrollment', 'size'), sum_enrollment=('enrollment', 'sum'))"
"how many donors have endowment for school named ""glenn""?","endowment.merge(school, on='school_id').loc[lambda x: x['school_name']=='glenn', 'donator_name'].nunique()"
list each donator name and the amount of endowment in descending order of the amount of endowment.,endowment.groupby('donator_name')['amount'].sum().sort_values(ascending=false)
list the names of the schools without any endowment.,"school.loc[~school['school_id'].isin(endowment['school_id']), 'school_name']"
list all the names of schools with an endowment amount smaller than or equal to 10.,"endowment.merge(school, on='school_id').groupby('school_name').filter(lambda x: x['amount'].sum() <= 10)['school_name'].unique()"
"show the names of donors who donated to both school ""glenn"" and ""triton.""","pd.merge(endowment.loc[endowment['school_id'].isin(school.loc[school['school_name']=='glenn', 'school_id'])], endowment.loc[endowment['school_id'].isin(school.loc[school['school_name']=='triton', 'school_id'])], on='donator_name')['donator_name']"
show the names of all the donors except those whose donation amount less than 9.,"endowment.loc[lambda x: x['amount'] >= 9, 'donator_name'].drop_duplicates()"
list the amount and donor name for the largest amount of donation.,"endowment[['amount', 'donator_name']].sort_values('amount', ascending=false).iloc[:1]"
how many budgets are above 3000 in year 2001 or before?,budget.loc[(budget['budgeted'] > 3000) & (budget['year'] <= 2001)].shape[0]
count the number of budgets in year 2001 or before whose budgeted amount is greater than 3000,budget.loc[(budget['budgeted'] > 3000) & (budget['year'] <= 2001)].shape[0]
"show each school name, its budgeted amount, and invested amount in year 2002 or after.","pd.merge(budget.query(""year >= 2002""), school, on='school_id')[['school_name', 'budgeted', 'invested']]"
show all donor names.,endowment['donator_name'].unique()
how many budget record has a budget amount smaller than the invested amount?,(budget['budgeted'] < budget['invested']).sum()
"what is the total budget amount for school ""glenn"" in all years?","pd.merge(budget, school, on='school_id').loc[lambda x: x['school_name']=='glenn', 'budgeted'].sum()"
show the names of schools with a total budget amount greater than 100 or a total endowment greater than 10.,"pd.merge(pd.merge(budget, school, on='school_id'), endowment, on='school_id').groupby('school_name').agg(total_budget=('budgeted', 'sum'), total_endowment=('amount', 'sum')).loc[lambda x: (x['total_budget'] > 100) | (x['total_endowment'] > 10), :].reset_index()['school_name']"
find the names of schools that have more than one donator with donation amount above 8.5.,"pd.merge(endowment.query('amount > 8.5'), school, on='school_id').groupby('school_id').filter(lambda x: len(x) > 1)['school_name']"
find the number of schools that have more than one donator whose donation amount is less than 8.5.,endowment.groupby('school_id').filter(lambda x: (x['amount'] > 8.5).sum() > 1).nunique()
how many buildings are there?,building.shape[0]
"show the name, street address, and number of floors for all buildings ordered by the number of floors.","building[['name', 'street_address', 'floors']].sort_values('floors')"
what is the name of the tallest building?,"building.sort_values('height_feet', ascending=false)['name'].iloc[0]"
"what are the average, maximum, and minimum number of floors for all buildings?","building['floors'].agg(['mean', 'max', 'min'])"
show the number of buildings with a height above the average or a number of floors above the average.,building[(building['height_feet'] > building['height_feet'].mean()) | (building['floors'] > building['floors'].mean())].shape[0]
list the names of buildings with at least 200 feet of height and with at least 20 floors.,"building.loc[(building['height_feet'] >= 200) & (building['floors'] >= 20), 'name']"
"show the names and locations of institutions that are founded after 1990 and have the type ""private"".","institution.loc[(institution['founded'] > 1990) & (institution['type'] == 'private'), ['institution', 'location']]"
"show institution types, along with the number of institutions and total enrollment for each type.","institution.groupby('type').agg({'type': 'count', 'enrollment': 'sum'}).rename(columns={'type': 'count'})"
show the institution type with the largest number of institutions.,institution.groupby('type').size().sort_values(ascending=false).index[0]
show the institution type with an institution founded after 1990 and an institution with at least 1000 enrollment.,"institution.loc[(institution['founded'] > 1990) & (institution['enrollment'] >= 1000), 'type']"
show the name of buildings that do not have any institution.,"building.loc[~building['building_id'].isin(institution['building_id']), 'name']"
show the names of buildings except for those having an institution founded in 2003.,building[~building['building_id'].isin(institution[institution['founded']==2003]['building_id'])]['name']
"for each building, show the name of the building and the number of institutions in it.","institution.merge(building, on='building_id').groupby('name')['building_id'].count()"
show the names and heights of buildings with at least two institutions founded after 1880.,"building.merge(institution.loc[lambda x: x['founded'] > 1880], on='building_id').groupby(['building_id', 'name', 'height_feet']).size().reset_index(name='count').loc[lambda x: x['count'] >= 2][['name', 'height_feet']]"
show all the distinct institution types.,institution['type'].unique()
show institution names along with the number of proteins for each institution.,"protein.merge(institution, on='institution_id').groupby('institution')['institution'].count()"
"how many proteins are associated with an institution founded after 1880 or an institution with type ""private""?","pd.merge(institution, protein, on='institution_id').loc[lambda x: (x['founded'] > 1880) | (x['type'] == 'private'), :].shape[0]"
show the protein name and the institution name.,"pd.merge(institution, protein, on='institution_id')[['protein_name', 'institution']]"
how many proteins are associated with an institution in a building with at least 20 floors?,"pd.merge(pd.merge(institution, protein, on='institution_id'), building, on='building_id').loc[lambda x: x['floors']>=20].shape[0]"
how many institutions do not have an associated protein in our record?,len(institution[~institution['institution_id'].isin(protein['institution_id'])])
show all the locations where no cinema has capacity over 800.,"cinema.loc[lambda x: (~x['location'].isin(cinema.loc[lambda x: x['capacity'] > 800, 'location']))]['location']"
show all the locations where some cinemas were opened in both year 2010 and year 2011.,"cinema.loc[cinema['openning_year'] == 2010, 'location'].unique() & cinema.loc[cinema['openning_year'] == 2011, 'location'].unique()"
how many cinema do we have?,cinema.shape[0]
count the number of cinemas.,cinema.shape[0]
"show name, opening year, and capacity for each cinema.","cinema[['name', 'openning_year', 'capacity']]"
show the cinema name and location for cinemas with capacity above average.,"cinema.loc[cinema['capacity'] > cinema['capacity'].mean(), ['name', 'location']]"
what are all the locations with a cinema?,cinema['location'].unique()
find the distinct locations that has a cinema.,cinema['location'].unique()
show all the cinema names and opening years in descending order of opening year.,"cinema[['name', 'openning_year']].sort_values('openning_year', ascending=false)"
what are the name and location of the cinema with the largest capacity?,"cinema[['name', 'location']].sort_values('capacity', ascending=false).iloc[0]"
"show the average, minimum, and maximum capacity for all the cinemas opened in year 2011 or later.","cinema.loc[cinema['openning_year'] >= 2011, 'capacity'].agg(['mean', 'min', 'max'])"
show each location and the number of cinemas there.,cinema.groupby('location').size()
what is the location with the most cinemas opened in year 2010 or later?,cinema.loc[cinema['openning_year'] >= 2010].groupby('location').size().sort_values(ascending=false).index[0]
show all the locations with at least two cinemas with capacity above 300.,cinema.loc[cinema['capacity'] > 300].groupby('location').filter(lambda x: len(x) >= 2)['location'].unique()
which locations have 2 or more cinemas with capacity over 300?,cinema.loc[cinema['capacity'] > 300].groupby('location').filter(lambda x: len(x) >= 2)['location'].unique()
show the title and director for all films.,"film[['title', 'directed_by']]"
what are the title and director of each film?,"film[['title', 'directed_by']]"
show all directors.,film['directed_by'].unique()
who are all the directors?,film['directed_by'].unique()
list all directors along with the number of films directed by each director.,film.groupby('directed_by').size().reset_index(name='count')
what is total number of show times per dat for each cinema?,"schedule.groupby('cinema_id').sum('show_times_per_day').reset_index().merge(cinema, on='cinema_id')[['name', 'show_times_per_day']]"
what are the title and maximum price of each film?,"pd.merge(schedule, film, on='film_id').groupby('film_id').agg({'title': 'first', 'price': 'max'}).reset_index()[['title', 'price']]"
give me the title and highest price for each film.,"pd.merge(schedule, film, on='film_id').groupby('film_id').agg({'title': 'first', 'price': 'max'}).reset_index()[['title', 'price']]"
"show cinema name, film title, date, and price for each record in schedule.","pd.merge(pd.merge(schedule, film, on='film_id'), cinema, on='cinema_id')[['name', 'title', 'date', 'price']]"
what are the title and director of the films without any schedule?,"film.loc[~film['film_id'].isin(schedule['film_id']), ['title', 'directed_by']]"
show director with the largest number of show times in total.,"pd.merge(schedule, film, on='film_id').groupby('directed_by').agg(show_times_per_day_sum=('show_times_per_day', 'sum')).nlargest(1, 'show_times_per_day_sum').index[0]"
find the locations that have more than one movie theater with capacity above 300.,cinema.loc[cinema['capacity'] > 300].groupby('location').filter(lambda x: len(x) > 1)['location'].unique()
in which locations are there more than one movie theater with capacity above 300?,cinema.loc[cinema['capacity'] > 300].groupby('location').filter(lambda x: len(x) > 1)['location'].unique()
how many films have the word 'dummy' in their titles?,film['title'].str.contains('dummy').sum()
count the number of films whose title contains the word 'dummy'.,film['title'].str.contains('dummy').sum()
are the customers holding coupons with amount 500 bad or good?,"customers.merge(discount_coupons).loc[lambda x: x['coupon_amount']==500, 'good_or_bad_customer']"
"how many bookings did each customer make? list the customer id, first name, and the count.","bookings.groupby('customer_id').size().reset_index(name='count').merge(customers[['customer_id', 'first_name']], on='customer_id')[['customer_id', 'first_name', 'count']]"
what is the maximum total amount paid by a customer? list the customer id and amount.,"payments.groupby('customer_id')['amount_paid'].sum().reset_index().sort_values('amount_paid', ascending=false).iloc[0]"
what are the id and the amount of refund of the booking that incurred the most times of payments?,"pd.merge(bookings, payments, on='booking_id').groupby('booking_id').agg({'amount_of_refund':'first'}).reset_index().sort_values(by='booking_id', ascending=false)[:1]"
what is the id of the product that is booked for 3 times?,products_booked.groupby('product_id').filter(lambda x: len(x) == 3)['product_id'].unique()
what is the product description of the product booked with an amount of 102.76?,"pd.merge(products_booked.loc[lambda x: x['booked_amount']==102.76], products_for_hire, on='product_id')['product_description']"
what are the start date and end date of the booking that has booked the product named 'book collection a'?,"pd.merge(pd.merge(products_for_hire.loc[lambda x: x['product_name']=='book collection a'], products_booked, on='product_id'), bookings, on='booking_id')[['booking_start_date', 'booking_end_date']]"
what are the names of products whose availability equals to 1?,"pd.merge(view_product_availability.loc[lambda x: x['available_yn']==1], products_for_hire, on='product_id')['product_name']"
how many different product types are there?,products_for_hire['product_type_code'].nunique()
"what are the first name, last name, and gender of all the good customers? order by their last name.","customers.loc[lambda x: x['good_or_bad_customer']=='good',['first_name', 'last_name', 'gender_mf']].sort_values('last_name')"
what is the average amount due for all the payments?,payments['amount_due'].mean()
"what are the maximum, minimum, and average booked count for the products booked?","products_booked['booked_count'].agg(['max', 'min', 'mean'])"
what are all the distinct payment types?,payments['payment_type_code'].unique()
what are the daily hire costs for the products with substring 'book' in its name?,"products_for_hire.loc[products_for_hire['product_name'].str.contains('book'), 'daily_hire_cost']"
how many products are never booked with amount higher than 200?,"products_for_hire[~products_for_hire['product_id'].isin(products_booked.loc[lambda x: x['booked_amount']>200, 'product_id'].unique())].shape[0]"
what are the coupon amount of the coupons owned by both good and bad customers?,"pd.merge(discount_coupons, customers, on='coupon_id').loc[lambda x: x['good_or_bad_customer']=='good', 'coupon_amount'].to_frame().merge(pd.merge(discount_coupons, customers, on='coupon_id').loc[lambda x: x['good_or_bad_customer']=='bad', 'coupon_amount'].to_frame()).rename(columns={'coupon_amount': 'common_coupon_amount'})['common_coupon_amount'].unique()"
what are the payment date of the payment with amount paid higher than 300 or with payment type is 'check',"payments.loc[(payments['amount_paid'] > 300) | (payments['payment_type_code'] == 'check'), 'payment_date']"
what are the names and descriptions of the products that are of 'cutlery' type and have daily hire cost lower than 20?,"products_for_hire.loc[(products_for_hire['product_type_code'] == 'cutlery') & (products_for_hire['daily_hire_cost'] < 20), ['product_name', 'product_description']]"
how many phones are there?,phone.shape[0]
list the names of phones in ascending order of price.,phone.sort_values('price')['name']
what are the memories and carriers of phones?,"phone[['memory_in_g', 'carrier']]"
list the distinct carriers of phones with memories bigger than 32.,"phone.loc[lambda x: x['memory_in_g'] > 32, 'carrier'].unique()"
"show the names of phones with carrier either ""sprint"" or ""tmobile"".","phone.loc[lambda x: x['carrier'].isin(['sprint', 'tmobile']), 'name']"
what is the carrier of the most expensive phone?,"phone.sort_values('price', ascending=false).iloc[0]['carrier']"
show different carriers of phones together with the number of phones with each carrier.,phone.groupby('carrier').size().reset_index(name='count')
show the most frequently used carrier of the phones.,phone.groupby('carrier').size().sort_values(ascending=false).index[0]
show the carriers that have both phones with memory smaller than 32 and phones with memory bigger than 64.,"pd.merge(phone.loc[lambda x: x['memory_in_g'] < 32, ['carrier']], phone.loc[lambda x: x['memory_in_g'] > 64, ['carrier']])['carrier']"
show the names of phones and the districts of markets they are on.,"pd.merge(pd.merge(phone_market, market, on='market_id'), phone, on='phone_id')[['name', 'district']]"
"show the names of phones and the districts of markets they are on, in ascending order of the ranking of the market.","pd.merge(pd.merge(phone_market, market, on='market_id'), phone, on='phone_id').sort_values('ranking')[['name', 'district']]"
show the names of phones that are on market with number of shops greater than 50.,"pd.merge(pd.merge(phone_market, market, on='market_id'), phone, on='phone_id').loc[lambda x: x['num_of_shops']>50, 'name']"
"for each phone, show its names and total number of stocks.","phone_market.merge(phone, on='phone_id').groupby('name')['num_of_stock'].sum()"
"show the names of phones that have total number of stocks bigger than 2000, in descending order of the total number of stocks.","pd.merge(phone_market, phone, on='phone_id').groupby('name').filter(lambda x: x['num_of_stock'].sum() >= 2000).groupby('name').agg('sum').sort_values('num_of_stock', ascending=false).index.tolist()"
list the names of phones that are not on any market.,"phone.loc[~phone['phone_id'].isin(phone_market['phone_id']), 'name']"
how many gas companies are there?,company.shape[0]
what is the total number of companies?,company.shape[0]
list the company name and rank for all companies in the decreasing order of their sales.,"company[['company', 'rank']].sort_values('sales_billion', ascending=false)"
what is the name and rank of every company ordered by descending number of sales?,"company[['company', 'rank']].sort_values('sales_billion', ascending=false)"
show the company name and the main industry for all companies whose headquarters are not from usa.,"company.loc[lambda x: x['headquarters'] != 'usa', ['company', 'main_industry']]"
what are the companies and main industries of all companies that are not headquartered in the united states?,"company.loc[lambda x: x['headquarters'] != 'usa', ['company', 'main_industry']]"
show all company names and headquarters in the descending order of market value.,"company[['company', 'headquarters']].sort_values('market_value', ascending=false)"
what are the names and headquarters of all companies ordered by descending market value?,"company[['company', 'headquarters']].sort_values('market_value', ascending=false)"
"show minimum, maximum, and average market value for all companies.","company['market_value'].agg(['min', 'max', 'mean'])"
"what is the minimum, maximum, and average market value for every company?","company['market_value'].agg(['min', 'max', 'mean'])"
show all main industry for all companies.,company['main_industry'].unique()
what are the different main industries for all companies?,company['main_industry'].unique()
list all headquarters and the number of companies in each headquarter.,company.groupby('headquarters').size()
"for each headquarter, what are the headquarter and how many companies are centered there?",company.groupby('headquarters').size()
show all main industry and total market value in each industry.,company.groupby('main_industry')['market_value'].sum()
what are the main indstries and total market value for each industry?,company.groupby('main_industry')['market_value'].sum()
list the main industry with highest total market value and its number of companies.,"company.groupby('main_industry').agg({'market_value': 'sum'}).nlargest(1, 'market_value')"
"for each main industry, what is the total number of companies for the industry with the highest total market value?","company.groupby('main_industry').agg({'market_value': 'sum'}).nlargest(1, 'market_value')"
show headquarters with at least two companies in the banking industry.,company.loc[lambda x: x['main_industry']=='banking'].groupby('headquarters').filter(lambda x: len(x)>=2)['headquarters'].unique()
what are the headquarters with at least two companies in the banking industry?,company.loc[lambda x: x['main_industry']=='banking'].groupby('headquarters').filter(lambda x: len(x)>=2)['headquarters'].unique()
"show gas station id, location, and manager_name for all gas stations ordered by open year.","gas_station.sort_values('open_year')[['station_id', 'location', 'manager_name']]"
"what are the gas station ids, locations, and manager names for the gas stations ordered by opening year?","gas_station.sort_values('open_year')[['station_id', 'location', 'manager_name']]"
how many gas station are opened between 2000 and 2005?,((gas_station['open_year'] >= 2000) & (gas_station['open_year'] <= 2005)).sum()
what is the total number of gas stations that opened between 2000 and 2005?,((gas_station['open_year'] >= 2000) & (gas_station['open_year'] <= 2005)).sum()
show all locations and the number of gas stations in each location ordered by the count.,gas_station.groupby('location').size().sort_values()
"for each location, how many gas stations are there in order?",gas_station.groupby('location').size().sort_values()
show all headquarters with both a company in banking industry and a company in oil and gas.,"pd.merge(company.loc[lambda x: x['main_industry']=='banking', 'headquarters'], company.loc[lambda x: x['main_industry']=='oil and gas', 'headquarters']).squeeze()"
what are the headquarters that have both a company in the banking and 'oil and gas' industries?,"pd.merge(company.loc[lambda x: x['main_industry']=='banking', 'headquarters'], company.loc[lambda x: x['main_industry']=='oil and gas', 'headquarters']).squeeze()"
show all headquarters without a company in banking industry.,"company.loc[lambda x: x['main_industry'] != 'banking', 'headquarters']"
what are the headquarters without companies that are in the banking industry?,"company.loc[lambda x: x['main_industry'] != 'banking', 'headquarters']"
show the company name with the number of gas station.,"pd.merge(station_company, company, on='company_id').groupby('company')['company'].count()"
"for each company id, what are the companies and how many gas stations does each one operate?","pd.merge(station_company, company, on='company_id').groupby('company')['company'].count()"
show company name and main industry without a gas station.,"company.loc[~company['company_id'].isin(station_company['company_id']), ['company', 'main_industry']]"
what are the main industries of the companies without gas stations and what are the companies?,"company.loc[~company['company_id'].isin(station_company['company_id']), ['company', 'main_industry']]"
show the manager name for gas stations belonging to the exxonmobil company.,"pd.merge(pd.merge(station_company, company, on='company_id'), gas_station, on='station_id').loc[lambda x: x['company']=='exxonmobil', 'manager_name']"
what are the names of the managers for gas stations that are operated by the exxonmobil company?,"pd.merge(pd.merge(station_company, company, on='company_id'), gas_station, on='station_id').loc[lambda x: x['company']=='exxonmobil', 'manager_name']"
show all locations where a gas station for company with market value greater than 100 is located.,"pd.merge(pd.merge(station_company, company, on='company_id'), gas_station, on='station_id').loc[lambda x: x['market_value'] > 100, 'location']"
what are the locations that have gas stations owned by a company with a market value greater than 100?,"pd.merge(pd.merge(station_company, company, on='company_id'), gas_station, on='station_id').loc[lambda x: x['market_value'] > 100, 'location']"
show the manager name with most number of gas stations opened after 2000.,gas_station.loc[lambda x: x['open_year'] > 2000].groupby('manager_name').size().sort_values(ascending=false).index[0]
what is the name of the manager with the most gas stations that opened after 2000?,gas_station.loc[lambda x: x['open_year'] > 2000].groupby('manager_name').size().sort_values(ascending=false).index[0]
order all gas station locations by the opening year.,gas_station.sort_values('open_year')['location']
what are the locations of all the gas stations ordered by opening year?,gas_station.sort_values('open_year')['location']
"find the rank, company names, market values of the companies in the banking industry order by their sales and profits in billion.","company.loc[lambda x: x['main_industry']=='banking', ['rank', 'company', 'market_value']].sort_values(['sales_billion', 'profits_billion'])"
"what is the rank, company, and market value of every comapny in the banking industry ordered by sales and profits?","company.loc[lambda x: x['main_industry']=='banking', ['rank', 'company', 'market_value']].sort_values(['sales_billion', 'profits_billion'])"
find the location and representative name of the gas stations owned by the companies with top 3 asset amounts.,"pd.merge(pd.merge(station_company, company, on='company_id'), gas_station, on='station_id').sort_values('assets_billion', ascending=false).iloc[:3][['location', 'representative_name']]"
what are the locations and representatives' names of the gas stations owned by the companies with the 3 largest amounts of assets?,"pd.merge(pd.merge(station_company, company, on='company_id'), gas_station, on='station_id').sort_values('assets_billion', ascending=false).iloc[:3][['location', 'representative_name']]"
how many regions do we have?,region.shape[0]
count the number of regions.,region.shape[0]
show all distinct region names ordered by their labels.,region.sort_values('label')['region_name'].unique()
"what are the different region names, ordered by labels?",region.sort_values('label')['region_name'].unique()
how many parties do we have?,party['party_name'].nunique()
count the number of different parties.,party['party_name'].nunique()
"show the ministers and the time they took and left office, listed by the time they left office.","party[['minister', 'took_office', 'left_office']].sort_values('left_office')"
"who are the ministers, when did they take office, and when did they leave office, ordered by when they left office?","party[['minister', 'took_office', 'left_office']].sort_values('left_office')"
show the minister who took office after 1961 or before 1959.,"party.loc[(party['took_office'] > 1961) | (party['took_office'] < 1959), 'minister']"
who are the ministers who took office after 1961 or before 1959?,"party.loc[(party['took_office'] > 1961) | (party['took_office'] < 1959), 'minister']"
show all ministers who do not belong to progress party.,"party.loc[lambda x: x['party_name'] != 'progress party', 'minister']"
which ministers are not a part of the progress party?,"party.loc[lambda x: x['party_name'] != 'progress party', 'minister']"
show all ministers and parties they belong to in descending order of the time they took office.,"party[['minister', 'party_name']].sort_values('took_office', ascending=false)"
"who are the ministers and what parties do they belong to, listed descending by the times they took office?","party[['minister', 'party_name']].sort_values('took_office', ascending=false)"
return the minister who left office at the latest time.,"party.sort_values('left_office', ascending=false).iloc[0]['minister']"
which minister left office the latest?,"party.sort_values('left_office', ascending=false).iloc[0]['minister']"
list member names and their party names.,"pd.merge(member, party, on='party_id')[['member_name', 'party_name']]"
what are the names of members and their corresponding parties?,"pd.merge(member, party, on='party_id')[['member_name', 'party_name']]"
show all party names and the number of members in each party.,"pd.merge(member, party, on='party_id').groupby('party_name').size()"
how many members are in each party?,"pd.merge(member, party, on='party_id').groupby('party_name').size()"
what is the name of party with most number of members?,"pd.merge(member, party, on='party_id').groupby('party_name').size().sort_values(ascending=false).index[0]"
return the name of the party with the most members.,"pd.merge(member, party, on='party_id').groupby('party_name').size().sort_values(ascending=false).index[0]"
show all party names and their region names.,"pd.merge(party, region, on='region_id')[['party_name', 'region_name']]"
what are the names of parties and their respective regions?,"pd.merge(party, region, on='region_id')[['party_name', 'region_name']]"
show names of parties that does not have any members.,"party.loc[~party['party_id'].isin(member['party_id']), 'party_name']"
what are the names of parties that have no members?,"party.loc[~party['party_id'].isin(member['party_id']), 'party_name']"
show the member names which are in both the party with id 3 and the party with id 1.,"pd.merge(member.loc[lambda x: x['party_id']==3, 'member_name'], member.loc[lambda x: x['party_id']==1, 'member_name'])"
which member names are shared among members in the party with the id 3 and the party with the id 1?,"pd.merge(member.loc[lambda x: x['party_id']==3, 'member_name'], member.loc[lambda x: x['party_id']==1, 'member_name'])"
show member names that are not in the progress party.,"member.merge(party, on='party_id').query('party_name != ""progress party""')['member_name']"
which member names corresponding to members who are not in the progress party?,"member.merge(party, on='party_id').query('party_name != ""progress party""')['member_name']"
how many party events do we have?,party_events.shape[0]
count the number of party events.,party_events.shape[0]
show party names and the number of events for each party.,"party_events.merge(party, on='party_id').groupby('party_id')['party_name'].agg(['first', 'count'])['first'].reset_index()"
how many events are there for each party?,"party_events.merge(party, on='party_id').groupby('party_id')['party_name'].agg(['first', 'count'])['first'].reset_index()"
show all member names who are not in charge of any event.,"member[~member['member_name'].isin(pd.merge(member, party_events, left_on='member_id', right_on='member_in_charge_id')['member_name'])]['member_name']"
what are the names of members who are not in charge of any events?,"member[~member['member_name'].isin(pd.merge(member, party_events, left_on='member_id', right_on='member_in_charge_id')['member_name'])]['member_name']"
what are the names of parties with at least 2 events?,"pd.merge(party_events, party, on='party_id').groupby('party_id').filter(lambda x: len(x) >= 2)['party_name']"
return the names of parties that have two or more events.,"pd.merge(party_events, party, on='party_id').groupby('party_id').filter(lambda x: len(x) >= 2)['party_name']"
what is the name of member in charge of greatest number of events?,"member.merge(party_events, left_on='member_id', right_on='member_in_charge_id').groupby('member_name').size().nlargest(1).index[0]"
return the name of the member who is in charge of the most events.,"member.merge(party_events, left_on='member_id', right_on='member_in_charge_id').groupby('member_name').size().nlargest(1).index[0]"
find the event names that have more than 2 records.,party_events.groupby('event_name').filter(lambda x: x['event_name'].count() > 2)['event_name'].unique()
which event names were used more than twice for party events?,party_events.groupby('event_name').filter(lambda x: x['event_name'].count() > 2)['event_name'].unique()
how many annual meeting events happened in the united kingdom region?,"pd.merge(pd.merge(region, party, on='region_id'), party_events, on='party_id').loc[(lambda x: x['region_name']=='united kingdom') & (lambda x: x['event_name']=='annaual meeting'), :].shape[0]"
count the number of annual meeting events that took place in the region of the united kingdom.,"pd.merge(pd.merge(region, party, on='region_id'), party_events, on='party_id').loc[(lambda x: x['region_name']=='united kingdom') & (lambda x: x['event_name']=='annaual meeting'), :].shape[0]"
how many pilots are there?,pilot.shape[0]
list the names of pilots in ascending order of rank.,pilot.sort_values('rank')['pilot_name']
what are the positions and teams of pilots?,"pilot[['position', 'team']]"
list the distinct positions of pilots older than 30.,"pilot.loc[lambda x: x['age'] > 30, 'position'].unique()"
"show the names of pilots from team ""bradley"" or ""fordham"".","pilot.loc[pilot['team'].isin(['bradley', 'fordham']), 'pilot_name']"
what is the joined year of the pilot of the highest rank?,pilot.sort_values('rank').iloc[0]['join_year']
what are the different nationalities of pilots? show each nationality and the number of pilots of each nationality.,pilot.groupby('nationality').size()
show the most common nationality of pilots.,pilot.groupby('nationality').size().sort_values(ascending=false).index[0]
show the pilot positions that have both pilots joining after year 2005 and pilots joining before 2000.,"pilot.loc[pilot['join_year'] < 2000, 'position'].interesect(pilot.loc[pilot['join_year'] > 2005, 'position'])"
show the names of pilots and models of aircrafts they have flied with.,"pd.merge(pd.merge(pilot_record, aircraft, on='aircraft_id'), pilot, on='pilot_id')[['pilot_name', 'model']]"
show the names of pilots and fleet series of the aircrafts they have flied with in ascending order of the rank of the pilot.,"pd.merge(pd.merge(pilot_record, aircraft, on='aircraft_id'), pilot, on='pilot_id').sort_values('rank')[['pilot_name', 'fleet_series']]"
show the fleet series of the aircrafts flied by pilots younger than 34,"pd.merge(pd.merge(pilot_record, aircraft, on='aircraft_id'), pilot, on='pilot_id').loc[lambda x: x['age']<34, 'fleet_series']"
show the names of pilots and the number of records they have.,"pd.merge(pilot_record, pilot, on='pilot_id').groupby('pilot_name').size()"
show names of pilots that have more than one record.,"pd.merge(pilot_record, pilot, on='pilot_id').groupby('pilot_name').filter(lambda x: len(x) > 1).groupby('pilot_name').size()"
list the names of pilots that do not have any record.,"pilot.loc[~pilot['pilot_id'].isin(pilot_record['pilot_id']), 'pilot_name']"
what document status codes do we have?,ref_document_status['document_status_code']
what is the description of document status code 'working'?,"ref_document_status.loc[lambda x: x['document_status_code']==""working"", 'document_status_description']"
what document type codes do we have?,ref_document_types['document_type_code']
what is the description of document type 'paper'?,"ref_document_types.loc[lambda x: x['document_type_code']=='paper', 'document_type_description']"
what are the shipping agent names?,ref_shipping_agents['shipping_agent_name']
what is the shipping agent code of shipping agent ups?,"ref_shipping_agents.loc[lambda x: x['shipping_agent_name']=='ups', 'shipping_agent_code']"
what are all role codes?,roles['role_code']
what is the description of role code ed?,"roles.loc[lambda x: x['role_code']=='ed', 'role_description']"
what is the role of the employee named koby?,"roles.merge(employees.loc[lambda x: x['employee_name']=='koby'], on='role_code')['role_description']"
list all document ids and receipt dates of documents.,"documents[['document_id', 'receipt_date']]"
"how many employees does each role have? list role description, id and number of employees.","roles.merge(employees, on='role_code').groupby(['role_description', 'role_code']).size().reset_index(name='count')"
list roles that have more than one employee. list the role description and number of employees.,"(employees.merge(roles, on='role_code').groupby(['role_description'])['employee_id'].count().loc[lambda x: x > 1])"
what is the document status description of the document with id 1?,"pd.merge(ref_document_status, documents.loc[lambda x: x['document_id']==1], on='document_status_code')['document_status_description'].squeeze()"
how many documents have the status code done?,(documents['document_status_code'] == 'done').sum()
list the document type code for the document with the id 2.,"documents.loc[lambda x: x['document_id']==2, 'document_type_code']"
list the document ids for any documents with the status code done and the type code paper.,"documents.loc[(documents['document_status_code'] == 'done') & (documents['document_type_code'] == 'paper'), 'document_id']"
what is the name of the shipping agent of the document with id 2?,"pd.merge(ref_shipping_agents, documents.loc[lambda x: x['document_id']==2], on='shipping_agent_code')['shipping_agent_name']"
how many documents were shipped by usps?,"pd.merge(ref_shipping_agents, documents, on='shipping_agent_code').loc[lambda x: x['shipping_agent_name']=='usps', :].shape[0]"
which shipping agent shipped the most documents? list the shipping agent name and the number of documents.,"pd.merge(ref_shipping_agents, documents, on='shipping_agent_code').groupby('shipping_agent_name')['document_id'].count().sort_values(ascending=false).nlargest(1)"
what is the receipt date of the document with id 3?,"documents.loc[lambda x: x['document_id']==3, 'receipt_date']"
what address was the document with id 4 mailed to?,"addresses.merge(documents_mailed, left_on='address_id', right_on='mailed_to_address_id').loc[lambda x: x['document_id']==4, 'address_details']"
what is the mail date of the document with id 7?,"documents_mailed.loc[lambda x: x['document_id']==7, 'mailing_date']"
"list the document ids of documents with the status done and type paper, which not shipped by the shipping agent named usps.","documents.query('document_status_code == ""done"" & document_type_code == ""paper""')['document_id'].values.tolist() - documents[documents['shipping_agent_code'].isin(ref_shipping_agents[ref_shipping_agents['shipping_agent_name']=='usps']['shipping_agent_code'])]['document_id'].values.tolist()"
list document id of documents status is done and document type is paper and the document is shipped by shipping agent named usps.,"documents.loc[(documents['document_status_code']=='done') & (documents['document_type_code']=='paper') & (documents['shipping_agent_code'].isin(ref_shipping_agents.loc[ref_shipping_agents['shipping_agent_name']=='usps', 'shipping_agent_code'])), 'document_id']"
what is draft detail of the document with id 7?,"document_drafts.loc[lambda x: x['document_id']==7, 'draft_details']"
how many draft copies does the document with id 2 have?,(df['document_id'] == 2).sum()
which document has the most draft copies? list its document id and number of draft copies.,"(draft_copies.groupby('document_id')['copy_number'].count().reset_index().sort_values('copy_number', ascending=false).iloc[0])[['document_id', 'copy_number']]"
which documents have more than 1 draft copies? list document id and number of draft copies.,draft_copies.groupby('document_id').filter(lambda x: len(x) > 1).groupby('document_id').size().reset_index(name='count')
list all employees in the circulation history of the document with id 1. list the employee's name.,"pd.merge(employees, circulation_history[circulation_history['document_id']==1], on='employee_id')['employee_name']"
list the employees who have not showed up in any circulation history of documents. list the employee's name.,"employees[~employees['employee_name'].isin(pd.merge(employees, circulation_history, on='employee_id')['employee_name'])]['employee_name']"
which employee has showed up in most circulation history documents. list the employee's name and the number of drafts and copies.,"pd.merge(employees, circulation_history, on='employee_id').groupby(['document_id', 'draft_number', 'copy_number'])['employee_name'].count().reset_index().sort_values(0, ascending=false).iloc[0]['employee_name']"
"for each document, list the number of employees who have showed up in the circulation history of that document. list the document ids and number of employees.",circulation_history.groupby('document_id')['employee_id'].nunique().reset_index(name='count')
list all department names ordered by their starting date.,department.sort_values('mgr_start_date')['dname']
find all dependent names who have a spouse relation with some employee.,"dependent.loc[lambda x: x['relationship'] == 'spouse', 'dependent_name']"
how many female dependents are there?,(dependent['sex'] == 'f').sum()
find the names of departments that are located in houston.,"department.merge(dept_locations, on='dnumber').loc[lambda x: x['dlocation']=='houston', 'dname']"
return the first names and last names of employees who earn more than 30000 in salary.,"employee.loc[lambda x: x['salary'] > 30000, ['fname', 'lname']]"
find the number of employees of each gender whose salary is lower than 50000.,employee.loc[lambda x: x['salary'] < 50000].groupby('sex').size()
"list the first and last names, and the addresses of all employees in the ascending order of their birth date.","employee[['fname', 'lname', 'address']].sort_values('bdate')"
what are the event details of the services that have the type code 'marriage'?,"pd.merge(events, services.query(""service_type_code == 'marriage'""), on='service_id')['event_details']"
what are the ids and details of events that have more than one participants?,"pd.merge(events, participants_in_events, on='event_id').groupby('event_id').filter(lambda x: x.shape[0] > 1)[['event_id', 'event_details']].drop_duplicates()"
"how many events have each participants attended? list the participant id, type and the number.","participants.merge(participants_in_events, on='participant_id').groupby(['participant_id', 'participant_type_code'])['participant_id'].count().reset_index(name='count')"
"what are all the the participant ids, type code and details?","participants[['participant_id', 'participant_type_code', 'participant_details']]"
how many participants belong to the type 'organizer'?,(participants['participant_type_code']=='organizer').sum()
list the type of the services in alphabetical order.,services['service_type_code'].sort_values()
list the service id and details for the events.,"events[['service_id', 'event_details']]"
how many events had participants whose details had the substring 'dr.',"pd.merge(participants, participants_in_events, on='participant_id').loc[lambda x: x['participant_details'].str.contains('dr.')].shape[0]"
what is the most common participant type?,participants.groupby('participant_type_code').size().sort_values(ascending=false).head(1).index[0]
which service id and type has the least number of participants?,"pd.merge(pd.merge(pd.merge(participants, participants_in_events, on='participant_id'), events, on='event_id'), services, on='service_id').groupby('service_id')['service_type_code'].first().sort_values().index[0]"
what is the id of the event with the most participants?,participants_in_events.groupby('event_id').size().sort_values(ascending=false).index[0]
which events id does not have any participant with detail 'kenyatta kuhn'?,"events[~events['event_id'].isin(participants_in_events.merge(participants.query(""participant_details == 'kenyatta kuhn'""), on='participant_id')['event_id'])]['event_id']"
which services type had both successful and failure event details?,"pd.merge(services.loc[lambda x: x.merge(events.loc[lambda x: x['event_details'].eq('success')], on='service_id').index, 'service_type_code'], services.loc[lambda x: x.merge(events.loc[lambda x: x['event_details'].eq('fail')], on='service_id').index, 'service_type_code']).drop_duplicates()"
how many events did not have any participants?,"events.loc[~events['event_id'].isin(participants_in_events['event_id']), 'event_id'].count()"
what are all the distinct participant ids who attended any events?,participants_in_events['participant_id'].nunique()
what is the name of the race held most recently?,"races.sort_values('date', ascending=false).iloc[0]['name']"
what is the name of the race that occurred most recently?,"races.sort_values('date', ascending=false).iloc[0]['name']"
what is the name and date of the most recent race?,"races[['name', 'date']].sort_values('date', ascending=false).head(1)"
what is the name and date of the race that occurred most recently?,"races[['name', 'date']].sort_values('date', ascending=false).head(1)"
find the names of all races held in 2017.,"races.loc[races['year']==2017, 'name']"
what are the names of all the races that occurred in the year 2017?,"races.loc[races['year']==2017, 'name']"
find the distinct names of all races held between 2014 and 2017?,races.query('year >= 2014 and year <= 2017')['name'].unique()
what are the unique names of all race held between 2014 and 2017?,races.query('year >= 2014 and year <= 2017')['name'].unique()
list the forename and surname of all distinct drivers who once had laptime less than 93000 milliseconds?,"pd.merge(drivers, laptimes, on='driverid').loc[lambda x: x['milliseconds'] < 93000, ['forename', 'surname']].drop_duplicates()"
what are the forenames and surnames of all unique drivers who had a lap time of less than 93000 milliseconds?,"pd.merge(drivers, laptimes, on='driverid').loc[lambda x: x['milliseconds'] < 93000, ['forename', 'surname']].drop_duplicates()"
find all the distinct id and nationality of drivers who have had laptime more than 100000 milliseconds?,"pd.merge(drivers, laptimes.loc[laptimes['milliseconds'] > 100000, :], on='driverid')[['driverid', 'nationality']].drop_duplicates()"
what are the different driver ids and nationalities of all drivers who had a laptime of more than 100000 milliseconds?,"pd.merge(drivers, laptimes.loc[laptimes['milliseconds'] > 100000, :], on='driverid')[['driverid', 'nationality']].drop_duplicates()"
what are the forename and surname of the driver who has the smallest laptime?,"drivers.merge(laptimes, on='driverid').sort_values('milliseconds').iloc[0][['forename', 'surname']]"
what is the forename and surname of the driver with the shortest laptime?,"drivers.merge(laptimes, on='driverid').sort_values('milliseconds').iloc[0][['forename', 'surname']]"
what is the id and family name of the driver who has the longest laptime?,"pd.merge(drivers, laptimes, on='driverid').sort_values('milliseconds', ascending=false).iloc[0][['driverid', 'surname']]"
what is the id and last name of the driver with the longest laptime?,"pd.merge(drivers, laptimes, on='driverid').sort_values('milliseconds', ascending=false).iloc[0][['driverid', 'surname']]"
"what is the id, forname and surname of the driver who had the first position in terms of laptime at least twice?","drivers.merge(laptimes.loc[laptimes['position'] == '1'], on='driverid').groupby(['driverid', 'forename', 'surname']).filter(lambda x: x['driverid'].count() >= 2).loc[:, ['driverid', 'forename', 'surname']].drop_duplicates()"
"what is the id, first name, and last name of the driver who was in the first position for laptime at least twice?","drivers.merge(laptimes.loc[laptimes['position'] == '1'], on='driverid').groupby(['driverid', 'forename', 'surname']).filter(lambda x: x['driverid'].count() >= 2).loc[:, ['driverid', 'forename', 'surname']].drop_duplicates()"
how many drivers participated in the race australian grand prix held in 2009?,"pd.merge(results, races, on='raceid').query('name==""australian grand prix"" and year==2009').shape[0]"
how many drivers were in the australian grand prix held in 2009?,"pd.merge(results, races, on='raceid').query('name==""australian grand prix"" and year==2009').shape[0]"
how many drivers did not participate in the races held in 2009?,"results.loc[~results['raceid'].isin(races.loc[races['year']!=2009,'raceid']),'driverid'].nunique()"
how many drivers did not race in 2009?,"results.loc[~results['raceid'].isin(races.loc[races['year']!=2009,'raceid']),'driverid'].nunique()"
give me a list of names and years of races that had any driver whose forename is lewis?,"results.merge(races, on='raceid').merge(drivers, on='driverid').loc[lambda x: x['forename'] == ""lewis"", ['name', 'year']]"
what are the names and years of all races that had a driver with the last name lewis?,"results.merge(races, on='raceid').merge(drivers, on='driverid').loc[lambda x: x['forename'] == ""lewis"", ['name', 'year']]"
find the forename and surname of drivers whose nationality is german?,"drivers.loc[lambda x: x['nationality']=='german', ['forename', 'surname']]"
what is the first and last name of all the german drivers?,"drivers.loc[lambda x: x['nationality']=='german', ['forename', 'surname']]"
find the id and forenames of drivers who participated both the races with name australian grand prix and the races with name chinese grand prix?,"pd.merge(pd.merge(races[races['name']=='australian grand prix'], results, on='raceid'), drivers, on='driverid')[['driverid', 'forename']].merge(pd.merge(pd.merge(races[races['name']=='chinese grand prix'], results, on='raceid'), drivers, on='driverid')[['driverid', 'forename']]).drop_duplicates()"
what is the id and first name of all the drivers who participated in the australian grand prix and the chinese grand prix?,"pd.merge(pd.merge(races[races['name']=='australian grand prix'], results, on='raceid'), drivers, on='driverid')[['driverid', 'forename']].merge(pd.merge(pd.merge(races[races['name']=='chinese grand prix'], results, on='raceid'), drivers, on='driverid')[['driverid', 'forename']]).drop_duplicates()"
what are the forenames and surnames of drivers who participated in the races named australian grand prix but not the races named chinese grand prix?,"drivers[drivers['driverid'].isin(pd.merge(pd.merge(races[races['name']=='australian grand prix'], results, on='raceid'), drivers, on='driverid')[['driverid', 'forename', 'surname']].drop_duplicates().reset_index(drop=true)).query('driverid not in @pd.merge(pd.merge(races[races[""name""]==""chinese grand prix""], results, on=""raceid""), drivers, on=""driverid"")[[""driverid"", ""forename"", ""surname""]].drop_duplicates().reset_index(drop=true)[""driverid""].tolist())][['forename', 'surname']]"
what are the first and last names of all drivers who participated in the australian grand prix but not the chinese grand prix?,"drivers[drivers['driverid'].isin(pd.merge(pd.merge(races[races['name']=='australian grand prix'], results, on='raceid'), drivers, on='driverid')[['driverid', 'forename', 'surname']].drop_duplicates().reset_index(drop=true)).query('driverid not in @pd.merge(pd.merge(races[races[""name""]==""chinese grand prix""], results, on=""raceid""), drivers, on=""driverid"")[[""driverid"", ""forename"", ""surname""]].drop_duplicates().reset_index(drop=true)[""driverid""].tolist())][['forename', 'surname']]"
find all the forenames of distinct drivers who was in position 1 as standing and won?,"pd.merge(drivers, driverstandings.query('position == 1 and wins == 1'), on='driverid')['forename'].unique()"
what are all the different first names of the drivers who are in position as standing and won?,"pd.merge(drivers, driverstandings.query('position == 1 and wins == 1'), on='driverid')['forename'].unique()"
find all the forenames of distinct drivers who won in position 1 as driver standing and had more than 20 points?,"pd.merge(drivers, driverstandings, on='driverid').query('position == 1 and wins == 1 and points > 20')['forename'].unique()"
what are the first names of the different drivers who won in position 1 as driver standing and had more than 20 points?,"pd.merge(drivers, driverstandings, on='driverid').query('position == 1 and wins == 1 and points > 20')['forename'].unique()"
what are the numbers of constructors for different nationalities?,constructors.groupby('nationality').size().reset_index(name='count')
"for each nationality, how many different constructors are there?",constructors.groupby('nationality').size().reset_index(name='count')
what are the numbers of races for each constructor id?,constructorstandings.groupby('constructorid').size().reset_index(name='count')
"for each constructor id, how many races are there?",constructorstandings.groupby('constructorid').size().reset_index(name='count')
what are the names of races that were held after 2017 and the circuits were in the country of spain?,"pd.merge(races, circuits, on='circuitid').loc[(lambda x: x['country']=='spain') & (lambda x: x['year']>2017), 'name']"
what are the names of the races held after 2017 in spain?,"pd.merge(races, circuits, on='circuitid').loc[(lambda x: x['country']=='spain') & (lambda x: x['year']>2017), 'name']"
what are the unique names of races that held after 2000 and the circuits were in spain?,"pd.merge(races, circuits, on='circuitid').loc[(lambda x: (x['country']=='spain') & (x['year']>2000)), 'name'].unique()"
what are the names of all races held after 2000 in spain?,"pd.merge(races, circuits, on='circuitid').loc[(lambda x: (x['country']=='spain') & (x['year']>2000)), 'name'].unique()"
find the distinct driver id and the stop number of all drivers that have a shorter pit stop duration than some drivers in the race with id 841.,"pitstops.loc[lambda x: x['duration'] < pitstops.loc[lambda y: y['raceid'] == 841, 'duration'].max(), ['driverid', 'stop']].drop_duplicates()"
what is the id and stop number for each driver that has a shorter pit stop than the driver in the race with id 841?,"pitstops.loc[lambda x: x['duration'] < pitstops.loc[lambda y: y['raceid'] == 841, 'duration'].max(), ['driverid', 'stop']].drop_duplicates()"
find the distinct driver id of all drivers that have a longer stop duration than some drivers in the race whose id is 841?,"pitstops.loc[lambda x: x['duration'] > pitstops.loc[lambda y: y['raceid']==841, 'duration'].min(), ['driverid', 'stop']].drop_duplicates()"
what are the different ids and stop durations of all the drivers whose stop lasted longer than the driver in the race with the id 841?,"pitstops.loc[lambda x: x['duration'] > pitstops.loc[lambda y: y['raceid']==841, 'duration'].min(), ['driverid', 'stop']].drop_duplicates()"
list the forenames of all distinct drivers in alphabetical order?,drivers['forename'].sort_values().unique()
what are the first names of all the different drivers in alphabetical order?,drivers['forename'].sort_values().unique()
list the names of all distinct races in reversed  lexicographic order?,races['name'].sort_values(ascending=false).unique()
what are the different names of all the races in reverse alphabetical order?,races['name'].sort_values(ascending=false).unique()
what are the names of races held between 2009 and 2011?,"races.loc[races['year'].between(2009, 2011), 'name']"
what are the names of all races held between 2009 and 2011?,"races.loc[races['year'].between(2009, 2011), 'name']"
what are the names of races held after 12:00:00 or before 09:00:00?,"races.loc[races['time'].between('09:00:00', '12:00:00', inclusive=false), 'name']"
what are the names of all races that occurred after 12:00:00 or before 09:00:00?,"races.loc[races['time'].between('09:00:00', '12:00:00', inclusive=false), 'name']"
"what are the drivers' first, last names and id who had more than 8 pit stops or participated in more than 5 race results?","pd.concat([drivers.merge(pitstops, on='driverid').groupby('driverid').filter(lambda x: len(x) > 8),drivers.merge(results, on='driverid').groupby('driverid').filter(lambda x: len(x) > 5)])[['forename', 'surname', 'driverid']].drop_duplicates()"
"what are the drivers' first names,last names, and ids for all those that had more than 8 stops or participated in more than 5 races?","pd.concat([drivers.merge(pitstops, on='driverid').groupby('driverid').filter(lambda x: len(x) > 8),drivers.merge(results, on='driverid').groupby('driverid').filter(lambda x: len(x) > 5)])[['forename', 'surname', 'driverid']].drop_duplicates()"
what are the drivers' last names and id who had 11 pit stops and participated in more than 5 race results?,"pd.merge(drivers, pitstops, on='driverid').groupby(['surname_x', 'driverid']).filter(lambda x: len(x)==11).reset_index()[['surname_x', 'driverid']].merge(pd.merge(drivers, results, on='driverid').groupby(['surname_x', 'driverid']).filter(lambda x: len(x)>5).reset_index()[['surname_x', 'driverid']], on=['surname_x', 'driverid'], how='inner')['surname_x', 'driverid']"
what are the last names and ids of all drivers who had 11 pit stops and participated in more than 5 races?,"pd.merge(drivers, pitstops, on='driverid').groupby(['surname_x', 'driverid']).filter(lambda x: len(x)==11).reset_index()[['surname_x', 'driverid']].merge(pd.merge(drivers, results, on='driverid').groupby(['surname_x', 'driverid']).filter(lambda x: len(x)>5).reset_index()[['surname_x', 'driverid']], on=['surname_x', 'driverid'], how='inner')['surname_x', 'driverid']"
what is the id and last name of the driver who participated in the most races after 2010?,"drivers.merge(results, on='driverid').merge(races, on='raceid').loc[lambda x: x['year']>2010].groupby(['driverid', 'surname']).size().idxmax()[1]"
what are the names of circuits that belong to uk or malaysia?,"circuits.loc[circuits['country'].isin(['uk', 'malaysia']), 'name']"
what are the names of all the circuits that are in the uk or malaysia?,"circuits.loc[circuits['country'].isin(['uk', 'malaysia']), 'name']"
find the id and location of circuits that belong to france or belgium?,"circuits.loc[circuits['country'].isin(['france', 'belgium']), ['circuitid', 'location']]"
what are the ids and locations of all circuits in france or belgium?,"circuits.loc[circuits['country'].isin(['france', 'belgium']), ['circuitid', 'location']]"
find the names of japanese constructors that have once earned more than 5 points?,"pd.merge(constructors, constructorstandings, on='constructorid').loc[(constructors['nationality']=='japanese') & (constructorstandings['points']>5), 'name']"
what are the names of all the japanese constructors that have earned more than 5 points?,"pd.merge(constructors, constructorstandings, on='constructorid').loc[(constructors['nationality']=='japanese') & (constructorstandings['points']>5), 'name']"
what is the average fastest lap speed in race named 'monaco grand prix' in 2008 ?,"results.merge(races.loc[(races['year'] == 2008) & (races['name'] == 'monaco grand prix'), ['raceid']], on='raceid')['fastestlapspeed'].mean()"
what is the average fastest lap speed for the monaco grand prix in 2008?,"results.merge(races.loc[(races['year'] == 2008) & (races['name'] == 'monaco grand prix'), ['raceid']], on='raceid')['fastestlapspeed'].mean()"
what is the maximum fastest lap speed in race named 'monaco grand prix' in 2008 ?,"races.merge(results, on='raceid').query('year == 2008 and name == ""monaco grand prix""')['fastestlapspeed'].max()"
what is the maximum fastest lap speed in the monaco grand prix in 2008?,"races.merge(results, on='raceid').query('year == 2008 and name == ""monaco grand prix""')['fastestlapspeed'].max()"
what are the maximum fastest lap speed in races held after 2004 grouped by race name and ordered by year?,"pd.merge(races[races['year'] > 2014], results, on='raceid').groupby('name').agg({'fastestlapspeed': 'max', 'year': 'first'}).sort_values('year')[['fastestlapspeed', 'year']]"
"for each race name, what is the maximum fastest lap speed for races after 2004 ordered by year?","pd.merge(races[races['year'] > 2014], results, on='raceid').groupby('name').agg({'fastestlapspeed': 'max', 'year': 'first'}).sort_values('year')[['fastestlapspeed', 'year']]"
what are the average fastest lap speed in races held after 2004 grouped by race name and ordered by year?,"pd.merge(races[races['year'] > 2014], results, on='raceid').groupby('name').agg(avg_fastestlapspeed=('fastestlapspeed', 'mean'), year=('year', 'first')).sort_values('year')"
"what is the average fastest lap speed for races held after 2004, for each race, ordered by year?","pd.merge(races[races['year'] > 2014], results, on='raceid').groupby('name').agg(avg_fastestlapspeed=('fastestlapspeed', 'mean'), year=('year', 'first')).sort_values('year')"
"find the id, forename and number of races of all drivers who have at least participated in two races?","drivers.merge(results, on='driverid').merge(races, on='raceid').groupby(['driverid', 'forename']).size().reset_index(name='count').loc[lambda x: x['count']>=2, ['driverid', 'forename', 'count']]"
"what is the id, forename, and number of races for all drivers that have participated in at least 2 races?","drivers.merge(results, on='driverid').merge(races, on='raceid').groupby(['driverid', 'forename']).size().reset_index(name='count').loc[lambda x: x['count']>=2, ['driverid', 'forename', 'count']]"
find the driver id and number of races of all drivers who have at most participated in 30 races?,"pd.merge(pd.merge(drivers, results, on='driverid'), races, on='raceid').groupby('driverid').filter(lambda x: x.shape[0] <= 30).groupby('driverid').size().reset_index(name='count(*)')[['driverid', 'count(*)']]"
"for each id of a driver who participated in at most 30 races, how many races did they participate in?","pd.merge(pd.merge(drivers, results, on='driverid'), races, on='raceid').groupby('driverid').filter(lambda x: x.shape[0] <= 30).groupby('driverid').size().reset_index(name='count(*)')[['driverid', 'count(*)']]"
find the id and surname of the driver who participated the most number of races?,"pd.merge(pd.merge(drivers, results, on='driverid'), races, on='raceid').groupby(['driverid', 'surname']).size().sort_values(ascending=false).reset_index().iloc[0][['driverid', 'surname']]"
what are the ids and last names of all drivers who participated in the most races?,"pd.merge(pd.merge(drivers, results, on='driverid'), races, on='raceid').groupby(['driverid', 'surname']).size().sort_values(ascending=false).reset_index().iloc[0][['driverid', 'surname']]"
how many technicians are there?,technician.shape[0]
what is the number of technicians?,technician.shape[0]
list the names of technicians in ascending order of age.,technician.sort_values('age')['name']
what are the names of the technicians by ascending order of age?,technician.sort_values('age')['name']
what are the team and starting year of technicians?,"technician[['team', 'starting_year']]"
what is the team and starting year for each technician?,"technician[['team', 'starting_year']]"
"list the name of technicians whose team is not ""nyy"".","technician.loc[lambda x: x['team'] != 'nyy', 'name']"
what is the name of the technician whose team is not 'nyy'?,"technician.loc[lambda x: x['team'] != 'nyy', 'name']"
show the name of technicians aged either 36 or 37,"technician.loc[technician['age'].isin([36, 37]), 'name']"
what are the names of the technicians aged either 36 or 37?,"technician.loc[technician['age'].isin([36, 37]), 'name']"
what is the starting year of the oldest technicians?,"technician.sort_values('age', ascending=false).iloc[0]['starting_year']"
what is the starting year for the oldest technician?,"technician.sort_values('age', ascending=false).iloc[0]['starting_year']"
show different teams of technicians and the number of technicians in each team.,technician.groupby('team').size()
"for each team, how many technicians are there?",technician.groupby('team').size()
please show the team that has the most number of technicians.,technician.groupby('team').size().sort_values(ascending=false).index[0]
what are the teams with the most technicians?,technician.groupby('team').size().sort_values(ascending=false).index[0]
show the team that have at least two technicians.,technician.groupby('team').filter(lambda x: x['team'].count() >= 2)['team'].unique()
what is the team with at least 2 technicians?,technician.groupby('team').filter(lambda x: x['team'].count() >= 2)['team'].unique()
show names of technicians and series of machines they are assigned to repair.,"pd.merge(pd.merge(repair_assignment, machine, on='machine_id'), technician, on='technician_id')[['name', 'machine_series']]"
what are the names of technicians and the machine series that they repair?,"pd.merge(pd.merge(repair_assignment, machine, on='machine_id'), technician, on='technician_id')[['name', 'machine_series']]"
show names of technicians in ascending order of quality rank of the machine they are assigned.,"pd.merge(pd.merge(repair_assignment, machine, on='machine_id'), technician, on='technician_id').sort_values('quality_rank')['name']"
what are the names of the technicians by ascending order of quality rank for the machine they are assigned?,"pd.merge(pd.merge(repair_assignment, machine, on='machine_id'), technician, on='technician_id').sort_values('quality_rank')['name']"
show names of technicians who are assigned to repair machines with value point more than 70.,"pd.merge(pd.merge(repair_assignment, machine, on='machine_id'), technician, on='technician_id').loc[lambda x: x['value_points']>70, 'name']"
what are the names of the technicians that are assigned to repair machines with more point values than 70?,"pd.merge(pd.merge(repair_assignment, machine, on='machine_id'), technician, on='technician_id').loc[lambda x: x['value_points']>70, 'name']"
show names of technicians and the number of machines they are assigned to repair.,"repair_assignment.merge(technician, on='technician_id').groupby('name').size().rename_axis('name').reset_index(name='count')"
what are the names of the technicians  and how many machines are they assigned to repair?,"repair_assignment.merge(technician, on='technician_id').groupby('name').size().rename_axis('name').reset_index(name='count')"
list the names of technicians who have not been assigned to repair machines.,"technician.loc[~technician['technician_id'].isin(repair_assignment['technician_id']), 'name']"
what are the names of the technicians that have not been assigned to repair machines?,"technician.loc[~technician['technician_id'].isin(repair_assignment['technician_id']), 'name']"
"show the starting years shared by technicians from team ""cle"" and ""cws"".","set(technician.loc[technician['team']=='cle', 'starting_year']).intersection(set(technician.loc[technician['team']=='cws', 'starting_year']))"
"what are the starting years shared by the technicians from the team ""cle"" or ""cws""?","set(technician.loc[technician['team']=='cle', 'starting_year']).intersection(set(technician.loc[technician['team']=='cws', 'starting_year']))"
how many entrepreneurs are there?,entrepreneur.shape[0]
count the number of entrepreneurs.,entrepreneur.shape[0]
list the companies of entrepreneurs in descending order of money requested.,"entrepreneur.sort_values('money_requested', ascending=false)['company']"
"what are the companies of entrepreneurs, ordered descending by amount of money requested?","entrepreneur.sort_values('money_requested', ascending=false)['company']"
list the companies and the investors of entrepreneurs.,"entrepreneur[['company', 'investor']]"
what are the companies and investors that correspond to each entrepreneur?,"entrepreneur[['company', 'investor']]"
what is the average money requested by all entrepreneurs?,entrepreneur['money_requested'].mean()
return the average money requested across all entrepreneurs.,entrepreneur['money_requested'].mean()
what are the names of people in ascending order of weight?,people.sort_values('weight')['name']
"return the names of people, ordered by weight ascending.",people.sort_values('weight')['name']
what are the names of entrepreneurs?,"pd.merge(entrepreneur, people, on='people_id')['name']"
return the names of entrepreneurs.,"pd.merge(entrepreneur, people, on='people_id')['name']"
"what are the names of entrepreneurs whose investor is not ""rachel elnaugh""?","pd.merge(entrepreneur, people, on='people_id').loc[lambda x: x['investor']!='rachel elnaugh', 'name']"
return the names of entrepreneurs do no not have the investor rachel elnaugh.,"pd.merge(entrepreneur, people, on='people_id').loc[lambda x: x['investor']!='rachel elnaugh', 'name']"
what is the weight of the shortest person?,people.sort_values('height').iloc[0]['weight']
return the weight of the shortest person.,people.sort_values('height').iloc[0]['weight']
what is the name of the entrepreneur with the greatest weight?,"pd.merge(entrepreneur, people, on='people_id').sort_values('weight', ascending=false).iloc[0]['name']"
return the name of the heaviest entrepreneur.,"pd.merge(entrepreneur, people, on='people_id').sort_values('weight', ascending=false).iloc[0]['name']"
what is the total money requested by entrepreneurs with height more than 1.85?,"pd.merge(entrepreneur, people, on='people_id').loc[lambda x: x['height']>1.85, 'money_requested'].sum()"
give the total money requested by entrepreneurs who are taller than 1.85.,"pd.merge(entrepreneur, people, on='people_id').loc[lambda x: x['height']>1.85, 'money_requested'].sum()"
"what are the dates of birth of entrepreneurs with investor ""simon woodroffe"" or ""peter jones""?","people.merge(entrepreneur, on='people_id').loc[lambda x: x['investor'].isin(['simon woodroffe', 'peter jones']), 'date_of_birth']"
return the dates of birth for entrepreneurs who have either the investor simon woodroffe or peter jones.,"people.merge(entrepreneur, on='people_id').loc[lambda x: x['investor'].isin(['simon woodroffe', 'peter jones']), 'date_of_birth']"
what are the weights of entrepreneurs in descending order of money requested?,"people.merge(entrepreneur, on='people_id').sort_values('money_requested', ascending=false)['weight']"
"return the weights of entrepreneurs, ordered descending by amount of money requested.","people.merge(entrepreneur, on='people_id').sort_values('money_requested', ascending=false)['weight']"
what are the investors of entrepreneurs and the corresponding number of entrepreneurs invested by each investor?,entrepreneur.groupby('investor').size()
how many entrepreneurs correspond to each investor?,entrepreneur.groupby('investor').size()
what is the investor that has invested in the most number of entrepreneurs?,entrepreneur.groupby('investor').size().sort_values(ascending=false).index[0]
return the investor who have invested in the greatest number of entrepreneurs.,entrepreneur.groupby('investor').size().sort_values(ascending=false).index[0]
what are the investors that have invested in at least two entrepreneurs?,entrepreneur.groupby('investor').filter(lambda x: len(x) >= 2)['investor'].unique()
return the investors who have invested in two or more entrepreneurs.,entrepreneur.groupby('investor').filter(lambda x: len(x) >= 2)['investor'].unique()
list the names of entrepreneurs and their companies in descending order of money requested?,"pd.merge(entrepreneur, people, on='people_id').sort_values('money_requested')[['name', 'company']]"
"what are the names of entrepreneurs and their corresponding investors, ordered descending by the amount of money requested?","pd.merge(entrepreneur, people, on='people_id').sort_values('money_requested')[['name', 'company']]"
list the names of people that are not entrepreneurs.,"people.loc[~people['people_id'].isin(entrepreneur['people_id']), 'name']"
what are the names of people who are not entrepreneurs?,"people.loc[~people['people_id'].isin(entrepreneur['people_id']), 'name']"
show the investors shared by entrepreneurs that requested more than 140000 and entrepreneurs that requested less than 120000.,"entrepreneur.loc[entrepreneur['money_requested'] > 140000, 'investor'].to_frame().merge(entrepreneur.loc[entrepreneur['money_requested'] < 120000, 'investor'].to_frame(),on='investor')['investor']"
what are the investors who have invested in both entrepreneurs who requested more than 140000 and entrepreneurs who requested less than 120000?,"entrepreneur.loc[entrepreneur['money_requested'] > 140000, 'investor'].to_frame().merge(entrepreneur.loc[entrepreneur['money_requested'] < 120000, 'investor'].to_frame(),on='investor')['investor']"
how many distinct companies are there?,entrepreneur['company'].nunique()
count the number of different companies.,entrepreneur['company'].nunique()
show the company of the tallest entrepreneur.,"pd.merge(entrepreneur, people, on='people_id').sort_values('height', ascending=false).iloc[0]['company']"
which company was started by the entrepreneur with the greatest height?,"pd.merge(entrepreneur, people, on='people_id').sort_values('height', ascending=false).iloc[0]['company']"
how many perpetrators are there?,perpetrator.shape[0]
list the date of perpetrators in descending order of the number of people killed.,"perpetrator.sort_values('killed', ascending=false)['date']"
list the number of people injured by perpetrators in ascending order.,perpetrator.sort_values('injured')['injured']
what is the average number of people injured by all perpetrators?,perpetrator['injured'].mean()
what is the location of the perpetrator with the largest kills.,"perpetrator.sort_values('killed', ascending=false).iloc[0]['location']"
what are the names of people in ascending order of height?,people.sort_values('height')['name']
what are the names of perpetrators?,"pd.merge(people, perpetrator, on='people_id')['name']"
"what are the names of perpetrators whose country is not ""china""?","pd.merge(people, perpetrator, on='people_id').loc[lambda x: x['country'] != 'china', 'name']"
what is the name of the perpetrator with the biggest weight.,"people.merge(perpetrator, on='people_id').sort_values('weight', ascending=false).iloc[0]['name']"
what is the total kills of the perpetrators with height more than 1.84.,"pd.merge(people, perpetrator, on='people_id').loc[lambda x: x['height'] > 1.84, 'killed'].sum()"
"what are the names of perpetrators in country ""china"" or ""japan""?","pd.merge(people, perpetrator, on='people_id').loc[lambda x: x['country'].isin(['china', 'japan']), 'name']"
what are the heights of perpetrators in descending order of the number of people they injured?,"people.merge(perpetrator, on=""people_id"").sort_values('injured', ascending=false)[""height""]"
what are the countries of perpetrators? show each country and the corresponding number of perpetrators there.,perpetrator.groupby('country').size().reset_index(name='count')
what is the country that has the most perpetrators?,perpetrator.groupby('country').size().nlargest(1)
what are the countries that have at least two perpetrators?,perpetrator.groupby('country').filter(lambda x: len(x) >= 2).groupby('country').size()
list the names of perpetrators in descending order of the year.,"pd.merge(people, perpetrator, on='people_id').sort_values('year', ascending=false)['name']"
list the names of people that are not perpetrators.,"people.loc[~people['people_id'].isin(perpetrator['people_id']), 'name']"
show the countries that have both perpetrators with injures more than 50 and perpetrators with injures smaller than 20.,"set(perpetrator.loc[perpetrator['injured'] > 50, 'country']).intersection(perpetrator.loc[perpetrator['injured'] < 20, 'country'])"
how many distinct locations of perpetrators are there?,perpetrator['location'].nunique()
show the date of the tallest perpetrator.,"perpetrator.merge(people, on='people_id').sort_values('height', ascending=false).iloc[0]['date']"
in which year did the most recent crime happen?,perpetrator['year'].max()
report the name of all campuses in los angeles county.,"campuses.loc[campuses['county']=='los angeles', 'campus']"
what campuses are located in the county of los angeles?,"campuses.loc[campuses['county']=='los angeles', 'campus']"
what are the names of all campuses located at chico?,"campuses.loc[campuses['location']=='chico', 'campus']"
what campuses are located in chico?,"campuses.loc[campuses['location']=='chico', 'campus']"
find all the campuses opened in 1958.,"campuses.loc[campuses['year']==1958, 'campus']"
what are the campuses that opened in 1958?,"campuses.loc[campuses['year']==1958, 'campus']"
find the name of the campuses opened before 1800.,"campuses.loc[lambda x: x['year'] < 1800, 'campus']"
what campuses opened before 1800?,"campuses.loc[lambda x: x['year'] < 1800, 'campus']"
which campus was opened between 1935 and 1939?,"campuses.loc[lambda x: (x['year'] >= 1935) & (x['year'] <= 1939), 'campus']"
what campuses opened between 1935 and 1939?,"campuses.loc[lambda x: (x['year'] >= 1935) & (x['year'] <= 1939), 'campus']"
"find the name of the campuses that is in northridge, los angeles or in san francisco, san francisco.","pd.concat([campuses.loc[(campuses['location']=='northridge') & (campuses['county']=='los angeles'), 'campus'], campuses.loc[(campuses['location']=='san francisco') & (campuses['county']=='san francisco'), 'campus']]).drop_duplicates()"
"what campuses are located in northridge, los angeles or in san francisco, san francisco?","pd.concat([campuses.loc[(campuses['location']=='northridge') & (campuses['county']=='los angeles'), 'campus'], campuses.loc[(campuses['location']=='san francisco') & (campuses['county']=='san francisco'), 'campus']]).drop_duplicates()"
"what is the campus fee of ""san jose state university"" in year 1996?","pd.merge(campuses[campuses['campus'] == 'san jose state university'], csu_fees[csu_fees['year'] == 1996], left_on='id', right_on='campus')['campusfee']"
what is the campus fee for san jose state university in 1996?,"pd.merge(campuses[campuses['campus'] == 'san jose state university'], csu_fees[csu_fees['year'] == 1996], left_on='id', right_on='campus')['campusfee']"
"what is the campus fee of ""san francisco state university"" in year 1996?","pd.merge(campuses[campuses['campus'] == 'san francisco state university'], csu_fees[csu_fees['year'] == 1996], left_on='id', right_on='campus')['campusfee'].iloc[0]"
what is the campus fee for san francisco state university in 1996?,"pd.merge(campuses[campuses['campus'] == 'san francisco state university'], csu_fees[csu_fees['year'] == 1996], left_on='id', right_on='campus')['campusfee'].iloc[0]"
find the count of universities whose campus fee is greater than the average campus fee.,(csu_fees['campusfee'] > csu_fees['campusfee'].mean()).sum()
how many universities have a campus fee higher than average?,(csu_fees['campusfee'] > csu_fees['campusfee'].mean()).sum()
how many universities have a campus fee greater than the average?,(csu_fees['campusfee'] > csu_fees['campusfee'].mean()).sum()
which university is in los angeles county and opened after 1950?,"campuses.loc[(campuses['county'] == 'los angeles') & (campuses['year'] > 1950), 'campus']"
what campuses are located in los angeles county and opened after 1950?,"campuses.loc[(campuses['county'] == 'los angeles') & (campuses['year'] > 1950), 'campus']"
which year has the most degrees conferred?,degrees.groupby('year').sum().sort_values(ascending=false).head(1).index[0]
in what year was the most degrees conferred?,degrees.groupby('year').sum().sort_values(ascending=false).head(1).index[0]
which campus has the most degrees conferred in all times?,degrees.groupby('campus').sum().sort_values(ascending=false).index[0]
what campus has the most degrees  conferrred over its entire existence?,degrees.groupby('campus').sum().sort_values(ascending=false).index[0]
which campus has the most faculties in year 2003?,"pd.merge(campuses, faculty, left_on='id', right_on='campus').loc[lambda x: x['year']==2003].sort_values('faculty', ascending=false).iloc[0]['campus']"
what campus has the most faculties in 2003?,"pd.merge(campuses, faculty, left_on='id', right_on='campus').loc[lambda x: x['year']==2003].sort_values('faculty', ascending=false).iloc[0]['campus']"
find the average fee on a csu campus in 1996,"csu_fees.loc[lambda x: x['year']==1996, 'campusfee'].mean()"
what is the average fee for a csu campus in the year of 1996?,"csu_fees.loc[lambda x: x['year']==1996, 'campusfee'].mean()"
what is the average fee on a csu campus in 2005?,"csu_fees.loc[lambda x: x['year']==2005, 'campusfee'].mean()"
what is the average fee for a csu campus in the year of 2005?,"csu_fees.loc[lambda x: x['year']==2005, 'campusfee'].mean()"
report the total number of degrees granted between 1998 and 2002.,"degrees.loc[lambda x: (x['year'] >= 1998) & (x['year'] <= 2002)].merge(campuses, left_on='campus', right_on='id').groupby('campus')['degrees'].sum()"
how many degrees were conferred between 1998 and 2002?,"degrees.loc[lambda x: (x['year'] >= 1998) & (x['year'] <= 2002)].merge(campuses, left_on='campus', right_on='id').groupby('campus')['degrees'].sum()"
"for each orange county campus, report the number of degrees granted after 2000.","degrees.loc[lambda x: x['year']>=2000].merge(campuses[campuses['county']=='orange'], left_on='campus', right_on='id').groupby('campus').agg({'degrees':'sum'}).reset_index().rename(columns={'campus':'campus', 'degrees':'sum'})[['campus', 'sum']]"
what is the total number of degrees granted after 2000 for each orange county campus?,"degrees.loc[lambda x: x['year']>=2000].merge(campuses[campuses['county']=='orange'], left_on='campus', right_on='id').groupby('campus').agg({'degrees':'sum'}).reset_index().rename(columns={'campus':'campus', 'degrees':'sum'})[['campus', 'sum']]"
find the names of the campus which has more faculties in 2002 than every campus in orange county.,"campuses.merge(faculty[faculty['year']==2002][['campus', 'faculty']]).query('year==2002 and faculty > @campuses.merge(faculty[faculty[""year""]==2002][[""campus"", ""faculty""]]).query(""year==2002 and county=='orange'"")[""faculty""].max()')['campus']"
what are the names of the campus that have more faculties in 2002 than the maximum number in orange county?,"campuses.merge(faculty[faculty['year']==2002][['campus', 'faculty']]).query('year==2002 and faculty > @campuses.merge(faculty[faculty[""year""]==2002][[""campus"", ""faculty""]]).query(""year==2002 and county=='orange'"")[""faculty""].max()')['campus']"
what campus had more than 400 total enrollment but more than 200 full time enrollment in year 1956?,"pd.merge(campuses, enrollments, left_on='id', right_on='campus').query('year == 1956 and totalenrollment_ay > 400 and fte_ay > 200')['campus']"
"what campus started in year 1956, has more than 200 full time students, and more than 400 students enrolled?","pd.merge(campuses, enrollments, left_on='id', right_on='campus').query('year == 1956 and totalenrollment_ay > 400 and fte_ay > 200')['campus']"
how many campuses are there in los angeles county?,(campuses['county'] == 'los angeles').sum()
how many campuses exist are in the county of la?,(campuses['county'] == 'los angeles').sum()
list the campuses in los angeles county.,"campuses.loc[campuses['county']=='los angeles', 'campus']"
what campuses are in los angeles county?,"campuses.loc[campuses['county']=='los angeles', 'campus']"
"how many degrees were conferred in ""san jose state university"" in 2000?","pd.merge(campuses.loc[lambda x: x['campus'] == 'san jose state university'], degrees.loc[lambda x: x['year'] == 2000], left_on='id', right_on='campus')['degrees']"
how many degrees were conferred at san jose state university in 2000?,"pd.merge(campuses.loc[lambda x: x['campus'] == 'san jose state university'], degrees.loc[lambda x: x['year'] == 2000], left_on='id', right_on='campus')['degrees']"
"what are the degrees conferred in ""san francisco state university"" in 2001.","pd.merge(campuses[campuses['campus'] == 'san francisco state university'], degrees[degrees['year']==2001], left_on='id', right_on='campus')['degrees']"
what degrees were conferred in san francisco state university in the year 2001?,"pd.merge(campuses[campuses['campus'] == 'san francisco state university'], degrees[degrees['year']==2001], left_on='id', right_on='campus')['degrees']"
how many faculty is there in total in the year of 2002?,"faculty.loc[lambda x: x['year']==2002, 'faculty'].sum()"
"how many faculty, in total, are there in the year 2002?","faculty.loc[lambda x: x['year']==2002, 'faculty'].sum()"
"what is the number of faculty lines in campus ""long beach state university"" in 2002?","pd.merge(faculty, campuses, left_on='campus', right_on='id').loc[(faculty['year']==2002) & (campuses['campus']=='long beach state university'), 'faculty']"
what is the number of faculty at long beach state university in 2002?,"pd.merge(faculty, campuses, left_on='campus', right_on='id').loc[(faculty['year']==2002) & (campuses['campus']=='long beach state university'), 'faculty']"
"how many faculty lines are there in ""san francisco state university"" in year 2004?","pd.merge(faculty.loc[faculty['year']==2004], campuses.loc[campuses['campus']==""san francisco state university""], left_on='campus', right_on='id')['faculty']"
how many faculty lines are there at san francisco state university in 2004?,"pd.merge(faculty.loc[faculty['year']==2004], campuses.loc[campuses['campus']==""san francisco state university""], left_on='campus', right_on='id')['faculty']"
list the campus that have between 600 and 1000 faculty lines in year 2004.,"pd.merge(campuses, faculty, left_on='id', right_on='campus').loc[lambda x: (x['faculty'] >= 600) & (x['faculty'] <= 1000) & (x['year'] == 2004), 'campus']"
what are the campuses that had between 600 and 1000 faculty members in 2004?,"pd.merge(campuses, faculty, left_on='id', right_on='campus').loc[lambda x: (x['faculty'] >= 600) & (x['faculty'] <= 1000) & (x['year'] == 2004), 'campus']"
how many faculty lines are there in the university that conferred the most number of degrees in year 2002?,"(pd.merge(pd.merge(campuses, faculty, left_on='id', right_on='campus'),degrees,left_on=['id', 'year'],right_on=['campus', 'year']).loc[lambda x: x['year']==2002].sort_values('degrees', ascending=false).iloc[0]['faculty'])"
how many faculty members did the university that conferred the most degrees in 2002 have?,"(pd.merge(pd.merge(campuses, faculty, left_on='id', right_on='campus'),degrees,left_on=['id', 'year'],right_on=['campus', 'year']).loc[lambda x: x['year']==2002].sort_values('degrees', ascending=false).iloc[0]['faculty'])"
how many faculty lines are there in the university that conferred the least number of degrees in year 2001?,"pd.merge(pd.merge(campuses, faculty, left_on='id', right_on='campus'), degrees, left_on=['id', 'year'], right_on=['campus', 'year']).loc[lambda x: x['year']==2001].sort_values('degrees').iloc[0]['faculty']"
how many faculty members are at the university that gave the least number of degrees in 2001?,"pd.merge(pd.merge(campuses, faculty, left_on='id', right_on='campus'), degrees, left_on=['id', 'year'], right_on=['campus', 'year']).loc[lambda x: x['year']==2001].sort_values('degrees').iloc[0]['faculty']"
"how many undergraduates are there in ""san jose state university"" in year 2004?","pd.merge(discipline_enrollments, campuses, left_on='campus', right_on='id').loc[(discipline_enrollments['year'] == 2004) & (campuses['campus'] == 'san jose state university'), 'undergraduate'].sum()"
how many undergraduates are there at san jose state,"pd.merge(discipline_enrollments, campuses, left_on='campus', right_on='id').loc[(discipline_enrollments['year'] == 2004) & (campuses['campus'] == 'san jose state university'), 'undergraduate'].sum()"
"what is the number of graduates in ""san francisco state university"" in year 2004?","pd.merge(discipline_enrollments, campuses, left_on='campus', right_on='id').loc[(lambda x: (x['year']==2004) & (x['campus']=='san francisco state university')), 'graduate'].sum()"
how many people graduated from san francisco state university in 2004?,"pd.merge(discipline_enrollments, campuses, left_on='campus', right_on='id').loc[(lambda x: (x['year']==2004) & (x['campus']=='san francisco state university')), 'graduate'].sum()"
"what is the campus fee of ""san francisco state university"" in year 2000?","pd.merge(csu_fees, campuses, left_on='campus', right_on='id').loc[(lambda x: x['campus']=='san francisco state university')(campuses) & (csu_fees['year']==2000)].iloc[0]['campusfee']"
"in the year 2000, what is the campus fee for san francisco state university?","pd.merge(csu_fees, campuses, left_on='campus', right_on='id').loc[(lambda x: x['campus']=='san francisco state university')(campuses) & (csu_fees['year']==2000)].iloc[0]['campusfee']"
"find the campus fee of ""san jose state university"" in year 2000.","pd.merge(csu_fees, campuses, left_on='campus', right_on='id').loc[(lambda x: x['campus']=='san jose state university')(df) & (df['year']==2000), 'campusfee']"
what is the campus fee in the year 2000 for san jose state university?,"pd.merge(csu_fees, campuses, left_on='campus', right_on='id').loc[(lambda x: x['campus']=='san jose state university')(df) & (df['year']==2000), 'campusfee']"
how many csu campuses are there?,campuses.shape[0]
what is the total number of campuses?,campuses.shape[0]
how many candidates are there?,candidate.shape[0]
count the number of candidates.,candidate.shape[0]
which poll resource provided the most number of candidate information?,candidate.groupby('poll_source').size().sort_values(ascending=false).index[0]
return the poll resource associated with the most candidates.,candidate.groupby('poll_source').size().sort_values(ascending=false).index[0]
what are the top 3 highest support rates?,"candidate.sort_values('support_rate', ascending=false)['support_rate'].head(3)"
return the top 3 greatest support rates.,"candidate.sort_values('support_rate', ascending=false)['support_rate'].head(3)"
find the id of the candidate who got the lowest oppose rate.,candidate.sort_values('oppose_rate').iloc[0]['candidate_id']
what is the id of the candidate with the lowest oppose rate?,candidate.sort_values('oppose_rate').iloc[0]['candidate_id']
"please list support, consider, and oppose rates for each candidate in ascending order by unsure rate.","candidate[['support_rate', 'consider_rate', 'oppose_rate']].sort_values('unsure_rate')"
"what are the support, consider, and oppose rates of each candidate, ordered ascending by their unsure rate?","candidate[['support_rate', 'consider_rate', 'oppose_rate']].sort_values('unsure_rate')"
which poll source does the highest oppose rate come from?,"candidate.sort_values('oppose_rate', ascending=false).iloc[0]['poll_source']"
return the poll source corresponding to the candidate who has the oppose rate.,"candidate.sort_values('oppose_rate', ascending=false).iloc[0]['poll_source']"
list all people names in the order of their date of birth from old to young.,people.sort_values('date_of_birth')['name']
"what are the names of all people, ordered by their date of birth?",people.sort_values('date_of_birth')['name']
find the average height and weight for all males (sex is m).,"people.loc[lambda x: x['sex']=='m', ['height', 'weight']].mean()"
what are the average height and weight across males (sex is m)?,"people.loc[lambda x: x['sex']=='m', ['height', 'weight']].mean()"
find the names of people who are taller than 200 or lower than 190.,"people.loc[(people['height'] > 200) | (people['height'] < 190), 'name']"
what are the names of people who have a height greater than 200 or less than 190?,"people.loc[(people['height'] > 200) | (people['height'] < 190), 'name']"
find the average and minimum weight for each gender.,"people.groupby('sex')['weight'].agg(['mean', 'min']).reset_index()"
what are the average and minimum weights for people of each sex?,"people.groupby('sex')['weight'].agg(['mean', 'min']).reset_index()"
find the name and gender of the candidate who got the highest support rate.,"people.merge(candidate, on='people_id').sort_values('support_rate', ascending=false)[['name', 'sex']].iloc[:1]"
what is the name and sex of the candidate with the highest support rate?,"people.merge(candidate, on='people_id').sort_values('support_rate', ascending=false)[['name', 'sex']].iloc[:1]"
find the name of the candidates whose oppose percentage is the lowest for each sex.,"pd.merge(people, candidate, on='people_id').groupby('sex').agg({'name': 'first', 'sex': 'first', 'oppose_rate': 'min'}).reset_index(drop=true)"
"for each sex, what is the name and sex of the candidate with the oppose rate for their sex?","pd.merge(people, candidate, on='people_id').groupby('sex').agg({'name': 'first', 'sex': 'first', 'oppose_rate': 'min'}).reset_index(drop=true)"
which gender got the highest average uncertain ratio.,"pd.merge(people, candidate, on='people_id').groupby('sex').agg(avg_unsure_rate=('unsure_rate', 'mean')).sort_values('avg_unsure_rate', ascending=false).iloc[[0]].index.reshape(-1)"
what is the sex of the candidate who had the highest unsure rate?,"pd.merge(people, candidate, on='people_id').groupby('sex').agg(avg_unsure_rate=('unsure_rate', 'mean')).sort_values('avg_unsure_rate', ascending=false).iloc[[0]].index.reshape(-1)"
what are the names of people who did not participate in the candidate election.,"people.loc[~people['people_id'].isin(candidate['people_id']), 'name']"
give the names of people who did not participate in the candidate election.,"people.loc[~people['people_id'].isin(candidate['people_id']), 'name']"
find the names of the candidates whose support percentage is lower than their oppose rate.,"pd.merge(people, candidate, on='people_id').loc[lambda x: x['support_rate'] < x['oppose_rate'], 'name']"
what are the names of candidates who have a lower support rate than oppose rate?,"pd.merge(people, candidate, on='people_id').loc[lambda x: x['support_rate'] < x['oppose_rate'], 'name']"
how many people are there whose weight is higher than 85 for each gender?,people[people['weight'] > 85].groupby('sex').size()
count the number of people of each sex who have a weight higher than 85.,people[people['weight'] > 85].groupby('sex').size()
"find the highest support percentage, lowest consider rate and oppose rate of all candidates.","candidate.agg({'support_rate': 'max', 'consider_rate': 'min', 'oppose_rate': 'min'})"
"return the maximum support rate, minimum consider rate, and minimum oppose rate across all candidates?","candidate.agg({'support_rate': 'max', 'consider_rate': 'min', 'oppose_rate': 'min'})"
list all female (sex is f) candidate names in the alphabetical order.,"pd.merge(people, candidate, on='people_id').loc[lambda x: x['sex']=='f'].sort_values('name')['name']"
what are the names of all female candidates in alphabetical order (sex is f)?,"pd.merge(people, candidate, on='people_id').loc[lambda x: x['sex']=='f'].sort_values('name')['name']"
find the name of people whose height is lower than the average.,"people.loc[lambda x: x['height'] < x['height'].mean(), 'name']"
what are the names of people who are shorter than average?,"people.loc[lambda x: x['height'] < x['height'].mean(), 'name']"
list all info about all people.,people
what is all the information about all people?,people
find the titles of all movies directed by steven spielberg.,"movie.loc[lambda x: x['director']=='steven spielberg', 'title']"
what are the names of all movies directed by steven spielberg?,"movie.loc[lambda x: x['director']=='steven spielberg', 'title']"
what is the name of the movie produced after 2000 and directed by james cameron?,"movie.loc[(movie['director']=='james cameron') & (movie['year']>2000), 'title']"
what are the titles of all movies that james cameron directed after 2000?,"movie.loc[(movie['director']=='james cameron') & (movie['year']>2000), 'title']"
how many movies were made before 2000?,(movie['year'] < 2000).sum()
who is the director of movie avatar?,"movie.loc[lambda x: x['title']=='avatar', 'director']"
who directed avatar?,"movie.loc[lambda x: x['title']=='avatar', 'director']"
how many reviewers listed?,reviewer.shape[0]
how many reviewers are there?,reviewer.shape[0]
what is the id of the reviewer whose name has substring “mike”?,"reviewer.loc[reviewer['name'].str.contains('mike'), 'rid']"
"what is the id of the reviewer whose name includes the word ""mike""?","reviewer.loc[reviewer['name'].str.contains('mike'), 'rid']"
what is the reviewer id of daniel lewis?,"reviewer.loc[lambda x: x['name']=='daniel lewis', 'rid']"
what is the id of the reviewer named daniel lewis?,"reviewer.loc[lambda x: x['name']=='daniel lewis', 'rid']"
what is the total number of ratings that has more than 3 stars?,(rating['stars'] > 3).sum()
how many movie ratings have more than 3 stars?,(rating['stars'] > 3).sum()
what is the lowest and highest rating star?,"rating['stars'].agg(['max', 'min'])"
what is the maximum and mininum number of stars a rating can receive?,"rating['stars'].agg(['max', 'min'])"
"find all years that have a movie that received a rating of 4 or 5, and sort them in increasing order of year.","pd.merge(movie, rating, on='mid').loc[lambda x: x['stars']>=4, 'year'].sort_values().unique()"
"in what years did a movie receive a 4 or 5 star rating, and list the years from oldest to most recently?","pd.merge(movie, rating, on='mid').loc[lambda x: x['stars']>=4, 'year'].sort_values().unique()"
what are the names of directors who directed movies with 5 star rating? also return the title of these movies.,"pd.merge(movie, rating, on='mid').loc[lambda x: x['stars']==5, ['director', 'title']]"
"what are the names of the directors who created a movie with a 5 star rating, and what was the name of those movies?","pd.merge(movie, rating, on='mid').loc[lambda x: x['stars']==5, ['director', 'title']]"
what is the average rating star for each reviewer?,"pd.merge(rating, reviewer, on='rid').groupby('name')['stars'].mean()"
what is the average number of stars that each reviewer awards for a movie?,"pd.merge(rating, reviewer, on='rid').groupby('name')['stars'].mean()"
find the titles of all movies that have no ratings.,"movie.loc[~movie['mid'].isin(rating['mid']), 'title']"
what are the titles of all movies that have not been rated?,"movie.loc[~movie['mid'].isin(rating['mid']), 'title']"
find the names of all reviewers who have ratings with a null value for the date.,"pd.merge(reviewer, rating, on='rid').loc[lambda x: x['ratingdate']=='null', 'name'].unique()"
what are the different names of all reviewers whose ratings do not have a date field?,"pd.merge(reviewer, rating, on='rid').loc[lambda x: x['ratingdate']=='null', 'name'].unique()"
what is the average rating stars and title for the oldest movie?,"rating.merge(movie.query('year == @movie.year.min()'), on='mid').groupby('title')['stars'].mean()"
"for the oldest movie listed, what is its average rating and title?","rating.merge(movie.query('year == @movie.year.min()'), on='mid').groupby('title')['stars'].mean()"
what is the name of the most recent movie?,"movie.loc[movie['year'] == movie['year'].max(), 'title']"
what is the title of the newest movie?,"movie.loc[movie['year'] == movie['year'].max(), 'title']"
what is the maximum stars and year for the most recent movie?,"rating.merge(movie.query('year == @movie.year.max()'), on='mid').agg({'stars': 'max', 'year': 'first'})"
what is highest rating for the most recent movie and when was it released?,"rating.merge(movie.query('year == @movie.year.max()'), on='mid').agg({'stars': 'max', 'year': 'first'})"
what is the names of movies whose created year is after all movies directed by steven spielberg?,"movie.loc[lambda x: x['year'] > movie.loc[lambda y: y['director'] == 'steven spielberg', 'year'].max(), 'title']"
what are the names of all movies that were created after the most recent steven spielberg film?,"movie.loc[lambda x: x['year'] > movie.loc[lambda y: y['director'] == 'steven spielberg', 'year'].max(), 'title']"
what are the titles and directors of the movies whose star is greater than the average stars of the movies directed by james cameron?,"movie.merge(rating, on='mid').loc[lambda x: x['stars']>x.merge(movie, on='mid').loc[lambda y: y['director']=='james cameron','stars'].mean(), ['title','director']].drop_duplicates().reset_index(drop=true)"
what are the titles and directors of all movies that have a rating higher than the average james cameron film rating?,"movie.merge(rating, on='mid').loc[lambda x: x['stars']>x.merge(movie, on='mid').loc[lambda y: y['director']=='james cameron','stars'].mean(), ['title','director']].drop_duplicates().reset_index(drop=true)"
"return reviewer name, movie title, stars, and ratingdate. and sort the data first by reviewer name, then by movie title, and lastly by number of stars.","pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').sort_values(['name', 'title', 'stars'])[['name', 'title', 'stars', 'ratingdate']]"
"what is the reviewer name, film title, movie rating, and rating date  for every movie ordered by reviewer name, movie title, then finally rating?","pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').sort_values(['name', 'title', 'stars'])[['name', 'title', 'stars', 'ratingdate']]"
find the names of all reviewers who have contributed three or more ratings.,"pd.merge(rating, reviewer, on='rid').groupby('rid').filter(lambda x: len(x) >= 3)['name']"
what are the names of all reviewers that have rated 3 or more movies?,"pd.merge(rating, reviewer, on='rid').groupby('rid').filter(lambda x: len(x) >= 3)['name']"
find the names of all reviewers who rated gone with the wind.,"pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: x['title']=='gone with the wind', 'name'].unique()"
what are the names of all the different reviewers who rates gone with the wind?,"pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: x['title']=='gone with the wind', 'name'].unique()"
find the names of all directors whose movies are rated by sarah martinez.,"pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: x['name']=='sarah martinez', 'director'].unique()"
what are the names of all directors whose movies have been reviewed by sarah martinez?,"pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: x['name']=='sarah martinez', 'director'].unique()"
"for any rating where the name of reviewer is the same as the director of the movie, return the reviewer name, movie title, and number of stars.","pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: x['director']==x['name'], ['name', 'title', 'stars']].drop_duplicates()"
"what are the different reviewer names, movie titles, and stars for every rating where the reviewer had the same name as the director?","pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: x['director']==x['name'], ['name', 'title', 'stars']].drop_duplicates()"
return all reviewer names and movie names together in a single list.,"pd.concat([reviewer['name'], movie['title']]).reset_index(drop=true)"
what are the names of all the reviewers and movie names?,"pd.concat([reviewer['name'], movie['title']]).reset_index(drop=true)"
find the titles of all movies not reviewed by chris jackson.,"movie['title'].unique().tolist() - pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: x['name']=='chris jackson', 'title'].tolist()"
what are the titles of all movies that were not reviewed by chris jackson?,"movie['title'].unique().tolist() - pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: x['name']=='chris jackson', 'title'].tolist()"
"for all directors who directed more than one movie, return the titles of all movies directed by them, along with the director name. sort by director name, then movie title.","movie.merge(movie, on='director').loc[lambda x: x['title_x'] != x['title_y'], ['title_x', 'director']].rename(columns={'title_x': 'title'}).sort_values(['director', 'title'])"
"for all directors who have directed more than one movie, what movies have they directed and what are their names?","movie.merge(movie, on='director').loc[lambda x: x['title_x'] != x['title_y'], ['title_x', 'director']].rename(columns={'title_x': 'title'}).sort_values(['director', 'title'])"
"for directors who had more than one movie, return the titles and produced years of all movies directed by them.","movie.merge(movie, on='director', suffixes=('_1', '_2')).loc[lambda x: x['title_1'] != x['title_2'], ['title_1', 'year_1']]"
"for each director who directed more than one movie, what are the titles and dates of release for all those movies?","movie.merge(movie, on='director', suffixes=('_1', '_2')).loc[lambda x: x['title_1'] != x['title_2'], ['title_1', 'year_1']]"
what are the names of the directors who made exactly one movie?,movie.groupby('director').filter(lambda x: len(x)==1)['director'].unique()
what are the names of all directors who made one movie?,movie.groupby('director').filter(lambda x: len(x)==1)['director'].unique()
what are the names of the directors who made exactly one movie excluding director null?,movie[movie['director'].notnull()].groupby('director').filter(lambda x: len(x)==1)['director']
what are the names of all directors who have made one movie except for the director named null?,movie[movie['director'].notnull()].groupby('director').filter(lambda x: len(x)==1)['director']
how many movie reviews does each director get?,"pd.merge(movie, rating, on='mid').groupby('director').size().reset_index(name='count')"
"for each director, how many reviews have they received?","pd.merge(movie, rating, on='mid').groupby('director').size().reset_index(name='count')"
find the movies with the highest average rating. return the movie titles and average rating.,"pd.merge(rating, movie, on='mid').groupby('mid').agg({'title': 'first', 'stars': 'mean'}).sort_values('stars', ascending=false).iloc[0]"
what are the movie titles with the highest average rating and what are those ratings?,"pd.merge(rating, movie, on='mid').groupby('mid').agg({'title': 'first', 'stars': 'mean'}).sort_values('stars', ascending=false).iloc[0]"
what are the movie titles and average rating of the movies with the lowest average rating?,"pd.merge(rating, movie, on='mid').groupby('mid').agg(avg_stars=('stars', 'mean'), title=('title', 'first')).sort_values('avg_stars').head(1)[['title', 'avg_stars']]"
what are the titles and average ratings for all movies that have the lowest average rating?,"pd.merge(rating, movie, on='mid').groupby('mid').agg(avg_stars=('stars', 'mean'), title=('title', 'first')).sort_values('avg_stars').head(1)[['title', 'avg_stars']]"
what are the names and years of the movies that has the top 3 highest rating star?,"rating.merge(movie, on='mid')[['title', 'year', 'stars']].sort_values('stars', ascending=false).head(3)[['title', 'year']]"
what are the names and years released for the movies with the top 3 highest ratings?,"rating.merge(movie, on='mid')[['title', 'year', 'stars']].sort_values('stars', ascending=false).head(3)[['title', 'year']]"
"for each director, what are the titles and ratings for all the movies they reviewed?","rating.merge(movie[movie['director']!='null'], on='mid').groupby('director').agg({'title':'first', 'stars':'max'}).reset_index()[['title', 'stars', 'director']]"
find the title and star rating of the movie that got the least rating star for each reviewer.,"rating.merge(movie, on='mid').groupby('rid').agg({'title': 'first', 'stars': ['first', 'min']}).droplevel(level=0, axis=1).rename(columns={'first': 'stars', 'min': 'min_stars'})"
"for each reviewer id, what is the title and rating for the movie with the smallest rating?","rating.merge(movie, on='mid').groupby('rid').agg({'title': 'first', 'stars': ['first', 'min']}).droplevel(level=0, axis=1).rename(columns={'first': 'stars', 'min': 'min_stars'})"
find the title and score of the movie with the lowest rating among all movies directed by each director.,"pd.merge(rating, movie, on='mid').groupby('director').agg({'title':'first', 'stars':'min'}).reset_index()[['title', 'stars', 'director']]"
"for each director, what is the title and score of their most poorly rated movie?","pd.merge(rating, movie, on='mid').groupby('director').agg({'title':'first', 'stars':'min'}).reset_index()[['title', 'stars', 'director']]"
what is the name of the movie that is rated by most of times?,"movie.merge(rating).groupby(['mid', 'title'])['rating'].count().reset_index().sort_values('rating', ascending=false).iloc[0][['title', 'mid']]"
what is the name of the movie that has been reviewed the most?,"movie.merge(rating).groupby(['mid', 'title'])['rating'].count().reset_index().sort_values('rating', ascending=false).iloc[0][['title', 'mid']]"
what are the titles of all movies that have rating star is between 3 and 5?,"pd.merge(rating, movie, on='mid').loc[lambda x: x['stars'].between(3, 5), 'title']"
what are the titles of all movies that have between 3 and 5 stars?,"pd.merge(rating, movie, on='mid').loc[lambda x: x['stars'].between(3, 5), 'title']"
find the names of reviewers who had given higher than 3 star ratings.,"pd.merge(rating, reviewer, on='rid').loc[lambda x: x['stars'] > 3, 'name']"
what are the names of the reviewers who have rated a movie more than 3 stars before?,"pd.merge(rating, reviewer, on='rid').loc[lambda x: x['stars'] > 3, 'name']"
find the average rating star for each movie that are not reviewed by brittany harris.,"rating[~rating['mid'].isin(rating.merge(reviewer[reviewer['name']=='brittany harris'], on='rid', how='inner')['mid'])].groupby('mid')['stars'].mean()"
what is the average rating for each movie that has never been reviewed by brittany harris?,"rating[~rating['mid'].isin(rating.merge(reviewer[reviewer['name']=='brittany harris'], on='rid', how='inner')['mid'])].groupby('mid')['stars'].mean()"
what are the ids of the movies that are not reviewed by brittany harris.,"rating[~rating['rid'].isin(pd.merge(rating, reviewer.loc[reviewer['name'] == 'brittany harris'], on='rid')['mid'])]['mid']"
what are the ids of all moviest hat have not been reviewed by britanny harris?,"rating[~rating['rid'].isin(pd.merge(rating, reviewer.loc[reviewer['name'] == 'brittany harris'], on='rid')['mid'])]['mid']"
find the average rating star for each movie that received at least 2 ratings.,rating.groupby('mid')['stars'].filter(lambda x: len(x)>=2).groupby('mid').mean()
"for each movie that received more than 3 reviews, what is the average rating?",rating.groupby('mid')['stars'].filter(lambda x: len(x)>=2).groupby('mid').mean()
find the ids of reviewers who did not give 4 star.,"rating.loc[lambda x: x['stars'] != 4, 'rid']"
what are the ids of all reviewers who did not give 4 stars?,"rating.loc[lambda x: x['stars'] != 4, 'rid']"
find the ids of reviewers who didn't only give 4 star.,"rating.loc[lambda x: x['stars'] != 4, 'rid']"
what are the ids of all reviewers who have not given 4 stars at least once?,"rating.loc[lambda x: x['stars'] != 4, 'rid']"
what are names of the movies that are either made after 2000 or reviewed by brittany harris?,"pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: (x['name']=='brittany harris') | (x['year']>2000), 'title'].unique()"
what are the names of all movies that were made after 2000 or reviewed by brittany harris?,"pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: (x['name']=='brittany harris') | (x['year']>2000), 'title'].unique()"
what are names of the movies that are either made before 1980 or directed by james cameron?,"movie.loc[(movie['director'] == 'james cameron') | (movie['year'] < 1980), 'title']"
what are the names of all movies made before 1980 or had james cameron as the director?,"movie.loc[(movie['director'] == 'james cameron') | (movie['year'] < 1980), 'title']"
what are the names of reviewers who had rated 3 star and 4 star?,"pd.merge(rating.loc[lambda x: x['stars'] == 3, ['rid']], reviewer, on='rid')['name'].intersect(pd.merge(rating.loc[lambda x: x['stars'] == 4, ['rid']], reviewer, on='rid')['name'])"
what are the names of all reviewers that have given 3 or 4 stars for reviews?,"pd.merge(rating.loc[lambda x: x['stars'] == 3, ['rid']], reviewer, on='rid')['name'].intersect(pd.merge(rating.loc[lambda x: x['stars'] == 4, ['rid']], reviewer, on='rid')['name'])"
what are the names of movies that get 3 star and 4 star?,"pd.merge(rating.loc[lambda x: x['stars']==3], movie,on='mid', suffixes=['_rating', '_movie'])['title'].pipe(lambda x: x[np.in1d(x, pd.merge(rating.loc[lambda x: x['stars']==4], movie,on='mid', suffixes=['_rating', '_movie'])['title'].unique())])"
what are the names of all movies that received 3 or 4 stars?,"pd.merge(rating.loc[lambda x: x['stars']==3], movie,on='mid', suffixes=['_rating', '_movie'])['title'].pipe(lambda x: x[np.in1d(x, pd.merge(rating.loc[lambda x: x['stars']==4], movie,on='mid', suffixes=['_rating', '_movie'])['title'].unique())])"
how many counties are there?,county_public_safety.shape[0]
list the names of counties in descending order of population.,"county_public_safety.sort_values('population', ascending=false)['name']"
"what are the names of the counties of public safety, ordered by population descending?","county_public_safety.sort_values('population', ascending=false)['name']"
list the distinct police forces of counties whose location is not on east side.,"county_public_safety.loc[lambda x: x['location'] != 'east', 'police_force'].unique()"
what are the different police forces of counties that are not located in the east?,"county_public_safety.loc[lambda x: x['location'] != 'east', 'police_force'].unique()"
what are the minimum and maximum crime rate of counties?,"county_public_safety['crime_rate'].agg(['min', 'max'])"
return the minimum and maximum crime rates across all counties.,"county_public_safety['crime_rate'].agg(['min', 'max'])"
show the crime rates of counties in ascending order of number of police officers.,county_public_safety.sort_values('police_officers')['crime_rate']
what are the crime rates of counties sorted by number of offices ascending?,county_public_safety.sort_values('police_officers')['crime_rate']
what are the names of cities in ascending alphabetical order?,city.sort_values('name')['name']
"return the names of cities, ordered alphabetically.",city.sort_values('name')['name']
what are the percentage of hispanics in cities with the black percentage higher than 10?,"city.loc[lambda x: x['black'] > 10, 'hispanic']"
return the hispanic percentage for cities in which the black percentage is greater than 10.,"city.loc[lambda x: x['black'] > 10, 'hispanic']"
list the name of the county with the largest population.,"county_public_safety.sort_values('population', ascending=false).iloc[0]['name']"
what is the name of the county with the greatest population?,"county_public_safety.sort_values('population', ascending=false).iloc[0]['name']"
list the names of the city with the top 5 white percentages.,"city.sort_values('white', ascending=false)['name'].head(5)"
what are the names of the five cities with the greatest proportion of white people?,"city.sort_values('white', ascending=false)['name'].head(5)"
show names of cities and names of counties they are in.,"pd.merge(city[['name', 'county_id']], county_public_safety[['name', 'county_id']], on='county_id')"
"what are the names of cities, as well as the names of the counties they correspond to?","pd.merge(city[['name', 'county_id']], county_public_safety[['name', 'county_id']], on='county_id')"
show white percentages of cities and the crime rates of counties they are in.,"pd.merge(city, county_public_safety, on='county_id')[['white', 'crime_rate']]"
"what are the white percentages of cities, and the corresponding crime rates of the counties they correspond to?","pd.merge(city, county_public_safety, on='county_id')[['white', 'crime_rate']]"
show the name of cities in the county that has the largest number of police officers.,"city.loc[lambda x: x['county_id'] == county_public_safety.sort_values('police_officers', ascending=false)['county_id'].iloc[0], 'name']"
what are the names of cities that are in the county with the most police officers?,"city.loc[lambda x: x['county_id'] == county_public_safety.sort_values('police_officers', ascending=false)['county_id'].iloc[0], 'name']"
show the number of cities in counties that have a population more than 20000.,"city.loc[city['county_id'].isin(county_public_safety.loc[lambda x: x['population'] > 20000, 'county_id']), :].shape[0]"
how many cities are in counties that have populations of over 20000?,"city.loc[city['county_id'].isin(county_public_safety.loc[lambda x: x['population'] > 20000, 'county_id']), :].shape[0]"
show the crime rate of counties with a city having white percentage more than 90.,"pd.merge(city, county_public_safety, on='county_id').loc[lambda x: x['white'] > 90, 'crime_rate']"
what are the crime rates of counties that contain cities that have white percentages of over 90?,"pd.merge(city, county_public_safety, on='county_id').loc[lambda x: x['white'] > 90, 'crime_rate']"
please show the police forces and the number of counties with each police force.,county_public_safety.groupby('police_force').size()
how many counties correspond to each police force?,county_public_safety.groupby('police_force').size()
what is the location shared by most counties?,county_public_safety.groupby('location').size().sort_values(ascending=false).index[0]
which location has the most corresponding counties?,county_public_safety.groupby('location').size().sort_values(ascending=false).index[0]
list the names of counties that do not have any cities.,"county_public_safety.loc[~county_public_safety['county_id'].isin(city['county_id']), 'name']"
what are the names of counties that do not contain any cities?,"county_public_safety.loc[~county_public_safety['county_id'].isin(city['county_id']), 'name']"
show the police force shared by counties with location on the east and west.,"set(county_public_safety.loc[lambda x: x['location']=='east', 'police_force']).intersection(set(county_public_safety.loc[lambda x: x['location']=='west', 'police_force']))"
which police forces operate in both counties that are located in the east and in the west?,"set(county_public_safety.loc[lambda x: x['location']=='east', 'police_force']).intersection(set(county_public_safety.loc[lambda x: x['location']=='west', 'police_force']))"
show the names of cities in counties that have a crime rate less than 100.,"city.loc[city['county_id'].isin(county_public_safety.loc[county_public_safety['crime_rate'] < 100, 'county_id']), 'name']"
what are the names of cities that are in counties that have a crime rate below 100?,"city.loc[city['county_id'].isin(county_public_safety.loc[county_public_safety['crime_rate'] < 100, 'county_id']), 'name']"
show the case burden of counties in descending order of population.,"county_public_safety.sort_values('population', ascending=false)['case_burden']"
"what are the case burdens of counties, ordered descending by population?","county_public_safety.sort_values('population', ascending=false)['case_burden']"
find the names of all modern rooms with a base price below $160 and two beds.,"rooms.loc[(rooms['baseprice'] < 160) & (rooms['beds'] == 2) & (rooms['decor'] == 'modern'), 'roomname']"
what are the names of modern rooms that have a base price lower than $160 and two beds.,"rooms.loc[(rooms['baseprice'] < 160) & (rooms['beds'] == 2) & (rooms['decor'] == 'modern'), 'roomname']"
find all the rooms that have a price higher than 160 and can accommodate more than 2 people. report room names and ids.,"rooms.loc[(rooms['baseprice'] > 160) & (rooms['maxoccupancy'] > 2), ['roomname', 'roomid']]"
what are the room names and ids of all the rooms that cost more than 160 and can accommodate more than two people.,"rooms.loc[(rooms['baseprice'] > 160) & (rooms['maxoccupancy'] > 2), ['roomname', 'roomid']]"
find the most popular room in the hotel. the most popular room is the room that had seen the largest number of reservations.,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').groupby('roomname').size().nlargest(1).index[0]"
which room has the largest number of reservations?,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').groupby('roomname').size().nlargest(1).index[0]"
how many kids stay in the rooms reserved by roy sweazy?,"reservations.loc[(reservations['firstname']=='roy') & (reservations['lastname']=='sweazy'), 'kids']"
find the number of kids staying in the rooms reserved by a person called roy sweaz.,"reservations.loc[(reservations['firstname']=='roy') & (reservations['lastname']=='sweazy'), 'kids']"
how many times does roy sweazy has reserved a room.,((reservations['firstname']=='roy') & (reservations['lastname']=='sweazy')).sum()
find the number of times roy sweazy has reserved a room.,((reservations['firstname']=='roy') & (reservations['lastname']=='sweazy')).sum()
"which room has the highest rate? list the room's full name, rate, check in and check out date.","reservations.merge(rooms, left_on='room', right_on='roomid').groupby('room')[['rate', 'checkin', 'checkout', 'roomname']].max().sort_values('rate', ascending=false).iloc[0]"
"return the name, rate, check in and check out date for the room with the highest rate.","reservations.merge(rooms, left_on='room', right_on='roomid').groupby('room')[['rate', 'checkin', 'checkout', 'roomname']].max().sort_values('rate', ascending=false).iloc[0]"
"how many adults stay in the room conrad selbig checked in on oct 23, 2010?","reservations.loc[(reservations['checkin'] == '2010-10-23') & (reservations['firstname'] == 'conrad') & (reservations['lastname'] == 'selbig'), 'adults']"
"find the number of adults for the room reserved and checked in by conrad selbig on oct 23, 2010.","reservations.loc[(reservations['checkin'] == '2010-10-23') & (reservations['firstname'] == 'conrad') & (reservations['lastname'] == 'selbig'), 'adults']"
"how many kids stay in the room damien trachsel checked in on sep 21, 2010?","reservations.loc[(reservations['checkin']=='2010-09-21')&(reservations['firstname']=='damien')&(reservations['lastname']=='trachsel'), 'kids']"
"return the number of kids for the room reserved and checked in by damien trachsel on  sep 21, 2010.","reservations.loc[(reservations['checkin']=='2010-09-21')&(reservations['firstname']=='damien')&(reservations['lastname']=='trachsel'), 'kids']"
how many king beds are there?,"rooms.loc[lambda x: x['bedtype']=='king', 'beds'].sum()"
find the total number of king beds available.,"rooms.loc[lambda x: x['bedtype']=='king', 'beds'].sum()"
list the names and decor of rooms that have a king bed. sort the list by their price.,"rooms.loc[lambda x: x['bedtype']=='king'].sort_values('baseprice')[['roomname', 'decor']]"
what are the names and decor of rooms with a king bed? sort them by their price,"rooms.loc[lambda x: x['bedtype']=='king'].sort_values('baseprice')[['roomname', 'decor']]"
which room has cheapest base price? list the room's name and the base price.,"rooms[['roomname', 'baseprice']].sort_values('baseprice').iloc[0]"
what are the room name and base price of the room with the lowest base price?,"rooms[['roomname', 'baseprice']].sort_values('baseprice').iloc[0]"
what is the decor of room recluse and defiance?,"rooms.loc[lambda x: x['roomname']=='recluse and defiance', 'decor']"
"return the decor of the room named ""recluse and defiance"".","rooms.loc[lambda x: x['roomname']=='recluse and defiance', 'decor']"
what is the average base price of different bed type? list bed type and average base price.,rooms.groupby('bedtype')['baseprice'].mean()
"for each bed type, find the average base price of different bed type.",rooms.groupby('bedtype')['baseprice'].mean()
what is the total number of people who could stay in the modern rooms in this inn?,"rooms.loc[lambda x: x['decor']=='modern', 'maxoccupancy'].sum()"
how many people in total can stay in the modern rooms of this inn?,"rooms.loc[lambda x: x['decor']=='modern', 'maxoccupancy'].sum()"
what kind of decor has the least number of reservations?,"reservations.merge(rooms, left_on='room', right_on='roomid').groupby('decor')['decor'].count().sort_values().head(1).index[0]"
what is the least popular kind of decor?,"reservations.merge(rooms, left_on='room', right_on='roomid').groupby('decor')['decor'].count().sort_values().head(1).index[0]"
list how many times the number of people in the room reached the maximum occupancy of the room. the number of people include adults and kids.,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').eval(""maxoccupancy == adults + kids"").sum()"
how many times the number of adults and kids staying in a room reached the maximum capacity of the room?,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').eval(""maxoccupancy == adults + kids"").sum()"
find the first and last names of people who payed more than the rooms' base prices.,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').loc[lambda x: x['rate']-x['baseprice']>0, ['firstname', 'lastname']]"
what are the first and last names of people who payed more than the rooms' base prices?,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').loc[lambda x: x['rate']-x['baseprice']>0, ['firstname', 'lastname']]"
how many rooms are there?,rooms.shape[0]
what is the total number of rooms available in this inn?,rooms.shape[0]
find the number of rooms with a king bed.,sum(rooms['bedtype'] == 'king')
how many rooms have a king bed?,sum(rooms['bedtype'] == 'king')
find the number of rooms for each bed type.,rooms.groupby('bedtype').size()
what are the number of rooms for each bed type?,rooms.groupby('bedtype').size()
find the name of the room with the maximum occupancy.,"rooms.loc[rooms['maxoccupancy'].idxmax(), 'roomname']"
what is the name of the room that can accommodate the most people?,"rooms.loc[rooms['maxoccupancy'].idxmax(), 'roomname']"
find the id and name of the most expensive base price room.,"rooms[['roomid', 'roomname']].sort_values('baseprice', ascending=false).head(1)"
which room has the highest base price?,"rooms[['roomid', 'roomname']].sort_values('baseprice', ascending=false).head(1)"
list the type of bed and name of all traditional rooms.,"rooms.loc[lambda x: x['decor']=='traditional', ['roomname', 'bedtype']]"
what are the bed type and name of all the rooms with traditional decor?,"rooms.loc[lambda x: x['decor']=='traditional', ['roomname', 'bedtype']]"
find the number of rooms with king bed for each decor type.,rooms[rooms['bedtype']=='king'].groupby('decor').size()
how many rooms have king beds? report the number for each decor type.,rooms[rooms['bedtype']=='king'].groupby('decor').size()
find the average and minimum price of the rooms in different decor.,"rooms.groupby('decor')['baseprice'].agg(['mean','min']).reset_index()"
what is the average minimum and price of the rooms for each different decor.,"rooms.groupby('decor')['baseprice'].agg(['mean','min']).reset_index()"
list the name of all rooms sorted by their prices.,rooms.sort_values('baseprice')['roomname']
sort all the rooms according to the price. just report the room names.,rooms.sort_values('baseprice')['roomname']
find the number of rooms with price higher than 120 for different decor.,rooms.loc[lambda x: x['baseprice'] > 120].groupby('decor').size()
"how many rooms cost more than 120, for each different decor?",rooms.loc[lambda x: x['baseprice'] > 120].groupby('decor').size()
"for each bed type, find the average room price.",rooms.groupby('bedtype')['baseprice'].mean()
"what is the average base price of rooms, for each bed type?",rooms.groupby('bedtype')['baseprice'].mean()
list the name of rooms with king or queen bed.,"rooms.loc[lambda x: x['bedtype'].isin(['king', 'queen']), 'roomname']"
what are the names of rooms that have either king or queen bed?,"rooms.loc[lambda x: x['bedtype'].isin(['king', 'queen']), 'roomname']"
how many different types of beds are there?,rooms['bedtype'].nunique()
find the number of distinct bed types available in this inn.,rooms['bedtype'].nunique()
find the name and id of the top 3 expensive rooms.,"rooms[['roomid', 'roomname']].sort_values('baseprice', ascending=false).head(3)"
what are the name and id of the three highest priced rooms?,"rooms[['roomid', 'roomname']].sort_values('baseprice', ascending=false).head(3)"
find the name of rooms whose price is higher than the average price.,"rooms.loc[lambda x: x['baseprice'] > x['baseprice'].mean(), 'roomname']"
what are the name of rooms that cost more than the average.,"rooms.loc[lambda x: x['baseprice'] > x['baseprice'].mean(), 'roomname']"
find the number of rooms that do not have any reservation.,rooms.loc[~rooms['roomid'].isin(reservations['room'].unique())].shape[0]
how many rooms have not had any reservation yet?,rooms.loc[~rooms['roomid'].isin(reservations['room'].unique())].shape[0]
return the name and number of reservations made for each of the rooms.,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').groupby('room')[['roomname', 'room']].agg({'roomname': 'first', 'room': 'count'}).reset_index()[['roomname', 'room', 'count']]"
"for each room, find its name and the number of times reservations were made for it.","pd.merge(reservations, rooms, left_on='room', right_on='roomid').groupby('room')[['roomname', 'room']].agg({'roomname': 'first', 'room': 'count'}).reset_index()[['roomname', 'room', 'count']]"
find the names of rooms that have been reserved for more than 60 times.,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').groupby('room').filter(lambda x: len(x) > 60)['roomname'].unique()"
what are the names of rooms whose reservation frequency exceeds 60 times?,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').groupby('room').filter(lambda x: len(x) > 60)['roomname'].unique()"
find the name of rooms whose base price is between 120 and 150.,"rooms.loc[lambda x: (x['baseprice'] >= 120) & (x['baseprice'] <= 150), 'roomname']"
which rooms cost between 120 and 150? give me the room names.,"rooms.loc[lambda x: (x['baseprice'] >= 120) & (x['baseprice'] <= 150), 'roomname']"
find the name of rooms booked by some customers whose first name contains roy.,rooms[rooms['roomid'].isin(reservations[reservations['firstname'].str.contains('roy')]['room'])]['roomname']
"what are the name of rooms booked by customers whose first name has ""roy"" in part?",rooms[rooms['roomid'].isin(reservations[reservations['firstname'].str.contains('roy')]['room'])]['roomname']
what are the details of the cmi masters that have the cross reference code 'tax'?,"pd.merge(customer_master_index, cmi_cross_references.loc[lambda x: x['source_system_code']=='tax'], on='master_customer_id')['cmi_details']"
what is the cmi cross reference id that is related to at least one council tax entry? list the cross reference id and source system code.,"pd.merge(cmi_cross_references, council_tax, on='cmi_cross_ref_id').groupby('cmi_cross_ref_id').filter(lambda x: len(x) >= 1)[['cmi_cross_ref_id', 'source_system_code']]"
"how many business rates are related to each cmi cross reference? list cross reference id, master customer id and the n","business_rates.merge(cmi_cross_references, on='cmi_cross_ref_id').groupby('cmi_cross_ref_id').agg(count=('cmi_cross_ref_id', 'count'), master_customer_id=('master_customer_id', 'first'))[['master_customer_id', 'count']]"
"what is the tax source system code related to the benefits and overpayments? list the code and the benifit id, order by benifit id.","pd.merge(cmi_cross_references, benefits_overpayments, on='cmi_cross_ref_id').sort_values('council_tax_id')[['source_system_code', 'council_tax_id']]"
wat is the tax source system code and master customer id of the taxes related to each parking fine id?,"pd.merge(cmi_cross_references, parking_fines, on='cmi_cross_ref_id')[['source_system_code', 'master_customer_id', 'council_tax_id']]"
"what are the renting arrears tax ids related to the customer master index whose detail is not 'schmidt, kertzmann and lubowitz'?","rent_arrears.merge(cmi_cross_references, on='cmi_cross_ref_id').merge(customer_master_index, on='master_customer_id').loc[lambda x: x['cmi_details']!=""schmidt ,kertzmann and lubowitz"", 'council_tax_id']"
what are the register ids of electoral registries that have the cross reference source system code 'electoral' or 'tax'?,"pd.merge(electoral_register, cmi_cross_references.loc[cmi_cross_references['source_system_code'].isin(['electoral', 'tax'])], on='cmi_cross_ref_id')['electoral_register_id']"
how many different source system code for the cmi cross references are there?,cmi_cross_references['source_system_code'].nunique()
"list all information about customer master index, and sort them by details in descending order.","customer_master_index.sort_values('cmi_details', ascending=false)"
list the council tax ids and their related cmi cross references of all the parking fines.,"parking_fines[['council_tax_id', 'cmi_cross_ref_id']]"
how many council taxes are collected for renting arrears ?,rent_arrears.shape[0]
"what are the distinct cross reference source system codes which are related to the master customer details 'gottlieb, becker and wyman'?","pd.merge(customer_master_index[['master_customer_id', 'cmi_details']],cmi_cross_references['source_system_code'],on='master_customer_id').loc[lambda x: x['cmi_details']=='gottlieb ,becker and wyman', 'source_system_code'].unique()"
which cmi cross reference id is not related to any parking taxes?,"pd.concat([cmi_cross_references['cmi_cross_ref_id'], parking_fines['cmi_cross_ref_id']]).drop_duplicates(keep=false)"
which distinct source system code includes the substring 'en'?,"cmi_cross_references.loc[lambda x: x['source_system_code'].str.contains('en'), 'source_system_code'].unique()"
how many parties are there?,party.shape[0]
count the number of parties.,party.shape[0]
list the themes of parties in ascending order of number of hosts.,party.sort_values('number_of_hosts')['party_theme']
what are the themes of parties ordered by the number of hosts in ascending manner?,party.sort_values('number_of_hosts')['party_theme']
what are the themes and locations of parties?,"party[['party_theme', 'location']]"
give me the theme and location of each party.,"party[['party_theme', 'location']]"
"show the first year and last year of parties with theme ""spring"" or ""teqnology"".","party.loc[party['party_theme'].isin(['spring', 'technology']), ['first_year', 'last_year']]"
"what are the first year and last year of the parties whose theme is ""spring"" or ""teqnology""?","party.loc[party['party_theme'].isin(['spring', 'technology']), ['first_year', 'last_year']]"
what is the average number of hosts for parties?,party['number_of_hosts'].mean()
compute the average number of hosts for parties.,party['number_of_hosts'].mean()
what is the location of the party with the most hosts?,"party.sort_values('number_of_hosts', ascending=false).iloc[0]['location']"
which party had the most hosts? give me the party location.,"party.sort_values('number_of_hosts', ascending=false).iloc[0]['location']"
show different nationalities along with the number of hosts of each nationality.,host.groupby('nationality').size().reset_index(name='count')
how many hosts does each nationality have? list the nationality and the count.,host.groupby('nationality').size().reset_index(name='count')
show the most common nationality of hosts.,host.groupby('nationality').size().sort_values(ascending=false).head(1).index[0]
which nationality has the most hosts?,host.groupby('nationality').size().sort_values(ascending=false).head(1).index[0]
show the nations that have both hosts older than 45 and hosts younger than 35.,"set(host.loc[lambda x: x['age']>45, 'nationality']).intersection(set(host.loc[lambda x: x['age']<35, 'nationality']))"
which nations have both hosts of age above 45 and hosts of age below 35?,"set(host.loc[lambda x: x['age']>45, 'nationality']).intersection(set(host.loc[lambda x: x['age']<35, 'nationality']))"
show the themes of parties and the names of the party hosts.,"pd.merge(pd.merge(party_host, host, on='host_id'), party, on='party_id')[['party_theme', 'name']]"
"for each party, return its theme and the name of its host.","pd.merge(pd.merge(party_host, host, on='host_id'), party, on='party_id')[['party_theme', 'name']]"
show the locations of parties and the names of the party hosts in ascending order of the age of the host.,"pd.merge(pd.merge(party_host, host, on='host_id'), party,on='party_id').sort_values('age')[['location', 'name']]"
"for each party, find its location and the name of its host. sort the result in ascending order of the age of the host.","pd.merge(pd.merge(party_host, host, on='host_id'), party,on='party_id').sort_values('age')[['location', 'name']]"
show the locations of parties with hosts older than 50.,"pd.merge(pd.merge(party_host, host, on='host_id'), party, on='party_id').loc[lambda x: x['age'] > 50, 'location']"
which parties have hosts of age above 50? give me the party locations.,"pd.merge(pd.merge(party_host, host, on='host_id'), party, on='party_id').loc[lambda x: x['age'] > 50, 'location']"
show the host names for parties with number of hosts greater than 20.,"pd.merge(pd.merge(party_host, host, on='host_id'), party, on='party_id').loc[lambda x: x['number_of_hosts']>20, 'name_y']"
which parties have more than 20 hosts? give me the host names for these parties.,"pd.merge(pd.merge(party_host, host, on='host_id'), party, on='party_id').loc[lambda x: x['number_of_hosts']>20, 'name_y']"
show the name and the nationality of the oldest host.,"host[['name', 'nationality']].sort_values('age', ascending=false).iloc[0]"
what are the name and the nationality of the host of the highest age?,"host[['name', 'nationality']].sort_values('age', ascending=false).iloc[0]"
list the names of hosts who did not serve as a host of any party in our record.,"host.loc[~host['host_id'].isin(party_host['host_id']), 'name']"
what are the names of hosts who did not host any party in our record?,"host.loc[~host['host_id'].isin(party_host['host_id']), 'name']"
show all region code and region name sorted by the codes.,"region[['region_code', 'region_name']].sort_values('region_code')"
"what are the codes and names for all regions, sorted by codes?","region[['region_code', 'region_name']].sort_values('region_code')"
list all region names in alphabetical order.,region.sort_values('region_name')['region_name']
what are the names of the regions in alphabetical order?,region.sort_values('region_name')['region_name']
show names for all regions except for denmark.,"region.loc[lambda x: x['region_name'] != 'denmark', 'region_name']"
return the names of all regions other than denmark.,"region.loc[lambda x: x['region_name'] != 'denmark', 'region_name']"
how many storms had death records?,(storm['number_deaths'] > 0).sum()
count the number of storms in which at least 1 person died.,(storm['number_deaths'] > 0).sum()
"list name, dates active, and number of deaths for all storms with at least 1 death.","storm.loc[lambda x: x['number_deaths'] >= 1, ['name', 'dates_active', 'number_deaths']]"
"what are the names, dates active, and number of deaths for storms that had 1 or more death?","storm.loc[lambda x: x['number_deaths'] >= 1, ['name', 'dates_active', 'number_deaths']]"
show the average and maximum damage for all storms with max speed higher than 1000.,"storm.loc[lambda x: x['max_speed']>1000, 'damage_millions_usd'].agg(['mean', 'max'])"
what is the average and maximum damage in millions for storms that had a max speed over 1000?,"storm.loc[lambda x: x['max_speed']>1000, 'damage_millions_usd'].agg(['mean', 'max'])"
what is the total number of deaths and damage for all storms with a max speed greater than the average?,"storm.loc[lambda x: x['max_speed'] > x['max_speed'].mean()].agg({'number_deaths': 'sum', 'damage_millions_usd': 'sum'})"
return the total number of deaths and total damange in millions for storms that had a max speed greater than the average.,"storm.loc[lambda x: x['max_speed'] > x['max_speed'].mean()].agg({'number_deaths': 'sum', 'damage_millions_usd': 'sum'})"
list name and damage for all storms in a descending order of max speed.,"storm[['name', 'damage_millions_usd']].sort_values('max_speed', ascending=false)"
"what are the names and damage in millions for storms, ordered by their max speeds descending?","storm[['name', 'damage_millions_usd']].sort_values('max_speed', ascending=false)"
how many regions are affected?,affected_region['region_id'].nunique()
count the number of different affected regions.,affected_region['region_id'].nunique()
show the name for regions not affected.,"region.loc[~region['region_id'].isin(affected_region['region_id']), 'region_name']"
what are the names of regions that were not affected?,"region.loc[~region['region_id'].isin(affected_region['region_id']), 'region_name']"
show the name for regions and the number of storms for each region.,"region.merge(affected_region, on='region_id').groupby('region_name').size()"
how many storms occured in each region?,"region.merge(affected_region, on='region_id').groupby('region_name').size()"
list the name for storms and the number of affected regions for each storm.,"storm.merge(affected_region, on='storm_id').groupby('name').size().reset_index(name='count')"
how many regions were affected by each storm?,"storm.merge(affected_region, on='storm_id').groupby('name').size().reset_index(name='count')"
what is the storm name and max speed which affected the greatest number of regions?,"pd.merge(storm, affected_region, on='storm_id').groupby('storm_id').agg({'name': 'first', 'max_speed': 'first',}).reset_index().sort_values(by='storm_id', ascending=false)[:1]"
return the name and max speed of the storm that affected the most regions.,"pd.merge(storm, affected_region, on='storm_id').groupby('storm_id').agg({'name': 'first', 'max_speed': 'first',}).reset_index().sort_values(by='storm_id', ascending=false)[:1]"
show the name of storms which don't have affected region in record.,"storm.loc[~storm['storm_id'].isin(affected_region['storm_id']), 'name']"
what are the names of storms that did not affect any regions?,"storm.loc[~storm['storm_id'].isin(affected_region['storm_id']), 'name']"
show storm name with at least two regions and 10 cities affected.,"pd.merge(storm, affected_region, on='storm_id').groupby(['storm_id', 'name'], as_index=false).agg({'number_city_affected': 'sum'}).groupby('name').filter(lambda x: x['name'].count()>=2 and x['number_city_affected'].sum()>=10)['name']"
what are the names of storms that both affected two or more regions and affected a total of 10 or more cities?,"pd.merge(storm, affected_region, on='storm_id').groupby(['storm_id', 'name'], as_index=false).agg({'number_city_affected': 'sum'}).groupby('name').filter(lambda x: x['name'].count()>=2 and x['number_city_affected'].sum()>=10)['name']"
show all storm names except for those with at least two affected regions.,"storm['name'].loc[lambda x: ~x.isin(pd.merge(storm, affected_region, on='storm_id').groupby('storm_id').filter(lambda x: len(x) >= 2)['name'])]"
what are the names of storms that did not affect two or more regions?,"storm['name'].loc[lambda x: ~x.isin(pd.merge(storm, affected_region, on='storm_id').groupby('storm_id').filter(lambda x: len(x) >= 2)['name'])]"
what are the region names affected by the storm with a number of deaths of least 10?,"pd.merge(pd.merge(affected_region, region, on='region_id'), storm, on='storm_id').loc[lambda x: x['number_deaths'] >= 10, 'region_name']"
return the names of the regions affected by storms that had a death count of at least 10.,"pd.merge(pd.merge(affected_region, region, on='region_id'), storm, on='storm_id').loc[lambda x: x['number_deaths'] >= 10, 'region_name']"
"show all storm names affecting region ""denmark"".","pd.merge(pd.merge(affected_region, region, on='region_id'), storm, on='storm_id').loc[lambda x: x['region_name']=='denmark', 'name']"
what are the names of the storms that affected denmark?,"pd.merge(pd.merge(affected_region, region, on='region_id'), storm, on='storm_id').loc[lambda x: x['region_name']=='denmark', 'name']"
show the region name with at least two storms.,"pd.merge(region, affected_region, on='region_id').groupby('region_id').size().loc[lambda x: x>=2].reset_index().merge(region, on='region_id')['region_name']"
what are the names of regions with two or more storms?,"pd.merge(region, affected_region, on='region_id').groupby('region_id').size().loc[lambda x: x>=2].reset_index().merge(region, on='region_id')['region_name']"
find the names of the regions which were affected by the storm that killed the greatest number of people.,"pd.merge(pd.merge(affected_region, region, on='region_id'), storm, on='storm_id')[['region_name', 'number_deaths']].sort_values('number_deaths', ascending=false).iloc[0,0]"
what are the names of regions that were affected by the storm in which the most people died?,"pd.merge(pd.merge(affected_region, region, on='region_id'), storm, on='storm_id')[['region_name', 'number_deaths']].sort_values('number_deaths', ascending=false).iloc[0,0]"
find the name of the storm that affected both afghanistan and albania regions.,"pd.merge(pd.merge(affected_region, region.loc[lambda x: x['region_name']=='afghanistan'], on='region_id'), storm, on='storm_id')['name'].intersect(pd.merge(pd.merge(affected_region, region.loc[lambda x: x['region_name']=='albania'], on='region_id'), storm, on='storm_id')['name'])"
what are the names of the storms that affected both the regions of afghanistan and albania?,"pd.merge(pd.merge(affected_region, region.loc[lambda x: x['region_name']=='afghanistan'], on='region_id'), storm, on='storm_id')['name'].intersect(pd.merge(pd.merge(affected_region, region.loc[lambda x: x['region_name']=='albania'], on='region_id'), storm, on='storm_id')['name'])"
how many counties are there in total?,county.shape[0]
count the total number of counties.,county.shape[0]
show the county name and population of all counties.,"county[['county_name', 'population']]"
what are the name and population of each county?,"county[['county_name', 'population']]"
show the average population of all counties.,county['population'].mean()
on average how large is the population of the counties?,county['population'].mean()
return the maximum and minimum population among all counties.,"county['population'].agg(['max', 'min'])"
what are the maximum and minimum population of the counties?,"county['population'].agg(['max', 'min'])"
show all the distinct districts for elections.,election['district'].unique()
what are the distinct districts for elections?,election['district'].unique()
"show the zip code of the county with name ""howard"".","county.loc[lambda x: x['county_name']=='howard', 'zip_code']"
"what is the zip code the county named ""howard"" is located in?","county.loc[lambda x: x['county_name']=='howard', 'zip_code']"
show the delegate from district 1 in election.,"election.loc[election['district']==1, 'delegate']"
who is the delegate of district 1 in the elections?,"election.loc[election['district']==1, 'delegate']"
show the delegate and committee information of elections.,"election[['delegate', 'committee']]"
what are the delegate and committee information for each election record?,"election[['delegate', 'committee']]"
how many distinct governors are there?,party['governor'].nunique()
count the number of distinct governors.,party['governor'].nunique()
show the lieutenant governor and comptroller from the democratic party.,"party.loc[lambda x: x['party'] == 'democratic', ['lieutenant_governor', 'comptroller']]"
who are the lieutenant governor and comptroller from the democratic party?,"party.loc[lambda x: x['party'] == 'democratic', ['lieutenant_governor', 'comptroller']]"
"in which distinct years was the governor ""eliot spitzer""?","party.loc[lambda x: x['governor']=='eliot spitzer', 'year'].unique()"
"find the distinct years when the governor was named ""eliot spitzer"".","party.loc[lambda x: x['governor']=='eliot spitzer', 'year'].unique()"
show all the information about election.,election
return all the information for each election record.,election
show the delegates and the names of county they belong to.,"pd.merge(county, election, left_on='county_id', right_on='district')[['delegate', 'county_name']]"
"what are the delegate and name of the county they belong to, for each county?","pd.merge(county, election, left_on='county_id', right_on='district')[['delegate', 'county_name']]"
which delegates are from counties with population smaller than 100000?,"pd.merge(county.loc[lambda x: x['population'] < 100000, ['county_id']], election, left_on='county_id', right_on='district')['delegate']"
find the delegates who are from counties with population below 100000.,"pd.merge(county.loc[lambda x: x['population'] < 100000, ['county_id']], election, left_on='county_id', right_on='district')['delegate']"
how many distinct delegates are from counties with population larger than 50000?,"pd.merge(county[county['population'] > 50000], election, left_on='county_id', right_on='district')['delegate'].nunique()"
count the number of distinct delegates who are from counties with population above 50000.,"pd.merge(county[county['population'] > 50000], election, left_on='county_id', right_on='district')['delegate'].nunique()"
"what are the names of the county that the delegates on ""appropriations"" committee belong to?","county.merge(election, left_on='county_id', right_on='district').loc[lambda x: x['committee']=='appropriations', 'county_name']"
"which county do the delegates on ""appropriations"" committee belong to? give me the county names.","county.merge(election, left_on='county_id', right_on='district').loc[lambda x: x['committee']=='appropriations', 'county_name']"
show the delegates and the names of the party they belong to.,"pd.merge(election, party, left_on='party', right_on='party_id')[['delegate', 'party']]"
"for each delegate, find the names of the party they are part of.","pd.merge(election, party, left_on='party', right_on='party_id')[['delegate', 'party']]"
who were the governors of the parties associated with delegates from district 1?,"pd.merge(election.loc[lambda x: x['district'] == 1], party, left_on='party', right_on='party_id')['governor']"
find the parties associated with the delegates from district 1. who served as governors of the parties?,"pd.merge(election.loc[lambda x: x['district'] == 1], party, left_on='party', right_on='party_id')['governor']"
who were the comptrollers of the parties associated with the delegates from district 1 or district 2?,"pd.merge(election.loc[election['district'].isin([1, 2])], party, left_on='party', right_on='party_id')['comptroller']"
find the parties associated with the delegates from district 1 or 2. who served as comptrollers of the parties?,"pd.merge(election.loc[election['district'].isin([1, 2])], party, left_on='party', right_on='party_id')['comptroller']"
return all the committees that have delegates from democratic party.,"pd.merge(election, party, left_on='party', right_on='party_id').loc[lambda x: x['party']=='democratic', 'committee']"
which committees have delegates from the democratic party?,"pd.merge(election, party, left_on='party', right_on='party_id').loc[lambda x: x['party']=='democratic', 'committee']"
show the name of each county along with the corresponding number of delegates from that county.,"pd.merge(county, election, left_on='county_id', right_on='district').groupby('county_name').size().reset_index(name='count')"
"for each county, find the name of the county and the number of delegates from that county.","pd.merge(county, election, left_on='county_id', right_on='district').groupby('county_name').size().reset_index(name='count')"
show the name of each party and the corresponding number of delegates from that party.,"election.merge(party, left_on='party', right_on='party_id').groupby('party')['party'].count().reset_index(name='count')[['party', 'count']]"
"for each party, return the name of the party and the number of delegates from that party.","election.merge(party, left_on='party', right_on='party_id').groupby('party')['party'].count().reset_index(name='count')[['party', 'count']]"
return the names of all counties sorted by population in ascending order.,county.sort_values('population')['county_name']
sort the names of all counties in ascending order of population.,county.sort_values('population')['county_name']
return the names of all counties sorted by county name in descending alphabetical order.,"county.sort_values('county_name', ascending=false)['county_name']"
sort the names of all counties in descending alphabetical order.,"county.sort_values('county_name', ascending=false)['county_name']"
show the name of the county with the biggest population.,"county.sort_values('population', ascending=false).iloc[0]['county_name']"
which county has the largest population? give me the name of the county.,"county.sort_values('population', ascending=false).iloc[0]['county_name']"
show the 3 counties with the smallest population.,county.sort_values('population').iloc[:3]['county_name']
what are the 3 counties that have the smallest population? give me the county names.,county.sort_values('population').iloc[:3]['county_name']
show the names of counties that have at least two delegates.,"county.merge(election, left_on='county_id', right_on='district').groupby('county_name').filter(lambda x: len(x) >= 2)['county_name']"
which counties have two or more delegates? give me the county names.,"county.merge(election, left_on='county_id', right_on='district').groupby('county_name').filter(lambda x: len(x) >= 2)['county_name']"
show the name of the party that has at least two records.,party.groupby('party').filter(lambda x: len(x) >= 2)['party']
which party has two or more records?,party.groupby('party').filter(lambda x: len(x) >= 2)['party']
show the name of the party that has the most delegates.,"pd.merge(election, party, left_on='party', right_on='party_id').groupby('party')['party'].count().idxmax()"
which party has the largest number of delegates?,"pd.merge(election, party, left_on='party', right_on='party_id').groupby('party')['party'].count().idxmax()"
show the people that have been governor the most times.,party.groupby('governor').size().sort_values(ascending=false).index[0]
which people severed as governor most frequently?,party.groupby('governor').size().sort_values(ascending=false).index[0]
show the people that have been comptroller the most times and the corresponding number of times.,party.groupby('comptroller').size().sort_values(ascending=false).head(1)
which people severed as comptroller most frequently? give me the name of the person and the frequency count.,party.groupby('comptroller').size().sort_values(ascending=false).head(1)
what are the names of parties that do not have delegates in election?,"party.loc[~party['party_id'].isin(election['party']), 'party']"
which parties did not have any delegates in elections?,"party.loc[~party['party_id'].isin(election['party']), 'party']"
"what are the names of parties that have both delegates on ""appropriations"" committee and","set(election.loc[election['committee'] == 'appropriations'].merge(party, left_on='party', right_on='party_id')['party']).intersection(set(election.loc[election['committee'] == 'economic matters'].merge(party, left_on='party', right_on='party_id')['party']))"
"which parties have delegates in both the ""appropriations"" committee and the ""economic matters"" committee?","set(election.loc[election['committee'] == 'appropriations'].merge(party, left_on='party', right_on='party_id')['party']).intersection(set(election.loc[election['committee'] == 'economic matters'].merge(party, left_on='party', right_on='party_id')['party']))"
which committees have delegates from both democratic party and liberal party?,"set(election.merge(party[party['party']=='democratic'], left_on='party', right_on='party_id')['committee']).intersection(set(election.merge(party[party['party']=='liberal'], left_on='party', right_on='party_id')['committee']))"
find the committees that have delegates both from from the democratic party and the liberal party.,"set(election.merge(party[party['party']=='democratic'], left_on='party', right_on='party_id')['committee']).intersection(set(election.merge(party[party['party']=='liberal'], left_on='party', right_on='party_id')['committee']))"
how many journalists are there?,journalist.shape[0]
list the names of journalists in ascending order of years working.,journalist.sort_values('years_working')['name']
what are the nationalities and ages of journalists?,"journalist[['nationality', 'age']]"
"show the names of journalists from ""england"" or ""wales"".","journalist.loc[journalist['nationality'].isin(['england', 'wales']), 'name']"
what is the average number of years spent working as a journalist?,journalist['years_working'].mean()
what is the nationality of the journalist with the largest number of years working?,"journalist.sort_values('years_working', ascending=false).iloc[0]['nationality']"
show the different nationalities and the number of journalists of each nationality.,journalist.groupby('nationality').size().reset_index(name='count')
show the most common nationality for journalists.,journalist.groupby('nationality').size().sort_values(ascending=false).index[0]
show the nations that have both journalists with more than 10 years of working and journalists with less than 3 years of working.,"journalist.loc[journalist['years_working'] > 10, 'nationality'].interesect(journalist.loc[journalist['years_working'] < 3, 'nationality'])"
"show the dates, places, and names of events in descending order of the attendance.","event[['date', 'name', 'venue']].sort_values('event_attendance', ascending=false)"
show the names of journalists and the dates of the events they reported.,"pd.merge(pd.merge(news_report, event, on='event_id'), journalist, on='journalist_id')[['name', 'date']]"
show the names of journalists and the names of the events they reported in ascending order,"pd.merge(pd.merge(news_report, event, on='event_id'), journalist, on='journalist_id').sort_values('event_attendance')['name_x', 'name_y']"
show the names of journalists and the number of events they reported.,"pd.merge(pd.merge(news_report, event, on='event_id'), journalist, on='journalist_id').groupby('name').size().reset_index(name='count')"
show the names of journalists that have reported more than one event.,"pd.merge(pd.merge(news_report, event, on='event_id'), journalist, on='journalist_id').groupby('name').filter(lambda x: len(x) > 1)['name'].unique()"
list the names of journalists who have not reported any event.,"journalist.loc[~journalist['journalist_id'].isin(news_report['journalist_id']), 'name']"
what are the average and maximum attendances of all events?,"event['event_attendance'].agg(['mean', 'max'])"
find the average age and experience working length of journalists working on different role type.,"pd.merge(journalist, news_report, on='journalist_id').groupby('work_type').agg({'age': 'mean', 'years_working': 'mean'})"
list the event venues and names that have the top 2 most number of people attended.,"event[['venue', 'name']].sort_values('event_attendance', ascending=false).head(2)"
show me all the restaurants.,restaurant['resname']
what is the address of the restaurant subway?,"restaurant.loc[lambda x: x['resname']=='subway', 'address']"
what is the rating of the restaurant subway?,"restaurant.loc[lambda x: x['resname']=='subway', 'rating']"
list all restaurant types.,restaurant_type['restypename']
what is the description of the restaurant type sandwich?,"restaurant_type.loc[lambda x: x['restypename']=='sandwich', 'restypedescription']"
which restaurants have highest rating? list the restaurant name and its rating.,"restaurant[['resname', 'rating']].sort_values('rating', ascending=false).iloc[0]"
what is the age of student linda smith?,"student.loc[(student['fname']=='linda') & (student['lname']=='smith'), 'age']"
what is the gender of the student linda smith?,"student.loc[(student['fname'] == 'linda') & (student['lname'] == 'smith'), 'sex']"
list all students' first names and last names who majored in 600.,"student.loc[lambda x: x['major']==600, ['fname', 'lname']]"
which city does student linda smith live in?,"student.loc[(student['fname']=='linda') & (student['lname']=='smith'), 'city_code']"
advisor 1121 has how many students?,(student['advisor'] == 1121).sum()
which advisor has most of students? list advisor and the number of students.,student.groupby('advisor').size().sort_values(ascending=false).reset_index(name='count').iloc[0]
which major has least number of students? list the major and the number of students.,"student.groupby('major').size().sort_values().head(1).reset_index(name='count')[['major', 'count']]"
which major has between 2 and 30 number of students? list major and the number of students.,"student.groupby('major').filter(lambda x: x['major'].count().between(2, 30)).groupby('major').size()"
which student's age is older than 18 and is majoring in 600? list each student's first and last name.,"student.loc[(student['age'] > 18) & (student['major'] == 600), ['fname', 'lname']]"
list all female students age is older than 18 who is not majoring in 600. list students' first name and last name.,"student.loc[(student['age']>18) & (student['major']!=600) & (student['sex']=='f'), ['fname', 'lname']]"
how many restaurant is the sandwich type restaurant?,"restaurant.join(type_of_restaurant.set_index('resid'), on='resid').join(restaurant_type.set_index('restypeid'), on='restypeid').groupby('restypeid').filter(lambda x: x['restypename'].iloc[0] == 'sandwich').shape[0]"
how long does student linda smith spend on the restaurant in total?,"student.merge(visits_restaurant, on='stuid').loc[(student['fname']=='linda') & (student['lname']=='smith'), 'spent'].sum()"
how many times has the student linda smith visited subway?,"student.merge(visits_restaurant, on='stuid').merge(restaurant, on='resid').loc[(lambda x: (x['fname']=='linda') & (x['lname']=='smith') & (x['resname']=='subway'))].shape[0]"
when did linda smith visit subway?,"pd.merge(pd.merge(student, visits_restaurant, on='stuid'), restaurant, on='resid').loc[(lambda x: (x['fname']=='linda') & (x['lname']=='smith') & (x['resname']=='subway')), 'time']"
at which restaurant did the students spend the least amount of time? list restaurant and the time students spent on in total.,"pd.merge(visits_restaurant, restaurant, on='resid').groupby('resname')['spent'].sum().nsmallest(1)"
which student visited restaurant most often? list student's first name and last name.,"student.merge(visits_restaurant, on='stuid').groupby(['stuid', 'fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['fname', 'lname']]"
find the ids of orders whose status is 'success'.,"actual_orders.loc[lambda x: x['order_status_code']=='success', 'actual_order_id']"
find the name and price of the product that has been ordered the greatest number of times.,"pd.merge(products, regular_order_products, on='product_id').groupby('product_id').agg({'product_name':'first','product_price':'first','product_id':'count'} ).sort_values('product_id', ascending=false).iloc[0][['product_name', 'product_price']]"
find the number of customers in total.,customers.shape[0]
how many different payment methods are there?,customers['payment_method'].nunique()
show the details of all trucks in the order of their license number.,trucks.sort_values('truck_licence_number')['truck_details']
find the name of the most expensive product.,"products.sort_values('product_price', ascending=false)['product_name'].iloc[0]"
find the names of customers who are not living in the state of california.,"customers[~customers['customer_name'].isin(pd.merge(pd.merge(customer_addresses, addresses, on='address_id'), customers, on='customer_id').loc[lambda x: x['state_province_county']=='california', 'customer_name'])]['customer_name']"
list the names and emails of customers who payed by visa card.,"customers.loc[lambda x: x['payment_method']=='visa', ['customer_email', 'customer_name']]"
find the names and phone numbers of customers living in california state.,"pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').loc[lambda x: x['state_province_county']=='california', ['customer_name', 'customer_phone']]"
find the states which do not have any employee in their record.,"addresses.loc[~addresses['address_id'].isin(employees['employee_address_id']), 'state_province_county']"
"list the names, phone numbers, and emails of all customers sorted by their dates of becoming customers.","customers[['customer_name', 'customer_phone', 'customer_email']].sort_values('date_became_customer')"
find the name of the first 5 customers.,customers.sort_values('date_became_customer').iloc[:5]['customer_name']
find the payment method that is used most frequently.,customers.groupby('payment_method').size().sort_values(ascending=false).index[0]
list the names of all routes in alphabetic order.,delivery_routes.sort_values('route_name')['route_name']
find the name of route that has the highest number of deliveries.,"pd.merge(delivery_routes, delivery_route_locations, on='route_id').groupby('route_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['route_name']"
list the state names and the number of customers living in each state.,"pd.merge(customer_addresses, addresses, on='address_id').groupby('state_province_county').size()"
how many authors are there?,authors.shape[0]
count the number of authors.,authors.shape[0]
how many institutions are there?,inst.shape[0]
count the number of institutions.,inst.shape[0]
how many papers are published in total?,papers.shape[0]
count the number of total papers.,papers.shape[0]
"what are the titles of papers published by ""jeremy gibbons""?","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[(lambda x: (x['fname']=='jeremy') & (x['lname']=='gibbons'))(authors), 'title']"
"find the titles of all the papers written by ""jeremy gibbons""","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[(lambda x: (x['fname']=='jeremy') & (x['lname']=='gibbons'))(authors), 'title']"
"find all the papers published by ""aaron turon"".","authors.loc[(authors['fname']=='aaron') & (authors['lname']=='turon'), :].merge(authorship, on='authid').merge(papers, on='paperid')['title']"
"find the titles of all the papers written by ""aaron turon"".","authors.loc[(authors['fname']=='aaron') & (authors['lname']=='turon'), :].merge(authorship, on='authid').merge(papers, on='paperid')['title']"
"how many papers have ""atsushi ohori"" published?","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: (x['fname']=='atsushi') & (x['lname']=='ohori')].shape[0]"
"how many papers are ""atsushi ohori"" the author of?","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: (x['fname']=='atsushi') & (x['lname']=='ohori')].shape[0]"
"what is the name of the institution that ""matthias blume"" belongs to?","pd.merge(pd.merge(authors, authorship, on='authid'), inst, on='instid').loc[lambda x: (x['fname']=='matthias') & (x['lname']=='blume'), 'name'].unique()"
"which institution is the author ""matthias blume"" belong to? give me the name of the institution.","pd.merge(pd.merge(authors, authorship, on='authid'), inst, on='instid').loc[lambda x: (x['fname']=='matthias') & (x['lname']=='blume'), 'name'].unique()"
"which institution does ""katsuhiro ueno"" belong to?","pd.merge(pd.merge(authors, authorship, on='authid'), inst, on='instid').loc[lambda x: (x['fname']=='katsuhiro') & (x['lname']=='ueno'), 'name'].unique()"
"what is the name of the institution the author ""katsuhiro ueno"" belongs to?","pd.merge(pd.merge(authors, authorship, on='authid'), inst, on='instid').loc[lambda x: (x['fname']=='katsuhiro') & (x['lname']=='ueno'), 'name'].unique()"
"who belong to the institution ""university of oxford""? show the first names and last names.","pd.merge(pd.merge(authors, authorship, on='authid'), inst, on='instid').loc[lambda x: x['name']=='university of oxford', ['fname', 'lname']].drop_duplicates()"
"find the first names and last names of the authors whose institution affiliation is ""university of oxford"".","pd.merge(pd.merge(authors, authorship, on='authid'), inst, on='instid').loc[lambda x: x['name']=='university of oxford', ['fname', 'lname']].drop_duplicates()"
"which authors belong to the institution ""google""? show the first names and last names.","pd.merge(pd.merge(authors, authorship, on='authid'), inst, on='instid').loc[lambda x: x['name']=='google', ['fname', 'lname']].drop_duplicates()"
"find the first names and last names of the authors whose institution affiliation is ""google"".","pd.merge(pd.merge(authors, authorship, on='authid'), inst, on='instid').loc[lambda x: x['name']=='google', ['fname', 'lname']].drop_duplicates()"
"what are the last names of the author of the paper titled ""binders unbound""?","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: x['title']=='binders unbound', 'lname']"
"who is the author of the paper titled ""binders unbound""? give me the last name.","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: x['title']=='binders unbound', 'lname']"
"find the first and last name of the author(s) who wrote the paper ""nameless, painless"".","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: x['title']=='nameless , painless', ['fname', 'lname']]"
"what are the first and last name of the author who published the paper titled ""nameless, painless""?","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: x['title']=='nameless , painless', ['fname', 'lname']]"
"what are the papers published under the institution ""indiana university""?","pd.merge(pd.merge(papers, authorship, on='paperid'), inst, on='instid').loc[lambda x: x['name']=='indiana university', 'title'].unique()"
"list the titles of the papers whose authors are from the institution ""indiana university"".","pd.merge(pd.merge(papers, authorship, on='paperid'), inst, on='instid').loc[lambda x: x['name']=='indiana university', 'title'].unique()"
"find all the papers published by the institution ""google"".","pd.merge(pd.merge(papers, authorship, on='paperid'), inst, on='instid').loc[lambda x: x['name']=='google', 'title'].unique()"
"which papers were written by authors from the institution ""google""?","pd.merge(pd.merge(papers, authorship, on='paperid'), inst, on='instid').loc[lambda x: x['name']=='google', 'title'].unique()"
"how many papers are published by the institution ""tokohu university""?","pd.merge(pd.merge(papers, authorship, on='paperid'), inst, on='instid').loc[lambda x: x['name']=='tokohu university', 'title'].nunique()"
"find the number of papers published by authors from the institution ""tokohu university"".","pd.merge(pd.merge(papers, authorship, on='paperid'), inst, on='instid').loc[lambda x: x['name']=='tokohu university', 'title'].nunique()"
"find the number of papers published by the institution ""university of pennsylvania"".","pd.merge(pd.merge(papers, authorship, on='paperid'), inst, on='instid').loc[lambda x: x['name']=='university of pennsylvania', 'title'].nunique()"
"how many papers are written by authors from the institution ""university of pennsylvania""?","pd.merge(pd.merge(papers, authorship, on='paperid'), inst, on='instid').loc[lambda x: x['name']=='university of pennsylvania', 'title'].nunique()"
"find the papers which have ""olin shivers"" as an author.","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: (x['fname']=='olin') & (x['lname']=='shivers'), 'title']"
"which papers did the author ""olin shivers"" write? give me the paper titles.","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: (x['fname']=='olin') & (x['lname']=='shivers'), 'title']"
"which papers have ""stephanie weirich"" as an author?","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: (x['fname']=='stephanie') & (x['lname']=='weirich'), 'title']"
"find the titles of the papers the author ""stephanie weirich"" wrote.","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: (x['fname']=='stephanie') & (x['lname']=='weirich'), 'title']"
"which paper is published in an institution in ""usa"" and have ""turon"" as its second author?","pd.merge(pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid'), inst, on='instid').loc[(lambda x: (x['country'] == 'usa') & (x['authorder'] == 2) & (x['lname'] == 'turon'))(authors), 'title']"
"find papers whose second author has last name ""turon"" and is affiliated with an institution in the country ""usa"".","pd.merge(pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid'), inst, on='instid').loc[(lambda x: (x['country'] == 'usa') & (x['authorder'] == 2) & (x['lname'] == 'turon'))(authors), 'title']"
"find the titles of papers whose first author is affiliated with an institution in the country ""japan"" and has last name ""ohori""?","pd.merge(pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid'), inst, on='instid').loc[(lambda x: (x['country']=='japan') & (x['authorder']==1) & (x['lname']=='ohori'))].title"
"which papers' first author is affiliated with an institution in the country ""japan"" and has last name ""ohori""? give me the titles of the papers.","pd.merge(pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid'), inst, on='instid').loc[(lambda x: (x['country']=='japan') & (x['authorder']==1) & (x['lname']=='ohori'))].title"
what is the last name of the author that has published the most papers?,"authors.merge(authorship, on='authid').merge(papers, on='paperid').groupby(['fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['lname']"
which author has written the most papers? find his or her last name.,"authors.merge(authorship, on='authid').merge(papers, on='paperid').groupby(['fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['lname']"
retrieve the country that has published the most papers.,"inst.merge(authorship, on='instid').merge(papers, on='paperid').groupby('country')['paperid'].count().nlargest(1).index[0]"
find the country that the most papers are affiliated with.,"inst.merge(authorship, on='instid').merge(papers, on='paperid').groupby('country')['paperid'].count().nlargest(1).index[0]"
find the name of the organization that has published the largest number of papers.,"inst.merge(authorship, on='instid').merge(papers, on='paperid').groupby('name').size().sort_values(ascending=false).head(1).index[0]"
which institution has the most papers? find the name of the institution.,"inst.merge(authorship, on='instid').merge(papers, on='paperid').groupby('name').size().sort_values(ascending=false).head(1).index[0]"
"find the titles of the papers that contain the word ""ml"".","papers.loc[papers['title'].str.contains('ml'), 'title']"
"which papers have the substring ""ml"" in their titles? return the titles of the papers.","papers.loc[papers['title'].str.contains('ml'), 'title']"
"which paper's title contains the word ""database""?","papers.loc[papers['title'].str.contains('database'), 'title']"
"which papers have the substring ""database"" in their titles? show the titles of the papers.","papers.loc[papers['title'].str.contains('database'), 'title']"
"find the first names of all the authors who have written a paper with title containing the word ""functional"".","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: x['title'].str.contains('functional'), 'fname']"
"who has written a paper that has the word ""functional"" in its title? return the first names of the authors.","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: x['title'].str.contains('functional'), 'fname']"
"find the last names of all the authors that have written a paper with title containing the word ""monadic"".","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: x['title'].str.contains('monadic', case=false), 'lname']"
"which authors have written a paper with title containing the word ""monadic""? return their last names.","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: x['title'].str.contains('monadic', case=false), 'lname']"
retrieve the title of the paper that has the largest number of authors.,"papers.merge(authorship.groupby('paperid')['authorder'].max().reset_index(), on='paperid').loc[lambda x: x['authorder_x']==x['authorder_y'], 'title']"
which paper has the most authors? give me the paper title.,"papers.merge(authorship.groupby('paperid')['authorder'].max().reset_index(), on='paperid').loc[lambda x: x['authorder_x']==x['authorder_y'], 'title']"
"what is the first name of the author with last name ""ueno""?","authors.loc[lambda x: x['lname']=='ueno', 'fname']"
"which authors have last name ""ueno""? list their first names.","authors.loc[lambda x: x['lname']=='ueno', 'fname']"
"find the last name of the author with first name ""amal"".","authors.loc[lambda x: x['fname']=='amal', 'lname']"
"which authors have first name ""amal""? list their last names.","authors.loc[lambda x: x['fname']=='amal', 'lname']"
find the first names of all the authors ordered in alphabetical order.,authors.sort_values('fname')['fname']
sort the first names of all the authors in alphabetical order.,authors.sort_values('fname')['fname']
retrieve all the last names of authors in alphabetical order.,authors['lname'].sort_values()
give me a list of all the last names of authors sorted in alphabetical order,authors['lname'].sort_values()
retrieve all the first and last names of authors in the alphabetical order of last names.,"authors[['fname', 'lname']].sort_values('lname')"
sort the list of all the first and last names of authors in alphabetical order of the last names.,"authors[['fname', 'lname']].sort_values('lname')"
how many different last names do the actors and actresses have?,actor['last_name'].nunique()
count the number of different last names actors have.,actor['last_name'].nunique()
what is the most popular first name of the actors?,"actor.groupby('first_name').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['first_name']"
return the most common first name among all actors.,"actor.groupby('first_name').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['first_name']"
what is the most popular full name of the actors?,"actor.groupby(['first_name', 'last_name']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['first_name', 'last_name']]"
return the most common full name among all actors.,"actor.groupby(['first_name', 'last_name']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['first_name', 'last_name']]"
which districts have at least two addresses?,address.groupby('district').filter(lambda x: len(x) >= 2)['district'].unique()
give the districts which have two or more addresses.,address.groupby('district').filter(lambda x: len(x) >= 2)['district'].unique()
what is the phone number and postal code of the address 1031 daugavpils parkway?,"address.loc[lambda x: x['address']=='1031 daugavpils parkway', ['phone', 'postal_code']]"
give the phone and postal code corresponding to the address '1031 daugavpils parkway'.,"address.loc[lambda x: x['address']=='1031 daugavpils parkway', ['phone', 'postal_code']]"
"which city has the most addresses? list the city name, number of addresses, and city id.","address.merge(city, on='city_id').groupby('city_id').size().reset_index(name='count').merge(city, on='city_id').sort_values('count', ascending=false).iloc[0][['city', 'count', 'city_id']]"
"what are the city name, id, and number of addresses corresponding to the city with the most addressed?","address.merge(city, on='city_id').groupby('city_id').size().reset_index(name='count').merge(city, on='city_id').sort_values('count', ascending=false).iloc[0][['city', 'count', 'city_id']]"
how many addresses are in the district of california?,(address['district'] == 'california').sum()
count the number of addressed in the california district.,(address['district'] == 'california').sum()
which film is rented at a fee of 0.99 and has less than 3 in the inventory? list the film title and id.,"film.loc[film['rental_rate'] == 0.99, ['title', 'film_id']].merge(inventory, on='film_id').groupby('film_id').filter(lambda x: len(x) < 3)['title', 'film_id']"
what are the title and id of the film which has a rental rate of 0.99 and an inventory of below 3?,"film.loc[film['rental_rate'] == 0.99, ['title', 'film_id']].merge(inventory, on='film_id').groupby('film_id').filter(lambda x: len(x) < 3)['title', 'film_id']"
how many cities are in australia?,"pd.merge(city, country, on='country_id').loc[lambda x: x['country']=='australia'].shape[0]"
count the number of cities in australia.,"pd.merge(city, country, on='country_id').loc[lambda x: x['country']=='australia'].shape[0]"
which countries have at least 3 cities?,"pd.merge(city, country, on='country_id').groupby('country').filter(lambda x: len(x) >= 3)['country'].unique()"
what are the countries that contain 3 or more cities?,"pd.merge(city, country, on='country_id').groupby('country').filter(lambda x: len(x) >= 3)['country'].unique()"
find all the payment dates for the payments with an amount larger than 10 and the payments handled by a staff person with the first name elsa.,"payment.loc[payment['amount'] > 10, 'payment_date'].append(pd.merge(payment, staff, on='staff_id').loc[lambda x: x['first_name']=='elsa', 'payment_date']).drop_duplicates()"
what are the payment dates for any payments that have an amount greater than 10 or were handled by a staff member with the first name elsa?,"payment.loc[payment['amount'] > 10, 'payment_date'].append(pd.merge(payment, staff, on='staff_id').loc[lambda x: x['first_name']=='elsa', 'payment_date']).drop_duplicates()"
how many customers have an active value of 1?,(customer['active'] == '1').sum()
count the number of customers who are active.,(customer['active'] == '1').sum()
which film has the highest rental rate? and what is the rate?,"film[['title', 'rental_rate']].sort_values('rental_rate', ascending=false).iloc[0]"
what are the title and rental rate of the film with the highest rental rate?,"film[['title', 'rental_rate']].sort_values('rental_rate', ascending=false).iloc[0]"
"which film has the most number of actors or actresses? list the film name, film id and description.","film_actor.merge(film, on='film_id').groupby(['film_id', 'title', 'description']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['title', 'film_id', 'description']]"
"what are the title, id, and description of the movie with the greatest number of actors?","film_actor.merge(film, on='film_id').groupby(['film_id', 'title', 'description']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['title', 'film_id', 'description']]"
"which film actor (actress) starred the most films? list his or her first name, last name and actor id.","pd.merge(film_actor, actor, on='actor_id').groupby(['first_name', 'last_name', 'actor_id']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['first_name', 'last_name', 'actor_id']]"
return the full name and id of the actor or actress who starred in the greatest number of films.,"pd.merge(film_actor, actor, on='actor_id').groupby(['first_name', 'last_name', 'actor_id']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['first_name', 'last_name', 'actor_id']]"
which film actors (actresses) played a role in more than 30 films? list his or her first name and last name.,"pd.merge(film_actor, actor, on='actor_id').groupby(['actor_id', 'first_name', 'last_name']).filter(lambda x: len(x) > 30)[['first_name', 'last_name']].drop_duplicates()"
what are the full names of actors who had roles in more than 30 films?,"pd.merge(film_actor, actor, on='actor_id').groupby(['actor_id', 'first_name', 'last_name']).filter(lambda x: len(x) > 30)[['first_name', 'last_name']].drop_duplicates()"
which store owns most items?,inventory.groupby('store_id').size().sort_values(ascending=false).index[0]
what is the id of the store that has the most items in inventory?,inventory.groupby('store_id').size().sort_values(ascending=false).index[0]
what is the total amount of all payments?,payment['amount'].sum()
return the sum of all payment amounts.,payment['amount'].sum()
"which customer, who has made at least one payment, has spent the least money? list his or her first name, last name, and the id.","customer.merge(payment, on='customer_id').groupby(['customer_id', 'first_name', 'last_name']).agg({'amount': 'sum'}).reset_index().sort_values('amount').iloc[0][['first_name', 'last_name', 'customer_id']]"
what is the full name and id of the customer who has the lowest total amount of payment?,"customer.merge(payment, on='customer_id').groupby(['customer_id', 'first_name', 'last_name']).agg({'amount': 'sum'}).reset_index().sort_values('amount').iloc[0][['first_name', 'last_name', 'customer_id']]"
what is the genre name of the film hunger roof?,"pd.merge(pd.merge(category, film_category, on='category_id'), film, on='film_id').loc[lambda x: x['title']=='hunger roof', 'name']"
return the name of the category to which the film 'hunger roof' belongs.,"pd.merge(pd.merge(category, film_category, on='category_id'), film, on='film_id').loc[lambda x: x['title']=='hunger roof', 'name']"
"how many films are there in each category? list the genre name, genre id and the count.","pd.merge(film_category, category, on='category_id').groupby('category_id').agg({'name': 'first', 'film_id': 'count'}).reset_index()[['name', 'category_id', 'film_id']]"
"what are the names and ids of the different categories, and how many films are in each?","pd.merge(film_category, category, on='category_id').groupby('category_id').agg({'name': 'first', 'film_id': 'count'}).reset_index()[['name', 'category_id', 'film_id']]"
which film has the most copies in the inventory? list both title and id.,"pd.merge(film, inventory, on='film_id').groupby('film_id').agg({'title':'first', 'inventory_id':'count'}).sort_values('inventory_id', ascending=false).iloc[0][['title', 'inventory_id']]"
what is the title and id of the film that has the greatest number of copies in inventory?,"pd.merge(film, inventory, on='film_id').groupby('film_id').agg({'title':'first', 'inventory_id':'count'}).sort_values('inventory_id', ascending=false).iloc[0][['title', 'inventory_id']]"
what is the film title and inventory id of the item in the inventory which was rented most frequently?,"pd.merge(pd.merge(film, inventory, on='film_id'), rental, on='inventory_id').groupby('inventory_id').size().sort_values(ascending=false).reset_index(name='count').iloc[0][['title', 'inventory_id']]"
return the title and inventory id of the film that is rented most often.,"pd.merge(pd.merge(film, inventory, on='film_id'), rental, on='inventory_id').groupby('inventory_id').size().sort_values(ascending=false).reset_index(name='count').iloc[0][['title', 'inventory_id']]"
how many languages are in these films?,film['language_id'].nunique()
count the number of different languages in these films.,film['language_id'].nunique()
what are all the movies rated as r? list the titles.,"film.loc[film['rating']=='r', 'title']"
return the titles of any movies with an r rating.,"film.loc[film['rating']=='r', 'title']"
where is store 1 located?,"address.loc[lambda x: x['address_id']==store.loc[lambda y: y['store_id']==1, 'address_id'].iloc[0], 'address']"
return the address of store 1.,"address.loc[lambda x: x['address_id']==store.loc[lambda y: y['store_id']==1, 'address_id'].iloc[0], 'address']"
which staff handled least number of payments? list the full name and the id.,"pd.merge(staff, payment, on='staff_id').groupby(['first_name', 'last_name', 'staff_id']).size().reset_index(name='count').sort_values('count').iloc[0]"
give the full name and staff id of the staff who has handled the fewest payments.,"pd.merge(staff, payment, on='staff_id').groupby(['first_name', 'last_name', 'staff_id']).size().reset_index(name='count').sort_values('count').iloc[0]"
which language does the film airport pollock use? list the language name.,"film.merge(language, on='language_id').loc[lambda x: x['title']=='airport pollock', 'name']"
what is the name of the language that the film 'airport pollock' is in?,"film.merge(language, on='language_id').loc[lambda x: x['title']=='airport pollock', 'name']"
how many stores are there?,store.shape[0]
count the number of stores.,store.shape[0]
how many kinds of different ratings are listed?,film['rating'].nunique()
count the number of different film ratings.,film['rating'].nunique()
which movies have 'deleted scenes' as a substring in the special feature?,"film.loc[film['special_features'].str.contains('deleted scenes'), 'title']"
return the titles of films that include 'deleted scenes' in their special feature section.,"film.loc[film['special_features'].str.contains('deleted scenes'), 'title']"
how many items in inventory does store 1 have?,(inventory['store_id'] == 1).sum()
count the number of items store 1 has in stock.,(inventory['store_id'] == 1).sum()
when did the first payment happen?,payment.sort_values('payment_date').iloc[0]['payment_date']
what was the date of the earliest payment?,payment.sort_values('payment_date').iloc[0]['payment_date']
where does the customer with the first name linda live? and what is her email?,"pd.merge(customer.loc[lambda x: x['first_name']=='linda', ['address_id', 'email']], address, on='address_id')['address']"
return the address and email of the customer with the first name linda.,"pd.merge(customer.loc[lambda x: x['first_name']=='linda', ['address_id', 'email']], address, on='address_id')['address']"
"find all the films longer than 100 minutes, or rated pg, except those who cost more than 200 for replacement. list the titles.","film.loc[((film['length'] > 100) | (film['rating'] == 'pg')) & ~(film['replacement_cost'] > 200), 'title']"
what are the titles of films that are either longer than 100 minutes or rated pg other than those that cost more than 200 to replace?,"film.loc[((film['length'] > 100) | (film['rating'] == 'pg')) & ~(film['replacement_cost'] > 200), 'title']"
what is the first name and the last name of the customer who made the earliest rental?,"pd.merge(customer, rental, on='customer_id').sort_values('rental_date').iloc[0][['first_name', 'last_name']]"
return the full name of the customer who made the first rental.,"pd.merge(customer, rental, on='customer_id').sort_values('rental_date').iloc[0][['first_name', 'last_name']]"
what is the full name of the staff member who has rented a film to a customer with the first name april and the last name burns?,"pd.merge(pd.merge(staff, rental, on='staff_id'), customer, on='customer_id').loc[(lambda x: x['first_name']=='april')&(lambda x: x['last_name']=='burns'), ['first_name', 'last_name']].drop_duplicates()"
return the full name of the staff who provided a customer with the first name april and the last name burns with a film rental.,"pd.merge(pd.merge(staff, rental, on='staff_id'), customer, on='customer_id').loc[(lambda x: x['first_name']=='april')&(lambda x: x['last_name']=='burns'), ['first_name', 'last_name']].drop_duplicates()"
which store has most the customers?,customer.groupby('store_id').size().sort_values(ascending=false).index[0]
return the id of the store with the most customers.,customer.groupby('store_id').size().sort_values(ascending=false).index[0]
what is the largest payment amount?,payment['amount'].nlargest(1)
return the amount of the largest payment.,payment['amount'].nlargest(1)
where does the staff member with the first name elsa live?,"address.loc[lambda x: x['address_id'].isin(staff.loc[lambda x: x['first_name']=='elsa', 'address_id']), 'address']"
give the address of the staff member who has the first name elsa.,"address.loc[lambda x: x['address_id'].isin(staff.loc[lambda x: x['first_name']=='elsa', 'address_id']), 'address']"
what are the first names of customers who have not rented any films after '2005-08-23 02:06:01'?,"customer.loc[~customer['customer_id'].isin(rental.loc[rental['rental_date'] > '2005-08-23 02:06:01', 'customer_id']), 'first_name']"
return the first names of customers who did not rented a film after the date '2005-08-23 02:06:01'.,"customer.loc[~customer['customer_id'].isin(rental.loc[rental['rental_date'] > '2005-08-23 02:06:01', 'customer_id']), 'first_name']"
how many bank branches are there?,bank.shape[0]
count the number of bank branches.,bank.shape[0]
how many customers are there?,bank['no_of_customers'].sum()
what is the total number of customers across banks?,bank['no_of_customers'].sum()
find the number of customers in the banks at new york city.,"bank.loc[lambda x: x['city']=='new york city', 'no_of_customers'].sum()"
what is the total number of customers who use banks in new york city?,"bank.loc[lambda x: x['city']=='new york city', 'no_of_customers'].sum()"
find the average number of customers in all banks of utah state.,"bank.loc[lambda x: x['state']=='utah', 'no_of_customers'].mean()"
what is the average number of customers across banks in the state of utah?,"bank.loc[lambda x: x['state']=='utah', 'no_of_customers'].mean()"
find the average number of customers cross all banks.,bank['no_of_customers'].mean()
what is the average number of bank customers?,bank['no_of_customers'].mean()
find the city and state of the bank branch named morningside.,"bank.loc[lambda x: x['bname'] == 'morningside', ['city', 'state']]"
what city and state is the bank with the name morningside in?,"bank.loc[lambda x: x['bname'] == 'morningside', ['city', 'state']]"
find the branch names of banks in the new york state.,"bank.loc[lambda x: x['state']=='new york', 'bname']"
what are the names of banks in the state of new york?,"bank.loc[lambda x: x['state']=='new york', 'bname']"
list the name of all customers sorted by their account balance in ascending order.,customer.sort_values('acc_bal')['cust_name']
"what are the names of all customers, ordered by account balance?",customer.sort_values('acc_bal')['cust_name']
list the name of all different customers who have some loan sorted by their total loan amount.,"customer.merge(loan, on='cust_id').groupby('cust_name').agg({'amount': 'sum'}).sort_values('amount', ascending=true).reset_index()['cust_name']"
"what are the names of the different customers who have taken out a loan, ordered by the total amount that they have taken?","customer.merge(loan, on='cust_id').groupby('cust_name').agg({'amount': 'sum'}).sort_values('amount', ascending=true).reset_index()['cust_name']"
"find the state, account type, and credit score of the customer whose number of loan is 0.","customer.loc[lambda x: x['no_of_loans'] == 0, ['state', 'acc_type', 'credit_score']]"
"what are the states, account types, and credit scores for customers who have 0 loans?","customer.loc[lambda x: x['no_of_loans'] == 0, ['state', 'acc_type', 'credit_score']]"
find the number of different cities which banks are located at.,bank['city'].nunique()
in how many different cities are banks located?,bank['city'].nunique()
find the number of different states which banks are located at.,bank['state'].nunique()
in how many different states are banks located?,bank['state'].nunique()
how many distinct types of accounts are there?,customer['acc_type'].nunique()
count the number of different account types.,customer['acc_type'].nunique()
find the name and account balance of the customer whose name includes the letter ‘a’.,"customer.loc[lambda x: x['cust_name'].str.contains('a', case=false), ['cust_name', 'acc_bal']]"
what are the names and account balances of customers with the letter a in their names?,"customer.loc[lambda x: x['cust_name'].str.contains('a', case=false), ['cust_name', 'acc_bal']]"
find the total account balance of each customer from utah or texas.,"customer.loc[lambda x: x['state'].isin(['utah', 'texas']), 'acc_bal'].sum()"
what are the total account balances for each customer from utah or texas?,"customer.loc[lambda x: x['state'].isin(['utah', 'texas']), 'acc_bal'].sum()"
find the name of customers who have both saving and checking account types.,"pd.series(list(set(customer.loc[customer['acc_type']=='saving', 'cust_name']).intersection(set(customer.loc[customer['acc_type']=='checking', 'cust_name']))))"
what are the names of customers who have both savings and checking accounts?,"pd.series(list(set(customer.loc[customer['acc_type']=='saving', 'cust_name']).intersection(set(customer.loc[customer['acc_type']=='checking', 'cust_name']))))"
find the name of customers who do not have an saving account.,"customer.loc[lambda x: x['acc_type']!='saving', 'cust_name']"
what are the names of customers who do not have saving accounts?,"customer.loc[lambda x: x['acc_type']!='saving', 'cust_name']"
find the name of customers who do not have a loan with a type of mortgages.,"customer.loc[~customer['cust_name'].isin(pd.merge(customer, loan.loc[loan['loan_type']=='mortgages'], on='cust_id', how='inner')['cust_name'])]['cust_name']"
what are the names of customers who have not taken a mortage loan?,"customer.loc[~customer['cust_name'].isin(pd.merge(customer, loan.loc[loan['loan_type']=='mortgages'], on='cust_id', how='inner')['cust_name'])]['cust_name']"
find the name of customers who have loans of both mortgages and auto.,"pd.merge(customer.loc[lambda x: x['loan_type']=='mortgages', ['cust_id', 'cust_name']],loan.loc[lambda x: x['loan_type']=='mortgages', ['cust_id']],on='cust_id')['cust_name'].rename_axis(none).isin(pd.merge(customer.loc[lambda x: x['loan_type']=='auto', ['cust_id', 'cust_name']],loan.loc[lambda x: x['loan_type']=='auto', ['cust_id']],on='cust_id')['cust_name'].values).replace({true: 'yes', false: 'no'}).rename('cust_name')"
what are the names of customers who have taken both mortgage and auto loans?,"pd.merge(customer.loc[lambda x: x['loan_type']=='mortgages', ['cust_id', 'cust_name']],loan.loc[lambda x: x['loan_type']=='mortgages', ['cust_id']],on='cust_id')['cust_name'].rename_axis(none).isin(pd.merge(customer.loc[lambda x: x['loan_type']=='auto', ['cust_id', 'cust_name']],loan.loc[lambda x: x['loan_type']=='auto', ['cust_id']],on='cust_id')['cust_name'].values).replace({true: 'yes', false: 'no'}).rename('cust_name')"
find the name of customers whose credit score is below the average credit scores of all customers.,"customer.loc[lambda x: x['credit_score'] < x['credit_score'].mean(), 'cust_name']"
what are the names of customers with credit score less than the average credit score across customers?,"customer.loc[lambda x: x['credit_score'] < x['credit_score'].mean(), 'cust_name']"
find the branch name of the bank that has the most number of customers.,"bank.sort_values('no_of_customers', ascending=false).iloc[0]['bname']"
what is the name of the bank branch with the greatest number of customers?,"bank.sort_values('no_of_customers', ascending=false).iloc[0]['bname']"
find the name of customer who has the lowest credit score.,customer.sort_values('credit_score').iloc[0]['cust_name']
what is the name of the customer with the worst credit score?,customer.sort_values('credit_score').iloc[0]['cust_name']
"find the name, account type, and account balance of the customer who has the highest credit score.","customer[['cust_name', 'acc_type', 'acc_bal']].sort_values('credit_score', ascending=false).head(1)"
"what is the name, account type, and account balance corresponding to the customer with the highest credit score?","customer[['cust_name', 'acc_type', 'acc_bal']].sort_values('credit_score', ascending=false).head(1)"
find the name of customer who has the highest amount of loans.,"pd.merge(customer, loan, on='cust_id').groupby('cust_name').agg(total_loan=('amount', 'sum')).sort_values('total_loan', ascending=false).iloc[0]['cust_name']"
what is the name of the customer who has greatest total loan amount?,"pd.merge(customer, loan, on='cust_id').groupby('cust_name').agg(total_loan=('amount', 'sum')).sort_values('total_loan', ascending=false).iloc[0]['cust_name']"
find the state which has the most number of customers.,bank.groupby('state')['no_of_customers'].sum().sort_values(ascending=false).reset_index().iloc[0]['state']
which state has the greatest total number of bank customers?,bank.groupby('state')['no_of_customers'].sum().sort_values(ascending=false).reset_index().iloc[0]['state']
"for each account type, find the average account balance of customers with credit score lower than 50.",customer.loc[lambda x: x['credit_score'] < 50].groupby('acc_type')['acc_bal'].mean()
what is the average account balance of customers with credit score below 50 for the different account types?,customer.loc[lambda x: x['credit_score'] < 50].groupby('acc_type')['acc_bal'].mean()
"for each state, find the total account balance of customers whose credit score is above 100.",customer.loc[lambda x: x['credit_score'] > 100].groupby('state')['acc_bal'].sum()
what is the total account balance for customers with a credit score of above 100 for the different states?,customer.loc[lambda x: x['credit_score'] > 100].groupby('state')['acc_bal'].sum()
find the total amount of loans offered by each bank branch.,"pd.merge(bank, loan, on='branch_id').groupby('bname')['amount'].sum()"
"what are the names of the different bank branches, and what are their total loan amounts?","pd.merge(bank, loan, on='branch_id').groupby('bname')['amount'].sum()"
find the name of customers who have more than one loan.,"customer.merge(loan, on='cust_id').groupby('cust_name').filter(lambda x: len(x) > 1)['cust_name'].unique()"
what are the names of customers who have taken out more than one loan?,"customer.merge(loan, on='cust_id').groupby('cust_name').filter(lambda x: len(x) > 1)['cust_name'].unique()"
find the name and account balance of the customers who have loans with a total amount of more than 5000.,"customer.merge(loan, on='cust_id').groupby(['cust_name', 'acc_type']).filter(lambda x: x['amount'].sum() > 5000).iloc[:, :2].drop_duplicates()"
what are the names and account balances for customers who have taken a total amount of more than 5000 in loans?,"customer.merge(loan, on='cust_id').groupby(['cust_name', 'acc_type']).filter(lambda x: x['amount'].sum() > 5000).iloc[:, :2].drop_duplicates()"
find the name of bank branch that provided the greatest total amount of loans.,"bank.merge(loan, on='branch_id').groupby('bname').agg({'amount': 'sum'}).sort_values('amount', ascending=false).iloc[:1].index.tolist()[0]"
what is the name of the bank branch that has lent the greatest amount?,"bank.merge(loan, on='branch_id').groupby('bname').agg({'amount': 'sum'}).sort_values('amount', ascending=false).iloc[:1].index.tolist()[0]"
find the name of bank branch that provided the greatest total amount of loans to customers with credit score is less than 100.,"loan.merge(bank, on='branch_id').merge(customer, on='cust_id').loc[lambda x: x['credit_score']<100].groupby('bname')['amount'].sum().sort_values(ascending=false).index[0]"
"what is the name of the bank branch that has lended the largest total amount in loans, specifically to customers with credit scores below 100?","loan.merge(bank, on='branch_id').merge(customer, on='cust_id').loc[lambda x: x['credit_score']<100].groupby('bname')['amount'].sum().sort_values(ascending=false).index[0]"
find the name of bank branches that provided some loans.,"pd.merge(bank, loan, on='branch_id')['bname'].unique()"
what are the names of the different banks that have provided loans?,"pd.merge(bank, loan, on='branch_id')['bname'].unique()"
find the name and credit score of the customers who have some loans.,"pd.merge(customer, loan, on='cust_id')[['cust_name', 'credit_score']].drop_duplicates()"
what are the different names and credit scores of customers who have taken a loan?,"pd.merge(customer, loan, on='cust_id')[['cust_name', 'credit_score']].drop_duplicates()"
find the the name of the customers who have a loan with amount more than 3000.,"pd.merge(customer, loan, on='cust_id').loc[lambda x: x['amount'] > 3000, 'cust_name']"
what are the names of customers who have a loan of more than 3000 in amount?,"pd.merge(customer, loan, on='cust_id').loc[lambda x: x['amount'] > 3000, 'cust_name']"
find the city and name of bank branches that provide business loans.,"pd.merge(bank, loan, on='branch_id').loc[lambda x: x['loan_type']=='business', ['bname', 'city']]"
what are the names and cities of bank branches that offer loans for business?,"pd.merge(bank, loan, on='branch_id').loc[lambda x: x['loan_type']=='business', ['bname', 'city']]"
find the names of bank branches that have provided a loan to any customer whose credit score is below 100.,"pd.merge(pd.merge(loan, bank, on='branch_id'), customer, on='cust_id').loc[lambda x: x['credit_score'] < 100, 'bname']"
what are the names of banks that have loaned money to customers with credit scores below 100?,"pd.merge(pd.merge(loan, bank, on='branch_id'), customer, on='cust_id').loc[lambda x: x['credit_score'] < 100, 'bname']"
find the total amount of loans provided by bank branches in the state of new york.,"pd.merge(bank, loan, on='branch_id').loc[lambda x: x['state']=='new york', 'amount'].sum()"
what is the total amount of money loaned by banks in new york state?,"pd.merge(bank, loan, on='branch_id').loc[lambda x: x['state']=='new york', 'amount'].sum()"
find the average credit score of the customers who have some loan.,"customer.loc[lambda x: x['cust_id'].isin(loan['cust_id']), 'credit_score'].mean()"
what is the average credit score for customers who have taken a loan?,"customer.loc[lambda x: x['cust_id'].isin(loan['cust_id']), 'credit_score'].mean()"
find the average credit score of the customers who do not have any loan.,"customer.loc[~customer['cust_id'].isin(loan['cust_id']), 'credit_score'].mean()"
what is the average credit score for customers who have never taken a loan?,"customer.loc[~customer['cust_id'].isin(loan['cust_id']), 'credit_score'].mean()"
how many assessment notes are there in total?,assessment_notes.shape[0]
what are the dates of the assessment notes?,assessment_notes['date_of_notes']
how many addresses have zip code 197?,(addresses['zip_postcode'] == '197').sum()
how many distinct incident type codes are there?,behavior_incident['incident_type_code'].nunique()
return all distinct detention type codes.,detention['detention_type_code'].unique()
"what are the start and end dates for incidents with incident type code ""noise""?","behavior_incident.loc[lambda x: x['incident_type_code']=='noise', ['date_incident_start', 'date_incident_end']]"
return all detention summaries.,detention['detention_summary']
return the cell phone number and email address for all students.,"students[['cell_mobile_number', 'email_address']]"
"what is the email of the student with first name ""emma"" and last name ""rohan""?","students.loc[(students['first_name'] == ""emma"") & (students['last_name'] == ""rohan""), 'email_address']"
how many distinct students have been in detention?,students_in_detention['student_id'].nunique()
"what is the gender of the teacher with last name ""medhurst""?","teachers.loc[lambda x: x['last_name']=='medhurst', 'gender']"
"what is the incident type description for the incident type with code ""violence""?","ref_incident_type.loc[lambda x: x['incident_type_code']=='violence', 'incident_type_description']"
find the maximum and minimum monthly rental for all student addresses.,"student_addresses['monthly_rental'].agg(['max', 'min'])"
"find the first names of teachers whose email address contains the word ""man"".","teachers.loc[teachers['email_address'].str.contains('man'), 'first_name']"
list all information about the assessment notes sorted by date in ascending order.,assessment_notes.sort_values('date_of_notes')
list all cities of addresses in alphabetical order.,addresses['city'].sort_values()
find the first names and last names of teachers in alphabetical order of last name.,"teachers[['first_name', 'last_name']].sort_values('last_name')"
"find all information about student addresses, and sort by monthly rental in descending order.","student_addresses.sort_values('monthly_rental', ascending=false)"
find the id and first name of the student that has the most number of assessment notes?,"pd.merge(assessment_notes, students, on='student_id').groupby('student_id').size().sort_values(ascending=false).head(1).reset_index()[['student_id', 'first_name']]"
find the ids and first names of the 3 teachers that have the most number of assessment notes?,"pd.merge(assessment_notes, teachers, on='teacher_id').groupby('teacher_id')['first_name'].count().sort_values(ascending=false)[:3].reset_index()"
find the id and last name of the student that has the most behavior incidents?,"behavior_incident.merge(students, on='student_id').groupby(['student_id', 'last_name']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['student_id', 'last_name']]"
"find the id and last name of the teacher that has the most detentions with detention type code ""after""?","pd.merge(detention.loc[detention['detention_type_code']=='after'].groupby('teacher_id').size().reset_index(name='count'), teachers, on='teacher_id').sort_values('count', ascending=false).iloc[0][['teacher_id', 'last_name']]"
what are the id and first name of the student whose addresses have the highest average monthly rental?,"pd.merge(student_addresses, students, on='student_id').groupby('student_id').agg({'first_name':'first', 'monthly_rental':'mean'}).sort_values('monthly_rental', ascending=false).iloc[0][['first_name', 'student_id']]"
find the id and city of the student address with the highest average monthly rental.,"addresses.merge(student_addresses, on='address_id').groupby('address_id').agg({'city':'first', 'monthly_rental':'mean'}).sort_values('monthly_rental', ascending=false).iloc[0]"
what are the code and description of the most frequent behavior incident type?,"pd.merge(behavior_incident, ref_incident_type, on='incident_type_code').groupby('incident_type_code')['incident_type_description'].count().sort_values(ascending=false).iloc[0:1]"
what are the code and description of the least frequent detention type ?,"pd.merge(detention, ref_detention_type, on='detention_type_code').groupby('detention_type_code').size().sort_values().head(1).reset_index()[['detention_type_code', 'detention_type_description']]"
"find the dates of assessment notes for students with first name ""fanny"".","pd.merge(assessment_notes, students, on='student_id').loc[lambda x: x['first_name']=='fanny', 'date_of_notes']"
"find the texts of assessment notes for teachers with last name ""schuster"".","pd.merge(assessment_notes, teachers.loc[lambda x: x['last_name'] == 'schuster', ['teacher_id']], on='teacher_id')['text_of_notes']"
"find the start and end dates of behavior incidents of students with last name ""fahey"".","pd.merge(behavior_incident, students, on='student_id').loc[lambda x: x['last_name']=='fahey', ['date_incident_start', 'date_incident_end']]"
"find the start and end dates of detentions of teachers with last name ""schultz"".","pd.merge(detention, teachers, on='teacher_id').query('last_name==""schultz""')[['datetime_detention_start', 'datetime_detention_end']]"
what are the id and zip code of the address with the highest monthly rental?,"pd.merge(addresses, student_addresses, on='address_id').sort_values('monthly_rental', ascending=false).iloc[0][['address_id', 'zip_postcode']]"
what is the cell phone number of the student whose address has the lowest monthly rental?,"pd.merge(student_addresses, students, on='student_id').sort_values('monthly_rental').iloc[0]['cell_mobile_number']"
what are the monthly rentals of student addresses in texas state?,"pd.merge(addresses, student_addresses, on='address_id').loc[lambda x: x['state_province_county'] == 'texas', 'monthly_rental']"
what are the first names and last names of students with address in wisconsin state?,"pd.merge(addresses, students, on='address_id').loc[lambda x: x['state_province_county']=='wisconsin', ['first_name', 'last_name']]"
what are the line 1 and average monthly rentals of all student addresses?,"pd.merge(addresses, student_addresses, on='address_id').groupby('address_id').agg({'line_1': 'first', 'monthly_rental': 'mean'})['line_1']"
"what is the zip code of the address where the teacher with first name ""lyla"" lives?","addresses.merge(teachers.loc[lambda x: x['first_name']=='lyla'], on='address_id')['zip_postcode']"
"what are the email addresses of teachers whose address has zip code ""918""?","pd.merge(addresses, teachers, on='address_id').loc[lambda x: x['zip_postcode']=='918', 'email_address']"
how many students are not involved in any behavior incident?,students[~students['student_id'].isin(behavior_incident['student_id'])].shape[0]
find the last names of teachers who are not involved in any detention.,teachers['last_name'].loc[~teachers['teacher_id'].isin(detention['teacher_id'])]
what are the line 1 of addresses shared by some students and some teachers?,"pd.merge(addresses, students, on='address_id')['line_1'].interesect(pd.merge(addresses, teachers, on='address_id')['line_1'])"
which assets have 2 parts and have less than 2 fault logs? list the asset id and detail.,"pd.merge(assets, asset_parts, on='asset_id').groupby(['asset_id', 'asset_details']).filter(lambda x: len(x) == 2).merge(pd.merge(assets, fault_log, on='asset_id').groupby(['asset_id', 'asset_details']).filter(lambda x: len(x) < 2), on=['asset_id', 'asset_details'])['asset_id']"
how many assets does each maintenance contract contain? list the number and the contract id.,"assets.merge(maintenance_contracts, on='maintenance_contract_id').groupby('maintenance_contract_id').size().reset_index(name='count')"
how many assets does each third party company supply? list the count and the company id.,"assets.merge(third_party_companies, left_on='supplier_company_id', right_on='company_id').groupby('company_id').size().reset_index(name='count')"
which third party companies have at least 2 maintenance engineers or have at least 2 maintenance contracts? list the company id and name.,"pd.concat([third_party_companies.merge(maintenance_engineers, on='company_id').groupby(['company_id', 'company_name']).filter(lambda x: len(x)>=2), third_party_companies.merge(maintenance_contracts, left_on='company_id', right_on='maintenance_contract_company_id').groupby(['company_id', 'company_name']).filter(lambda x: len(x)>=2)] ).drop_duplicates(subset=['company_id', 'company_name'])[['company_id', 'company_name']]"
what is the name and id of the staff who recorded the fault log but has not contacted any visiting engineers?,"pd.merge(staff, fault_log, left_on='staff_id', right_on='recorded_by_staff_id')[['staff_name', 'staff_id']].drop_duplicates().merge(pd.merge(staff, engineer_visits, left_on='staff_id', right_on='contact_staff_id')[['staff_name', 'staff_id']].drop_duplicates(), how='left', on=['staff_name', 'staff_id'], indicator=true).loc[lambda x: x['_merge']=='left_only', ['staff_name', 'staff_id']].reset_index(drop=true)"
"which engineer has visited the most times? show the engineer id, first name and last name.","pd.merge(maintenance_engineers, engineer_visits).groupby(['engineer_id', 'first_name', 'last_name']).size().sort_values(ascending=false).reset_index().iloc[0, :3]"
which parts have more than 2 faults? show the part name and id.,"parts.merge(part_faults, on='part_id').groupby(['part_name', 'part_id']).filter(lambda x: len(x) > 2)[['part_name', 'part_id']].drop_duplicates()"
"list all every engineer's first name, last name, details and coresponding skill description.","pd.merge(pd.merge(maintenance_engineers, engineer_skills, on='engineer_id'), skills, on='skill_id')[['first_name', 'last_name', 'other_details', 'skill_description']]"
"for all the faults of different parts, what are all the decriptions of the skills required to fix them? list the name of the faults and the skill description.","pd.merge(pd.merge(part_faults, skills_required_to_fix, on='part_fault_id'), skills, on='skill_id')[['fault_short_name', 'skill_description']]"
how many assets can each parts be used in? list the part name and the number.,"asset_parts.merge(parts, on='part_id').groupby('part_name').size().reset_index(name='count')[['part_name', 'count']]"
what are all the fault descriptions and the fault status of all the faults recoreded in the logs?,"pd.merge(fault_log, fault_log_parts, on='fault_log_entry_id')[['fault_description', 'fault_status']]"
how many engineer visits are required at most for a single fault log? list the number and the log entry id.,"pd.merge(fault_log, engineer_visits, on='fault_log_entry_id').groupby('fault_log_entry_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
what are all the distinct last names of all the engineers?,maintenance_engineers['last_name'].unique()
how many fault status codes are recorded in the fault log parts table?,fault_log_parts['fault_status'].unique()
which engineers have never visited to maintain the assets? list the engineer first name and last name.,"maintenance_engineers[~maintenance_engineers['engineer_id'].isin(engineer_visits['engineer_id'])][['first_name', 'last_name']]"
"list the asset id, details, make and model for every asset.","assets[['asset_id', 'asset_details', 'asset_make', 'asset_model']]"
when was the first asset acquired?,assets.sort_values('asset_acquired_date').iloc[0]['asset_acquired_date']
which part fault requires the most number of skills to fix? list part id and name.,"(parts.merge(part_faults, on='part_id').merge(skills_required_to_fix, on='part_fault_id').groupby(['part_id', 'part_name'])['part_fault_id'].count().reset_index().sort_values(['part_fault_id', 'part_id'], ascending=[false, true]).iloc[:1, :2])"
which kind of part has the least number of faults? list the part name.,"(pd.merge(parts, part_faults, on='part_id').groupby('part_name').size().sort_values().index[0])"
"among those engineers who have visited, which engineer makes the least number of visits? list the engineer id, first name and last name.","pd.merge(maintenance_engineers, engineer_visits, on='engineer_id').groupby(['engineer_id', 'first_name', 'last_name']).size().sort_values().reset_index().iloc[0][['engineer_id', 'first_name', 'last_name']]"
which staff have contacted which engineers? list the staff name and the engineer first name and last name.,"pd.merge(pd.merge(staff, engineer_visits, left_on='staff_id', right_on='contact_staff_id'), maintenance_engineers, on='engineer_id')[['staff_name', 'first_name', 'last_name']]"
"which fault log included the most number of faulty parts? list the fault log id, description and record time.","fault_log.groupby(['fault_log_entry_id', 'fault_description', 'fault_log_entry_datetime']).size().sort_values(ascending=false).reset_index().iloc[0][['fault_log_entry_id', 'fault_description', 'fault_log_entry_datetime']]"
which skill is used in fixing the most number of faults? list the skill id and description.,"skills.merge(skills_required_to_fix, on='skill_id').groupby(['skill_id','skill_description']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['skill_id','skill_description']]"
what are all the distinct asset models?,assets['asset_model'].unique()
"list the all the assets make, model, details by the disposed date ascendingly.","assets.sort_values('asset_disposed_date')[['asset_make', 'asset_model', 'asset_details']]"
which part has the least chargeable amount? list the part id and amount.,"parts[['part_id', 'chargeable_amount']].sort_values('chargeable_amount').iloc[0]"
which company started the earliest the maintenance contract? show the company name.,"pd.merge(third_party_companies, maintenance_contracts.rename(columns={'maintenance_contract_company_id': 'company_id'}), on='company_id').sort_values('contract_start_date').iloc[0]['company_name']"
what is the description of the type of the company who concluded its contracts most recently?,"pd.merge(pd.merge(third_party_companies, maintenance_contracts, left_on='company_id', right_on='maintenance_contract_company_id'), ref_company_types, on='company_type_code').sort_values('contract_end_date', ascending=false).iloc[0]['company_name']"
which gender makes up the majority of the staff?,staff.groupby('gender').size().sort_values(ascending=false).index[0]
how many engineers did each staff contact? list both the contact staff name and number of engineers contacted.,"engineer_visits.merge(staff, left_on='contact_staff_id', right_on='staff_id').groupby('staff_name').size().reset_index(name='count')"
which assets did not incur any fault log? list the asset model.,"assets.loc[~assets['asset_id'].isin(fault_log['asset_id']), 'asset_model']"
list the local authorities and services provided by all stations.,"station[['local_authority', 'services']]"
show all train numbers and names ordered by their time from early to late.,"train.sort_values('time')[['train_number', 'name']]"
"give me the times and numbers of all trains that go to chennai, ordered by time.","train.loc[train['destination']=='chennai'].sort_values('time')[['time', 'train_number']]"
how many trains have 'express' in their names?,train['name'].str.contains('express').sum()
find the number and time of the train that goes from chennai to guruvayur.,"train.loc[(train['origin']=='chennai') & (train['destination']=='guruvayur'), ['train_number', 'time']]"
find the number of trains starting from each origin.,train.groupby('origin').size()
find the name of the train whose route runs through greatest number of stations.,"pd.merge(train, route, on='id').groupby('train_id')['name'].count().idxmax()"
"find the number of trains for each station, as well as the station network name and services.","station.merge(route, on='id').groupby('station_id').agg({'network_name':'first', 'services':'first', 'id':'count'})"
what is the average high temperature for each day of week?,weekly_weather.groupby('day_of_week')['high_temperature'].mean()
give me the maximum low temperature and average precipitation at the amersham station.,"pd.merge(weekly_weather, station, left_on='station_id', right_on='id').loc[lambda x: x['network_name']=='amersham'].agg({'low_temperature': 'max', 'precipitation': 'mean'})"
find names and times of trains that run through stations for the local authority chiltern.,"pd.merge(pd.merge(station, route, on='id'), train, on='train_id').loc[lambda x: x['local_authority']=='chiltern', ['name', 'time']]"
how many different services are provided by all stations?,station['services'].nunique()
find the id and local authority of the station with has the highest average high temperature.,"pd.merge(weekly_weather, station, left_on='station_id', right_on='id').groupby('station_id').agg({'id': 'first', 'local_authority': 'first', 'high_temperature': 'mean'}).sort_values('high_temperature', ascending=false).iloc[0, ['id', 'local_authority']]"
find the id and local authority of the station whose maximum precipitation is higher than 50.,"weekly_weather.merge(station, left_on='station_id', right_on='id').groupby('station_id').filter(lambda x: x['precipitation'].max() > 50)[['id', 'local_authority']]"
show the lowest low temperature and highest wind speed in miles per hour.,"weekly_weather.agg({'low_temperature': 'min', 'wind_speed_mph': 'max'})"
find the origins from which more than 1 train starts.,train.groupby('origin').filter(lambda x: len(x) > 1)['origin'].unique()
find the number of professors in accounting department.,"pd.merge(professor, department, on='dept_code').loc[lambda x: x['dept_name']=='accounting'].shape[0]"
how many professors are in the accounting dept?,"pd.merge(professor, department, on='dept_code').loc[lambda x: x['dept_name']=='accounting'].shape[0]"
how many professors are teaching class with code acct-211?,"class.loc[lambda x: x['crs_code']=='acct-211', 'prof_num'].nunique()"
how many professors teach a class with the code acct-211?,"class.loc[lambda x: x['crs_code']=='acct-211', 'prof_num'].nunique()"
what is the first and last name of the professor in biology department?,"pd.merge(pd.merge(professor, department, on='dept_code'), employee, on='emp_num').loc[lambda x: x['dept_name']=='biology', ['emp_fname', 'emp_lname']]"
what are the first and last name of all biology professors?,"pd.merge(pd.merge(professor, department, on='dept_code'), employee, on='emp_num').loc[lambda x: x['dept_name']=='biology', ['emp_fname', 'emp_lname']]"
what are the first names and date of birth of professors teaching course acct-211?,"pd.merge(employee, class_, left_on='emp_num', right_on='prof_num').loc[lambda x: x['crs_code']=='acct-211', ['emp_fname', 'emp_dob']].drop_duplicates()"
what are the first names and birthdates of the professors in charge of acct-211?,"pd.merge(employee, class_, left_on='emp_num', right_on='prof_num').loc[lambda x: x['crs_code']=='acct-211', ['emp_fname', 'emp_dob']].drop_duplicates()"
how many classes are professor whose last name is graztevski has?,"pd.merge(employee, class, left_on='emp_num', right_on='prof_num').loc[lambda x: x['emp_lname']=='graztevski'].shape[0]"
how many classes does the professor whose last name is graztevski teach?,"pd.merge(employee, class, left_on='emp_num', right_on='prof_num').loc[lambda x: x['emp_lname']=='graztevski'].shape[0]"
what is the code of the school where the accounting department belongs to?,"department.loc[lambda x: x['dept_name']=='accounting', 'school_code']"
what is the school code of the accounting department?,"department.loc[lambda x: x['dept_name']=='accounting', 'school_code']"
"how many credits does course cis-220 have, and what its description?","course.loc[course['crs_code'] == 'cis-220', ['crs_credit', 'crs_description']]"
what is the description for the cis-220 and how many credits does it have?,"course.loc[course['crs_code'] == 'cis-220', ['crs_credit', 'crs_description']]"
what is the address of history department?,"department.loc[lambda x: x['dept_name']=='history', 'dept_address']"
where is the history department?,"department.loc[lambda x: x['dept_name']=='history', 'dept_address']"
how many different locations does the school with code bus has?,"department.loc[lambda x: x['school_code']=='bus', 'dept_address'].nunique()"
what are the different locations of the school with the code bus?,"department.loc[lambda x: x['school_code']=='bus', 'dept_address'].nunique()"
how many different locations does each school have?,department.groupby('school_code')['dept_address'].nunique()
count different addresses of each school.,department.groupby('school_code')['dept_address'].nunique()
find the description and credit for the course qm-261?,"course.loc[lambda x: x['crs_code']=='qm-261', ['crs_credit', 'crs_description']]"
what is the course description and number of credits for qm-261?,"course.loc[lambda x: x['crs_code']=='qm-261', ['crs_credit', 'crs_description']]"
find the number of departments in each school.,department.groupby('school_code')['dept_name'].nunique().reset_index().rename(columns={'dept_name': 'count'})
how many departments are in each school?,department.groupby('school_code')['dept_name'].nunique().reset_index().rename(columns={'dept_name': 'count'})
find the number of different departments in each school whose number of different departments is less than 5.,"department.groupby('school_code').agg({'dept_name': 'nunique'}).reset_index().rename(columns={'dept_name': 'unique_dept_count'}).loc[lambda x: x['unique_dept_count'] < 5].agg({'unique_dept_count': 'count', 'school_code': 'first'})"
how many different departments are there in each school that has less than 5 apartments?,"department.groupby('school_code').agg({'dept_name': 'nunique'}).reset_index().rename(columns={'dept_name': 'unique_dept_count'}).loc[lambda x: x['unique_dept_count'] < 5].agg({'unique_dept_count': 'count', 'school_code': 'first'})"
how many sections does each course has?,class.groupby('crs_code').size().reset_index(name='count')
how many sections does each course have?,class.groupby('crs_code').size().reset_index(name='count')
what is the total credit does each department offer?,course.groupby('dept_code')['crs_credit'].sum()
how many credits does the department offer?,course.groupby('dept_code')['crs_credit'].sum()
find the number of classes offered for all class rooms that held at least 2 classes.,class.groupby('class_room').filter(lambda x: len(x) >=2).groupby('class_room').size().reset_index(name='count(*)')
"for each classroom with at least 2 classes, how many classes are offered?",class.groupby('class_room').filter(lambda x: len(x) >=2).groupby('class_room').size().reset_index(name='count(*)')
find the number of classes in each department.,"pd.merge(class, course, on='crs_code').groupby('dept_code').size().reset_index(name='count')"
how many classes are held in each department?,"pd.merge(class, course, on='crs_code').groupby('dept_code').size().reset_index(name='count')"
find the number of classes in each school.,"pd.merge(pd.merge(class, course, on='crs_code'), department, on='dept_code').groupby('school_code').size().reset_index(name='count')"
how many classes exist for each school?,"pd.merge(pd.merge(class, course, on='crs_code'), department, on='dept_code').groupby('school_code').size().reset_index(name='count')"
what is the number of professors for different school?,"pd.merge(department, professor, on='dept_code').groupby('school_code').size().reset_index(name='count')"
how many different professors are there for the different schools?,"pd.merge(department, professor, on='dept_code').groupby('school_code').size().reset_index(name='count')"
find the count and code of the job has most employees.,employee.groupby('emp_jobcode').size().sort_values(ascending=false).head(1)
what is the count and code of the job with the most employee?,employee.groupby('emp_jobcode').size().sort_values(ascending=false).head(1)
which school has the smallest amount of professors?,"pd.merge(department, professor, on='dept_code').groupby('school_code')['dept_code'].count().sort_values().index[0]"
which school has the fewest professors?,"pd.merge(department, professor, on='dept_code').groupby('school_code')['dept_code'].count().sort_values().index[0]"
find the number of professors with a ph.d. degree in each department.,professor.loc[lambda x: x['prof_high_degree']=='ph.d.'].groupby('dept_code').size().reset_index(name='count')
how many professors have a ph.d. in each department?,professor.loc[lambda x: x['prof_high_degree']=='ph.d.'].groupby('dept_code').size().reset_index(name='count')
find the number of students for each department.,student.groupby('dept_code').size().reset_index(name='count')
find the total number of hours have done for all students in each department.,student.groupby('dept_code')['stu_hrs'].sum()
how many hours do the students spend studying in each department?,student.groupby('dept_code')['stu_hrs'].sum()
"find the max, average, and minimum gpa of all students in each department.","student.groupby('dept_code')['stu_gpa'].agg(['max', 'mean', 'min']).reset_index()"
"what is the highest, lowest, and average student gpa for every department?","student.groupby('dept_code')['stu_gpa'].agg(['max', 'mean', 'min']).reset_index()"
what is the name and the average gpa of department whose students have the highest average gpa?,"student.merge(department, on='dept_code').groupby('dept_name')['stu_gpa'].mean().sort_values(ascending=false).head(1).reset_index()"
"which department has the highest average student gpa, and what is the average gpa?","student.merge(department, on='dept_code').groupby('dept_name')['stu_gpa'].mean().sort_values(ascending=false).head(1).reset_index()"
how many schools exist in total?,department['school_code'].nunique()
how many schools are there in the department?,department['school_code'].nunique()
how many different classes are there?,class['class_code'].nunique()
how many unique classes are offered?,class['class_code'].nunique()
how many courses are offered?,class['crs_code'].nunique()
what are the number of different course codes?,class['crs_code'].nunique()
how many departments does the college has?,department['dept_name'].nunique()
how many different departments are there?,department['dept_name'].nunique()
how many courses are offered by the computer info. systems department?,"pd.merge(department.loc[lambda x: x['dept_name'] == ""computer info. systems""], course, on='dept_code').shape[0]"
how many courses does the department of computer information systmes offer?,"pd.merge(department.loc[lambda x: x['dept_name'] == ""computer info. systems""], course, on='dept_code').shape[0]"
how many sections does course acct-211 has?,"class.loc[lambda x: x['crs_code']=='acct-211', 'class_section'].nunique()"
what is the number of different class sections offered in the course acct-211?,"class.loc[lambda x: x['crs_code']=='acct-211', 'class_section'].nunique()"
find the total credits of all classes offered by each department.,"pd.merge(course, class, on='crs_code').groupby('dept_code')['crs_credit'].sum()"
what are the total number of credits offered by each department?,"pd.merge(course, class, on='crs_code').groupby('dept_code')['crs_credit'].sum()"
find the name of the department that offers the largest number of credits of all classes.,"pd.merge(pd.merge(course, class_, on='crs_code'), department, on='dept_code').groupby('dept_name').agg(total_credit=('crs_credit','sum')).sort_values('total_credit', ascending=false).head(1).index.values[0]"
which department offers the most credits all together?,"pd.merge(pd.merge(course, class_, on='crs_code'), department, on='dept_code').groupby('dept_name').agg(total_credit=('crs_credit','sum')).sort_values('total_credit', ascending=false).head(1).index.values[0]"
how many students enrolled in class acct-211?,"pd.merge(class, enroll, on='class_code').loc[lambda x: x['crs_code']=='acct-211'].shape[0]"
what are the total number of students enrolled in acct-211?,"pd.merge(class, enroll, on='class_code').loc[lambda x: x['crs_code']=='acct-211'].shape[0]"
what is the first name of each student enrolled in class acct-211?,"pd.merge(pd.merge(class.loc[lambda x: x['crs_code']=='acct-211'], enroll, on='class_code'), student, on='stu_num')['stu_fname']"
what are the first names of all students in course acct-211?,"pd.merge(pd.merge(class.loc[lambda x: x['crs_code']=='acct-211'], enroll, on='class_code'), student, on='stu_num')['stu_fname']"
what is the first name of students enrolled in class acct-211 and got grade c?,"pd.merge(pd.merge(students, enroll, on='stu_num'), classes, on='class_code').loc[(lambda x: (x['enroll_grade'] == 'c') & (x['crs_code'] == 'acct-211')), 'stu_fname']"
what are the first names of all students who took acct-211 and received a c?,"pd.merge(pd.merge(students, enroll, on='stu_num'), classes, on='class_code').loc[(lambda x: (x['enroll_grade'] == 'c') & (x['crs_code'] == 'acct-211')), 'stu_fname']"
find the total number of employees.,employee.shape[0]
how many employees are there all together?,employee.shape[0]
how many professors do have a ph.d. degree?,(professor['prof_high_degree']=='ph.d.').sum()
what is the total number of professors with a ph.d. ?,(professor['prof_high_degree']=='ph.d.').sum()
how many students are enrolled in the class taught by some professor from the accounting department?,"(pd.merge(pd.merge(pd.merge(class, enroll, on='class_code'), course, on='crs_code'), department, on='dept_code').loc[lambda x: x['dept_name']=='accounting'].shape[0])"
how many students are enrolled in some classes that are taught by an accounting professor?,"(pd.merge(pd.merge(pd.merge(class, enroll, on='class_code'), course, on='crs_code'), department, on='dept_code').loc[lambda x: x['dept_name']=='accounting'].shape[0])"
what is the name of the department that has the largest number of students enrolled?,"(pd.merge(pd.merge(pd.merge(class, enroll, on='class_code'), course, on='crs_code'), department, on='dept_code').groupby('dept_name').size().sort_values(ascending=false).reset_index().loc[0,'dept_name'])"
what is the name of the department with the most students enrolled?,"(pd.merge(pd.merge(pd.merge(class, enroll, on='class_code'), course, on='crs_code'), department, on='dept_code').groupby('dept_name').size().sort_values(ascending=false).reset_index().loc[0,'dept_name'])"
list names of all departments ordered by their names.,department.sort_values('dept_name')['dept_name']
what are the names of all departments in alphabetical order?,department.sort_values('dept_name')['dept_name']
list the codes of all courses that take place in room klr209.,"class.loc[lambda x: x['class_room']=='klr209', 'class_code']"
what are the codes of all the courses that are located in room klr209?,"class.loc[lambda x: x['class_room']=='klr209', 'class_code']"
list the first name of all employees with job code prof ordered by their date of birth.,employee.loc[employee['emp_jobcode']=='prof'].sort_values('emp_dob')['emp_fname']
what are the first names of all employees that are professors ordered by date of birth?,employee.loc[employee['emp_jobcode']=='prof'].sort_values('emp_dob')['emp_fname']
find the first names and offices of all professors sorted by alphabetical order of their first name.,"pd.merge(professor, employee, on='emp_num').sort_values('emp_fname')[['emp_fname', 'prof_office']]"
what are the first names and office locations for all professors sorted alphabetically by first name?,"pd.merge(professor, employee, on='emp_num').sort_values('emp_fname')[['emp_fname', 'prof_office']]"
what is the first and last name of the oldest employee?,"employee[['emp_fname', 'emp_lname']].sort_values('emp_dob').head(1)"
what are the first and last names of the employee with the earliest date of birth?,"employee[['emp_fname', 'emp_lname']].sort_values('emp_dob').head(1)"
"what is the first, last name, gpa of the youngest one among students whose gpa is above 3?","student.loc[lambda x: x['stu_gpa'] > 3, ['stu_fname', 'stu_lname', 'stu_gpa', 'stu_dob']].sort_values('stu_dob', ascending=false).head(1)[['stu_fname', 'stu_lname', 'stu_gpa']]"
"what is the first and last name of the youngest student with a gpa above 3, and what is their gpa?","student.loc[lambda x: x['stu_gpa'] > 3, ['stu_fname', 'stu_lname', 'stu_gpa', 'stu_dob']].sort_values('stu_dob', ascending=false).head(1)[['stu_fname', 'stu_lname', 'stu_gpa']]"
what is the first name of students who got grade c in any class?,"pd.merge(student, enroll, on='stu_num').loc[lambda x: x['enroll_grade']=='c', 'stu_fname'].unique()"
what are the first names of all students who got a grade c in a class?,"pd.merge(student, enroll, on='stu_num').loc[lambda x: x['enroll_grade']=='c', 'stu_fname'].unique()"
what is the name of department where has the smallest number of professors?,"pd.merge(professor, department, on='dept_code').groupby('dept_code')['dept_name'].count().sort_values().head(1)"
what is the name of the department with the fewest professors?,"pd.merge(professor, department, on='dept_code').groupby('dept_code')['dept_name'].count().sort_values().head(1)"
what is the name of department where has the largest number of professors with a ph.d. degree?,"professor.merge(department, on='dept_code').loc[lambda x: x['prof_high_degree']=='ph.d.'].groupby('dept_code')['dept_name'].count().reset_index().rename(columns={'dept_name': 'count'}).sort_values('count', ascending=false).iloc[0][['dept_name', 'dept_code']]"
which department has the most professors with a ph.d.?,"professor.merge(department, on='dept_code').loc[lambda x: x['prof_high_degree']=='ph.d.'].groupby('dept_code')['dept_name'].count().reset_index().rename(columns={'dept_name': 'count'}).sort_values('count', ascending=false).iloc[0][['dept_name', 'dept_code']]"
what are the first names of the professors who do not teach a class.,"employee.loc[lambda x: (x['emp_jobcode']=='prof') & (~x['emp_num'].isin(class['prof_num'])), 'emp_fname']"
what are the first names of all professors not teaching any classes?,"employee.loc[lambda x: (x['emp_jobcode']=='prof') & (~x['emp_num'].isin(class['prof_num'])), 'emp_fname']"
what is the first names of the professors from the history department who do not teach a class.,"employee.merge(professor, on='emp_num').merge(department, on='dept_code').query('dept_name==""history""')['emp_fname'].unique().difference(employee.merge(class, left_on='emp_num', right_on='prof_num')['emp_fname'])"
what are the first names of all history professors who do not teach?,"employee.merge(professor, on='emp_num').merge(department, on='dept_code').query('dept_name==""history""')['emp_fname'].unique().difference(employee.merge(class, left_on='emp_num', right_on='prof_num')['emp_fname'])"
what is the last name and office of the professor from the history department?,"pd.merge(pd.merge(employee, professor, on='emp_num'), department, on='dept_code').loc[lambda x: x['dept_name']=='history', ['emp_lname', 'prof_office']]"
what are the last name and office of all history professors?,"pd.merge(pd.merge(employee, professor, on='emp_num'), department, on='dept_code').loc[lambda x: x['dept_name']=='history', ['emp_lname', 'prof_office']]"
what is department name and office for the professor whose last name is heffington?,"pd.merge(pd.merge(employee, professor, on='emp_num'), department, on='dept_code').loc[lambda x: x['emp_lname']=='heffington', ['dept_name', 'prof_office']]"
what is the name of the department and office location for the professor with the last name of heffington?,"pd.merge(pd.merge(employee, professor, on='emp_num'), department, on='dept_code').loc[lambda x: x['emp_lname']=='heffington', ['dept_name', 'prof_office']]"
find the last name and hire date of the professor who is in office dre 102.,"pd.merge(employee, professor, on='emp_num').loc[lambda x: x['prof_office']=='dre 102', ['emp_lname', 'emp_hiredate']]"
"what is the last name of the professor whose office is located in dre 102, and when were they hired?","pd.merge(employee, professor, on='emp_num').loc[lambda x: x['prof_office']=='dre 102', ['emp_lname', 'emp_hiredate']]"
what is the code of the course which the student whose last name is smithson took?,"pd.merge(pd.merge(class, enroll, on='class_code'), student, on='stu_num').loc[lambda x: x['stu_lname']=='smithson', 'crs_code']"
what are the course codes for every class that the student with the last name smithson took?,"pd.merge(pd.merge(class, enroll, on='class_code'), student, on='stu_num').loc[lambda x: x['stu_lname']=='smithson', 'crs_code']"
what are the description and credit of the course which the student whose last name is smithson took?,"pd.merge(pd.merge(pd.merge(student.loc[lambda x: x['stu_lname']=='smithson'], enroll, on='stu_num'), class, on='class_code'), course, on='crs_code')[['crs_description', 'crs_credit']]"
"how many credits is the course that the student with the last name smithson took, and what is its description?","pd.merge(pd.merge(pd.merge(student.loc[lambda x: x['stu_lname']=='smithson'], enroll, on='stu_num'), class, on='class_code'), course, on='crs_code')[['crs_description', 'crs_credit']]"
how many professors who has a either ph.d. or ma degree?,"professor.loc[lambda x: x['prof_high_degree'].isin(['ph.d.', 'ma'])].shape[0]"
how many professors attained either ph.d. or masters degrees?,"professor.loc[lambda x: x['prof_high_degree'].isin(['ph.d.', 'ma'])].shape[0]"
how many professors who are from either accounting or biology department?,"pd.merge(professor, department, on='dept_code').loc[lambda x: x['dept_name'].isin(['accounting', 'biology'])].shape[0]"
what is the number of professors who are in the accounting or biology departments?,"pd.merge(professor, department, on='dept_code').loc[lambda x: x['dept_name'].isin(['accounting', 'biology'])].shape[0]"
find the first name of the professor who is teaching two courses with code cis-220 and qm-261.,"pd.merge(employee[employee['emp_num'].isin(classroom[classroom['crs_code']=='cis-220']['prof_num'].unique())]['emp_fname'], employee[employee['emp_num'].isin(classroom[classroom['crs_code']=='qm-261']['prof_num'].unique())]['emp_fname'])"
what is the first name of the professor who is teaching cis-220 and qm-261?,"pd.merge(employee[employee['emp_num'].isin(classroom[classroom['crs_code']=='cis-220']['prof_num'].unique())]['emp_fname'], employee[employee['emp_num'].isin(classroom[classroom['crs_code']=='qm-261']['prof_num'].unique())]['emp_fname'])"
find the first name of student who is taking classes from accounting and computer info. systems departments,"pd.merge(pd.merge(pd.merge(pd.merge(student, enroll, on='stu_num'), class, on='class_code'), course, on='crs_code'), department, on='dept_code').loc[lambda x: x['dept_name']=='accounting', 'stu_fname'].unique() & pd.merge(pd.merge(pd.merge(pd.merge(student, enroll, on='stu_num'), class, on='class_code'), course, on='crs_code'), department, on='dept_code').loc[lambda x: x['dept_name']=='computer info. systems', 'stu_fname'].unique()"
what are the first names of all students taking accoutning and computer information systems classes?,"pd.merge(pd.merge(pd.merge(pd.merge(student, enroll, on='stu_num'), class, on='class_code'), course, on='crs_code'), department, on='dept_code').loc[lambda x: x['dept_name']=='accounting', 'stu_fname'].unique() & pd.merge(pd.merge(pd.merge(pd.merge(student, enroll, on='stu_num'), class, on='class_code'), course, on='crs_code'), department, on='dept_code').loc[lambda x: x['dept_name']=='computer info. systems', 'stu_fname'].unique()"
what is the average gpa of the students enrolled in the course with code acct-211?,"enroll.merge(student, on='stu_num').merge(class, on='class_code').loc[lambda x: x['crs_code']=='acct-211', 'stu_gpa'].mean()"
what is the average gpa of students taking acct-211?,"enroll.merge(student, on='stu_num').merge(class, on='class_code').loc[lambda x: x['crs_code']=='acct-211', 'stu_gpa'].mean()"
"what is the first name, gpa and phone number of the top 5 students with highest gpa?","student[['stu_gpa', 'stu_phone', 'stu_fname']].sort_values('stu_gpa', ascending=false).head(5)"
"what is the first name, gpa, and phone number of the students with the top 5 gpas?","student[['stu_gpa', 'stu_phone', 'stu_fname']].sort_values('stu_gpa', ascending=false).head(5)"
what is the department name of the students with lowest gpa belongs to?,"pd.merge(student, department, on='dept_code').sort_values('stu_gpa').iloc[0]['dept_name']"
what is the name of the department with the student that has the lowest gpa?,"pd.merge(student, department, on='dept_code').sort_values('stu_gpa').iloc[0]['dept_name']"
find the first name and gpa of the students whose gpa is lower than the average gpa of all students.,"student.loc[lambda x: x['stu_gpa'] < student['stu_gpa'].mean(), ['stu_fname', 'stu_gpa']]"
what is the first name and gpa of every student that has a gpa lower than average?,"student.loc[lambda x: x['stu_gpa'] < student['stu_gpa'].mean(), ['stu_fname', 'stu_gpa']]"
find the name and address of the department that has the highest number of students.,"student.merge(department, on='dept_code').groupby('dept_code')[['dept_name', 'dept_address']].first().nlargest(1, 'dept_code').reset_index(drop=true)"
what is the name and address of the department with the most students?,"student.merge(department, on='dept_code').groupby('dept_code')[['dept_name', 'dept_address']].first().nlargest(1, 'dept_code').reset_index(drop=true)"
"find the name, address, number of students in the departments that have the top 3 highest number of students.","student.merge(department, on='dept_code').groupby(['dept_name', 'dept_address'])['dept_code'].count().sort_values(ascending=false).head(3).reset_index()"
"what is the name, address, and number of students in the departments that have the 3 most students?","student.merge(department, on='dept_code').groupby(['dept_name', 'dept_address'])['dept_code'].count().sort_values(ascending=false).head(3).reset_index()"
find the first name and office of the professor who is in the history department and has a ph.d. degree.,"employee.merge(professor, on='emp_num').merge(department, on='dept_code').loc[lambda x: (x['dept_name']=='history') & (x['prof_high_degree']=='ph.d.'), ['emp_fname', 'prof_office']]"
what are the first names and office of the professors who are in the history department and have a ph.d?,"employee.merge(professor, on='emp_num').merge(department, on='dept_code').loc[lambda x: (x['dept_name']=='history') & (x['prof_high_degree']=='ph.d.'), ['emp_fname', 'prof_office']]"
find the first names of all instructors who have taught some course and the course code.,"pd.merge(class, employee, left_on='prof_num', right_on='emp_num')[['emp_fname', 'crs_code']]"
what are the first names of all teachers who have taught a course and the corresponding course codes?,"pd.merge(class, employee, left_on='prof_num', right_on='emp_num')[['emp_fname', 'crs_code']]"
find the first names of all instructors who have taught some course and the course description.,"pd.merge(pd.merge(class, employee, left_on='prof_num', right_on='emp_num'), course, on='crs_code')[['emp_fname', 'crs_description']]"
what are the first names of all teachers who have taught a course and the corresponding descriptions?,"pd.merge(pd.merge(class, employee, left_on='prof_num', right_on='emp_num'), course, on='crs_code')[['emp_fname', 'crs_description']]"
find the first names and offices of all instructors who have taught some course and also find the course description.,"pd.merge(pd.merge(pd.merge(class, employee, left_on='prof_num', right_on='emp_num'), course, on='crs_code'), professor, on='emp_num')[['emp_fname', 'prof_office', 'crs_description']]"
"what are the first names, office locations of all lecturers who have taught some course?","pd.merge(pd.merge(pd.merge(class, employee, left_on='prof_num', right_on='emp_num'), course, on='crs_code'), professor, on='emp_num')[['emp_fname', 'prof_office', 'crs_description']]"
find the first names and offices of all instructors who have taught some course and the course description and the department name.,"pd.merge(pd.merge(pd.merge(pd.merge(class, employee, left_on='prof_num', right_on='emp_num'), course, on='crs_code'), professor, left_on='emp_num_y', right_on='emp_num'), department, on='dept_code')[['emp_fname', 'prof_office', 'crs_description', 'dept_name']]"
"what are the first names, office locations, and departments of all instructors, and also what are the descriptions of the courses they teach?","pd.merge(pd.merge(pd.merge(pd.merge(class, employee, left_on='prof_num', right_on='emp_num'), course, on='crs_code'), professor, left_on='emp_num_y', right_on='emp_num'), department, on='dept_code')[['emp_fname', 'prof_office', 'crs_description', 'dept_name']]"
find names of all students who took some course and the course description.,"pd.merge(pd.merge(pd.merge(student, enroll, on='stu_num'), class, on='class_code'), course, on='crs_code')[['stu_fname', 'stu_lname', 'crs_description']]"
what are the names of all students who took a class and the corresponding course descriptions?,"pd.merge(pd.merge(pd.merge(student, enroll, on='stu_num'), class, on='class_code'), course, on='crs_code')[['stu_fname', 'stu_lname', 'crs_description']]"
find names of all students who took some course and got a or c.,"student.merge(enroll, on='stu_num').loc[lambda x: x['enroll_grade'].isin(['c', 'a']), ['stu_fname', 'stu_lname']]"
what are the names of all students taking a course who received an a or c?,"student.merge(enroll, on='stu_num').loc[lambda x: x['enroll_grade'].isin(['c', 'a']), ['stu_fname', 'stu_lname']]"
find the first names of all professors in the accounting department who is teaching some course and the class room.,"pd.merge(pd.merge(pd.merge(class_room, employee, left_on='prof_num', right_on='emp_num'), professor, on='emp_num'), department, left_on='dept_code', right_on='dept_code').loc[lambda x: x['dept_name']=='accounting', ['emp_fname', 'class_room']]"
what are the first names of all accounting professors who teach and what are the classrooms of the courses they teach?,"pd.merge(pd.merge(pd.merge(class_room, employee, left_on='prof_num', right_on='emp_num'), professor, on='emp_num'), department, left_on='dept_code', right_on='dept_code').loc[lambda x: x['dept_name']=='accounting', ['emp_fname', 'class_room']]"
find the first names and degree of all professors who are teaching some class in computer info. systems department.,"pd.merge(pd.merge(pd.merge(class, employee, left_on='prof_num', right_on='emp_num'), professor, on='emp_num'), department, on='dept_code').loc[lambda x: x['dept_name']=='computer info. systems', ['emp_fname', 'prof_high_degree']].drop_duplicates()"
what are the different first names and highest degree attained for professors teaching in the computer information systems department?,"pd.merge(pd.merge(pd.merge(class, employee, left_on='prof_num', right_on='emp_num'), professor, on='emp_num'), department, on='dept_code').loc[lambda x: x['dept_name']=='computer info. systems', ['emp_fname', 'prof_high_degree']].drop_duplicates()"
what is the last name of the student who got a grade a in the class with code 10018.,"pd.merge(student, enroll.loc[(enroll['enroll_grade']=='a') & (enroll['class_code']==10018), 'stu_num'], on='stu_num')['stu_lname']"
what is the last name of the student who received an a in the class with the code 10018?,"pd.merge(student, enroll.loc[(enroll['enroll_grade']=='a') & (enroll['class_code']==10018), 'stu_num'], on='stu_num')['stu_lname']"
find the first name and office of history professor who did not get a ph.d. degree.,"pd.merge(pd.merge(professor, employee, on='emp_num'), department, on='dept_code').loc[(lambda x: x['dept_name']=='history') & ~(lambda x: x['prof_high_degree']==""ph.d.""), ['emp_fname', 'prof_office']]"
what are the first names and offices of history professors who don't have ph.d.s?,"pd.merge(pd.merge(professor, employee, on='emp_num'), department, on='dept_code').loc[(lambda x: x['dept_name']=='history') & ~(lambda x: x['prof_high_degree']==""ph.d.""), ['emp_fname', 'prof_office']]"
find the first names of professors who are teaching more than one class.,"pd.merge(class, employee, left_on='prof_num', right_on='emp_num').groupby('prof_num').filter(lambda x: x['emp_num'].count() > 1)['emp_fname']"
what are the first names of all professors who teach more than one class?,"pd.merge(class, employee, left_on='prof_num', right_on='emp_num').groupby('prof_num').filter(lambda x: x['emp_num'].count() > 1)['emp_fname']"
find the first names of students who took exactly one class.,"student.merge(enroll, on='stu_num').groupby('stu_num').filter(lambda x: len(x) == 1)['stu_fname']"
what are the first names of student who only took one course?,"student.merge(enroll, on='stu_num').groupby('stu_num').filter(lambda x: len(x) == 1)['stu_fname']"
"find the name of department that offers the class whose description has the word ""statistics"".","pd.merge(course, department, on='dept_code').loc[lambda x: x['crs_description'].str.contains('statistics'), 'dept_name']"
"what is the name of the department that offers a course that has a description including the word ""statistics""?","pd.merge(course, department, on='dept_code').loc[lambda x: x['crs_description'].str.contains('statistics'), 'dept_name']"
what is the first name of the student whose last name starting with the letter s and is taking acct-211 class?,"student.merge(enroll, on='stu_num').merge(class, on='class_code').loc[(class['crs_code'] == 'acct-211') & (student['stu_lname'].str.startswith('s')), 'stu_fname']"
what is the first name of the student whose last name starts with the letter s and is taking acct-211?,"student.merge(enroll, on='stu_num').merge(class, on='class_code').loc[(class['crs_code'] == 'acct-211') & (student['stu_lname'].str.startswith('s')), 'stu_fname']"
how many clubs are there?,club.shape[0] or len(club)
what is the total number of clubs?,club.shape[0] or len(club)
list the distinct region of clubs in ascending alphabetical order.,club['region'].sort_values().unique()
what are the different regions of clubs in ascending alphabetical order?,club['region'].sort_values().unique()
what is the average number of gold medals for clubs?,club_rank['gold'].mean()
what is the average number of gold medals for a club?,club_rank['gold'].mean()
what are the types and countries of competitions?,"competition[['competition_type', 'country']]"
what are the types of every competition and in which countries are they located?,"competition[['competition_type', 'country']]"
"what are the distinct years in which the competitions type is not ""tournament""?","competition.loc[lambda x: x['competition_type'] != 'tournament', 'year'].unique()"
what are the different years for all competitions that are not of type equal to tournament?,"competition.loc[lambda x: x['competition_type'] != 'tournament', 'year'].unique()"
what are the maximum and minimum number of silver medals for clubs.,"club_rank['silver'].agg(['max', 'min'])"
what are the maximum and minimum number of silver medals for all the clubs?,"club_rank['silver'].agg(['max', 'min'])"
how many clubs have total medals less than 10?,(club_rank['total'] < 10).sum()
what is the total number of clubs that have less than 10 medals in total?,(club_rank['total'] < 10).sum()
list all club names in ascending order of start year.,club.sort_values('start_year')['name']
what are the names of all the clubs starting with the oldest?,club.sort_values('start_year')['name']
list all club names in descending alphabetical order.,"club.sort_values('name', ascending=false)['name']"
what are the names of all the clubs ordered in descending alphabetical order?,"club.sort_values('name', ascending=false)['name']"
please show the names and the players of clubs.,"pd.merge(club, player, on='club_id')[['name', 'player_id']]"
what are the names and players of all the clubs?,"pd.merge(club, player, on='club_id')[['name', 'player_id']]"
"show the names of clubs that have players with position ""right wing"".","pd.merge(club, player.query(""position == 'right wing'""), on='club_id')['name']"
"what are the names of the clubs that have players in the position of ""right wing""?","pd.merge(club, player.query(""position == 'right wing'""), on='club_id')['name']"
"what is the average points of players from club with name ""aib"".","player.loc[player['club_id'].isin(club.loc[club['name']=='aib', 'club_id']), 'points'].mean()"
"what is the average number of points for players from the ""aib"" club?","player.loc[player['club_id'].isin(club.loc[club['name']=='aib', 'club_id']), 'points'].mean()"
list the position of players and the average number of points of players of each position.,player.groupby('position')['points'].mean()
"for each position, what is the average number of points for players in that position?",player.groupby('position')['points'].mean()
list the position of players with average number of points scored by players of that position bigger than 20.,player.groupby('name').filter(lambda x: x['points'].mean() >= 20)['position']
what are the positions of players whose average number of points scored by that position is larger than 20?,player.groupby('name').filter(lambda x: x['points'].mean() >= 20)['position']
list the types of competition and the number of competitions of each type.,competition.groupby('competition_type').size().reset_index(name='count')
what are the types of competition and number of competitions for that type?,competition.groupby('competition_type').size().reset_index(name='count')
list the most common type of competition.,competition.groupby('competition_type').size().sort_values(ascending=false).index[0]
what is the most common competition type?,competition.groupby('competition_type').size().sort_values(ascending=false).index[0]
list the types of competition that have at most five competitions of that type.,competition.groupby('competition_type').filter(lambda x: len(x) <= 5).drop_duplicates('competition_type')['competition_type']
what are the types of competition that have most 5 competitions for that type?,competition.groupby('competition_type').filter(lambda x: len(x) <= 5).drop_duplicates('competition_type')['competition_type']
list the names of clubs that do not have any players.,"club.loc[~club['club_id'].isin(player['club_id']), 'name']"
what are the names of all clubs that do not have any players?,"club.loc[~club['club_id'].isin(player['club_id']), 'name']"
what are the positions with both players having more than 20 points and less than 10 points.,"set(player.loc[player['points'] > 20, 'position']).intersection(set(player.loc[player['points'] < 10, 'position']))"
what are the positions of both players that have more than 20 20 points and less than 10 points?,"set(player.loc[player['points'] > 20, 'position']).intersection(set(player.loc[player['points'] < 10, 'position']))"
show total points of all players.,player['points'].sum()
what is the total number of points for all players?,player['points'].sum()
how many different positions are there?,player['position'].nunique()
how many different position for players are listed?,player['position'].nunique()
what are the name of players who get more than the average points.,"player.loc[player['points'] > player['points'].mean(), 'name']"
what are the names of all players that got more than the average number of points?,"player.loc[player['points'] > player['points'].mean(), 'name']"
find the number of players whose points are lower than 30 in each position.,player.loc[player['points'] < 30].groupby('position').size().reset_index(name='count')
what is the number of players who have points less than 30 for each position?,player.loc[player['points'] < 30].groupby('position').size().reset_index(name='count')
which country did participated in the most number of tournament competitions?,"competition.loc[lambda x: x['competition_type']=='tournament', 'country'].value_counts().index[0]"
what is the name of the country that participated in the most tournament competitions?,"competition.loc[lambda x: x['competition_type']=='tournament', 'country'].value_counts().index[0]"
which countries did participated in both friendly and tournament type competitions.,"pd.merge(competition.loc[lambda x: x['competition_type']=='friendly', 'country'], competition.loc[lambda x: x['competition_type']=='tournament', 'country']).drop_duplicates()"
what are the countries that participated in both friendly and tournament type competitions?,"pd.merge(competition.loc[lambda x: x['competition_type']=='friendly', 'country'], competition.loc[lambda x: x['competition_type']=='tournament', 'country']).drop_duplicates()"
find the countries that have never participated in any competition with friendly type.,"competition['country'].drop(competition.loc[competition['competition_type']=='friendly', 'country'].index).unique()"
what are the countries that have never participated in any friendly-type competitions?,"competition['country'].drop(competition.loc[competition['competition_type']=='friendly', 'country'].index).unique()"
how many furniture components are there in total?,furniture['num_of_component'].sum()
return the name and id of the furniture with the highest market rate.,"furniture[['name', 'furniture_id']].sort_values('market_rate', ascending=false).iloc[[0]]"
find the total market rate of the furnitures that have the top 2 market shares.,"furniture.sort_values('market_rate', ascending=false).head(2)['market_rate'].sum()"
find the component amounts and names of all furnitures that have more than 10 components.,"furniture.loc[lambda x: x['num_of_component'] > 10, ['num_of_component', 'name']]"
find the name and component amount of the least popular furniture.,"furniture[['name', 'num_of_component']].sort_values('market_rate').iloc[0]"
find the names of furnitures whose prices are lower than the highest price.,"furniture.loc[lambda x: x['furniture_id'].isin(furniture_manufacte.loc[lambda y: y['price_in_dollar'] < furniture_manufacte['price_in_dollar'].max(), 'furniture_id']), 'name']"
which manufacturer has the most number of shops? list its name and year of opening.,"manufacturer[['open_year', 'name']].sort_values('num_of_shops', ascending=false).iloc[0]"
find the average number of factories for the manufacturers that have more than 20 shops.,"manufacturer.loc[lambda x: x['num_of_shops'] > 20, 'num_of_factories'].mean()"
list all manufacturer names and ids ordered by their opening year.,"manufacturer[['name', 'manufacturer_id']].sort_values('open_year')"
give me the name and year of opening of the manufacturers that have either less than 10 factories or more than 10 shops.,"manufacturer.loc[(manufacturer['num_of_shops']>10) | (manufacturer['num_of_factories']<10), ['name', 'open_year']]"
what is the average number of factories and maximum number of shops for manufacturers that opened before 1990.,"manufacturer.loc[manufacturer['open_year'] < 1990, ['num_of_shops', 'num_of_factories']].agg({'num_of_shops': 'max', 'num_of_factories': 'mean'})"
find the id and number of shops for the company that produces the most expensive furniture.,"pd.merge(manufacturer, furniture_manufacte, on='manufacturer_id').sort_values('price_in_dollar', ascending=false).iloc[0][['manufacturer_id', 'num_of_shops']]"
find the number of funiture types produced by each manufacturer as well as the company names.,"pd.merge(manufacturer, furniture_manufacte, on='manufacturer_id').groupby('manufacturer_id')['name'].count().reset_index(name='count')"
give me the names and prices of furnitures which some companies are manufacturing.,"pd.merge(furniture, furniture_manufacte, on='furniture_id')[['name', 'price_in_dollar']]"
find the market shares and names of furnitures which no any company is producing in our records.,"furniture[~furniture['furniture_id'].isin(furniture_manufacte['furniture_id'])][['market_rate', 'name']]"
find the name of the company that produces both furnitures with less than 6 components and furnitures with more than 10 components.,"pd.merge(pd.merge(furniture, furniture_manufacte, on='furniture_id'), manufacturer, on='manufacturer_id').loc[lambda x: x['num_of_component'] < 6, 'name'].unique() & pd.merge(pd.merge(furniture, furniture_manufacte, on='furniture_id'), manufacturer, on='manufacturer_id').loc[lambda x: x['num_of_component'] > 10, 'name'].unique()"
display the first name and department name for each employee.,"pd.merge(employees, departments, on='department_id')[['first_name', 'department_name']]"
what are the first name and department name of all employees?,"pd.merge(employees, departments, on='department_id')[['first_name', 'department_name']]"
"list the full name (first and last name), and salary for those employees who earn below 6000.","employees.loc[lambda x: x['salary'] < 6000, ['first_name', 'last_name', 'salary']]"
what are the full names and salaries for any employees earning less than 6000?,"employees.loc[lambda x: x['salary'] < 6000, ['first_name', 'last_name', 'salary']]"
"display the first name, and department number for all employees whose last name is ""mcewen"".","employees.loc[lambda x: x['last_name']=='mcewen', ['first_name', 'department_id']]"
what are the first names and department numbers for employees with last name mcewen?,"employees.loc[lambda x: x['last_name']=='mcewen', ['first_name', 'department_id']]"
return all the information for all employees without any department number.,employees.loc[employees['department_id'].isnull()]
what are all the employees without a department number?,employees.loc[employees['department_id'].isnull()]
display all the information about the department marketing.,departments.loc[lambda x: x['department_name']=='marketing']
what is all the information about the marketing department?,departments.loc[lambda x: x['department_name']=='marketing']
when is the hire date for those employees whose first name does not containing the letter m?,"employees.loc[~employees['first_name'].str.contains('m'), 'hire_date']"
on what dates were employees without the letter m in their first names hired?,"employees.loc[~employees['first_name'].str.contains('m'), 'hire_date']"
"display the full name (first and last), hire date, salary, and department number for those employees whose first name does not containing the letter m.","employees.loc[~employees['first_name'].str.contains('m'), ['first_name', 'last_name', 'hire_date', 'salary', 'department_id']]"
"what are the full name, hire date, salary, and department id for employees without the letter m in their first name?","employees.loc[~employees['first_name'].str.contains('m'), ['first_name', 'last_name', 'hire_date', 'salary', 'department_id']]"
"what are the full name, hire data, salary and department id for employees without the letter m in their first name, ordered by ascending department id?","employees.loc[~employees['first_name'].str.contains('m'), ['first_name', 'last_name', 'hire_date', 'salary', 'department_id']].sort_values('department_id')"
what is the phone number of employees whose salary is in the range of 8000 and 12000?,"employees.loc[lambda x: x['salary'].between(8000, 12000), 'phone_number']"
return the phone numbers of employees with salaries between 8000 and 12000.,"employees.loc[lambda x: x['salary'].between(8000, 12000), 'phone_number']"
display all the information of employees whose salary is in the range of 8000 and 12000 and commission is not null or department number does not equal to 40.,"employees.loc[(employees['salary'].between(8000, 12000)) & (employees['commission_pct'] != ""null"") | (employees['department_id'] != 40)]"
return all information about employees with salaries between 8000 and 12000 for which commission is not null or where their department id is not 40.,"employees.loc[(employees['salary'].between(8000, 12000)) & (employees['commission_pct'] != ""null"") | (employees['department_id'] != 40)]"
what are the full name (first and last name) and salary for all employees who does not have any value for commission?,"employees.loc[employees['commission_pct'].isnull(), ['first_name', 'last_name', 'salary']]"
return the full names and salaries of employees with null commissions.,"employees.loc[employees['commission_pct'].isnull(), ['first_name', 'last_name', 'salary']]"
"display the first and last name, and salary for those employees whose first name is ending with the letter m.","employees.loc[employees['first_name'].str.contains('m'), ['first_name', 'last_name', 'salary']]"
return the full names and salaries for employees with first names that end with the letter m.,"employees.loc[employees['first_name'].str.contains('m'), ['first_name', 'last_name', 'salary']]"
"find job id and date of hire for those employees who was hired between november 5th, 2007 and july 5th, 2009.","employees.loc[(employees['hire_date'] >= '2007-11-05') & (employees['hire_date'] <= '2009-07-05'), ['job_id', 'hire_date']]"
"what are the job ids and dates of hire for employees hired after november 5th, 2007 and before july 5th, 2009?","employees.loc[(employees['hire_date'] >= '2007-11-05') & (employees['hire_date'] <= '2009-07-05'), ['job_id', 'hire_date']]"
what are the first and last name for those employees who works either in department 70 or 90?,"employees.loc[lambda x: x['department_id'].isin([70, 90]), ['first_name', 'last_name']]"
what are the full names of employees who with in department 70 or 90?,"employees.loc[lambda x: x['department_id'].isin([70, 90]), ['first_name', 'last_name']]"
find the salary and manager number for those employees who is working under a manager.,"employees[employees['manager_id'].notnull()][['salary', 'manager_id']]"
what are the salaries and manager ids for employees who have managers?,"employees[employees['manager_id'].notnull()][['salary', 'manager_id']]"
display all the details from employees table for those employees who was hired before 2002-06-21.,employees[employees['hire_date'] < '2002-06-21']
"what is all the information about employees hired before june 21, 2002?",employees[employees['hire_date'] < '2002-06-21']
display all the information for all employees who have the letters d or s in their first name and also arrange the result in descending order by salary.,"employees.loc[employees['first_name'].str.contains('d|s', regex=true)].sort_values('salary', ascending=false)"
"what is all the information about employees with d or s in their first name, ordered by salary descending?","employees.loc[employees['first_name'].str.contains('d|s', regex=true)].sort_values('salary', ascending=false)"
"display those employees who joined after 7th september, 1987.",employees.loc[lambda x: x['hire_date'] > '1987-09-07']
"which employees were hired after september 7th, 1987?",employees.loc[lambda x: x['hire_date'] > '1987-09-07']
display the job title of jobs which minimum salary is greater than 9000.,"jobs.loc[jobs['min_salary'] > 9000, 'job_title']"
which job titles correspond to jobs with salaries over 9000?,"jobs.loc[jobs['min_salary'] > 9000, 'job_title']"
"display job title, the difference between minimum and maximum salaries for those jobs which max salary within the range 12000 to 18000.","jobs.loc[jobs['max_salary'].between(12000, 18000), ['job_title', 'max_salary', 'min_salary']].assign(diff=lambda x: x['max_salary'] - x['min_salary'])[['job_title', 'diff']]"
"what are the job titles, and range of salaries for jobs with maximum salary between 12000 and 18000?","jobs.loc[jobs['max_salary'].between(12000, 18000), ['job_title', 'max_salary', 'min_salary']].assign(diff=lambda x: x['max_salary'] - x['min_salary'])[['job_title', 'diff']]"
display the emails of the employees who have no commission percentage and salary within the range 7000 to 12000 and works in that department which number is 50.,"employees.loc[(employees['commission_pct'].isnull()) & (employees['salary'].between(7000, 12000)) & (employees['department_id'] == 50), 'email']"
"what are the emails of employees with null commission, salary between 7000 and 12000, and who work in department 50?","employees.loc[(employees['commission_pct'].isnull()) & (employees['salary'].between(7000, 12000)) & (employees['department_id'] == 50), 'email']"
display the employee id for each employee and the date on which he ended his previous job.,job_history.groupby('employee_id')['end_date'].max().reset_index()
what are the employee ids for each employee and final dates of employment at their last job?,job_history.groupby('employee_id')['end_date'].max().reset_index()
display those departments where more than ten employees work who got a commission percentage.,employees.groupby('department_id').filter(lambda x: x['commission_pct'].count() > 10)['department_id'].unique()
what are the department ids for which more than 10 employees had a commission?,employees.groupby('department_id').filter(lambda x: x['commission_pct'].count() > 10)['department_id'].unique()
find the ids of the departments where any manager is managing 4 or more employees.,"employees.groupby(['department_id', 'manager_id']).filter(lambda x: len(x) >= 4)['department_id'].unique()"
what are department ids for departments with managers managing more than 3 employees?,"employees.groupby(['department_id', 'manager_id']).filter(lambda x: len(x) >= 4)['department_id'].unique()"
display the average salary of employees for each department who gets a commission percentage.,employees.loc[employees['commission_pct'].notnull()].groupby('department_id')['salary'].mean()
what is the average salary of employees who have a commission percentage that is not null?,employees.loc[employees['commission_pct'].notnull()].groupby('department_id')['salary'].mean()
display the country id and number of cities for each country.,locations.groupby('country_id').size().reset_index(name='count')
give the country id and corresponding count of cities in each country.,locations.groupby('country_id').size().reset_index(name='count')
display job id for those jobs that were done by two or more for more than 300 days.,job_history.loc[(job_history['end_date'] - job_history['start_date']).dt.days > 300].groupby('job_id').filter(lambda x: len(x)>=2)['job_id'].unique()
what are the job ids for jobs done more than once for a period of more than 300 days?,job_history.loc[(job_history['end_date'] - job_history['start_date']).dt.days > 300].groupby('job_id').filter(lambda x: len(x)>=2)['job_id'].unique()
display the id for those employees who did two or more jobs in the past.,job_history.groupby('employee_id').filter(lambda x: len(x) >= 2)['employee_id'].unique()
what are the employee ids for employees who have held two or more jobs?,job_history.groupby('employee_id').filter(lambda x: len(x) >= 2)['employee_id'].unique()
find employee with id and name of the country presently where (s)he is working.,"pd.merge(pd.merge(pd.merge(employees, departments, on='department_id'), locations, on='location_id'), countries, on='country_id')[['employee_id', 'country_name']]"
what are all the employee ids and the names of the countries in which they work?,"pd.merge(pd.merge(pd.merge(employees, departments, on='department_id'), locations, on='location_id'), countries, on='country_id')[['employee_id', 'country_name']]"
display the department name and number of employees in each of the department.,"employees.merge(departments, on='department_id').groupby('department_name').size().reset_index(name='count')"
give the name of each department and the number of employees in each.,"employees.merge(departments, on='department_id').groupby('department_name').size().reset_index(name='count')"
can you return all detailed info of jobs which was done by any of the employees who is presently earning a salary on and above 12000?,"pd.merge(job_history, employees.loc[lambda x: x['salary'] >= 12000], on='employee_id')"
what is all the job history info done by employees earning a salary greater than or equal to 12000?,"pd.merge(job_history, employees.loc[lambda x: x['salary'] >= 12000], on='employee_id')"
display job title and average salary of employees.,"pd.merge(employees, jobs, on='job_id').groupby('job_title')['salary'].mean()"
what is the average salary for each job title?,"pd.merge(employees, jobs, on='job_id').groupby('job_title')['salary'].mean()"
what is the full name ( first name and last name ) for those employees who gets more salary than the employee whose id is 163?,"employees.loc[lambda x: x['salary'] > employees.loc[lambda y: y['employee_id']==163, 'salary'].values[0], ['first_name', 'last_name']]"
provide the full names of employees earning more than the employee with id 163.,"employees.loc[lambda x: x['salary'] > employees.loc[lambda y: y['employee_id']==163, 'salary'].values[0], ['first_name', 'last_name']]"
return the smallest salary for every departments.,employees.groupby('department_id')['salary'].min().reset_index()
what is the minimum salary in each department?,employees.groupby('department_id')['salary'].min().reset_index()
find the first name and last name and department id for those employees who earn such amount of salary which is the smallest salary of any of the departments.,"employees.loc[employees['salary'].isin(employees.groupby('department_id')['salary'].min()), ['first_name', 'last_name', 'department_id']]"
what are the full names and department ids for the lowest paid employees across all departments.,"employees.loc[employees['salary'].isin(employees.groupby('department_id')['salary'].min()), ['first_name', 'last_name', 'department_id']]"
find the employee id for all employees who earn more than the average salary.,"employees.loc[lambda x: x['salary'] > x['salary'].mean(), 'employee_id']"
what are the employee ids for employees who make more than the average?,"employees.loc[lambda x: x['salary'] > x['salary'].mean(), 'employee_id']"
display the employee id and salary of all employees who report to payam (first name).,"employees.loc[lambda x: x['manager_id'] == employees.loc[lambda y: y['first_name']=='payam', 'employee_id'].iloc[0], ['employee_id', 'salary']]"
"what are the employee ids of employees who report to payam, and what are their salaries?","employees.loc[lambda x: x['manager_id'] == employees.loc[lambda y: y['first_name']=='payam', 'employee_id'].iloc[0], ['employee_id', 'salary']]"
find the name of all departments that do actually have one or more employees assigned to them.,"pd.merge(employees, departments, on='department_id')['department_name'].unique()"
what are the names of departments that have at least one employee.,"pd.merge(employees, departments, on='department_id')['department_name'].unique()"
get the details of employees who manage a department.,"pd.merge(employees, departments, on='department_id', suffixes=('_emp', '_dept')).loc[lambda x: x['employee_id_emp']==x['manager_id'], :].drop(columns=['department_id_dept', 'manager_id'])"
what is all the information regarding employees who are managers?,"pd.merge(employees, departments, on='department_id', suffixes=('_emp', '_dept')).loc[lambda x: x['employee_id_emp']==x['manager_id'], :].drop(columns=['department_id_dept', 'manager_id'])"
display all the information about the department marketing.,departments.loc[lambda x: x['department_name']=='marketing']
what are the employee ids for those who had two or more jobs.,job_history.groupby('employee_id').filter(lambda x: len(x) >= 2)['employee_id'].unique()
what are the unique ids of those departments where any manager is managing 4 or more employees.,"employees.groupby(['department_id', 'manager_id']).filter(lambda x: len(x) >= 4)['department_id'].unique()"
give the distinct department ids of departments in which a manager is in charge of 4 or more employees?,"employees.groupby(['department_id', 'manager_id']).filter(lambda x: len(x) >= 4)['department_id'].unique()"
find the job id for those jobs which average salary is above 8000.,employees.groupby('job_id').filter(lambda x: x['salary'].mean()>8000)['job_id'].unique()
what are the job ids corresponding to jobs with average salary above 8000?,employees.groupby('job_id').filter(lambda x: x['salary'].mean()>8000)['job_id'].unique()
display the employee id and job name for all those jobs in department 80.,"pd.merge(employees.loc[lambda x: x['department_id']==80, ['employee_id', 'job_id']], jobs, on='job_id')[['employee_id', 'job_title']]"
what are the employee ids and job titles for employees in department 80?,"pd.merge(employees.loc[lambda x: x['department_id']==80, ['employee_id', 'job_id']], jobs, on='job_id')[['employee_id', 'job_title']]"
what is the first name and job id for all employees in the finance department?,"employees.merge(departments, on='department_id').loc[lambda x: x['department_name']=='finance', ['first_name', 'job_id']]"
give the first name and job id for all employees in the finance department.,"employees.merge(departments, on='department_id').loc[lambda x: x['department_name']=='finance', ['first_name', 'job_id']]"
display all the information of the employees whose salary if within the range of smallest salary and 2500.,employees.loc[lambda x: (x['salary'] >= employees['salary'].min()) & (x['salary'] <= 2500)]
what is all the information regarding employees with salaries above the minimum and under 2500?,employees.loc[lambda x: (x['salary'] >= employees['salary'].min()) & (x['salary'] <= 2500)]
find the ids of the employees who does not work in those departments where some employees works whose manager id within the range 100 and 200.,"employees[~employees['department_id'].isin(departments.loc[lambda x: x['manager_id'].between(100, 200), 'department_id'])]"
what are the ids for employees who do not work in departments with managers that have ids between 100 and 200?,"employees[~employees['department_id'].isin(departments.loc[lambda x: x['manager_id'].between(100, 200), 'department_id'])]"
display the employee name ( first name and last name ) and hire date for all employees in the same department as clara.,"employees.loc[employees['department_id']==employees.loc[employees['first_name']=='clara', 'department_id'].iloc[0], ['first_name', 'last_name', 'hire_date']]"
what are the full names and hire dates for employees in the same department as someone with the first name clara?,"employees.loc[employees['department_id']==employees.loc[employees['first_name']=='clara', 'department_id'].iloc[0], ['first_name', 'last_name', 'hire_date']]"
display the employee name ( first name and last name ) and hire date for all employees in the same department as clara excluding clara.,"employees[employees['department_id'] == employees[employees['first_name'] == 'clara']['department_id'].iloc[0]].loc[lambda x: x['first_name'] != 'clara', ['first_name', 'last_name', 'hire_date']]"
"what are the full names and hire dates for employees in the same department as someone with the first name clara, not including clara?","employees[employees['department_id'] == employees[employees['first_name'] == 'clara']['department_id'].iloc[0]].loc[lambda x: x['first_name'] != 'clara', ['first_name', 'last_name', 'hire_date']]"
display the employee number and name( first name and last name ) for all employees who work in a department with any employee whose name contains a ’t’.,"employees[employees['department_id'].isin(employees[employees['first_name'].str.contains('t')]['department_id'])][['employee_id', 'first_name', 'last_name']]"
what are the ids and full names for employees who work in a department that has someone with a first name that contains the letter t?,"employees[employees['department_id'].isin(employees[employees['first_name'].str.contains('t')]['department_id'])][['employee_id', 'first_name', 'last_name']]"
display the employee number and job id for all employees whose salary is smaller than any salary of those employees whose job title is mk_man.,"employees.loc[employees['salary'] < employees.loc[employees['job_id']=='mk_man', 'salary'].min(), ['employee_id', 'job_id']]"
what are the employee ids and job ids for employees who make less than the lowest earning employee with title mk_man?,"employees.loc[employees['salary'] < employees.loc[employees['job_id']=='mk_man', 'salary'].min(), ['employee_id', 'job_id']]"
"what are the employee ids, full names, and job ids for employees who make more than the highest earning employee with title pu_man?","employees.loc[lambda x: x['salary'] > employees.loc[lambda y: y['job_id'] == 'pu_man', 'salary'].max(), ['employee_id', 'first_name', 'last_name', 'job_id']]"
display the department id and the total salary for those departments which contains at least two employees.,employees.groupby('department_id').filter(lambda x: len(x) >= 2).groupby('department_id')['salary'].sum()
what are total salaries and department id for each department that has more than 2 employees?,employees.groupby('department_id').filter(lambda x: len(x) >= 2).groupby('department_id')['salary'].sum()
display all the information of those employees who did not have any job in the past.,employees[~employees['employee_id'].isin(job_history['employee_id'])]
what is all the information about employees who have never had a job in the past?,employees[~employees['employee_id'].isin(job_history['employee_id'])]
"display the department id, full name (first and last name), salary for those employees who is highest salary in every department.","employees.groupby('department_id').agg({'first_name': 'first', 'last_name': 'first', 'salary': 'sum'}).reset_index()"
"what are the department ids, full names, and salaries for employees who make the most in their departments?","employees.groupby('department_id').agg({'first_name': 'first', 'last_name': 'first', 'salary': 'sum'}).reset_index()"
"display the first and last name, department, city, and state province for each employee.","pd.merge(pd.merge(employees, departments, on='department_id'), locations, on='location_id')[['first_name', 'last_name', 'department_name', 'city', 'state_province']]"
"what are the full names, departments, cities, and state provinces for each employee?","pd.merge(pd.merge(employees, departments, on='department_id'), locations, on='location_id')[['first_name', 'last_name', 'department_name', 'city', 'state_province']]"
"display those employees who contain a letter z to their first name and also display their last name, city.","employees.merge(departments, on='department_id').merge(locations, on='location_id')[lambda x: x['first_name'].str.contains('z')][['first_name', 'last_name','city']]"
what are the full names and cities of employees who have the letter z in their first names?,"employees.merge(departments, on='department_id').merge(locations, on='location_id')[lambda x: x['first_name'].str.contains('z')][['first_name', 'last_name','city']]"
"display the department name, city, and state province for each department.","pd.merge(departments, locations, on='location_id')[['department_name', 'city', 'state_province']]"
"what are the department names, cities, and state provinces for each department?","pd.merge(departments, locations, on='location_id')[['department_name', 'city', 'state_province']]"
display the full name (first and last name ) of employee with id and name of the country presently where (s)he is working.,"pd.merge(pd.merge(pd.merge(employees, departments, on='department_id'), locations, on='location_id'), countries, on='country_id')[['first_name', 'last_name', 'employee_id', 'country_name']]"
"what the full names, ids of each employee and the name of the country they are in?","pd.merge(pd.merge(pd.merge(employees, departments, on='department_id'), locations, on='location_id'), countries, on='country_id')[['first_name', 'last_name', 'employee_id', 'country_name']]"
what are the department names and how many employees work in each of them?,"pd.merge(employees, departments, on='department_id').groupby('department_name').size()"
"display the full name (first and last name), and salary of those employees who working in any department located in london.","pd.merge(pd.merge(employees, departments, on='department_id'), locations, on='location_id').loc[lambda x: x['city']=='london', ['first_name', 'last_name', 'salary']]"
what are full names and salaries of employees working in the city of london?,"pd.merge(pd.merge(employees, departments, on='department_id'), locations, on='location_id').loc[lambda x: x['city']=='london', ['first_name', 'last_name', 'salary']]"
what is the name of the song that was released in the most recent year?,"song.sort_values('releasedate', ascending=false).iloc[0][['song_name', 'releasedate']]"
what is the name of the song that was released most recently?,"song.sort_values('releasedate', ascending=false).iloc[0][['song_name', 'releasedate']]"
what is the id of the longest song?,"files.sort_values('duration', ascending=false).iloc[0]['f_id']"
find the id of the song that lasts the longest.,"files.sort_values('duration', ascending=false).iloc[0]['f_id']"
find the names of all english songs.,"song.loc[song['languages']=='english', 'song_name']"
what are the names of all songs in english?,"song.loc[song['languages']=='english', 'song_name']"
what are the id of songs whose format is mp3.,"files.loc[lambda x: x['formats'] == 'mp3', 'f_id']"
what are the id of all the files in mp3 format?,"files.loc[lambda x: x['formats'] == 'mp3', 'f_id']"
list the name and country of origin for all singers who have produced songs with rating above 9.,"pd.merge(artist, song[song['rating'] > 9], on='artist_name')[['artist_name', 'country']].drop_duplicates()"
what are the different names and countries of origins for all artists whose song ratings are above 9?,"pd.merge(artist, song[song['rating'] > 9], on='artist_name')[['artist_name', 'country']].drop_duplicates()"
list the file size and format for all songs that have resolution lower than 800.,"pd.merge(files, song, on='f_id').loc[lambda x: x['resolution']<800, ['file_size', 'formats']].drop_duplicates()"
what are the file sizes and formats for all songs with a resolution lower than 800?,"pd.merge(files, song, on='f_id').loc[lambda x: x['resolution']<800, ['file_size', 'formats']].drop_duplicates()"
what is the name of the artist who produced the shortest song?,"pd.merge(song, files, on='f_id').sort_values('duration').iloc[0]['artist_name']"
what are the names of the artists who sang the shortest song?,"pd.merge(song, files, on='f_id').sort_values('duration').iloc[0]['artist_name']"
what are the names and countries of origin for the artists who produced the top three highly rated songs.,"pd.merge(artist, song, on='artist_name').sort_values('rating', ascending=false).iloc[:3][['artist_name', 'country']]"
what are the names of the singers who sang the top 3 most highly rated songs and what countries do they hail from?,"pd.merge(artist, song, on='artist_name').sort_values('rating', ascending=false).iloc[:3][['artist_name', 'country']]"
how many songs have 4 minute duration?,files.loc[lambda x: x['duration'].str.startswith('4:')].shape[0]
what is the count of the songs that last approximately 4 minutes?,files.loc[lambda x: x['duration'].str.startswith('4:')].shape[0]
how many artists are from bangladesh?,(artist['country'] == 'bangladesh').sum()
how many bangladeshi artists are listed?,(artist['country'] == 'bangladesh').sum()
what is the average rating of songs produced by female artists?,"song.merge(artist, on='artist_name').loc[lambda x: x['gender']=='female', 'rating'].mean()"
"how many songs, on average, are sung by a female artist?","song.merge(artist, on='artist_name').loc[lambda x: x['gender']=='female', 'rating'].mean()"
what is the most popular file format?,files.groupby('formats').size().sort_values(ascending=false).index[0]
find the file format that is used by the most files.,files.groupby('formats').size().sort_values(ascending=false).index[0]
find the names of the artists who are from uk and have produced english songs.,artist[artist['country']=='uk']['artist_name'].interesect(song[song['languages']=='english']['artist_name'])
what are the names of the artists that are from the uk and sang songs in english?,artist[artist['country']=='uk']['artist_name'].interesect(song[song['languages']=='english']['artist_name'])
find the id of songs that are available in mp4 format and have resolution lower than 1000.,"files.loc[files['formats']=='mp4', 'f_id'].interesect(song.loc[song['resolution']<1000, 'f_id'])"
what is the id of the files that are available in the format of mp4 and a resolution smaller than 1000?,"files.loc[files['formats']=='mp4', 'f_id'].interesect(song.loc[song['resolution']<1000, 'f_id'])"
what is the country of origin of the artist who is female and produced a song in bangla?,"pd.merge(artist.loc[lambda x: x['gender']=='female'], song.loc[lambda x: x['languages']=='bangla'], on='artist_name')['country']"
what countries are the female artists who sung in the language bangla from?,"pd.merge(artist.loc[lambda x: x['gender']=='female'], song.loc[lambda x: x['languages']=='bangla'], on='artist_name')['country']"
what is the average duration of songs that have mp3 format and resolution below 800?,"pd.merge(files.loc[lambda x: x['formats']=='mp3'], song.loc[lambda x: x['resolution']<800], on='f_id')['duration'].mean()"
what is the average song duration for the songs that are in mp3 format and whose resolution below 800?,"pd.merge(files.loc[lambda x: x['formats']=='mp3'], song.loc[lambda x: x['resolution']<800], on='f_id')['duration'].mean()"
what is the number of artists for each gender?,artist.groupby('gender').size().reset_index(name='count')
how many artists are male and how many are female?,artist.groupby('gender').size().reset_index(name='count')
what is the average rating of songs for each language?,"song.groupby('languages').agg(avg_rating=('rating', 'mean'), languages=('languages', 'first'))[['avg_rating', 'languages']]"
what is the average song rating for each language?,"song.groupby('languages').agg(avg_rating=('rating', 'mean'), languages=('languages', 'first'))[['avg_rating', 'languages']]"
return the gender and name of artist who produced the song with the lowest resolution.,"pd.merge(artist, song, on='artist_name').sort_values('resolution').head(1)[['gender', 'artist_name']]"
what is the gender and name of the artist who sang the song with the smallest resolution?,"pd.merge(artist, song, on='artist_name').sort_values('resolution').head(1)[['gender', 'artist_name']]"
"for each file format, return the number of artists who released songs in that format.",files.groupby('formats').size().reset_index(name='count')
how many songs were released for each format?,files.groupby('formats').size().reset_index(name='count')
find the distinct names of all songs that have a higher resolution than some songs in english.,"song.loc[lambda x: x['resolution'] > song.loc[lambda y: y['languages']=='english', 'resolution'].min(), 'song_name'].unique()"
what are the different names for all songs that have a higher resolution than english songs?,"song.loc[lambda x: x['resolution'] > song.loc[lambda y: y['languages']=='english', 'resolution'].min(), 'song_name'].unique()"
what are the names of all songs that have a lower rating than some song of blues genre?,"song.loc[song['rating'] < song.loc[song['genre_is'] == 'blues', 'rating'].max(), 'song_name']"
what are the names of the songs that have a lower rating than at least one blues song?,"song.loc[song['rating'] < song.loc[song['genre_is'] == 'blues', 'rating'].max(), 'song_name']"
"what is the name and country of origin of the artist who released a song that has ""love"" in its title?","pd.merge(artist, song, on='artist_name').loc[lambda x: x['song_name'].str.contains('love', case=false), ['artist_name', 'country']]"
"what are the names of the artists who released a song that has the word love in its title, and where are the artists from?","pd.merge(artist, song, on='artist_name').loc[lambda x: x['song_name'].str.contains('love', case=false), ['artist_name', 'country']]"
list the name and gender for all artists who released songs in march.,"pd.merge(artist, song, on='artist_name').loc[lambda x: x['releasedate'].str.contains('mar'), ['artist_name', 'gender']]"
what are the names and genders of all artists who released songs in the month of march?,"pd.merge(artist, song, on='artist_name').loc[lambda x: x['releasedate'].str.contains('mar'), ['artist_name', 'gender']]"
"list the names of all genres in alphabetical oder, together with its ratings.","genre.sort_values('g_name')[['g_name', 'rating']]"
"what are the names of all genres in alphabetical order, combined with its ratings?","genre.sort_values('g_name')[['g_name', 'rating']]"
give me a list of the names of all songs ordered by their resolution.,song.sort_values('resolution')['song_name']
what are the names of all songs that are ordered by their resolution numbers?,song.sort_values('resolution')['song_name']
what are the ids of songs that are available in either mp4 format or have resolution above 720?,"pd.concat([files.loc[lambda x: x['formats']=='mp4', 'f_id'], song.loc[lambda x: x['resolution']>720, 'f_id']]).drop_duplicates()"
what are the ids of all songs that are available on mp4 or have a higher resolution than 720?,"pd.concat([files.loc[lambda x: x['formats']=='mp4', 'f_id'], song.loc[lambda x: x['resolution']>720, 'f_id']]).drop_duplicates()"
list the names of all songs that have 4 minute duration or are in english.,"pd.concat([pd.merge(files, song, on='f_id').loc[lambda x: x['duration'].str.startswith('4:'), 'song_name'], song.loc[lambda x: x['languages']=='english', 'song_name']]).drop_duplicates()"
what are the names of all songs that are approximately 4 minutes long or are in english?,"pd.concat([pd.merge(files, song, on='f_id').loc[lambda x: x['duration'].str.startswith('4:'), 'song_name'], song.loc[lambda x: x['languages']=='english', 'song_name']]).drop_duplicates()"
what is the language used most often in the songs?,song.groupby('languages').size().sort_values(ascending=false).index[0]
what are the languages that are used most often in songs?,song.groupby('languages').size().sort_values(ascending=false).index[0]
what is the language that was used most often in songs with resolution above 500?,song.loc[song['resolution'] > 500].groupby('languages')['artist_name'].agg(lambda x: x.value_counts().index[0]).sort_values(ascending=false).iloc[0]
"what is the name of the artist, for each language, that has the most songs with a higher resolution than 500?",song.loc[song['resolution'] > 500].groupby('languages')['artist_name'].agg(lambda x: x.value_counts().index[0]).sort_values(ascending=false).iloc[0]
what are the names of artists who are male and are from uk?,"artist.loc[(artist['country']=='uk') & (artist['gender']=='male'), 'artist_name']"
what are the names of all male british artists?,"artist.loc[(artist['country']=='uk') & (artist['gender']=='male'), 'artist_name']"
find the names of songs whose genre is modern or language is english.,"song.loc[(song['genre_is']=='modern') | (song['languages']=='english'), 'song_name']"
what are the names of the songs that are modern or sung in english?,"song.loc[(song['genre_is']=='modern') | (song['languages']=='english'), 'song_name']"
return the names of songs for which format is mp3 and resolution is below 1000.,"files.merge(song, on='f_id').query('formats == ""mp3""')['song_name'].loc[lambda x: x.isin(song.loc[lambda x: x['resolution'] < 1000, 'song_name'])]"
what are the names of all songs that are in mp3 format and have a resolution lower than 1000?,"files.merge(song, on='f_id').query('formats == ""mp3""')['song_name'].loc[lambda x: x.isin(song.loc[lambda x: x['resolution'] < 1000, 'song_name'])]"
return the names of singers who are from uk and released an english song.,"set(artist.query('country == ""uk""')['artist_name']).intersection(song.query('languages == ""english""')['artist_name'])"
what are the names of all singers that are from the uk and released a song in english?,"set(artist.query('country == ""uk""')['artist_name']).intersection(song.query('languages == ""english""')['artist_name'])"
what are the average rating and resolution of songs that are in bangla?,"song.loc[song['languages'] == 'bangla', ['rating', 'resolution']].mean()"
what is the average rating and resolution of all bangla songs?,"song.loc[song['languages'] == 'bangla', ['rating', 'resolution']].mean()"
what are the maximum and minimum resolution of songs whose duration is 3 minutes?,"pd.merge(files.loc[lambda x: x['duration'].str.startswith('3:'), ['f_id']], song, on='f_id').agg({'resolution': ['max', 'min']})"
what is the maximum and minimum resolution of all songs that are approximately 3 minutes long?,"pd.merge(files.loc[lambda x: x['duration'].str.startswith('3:'), ['f_id']], song, on='f_id').agg({'resolution': ['max', 'min']})"
what are the maximum duration and resolution of songs grouped and ordered by languages?,"pd.merge(files, song, on='f_id').groupby('languages').agg({'duration': 'max', 'resolution': 'max'})"
"what are the maximum duration and resolution of all songs, for each language, ordered alphabetically by language?","pd.merge(files, song, on='f_id').groupby('languages').agg({'duration': 'max', 'resolution': 'max'})"
what are the shortest duration and lowest rating of songs grouped by genre and ordered by genre?,"pd.merge(files, song, on='f_id').groupby('genre_is').agg({'duration':'min', 'rating':'min'})"
"what is the shortest and most poorly rated song for each genre, ordered alphabetically by genre?","pd.merge(files, song, on='f_id').groupby('genre_is').agg({'duration':'min', 'rating':'min'})"
find the names and number of works of all artists who have at least one english songs.,"song.loc[song['languages']=='english'].merge(artist, on='artist_name').groupby('artist_name').filter(lambda x: len(x)>=1).groupby('artist_name').size().reset_index(name='count')[['artist_name', 'count']]"
what are the names and number of works for all artists who have sung at least one song in english?,"song.loc[song['languages']=='english'].merge(artist, on='artist_name').groupby('artist_name').filter(lambda x: len(x)>=1).groupby('artist_name').size().reset_index(name='count')[['artist_name', 'count']]"
find the name and country of origin for all artists who have release at least one song of resolution above 900.,"artist.merge(song[song['resolution'] > 900], on='artist_name').groupby('artist_name').filter(lambda group: len(group) >= 1)[['artist_name', 'country']]"
what is the name and country of origin for each artist who has released a song with a resolution higher than 900?,"artist.merge(song[song['resolution'] > 900], on='artist_name').groupby('artist_name').filter(lambda group: len(group) >= 1)[['artist_name', 'country']]"
find the names and number of works of the three artists who have produced the most songs.,"song.groupby('artist_name').size().nlargest(3).reset_index(name='count').merge(artist, on='artist_name', how='left')[['artist_name', 'count']]"
"what are the names of the three artists who have produced the most songs, and how many works did they produce?","song.groupby('artist_name').size().nlargest(3).reset_index(name='count').merge(artist, on='artist_name', how='left')[['artist_name', 'count']]"
find the country of origin for the artist who made the least number of songs?,"pd.merge(artist, song, on='artist_name').groupby('artist_name')['country'].count().sort_values().index.values[0]"
what country is the artist who made the fewest songs from?,"pd.merge(artist, song, on='artist_name').groupby('artist_name')['country'].count().sort_values().index.values[0]"
what are the names of the songs whose rating is below the rating of all songs in english?,"song.loc[song['rating'] < song.loc[song['languages']=='english', 'rating'].min(), 'song_name']"
what are the song names for every song whose rating is less than the minimum rating for english songs?,"song.loc[song['rating'] < song.loc[song['languages']=='english', 'rating'].min(), 'song_name']"
what is ids of the songs whose resolution is higher than the resolution of any songs with rating lower than 8?,"song.loc[song['resolution'] > song.loc[song['rating'] < 8, 'resolution'].max(), 'f_id']"
what is the id of every song that has a resolution higher than that of a song with a rating below 8?,"song.loc[song['resolution'] > song.loc[song['rating'] < 8, 'resolution'].max(), 'f_id']"
what is ids of the songs whose resolution is higher than the average resolution of songs in modern genre?,"song.loc[song['resolution'] > song.loc[song['genre_is'] == 'modern', 'resolution'].mean(), 'f_id']"
what are the ids of all songs that have higher resolution of the average resolution in the modern genre?,"song.loc[song['resolution'] > song.loc[song['genre_is'] == 'modern', 'resolution'].mean(), 'f_id']"
find the top 3 artists who have the largest number of songs works whose language is bangla.,"song.loc[song['languages']=='bangla'].merge(artist, on='artist_name').groupby('artist_name').size().nlargest(3).reset_index(name='count').loc[:, 'artist_name']"
what are the top 3 artists with the largest number of songs in the language bangla?,"song.loc[song['languages']=='bangla'].merge(artist, on='artist_name').groupby('artist_name').size().nlargest(3).reset_index(name='count').loc[:, 'artist_name']"
"list the id, genre and artist name of english songs ordered by rating.","song.loc[song['languages'] == 'english', ['f_id', 'genre_is', 'artist_name']].sort_values('rating')"
"what is the id, genre, and name of the artist for every english song ordered by ascending rating?","song.loc[song['languages'] == 'english', ['f_id', 'genre_is', 'artist_name']].sort_values('rating')"
"list the duration, file size and format of songs whose genre is pop, ordered by title?","files.merge(song[song['genre_is']=='pop'], on='f_id').sort_values('song_name')[['duration', 'file_size', 'formats']]"
"what is the duration, file size, and song format for every pop song, ordered by title alphabetically?","files.merge(song[song['genre_is']=='pop'], on='f_id').sort_values('song_name')[['duration', 'file_size', 'formats']]"
find the names of the artists who have produced english songs but have never received rating higher than 8.,"song.loc[song['languages']=='english', 'artist_name'].drop_duplicates().append(song.loc[song['rating']>8, 'artist_name']).drop_duplicates(keep=false)"
what are the names of the different artists that have produced a song in english but have never receieved a rating higher than 8?,"song.loc[song['languages']=='english', 'artist_name'].drop_duplicates().append(song.loc[song['rating']>8, 'artist_name']).drop_duplicates(keep=false)"
find the names of the artists who are from bangladesh and have never received rating higher than 7.,"set(artist.loc[artist['country']=='bangladesh', 'artist_name']) - set(song.loc[song['rating']>7, 'artist_name'])"
what are the names of the different artists from bangladesh who never received a rating higher than a 7?,"set(artist.loc[artist['country']=='bangladesh', 'artist_name']) - set(song.loc[song['rating']>7, 'artist_name'])"
what is the full name and id of the college with the largest number of baseball players?,"pd.merge(college, player_college, on='college_id').groupby('college_id').apply(lambda x: x['name_full'].nunique()).idxmax()"
find the full name and id of the college that has the most baseball players.,"pd.merge(college, player_college, on='college_id').groupby('college_id').apply(lambda x: x['name_full'].nunique()).idxmax()"
what is average salary of the players in the team named 'boston red stockings' ?,"salary.merge(team, left_on='team_id', right_on='team_id_br').loc[lambda x: x['name']=='boston red stockings', 'salary'].mean()"
compute the average salary of the players in the team called 'boston red stockings'.,"salary.merge(team, left_on='team_id', right_on='team_id_br').loc[lambda x: x['name']=='boston red stockings', 'salary'].mean()"
what are first and last names of players participating in all star game in 1998?,"pd.merge(player, all_star, on='player_id').loc[lambda x: x['year']==1998, ['name_first', 'name_last']]"
list the first and last name for players who participated in all star game in 1998.,"pd.merge(player, all_star, on='player_id').loc[lambda x: x['year']==1998, ['name_first', 'name_last']]"
"what are the first name, last name and id of the player with the most all star game experiences? also list the count.","player.merge(all_star).groupby(['name_first', 'name_last', 'player_id']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
how many players enter hall of fame each year?,hall_of_fame.groupby('yearid').size()
count the number of players who enter hall of fame for each year.,hall_of_fame.groupby('yearid').size()
what is the average number of attendance at home games for each year?,home_game.groupby('year')['attendance'].mean()
"for each year, return the year and the average number of attendance at home games.",home_game.groupby('year')['attendance'].mean()
"in 2014, what are the id and rank of the team that has the largest average number of attendance?","home_game.query(""year == 2014"").merge(team, on=""team_id"").groupby([""team_id"", ""rank""]).mean()[""attendance""].reset_index().sort_values(""attendance"", ascending=false).iloc[0][[""team_id"", ""rank""]]"
find the id and rank of the team that has the highest average attendance rate in 2014.,"home_game.query(""year == 2014"").merge(team, on=""team_id"").groupby([""team_id"", ""rank""]).mean()[""attendance""].reset_index().sort_values(""attendance"", ascending=false).iloc[0][[""team_id"", ""rank""]]"
"what are the manager's first name, last name and id who won the most manager award?","player.merge(manager_award, on='player_id').groupby('player_id').apply(lambda x: x.iloc[0][['name_first', 'name_last', 'player_id']]).reset_index(drop=true).sort_values(by=manager_award.groupby('player_id').size().sort_values(ascending=false).index[0], ascending=false).head(1)"
"which manager won the most manager award? give me the manager's first name, last name and id.","player.merge(manager_award, on='player_id').groupby('player_id').apply(lambda x: x.iloc[0][['name_first', 'name_last', 'player_id']]).reset_index(drop=true).sort_values(by=manager_award.groupby('player_id').size().sort_values(ascending=false).index[0], ascending=false).head(1)"
how many parks are there in the state of ny?,(park['state'] == 'ny').sum()
show me the number of parks the state of ny has.,(park['state'] == 'ny').sum()
which 3 players won the most player awards? list their full name and id.,"pd.merge(player, player_award, on='player_id').groupby(['name_first', 'name_last', 'player_id']).size().reset_index(name='count').nlargest(3, 'count')[['name_first', 'name_last', 'player_id']]"
"find the first name, last name and id for the top three players won the most player awards.","pd.merge(player, player_award, on='player_id').groupby(['name_first', 'name_last', 'player_id']).size().reset_index(name='count').nlargest(3, 'count')[['name_first', 'name_last', 'player_id']]"
list three countries which are the origins of the least players.,player.groupby('birth_country')['birth_country'].agg(['count']).sort_values('count').head(3).reset_index()['birth_country']
what are the three countries that the least players are from?,player.groupby('birth_country')['birth_country'].agg(['count']).sort_values('count').head(3).reset_index()['birth_country']
find all the players' first name and last name who have empty death record.,"player.loc[player['death_year'].isnull(), ['name_first', 'name_last']]"
what are the first name and last name of the players whose death record is empty?,"player.loc[player['death_year'].isnull(), ['name_first', 'name_last']]"
"how many players born in usa are right-handed batters? that is, have the batter value 'r'.","player.loc[(player['birth_country'] == 'usa') & (player['bats'] == 'r'),:].shape[0]"
count the number of players who were born in usa and have bats information 'r'.,"player.loc[(player['birth_country'] == 'usa') & (player['bats'] == 'r'),:].shape[0]"
what is the average height of the players from the college named 'yale university'?,"pd.merge(pd.merge(player, player_college, on='player_id'), college, on='college_id').loc[lambda x: x['name_full']=='yale university', 'height'].mean()"
find the average height of the players who belong to the college called 'yale university'.,"pd.merge(pd.merge(player, player_college, on='player_id'), college, on='college_id').loc[lambda x: x['name_full']=='yale university', 'height'].mean()"
"what is the highest salary among each team? list the team name, id and maximum salary.","pd.merge(team, salary, on='team_id').groupby(['name', 'team_id']).agg({'salary': 'max'})"
"for each team, return the team name, id and the maximum salary among the team.","pd.merge(team, salary, on='team_id').groupby(['name', 'team_id']).agg({'salary': 'max'})"
what are the name and id of the team offering the lowest average salary?,"team.merge(salary, on='team_id').groupby('team_id').mean().sort_values('salary').head(1).reset_index()[['name', 'team_id']]"
which team offers the lowest average salary? give me the name and id of the team.,"team.merge(salary, on='team_id').groupby('team_id').mean().sort_values('salary').head(1).reset_index()[['name', 'team_id']]"
find the players' first name and last name who won award both in 1960 and in 1961.,"pd.merge(player.loc[player_award.loc[player_award['year'] == 1960, 'player_id'], ['name_first', 'name_last']], player.loc[player_award.loc[player_award['year'] == 1961, 'player_id'], ['name_first', 'name_last']]).drop_duplicates().reset_index(drop=true)"
which players won awards in both 1960 and 1961? return their first names and last names.,"pd.merge(player.loc[player_award.loc[player_award['year'] == 1960, 'player_id'], ['name_first', 'name_last']], player.loc[player_award.loc[player_award['year'] == 1961, 'player_id'], ['name_first', 'name_last']]).drop_duplicates().reset_index(drop=true)"
list players' first name and last name who have weight greater than 220 or height shorter than 75.,"player.loc[(player['weight'] > 220) | (player['height'] < 75), ['name_first', 'name_last']]"
what are the first name and last name of the players who have weight above 220 or height below 75?,"player.loc[(player['weight'] > 220) | (player['height'] < 75), ['name_first', 'name_last']]"
list the maximum scores of the team boston red stockings when the team won in postseason?,"postseason.merge(team, left_on='team_id_winner', right_on='team_id_br').loc[lambda x: x['name']=='boston red stockings', 'wins'].max()"
what are the maximum scores the team boston red stockings got when the team won in postseason?,"postseason.merge(team, left_on='team_id_winner', right_on='team_id_br').loc[lambda x: x['name']=='boston red stockings', 'wins'].max()"
how many times did boston red stockings lose in 2009 postseason?,"pd.merge(postseason, team, left_on='team_id_loser', right_on='team_id_br').loc[(lambda x: x['name']=='boston red stockings')(team) & (postseason['year'] == 2009), :].shape[0]"
"count the number of times the team ""boston red stockings"" lost in 2009 postseason.","pd.merge(postseason, team, left_on='team_id_loser', right_on='team_id_br').loc[(lambda x: x['name']=='boston red stockings')(team) & (postseason['year'] == 2009), :].shape[0]"
what are the name and id of the team with the most victories in 2008 postseason?,"postseason[postseason['year']==2008].merge(team, left_on='team_id_winner', right_on='team_id_br').groupby(['team_id_winner', 'name']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'team_id_winner']]"
find the name and id of the team that won the most times in 2008 postseason.,"postseason[postseason['year']==2008].merge(team, left_on='team_id_winner', right_on='team_id_br').groupby(['team_id_winner', 'name']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'team_id_winner']]"
what is the number of wins the team boston red stockings got in the postseasons each year in history?,"postseason.merge(team, left_on='team_id_winner', right_on='team_id_br').loc[lambda x: x['name']=='boston red stockings'].groupby('year').size().reset_index(name='count')"
"for each year, return the year and the number of times the team boston red stockings won in the postseasons.","postseason.merge(team, left_on='team_id_winner', right_on='team_id_br').loc[lambda x: x['name']=='boston red stockings'].groupby('year').size().reset_index(name='count')"
what is the total number of postseason games that team boston red stockings participated in?,"pd.concat([postseason.merge(team, left_on='team_id_winner', right_on='team_id_br'),postseason.merge(team, left_on='team_id_loser', right_on='team_id_br')]).loc[lambda x: x['name']=='boston red stockings'].nunique()[0]"
how many times in total did the team boston red stockings participate in postseason games?,"pd.concat([postseason.merge(team, left_on='team_id_winner', right_on='team_id_br'),postseason.merge(team, left_on='team_id_loser', right_on='team_id_br')]).loc[lambda x: x['name']=='boston red stockings'].nunique()[0]"
"how many games in 1885 postseason resulted in ties (that is, the value of ""ties"" is '1')?",postseason.loc[(postseason['year']==1885) & (postseason['ties']==1)].shape[0]
"find the number of tied games (the value of ""ties"" is '1') in 1885 postseason.",postseason.loc[(postseason['year']==1885) & (postseason['ties']==1)].shape[0]
what is the total salary paid by team boston red stockings in 2010?,"salary.merge(team, left_on='team_id', right_on='team_id_br').query(""name=='boston red stockings' and year==2010"")['salary'].sum()"
what is the total salary expenses of team boston red stockings in 2010?,"salary.merge(team, left_on='team_id', right_on='team_id_br').query(""name=='boston red stockings' and year==2010"")['salary'].sum()"
how many players were in the team boston red stockings in 2000?,"pd.merge(salary, team, left_on='team_id', right_on='team_id_br').loc[lambda x: (x['name']=='boston red stockings') & (x['year']==2000)].shape[0]"
how many players did boston red stockings have in 2000?,"pd.merge(salary, team, left_on='team_id', right_on='team_id_br').loc[lambda x: (x['name']=='boston red stockings') & (x['year']==2000)].shape[0]"
list the 3 highest salaries of the players in 2001?,"salary.loc[salary['year']==2001, 'salary'].sort_values(ascending=false).head(3)"
how much salary did the top 3 well-paid players get in 2001?,"salary.loc[salary['year']==2001, 'salary'].sort_values(ascending=false).head(3)"
what were all the salary values of players in 2010 and 2001?,"pd.concat([salary[salary['year']==2010]['salary'], salary[salary['year']==2001]['salary']]).drop_duplicates()"
list all the salary values players received in 2010 and 2001.,"pd.concat([salary[salary['year']==2010]['salary'], salary[salary['year']==2001]['salary']]).drop_duplicates()"
in which year did the least people enter hall of fame?,hall_of_fame.groupby('yearid').size().sort_values().index[0]
find the year in which the least people enter hall of fame.,hall_of_fame.groupby('yearid').size().sort_values().index[0]
how many parks are there in atlanta city?,(park['city'] == 'atlanta').sum()
how many parks does atlanta city have?,(park['city'] == 'atlanta').sum()
"how many games were played in park ""columbia park"" in 1907?","pd.merge(home_game.loc[home_game['year'] == 1907], park.loc[park['park_name'] == 'columbia park'], on='park_id')['year'].count()"
"count the number of games taken place in park ""columbia park"" in 1907.","pd.merge(home_game.loc[home_game['year'] == 1907], park.loc[park['park_name'] == 'columbia park'], on='park_id')['year'].count()"
how many games were played in city atlanta in 2000?,"home_game.merge(park, on='park_id').query(""year == 2000 and city == 'atlanta'"").shape[0]"
find the number of games taken place in city atlanta in 2000.,"home_game.merge(park, on='park_id').query(""year == 2000 and city == 'atlanta'"").shape[0]"
what is the total home game attendance of team boston red stockings from 2000 to 2010?,"home_game.merge(team, left_on='team_id', right_on='team_id_br').loc[lambda x: (x['name'] == 'boston red stockings') & (x['year'].between(2000, 2010)), 'attendance'].sum()"
how many games in total did team boston red stockings attend from 2000 to 2010?,"home_game.merge(team, left_on='team_id', right_on='team_id_br').loc[lambda x: (x['name'] == 'boston red stockings') & (x['year'].between(2000, 2010)), 'attendance'].sum()"
how much did the the player with first name len and last name barker earn between 1985 to 1990 in total?,"salary.merge(player).query(""name_first == 'len' and name_last == 'barker' and 1985 <= year <= 1990"")['salary'].sum()"
compute the total salary that the player with first name len and last name barker received between 1985 to 1990.,"salary.merge(player).query(""name_first == 'len' and name_last == 'barker' and 1985 <= year <= 1990"")['salary'].sum()"
list players' first name and last name who received salary from team washington nationals in both 2005 and 2007.,"pd.merge(pd.merge(salary[salary['year']==2005], player, on='player_id'), team[team['name']=='washington nationals'], left_on='team_id', right_on='team_id_br')[['name_first', 'name_last']].merge(pd.merge(pd.merge(salary[salary['year']==2007], player, on='player_id'), team[team['name']=='washington nationals'], left_on='team_id', right_on='team_id_br')[['name_first', 'name_last']]).drop_duplicates()"
what are the first name and last name of the players who were paid salary by team washington nationals in both 2005 and 2007?,"pd.merge(pd.merge(salary[salary['year']==2005], player, on='player_id'), team[team['name']=='washington nationals'], left_on='team_id', right_on='team_id_br')[['name_first', 'name_last']].merge(pd.merge(pd.merge(salary[salary['year']==2007], player, on='player_id'), team[team['name']=='washington nationals'], left_on='team_id', right_on='team_id_br')[['name_first', 'name_last']]).drop_duplicates()"
how many home games did the team boston red stockings play from 1990 to 2000 in total?,"pd.merge(home_game, team, left_on='team_id', right_on='team_id_br').loc[lambda x: (x['name']=='boston red stockings') & (x['year'].between(1990, 2000)), 'games'].sum()"
count the total number of games the team boston red stockings attended from 1990 to 2000.,"pd.merge(home_game, team, left_on='team_id', right_on='team_id_br').loc[lambda x: (x['name']=='boston red stockings') & (x['year'].between(1990, 2000)), 'games'].sum()"
which team had the least number of attendances in home games in 1980?,"pd.merge(home_game.loc[lambda x: x['year'] == 1980], team, how='inner', left_on='team_id', right_on='team_id_br').sort_values('attendance').iloc[0]['name']"
find the team that attended the least number of home games in 1980.,"pd.merge(home_game.loc[lambda x: x['year'] == 1980], team, how='inner', left_on='team_id', right_on='team_id_br').sort_values('attendance').iloc[0]['name']"
list the names of states that have more than 2 parks.,park.groupby('state').filter(lambda x: len(x) > 2)['state'].unique()
which states have more than 2 parks?,park.groupby('state').filter(lambda x: len(x) > 2)['state'].unique()
"how many team franchises are active, with active value 'y'?",(team_franchise['active'] == 'y').sum()
"find the number of team franchises that are active (have 'y' as ""active"" information).",(team_franchise['active'] == 'y').sum()
which cities have 2 to 4 parks?,park.groupby('city').filter(lambda x: (2 <= len(x) <= 4))['city'].unique()
find all the cities that have 2 to 4 parks.,park.groupby('city').filter(lambda x: (2 <= len(x) <= 4))['city'].unique()
which park had most attendances in 2008?,"pd.merge(home_game.loc[lambda x: x['year']==2008], park, on='park_id').sort_values('attendance', ascending=false).iloc[0]['park_name']"
which park did the most people attend in 2008?,"pd.merge(home_game.loc[lambda x: x['year']==2008], park, on='park_id').sort_values('attendance', ascending=false).iloc[0]['park_name']"
how many camera lenses have a focal length longer than 15 mm?,(camera_lens['focal_length_mm'] > 15).sum()
"find the brand and name for each camera lens, and sort in descending order of maximum aperture.","camera_lens[['brand', 'name']].sort_values('max_aperture', ascending=false)"
"list the id, color scheme, and name for all the photos.","photos[['id', 'color', 'name']]"
what are the maximum and average height of the mountains?,"mountain['height'].agg(['max', 'mean'])"
what are the average prominence of the mountains in country 'morocco'?,"mountain.loc[mountain['country']=='morocco', 'prominence'].mean()"
"what are the name, height and prominence of mountains which do not belong to the range 'aberdare range'?","mountain.loc[lambda x: x['range']!='aberdare range', ['name', 'height', 'prominence']]"
what are the id and name of the photos for mountains?,"pd.merge(mountain, photos, on='mountain_id').loc[lambda x: x['height'] > 4000, ['id', 'name']]"
what are the id and name of the mountains that have at least 2 photos?,"mountain.merge(photos, on='mountain_id').groupby(['id', 'name']).filter(lambda x: len(x) >= 2)[['id', 'name']].drop_duplicates()"
what are the names of the cameras that have taken picture of the most mountains?,"pd.merge(photos, camera_lens, left_on='camera_lens_id', right_on='id').groupby('name').size().sort_values(ascending=false).index[0]"
what are the names of photos taken with the lens brand 'sigma' or 'olympus'?,"photos.merge(camera_lens, left_on='camera_lens_id', right_on='id', how='inner').query(""brand in ['sigma', 'olympus']"")['name']"
how many different kinds of lens brands are there?,camera_lens['brand'].nunique()
how many camera lenses are not used in taking any photos?,camera_lens[~camera_lens['id'].isin(photos['camera_lens_id'])].shape[0]
how many distinct kinds of camera lenses are used to take photos of mountains in the country 'ethiopia'?,"photos.merge(mountain, left_on='mountain_id', right_on='id').loc[lambda x: x['country']=='ethiopia', 'camera_lens_id'].nunique()"
list the brands of lenses that took both a picture of mountains with range 'toubkal atlas' and a picture of mountains with range 'lasta massif',"pd.merge(pd.merge(mountain.loc[lambda x: x['range']=='toubkal atlas'], photos, on='id'), camera_lens, on='camera_lens_id')['brand'].drop_duplicates().reset_index(drop=true).merge(pd.merge(pd.merge(mountain.loc[lambda x: x['range']=='lasta massif'], photos, on='id'), camera_lens, on='camera_lens_id')['brand'].drop_duplicates().reset_index(drop=true), how='inner')"
show the name and prominence of the mountains whose picture is not taken by a lens of brand 'sigma'.,"mountain[['name', 'prominence']].merge(photos.merge(camera_lens[camera_lens['brand']!='sigma'], on='camera_lens_id'), on='id', how='left').loc[lambda x: x['camera_lens_id'].isna(), ['name', 'prominence']]"
"list the camera lens names containing substring ""digital"".","camera_lens.loc[camera_lens['name'].str.contains('digital'), 'name']"
what is the name of each camera lens and the number of photos taken by it? order the result by the count of photos.,"pd.merge(camera_lens, photos, on='camera_lens_id').groupby('id')['name'].agg([('count', 'count')]).sort_values('count')"
find the names of channels that are not owned by cctv.,"channel.loc[lambda x: x['owner'] != 'cctv', 'name']"
which channels are not owned by cctv? give me the channel names.,"channel.loc[lambda x: x['owner'] != 'cctv', 'name']"
list all channel names ordered by their rating in percent from big to small.,"channel.sort_values('rating_in_percent', ascending=false)['name']"
give me a list of all the channel names sorted by the channel rating in descending order.,"channel.sort_values('rating_in_percent', ascending=false)['name']"
what is the owner of the channel that has the highest rating ratio?,"channel.sort_values('rating_in_percent', ascending=false).iloc[0]['owner']"
show me the owner of the channel with the highest rating.,"channel.sort_values('rating_in_percent', ascending=false).iloc[0]['owner']"
how many programs are there?,program.shape[0]
count the number of programs.,program.shape[0]
"list all the names of programs, ordering by launch time.",program.sort_values('launch')['name']
"what is the list of program names, sorted by the order of launch date?",program.sort_values('launch')['name']
"list the name, origin and owner of each program.","program[['name', 'origin', 'owner']]"
"what are the name, origin and owner of each program?","program[['name', 'origin', 'owner']]"
find the name of the program that was launched most recently.,"program.sort_values('launch', ascending=false).iloc[0]['name']"
which program was launched most recently? return the program name.,"program.sort_values('launch', ascending=false).iloc[0]['name']"
find the total percentage share of all channels owned by cctv.,"channel.loc[channel['owner']=='cctv', 'share_in_percent'].sum()"
what is the total share (in percent) of all the channels owned by cctv?,"channel.loc[channel['owner']=='cctv', 'share_in_percent'].sum()"
find the names of the channels that are broadcast in the morning.,"channel.merge(broadcast[broadcast['time_of_day']=='morning'], on='channel_id')['name']"
which channels are broadcast in the morning? give me the channel names.,"channel.merge(broadcast[broadcast['time_of_day']=='morning'], on='channel_id')['name']"
what are the names of the channels that broadcast in both morning and night?,"pd.merge(broadcast.query(""time_of_day == 'morning'"")[['channel_id']], channel, on='channel_id')['name'].intersect(pd.merge(broadcast.query(""time_of_day == 'night'"")[['channel_id']], channel, on='channel_id')['name'])"
which channels broadcast both in the morning and at night? give me the channel names.,"pd.merge(broadcast.query(""time_of_day == 'morning'"")[['channel_id']], channel, on='channel_id')['name'].intersect(pd.merge(broadcast.query(""time_of_day == 'night'"")[['channel_id']], channel, on='channel_id')['name'])"
how many programs are broadcast in each time section of the day?,broadcast.groupby('time_of_day').size().reset_index(name='count')
count the number of programs broadcast for each time section of a day.,broadcast.groupby('time_of_day').size().reset_index(name='count')
find the number of different programs that are broadcast during night time.,broadcast[broadcast['time_of_day']=='night']['program_id'].nunique()
"how many distinct programs are broadcast at ""night"" time?",broadcast[broadcast['time_of_day']=='night']['program_id'].nunique()
find the names of programs that are never broadcasted in the morning.,"program.loc[~program['name'].isin(pd.merge(program, broadcast, on='program_id').loc[lambda x: x['time_of_day']=='morning', 'name'])]['name']"
which programs are never broadcasted in the morning? give me the names of the programs.,"program.loc[~program['name'].isin(pd.merge(program, broadcast, on='program_id').loc[lambda x: x['time_of_day']=='morning', 'name'])]['name']"
find the program owners that have some programs in both morning and night time.,"pd.merge(program.loc[lambda x: x.merge(broadcast).time_of_day == 'morning', 'owner'], program.loc[lambda x: x.merge(broadcast).time_of_day == 'night', 'owner']).drop_duplicates()"
who are the owners of the programs that broadcast both in the morning and at night?,"pd.merge(program.loc[lambda x: x.merge(broadcast).time_of_day == 'morning', 'owner'], program.loc[lambda x: x.merge(broadcast).time_of_day == 'night', 'owner']).drop_duplicates()"
list all program origins in the alphabetical order.,program.sort_values('origin')['origin']
what is the list of program origins ordered alphabetically?,program.sort_values('origin')['origin']
what is the number of different channel owners?,channel['owner'].nunique()
count the number of distinct channel owners.,channel['owner'].nunique()
find the names of programs whose origin is not in beijing.,"program.loc[lambda x: x['origin']!='beijing', 'name']"
"which programs' origins are not ""beijing""? give me the program names.","program.loc[lambda x: x['origin']!='beijing', 'name']"
what are the names of the channels owned by cctv or hbs?,"channel.loc[channel['owner'].isin(['cctv', 'hbs']), 'name']"
list the names of all the channels owned by either cctv or hbs,"channel.loc[channel['owner'].isin(['cctv', 'hbs']), 'name']"
find the total rating ratio for each channel owner.,channel.groupby('owner')['rating_in_percent'].sum()
what is the total rating of channel for each channel owner?,channel.groupby('owner')['rating_in_percent'].sum()
find the name of the program that is broadcast most frequently.,"pd.merge(program, broadcast, on='program_id').groupby('program_id')['name'].first().value_counts().index[0]"
which program is broadcast most frequently? give me the program name.,"pd.merge(program, broadcast, on='program_id').groupby('program_id')['name'].first().value_counts().index[0]"
how many courses are there in total?,courses.shape[0]
find the total number of courses offered.,courses.shape[0]
"what are the descriptions of the courses with name ""database""?","courses.loc[courses['course_name'] == 'database', 'course_description']"
"return the description for the courses named ""database"".","courses.loc[courses['course_name'] == 'database', 'course_description']"
"what are the addresses of the course authors or tutors with personal name ""cathrine""","course_authors_and_tutors.loc[lambda x: x['personal_name']=='cathrine', 'address_line_1']"
"return the addresses of the course authors or tutors whose personal name is ""cathrine"".","course_authors_and_tutors.loc[lambda x: x['personal_name']=='cathrine', 'address_line_1']"
list the addresses of all the course authors or tutors.,course_authors_and_tutors['address_line_1']
what is the address of each course author or tutor?,course_authors_and_tutors['address_line_1']
list all the login names and family names of course author and tutors.,"course_authors_and_tutors.loc[:, ['login_name', 'family_name']]"
what are the login names and family names of course author and tutors?,"course_authors_and_tutors.loc[:, ['login_name', 'family_name']]"
list all the dates of enrollment and completion of students.,"student_course_enrolment[['date_of_enrolment', 'date_of_completion']]"
what are all the dates of enrollment and completion in record?,"student_course_enrolment[['date_of_enrolment', 'date_of_completion']]"
how many distinct students are enrolled in courses?,student_course_enrollment['student_id'].nunique()
find the number of distinct students enrolled in courses.,student_course_enrollment['student_id'].nunique()
how many distinct courses are enrolled in by students?,student_course_enrolment['course_id'].count()
find the number of distinct courses that have enrolled students.,student_course_enrolment['course_id'].count()
"find the dates of the tests taken with result ""pass"".","student_tests_taken.loc[lambda x: x['test_result']=='pass', 'date_test_taken']"
"which tests have ""pass"" results? return the dates when the tests were taken.","student_tests_taken.loc[lambda x: x['test_result']=='pass', 'date_test_taken']"
"how many tests have result ""fail""?",(student_tests_taken['test_result'] == 'fail').sum()
"count the number of tests with ""fail"" result.",(student_tests_taken['test_result'] == 'fail').sum()
"what are the login names of the students with family name ""ward""?","students.loc[lambda x: x['family_name']=='ward', 'login_name']"
"return the login names of the students whose family name is ""ward"".","students.loc[lambda x: x['family_name']=='ward', 'login_name']"
"what are the dates of the latest logon of the students with family name ""jaskolski"" or ""langosh""?","students.loc[students['family_name'].isin(['jaskolski', 'langosh']), 'date_of_latest_logon']"
"find the latest logon date of the students whose family name is ""jaskolski"" or ""langosh"".","students.loc[students['family_name'].isin(['jaskolski', 'langosh']), 'date_of_latest_logon']"
"how many students have personal names that contain the word ""son""?",students['personal_name'].str.contains('son').sum()
"find the number of students who have the word ""son"" in their personal names.",students['personal_name'].str.contains('son').sum()
list all the subject names.,subjects['subject_name']
what are the names of all the subjects.,subjects['subject_name']
list all the information about course authors and tutors in alphabetical order of the personal name.,course_authors_and_tutors.sort_values('personal_name')
sort the information about course authors and tutors in alphabetical order of the personal name.,course_authors_and_tutors.sort_values('personal_name')
list the personal names and family names of all the students in alphabetical order of family name.,"students[['personal_name', 'family_name']].sort_values('family_name')"
what are the personal names and family names of the students? sort the result in alphabetical order of the family name.,"students[['personal_name', 'family_name']].sort_values('family_name')"
list each test result and its count in descending order of count.,"student_tests_taken.groupby('test_result').size().sort_values(ascending=false).reset_index(name='count')[['test_result', 'count']]"
"for each distinct test result, find the number of students who got the result.","student_tests_taken.groupby('test_result').size().sort_values(ascending=false).reset_index(name='count')[['test_result', 'count']]"
"find the login name of the course author that teaches the course with name ""advanced database"".","pd.merge(course_authors_and_tutors, courses, on='author_id').loc[lambda x: x['course_name'] == 'advanced database', 'login_name']"
"which course author teaches the ""advanced database"" course? give me his or her login name.","pd.merge(course_authors_and_tutors, courses, on='author_id').loc[lambda x: x['course_name'] == 'advanced database', 'login_name']"
"find the addresses of the course authors who teach the course with name ""operating system"" or ""data structure"".","pd.merge(course_authors_and_tutors, courses, on='author_id').loc[lambda x: x['course_name'].isin(['operating system', 'data structure']), 'address_line_1']"
"what are the addresses of the course authors who teach either ""operating system"" or ""data structure"" course.","pd.merge(course_authors_and_tutors, courses, on='author_id').loc[lambda x: x['course_name'].isin(['operating system', 'data structure']), 'address_line_1']"
"find the personal name, family name, and author id of the course author that teaches the most courses.","pd.merge(course_authors_and_tutors, courses, on='author_id').groupby(['personal_name', 'family_name', 'author_id']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['personal_name', 'family_name', 'author_id']]"
"what are the personal name, family name, and author id of the course author who teaches the most courses?","pd.merge(course_authors_and_tutors, courses, on='author_id').groupby(['personal_name', 'family_name', 'author_id']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['personal_name', 'family_name', 'author_id']]"
find the addresses and author ids of the course authors that teach at least two courses.,"pd.merge(course_authors_and_tutors, courses, on='author_id').groupby('author_id').filter(lambda x: len(x) >= 2)[['address_line_1', 'author_id']]"
which course authors teach two or more courses? give me their addresses and author ids.,"pd.merge(course_authors_and_tutors, courses, on='author_id').groupby('author_id').filter(lambda x: len(x) >= 2)[['address_line_1', 'author_id']]"
"find the names of courses taught by the tutor who has personal name ""julio"".","pd.merge(course_authors_and_tutors.loc[lambda x: x['personal_name']=='julio'], courses, on='author_id')['course_name']"
"what are the names of the courses taught by the tutor whose personal name is ""julio""?","pd.merge(course_authors_and_tutors.loc[lambda x: x['personal_name']=='julio'], courses, on='author_id')['course_name']"
"find the names and descriptions of courses that belong to the subject named ""computer science"".","pd.merge(courses, subjects, on='subject_id').loc[lambda x: x['subject_name']=='computer science', ['course_name', 'course_description']]"
"what are the names and descriptions of the all courses under the ""computer science"" subject?","pd.merge(courses, subjects, on='subject_id').loc[lambda x: x['subject_name']=='computer science', ['course_name', 'course_description']]"
"find the subject id, subject name, and the corresponding number of available courses for each subject.","pd.merge(courses, subjects, on='subject_id').groupby(['subject_id', 'subject_name']).size().reset_index(name='count')"
"what are the subject id, subject name, and the number of available courses for each subject?","pd.merge(courses, subjects, on='subject_id').groupby(['subject_id', 'subject_name']).size().reset_index(name='count')"
"find the subject id, name of subject and the corresponding number of courses for each subject, and sort by the course count in ascending order.","pd.merge(courses, subjects, on='subject_id').groupby(['subject_id', 'subject_name']).size().reset_index(name='count').sort_values(""count"")[['subject_id', 'subject_name', 'count']]"
"list the subject id, name of subject and the number of courses available for each subject in ascending order of the course counts.","pd.merge(courses, subjects, on='subject_id').groupby(['subject_id', 'subject_name']).size().reset_index(name='count').sort_values(""count"")[['subject_id', 'subject_name', 'count']]"
"what is the date of enrollment of the course named ""spanish""?","pd.merge(courses.loc[lambda x: x['course_name']=='spanish'], student_course_enrolment, on='course_id')['date_of_enrolment']"
"find the the date of enrollment of the ""spanish"" course.","pd.merge(courses.loc[lambda x: x['course_name']=='spanish'], student_course_enrolment, on='course_id')['date_of_enrolment']"
what is the name of the course that has the most student enrollment?,"courses.loc[pd.merge(courses, enrollment)['course_id'].value_counts().idxmax(), 'course_name']"
which course is enrolled in by the most students? give me the course name.,"courses.loc[pd.merge(courses, enrollment)['course_id'].value_counts().idxmax(), 'course_name']"
what are the names of the courses that have exactly 1 student enrollment?,"pd.merge(courses, student_course_enrolment, on='course_id').groupby('course_name').filter(lambda x: len(x) == 1)['course_name']"
find the names of the courses that have just one student enrollment.,"pd.merge(courses, student_course_enrolment, on='course_id').groupby('course_name').filter(lambda x: len(x) == 1)['course_name']"
what are the descriptions and names of the courses that have student enrollment bigger than 2?,"courses.merge(student_course_enrolment, on='course_id').groupby('course_name').filter(lambda x: len(x) > 2)[['course_description', 'course_name']].drop_duplicates()"
return the descriptions and names of the courses that have more than two students enrolled in.,"courses.merge(student_course_enrolment, on='course_id').groupby('course_name').filter(lambda x: len(x) > 2)[['course_description', 'course_name']].drop_duplicates()"
what is the name of each course and the corresponding number of student enrollment?,"pd.merge(courses, student_course_enrolment, on='course_id').groupby('course_name').size().reset_index(name='count')"
list the name and the number of enrolled student for each course.,"pd.merge(courses, student_course_enrolment, on='course_id').groupby('course_name').size().reset_index(name='count')"
"what are the enrollment dates of all the tests that have result ""pass""?","pd.merge(student_course_enrolment, student_tests_taken.loc[lambda x: x['test_result']=='pass'], on='registration_id')['date_of_enrolment']"
"find the enrollment date for all the tests that have ""pass"" result.","pd.merge(student_course_enrolment, student_tests_taken.loc[lambda x: x['test_result']=='pass'], on='registration_id')['date_of_enrolment']"
"what are the completion dates of all the tests that have result ""fail""?","pd.merge(student_course_enrolment, student_tests_taken, on='registration_id').loc[lambda x: x['test_result']=='fail', 'date_of_completion']"
"return the completion date for all the tests that have ""fail"" result.","pd.merge(student_course_enrolment, student_tests_taken, on='registration_id').loc[lambda x: x['test_result']=='fail', 'date_of_completion']"
"list the dates of enrollment and completion of the student with personal name ""karson"".","pd.merge(student_course_enrolment, students.loc[lambda x: x['personal_name']=='karson', ['student_id']], on='student_id')[['date_of_enrolment', 'date_of_completion']]"
"on what dates did the student whose personal name is ""karson"" enroll in and complete the courses?","pd.merge(student_course_enrolment, students.loc[lambda x: x['personal_name']=='karson', ['student_id']], on='student_id')[['date_of_enrolment', 'date_of_completion']]"
"list the dates of enrollment and completion of the student with family name ""zieme"" and personal name ""bernie"".","pd.merge(student_course_enrolment, students, on='student_id').loc[lambda x: (x['family_name']=='zieme') & (x['personal_name']=='bernie'), ['date_of_enrolment', 'date_of_completion']]"
"on what dates did the student with family name ""zieme"" and personal name ""bernie"" enroll in and complete the courses?","pd.merge(student_course_enrolment, students, on='student_id').loc[lambda x: (x['family_name']=='zieme') & (x['personal_name']=='bernie'), ['date_of_enrolment', 'date_of_completion']]"
find the student id and login name of the student with the most course enrollments,"pd.merge(student_course_enrolment, students, on='student_id').groupby('student_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['student_id', 'login_name']]"
what are the student id and login name of the student who are enrolled in the most courses?,"pd.merge(student_course_enrolment, students, on='student_id').groupby('student_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['student_id', 'login_name']]"
find the student id and personal name of the student with at least two enrollments.,"pd.merge(student_course_enrolment, students, on='student_id').groupby(['student_id', 'personal_name']).filter(lambda x: len(x) >= 2)[['student_id', 'personal_name']].drop_duplicates()"
which student are enrolled in at least two courses? give me the student id and personal name.,"pd.merge(student_course_enrolment, students, on='student_id').groupby(['student_id', 'personal_name']).filter(lambda x: len(x) >= 2)[['student_id', 'personal_name']].drop_duplicates()"
find the student id and middle name for all the students with at most two enrollments.,"pd.merge(student_course_enrolment, students[['student_id', 'middle_name']], on='student_id').groupby('student_id').filter(lambda x: x.shape[0] <= 2)[['student_id', 'middle_name']]"
what are the student ids and middle names of the students enrolled in at most two courses?,"pd.merge(student_course_enrolment, students[['student_id', 'middle_name']], on='student_id').groupby('student_id').filter(lambda x: x.shape[0] <= 2)[['student_id', 'middle_name']]"
find the personal names of students not enrolled in any course.,"students.loc[~students['personal_name'].isin(pd.merge(students, student_course_enrolment, on='student_id')['personal_name'])]['personal_name']"
which students not enrolled in any course? find their personal names.,"students.loc[~students['personal_name'].isin(pd.merge(students, student_course_enrolment, on='student_id')['personal_name'])]['personal_name']"
how many students did not have any course enrollment?,students[~students['student_id'].isin(student_course_enrolment['student_id'])].shape[0]
count the number of students who did not enroll in any course.,students[~students['student_id'].isin(student_course_enrolment['student_id'])].shape[0]
find the common login name of course authors and students.,pd.series(list(set(course_authors_and_tutors['login_name']).intersection(set(students['login_name']))))
what are the login names used both by some course authors and some students?,pd.series(list(set(course_authors_and_tutors['login_name']).intersection(set(students['login_name']))))
find the common personal name of course authors and students.,pd.series(list(set(course_authors_and_tutors['personal_name']) & set(students['personal_name'])))
what are the personal names used both by some course authors and some students?,pd.series(list(set(course_authors_and_tutors['personal_name']) & set(students['personal_name'])))
which claims caused more than 2 settlements or have the maximum claim value? list the date the claim was made and the claim id.,"(pd.merge(claims, settlements, on='claim_id').groupby('claim_id').filter(lambda x: len(x) > 2)[['date_claim_made', 'claim_id']]).append(claims.loc[claims['amount_claimed']==claims['amount_claimed'].max(), ['date_claim_made', 'claim_id']].merge(settlements, on='claim_id'))"
which customer had at least 2 policies but did not file any claims? list the customer details and id.,"pd.merge(customers, customer_policies, on='customer_id').groupby('customer_id').filter(lambda x: len(x)>=2).merge(claims, on='policy_id', how='left').dropna().drop_duplicates(subset=['customer_details', 'customer_id'])[['customer_details', 'customer_id']]"
give me the the customer details and id for the customers who had two or more policies but did not file any claims.,"pd.merge(customers, customer_policies, on='customer_id').groupby('customer_id').filter(lambda x: len(x)>=2).merge(claims, on='policy_id', how='left').dropna().drop_duplicates(subset=['customer_details', 'customer_id'])[['customer_details', 'customer_id']]"
"list the method, date and amount of all the payments, in ascending order of date.","payments[['payment_method_code', 'date_payment_made', 'amount_payment']].sort_values('date_payment_made')"
"what are the method, date and amount of each payment? sort the list in ascending order of date.","payments[['payment_method_code', 'date_payment_made', 'amount_payment']].sort_values('date_payment_made')"
"among all the claims, what is the settlement amount of the claim with the largest claim amount? list both the settlement amount and claim amount.","claims[['amount_settled', 'amount_claimed']].sort_values('amount_claimed', ascending=false).head(1)"
find the settlement amount of the claim with the largest claim amount. show both the settlement amount and claim amount.,"claims[['amount_settled', 'amount_claimed']].sort_values('amount_claimed', ascending=false).head(1)"
"among all the claims, what is the amount claimed in the claim with the least amount settled? list both the settlement amount and claim amount.","claims[['amount_settled', 'amount_claimed']].sort_values('amount_settled').head(1)"
find the claimed amount in the claim with the least amount settled. show both the settlement amount and claim amount.,"claims[['amount_settled', 'amount_claimed']].sort_values('amount_settled').head(1)"
"among all the claims, which claims have a claimed amount larger than the average? list the date the claim was made and the date it was settled.","claims.loc[lambda x: x['amount_claimed']>claims['amount_claimed'].mean(), ['date_claim_made', 'date_claim_settled']]"
"give me the claim date, settlement date for all the claims whose claimed amount is larger than the average.","claims.loc[lambda x: x['amount_claimed']>claims['amount_claimed'].mean(), ['date_claim_made', 'date_claim_settled']]"
"among all the claims, which settlements have a claimed amount that is no more than the average? list the claim start date.","claims.loc[lambda x: x['amount_settled'] <= x['amount_settled'].mean(), 'date_claim_made']"
return the claim start date for the claims whose claimed amount is no more than the average,"claims.loc[lambda x: x['amount_settled'] <= x['amount_settled'].mean(), 'date_claim_made']"
how many settlements does each claim correspond to? list the claim id and the number of settlements.,"pd.merge(claims, settlements, on='claim_id').groupby('claim_id').size().reset_index(name='count')"
find the number of settlements each claim corresponds to. show the number together with the claim id.,"pd.merge(claims, settlements, on='claim_id').groupby('claim_id').size().reset_index(name='count')"
"which claim incurred the most number of settlements? list the claim id, the date the claim was made, and the number.","claims.merge(settlements, on='claim_id').groupby(['claim_id', 'date_claim_made']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
find the claim id and claim date of the claim that incurred the most settlement count. also tell me the count.,"claims.merge(settlements, on='claim_id').groupby(['claim_id', 'date_claim_made']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
how many settlements were made on the claim with the most recent claim settlement date? list the number and the claim id.,"pd.merge(claims, settlements, on='claim_id').groupby('claim_id').size().reset_index(name='count').sort_values(by='date_claim_settled', ascending=false).iloc[0]"
find the claim id and the number of settlements made for the claim with the most recent settlement date.,"pd.merge(claims, settlements, on='claim_id').groupby('claim_id').size().reset_index(name='count').sort_values(by='date_claim_settled', ascending=false).iloc[0]"
"of all the claims, what was the earliest date when any claim was made?",claims.sort_values('date_claim_made').iloc[0]['date_claim_made']
tell me the the date when the first claim was made.,claims.sort_values('date_claim_made').iloc[0]['date_claim_made']
what is the total amount of settlement made for all the settlements?,settlements['amount_settled'].sum()
compute the total amount of settlement across all the settlements.,settlements['amount_settled'].sum()
who are the customers that had more than 1 policy? list the customer details and id.,"pd.merge(customers, customer_policies, on='customer_id').groupby('customer_id').filter(lambda x: len(x)>1)[['customer_details', 'customer_id']]"
find the the customer details and id for the customers who had more than one policy.,"pd.merge(customers, customer_policies, on='customer_id').groupby('customer_id').filter(lambda x: len(x)>1)[['customer_details', 'customer_id']]"
what are the claim dates and settlement dates of all the settlements?,"settlements[['date_claim_made', 'date_claim_settled']]"
tell me the the claim date and settlement date for each settlement case.,"settlements[['date_claim_made', 'date_claim_settled']]"
what is the most popular payment method?,payments.groupby('payment_method_code').size().sort_values(ascending=false).index[0]
which payment method is used the most often?,payments.groupby('payment_method_code').size().sort_values(ascending=false).index[0]
with which kind of payment method were the least number of payments processed?,payments.groupby('payment_method_code').size().sort_values().index[0]
what is the payment method that were used the least often?,payments.groupby('payment_method_code').size().sort_values().index[0]
what is the total amount of payment?,payments['amount_payment'].sum()
compute the total amount of payment processed.,payments['amount_payment'].sum()
what are all the distinct details of the customers?,customers['customer_details'].unique()
return the distinct customer details.,customers['customer_details'].unique()
which kind of policy type was chosen by the most customers?,customer_policies.groupby('policy_type_code').size().sort_values(ascending=false).index[0]
find the policy type the most customers choose.,customer_policies.groupby('policy_type_code').size().sort_values(ascending=false).index[0]
how many settlements are there in total?,settlements.shape[0]
count the total number of settlements made.,settlements.shape[0]
"which payments were processed with visa? list the payment id, the date and the amount.","payments.loc[payments['payment_method_code']=='visa', ['payment_id', 'date_payment_made', 'amount_payment']]"
"give me the payment id, the date and the amount for all the payments processed with visa.","payments.loc[payments['payment_method_code']=='visa', ['payment_id', 'date_payment_made', 'amount_payment']]"
list the details of the customers who do not have any policies.,"customers.loc[~customers['customer_id'].isin(customer_policies['customer_id']), 'customer_details']"
which customers do not have any policies? find the details of these customers.,"customers.loc[~customers['customer_id'].isin(customer_policies['customer_id']), 'customer_details']"
"list the date the claim was made, the date it was settled and the amount settled for all the claims which had exactly one settlement.","pd.merge(claims, settlements, on='claim_id').groupby('claim_id').filter(lambda g: g.shape[0] == 1)[['claim_id', 'date_claim_made', 'date_claim_settled']]"
"which claims had exactly one settlement? for each, tell me the the date the claim was made, the date it was settled and the amount settled.","pd.merge(claims, settlements, on='claim_id').groupby('claim_id').filter(lambda g: g.shape[0] == 1)[['claim_id', 'date_claim_made', 'date_claim_settled']]"
find the total claimed amount of all the claims.,claims['amount_claimed'].sum()
what is total amount claimed summed across all the claims?,claims['amount_claimed'].sum()
which department has the largest number of employees?,department.groupby('departmentid')['name'].count().sort_values(ascending=false).index[0]
find the department with the most employees.,department.groupby('departmentid')['name'].count().sort_values(ascending=false).index[0]
what is the employee id of the head whose department has the least number of employees?,"department.groupby('departmentid').agg(head=pd.namedagg(column='head', aggfunc='first')).reset_index().sort_values(by='departmentid').groupby('head').agg(department_count=pd.namedagg(column='departmentid', aggfunc='count')).reset_index().sort_values(by='department_count').reset_index(drop=true).head(1)['head']"
tell me the employee id of the head of the department with the least employees.,"department.groupby('departmentid').agg(head=pd.namedagg(column='head', aggfunc='first')).reset_index().sort_values(by='departmentid').groupby('head').agg(department_count=pd.namedagg(column='departmentid', aggfunc='count')).reset_index().sort_values(by='department_count').reset_index(drop=true).head(1)['head']"
what is the name and position of the head whose department has least number of employees?,"department.merge(physician, left_on='head', right_on='employeeid').groupby('departmentid').apply(lambda x: x[['name', 'position']].iloc[0]).sort_values('departmentid', ascending=true).iloc[[0]]"
find the name and position of the head of the department with the least employees.,"department.merge(physician, left_on='head', right_on='employeeid').groupby('departmentid').apply(lambda x: x[['name', 'position']].iloc[0]).sort_values('departmentid', ascending=true).iloc[[0]]"
what are names of patients who made an appointment?,"pd.merge(appointment, patient, left_on='patient', right_on='ssn')['name']"
list the names of patients who have made appointments.,"pd.merge(appointment, patient, left_on='patient', right_on='ssn')['name']"
what are name and phone number of patients who had more than one appointment?,"pd.merge(appointment, patient, left_on='patient', right_on='ssn').groupby('patient').filter(lambda x: len(x) > 1).loc[:, ['name', 'phone']]"
which patients made more than one appointment? tell me the name and phone number of these patients.,"pd.merge(appointment, patient, left_on='patient', right_on='ssn').groupby('patient').filter(lambda x: len(x) > 1).loc[:, ['name', 'phone']]"
find the id of the appointment with the most recent start date?,"appointment.sort_values('start', ascending=false).iloc[0]['appointmentid']"
what is the id of the appointment that started most recently?,"appointment.sort_values('start', ascending=false).iloc[0]['appointmentid']"
list the name of physicians who took some appointment.,"pd.merge(appointment, physician, left_on='physician', right_on='employeeid')['name']"
what are the names of all the physicians who took appointments.,"pd.merge(appointment, physician, left_on='physician', right_on='employeeid')['name']"
list the name of physicians who never took any appointment.,"physician[~physician['name'].isin(appointment.merge(physician, left_on='physician', right_on='employeeid')['name_y'])]['name']"
which physicians have never taken any appointment? find their names.,"physician[~physician['name'].isin(appointment.merge(physician, left_on='physician', right_on='employeeid')['name_y'])]['name']"
find the names of all physicians and their primary affiliated departments' names.,"pd.merge(pd.merge(physician, affiliated_with, left_on='employeeid', right_on='physician'), department, left_on='department', right_on='departmentid').loc[lambda x: x['primaryaffiliation']==1, ['name_x', 'name_y']]"
what are the name and primarily affiliated department name of each physician?,"pd.merge(pd.merge(physician, affiliated_with, left_on='employeeid', right_on='physician'), department, left_on='department', right_on='departmentid').loc[lambda x: x['primaryaffiliation']==1, ['name_x', 'name_y']]"
what is the name of the patient who made the most recent appointment?,"pd.merge(patient, appointment, left_on='ssn', right_on='patient').sort_values('start', ascending=false).iloc[0]['name']"
find the name of the patient who made the appointment with the most recent start date.,"pd.merge(patient, appointment, left_on='ssn', right_on='patient').sort_values('start', ascending=false).iloc[0]['name']"
how many patients stay in room 112?,(stay['room'] == 112)['patient'].sum()
count the number of patients who stayed in room 112.,(stay['room'] == 112)['patient'].sum()
how many patients' prescriptions are made by physician john dorian?,"pd.merge(pd.merge(patient, prescribes, left_on='ssn', right_on='patient'), physician, left_on='physician', right_on='employeeid').loc[lambda x: x['name']=='john dorian', 'ssn'].count()"
find the number of patients' prescriptions physician john dorian made.,"pd.merge(pd.merge(patient, prescribes, left_on='ssn', right_on='patient'), physician, left_on='physician', right_on='employeeid').loc[lambda x: x['name']=='john dorian', 'ssn'].count()"
find the name of medication used on the patient who stays in room 111?,"pd.merge(pd.merge(pd.merge(stay, patient, left_on='patient', right_on='ssn'), prescribes, left_on='ssn', right_on='patient'), medication, left_on='medication', right_on='code').loc[lambda x: x['room']==111, 'name']"
what is the name of the medication used for the patient staying in room 111?,"pd.merge(pd.merge(pd.merge(stay, patient, left_on='patient', right_on='ssn'), prescribes, left_on='ssn', right_on='patient'), medication, left_on='medication', right_on='code').loc[lambda x: x['room']==111, 'name']"
find the patient who most recently stayed in room 111.,"stay.loc[lambda x: x['room']==111].sort_values('staystart', ascending=false).iloc[0]['patient']"
what is the id of the patient who stayed in room 111 most recently?,"stay.loc[lambda x: x['room']==111].sort_values('staystart', ascending=false).iloc[0]['patient']"
what is the name of the nurse has the most appointments?,"pd.merge(nurse, appointment, left_on='employeeid', right_on='prepnurse').groupby('employeeid').size().sort_values(ascending=false).reset_index(drop=true).iloc[0]"
find the name of the nurse who has the largest number of appointments.,"pd.merge(nurse, appointment, left_on='employeeid', right_on='prepnurse').groupby('employeeid').size().sort_values(ascending=false).reset_index(drop=true).iloc[0]"
how many patients do each physician take care of? list their names and number of patients they take care of.,"patient.groupby('pcp').size().reset_index(name='count').merge(physician[['employeeid', 'name']], left_on='pcp', right_on='employeeid', how='left').drop('employeeid', axis=1)"
return the name of each physician and the number of patients he or she treats.,"patient.groupby('pcp').size().reset_index(name='count').merge(physician[['employeeid', 'name']], left_on='pcp', right_on='employeeid', how='left').drop('employeeid', axis=1)"
find the name of physicians who are in charge of more than one patient.,"pd.merge(physician, patient, left_on='employeeid', right_on='pcp').groupby('employeeid').filter(lambda x: len(x) > 1)['name']"
which physicians are in charge of more than one patient? give me their names.,"pd.merge(physician, patient, left_on='employeeid', right_on='pcp').groupby('employeeid').filter(lambda x: len(x) > 1)['name']"
find the number of rooms located on each block floor.,"pd.merge(block, room, on=['blockfloor', 'blockcode']).groupby('blockfloor').size().reset_index(name='count')"
how many rooms does each block floor have?,"pd.merge(block, room, on=['blockfloor', 'blockcode']).groupby('blockfloor').size().reset_index(name='count')"
find the number of rooms for different block code?,"pd.merge(block, room, on=['blockfloor', 'blockcode']).groupby('blockcode').size().reset_index(name='count')"
how many rooms are located for each block code?,"pd.merge(block, room, on=['blockfloor', 'blockcode']).groupby('blockcode').size().reset_index(name='count')"
what are the unique block codes that have available rooms?,"room.loc[lambda x: x['unavailable']==0, 'blockcode'].unique()"
tell me the distinct block codes where some rooms are available.,"room.loc[lambda x: x['unavailable']==0, 'blockcode'].unique()"
how many different types of rooms are there?,room['roomtype'].nunique()
find the number of distinct room types available.,room['roomtype'].nunique()
what is the names of the physicians who prescribe medication thesisin?,"pd.merge(pd.merge(physician, prescribes, left_on='employeeid', right_on='physician'), medication, left_on='medication', right_on='code').loc[lambda x: x['name']=='thesisin', 'name_x'].unique()"
list the names of all the physicians who prescribe thesisin as medication.,"pd.merge(pd.merge(physician, prescribes, left_on='employeeid', right_on='physician'), medication, left_on='medication', right_on='code').loc[lambda x: x['name']=='thesisin', 'name_x'].unique()"
find the name and position of physicians who prescribe some medication whose brand is x?,"pd.merge(pd.merge(physician, prescribes, left_on='employeeid', right_on='physician'), medication, on='code').loc[lambda x: x['brand']=='x', ['name', 'position']].drop_duplicates()"
which physicians prescribe a medication of brand x? tell me the name and position of those physicians.,"pd.merge(pd.merge(physician, prescribes, left_on='employeeid', right_on='physician'), medication, on='code').loc[lambda x: x['brand']=='x', ['name', 'position']].drop_duplicates()"
find the number of medications prescribed for each brand.,"medication.merge(prescribes, left_on='code', right_on='medication').groupby('brand')['name'].agg(['count', lambda x: x.iloc[0]])"
how many medications are prescribed for each brand?,"medication.merge(prescribes, left_on='code', right_on='medication').groupby('brand')['name'].agg(['count', lambda x: x.iloc[0]])"
find the name of physicians whose position title contains the word 'senior'.,"physician.loc[physician['position'].str.contains('senior', case=false), 'name']"
what are the names of the physicians who have 'senior' in their titles.,"physician.loc[physician['position'].str.contains('senior', case=false), 'name']"
find the patient who has the most recent undergoing treatment?,undergoes.sort_values('dateundergoes')['patient'].iloc[0]
which patient is undergoing the most recent treatment?,undergoes.sort_values('dateundergoes')['patient'].iloc[0]
find the names of all patients who have an undergoing treatment and are staying in room 111.,"pd.merge(pd.merge(undergoes, patient, left_on='patient', right_on='ssn'), stay, left_on='stay', right_on='stayid').loc[lambda x: x['room']==111, 'name'].unique()"
what are the names of patients who are staying in room 111 and have an undergoing treatment?,"pd.merge(pd.merge(undergoes, patient, left_on='patient', right_on='ssn'), stay, left_on='stay', right_on='stayid').loc[lambda x: x['room']==111, 'name'].unique()"
list the names of all distinct nurses ordered by alphabetical order?,nurse['name'].sort_values().unique()
what is the alphabetically ordered list of all the distinct names of nurses?,nurse['name'].sort_values().unique()
find the names of nurses who are nursing an undergoing treatment.,"pd.merge(undergoes, nurse, left_on='assistingnurse', right_on='employeeid')['name'].unique()"
which nurses are in charge of patients undergoing treatments?,"pd.merge(undergoes, nurse, left_on='assistingnurse', right_on='employeeid')['name'].unique()"
"list the names of all distinct medications, ordered in an alphabetical order.",medication['name'].sort_values().unique()
what is the alphabetically ordered list of all distinct medications?,medication['name'].sort_values().unique()
what are the names of the physician who prescribed the highest dose?,"pd.merge(physician, prescribes, left_on='employeeid', right_on='physician').nlargest(1, 'dose')['name']"
find the physician who prescribed the highest dose. what is his or her name?,"pd.merge(physician, prescribes, left_on='employeeid', right_on='physician').nlargest(1, 'dose')['name']"
list the physicians' employee ids together with their primary affiliation departments' ids.,"affiliated_with.loc[lambda x: x['primaryaffiliation']==1, ['physician', 'department']]"
what are each physician's employee id and department id primarily affiliated.,"affiliated_with.loc[lambda x: x['primaryaffiliation']==1, ['physician', 'department']]"
list the names of departments where some physicians are primarily affiliated with.,"pd.merge(affiliated_with, department, left_on='department', right_on='departmentid').loc[lambda x: x['primaryaffiliation']==1, 'name'].unique()"
what are the names of departments that have primarily affiliated physicians.,"pd.merge(affiliated_with, department, left_on='department', right_on='departmentid').loc[lambda x: x['primaryaffiliation']==1, 'name'].unique()"
what nurses are on call with block floor 1 and block code 1? tell me their names.,"on_call.loc[(on_call['blockfloor'] == 1) & (on_call['blockcode'] == 1), 'nurse']"
find the ids of the nurses who are on call in block floor 1 and block code 1.,"on_call.loc[(on_call['blockfloor'] == 1) & (on_call['blockcode'] == 1), 'nurse']"
"what are the highest cost, lowest cost and average cost of procedures?","procedures['cost'].agg(['max', 'min', 'mean'])"
"tell me the highest, lowest, and average cost of procedures.","procedures['cost'].agg(['max', 'min', 'mean'])"
list the name and cost of all procedures sorted by the cost from the highest to the lowest.,"procedures[['name', 'cost']].sort_values('cost', ascending=false)"
sort the list of names and costs of all procedures in the descending order of cost.,"procedures[['name', 'cost']].sort_values('cost', ascending=false)"
find the three most expensive procedures.,procedures.sort_values('cost').reset_index()['name'][:3]
what are the three most costly procedures?,procedures.sort_values('cost').reset_index()['name'][:3]
find the physicians who are trained in a procedure that costs more than 5000.,"pd.merge(pd.merge(physician, trained_in, left_on='employeeid', right_on='physician'), procedures, left_on='treatment', right_on='code').loc[lambda x: x['cost'] > 5000, 'name']"
which physicians are trained in procedures that are more expensive than 5000?,"pd.merge(pd.merge(physician, trained_in, left_on='employeeid', right_on='physician'), procedures, left_on='treatment', right_on='code').loc[lambda x: x['cost'] > 5000, 'name']"
find the physician who was trained in the most expensive procedure?,"pd.merge(pd.merge(physician, trained_in, left_on='employeeid', right_on='physician'), procedures, left_on='treatment', right_on='code')['name'].loc[lambda x: x['cost']==x['cost'].max()]"
which physician was trained in the procedure that costs the most.,"pd.merge(pd.merge(physician, trained_in, left_on='employeeid', right_on='physician'), procedures, left_on='treatment', right_on='code')['name'].loc[lambda x: x['cost']==x['cost'].max()]"
what is the average cost of procedures that physician john wen was trained in?,"pd.merge(pd.merge(physician.loc[lambda x: x['name']=='john wen'], trained_in, left_on='employeeid', right_on='physician'), procedures, left_on='treatment', right_on='code')['cost'].mean()"
compute the mean price of procedures physician john wen was trained in.,"pd.merge(pd.merge(physician.loc[lambda x: x['name']=='john wen'], trained_in, left_on='employeeid', right_on='physician'), procedures, left_on='treatment', right_on='code')['cost'].mean()"
find the names of procedures which physician john wen was trained in.,"procedures.merge(trained_in.merge(physician[physician['name']=='john wen'], left_on='physician', right_on='employeeid'), left_on='code', right_on='treatment')['name']"
what are the names of procedures physician john wen was trained in?,"procedures.merge(trained_in.merge(physician[physician['name']=='john wen'], left_on='physician', right_on='employeeid'), left_on='code', right_on='treatment')['name']"
find all procedures which cost more than 1000 or which physician john wen was trained in.,"pd.concat([procedures.loc[lambda x: x['cost'] > 1000, 'name'], pd.merge(pd.merge(physician.loc[lambda x: x['name'] == 'john wen'], trained_in, left_on='employeeid', right_on='physician'), procedures, on='code')['name']]).drop_duplicates()"
what are the procedures that cost more than 1000 or are specialized in by physician john wen?,"pd.concat([procedures.loc[lambda x: x['cost'] > 1000, 'name'], pd.merge(pd.merge(physician.loc[lambda x: x['name'] == 'john wen'], trained_in, left_on='employeeid', right_on='physician'), procedures, on='code')['name']]).drop_duplicates()"
find the names of all procedures which cost more than 1000 but which physician john wen was not trained in?,"procedures.loc[lambda x: x['cost']>1000, 'name'].tolist() - procedures.loc[procedures.merge(trained_in.merge(physician.loc[lambda x: x['name']=='john wen'], on='employeeid'), on='code')]['name'].tolist()"
"among the procedures that cost more than 1000, which were not specialized in by physician john wen?","procedures.loc[lambda x: x['cost']>1000, 'name'].tolist() - procedures.loc[procedures.merge(trained_in.merge(physician.loc[lambda x: x['name']=='john wen'], on='employeeid'), on='code')]['name'].tolist()"
find the names of all procedures such that the cost is less than 5000 and physician john wen was trained in.,"procedures[procedures['cost'] < 5000]['name'].intersec‌t(procedures.merge(trained_in.merge(physician[physician['name'] == 'john wen'], on='employeeid', how='inner'), left_on='code', right_on='treatment', how='inner')['name'])"
what procedures cost less than 5000 and have john wen as a trained physician?,"procedures.loc[lambda x: x['cost']<5000, 'name'].intersects(procedures.merge(trained_in.merge(physician.loc[lambda x: x['name']=='john wen'], on='employeeid'), on='code')['name'])"
find the name of physicians who are affiliated with both surgery and psychiatry departments.,"pd.merge(pd.merge(physician.merge(affiliated_with, left_on='employeeid', right_on='physician'), department, left_on='department', right_on='departmentid').loc[lambda x: x['name']=='surgery', 'name'], pd.merge(physician.merge(affiliated_with, left_on='employeeid', right_on='physician'), department, left_on='department', right_on='departmentid').loc[lambda x: x['name']=='psychiatry', 'name'], on='name')['name']"
which physicians are affiliated with both surgery and psychiatry departments? tell me their names.,"pd.merge(pd.merge(physician.merge(affiliated_with, left_on='employeeid', right_on='physician'), department, left_on='department', right_on='departmentid').loc[lambda x: x['name']=='surgery', 'name'], pd.merge(physician.merge(affiliated_with, left_on='employeeid', right_on='physician'), department, left_on='department', right_on='departmentid').loc[lambda x: x['name']=='psychiatry', 'name'], on='name')['name']"
find the name of physicians who are affiliated with surgery or psychiatry department.,"pd.merge(pd.merge(physician, affiliated_with, left_on='employeeid', right_on='physician'), department, left_on='department', right_on='departmentid').loc[lambda x: x['name'].isin(['surgery', 'psychiatry']), 'name_x']"
which physicians are affiliated with either surgery or psychiatry department? give me their names.,"pd.merge(pd.merge(physician, affiliated_with, left_on='employeeid', right_on='physician'), department, left_on='department', right_on='departmentid').loc[lambda x: x['name'].isin(['surgery', 'psychiatry']), 'name_x']"
find the names of patients who are not using the medication of procrastin-x.,"patient.loc[~patient['name'].isin(pd.merge(pd.merge(prescribes, medication, left_on='medication', right_on='code'), patient, left_on='patient', right_on='ssn').loc[lambda x: x['name']=='procrastin-x', 'name'])]['name']"
what are the names of patients who are not taking the medication of procrastin-x.,"patient.loc[~patient['name'].isin(pd.merge(pd.merge(prescribes, medication, left_on='medication', right_on='code'), patient, left_on='patient', right_on='ssn').loc[lambda x: x['name']=='procrastin-x', 'name'])]['name']"
find the number of patients who are not using the medication of procrastin-x.,"patient.loc[~patient['ssn'].isin(pd.merge(prescribes, medication, left_on='medication', right_on='code').loc[lambda x: x['name']=='procrastin-x', 'patient']), :].shape[0]"
how many patients are not using procrastin-x as medication?,"patient.loc[~patient['ssn'].isin(pd.merge(prescribes, medication, left_on='medication', right_on='code').loc[lambda x: x['name']=='procrastin-x', 'patient']), :].shape[0]"
how many appointments are there?,appointment.shape[0]
count how many appointments have been made in total.,appointment.shape[0]
find the names of nurses who are on call.,"pd.merge(nurse, on_call, left_on='employeeid', right_on='nurse')['name'].unique()"
what are the distinct names of nurses on call?,"pd.merge(nurse, on_call, left_on='employeeid', right_on='nurse')['name'].unique()"
how many ships are there?,ship.shape[0]
what is the number of ships?,ship.shape[0]
list the name of ships in ascending order of tonnage.,ship.sort_values('tonnage')['name']
what are the names of the ships ordered by ascending tonnage?,ship.sort_values('tonnage')['name']
what are the type and nationality of ships?,"ship[['type', 'nationality']]"
what are the types and nationalities of every ship?,"ship[['type', 'nationality']]"
"list the name of ships whose nationality is not ""united states"".","ship.loc[ship['nationality'] != 'united states', 'name']"
what are the names of the ships that are not from the united states?,"ship.loc[ship['nationality'] != 'united states', 'name']"
show the name of ships whose nationality is either united states or united kingdom.,"ship.loc[lambda x: x['nationality'].isin(['united states', 'united kingdom']), 'name']"
what are the names of the ships  that are from either the us or the uk?,"ship.loc[lambda x: x['nationality'].isin(['united states', 'united kingdom']), 'name']"
what is the name of the ship with the largest tonnage?,"ship.sort_values('tonnage', ascending=false).iloc[0]['name']"
what is the ship with the largest amount of tonnage called?,"ship.sort_values('tonnage', ascending=false).iloc[0]['name']"
show different types of ships and the number of ships of each type.,ship.groupby('type').size().reset_index(name='count')
"for each type, how many ships are there?",ship.groupby('type').size().reset_index(name='count')
please show the most common type of ships.,ship.groupby('type').size().sort_values(ascending=false).index[0]
what is the most common type of ships?,ship.groupby('type').size().sort_values(ascending=false).index[0]
list the nations that have more than two ships.,ship.groupby('nationality').filter(lambda x: len(x) > 2)['nationality'].unique()
what are the nations that have more than two ships?,ship.groupby('nationality').filter(lambda x: len(x) > 2)['nationality'].unique()
show different types of ships and the average tonnage of ships of each type.,ship.groupby('type')['tonnage'].mean()
"for each type, what is the average tonnage?",ship.groupby('type')['tonnage'].mean()
"show codes and fates of missions, and names of ships involved.","pd.merge(mission, ship, on='ship_id')[['code', 'fate', 'name']]"
"what are the mission codes, fates, and names of the ships involved?","pd.merge(mission, ship, on='ship_id')[['code', 'fate', 'name']]"
show names of ships involved in a mission launched after 1928.,"pd.merge(mission, ship, on='ship_id').loc[lambda x: x['launched_year'] > 1928, 'name']"
what are the names of ships that were involved in a mission launched after 1928?,"pd.merge(mission, ship, on='ship_id').loc[lambda x: x['launched_year'] > 1928, 'name']"
"show the distinct fate of missions that involve ships with nationality ""united states""","pd.merge(mission, ship, on='ship_id').loc[lambda x: x['nationality']=='united states', 'fate'].unique()"
what are the different fates of the mission that involved ships from the united states?,"pd.merge(mission, ship, on='ship_id').loc[lambda x: x['nationality']=='united states', 'fate'].unique()"
list the name of ships that are not involved in any mission,"ship.loc[~ship['ship_id'].isin(mission['ship_id']), 'name']"
what are the names of the ships that are not involved in any missions?,"ship.loc[~ship['ship_id'].isin(mission['ship_id']), 'name']"
show the types of ships that have both ships with tonnage larger than 6000 and ships with tonnage smaller than 4000.,"ship.loc[ship['tonnage'] > 6000, 'type'].intersect(ship.loc[ship['tonnage'] < 4000, 'type'])"
what are the types of the ships that have both shiips with tonnage more than 6000 and those with tonnage less than 4000?,"ship.loc[ship['tonnage'] > 6000, 'type'].intersect(ship.loc[ship['tonnage'] < 4000, 'type'])"
find the number of students in total.,list.shape[0]
find the last names of students studying in room 111.,"list.loc[list['classroom']==111, 'lastname']"
what are the last names of students in room 111?,"list.loc[list['classroom']==111, 'lastname']"
find the first names of students studying in room 108.,"list.loc[list['classroom']==108, 'firstname']"
what are the first names of students in room 108?,"list.loc[list['classroom']==108, 'firstname']"
what are the first names of students studying in room 107?,"list.loc[list['classroom']==107, 'firstname'].unique()"
list the first names of all the students in room 107.,"list.loc[list['classroom']==107, 'firstname'].unique()"
for each classroom report the grade that is taught in it. report just the classroom number and the grade number.,"list[['classroom', 'grade']].drop_duplicates()"
what are the grade number and classroom number of each class in the list?,"list[['classroom', 'grade']].drop_duplicates()"
which grade is studying in classroom 103?,"list.loc[list['classroom']==103, 'grade'].unique()"
find the grade taught in classroom 103.,"list.loc[list['classroom']==103, 'grade'].unique()"
find the grade studying in room 105.,"list.loc[list['classroom']==105, 'grade'].unique()"
which grade is studying in room 105?,"list.loc[list['classroom']==105, 'grade'].unique()"
which classrooms are used by grade 4?,"list.loc[lambda x: x['grade'] == 4, 'classroom'].unique()"
find the classrooms in which grade 4 is studying.,"list.loc[lambda x: x['grade'] == 4, 'classroom'].unique()"
which classrooms are used by grade 5?,"list.loc[lambda x: x['grade']==5, 'classroom'].unique()"
show me the classrooms grade 5 is using.,"list.loc[lambda x: x['grade']==5, 'classroom'].unique()"
find the last names of the teachers that teach fifth grade.,"pd.merge(list, teachers, on='classroom').loc[lambda x: x['grade']==5, 'lastname'].unique()"
what are the last names of the teachers who teach grade 5?,"pd.merge(list, teachers, on='classroom').loc[lambda x: x['grade']==5, 'lastname'].unique()"
find the first names of the teachers that teach first grade.,"pd.merge(list, teachers, on='classroom').loc[lambda x: x['grade']==1, 'firstname'].unique()"
what are the first names of the teachers who teach grade 1?,"pd.merge(list, teachers, on='classroom').loc[lambda x: x['grade']==1, 'firstname'].unique()"
find the first names of all the teachers that teach in classroom 110.,"teachers.loc[lambda x: x['classroom']==110, 'firstname']"
which teachers teach in classroom 110? give me their first names.,"teachers.loc[lambda x: x['classroom']==110, 'firstname']"
find the last names of teachers teaching in classroom 109.,"teachers.loc[lambda x: x['classroom'] == 109, 'lastname']"
which teachers teach in classroom 109? give me their last names.,"teachers.loc[lambda x: x['classroom'] == 109, 'lastname']"
report the first name and last name of all the teachers.,"teachers[['firstname', 'lastname']].drop_duplicates()"
what are the first name and last name of all the teachers?,"teachers[['firstname', 'lastname']].drop_duplicates()"
report the first name and last name of all the students.,"list[['firstname', 'lastname']].drop_duplicates()"
show each student's first name and last name.,"list[['firstname', 'lastname']].drop_duplicates()"
find all students taught by otha moyer. output the first and last names of the students.,"list.loc[list['classroom'].isin(teachers.loc[(teachers['firstname']=='otha') & (teachers['lastname']=='moyer'), 'classroom']), ['firstname', 'lastname']]"
which students study under the teacher named otha moyer? give me the first and last names of the students.,"list.loc[list['classroom'].isin(teachers.loc[(teachers['firstname']=='otha') & (teachers['lastname']=='moyer'), 'classroom']), ['firstname', 'lastname']]"
find all students taught by marrotte kirk. output first and last names of students.,"list.merge(teachers.loc[(teachers['firstname']=='marrotte') & (teachers['lastname']=='kirk'), 'classroom'], on='classroom')[['firstname', 'lastname']]"
which are the first and last names of the students taught by marrotte kirk?,"list.merge(teachers.loc[(teachers['firstname']=='marrotte') & (teachers['lastname']=='kirk'), 'classroom'], on='classroom')[['firstname', 'lastname']]"
find the first and last name of all the teachers that teach evelina bromley.,"teachers.loc[lambda x: x['classroom'].isin(list.loc[lambda y: (y['firstname']=='evelina')&(y['lastname']=='bromley'), 'classroom']), ['firstname', 'lastname']]"
which teachers teach the student named evelina bromley? give me the first and last name  of the teachers.,"teachers.loc[lambda x: x['classroom'].isin(list.loc[lambda y: (y['firstname']=='evelina')&(y['lastname']=='bromley'), 'classroom']), ['firstname', 'lastname']]"
find the last names of all the teachers that teach gell tami.,"pd.merge(list[list['firstname']=='gell'][list['lastname']=='tami'], teachers, on='classroom')['lastname']"
what are the last names of the teachers who teach the student called gell tami?,"pd.merge(list[list['firstname']=='gell'][list['lastname']=='tami'], teachers, on='classroom')['lastname']"
how many students does loria ondersma teaches?,"pd.merge(list, teachers, on='classroom').loc[lambda x: (x['firstname']=='loria') & (x['lastname']=='ondersma'), :].shape[0]"
count the number of students the teacher loria ondersma teaches.,"pd.merge(list, teachers, on='classroom').loc[lambda x: (x['firstname']=='loria') & (x['lastname']=='ondersma'), :].shape[0]"
how many students does kawa gordon teaches?,"pd.merge(list, teachers, on='classroom').loc[lambda x: (x['firstname']=='kawa')&(x['lastname']=='gordon'), :].shape[0]"
find the number of students taught by the teacher kawa gordon.,"pd.merge(list, teachers, on='classroom').loc[lambda x: (x['firstname']=='kawa')&(x['lastname']=='gordon'), :].shape[0]"
find the number of students taught by tarring leia.,"pd.merge(list, teachers, on='classroom').loc[lambda x: (x['firstname']=='tarring')&(x['lastname']=='leia'), :].shape[0]"
how many students are taught by teacher tarring leia?,"pd.merge(list, teachers, on='classroom').loc[lambda x: (x['firstname']=='tarring')&(x['lastname']=='leia'), :].shape[0]"
how many teachers does the student named chrissy nabozny have?,"len(pd.merge(list, teachers, on='classroom').loc[(list['firstname']=='chrissy') & (list['lastname']=='nabozny')])"
find the number of teachers who teach the student called chrissy nabozny.,"len(pd.merge(list, teachers, on='classroom').loc[(list['firstname']=='chrissy') & (list['lastname']=='nabozny')])"
how many teachers does the student named madlock ray have?,"pd.merge(list, teachers, on='classroom').loc[(lambda x: (x['firstname']=='madlock') & (x['lastname']=='ray')), :].shape[0]"
find the number of teachers who teach the student called madlock ray.,"pd.merge(list, teachers, on='classroom').loc[(lambda x: (x['firstname']=='madlock') & (x['lastname']=='ray')), :].shape[0]"
find all first-grade students who are not taught by otha moyer. report their first and last names.,"list.merge(teachers, on='classroom').loc[lambda x: x['grade']==1].loc[lambda x: ~((x['firstname']=='otha') & (x['lastname']=='moyer'))][['firstname', 'lastname']].drop_duplicates()"
what are the first and last names of the first-grade students who are not taught by teacher otha moyer?,"list.merge(teachers, on='classroom').loc[lambda x: x['grade']==1].loc[lambda x: ~((x['firstname']=='otha') & (x['lastname']=='moyer'))][['firstname', 'lastname']].drop_duplicates()"
find the last names of the students in third grade that are not taught by covin jerome.,"pd.merge(list.loc[lambda x: x['grade']==3], teachers.loc[(teachers['firstname']!='covin') & (teachers['lastname']!='jerome')], left_on='classroom', right_on='classroom')['lastname'].unique()"
which students in third grade are not taught by teacher covin jerome? give me the last names of the students.,"pd.merge(list.loc[lambda x: x['grade']==3], teachers.loc[(teachers['firstname']!='covin') & (teachers['lastname']!='jerome')], left_on='classroom', right_on='classroom')['lastname'].unique()"
"for each grade, report the grade, the number of classrooms in which it is taught and the total number of students in the grade.","list.groupby('grade').agg(num_classrooms=('classroom', 'nunique'),num_students=('grade', 'count')).reset_index()[['grade', 'num_classrooms', 'num_students']]"
"for each grade, return the grade number, the number of classrooms used for the grade, and the total number of students enrolled in the grade.","list.groupby('grade').agg(num_classrooms=('classroom', 'nunique'),num_students=('grade', 'count')).reset_index()[['grade', 'num_classrooms', 'num_students']]"
"for each classroom, report the classroom number and the number of grades using it.",list.groupby('classroom')['grade'].nunique()
"for each classroom, show the classroom number and count the number of distinct grades that use the room.",list.groupby('classroom')['grade'].nunique()
which classroom has the most students?,list.groupby('classroom').size().sort_values(ascending=false).index[0]
find the classroom that the most students use.,list.groupby('classroom').size().sort_values(ascending=false).index[0]
report the number of students in each classroom.,list.groupby('classroom').size()
"for each classroom, show the classroom number and find how many students are using it.",list.groupby('classroom').size()
"for each grade 0 classroom, report the total number of students.",list.loc[lambda x: x['grade'] == '0'].groupby('classroom').size()
"for each grade 0 classroom, return the classroom number and the count of students.",list.loc[lambda x: x['grade'] == '0'].groupby('classroom').size()
report the total number of students for each fourth-grade classroom.,list.loc[lambda x: x['grade']=='4'].groupby('classroom').size()
"for each fourth-grade classroom, show the classroom number and the total number of students using it.",list.loc[lambda x: x['grade']=='4'].groupby('classroom').size()
find the name of the teacher who teaches the largest number of students.,"list.merge(teachers, on='classroom').groupby(['firstname', 'lastname']).size().sort_values(ascending=false).reset_index().iloc[0, :2]"
which teacher teaches the most students? give me the first name and last name of the teacher.,"list.merge(teachers, on='classroom').groupby(['firstname', 'lastname']).size().sort_values(ascending=false).reset_index().iloc[0, :2]"
find the number of students in one classroom.,list.groupby('classroom').size().reset_index(name='count')
how many students does one classroom have?,list.groupby('classroom').size().reset_index(name='count')
how many companies are headquartered in the us?,(company['headquarters'] == 'usa').sum()
list the names of companies by ascending number of sales.,company.sort_values('sales_in_billion')['name']
what are the headquarters and industries of all companies?,"company[['headquarters', 'industry']]"
show the names of companies in the banking or retailing industry?,"company.loc[company['industry'].isin(['banking', 'retailing']), 'name']"
what is the maximum and minimum market value of companies?,"company['market_value_in_billion'].agg(['max', 'min'])"
what is the headquarter of the company with the largest sales?,"company.sort_values('sales_in_billion', ascending=false).iloc[0]['headquarters']"
show the different headquarters and number of companies at each headquarter.,company.groupby('headquarters').size()
show the most common headquarter for companies.,company.groupby('headquarters').size().sort_values(ascending=false).index[0]
show the headquarters that have at least two companies.,company.groupby('headquarters').filter(lambda x: len(x) >= 2)['headquarters'].unique()
show the headquarters that have both companies in banking industry and companies in oil and gas industry.,"pd.series(list(set(company.loc[company['industry']=='banking', 'headquarters']).intersection(set(company.loc[company['industry']=='oil and gas', 'headquarters']))))"
show the names of companies and of employees.,"pd.merge(pd.merge(employment, people, on='people_id'), company, on='company_id')[['name_x', 'name_y']]"
show names of companies and that of employees in descending order of number of years working for that employee.,"pd.merge(pd.merge(employment, people, on='people_id'), company, on='company_id').sort_values('year_working')[['name_x', 'name_y']]"
show the names of employees that work for companies with sales bigger than 200.,"pd.merge(pd.merge(employment, people, on='people_id'), company, on='company_id').loc[lambda x: x['sales_in_billion'] > 200, 'name']"
show the names of companies and the number of employees they have,"employment.merge(people, on='people_id').merge(company, on='company_id').groupby('name')['name'].count()"
list the names of people that are not employed by any company,"people.loc[~people['people_id'].isin(employment['people_id']), 'name']"
list the names of the companies with more than 200 sales in the descending order of sales and profits.,"company.loc[lambda x: x['sales_in_billion'] > 200].sort_values(['sales_in_billion', 'profits_in_billion'], ascending=[true, false])['name']"
how many film are there?,film.shape[0]
count the number of films.,film.shape[0]
list the distinct director of all films.,film['director'].unique()
what are the different film directors?,film['director'].unique()
what is the average ticket sales gross in dollars of films?,film['gross_in_dollar'].mean()
return the average gross sales in dollars across all films.,film['gross_in_dollar'].mean()
what are the low and high estimates of film markets?,"film_market_estimation[['low_estimate', 'high_estimate']]"
return the low and high estimates for all film markets.,"film_market_estimation[['low_estimate', 'high_estimate']]"
what are the types of film market estimations in year 1995?,"film_market_estimation.loc[film_market_estimation['year'] == 1995, 'type']"
return the types of film market estimations in 1995.,"film_market_estimation.loc[film_market_estimation['year'] == 1995, 'type']"
what are the maximum and minimum number of cities in all markets.,"market['number_cities'].agg(['max', 'min'])"
return the maximum and minimum number of cities across all markets.,"market['number_cities'].agg(['max', 'min'])"
how many markets have number of cities smaller than 300?,(market['number_cities'] < 300).sum()
count the number of markets that have a number of cities lower than 300.,(market['number_cities'] < 300).sum()
list all countries of markets in ascending alphabetical order.,market.sort_values('country')['country']
"what are the countries for each market, ordered alphabetically?",market.sort_values('country')['country']
list all countries of markets in descending order of number of cities.,"market.sort_values('number_cities', ascending=false)['country']"
what are the countries for each market ordered by decreasing number of cities?,"market.sort_values('number_cities', ascending=false)['country']"
please show the titles of films and the types of market estimations.,"pd.merge(film, film_market_estimation, on='film_id')[['title', 'type']]"
what are the titles of films and corresponding types of market estimations?,"pd.merge(film, film_market_estimation, on='film_id')[['title', 'type']]"
show the distinct director of films with market estimation in the year of 1995.,"pd.merge(film, film_market_estimation, on='film_id').loc[lambda x: x['year']==1995, 'director'].unique()"
who are the different directors of films which had market estimation in 1995?,"pd.merge(film, film_market_estimation, on='film_id').loc[lambda x: x['year']==1995, 'director'].unique()"
what is the average number of cities of markets with low film market estimate bigger than 10000?,"pd.merge(film_market_estimation.loc[lambda x: x['low_estimate'] > 10000], market, on='market_id')['number_cities'].mean()"
give the average number of cities within markets that had a low market estimation larger than 10000?,"pd.merge(film_market_estimation.loc[lambda x: x['low_estimate'] > 10000], market, on='market_id')['number_cities'].mean()"
please list the countries and years of film market estimations.,"pd.merge(film_market_estimation, market, on='market_id')[['country', 'year']]"
what are the countries of markets and their corresponding years of market estimation?,"pd.merge(film_market_estimation, market, on='market_id')[['country', 'year']]"
"please list the years of film market estimations when the market is in country ""japan"" in descending order.","film_market_estimation.merge(market, on='market_id').query('country == ""japan""').sort_values('year', ascending=false)['year']"
"what are the years of film market estimation for the market of japan, ordered by year descending?","film_market_estimation.merge(market, on='market_id').query('country == ""japan""').sort_values('year', ascending=false)['year']"
list the studios of each film and the number of films produced by that studio.,film.groupby('studio').size().reset_index(name='count')
how films are produced by each studio?,film.groupby('studio').size().reset_index(name='count')
list the name of film studio that have the most number of films.,film.groupby('studio').size().sort_values(ascending=false).index[0]
what is the name of teh studio that created the most films?,film.groupby('studio').size().sort_values(ascending=false).index[0]
list the names of studios that have at least two films.,film.groupby('studio').filter(lambda x: len(x) >= 2)['studio'].unique()
what are the names of studios that have made two or more films?,film.groupby('studio').filter(lambda x: len(x) >= 2)['studio'].unique()
list the title of films that do not have any market estimation.,"film.loc[~film['film_id'].isin(film_market_estimation['film_id']), 'title']"
what are the titles of films that do not have a film market estimation?,"film.loc[~film['film_id'].isin(film_market_estimation['film_id']), 'title']"
"show the studios that have produced films with director ""nicholas meyer"" and ""walter hill"".","set(film.loc[film['director']=='nicholas meyer', 'studio']).intersection(set(film.loc[film['director']=='walter hill', 'studio']))"
what are the names of studios that have produced films with both nicholas meyer and walter hill?,"set(film.loc[film['director']=='nicholas meyer', 'studio']).intersection(set(film.loc[film['director']=='walter hill', 'studio']))"
"find the titles and studios of the films that are produced by some film studios that contained the word ""universal"".","film.loc[film['studio'].str.contains('universal'), ['title', 'studio']]"
"what are the titles and studios of films that have been produced by a studio whose name contains ""universal""?","film.loc[film['studio'].str.contains('universal'), ['title', 'studio']]"
"show the studios that have not produced films with director ""walter hill"".","film.loc[lambda x: x['director'] != 'walter hill', 'studio'].drop_duplicates()"
which studios have never worked with the director walter hill?,"film.loc[lambda x: x['director'] != 'walter hill', 'studio'].drop_duplicates()"
list the studios which average gross is above 4500000.,film.groupby('studio').filter(lambda x: x['gross_in_dollar'].mean() >= 4500000)['studio'].unique()
which studios have an average gross of over 4500000?,film.groupby('studio').filter(lambda x: x['gross_in_dollar'].mean() >= 4500000)['studio'].unique()
what is the title of the film that has the highest high market estimation.,"film.merge(film_market_estimation, on='film_id').sort_values('high_estimate', ascending=false).iloc[0]['title']"
return the title of the film with the highest high estimate?,"film.merge(film_market_estimation, on='film_id').sort_values('high_estimate', ascending=false).iloc[0]['title']"
what are the titles and directors of the films were never presented in china?,"film.loc[~film['film_id'].isin(film_market_estimation.merge(market.loc[lambda x: x['country']=='china'], left_on='market_id', right_on='market_id', how='inner')['film_id_x']), ['title', 'director']]"
return the titles and directors of films that were never in the market of china.,"film.loc[~film['film_id'].isin(film_market_estimation.merge(market.loc[lambda x: x['country']=='china'], left_on='market_id', right_on='market_id', how='inner')['film_id_x']), ['title', 'director']]"
how many calendar items do we have?,ref_calendar.shape[0]
count the number of all the calendar items.,ref_calendar.shape[0]
show all calendar dates and day numbers.,"ref_calendar[['calendar_date', 'day_number']]"
what are all the calendar dates and day numbers?,"ref_calendar[['calendar_date', 'day_number']]"
show the number of document types.,ref_document_types.shape[0]
how many document types are there?,ref_document_types.shape[0]
list all document type codes and document type names.,"ref_document_types[['document_type_code', 'document_type_name']]"
what are all the document type codes and document type names?,"ref_document_types[['document_type_code', 'document_type_name']]"
what is the name and description for document type code rv?,"ref_document_types.loc[lambda x: x['document_type_code']=='rv', ['document_type_name', 'document_type_description']]"
give me the name and description of the document type code rv.,"ref_document_types.loc[lambda x: x['document_type_code']=='rv', ['document_type_name', 'document_type_description']]"
"what is the document type code for document type ""paper""?","ref_document_types.loc[lambda x: x['document_type_name']=='paper', 'document_type_code']"
"find the code of the document type ""paper"".","ref_document_types.loc[lambda x: x['document_type_name']=='paper', 'document_type_code']"
show the number of documents with document type code cv or bk.,"all_documents.loc[lambda x: (x['document_type_code']=='cv') | (x['document_type_code']=='bk'), :].shape[0]"
how many documents have document type code cv or bk?,"all_documents.loc[lambda x: (x['document_type_code']=='cv') | (x['document_type_code']=='bk'), :].shape[0]"
"what is the date when the document ""marry cv"" was stored?","all_documents.loc[lambda x: x['document_name']=='marry cv', 'date_stored']"
"when was the document named ""marry cv"" stored? give me the date.","all_documents.loc[lambda x: x['document_name']=='marry cv', 'date_stored']"
what is the day number and date of all the documents?,"pd.merge(all_documents, ref_calendar, left_on='date_stored', right_on='calendar_date')[['day_number', 'date_stored']]"
return the day number and stored date for all the documents.,"pd.merge(all_documents, ref_calendar, left_on='date_stored', right_on='calendar_date')[['day_number', 'date_stored']]"
"what is the document type name for the document with name ""how to read a book""?","pd.merge(all_documents, ref_document_types, on='document_type_code').loc[lambda x: x['document_name']=='how to read a book', 'document_type_name']"
"find the document type name of the document named ""how to read a book"".","pd.merge(all_documents, ref_document_types, on='document_type_code').loc[lambda x: x['document_name']=='how to read a book', 'document_type_name']"
show the number of locations.,ref_locations.shape[0]
how many locations are listed in the database?,ref_locations.shape[0]
list all location codes and location names.,"ref_locations[['location_code', 'location_name']]"
what are all the location codes and location names?,"ref_locations[['location_code', 'location_name']]"
what are the name and description for location code x?,"ref_locations.loc[lambda x: x['location_code']=='x', ['location_name', 'location_description']]"
give me the name and description of the location with code x.,"ref_locations.loc[lambda x: x['location_code']=='x', ['location_name', 'location_description']]"
"what is the location code for the country ""canada""?","ref_locations.loc[lambda x: x['location_name']=='canada', 'location_code']"
"show the location code of the country ""canada"".","ref_locations.loc[lambda x: x['location_name']=='canada', 'location_code']"
how many roles are there?,roles.shape[0]
count the total number of roles listed.,roles.shape[0]
"list all role codes, role names, and role descriptions.","roles[['role_code', 'role_name', 'role_description']]"
"what are all the role codes, role names, and role descriptions?","roles[['role_code', 'role_name', 'role_description']]"
"what are the name and description for role code ""mg""?","roles.loc[lambda x: x['role_code']=='mg', ['role_name', 'role_description']]"
"find the name and description of the role with code ""mg"".","roles.loc[lambda x: x['role_code']=='mg', ['role_name', 'role_description']]"
"show the description for role name ""proof reader"".","roles.loc[lambda x: x['role_name']=='proof reader', 'role_description']"
"what is the description of the role named ""proof reader""?","roles.loc[lambda x: x['role_name']=='proof reader', 'role_description']"
find the number of employees we have.,employees.shape[0]
"show the name, role code, and date of birth for the employee with name 'armani'.","employees.loc[lambda x: x['employee_name']=='armani', ['employee_name', 'role_code', 'date_of_birth']]"
"what are the name, role code, and date of birth of the employee named 'armani'?","employees.loc[lambda x: x['employee_name']=='armani', ['employee_name', 'role_code', 'date_of_birth']]"
what is the id for the employee called ebba?,"employees.loc[lambda x: x['employee_name']=='ebba', 'employee_id']"
show the id of the employee named ebba.,"employees.loc[lambda x: x['employee_name']=='ebba', 'employee_id']"
"show the names of all the employees with role ""hr"".","employees.loc[lambda x: x['role_code']=='hr', 'employee_name']"
"which employees have the role with code ""hr""? find their names.","employees.loc[lambda x: x['role_code']=='hr', 'employee_name']"
show all role codes and the number of employees in each role.,employees.groupby('role_code').size()
what is the code of each role and the number of employees in each role?,employees.groupby('role_code').size()
what is the role code with the largest number of employees?,employees.groupby('role_code').size().sort_values(ascending=false).index[0]
find the code of the role that have the most employees.,employees.groupby('role_code').size().sort_values(ascending=false).index[0]
show all role codes with at least 3 employees.,employees.groupby('role_code').filter(lambda x: len(x) >= 3)['role_code'].unique()
what are the roles with three or more employees? give me the role codes.,employees.groupby('role_code').filter(lambda x: len(x) >= 3)['role_code'].unique()
show the role code with the least employees.,employees.groupby('role_code').size().sort_values().index[0]
what is the role with the smallest number of employees? find the role codes.,employees.groupby('role_code').size().sort_values().index[0]
what is the role name and role description for employee called ebba?,"pd.merge(employees, roles, on='role_code').loc[lambda x: x['employee_name']=='ebba', ['role_name', 'role_description']]"
show the name and description of the role played by the employee named ebba.,"pd.merge(employees, roles, on='role_code').loc[lambda x: x['employee_name']=='ebba', ['role_name', 'role_description']]"
show the names of employees with role name editor.,"pd.merge(employees, roles, on='role_code').loc[lambda x: x['role_name']=='editor', 'employee_name']"
"find the names of all the employees whose the role name is ""editor"".","pd.merge(employees, roles, on='role_code').loc[lambda x: x['role_name']=='editor', 'employee_name']"
"show the employee ids for all employees with role name ""human resource"" or ""manager"".","pd.merge(employees, roles, on='role_code').loc[lambda x: x['role_name'].isin(['human resource', 'manager']), 'employee_id']"
"what are the employee ids of the employees whose role name is ""human resource"" or ""manager""?","pd.merge(employees, roles, on='role_code').loc[lambda x: x['role_name'].isin(['human resource', 'manager']), 'employee_id']"
what are the different location codes for documents?,document_locations['location_code'].unique()
give me all the distinct location codes for documents.,document_locations['location_code'].unique()
"show the location name for document ""robin cv"".","pd.merge(pd.merge(all_documents.loc[lambda x: x['document_name']=='robin cv'], document_locations, on='document_id'), ref_locations, on='location_code')['location_name']"
"what is the location name of the document ""robin cv""?","pd.merge(pd.merge(all_documents.loc[lambda x: x['document_name']=='robin cv'], document_locations, on='document_id'), ref_locations, on='location_code')['location_name']"
"show the location code, the starting date and ending data in that location for all the documents.","document_locations[['location_code', 'date_in_location_from', 'date_in_locaton_to']]"
"what are each document's location code, and starting date and ending data in that location?","document_locations[['location_code', 'date_in_location_from', 'date_in_locaton_to']]"
"what is ""the date in location from"" and ""the date in location to"" for the document with name ""robin cv""?","pd.merge(document_locations, all_documents.loc[lambda x: x['document_name']=='robin cv'], on='document_id', how='inner')[['date_in_location_from','date_in_location_to']]"
"find the starting date and ending data in location for the document named ""robin cv"".","pd.merge(document_locations, all_documents.loc[lambda x: x['document_name']=='robin cv'], on='document_id', how='inner')[['date_in_location_from','date_in_location_to']]"
show the location codes and the number of documents in each location.,document_locations.groupby('location_code').size().reset_index(name='count')
what is the code of each location and the number of documents in that location?,document_locations.groupby('location_code').size().reset_index(name='count')
what is the location code with the most documents?,document_locations.groupby('location_code').size().sort_values(ascending=false).index[0]
find the code of the location with the largest number of documents.,document_locations.groupby('location_code').size().sort_values(ascending=false).index[0]
show the location codes with at least 3 documents.,document_locations.groupby('location_code').filter(lambda x: len(x) >= 3)['location_code'].unique()
what are the codes of the locations with at least three documents?,document_locations.groupby('location_code').filter(lambda x: len(x) >= 3)['location_code'].unique()
show the location name and code with the least documents.,"pd.merge(document_locations, ref_locations, on='location_code').groupby('location_code').size().sort_values().reset_index(name='count').iloc[0][['location_name', 'location_code']]"
what are the name and code of the location with the smallest number of documents?,"pd.merge(document_locations, ref_locations, on='location_code').groupby('location_code').size().sort_values().reset_index(name='count').iloc[0][['location_name', 'location_code']]"
what are the names of the employees who authorised the destruction and the employees who destroyed the corresponding documents?,"pd.merge(pd.merge(documents_to_be_destroyed, employees, left_on='destruction_authorised_by_employee_id', right_on='employee_id')[['employee_name', 'document_id']], employees, left_on='destroyed_by_employee_id', right_on='employee_id')[['employee_name_x', 'employee_name_y']]"
list the names of the employees who authorized the destruction of documents and the employees who destroyed the corresponding documents.,"pd.merge(pd.merge(documents_to_be_destroyed, employees, left_on='destruction_authorised_by_employee_id', right_on='employee_id')[['employee_name', 'document_id']], employees, left_on='destroyed_by_employee_id', right_on='employee_id')[['employee_name_x', 'employee_name_y']]"
show the id of each employee and the number of document destruction authorised by that employee.,documents_to_be_destroyed.groupby('destruction_authorised_by_employee_id').size().reset_index(name='count')
what are the id of each employee and the number of document destruction authorised by that employee?,documents_to_be_destroyed.groupby('destruction_authorised_by_employee_id').size().reset_index(name='count')
show the employee ids and the number of documents destroyed by each employee.,documents_to_be_destroyed['destroyed_by_employee_id'].value_counts()
what are the id of each employee and the number of document destroyed by that employee?,documents_to_be_destroyed['destroyed_by_employee_id'].value_counts()
show the ids of the employees who don't authorize destruction for any document.,"pd.concat([employees['employee_id'], documents_to_be_destroyed['destruction_authorised_by_employee_id']]).drop_duplicates(keep=false)"
which employees do not authorize destruction for any document? give me their employee ids.,"pd.concat([employees['employee_id'], documents_to_be_destroyed['destruction_authorised_by_employee_id']]).drop_duplicates(keep=false)"
show the ids of all employees who have authorized destruction.,documents_to_be_destroyed['destruction_authorised_by_employee_id'].unique()
what are the ids of all the employees who authorize document destruction?,documents_to_be_destroyed['destruction_authorised_by_employee_id'].unique()
show the ids of all employees who have destroyed a document.,documents_to_be_destroyed['destroyed_by_employee_id'].unique()
what are the ids of all the employees who have destroyed documents?,documents_to_be_destroyed['destroyed_by_employee_id'].unique()
show the ids of all employees who don't destroy any document.,employees[~employees['employee_id'].isin(documents_to_be_destroyed['destroyed_by_employee_id'])]['employee_id']
which employees do not destroy any document? find their employee ids.,employees[~employees['employee_id'].isin(documents_to_be_destroyed['destroyed_by_employee_id'])]['employee_id']
show the ids of all employees who have either destroyed a document or made an authorization to do this.,"pd.concat([documents_to_be_destroyed['destroyed_by_employee_id'], documents_to_be_destroyed['destruction_authorised_by_employee_id']]).reset_index(drop=true)"
which employees have either destroyed a document or made an authorization to do so? return their employee ids.,"pd.concat([documents_to_be_destroyed['destroyed_by_employee_id'], documents_to_be_destroyed['destruction_authorised_by_employee_id']]).reset_index(drop=true)"
count the total number of clubs.,club.shape[0] or len(club)
what are the names of all clubs?,club['clubname']
give me the name of each club.,club['clubname']
count the total number of students.,student.shape[0]
what are the first names of all the students?,student['fname'].unique()
find each student's first name.,student['fname'].unique()
"find the last names of the members of the club ""bootup baltimore"".","club.merge(member_of_club, on='clubid').merge(student, on='stuid').loc[lambda x: x['clubname']=='bootup baltimore', 'lname']"
"who are the members of the club named ""bootup baltimore""? give me their last names.","club.merge(member_of_club, on='clubid').merge(student, on='stuid').loc[lambda x: x['clubname']=='bootup baltimore', 'lname']"
"who are the members of the club named ""hopkins student enterprises""? show the last name.","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['clubname']=='hopkins student enterprises', 'lname']"
"return the last name for the members of the club named ""hopkins student enterprises"".","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['clubname']=='hopkins student enterprises', 'lname']"
"how many members does the club ""tennis club"" has?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['clubname']=='tennis club'].shape[0]"
"count the members of the club ""tennis club"".","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['clubname']=='tennis club'].shape[0]"
"find the number of members of club ""pen and paper gaming"".","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['clubname']=='pen and paper gaming'].shape[0]"
"how many people have membership in the club ""pen and paper gaming""?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['clubname']=='pen and paper gaming'].shape[0]"
"how many clubs does ""linda smith"" belong to?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: (x['fname']=='linda') & (x['lname']=='smith')].shape[0]"
"how many clubs does ""linda smith"" have membership for?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: (x['fname']=='linda') & (x['lname']=='smith')].shape[0]"
"find the number of clubs where ""tracy kim"" is a member.","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: (x['fname']=='tracy') & (x['lname']=='kim')].shape[0]"
"for how many clubs is ""tracy kim"" a member?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: (x['fname']=='tracy') & (x['lname']=='kim')].shape[0]"
"find all the female members of club ""bootup baltimore"". show the first name and last name.","pd.merge(pd.merge(club[club['clubname']=='bootup baltimore'], member_of_club, on='clubid'), student[student['sex']=='f'], left_on='stuid', right_on='stuid')[['fname', 'lname']]"
"give me the first name and last name for all the female members of the club ""bootup baltimore"".","pd.merge(pd.merge(club[club['clubname']=='bootup baltimore'], member_of_club, on='clubid'), student[student['sex']=='f'], left_on='stuid', right_on='stuid')[['fname', 'lname']]"
"find all the male members of club ""hopkins student enterprises"". show the first name and last name.","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[(lambda x: (x['clubname']=='hopkins student enterprises') & (x['sex']=='m')) , ['fname', 'lname']]"
"what are the first name and last name of each male member in club ""hopkins student enterprises""?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[(lambda x: (x['clubname']=='hopkins student enterprises') & (x['sex']=='m')) , ['fname', 'lname']]"
"find all members of ""bootup baltimore"" whose major is ""600"". show the first name and last name.","pd.merge(pd.merge(club[club['clubname']=='bootup baltimore'], member_of_club, on='clubid'), student[student['major']=='600'], left_on='stuid', right_on='stuid')[['fname', 'lname']]"
"which members of ""bootup baltimore"" major in ""600""? give me their first names and last names.","pd.merge(pd.merge(club[club['clubname']=='bootup baltimore'], member_of_club, on='clubid'), student[student['major']=='600'], left_on='stuid', right_on='stuid')[['fname', 'lname']]"
"which club has the most members majoring in ""600""?","club.merge(member_of_club, on='clubid').merge(student.loc[lambda x: x['major']=='600'], left_on='stuid', right_on='stuid')['clubname'].value_counts().index[0]"
"find the club which has the largest number of members majoring in ""600"".","club.merge(member_of_club, on='clubid').merge(student.loc[lambda x: x['major']=='600'], left_on='stuid', right_on='stuid')['clubname'].value_counts().index[0]"
find the name of the club that has the most female students.,"pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: x['sex']=='f'].groupby('clubname').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['clubname']"
which club has the most female students as their members? give me the name of the club.,"pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: x['sex']=='f'].groupby('clubname').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['clubname']"
"what is the description of the club named ""tennis club""?","club.loc[lambda x: x['clubname']=='tennis club', 'clubdesc']"
"find the description of the club called ""tennis club"".","club.loc[lambda x: x['clubname']=='tennis club', 'clubdesc']"
"find the description of the club ""pen and paper gaming"".","club.loc[lambda x: x['clubname']=='pen and paper gaming', 'clubdesc']"
"what is the description of the club ""pen and paper gaming""?","club.loc[lambda x: x['clubname']=='pen and paper gaming', 'clubdesc']"
"what is the location of the club named ""tennis club""?","club.loc[lambda x: x['clubname']=='tennis club', 'clublocation']"
"where us the club named ""tennis club"" located?","club.loc[lambda x: x['clubname']=='tennis club', 'clublocation']"
"find the location of the club ""pen and paper gaming"".","club.loc[lambda x: x['clubname']==""pen and paper gaming"", 'clublocation']"
"where is the club ""pen and paper gaming"" located?","club.loc[lambda x: x['clubname']==""pen and paper gaming"", 'clublocation']"
"where is the club ""hopkins student enterprises"" located?","club.loc[club['clubname'] == 'hopkins student enterprises', 'clublocation']"
"tell me the location of the club ""hopkins student enterprises"".","club.loc[club['clubname'] == 'hopkins student enterprises', 'clublocation']"
"find the name of all the clubs at ""akw"".","club.loc[lambda x: x['clublocation']=='akw', 'clubname']"
"which clubs are located at ""akw""? return the club names.","club.loc[lambda x: x['clublocation']=='akw', 'clubname']"
"how many clubs are located at ""hhh""?",(club['clublocation'] == 'hhh').sum()
"count the number of clubs located at ""hhh"".",(club['clublocation'] == 'hhh').sum()
"what are the first and last name of the president of the club ""bootup baltimore""?","student.loc[lambda x: x['stuid'].isin(member_of_club.loc[lambda y: (y['position']=='president') & (y['clubid'].isin(club.loc[lambda z: z['clubname']=='bootup baltimore', 'clubid'])),'stuid']),['fname','lname']]"
"who is the president of the club ""bootup baltimore""? give me the first and last name.","student.loc[lambda x: x['stuid'].isin(member_of_club.loc[lambda y: (y['position']=='president') & (y['clubid'].isin(club.loc[lambda z: z['clubname']=='bootup baltimore', 'clubid'])),'stuid']),['fname','lname']]"
"who is the ""cto"" of club ""hopkins student enterprises""? show the first name and last name.","student.merge(member_of_club.merge(club.loc[lambda x: x['clubname']=='hopkins student enterprises'], on='clubid').loc[lambda x: x['position']=='cto'], on='stuid')[['fname', 'lname']]"
"find the first name and last name for the ""cto"" of the club ""hopkins student enterprises""?","student.merge(member_of_club.merge(club.loc[lambda x: x['clubname']=='hopkins student enterprises'], on='clubid').loc[lambda x: x['position']=='cto'], on='stuid')[['fname', 'lname']]"
"how many different roles are there in the club ""bootup baltimore""?","pd.merge(club[club['clubname']=='bootup baltimore'], member_of_club, on='clubid')['position'].nunique()"
"count the number of different positions in the club ""bootup baltimore"".","pd.merge(club[club['clubname']=='bootup baltimore'], member_of_club, on='clubid')['position'].nunique()"
"how many members of ""bootup baltimore"" are older than 18?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: (x['clubname']=='bootup baltimore') & (x['age']>18)].shape[0]"
"count the number of members in club ""bootup baltimore"" whose age is above 18.","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: (x['clubname']=='bootup baltimore') & (x['age']>18)].shape[0]"
"how many members of club ""bootup baltimore"" are younger than 18?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[(lambda x: x['clubname'] == 'bootup baltimore') & (lambda x: x['age'] < 18), :].shape[0]"
"count the number of members in club ""bootup baltimore"" whose age is below 18.","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[(lambda x: x['clubname'] == 'bootup baltimore') & (lambda x: x['age'] < 18), :].shape[0]"
"find the names of all the clubs that have at least a member from the city with city code ""bal"".","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['city_code']=='bal', 'clubname'].unique()"
"which clubs have one or more members from the city with code ""bal""? give me the names of the clubs.","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['city_code']=='bal', 'clubname'].unique()"
"find the names of the clubs that have at least a member from the city with city code ""hou"".","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['city_code']=='hou', 'clubname'].unique()"
"which clubs have one or more members from the city with code ""hou""? give me the names of the clubs.","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['city_code']=='hou', 'clubname'].unique()"
"how many clubs does the student named ""eric tai"" belong to?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: (x['fname']=='eric') & (x['lname']=='tai'), 'clubname'].nunique()"
"count the number of clubs for which the student named ""eric tai"" is a member.","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: (x['fname']=='eric') & (x['lname']=='tai'), 'clubname'].nunique()"
"list the clubs having ""davis steven"" as a member.","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: (x['fname']=='davis') & (x['lname']=='steven'), 'clubname'].unique()"
"what are the names of the clubs that have ""davis steven"" as a member?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: (x['fname']=='davis') & (x['lname']=='steven'), 'clubname'].unique()"
"list the clubs that have at least a member with advisor ""1121"".","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['advisor']==1121, 'clubname'].unique()"
"which clubs have one or more members whose advisor is ""1121""?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['advisor']==1121, 'clubname'].unique()"
"what is the average age of the members of the club ""bootup baltimore""?","student.loc[lambda x: x['stuid'].isin(member_of_club.loc[lambda x: x['clubid'].isin(club.loc[lambda x: x['clubname']=='bootup baltimore']['clubid']), 'stuid'])]['age'].mean()"
"find the average age of the members in the club ""bootup baltimore"".","student.loc[lambda x: x['stuid'].isin(member_of_club.loc[lambda x: x['clubid'].isin(club.loc[lambda x: x['clubname']=='bootup baltimore']['clubid']), 'stuid'])]['age'].mean()"
"find the average age of members of the club ""hopkins student enterprises"".","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['clubname']=='hopkins student enterprises', 'age'].mean()"
"on average, how old are the members in the club ""hopkins student enterprises""?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['clubname']=='hopkins student enterprises', 'age'].mean()"
"retrieve the average age of members of the club ""tennis club"".","student.merge(member_of_club.merge(club.query('clubname == ""tennis club""'), on='clubid'), on='stuid')['age'].mean()"
"compute the average age of the members in the club ""tennis club"".","student.merge(member_of_club.merge(club.query('clubname == ""tennis club""'), on='clubid'), on='stuid')['age'].mean()"
what are the distinct grant amount for the grants where the documents were sent before '1986-08-26 20:49:27' and grant were ended after '1989-03-16 18:27:16'?,"pd.merge(grants.loc[grants['grant_end_date'] > '1989-03-16 18:27:16', ['grant_id', 'grant_amount']], documents.loc[documents['sent_date'] < '1986-08-26 20:49:27', ['grant_id']], on='grant_id')['grant_amount'].unique()"
what are the different grant amounts for documents sent before '1986-08-26 20:49:27' and after the grant ended on '1989-03-16 18:27:16'?,"pd.merge(grants.loc[grants['grant_end_date'] > '1989-03-16 18:27:16', ['grant_id', 'grant_amount']], documents.loc[documents['sent_date'] < '1986-08-26 20:49:27', ['grant_id']], on='grant_id')['grant_amount'].unique()"
list the project details of the project both producing patent and paper as outcomes.,"pd.merge(projects[projects['project_id'].isin(project_outcomes[project_outcomes['outcome_code']=='paper']['project_id'])], projects[projects['project_id'].isin(project_outcomes[project_outcomes['outcome_code']=='patent']['project_id'])])['project_details'].tolist()"
what are the details of the project that is producing both patents and papers as outcomes?,"pd.merge(projects[projects['project_id'].isin(project_outcomes[project_outcomes['outcome_code']=='paper']['project_id'])], projects[projects['project_id'].isin(project_outcomes[project_outcomes['outcome_code']=='patent']['project_id'])])['project_details'].tolist()"
what is the total grant amount of the organisations described as research?,"pd.merge(pd.merge(grants, organisations, on='organisation_id'), organisation_types, on='organisation_type').loc[lambda x: x['organisation_type_description']=='research', 'grant_amount'].sum()"
what is the total amount of grant money for research?,"pd.merge(pd.merge(grants, organisations, on='organisation_id'), organisation_types, on='organisation_type').loc[lambda x: x['organisation_type_description']=='research', 'grant_amount'].sum()"
list from which date and to which date these staff work: project staff of the project which hires the most staffs,"project_staff.loc[lambda df: df['project_id'].isin(project_staff.groupby('project_id').size().sort_values().tail(1).index), ['date_from', 'date_to']].append(project_staff.loc[lambda df: df['role_code']=='leader', ['date_from', 'date_to']])"
from what date and to what date do the staff work on a project that has the most staff and has staff in a leader role?,"project_staff.loc[lambda df: df['project_id'].isin(project_staff.groupby('project_id').size().sort_values().tail(1).index), ['date_from', 'date_to']].append(project_staff.loc[lambda df: df['role_code']=='leader', ['date_from', 'date_to']])"
find the organisation ids and details of the organisations which are involved in,"grants.merge(organisations, on='organisation_id').groupby(['organisation_id', 'organisation_details']).filter(lambda x: x['grant_amount'].sum() > 6000)[['organisation_id', 'organisation_details']].drop_duplicates()"
what are the ids and details for all organizations that have grants of more than 6000 dollars?,"grants.merge(organisations, on='organisation_id').groupby(['organisation_id', 'organisation_details']).filter(lambda x: x['grant_amount'].sum() > 6000)[['organisation_id', 'organisation_details']].drop_duplicates()"
what is the organisation type and id of the organisation which has the most number of research staff?,"pd.merge(organisations, research_staff, left_on='organisation_id', right_on='employer_organisation_id').groupby(['organisation_type', 'organisation_id']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['organisation_type', 'organisation_id']]"
what is the type and id of the organization that has the most research staff?,"pd.merge(organisations, research_staff, left_on='organisation_id', right_on='employer_organisation_id').groupby(['organisation_type', 'organisation_id']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['organisation_type', 'organisation_id']]"
which organisation type hires most research staff?,"pd.merge(organisations, research_staff, left_on='organisation_id', right_on='employer_organisation_id').groupby('organisation_type').size().idxmax()"
what is the type of the organization with the most research staff?,"pd.merge(organisations, research_staff, left_on='organisation_id', right_on='employer_organisation_id').groupby('organisation_type').size().idxmax()"
find out the send dates of the documents with the grant amount of more than 5000 were granted by organisation type described,"pd.merge(pd.merge(pd.merge(documents, grants, on='grant_id'), organisations, on='organisation_id'), organisation_types, on='organisation_type').loc[lambda x: (x['grant_amount'] > 5000) & (x['organisation_type_description'] == 'research'), 'sent_date']"
what are the send dates for all documents that have a grant amount of more than 5000 and are involved in research?,"pd.merge(pd.merge(pd.merge(documents, grants, on='grant_id'), organisations, on='organisation_id'), organisation_types, on='organisation_type').loc[lambda x: (x['grant_amount'] > 5000) & (x['organisation_type_description'] == 'research'), 'sent_date']"
what are the response received dates for the documents described as 'regular' or granted with more than 100?,"pd.merge(pd.merge(documents, document_types, on='document_type_code'), grants, on='grant_id').loc[lambda x: (x['document_description']=='regular') | (x['grant_amount']>100), 'response_received_date']"
what is the response received date for the document described as regular that was granted more than 100 dollars?,"pd.merge(pd.merge(documents, document_types, on='document_type_code'), grants, on='grant_id').loc[lambda x: (x['document_description']=='regular') | (x['grant_amount']>100), 'response_received_date']"
list the project details of the projects which did not hire any staff for a researcher role.,"projects.loc[~projects['project_id'].isin(project_staff.loc[project_staff['role_code']=='researcher', 'project_id']), 'project_details']"
what are the details for all projects that did not hire any staff in a research role?,"projects.loc[~projects['project_id'].isin(project_staff.loc[project_staff['role_code']=='researcher', 'project_id']), 'project_details']"
"what are the task details, task id and project id for the projects which are detailed as 'omnis' or  have more than 2 outcomes?","pd.concat([pd.merge(tasks, projects, on='project_id').query(""project_details=='omnis'""), pd.merge(pd.merge(tasks, projects, on='project_id'), project_outcomes, on='project_id').groupby('project_id').filter(lambda x: len(x) > 2)], sort=false) [['task_details', 'task_id', 'project_id']].drop_duplicates()"
"what are the task details, task ids, and project ids for the progrects that are detailed as 'omnis' or have at least 3 outcomes?","pd.concat([pd.merge(tasks, projects, on='project_id').query(""project_details=='omnis'""), pd.merge(pd.merge(tasks, projects, on='project_id'), project_outcomes, on='project_id').groupby('project_id').filter(lambda x: len(x) > 2)], sort=false) [['task_details', 'task_id', 'project_id']].drop_duplicates()"
"when do all the researcher role staff start to work, and when do they stop working?","project_staff.loc[lambda x: x['role_code']=='researcher', ['date_from', 'date_to']]"
when did researchers start and stop working?,"project_staff.loc[lambda x: x['role_code']=='researcher', ['date_from', 'date_to']]"
how many kinds of roles are there for the staff?,project_staff['role_code'].nunique()
how many different roles are there on the project staff?,project_staff['role_code'].nunique()
what is the total amount of grants given by each organisations? also list the organisation id.,grants.groupby('organisation_id')['grant_amount'].sum()
what is the total amount of grant money given to each organization and what is its id?,grants.groupby('organisation_id')['grant_amount'].sum()
list the project details of the projects with the research outcome described with the substring 'published'.,"pd.merge(pd.merge(projects, project_outcomes, on='project_id'), research_outcomes, on='outcome_code').loc[lambda x: x['outcome_description'].str.contains('published'), 'project_details']"
what are the details for the project whose research has been published?,"pd.merge(pd.merge(projects, project_outcomes, on='project_id'), research_outcomes, on='outcome_code').loc[lambda x: x['outcome_description'].str.contains('published'), 'project_details']"
how many staff does each project has? list the project id and the number in an ascending order.,"pd.merge(project_staff, projects, on='project_id').groupby('project_id').size().sort_values().reset_index(name='count')"
"for each project id, how many staff does it have? list them in increasing order.","pd.merge(project_staff, projects, on='project_id').groupby('project_id').size().sort_values().reset_index(name='count')"
what is the complete description of the researcher role.,"staff_roles.loc[lambda x: x['role_code']=='researcher', 'role_description']"
what is the complete description of the job of a researcher?,"staff_roles.loc[lambda x: x['role_code']=='researcher', 'role_description']"
when did the first staff for the projects started working?,project_staff.sort_values('date_from').iloc[0]['date_from']
when did the first staff member start working?,project_staff.sort_values('date_from').iloc[0]['date_from']
which project made the most number of outcomes? list the project details and the project id.,"pd.merge(projects, project_outcomes, on='project_id').groupby('project_id').size().idxmax()"
what are the details and id of the project with the most outcomes?,"pd.merge(projects, project_outcomes, on='project_id').groupby('project_id').size().idxmax()"
which projects have no outcome? list the project details.,"projects.loc[~projects['project_id'].isin(project_outcomes['project_id']), 'project_details']"
what are the details of the project with no outcomes?,"projects.loc[~projects['project_id'].isin(project_outcomes['project_id']), 'project_details']"
"which organisation hired the most number of research staff? list the organisation id, type and detail.","pd.merge(organisations, research_staff, left_on='organisation_id', right_on='employer_organisation_id').groupby(['organisation_id', 'organisation_type', 'organisation_details']).size().sort_values(ascending=false).reset_index().iloc[0]"
"what are the ids, types, and details of the organization with the most research staff?","pd.merge(organisations, research_staff, left_on='organisation_id', right_on='employer_organisation_id').groupby(['organisation_id', 'organisation_type', 'organisation_details']).size().sort_values(ascending=false).reset_index().iloc[0]"
show the role description and the id of the project staff involved in most number of project outcomes?,"pd.merge(pd.merge(staff_roles, project_staff, on='role_code'), project_outcomes, on='project_id').groupby('staff_id').size().sort_values(ascending=false).reset_index(name='count').iloc[0][['role_description', 'staff_id']]"
"for each staff id, what is the description of the role that is involved with the most number of projects?","pd.merge(pd.merge(staff_roles, project_staff, on='role_code'), project_outcomes, on='project_id').groupby('staff_id').size().sort_values(ascending=false).reset_index(name='count').iloc[0][['role_description', 'staff_id']]"
which document type is described with the prefix 'initial'?,"document_types.loc[lambda x: x['document_description'].str.startswith('initial'), 'document_type_code']"
what is the type of the document whose description starts with the word 'initial'?,"document_types.loc[lambda x: x['document_description'].str.startswith('initial'), 'document_type_code']"
"for grants with both documents described as 'regular' and documents described as 'initial application', list its start date.","pd.merge(pd.merge(grants, documents, on='grant_id'), document_types, on='document_type_code').loc[lambda x: x['document_description']=='regular', 'grant_start_date'].unique() & pd.merge(pd.merge(grants, documents, on='grant_id'), document_types, on='document_type_code').loc[lambda x: x['document_description']=='initial application', 'grant_start_date'].unique()"
"for grants that have descriptions of regular and initial applications, what are their start dates?","pd.merge(pd.merge(grants, documents, on='grant_id'), document_types, on='document_type_code').loc[lambda x: x['document_description']=='regular', 'grant_start_date'].unique() & pd.merge(pd.merge(grants, documents, on='grant_id'), document_types, on='document_type_code').loc[lambda x: x['document_description']=='initial application', 'grant_start_date'].unique()"
how many documents can one grant have at most? list the grant id and number.,"documents.groupby('grant_id').size().nlargest(1).reset_index(name='count')[['grant_id', 'count']]"
"for each grant id, how many documents does it have, and which one has the most?","documents.groupby('grant_id').size().nlargest(1).reset_index(name='count')[['grant_id', 'count']]"
find the organisation type description of the organisation detailed as 'quo'.,"pd.merge(organisation_types, organisations, on='organisation_type').loc[lambda x: x['organisation_details']=='quo', 'organisation_type_description']"
what is the type description of the organization whose detail is listed as 'quo'?,"pd.merge(organisation_types, organisations, on='organisation_type').loc[lambda x: x['organisation_details']=='quo', 'organisation_type_description']"
what are all the details of the organisations described as 'sponsor'? sort the result in an ascending order.,"pd.merge(organisations, organisation_types, on='organisation_type').loc[lambda x: x['organisation_type_description']=='sponsor'].sort_values('organisation_details')['organisation_details']"
what are the details of all organizations that are described as sponsors and sort the results in ascending order?,"pd.merge(organisations, organisation_types, on='organisation_type').loc[lambda x: x['organisation_type_description']=='sponsor'].sort_values('organisation_details')['organisation_details']"
how many patent outcomes are generated from all the projects?,(project_outcomes['outcome_code'] == 'patent').sum()
how many patents outcomes were listed for all the projects?,(project_outcomes['outcome_code'] == 'patent').sum()
how many project staff worked as leaders or started working before '1989-04-24 23:51:54'?,((project_staff['role_code']=='leader')|(project_staff['date_from']<'1989-04-24 23:51:54')).sum()
how many project members were leaders or started working before '1989-04-24 23:51:54'?,((project_staff['role_code']=='leader')|(project_staff['date_from']<'1989-04-24 23:51:54')).sum()
what is the last date of the staff leaving the projects?,"project_staff.sort_values('date_to', ascending=false).iloc[0]['date_to']"
what is the last date that a staff member left a project?,"project_staff.sort_values('date_to', ascending=false).iloc[0]['date_to']"
what are the result description of the project whose detail is 'sint'?,"pd.merge(pd.merge(research_outcomes, project_outcomes, on='outcome_code'), projects, on='project_id').loc[lambda x: x['project_details']=='sint', 'outcome_description']"
what is the description for the results whose project detail is 'sint'?,"pd.merge(pd.merge(research_outcomes, project_outcomes, on='outcome_code'), projects, on='project_id').loc[lambda x: x['project_details']=='sint', 'outcome_description']"
"list the organisation id with the maximum outcome count, and the count.","projects.merge(project_outcomes, on='project_id').groupby('organisation_id').size().sort_values(ascending=false).iloc[[0]]"
what is the id of the organization with the maximum number of outcomes and how many outcomes are there?,"projects.merge(project_outcomes, on='project_id').groupby('organisation_id').size().sort_values(ascending=false).iloc[[0]]"
list the project details of the projects launched by the organisation,"projects.loc[lambda x: x['organisation_id'].isin(projects.groupby('organisation_id').size().sort_values(ascending=false).index[0:1]), 'project_details']"
what are the details for the projects which were launched by the organization with the most projects?,"projects.loc[lambda x: x['organisation_id'].isin(projects.groupby('organisation_id').size().sort_values(ascending=false).index[0:1]), 'project_details']"
"list the research staff details, and order in ascending order.",research_staff.sort_values('staff_details')['staff_details']
what details are there on the research staff? list the result in ascending alphabetical order.,research_staff.sort_values('staff_details')['staff_details']
how many tasks are there in total?,tasks.shape[0]
how many tasks are there?,tasks.shape[0]
how many tasks does each project have? list the task count and the project detail.,"pd.merge(projects, tasks, on='project_id').groupby('project_id').agg({'project_details': 'first', '*': 'count'})"
"for each project id, how many tasks are there?","pd.merge(projects, tasks, on='project_id').groupby('project_id').agg({'project_details': 'first', '*': 'count'})"
what are the staff roles of the staff who,"project_staff.loc[(project_staff['date_from'] > '2003-04-19 15:06:20') & (project_staff['date_to'] < '2016-03-15 00:33:18'), 'role_code']"
what roles did staff members play between '2003-04-19 15:06:20' and '2016-03-15 00:33:18'?,"project_staff.loc[(project_staff['date_from'] > '2003-04-19 15:06:20') & (project_staff['date_to'] < '2016-03-15 00:33:18'), 'role_code']"
what are the descriptions of all the project outcomes?,"pd.merge(research_outcomes, project_outcomes, on='outcome_code')['outcome_description']"
list the description of the outcomes for all projects.,"pd.merge(research_outcomes, project_outcomes, on='outcome_code')['outcome_description']"
which role is most common for the staff?,project_staff.groupby('role_code').size().sort_values(ascending=false).index[0]
what is the most common role for the staff?,project_staff.groupby('role_code').size().sort_values(ascending=false).index[0]
how many friends does dan have?,"pd.merge(person, personfriend, on='name').loc[lambda x: x['name']=='dan', 'friend'].count()"
how many females does this network has?,(person['gender'] == 'female').sum()
how many females are in the network?,(person['gender'] == 'female').sum()
what is the average age for all person?,person['age'].mean()
what is the average age for all people in the table?,person['age'].mean()
how many different cities are they from?,person['city'].nunique()
how many different cities do people originate from?,person['city'].nunique()
how many type of jobs do they have?,person['job'].nunique()
how many different jobs are listed?,person['job'].nunique()
who is the oldest person?,"person.loc[person['age'] == person['age'].max(), 'name']"
what is the name of the person who is the oldest?,"person.loc[person['age'] == person['age'].max(), 'name']"
who is the oldest person whose job is student?,"person.loc[lambda x: (x['job']=='student') & (x['age']==x.loc[x['job']=='student', 'age'].max()), 'name']"
what is the name of the oldest student?,"person.loc[lambda x: (x['job']=='student') & (x['age']==x.loc[x['job']=='student', 'age'].max()), 'name']"
who is the youngest male?,"person.loc[lambda x: (x['gender']=='male') & (x['age']==person.loc[lambda y: y['gender']=='male', 'age'].min()), 'name']"
what is the name of the youngest male?,"person.loc[lambda x: (x['gender']=='male') & (x['age']==person.loc[lambda y: y['gender']=='male', 'age'].min()), 'name']"
how old is the doctor named zach?,"person.loc[(person['job']=='doctor') & (person['name']=='zach'), 'age']"
what is the age of the doctor named zach?,"person.loc[(person['job']=='doctor') & (person['name']=='zach'), 'age']"
who is the person whose age is below 30?,"person.loc[lambda x: x['age'] < 30, 'name']"
what is the name of the person whose age is below 30?,"person.loc[lambda x: x['age'] < 30, 'name']"
how many people whose age is greater 30 and job is engineer?,"person.loc[(person['age'] > 30) & (person['job'] == 'engineer'), :].shape[0]"
how many engineers are older than 30?,"person.loc[(person['age'] > 30) & (person['job'] == 'engineer'), :].shape[0]"
what is the average age for each gender?,person.groupby('gender')['age'].mean()
"how old is each gender, on average?",person.groupby('gender')['age'].mean()
what is average age for different job title?,person.groupby('job')['age'].mean()
how old is the average person for each job?,person.groupby('job')['age'].mean()
what is average age of male for different job title?,person[person['gender']=='male'].groupby('job')['age'].mean()
what is the average age for a male in each job?,person[person['gender']=='male'].groupby('job')['age'].mean()
what is minimum age for different job title?,person.groupby('job')['age'].min()
how old is the youngest person for each job?,person.groupby('job')['age'].min()
find the number of people who is under 40 for each gender.,person.loc[person['age']<40].groupby(['gender']).size().reset_index(name='count')
how many people are under 40 for each gender?,person.loc[person['age']<40].groupby(['gender']).size().reset_index(name='count')
find the name of people whose age is greater than any engineer sorted by their age.,"person.loc[lambda x: x['age'] > person.loc[person['job'] == 'engineer', 'age'].min()].sort_values('age')['name']"
what is the name of all the people who are older than at least one engineer? order them by age.,"person.loc[lambda x: x['age'] > person.loc[person['job'] == 'engineer', 'age'].min()].sort_values('age')['name']"
find the number of people whose age is greater than all engineers.,"person.loc[lambda x: x['age'] > person.loc[lambda y: y['job']=='engineer', 'age'].max()].shape[0]"
how many people are older than every engineer?,"person.loc[lambda x: x['age'] > person.loc[lambda y: y['job']=='engineer', 'age'].max()].shape[0]"
"list the name, job title of all people ordered by their names.","person[['name', 'job']].sort_values('name')"
what are the names and job titles of every person ordered alphabetically by name?,"person[['name', 'job']].sort_values('name')"
find the names of all person sorted in the descending order using age.,"person.sort_values('age', ascending=false)['name']"
what are the names of everybody sorted by age in descending order?,"person.sort_values('age', ascending=false)['name']"
find the name and age of all males in order of their age.,person.loc[lambda x: x['gender']=='male'].sort_values('age')['name']
what is the name and age of every male? order the results by age.,person.loc[lambda x: x['gender']=='male'].sort_values('age')['name']
find the name and age of the person who is a friend of both dan and alice.,"person.merge(person_friend.loc[lambda x: x['friend']=='dan'], on='name')[['name', 'age']].merge(person_friend.loc[lambda x: x['friend']=='alice'], on='name')[['name', 'age']]"
what are the names and ages of every person who is a friend of both dan and alice?,"person.merge(person_friend.loc[lambda x: x['friend']=='dan'], on='name')[['name', 'age']].merge(person_friend.loc[lambda x: x['friend']=='alice'], on='name')[['name', 'age']]"
find the name and age of the person who is a friend of dan or alice.,"pd.merge(person, personfriend, on='name').loc[lambda x: x['friend'].isin(['dan', 'alice']), ['name', 'age']].drop_duplicates()"
what are the different names and ages of every friend of either dan or alice?,"pd.merge(person, personfriend, on='name').loc[lambda x: x['friend'].isin(['dan', 'alice']), ['name', 'age']].drop_duplicates()"
find the name of the person who has friends with age above 40 and under age 30?,"person_friend.merge(person.loc[person['age'] > 40][['name']], on='friend').merge(person.loc[person['age'] < 30][['name']], on=['name']).drop_duplicates()['name']"
what are the names of every person who has a friend over 40 and under 30?,"person_friend.merge(person.loc[person['age'] > 40][['name']], on='friend').merge(person.loc[person['age'] < 30][['name']], on=['name']).drop_duplicates()['name']"
find the name of the person who has friends with age above 40 but not under age 30?,"set(pd.merge(person, personfriend, on='name').loc[lambda x: x['friend'].isin(person.loc[lambda y: y['age'] > 40, 'name']), 'name']) - set(pd.merge(person, personfriend, on='name').loc[lambda x: x['friend'].isin(person.loc[lambda y: y['age'] < 30, 'name']), 'name'])"
what are the names of the people who are older 40 but no friends under age 30?,"set(pd.merge(person, personfriend, on='name').loc[lambda x: x['friend'].isin(person.loc[lambda y: y['age'] > 40, 'name']), 'name']) - set(pd.merge(person, personfriend, on='name').loc[lambda x: x['friend'].isin(person.loc[lambda y: y['age'] < 30, 'name']), 'name'])"
find the name of the person who has no student friends.,"person[~person['name'].isin(person.merge(person_friend, left_on='name', right_on='friend').loc[lambda x: x['job']=='student', 'name_x'])]['name']"
what are the names of the people who have no friends who are students?,"person[~person['name'].isin(person.merge(person_friend, left_on='name', right_on='friend').loc[lambda x: x['job']=='student', 'name_x'])]['name']"
find the person who has exactly one friend.,personfriend.groupby('name').filter(lambda x: len(x) == 1)['name']
what are the names of everybody who has exactly one friend?,personfriend.groupby('name').filter(lambda x: len(x) == 1)['name']
who are the friends of bob?,"personfriend.merge(person.loc[lambda x: x['name']=='bob'], on='name')['friend']"
who are bob's friends?,"personfriend.merge(person.loc[lambda x: x['name']=='bob'], on='name')['friend']"
find the name of persons who are friends with bob.,"pd.merge(df_person, df_personfriend, on='name').loc[lambda x: x['friend']=='bob', 'name']"
what are the names of all of bob's friends?,"pd.merge(df_person, df_personfriend, on='name').loc[lambda x: x['friend']=='bob', 'name']"
find the names of females who are friends with zach,"pd.merge(person, person_friend, on='name').loc[lambda x: (x['friend']=='zach') & (x['gender']=='female'), 'name']"
what are the names of all females who are friends with zach?,"pd.merge(person, person_friend, on='name').loc[lambda x: (x['friend']=='zach') & (x['gender']=='female'), 'name']"
find the female friends of alice.,"pd.merge(personfriend.loc[lambda x: x['name']=='alice'], person.loc[lambda x: (x['gender']=='female') & (x['name']==personfriend.loc[lambda x: x['name']=='alice', 'friend'].iloc[0])], left_on='friend', right_on='name')['friend']"
what are all the friends of alice who are female?,"pd.merge(personfriend.loc[lambda x: x['name']=='alice'], person.loc[lambda x: (x['gender']=='female') & (x['name']==personfriend.loc[lambda x: x['name']=='alice', 'friend'].iloc[0])], left_on='friend', right_on='name')['friend']"
find the male friend of alice whose job is a doctor?,"pd.merge(personfriend.loc[lambda x: x['name']=='alice'], person.loc[(person['gender']=='male') & (person['job']=='doctor')], left_on='friend', right_on='name')['friend']"
who are the friends of alice that are doctors?,"pd.merge(personfriend.loc[lambda x: x['name']=='alice'], person.loc[(person['gender']=='male') & (person['job']=='doctor')], left_on='friend', right_on='name')['friend']"
who has a friend that is from new york city?,"person.merge(person_friend, left_on='name', right_on='friend').loc[lambda x: x['city']=='new york city', 'name_y']"
what are the names of all friends who are from new york?,"person.merge(person_friend, left_on='name', right_on='friend').loc[lambda x: x['city']=='new york city', 'name_y']"
who has friends that are younger than the average age?,"person_friend.loc[person_friend['friend'].isin(person.loc[person['age'] < person['age'].mean(), 'name'].values), 'name'].unique()"
what are the different names of friends who are younger than the average age for a friend?,"person_friend.loc[person_friend['friend'].isin(person.loc[person['age'] < person['age'].mean(), 'name'].values), 'name'].unique()"
who has friends that are older than the average age? print their friends and their ages as well,"person.merge(person_friend, left_on='name', right_on='friend').loc[lambda x: x['age_x'] > person['age'].mean(), ['name_y', 'friend', 'age_x']].rename(columns={'name_y':'name'}).drop_duplicates()"
"whare the names, friends, and ages of all people who are older than the average age of a person?","person.merge(person_friend, left_on='name', right_on='friend').loc[lambda x: x['age_x'] > person['age'].mean(), ['name_y', 'friend', 'age_x']].rename(columns={'name_y':'name'}).drop_duplicates()"
who is the friend of zach with longest year relationship?,"personfriend.loc[lambda x: (x['name']=='zach')&(x['year']==personfriend.loc[lambda y: y['name']=='zach', 'year'].max()), 'friend']"
which friend of zach has the longest-lasting friendship?,"personfriend.loc[lambda x: (x['name']=='zach')&(x['year']==personfriend.loc[lambda y: y['name']=='zach', 'year'].max()), 'friend']"
what is the age of the friend of zach with longest year relationship?,"person.loc[lambda x: x['name'].isin(person_friend.loc[(person_friend['name'] == 'zach') & (person_friend['year'] == person_friend.loc[lambda y: y['name'] == 'zach', 'year'].max()), 'friend']), 'age']"
what are the ages of all of zach's friends who are in the longest relationship?,"person.loc[lambda x: x['name'].isin(person_friend.loc[(person_friend['name'] == 'zach') & (person_friend['year'] == person_friend.loc[lambda y: y['name'] == 'zach', 'year'].max()), 'friend']), 'age']"
find the name of persons who are friends with alice for the shortest years.,"personfriend.loc[lambda x: (x['friend'] == 'alice') & (x['year'] == personfriend.loc[lambda y: y['friend'] == 'alice', 'year'].min()), 'name']"
what are the names of all people who are friends with alice for the shortest amount of time?,"personfriend.loc[lambda x: (x['friend'] == 'alice') & (x['year'] == personfriend.loc[lambda y: y['friend'] == 'alice', 'year'].min()), 'name']"
"find the name, age, and job title of persons who are friends with alice for the longest years.","person.merge(personfriend.query(""friend == 'alice' and year == (select max(year) from personfriend where friend == 'alice')""), on='name')[['name', 'age', 'job']]"
"what are the names, ages, and jobs of all people who are friends with alice for the longest amount of time?","person.merge(personfriend.query(""friend == 'alice' and year == (select max(year) from personfriend where friend == 'alice')""), on='name')[['name', 'age', 'job']]"
who is the person that has no friend?,person[~person['name'].isin(personfriend['name'])]['name']
what are the names of all people who do not have friends?,person[~person['name'].isin(personfriend['name'])]['name']
which person whose friends have the oldest average age?,"person.merge(personfriend, left_on='name', right_on='friend').groupby('name_y').agg({'age': 'mean'}).sort_values('age', ascending=false).iloc[0]"
"what is the name of the person who has the oldest average age for their friends, and what is that average age?","person.merge(personfriend, left_on='name', right_on='friend').groupby('name_y').agg({'age': 'mean'}).sort_values('age', ascending=false).iloc[0]"
what is the total number of people who has no friend living in the city of austin.,"personfriend.loc[~personfriend['friend'].isin(person.loc[person['city']=='austin', 'name']), 'name'].nunique()"
what is the total number of people who have no friends living in austin?,"personfriend.loc[~personfriend['friend'].isin(person.loc[person['city']=='austin', 'name']), 'name'].nunique()"
find alice's friends of friends.,"(pd.merge(pd.merge(pd.merge(person_friend, person, left_on='name', right_on='name'), person_friend, left_on='friend', right_on='name'), person_friend, left_on='friend_y', right_on='name').loc[lambda x: (x['name_x']=='alice')&(x['name_y']!='alice'), 'name'])"
what are the names of all of alice's friends of friends?,"(pd.merge(pd.merge(pd.merge(person_friend, person, left_on='name', right_on='name'), person_friend, left_on='friend', right_on='name'), person_friend, left_on='friend_y', right_on='name').loc[lambda x: (x['name_x']=='alice')&(x['name_y']!='alice'), 'name'])"
how many members are there?,member.shape[0]
list the names of members in ascending alphabetical order.,member.sort_values('name')['name']
what are the names and countries of members?,"member[['name', 'country']]"
"show the names of members whose country is ""united states"" or ""canada"".","member.loc[lambda x: x['country'].isin(['united states', 'canada']), 'name']"
show the different countries and the number of members from each.,member.groupby('country').size().reset_index(name='count')
show the most common country across members.,member.groupby('country').size().sort_values(ascending=false).index[0]
which countries have more than two members?,member.groupby('country').filter(lambda x: len(x) > 2)['country'].unique()
show the leader names and locations of colleges.,"college[['leader_name', 'college_location']]"
show the names of members and names of colleges they go to.,"pd.merge(college, member, on='college_id')[['name_x', 'name_y']]"
show the names of members and the locations of colleges they go to in ascending alphabetical order of member names.,"pd.merge(college, member, on='college_id').sort_values('name')[['name', 'college_location']]"
"show the distinct leader names of colleges associated with members from country ""canada"".","pd.merge(college, member, on='college_id').loc[lambda x: x['country']=='canada', 'leader_name'].unique()"
show the names of members and the decoration themes they have.,"pd.merge(member, round, on='member_id')[['name', 'decoration_theme']]"
show the names of members that have a rank in round higher than 3.,"pd.merge(member, round, on='member_id').loc[lambda x: x['rank_in_round'] > 3, 'name']"
show the names of members in ascending order of their rank in rounds.,"pd.merge(member, round, on='member_id').sort_values('rank_in_round')['name']"
list the names of members who did not participate in any round.,"member.loc[~member['member_id'].isin(round['member_id']), 'name']"
"find the name and access counts of all documents, in alphabetic order of the document name.","documents[['document_name', 'access_count']].sort_values('document_name')"
"what are the names of all the documents, as well as the access counts of each, ordered alphabetically?","documents[['document_name', 'access_count']].sort_values('document_name')"
"find the name of the document that has been accessed the greatest number of times, as well as the count of how many times it has been accessed?","documents[['document_name', 'access_count']].sort_values('access_count', ascending=false).iloc[0]"
"what is the name of the document which has been accessed the most times, as well as the number of times it has been accessed?","documents[['document_name', 'access_count']].sort_values('access_count', ascending=false).iloc[0]"
find the types of documents with more than 4 documents.,documents.groupby('document_type_code').filter(lambda x: len(x) > 4)['document_type_code'].unique()
what are the codes of types of documents of which there are for or more?,documents.groupby('document_type_code').filter(lambda x: len(x) > 4)['document_type_code'].unique()
find the total access count of all documents in the most popular document type.,documents.groupby('document_type_code')['access_count'].sum().nlargest(1)
what is the total access count of documents that are of the most common document type?,documents.groupby('document_type_code')['access_count'].sum().nlargest(1)
what is the average access count of documents?,documents['access_count'].mean()
find the average access count across all documents?,documents['access_count'].mean()
what is the structure of the document with the least number of accesses?,"pd.merge(documents, document_structures, on='document_structure_code').groupby('document_structure_description').size().sort_values(ascending=false).index[0]"
return the structure description of the document that has been accessed the fewest number of times.,"pd.merge(documents, document_structures, on='document_structure_code').groupby('document_structure_description').size().sort_values(ascending=false).index[0]"
"what is the type of the document named ""david cv""?","documents.loc[lambda x: x['document_name']=='david cv', 'document_type_code']"
"return the type code of the document named ""david cv"".","documents.loc[lambda x: x['document_name']=='david cv', 'document_type_code']"
find the list of documents that are both in the most three popular type and have the most three popular structure.,"documents.groupby('document_type_code').count().sort_values(by='document_name', ascending=false).iloc[:3].reset_index()['document_name'].to_frame().merge(documents.groupby('document_structure_code').count().sort_values(by='document_name', ascending=false).iloc[:3].reset_index()['document_name'].to_frame()).drop_duplicates()['document_name']"
what are the names of documents that have both one of the three most common types and one of three most common structures?,"documents.groupby('document_type_code').count().sort_values(by='document_name', ascending=false).iloc[:3].reset_index()['document_name'].to_frame().merge(documents.groupby('document_structure_code').count().sort_values(by='document_name', ascending=false).iloc[:3].reset_index()['document_name'].to_frame()).drop_duplicates()['document_name']"
what document types do have more than 10000 total access number.,documents.groupby('document_type_code').filter(lambda x: x['access_count'].sum() > 10000)['document_type_code'].unique()
return the codes of the document types that do not have a total access count of over 10000.,documents.groupby('document_type_code').filter(lambda x: x['access_count'].sum() > 10000)['document_type_code'].unique()
"what are all the section titles of the document named ""david cv""?","document_sections.merge(documents[documents['document_name']=='david cv'], on='document_code')['section_title']"
"give the section titles of the document with the name ""david cv"".","document_sections.merge(documents[documents['document_name']=='david cv'], on='document_code')['section_title']"
find all the name of documents without any sections.,"documents.loc[~documents['document_code'].isin(document_sections['document_code']), 'document_name']"
what are the names of documents that do not have any sections?,"documents.loc[~documents['document_code'].isin(document_sections['document_code']), 'document_name']"
list all the username and passwords of users with the most popular role.,"users.groupby('role_code').agg({'user_name': 'first', 'password': 'first'}).reset_index().sort_values(by='role_code', ascending=false).nlargest(1, columns='role_code')[['user_name', 'password']]"
what are the usernames and passwords of users that have the most common role?,"users.groupby('role_code').agg({'user_name': 'first', 'password': 'first'}).reset_index().sort_values(by='role_code', ascending=false).nlargest(1, columns='role_code')[['user_name', 'password']]"
"find the average access counts of documents with functional area ""acknowledgement"".","pd.merge(pd.merge(documents, document_functional_areas, on='document_code'), functional_areas, on='functional_area_code').loc[lambda x: x['functional_area_description']=='acknowledgement', 'access_count'].mean()"
"what are the average access counts of documents that have the functional area description ""acknowledgement""?","pd.merge(pd.merge(documents, document_functional_areas, on='document_code'), functional_areas, on='functional_area_code').loc[lambda x: x['functional_area_description']=='acknowledgement', 'access_count'].mean()"
find names of the document without any images.,"documents['document_name'].loc[~documents['document_code'].isin(document_sections.merge(document_sections_images, on='section_id')['document_code'].unique())]"
what are the names of documents that do not have any images?,"documents['document_name'].loc[~documents['document_code'].isin(document_sections.merge(document_sections_images, on='section_id')['document_code'].unique())]"
what is the name of the document with the most number of sections?,"documents.merge(document_sections, on='document_code').groupby('document_code')['document_name'].first().value_counts().index[0]"
return the name of the document that has the most sections.,"documents.merge(document_sections, on='document_code').groupby('document_code')['document_name'].first().value_counts().index[0]"
"list all the document names which contains ""cv"".","documents.loc[documents['document_name'].str.contains('cv'), 'document_name']"
"what are the names of documents that contain the substring ""cv""?","documents.loc[documents['document_name'].str.contains('cv'), 'document_name']"
how many users are logged in?,(users['user_login'] == 1).sum()
count the number of users that are logged in.,(users['user_login'] == 1).sum()
find the description of the most popular role among the users that have logged in.,"roles.loc[lambda x: x['role_code']==users.loc[lambda y: y['user_login']==1, 'role_code'].value_counts().idxmax(), 'role_description']"
what is the description of the most popular role among users that have logged in?,"roles.loc[lambda x: x['role_code']==users.loc[lambda y: y['user_login']==1, 'role_code'].value_counts().idxmax(), 'role_description']"
find the average access count of documents with the least popular structure.,documents.groupby('document_structure_code')['access_count'].mean().sort_values().head(1)
what is the average access count of documents that have the least common structure?,documents.groupby('document_structure_code')['access_count'].mean().sort_values().head(1)
list all the image name and urls in the order of their names.,"images[['image_name', 'image_url']].sort_values('image_name')"
"what are the names and urls of images, sorted alphabetically?","images[['image_name', 'image_url']].sort_values('image_name')"
find the number of users in each role.,users.groupby('role_code').size().reset_index(name='count')
"what are the different role codes for users, and how many users have each?",users.groupby('role_code').size().reset_index(name='count')
what document types have more than 2 corresponding documents?,documents.groupby('document_type_code').filter(lambda x: len(x) > 2)['document_type_code'].unique()
give the codes of document types that have more than 2 corresponding documents.,documents.groupby('document_type_code').filter(lambda x: len(x) > 2)['document_type_code'].unique()
how many companies are there?,companies.shape[0]
count the number of companies.,companies.shape[0]
list the names of companies in descending order of market value.,"companies.sort_values('market_value_billion', ascending=false)['name']"
sort the company names in descending order of the company's market value.,"companies.sort_values('market_value_billion', ascending=false)['name']"
"what are the names of companies whose headquarters are not ""usa""?","companies.loc[lambda x: x['headquarters']!='usa', 'name']"
"find the names of the companies whose headquarters are not located in ""usa"".","companies.loc[lambda x: x['headquarters']!='usa', 'name']"
"what are the name and assets of each company, sorted in ascending order of company name?","companies[['name', 'assets_billion']].sort_values('name')"
list the name and assets of each company in ascending order of company name.,"companies[['name', 'assets_billion']].sort_values('name')"
what are the average profits of companies?,companies['profits_billion'].mean()
compute the average profits companies make.,companies['profits_billion'].mean()
"what are the maximum and minimum sales of the companies whose industries are not ""banking"".","companies.loc[lambda x: x['industry']!='banking', 'sales_billion'].agg(['max', 'min'])"
"find the maximum and minimum sales of the companies that are not in the ""banking"" industry.","companies.loc[lambda x: x['industry']!='banking', 'sales_billion'].agg(['max', 'min'])"
how many different industries are the companies in?,companies['industry'].nunique()
count the number of distinct company industries.,companies['industry'].nunique()
list the names of buildings in descending order of building height.,"buildings.sort_values('height', ascending=false)['name']"
what are the names of buildings sorted in descending order of building height?,"buildings.sort_values('height', ascending=false)['name']"
find the stories of the building with the largest height.,"buildings.sort_values('height', ascending=false).iloc[0]['stories']"
what is the stories of highest building?,"buildings.sort_values('height', ascending=false).iloc[0]['stories']"
list the name of a building along with the name of a company whose office is in the building.,"pd.merge(pd.merge(office_locations, buildings, left_on='building_id', right_on='id'), companies, left_on='company_id', right_on='id')[['name_x', 'name_y']]"
"for each company, return the company name and the name of the building its office is located in.","pd.merge(pd.merge(office_locations, buildings, left_on='building_id', right_on='id'), companies, left_on='company_id', right_on='id')[['name_x', 'name_y']]"
show the names of the buildings that have more than one company offices.,"pd.merge(pd.merge(office_locations, buildings, left_on='building_id', right_on='id'), companies, left_on='company_id', right_on='id').groupby('building_id').filter(lambda x: len(x) > 1)['name_y']"
which buildings have more than one company offices? give me the building names.,"pd.merge(pd.merge(office_locations, buildings, left_on='building_id', right_on='id'), companies, left_on='company_id', right_on='id').groupby('building_id').filter(lambda x: len(x) > 1)['name_y']"
show the name of the building that has the most company offices.,"pd.merge(pd.merge(office_locations, buildings, left_on='building_id', right_on='id'), companies, left_on='company_id', right_on='id').groupby('building_id')['name'].count().idxmax()"
which building has the largest number of company offices? give me the building name.,"pd.merge(pd.merge(office_locations, buildings, left_on='building_id', right_on='id'), companies, left_on='company_id', right_on='id').groupby('building_id')['name'].count().idxmax()"
"please show the names of the buildings whose status is ""on-hold"", in ascending order of stories.",buildings.loc[lambda x: x['status']=='on-hold'].sort_values('stories')['name']
"find the names of the buildings in ""on-hold"" status, and sort them in ascending order of building stories.",buildings.loc[lambda x: x['status']=='on-hold'].sort_values('stories')['name']
please show each industry and the corresponding number of companies in that industry.,companies.groupby('industry').size().reset_index(name='count')
whah are the name of each industry and the number of companies in that industry?,companies.groupby('industry').size().reset_index(name='count')
please show the industries of companies in descending order of the number of companies.,companies.groupby('industry').size().sort_values(ascending=false).index
sort all the industries in descending order of the count of companies in each industry,companies.groupby('industry').size().sort_values(ascending=false).index
list the industry shared by the most companies.,companies.groupby('industry').size().sort_values(ascending=false).index[0]
which industry has the most companies?,companies.groupby('industry').size().sort_values(ascending=false).index[0]
list the names of buildings that have no company office.,"buildings.loc[~buildings['id'].isin(office_locations['building_id']), 'name']"
which buildings do not have any company office? give me the building names.,"buildings.loc[~buildings['id'].isin(office_locations['building_id']), 'name']"
"show the industries shared by companies whose headquarters are ""usa"" and companies whose headquarters are ""china"".","set(companies.query('headquarters==""usa""')['industry']).intersection(set(companies.query('headquarters==""china""')['industry']))"
"which industries have both companies with headquarter in ""usa"" and companies with headquarter in ""china""?","set(companies.query('headquarters==""usa""')['industry']).intersection(set(companies.query('headquarters==""china""')['industry']))"
"find the number of companies whose industry is ""banking"" or ""conglomerate"",","companies.loc[lambda x: x['industry'].isin(['banking', 'conglomerate'])].shape[0]"
"how many companies are in either ""banking"" industry or ""conglomerate"" industry?","companies.loc[lambda x: x['industry'].isin(['banking', 'conglomerate'])].shape[0]"
show the headquarters shared by more than two companies.,companies.groupby('headquarters').filter(lambda x: len(x) > 2).groupby('headquarters').first()
which headquarter locations are used by more than 2 companies?,companies.groupby('headquarters').filter(lambda x: len(x) > 2).groupby('headquarters').first()
how many products are there?,products.shape[0]
list the name of products in ascending order of price.,products.sort_values('product_price')['product_name']
what are the names and type codes of products?,"products[['product_name', 'product_type_code']]"
"show the prices of the products named ""dining"" or ""trading policy"".","products.loc[lambda x: x['product_name'].isin(['dining', 'trading policy']), 'product_price']"
what is the average price for products?,products['product_price'].mean()
what is the name of the product with the highest price?,"products.sort_values('product_price', ascending=false).iloc[0]['product_name']"
show different type codes of products and the number of products with each type code.,products.groupby('product_type_code').size().rename_axis('product_type_code').reset_index(name='count')
show the most common type code across products.,products.groupby('product_type_code').size().sort_values(ascending=false).index[0]
show the product type codes that have at least two products.,products.groupby('product_type_code').filter(lambda x: len(x) >= 2)['product_type_code'].unique()
show the product type codes that have both products with price higher than 4500 and products with price lower than 3000.,set(products.query('product_price > 4500')['product_type_code']).intersection(set(products.query('product_price < 3000')['product_type_code']))
show the names of products and the number of events they are in.,"pd.merge(products, products_in_events, on='product_id').groupby('product_name').size().reset_index(name='count')"
"show the names of products and the number of events they are in, sorted by the number of events in descending order.","pd.merge(products, products_in_events, on='product_id').groupby('product_name').size().sort_values(ascending=false)"
show the names of products that are in at least two events.,"pd.merge(products, products_in_events, on='product_id').groupby('product_name').filter(lambda x: len(x) >= 2)['product_name'].unique()"
show the names of products that are in at least two events in ascending alphabetical order of product name.,"pd.merge(products, products_in_events, on='product_id').groupby('product_name').filter(lambda x: len(x) >= 2).sort_values('product_name')['product_name']"
list the names of products that are not in any event.,"products.loc[~products['product_id'].isin(products_in_events['product_id']), 'product_name']"
how many artworks are there?,artwork.shape[0]
list the name of artworks in ascending alphabetical order.,artwork.sort_values('name')['name']
"list the name of artworks whose type is not ""program talent show"".","artwork.loc[lambda x: x['type']!='program talent show', 'name']"
what are the names and locations of festivals?,"festival_detail[['festival_name', 'location']]"
"what are the names of the chairs of festivals, sorted in ascending order of the year held?",festival_detail.sort_values('year')['chair_name']
what is the location of the festival with the largest number of audience?,"festival_detail.sort_values('num_of_audience', ascending=false)['location'].iloc[0]"
what are the names of festivals held in year 2007?,"festival_detail.loc[lambda x: x['year']==2007, 'festival_name']"
what is the average number of audience for festivals?,festival_detail['num_of_audience'].mean()
show the names of the three most recent festivals.,"festival_detail.sort_values('year', ascending=false).iloc[:3]['festival_name']"
"for each nomination, show the name of the artwork and name of the festival where it is nominated.","pd.merge(pd.merge(nomination, artwork, on='artwork_id'), festival_detail, on='festival_id')[['name', 'festival_name']]"
show distinct types of artworks that are nominated in festivals in 2007.,"pd.merge(pd.merge(nomination, artwork, on='artwork_id'), festival_detail, on='festival_id').loc[lambda x: x['year']==2007, 'type'].unique()"
show the names of artworks in ascending order of the year they are nominated in.,"pd.merge(pd.merge(nomination, artwork, on='artwork_id'), festival_detail, on='festival_id').sort_values('year')['name']"
"show the names of festivals that have nominated artworks of type ""program talent show"".","pd.merge(pd.merge(nomination, artwork, on='artwork_id'), festival_detail, on='festival_id').loc[lambda x: x['type'] == 'program talent show', 'festival_name']"
show the ids and names of festivals that have at least two nominations for artworks.,"pd.merge(pd.merge(nomination, artwork, on='artwork_id'), festival_detail, on='festival_id').groupby(['festival_id', 'festival_name']).filter(lambda x: len(x) >= 2)[['festival_id', 'festival_name']].drop_duplicates()"
"show the id, name of each festival and the number of artworks it has nominated.","pd.merge(pd.merge(nomination, artwork, on='artwork_id'), festival_detail, on='festival_id').groupby(['festival_id', 'festival_name']).size().reset_index(name='count')[['festival_id', 'festival_name', 'count']]"
please show different types of artworks with the corresponding number of artworks of each type.,artwork.groupby('type').size().reset_index(name='count')
list the most common type of artworks.,artwork.groupby('type').size().sort_values(ascending=false).index[0]
list the year in which there are more than one festivals.,"festival_detail.groupby('year').filter(lambda x: len(x) > 1).groupby('year').size().reset_index(name='count').loc[:, 'year']"
list the name of artworks that are not nominated.,"artwork.loc[~artwork['artwork_id'].isin(nomination['artwork_id']), 'name']"
show the number of audience in year 2008 or 2010.,"festival_detail.loc[festival_detail['year'].isin([2008, 2010]), 'num_of_audience']"
what are the total number of the audiences who visited any of the festivals?,festival_detail['num_of_audience'].sum()
in which year are there festivals both inside the 'united states' and outside the 'united states'?,"festival_detail.loc[festival_detail['location'] == 'united states', 'year'].drop_duplicates().reset_index(drop=true).intersect(festival_detail.loc[festival_detail['location'] != 'united states', 'year'].drop_duplicates().reset_index(drop=true))"
how many premises are there?,premises.shape[0]
what are all the distinct premise types?,premises['premises_type'].unique()
find the types and details for all premises and order by the premise type.,"premises[['premises_type', 'premise_details']].sort_values('premises_type')"
show each premise type and the number of premises in that type.,premises.groupby('premises_type').size()
show all distinct product categories along with the number of mailshots in each category.,mailshot_campaigns.groupby('product_category').size()
show the name and phone of the customer without any mailshot.,"customers.loc[~customers['customer_id'].isin(mailshot_customers['customer_id']), ['customer_name', 'customer_phone']]"
show the name and phone for customers with a mailshot with outcome code 'no response'.,"pd.merge(customers, mailshot_customers, on='customer_id').loc[lambda x: x['outcome_code']=='no response', ['customer_name', 'customer_phone']]"
show the outcome code of mailshots along with the number of mailshots in each outcome code.,mailshot_customers['outcome_code'].value_counts()
show the names of customers who have at least 2 mailshots with outcome code 'order'.,"pd.merge(mailshot_customers, customers, on='customer_id').loc[lambda x: x['outcome_code']=='order'].groupby('customer_id')['customer_name'].filter(lambda x: len(x)>=2).unique()"
show the names of customers who have the most mailshots.,"pd.merge(mailshot_customers, customers, on='customer_id').groupby('customer_name').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0, 0]"
what are the name and payment method of customers who have both mailshots in 'order' outcome and mailshots in 'no response' outcome.,"pd.merge(mailshot_customers.loc[lambda x:x['outcome_code']=='order', ['customer_id']], customers, on='customer_id')[['customer_name', 'payment_method']].merge(pd.merge(mailshot_customers.loc[lambda x:x['outcome_code']=='no response', ['customer_id']],customers, on='customer_id')[['customer_name', 'payment_method']]).drop_duplicates()"
show the premise type and address type code for all customer addresses.,"pd.merge(customer_addresses, premises, on='premise_id')[['premises_type', 'address_type_code']]"
what are the distinct address type codes for all customer addresses?,customer_addresses['address_type_code'].unique()
show the shipping charge and customer id for customer orders with order status cancelled or paid.,"customer_orders.loc[lambda x: x['order_status_code'].isin(['cancelled', 'paid']), ['order_shipping_charges', 'customer_id']]"
show the names of customers having an order with shipping method fedex and order status paid.,"pd.merge(customers, customer_orders[(customer_orders['shipping_method_code']=='fedex') & (customer_orders['order_status_code']=='paid')], on='customer_id')['customer_name']"
count the number of courses.,course.shape[0]
how many courses have more than 2 credits?,(course['credits'] > 2).sum()
count the number of courses with more than 2 credits.,(course['credits'] > 2).sum()
list all names of courses with 1 credit?,"course.loc[lambda x: x['credits'] == 1, 'cname']"
what are the names of courses with 1 credit?,"course.loc[lambda x: x['credits'] == 1, 'cname']"
which courses are taught on days mtw?,"course.loc[course['days'] == 'mtw', 'cname']"
what are the course names for courses taught on mtw?,"course.loc[course['days'] == 'mtw', 'cname']"
"what is the number of departments in division ""as""?",(department['division'] == 'as').sum()
how many departments are in the division as?,(department['division'] == 'as').sum()
what are the phones of departments in room 268?,"department.loc[lambda x: x['room']==268, 'dphone']"
give the phones for departments in room 268.,"department.loc[lambda x: x['room']==268, 'dphone']"
"find the number of students that have at least one grade ""b"".","enrolled_in.loc[enrolled_in['grade'] == 'b', 'stuid'].nunique()"
"how many students have had at least one ""b"" grade?","enrolled_in.loc[enrolled_in['grade'] == 'b', 'stuid'].nunique()"
find the max and min grade point for all letter grade.,"gradeconversion.agg({'gradepoint': ['max', 'min']})"
what are the maximum and minumum grade points?,"gradeconversion.agg({'gradepoint': ['max', 'min']})"
"find the first names of students whose first names contain letter ""a"".","student.loc[lambda x: x['fname'].str.contains('a'), 'fname'].unique()"
"what are the first names for students who have an ""a"" in their first name?","student.loc[lambda x: x['fname'].str.contains('a'), 'fname'].unique()"
find the first names and last names of male (sex is m) faculties who live in building neb.,"faculty.loc[(faculty['sex'] == 'm') & (faculty['building'] == 'neb'), ['fname', 'lname']]"
what are the full names of faculties with sex m and who live in building neb?,"faculty.loc[(faculty['sex'] == 'm') & (faculty['building'] == 'neb'), ['fname', 'lname']]"
find the rooms of faculties with rank professor who live in building neb.,"faculty.loc[(faculty['rank'] == 'professor') & (faculty['building'] == 'neb'), 'room']"
what are the rooms for members of the faculty who are professors and who live in building neb?,"faculty.loc[(faculty['rank'] == 'professor') & (faculty['building'] == 'neb'), 'room']"
"find the department name that is in building ""mergenthaler"".","department.loc[lambda x: x['building']=='mergenthaler', 'dname']"
what is the name of the department in the building mergenthaler?,"department.loc[lambda x: x['building']=='mergenthaler', 'dname']"
list all information about courses sorted by credits in the ascending order.,course.sort_values('credits')
"what is all the information about courses, ordered by credits ascending?",course.sort_values('credits')
list the course name of courses sorted by credits.,course.sort_values('credits')['cname']
"what are the course names, ordered by credits?",course.sort_values('credits')['cname']
find the first name of students in the descending order of age.,"student.sort_values('age', ascending=false)['fname']"
"what are the first names of students, ordered by age from greatest to least?","student.sort_values('age', ascending=false)['fname']"
find the last name of female (sex is f) students in the descending order of age.,"student.loc[lambda x: x['sex']=='f'].sort_values('age', ascending=false)['lname']"
"what are the last names of female students, ordered by age descending?","student.loc[lambda x: x['sex']=='f'].sort_values('age', ascending=false)['lname']"
find the last names of faculties in building barton in alphabetic order.,faculty.loc[lambda x: x['building']=='barton'].sort_values('lname')['lname']
"what are the last names of faculty in building barton, sorted by last name?",faculty.loc[lambda x: x['building']=='barton'].sort_values('lname')['lname']
find the first names of faculties of rank professor in alphabetic order.,faculty.loc[faculty['rank']=='professor'].sort_values('fname')['fname']
"what are the first names for all faculty professors, ordered by first name?",faculty.loc[faculty['rank']=='professor'].sort_values('fname')['fname']
find the name of the department that has the biggest number of students minored in?,"department.merge(minor_in, on='dno').groupby('dname').size().sort_values(ascending=false).index[0]"
what is the name of the department with the most students minoring in it?,"department.merge(minor_in, on='dno').groupby('dname').size().sort_values(ascending=false).index[0]"
find the name of the department that has no students minored in?,department['dname'].loc[~department['dno'].isin(minor_in['dno'])]
what is the name of the department htat has no students minoring in it?,department['dname'].loc[~department['dno'].isin(minor_in['dno'])]
find the name of the department that has the fewest members.,"pd.merge(department, member_of, on='dno').groupby('dname').size().sort_values().index[0]"
what is the name of the department with the fewest members?,"pd.merge(department, member_of, on='dno').groupby('dname').size().sort_values().index[0]"
find the rank of the faculty that the fewest faculties belong to.,faculty.groupby('rank').size().sort_values().index[0]
what is the least common faculty rank?,faculty.groupby('rank').size().sort_values().index[0]
what are the first and last names of the instructors who teach the top 3 number of courses?,"course.merge(faculty, left_on='instructor', right_on='facid').groupby(['instructor', 'fname', 'lname'], as_index=false).size().rename(columns={'size': 'num_courses'}).sort_values('num_courses', ascending=false).iloc[:3, [1, 2]]"
what are the full names of the 3 instructors who teach the most courses?,"course.merge(faculty, left_on='instructor', right_on='facid').groupby(['instructor', 'fname', 'lname'], as_index=false).size().rename(columns={'size': 'num_courses'}).sort_values('num_courses', ascending=false).iloc[:3, [1, 2]]"
which building does the instructor who teaches the most number of courses live in?,"course.merge(faculty, left_on='instructor', right_on='facid').groupby('instructor')['building'].first().value_counts().index[0]"
give the building that the instructor who teaches the greatest number of courses lives in.,"course.merge(faculty, left_on='instructor', right_on='facid').groupby('instructor')['building'].first().value_counts().index[0]"
what are the name of courses that have at least five enrollments?,"pd.merge(course, enrolled_in, on='cid').groupby('cid').filter(lambda x: len(x) >= 5)['cname']"
give the names of the courses with at least five enrollments.,"pd.merge(course, enrolled_in, on='cid').groupby('cid').filter(lambda x: len(x) >= 5)['cname']"
find the first name and last name of the instructor of course that has course name,"pd.merge(course, faculty, left_on='instructor', right_on='facid').loc[lambda x: x['cname']=='computer literacy', ['fname', 'lname']]"
what is the full name of the instructor who has a course named computer literacy?,"pd.merge(course, faculty, left_on='instructor', right_on='facid').loc[lambda x: x['cname']=='computer literacy', ['fname', 'lname']]"
find the department name and room of the course introduction to computer science.,"pd.merge(course.loc[course['cname'] == ""introduction to computer science""], department, left_on='dno', right_on='dno')[['dname', 'room']]"
what are the department name and room for the course introduction to computer science?,"pd.merge(course.loc[course['cname'] == ""introduction to computer science""], department, left_on='dno', right_on='dno')[['dname', 'room']]"
find the student first and last names and grade points of all enrollments.,"enrolled_in.merge(gradeconversion, left_on='grade', right_on='lettergrade').merge(student, on='stuid')[['fname', 'lname', 'gradepoint']]"
what are the full names and gradepoints for all enrollments?,"enrolled_in.merge(gradeconversion, left_on='grade', right_on='lettergrade').merge(student, on='stuid')[['fname', 'lname', 'gradepoint']]"
find the distinct student first names of all students that have grade point at least 3.8 in one course.,"pd.merge(pd.merge(enrolled_in, gradeconversion, on='lettergrade'), student, on='stuid').loc[lambda x: x['gradepoint'] >= 3.8, 'fname'].unique()"
what are the distinct first names for students with a grade point of 3.8 or above in at least one course?,"pd.merge(pd.merge(enrolled_in, gradeconversion, on='lettergrade'), student, on='stuid').loc[lambda x: x['gradepoint'] >= 3.8, 'fname'].unique()"
find the full names of faculties who are members of department with department number 520.,"pd.merge(faculty, member_of, on='facid').loc[lambda x: x['dno']==520, ['fname', 'lname']]"
what are the full names of faculty members who are a part of department 520?,"pd.merge(faculty, member_of, on='facid').loc[lambda x: x['dno']==520, ['fname', 'lname']]"
what are the first names and last names of the students that minor in the department with dno 140.,"pd.merge(minor_in.loc[minor_in['dno']==140, ['stuid']], student, on='stuid')[['fname', 'lname']]"
what are the full names of students minoring in department 140?,"pd.merge(minor_in.loc[minor_in['dno']==140, ['stuid']], student, on='stuid')[['fname', 'lname']]"
find the last names of faculties who are members of computer science department.,"pd.merge(pd.merge(department.loc[lambda x: x['dname']=='computer science'], member_of, on='dno'), faculty, on='facid')['lname']"
what are the last names of faculty who are part of the computer science department?,"pd.merge(pd.merge(department.loc[lambda x: x['dname']=='computer science'], member_of, on='dno'), faculty, on='facid')['lname']"
find the average grade point of student whose last name is smith.,"enrolled_in.merge(gradeconversion, left_on='grade', right_on='lettergrade').merge(student, on='stuid').loc[lambda x: x['lname']=='smith', 'gradepoint'].mean()"
what is the average gradepoint for students with the last name smith?,"enrolled_in.merge(gradeconversion, left_on='grade', right_on='lettergrade').merge(student, on='stuid').loc[lambda x: x['lname']=='smith', 'gradepoint'].mean()"
what is the maximum and minimum grade point of students who live in nyc?,"pd.merge(pd.merge(enrolled_in, gradeconversion, left_on='grade', right_on='lettergrade'), student, on='stuid').loc[lambda x: x['city_code']=='nyc', 'gradepoint'].agg(['max', 'min'])"
give the maximum and minimum gradepoints for students living in nyc?,"pd.merge(pd.merge(enrolled_in, gradeconversion, left_on='grade', right_on='lettergrade'), student, on='stuid').loc[lambda x: x['city_code']=='nyc', 'gradepoint'].agg(['max', 'min'])"
find the names of courses that have either 3 credits or 1 credit but 4 hours.,"pd.concat([course.loc[lambda x: x['credits']==3, 'cname'] , course.loc[lambda x: (x['credits']==1) & (x['hours']==4), 'cname'] ]).drop_duplicates()"
"what are the names of courses that give either 3 credits, or 1 credit and 4 hours?","pd.concat([course.loc[lambda x: x['credits']==3, 'cname'] , course.loc[lambda x: (x['credits']==1) & (x['hours']==4), 'cname'] ]).drop_duplicates()"
find the names of departments that are either in division as or in division en and in building neb.,"pd.concat([department.loc[lambda x: x['division'] == 'as', 'dname'], department.loc[lambda x: (x['division'] == 'en') & (x['building'] == 'neb'), 'dname']]).drop_duplicates()"
"what are the names of departments either in division as, or in division en and in building neb?","pd.concat([department.loc[lambda x: x['division'] == 'as', 'dname'], department.loc[lambda x: (x['division'] == 'en') & (x['building'] == 'neb'), 'dname']]).drop_duplicates()"
find the first name of students not enrolled in any course.,"student.loc[~student['stuid'].isin(enrolled_in['stuid']), 'fname']"
what are the first names of all students that are not enrolled in courses?,"student.loc[~student['stuid'].isin(enrolled_in['stuid']), 'fname']"
what are the ids of the top three products that were purchased in the largest amount?,"product_suppliers.sort_values('total_amount_purchased', ascending=false)['product_id'].iloc[:3]"
give the ids of the three products purchased in the largest amounts.,"product_suppliers.sort_values('total_amount_purchased', ascending=false)['product_id'].iloc[:3]"
what are the product id and product type of the cheapest product?,"products[['product_id', 'product_type_code']].sort_values('product_price').head(1)"
give the id and product type of the product with the lowest price.,"products[['product_id', 'product_type_code']].sort_values('product_price').head(1)"
find the number of different product types.,products['product_type_code'].nunique()
count the number of distinct product types.,products['product_type_code'].nunique()
return the address of customer 10.,"addresses.merge(customer_addresses.query('customer_id==10'), on='address_id')['address_details']"
what is the address for the customer with id 10?,"addresses.merge(customer_addresses.query('customer_id==10'), on='address_id')['address_details']"
what are the staff ids and genders of all staffs whose job title is department manager?,"staff_department_assignments[staff_department_assignments['job_title_code']=='department manager'].merge(staff[['staff_id', 'staff_gender']], on='staff_id')[['staff_id', 'staff_gender']]"
return the staff ids and genders for any staff with the title department manager.,"staff_department_assignments[staff_department_assignments['job_title_code']=='department manager'].merge(staff[['staff_id', 'staff_gender']], on='staff_id')[['staff_id', 'staff_gender']]"
"for each payment method, return how many customers use it.",customers.groupby('payment_method_code').size().reset_index(name='count')
how many customers use each payment method?,customers.groupby('payment_method_code').size().reset_index(name='count')
what is the id of the product that was ordered the most often?,order_items['product_id'].value_counts().index[0]
give the product id for the product that was ordered most frequently.,order_items['product_id'].value_counts().index[0]
"what are the name, phone number and email address of the customer who made the largest number of orders?","pd.merge(customers, customer_orders, on='customer_id').groupby('customer_id').agg({'customer_name':'first', 'customer_phone':'first', 'customer_email':'first'}).sort_values(by='count', ascending=false).iloc[0][['customer_name','customer_phone','customer_email']]"
"return the name, phone number and email address for the customer with the most orders.","pd.merge(customers, customer_orders, on='customer_id').groupby('customer_id').agg({'customer_name':'first', 'customer_phone':'first', 'customer_email':'first'}).sort_values(by='count', ascending=false).iloc[0][['customer_name','customer_phone','customer_email']]"
what is the average price for each type of product?,products.groupby('product_type_code')['product_price'].mean()
return the average price for each product type.,products.groupby('product_type_code')['product_price'].mean()
how many department stores does the store chain south have?,"pd.merge(department_stores, department_store_chain, on='dept_store_chain_id').loc[lambda x: x['dept_store_chain_name']=='south'].shape[0]"
count the number of stores the chain south has.,"pd.merge(department_stores, department_store_chain, on='dept_store_chain_id').loc[lambda x: x['dept_store_chain_name']=='south'].shape[0]"
what is the name and job title of the staff who was assigned the latest?,"pd.merge(staff, staff_department_assignments, on='staff_id').sort_values('date_assigned_to', ascending=false).iloc[0][['staff_name', 'job_title_code']]"
return the name and job title of the staff with the latest date assigned.,"pd.merge(staff, staff_department_assignments, on='staff_id').sort_values('date_assigned_to', ascending=false).iloc[0][['staff_name', 'job_title_code']]"
"give me the product type, name and price for all the products supplied by supplier id 3.","pd.merge(product_suppliers[product_suppliers['supplier_id']==3], products, on='product_id')[['product_type_code', 'product_name', 'product_price']]"
"return the product type, name, and price for products supplied by supplier 3.","pd.merge(product_suppliers[product_suppliers['supplier_id']==3], products, on='product_id')[['product_type_code', 'product_name', 'product_price']]"
"return the distinct name of customers whose order status is pending, in the order of customer id.","pd.merge(customers, customer_orders.loc[lambda x: x['order_status_code']=='pending'], on='customer_id')['customer_name'].sort_values().unique()"
"what are the distinct names of customers with an order status of pending, sorted by customer id?","pd.merge(customers, customer_orders.loc[lambda x: x['order_status_code']=='pending'], on='customer_id')['customer_name'].sort_values().unique()"
find the name and address of the customers who have both new and pending orders.,"pd.merge(customers.loc[lambda x: x['customer_id'].isin(customer_orders.loc[lambda x: x['order_status_code']=='new', 'customer_id'])][['customer_name', 'customer_address']], customers.loc[lambda x: x['customer_id'].isin(customer_orders.loc[lambda x: x['order_status_code']=='pending', 'customer_id'])][['customer_name', 'customer_address']]).drop_duplicates()"
what are the names and addressed of customers who have both new and pending orders?,"pd.merge(customers.loc[lambda x: x['customer_id'].isin(customer_orders.loc[lambda x: x['order_status_code']=='new', 'customer_id'])][['customer_name', 'customer_address']], customers.loc[lambda x: x['customer_id'].isin(customer_orders.loc[lambda x: x['order_status_code']=='pending', 'customer_id'])][['customer_name', 'customer_address']]).drop_duplicates()"
return ids of all the products that are supplied by supplier id 2 and are more expensive than the average price of all products.,products.merge(product_suppliers[product_suppliers['supplier_id'] == 2])[lambda x: x['product_price'] > x['product_price'].mean()]['product_id']
"what are the ids of products from the supplier with id 2, which are more expensive than the average price across all products?",products.merge(product_suppliers[product_suppliers['supplier_id'] == 2])[lambda x: x['product_price'] > x['product_price'].mean()]['product_id']
what is the id and name of the department store that has both marketing and managing department?,"pd.merge(departments.loc[lambda x: x['department_name']=='marketing'], department_stores, on='dept_store_id')[['dept_store_id', 'store_name']].merge(departments.loc[lambda x: x['department_name']=='managing'], on='dept_store_id', how='inner')[['dept_store_id', 'store_name']]"
what are the ids and names of department stores with both marketing and managing departments?,"pd.merge(departments.loc[lambda x: x['department_name']=='marketing'], department_stores, on='dept_store_id')[['dept_store_id', 'store_name']].merge(departments.loc[lambda x: x['department_name']=='managing'], on='dept_store_id', how='inner')[['dept_store_id', 'store_name']]"
what are the ids of the two department store chains with the largest number of department stores?,department_stores.groupby('dept_store_chain_id').size().sort_values(ascending=false).head(2).index.tolist()
return the ids of the two department store chains with the most department stores.,department_stores.groupby('dept_store_chain_id').size().sort_values(ascending=false).head(2).index.tolist()
what is the id of the department with the least number of staff?,staff_department_assignments['department_id'].value_counts().sort_values().index[0]
return the id of the department with the fewest staff assignments.,staff_department_assignments['department_id'].value_counts().sort_values().index[0]
"for each product type, return the maximum and minimum price.","products.groupby('product_type_code')['product_price'].agg(['max', 'min'])"
what are the maximum and minimum product prices for each product type?,"products.groupby('product_type_code')['product_price'].agg(['max', 'min'])"
find the product type whose average price is higher than the average price of all products.,products.groupby('product_type_code').filter(lambda x: x['product_price'].mean() > products['product_price'].mean())['product_type_code'].unique()
what is the code of the product type with an average price higher than the average price of all products?,products.groupby('product_type_code').filter(lambda x: x['product_price'].mean() > products['product_price'].mean())['product_type_code'].unique()
find the id and name of the staff who has been assigned for the shortest period.,"pd.merge(staff, staff_department_assignments, on='staff_id').assign(difference=lambda x: x['date_assigned_to'] - x['date_assigned_from']).sort_values('difference').iloc[0][['staff_id', 'staff_name']]"
what is the id and name of the staff who has been assigned for the least amount of time?,"pd.merge(staff, staff_department_assignments, on='staff_id').assign(difference=lambda x: x['date_assigned_to'] - x['date_assigned_from']).sort_values('difference').iloc[0][['staff_id', 'staff_name']]"
return the names and ids of all products whose price is between 600 and 700.,"products.loc[lambda x: (x['product_price'] >= 600) & (x['product_price'] <= 700), ['product_name', 'product_id']]"
what are the names and ids of products costing between 600 and 700?,"products.loc[lambda x: (x['product_price'] >= 600) & (x['product_price'] <= 700), ['product_name', 'product_id']]"
find the ids of all distinct customers who made order after some orders that were cancelled.,"customer_orders.loc[lambda x: x['order_date'] > customer_orders.loc[lambda x: x['order_status_code'] == 'cancelled', 'order_date'].min(), 'customer_id'].unique()"
what are the distinct ids of customers who made an order after any order that was cancelled?,"customer_orders.loc[lambda x: x['order_date'] > customer_orders.loc[lambda x: x['order_status_code'] == 'cancelled', 'order_date'].min(), 'customer_id'].unique()"
what is id of the staff who had a staff department assignment earlier than any clerical staff?,staff_department_assignments[staff_department_assignments['date_assigned_to'] < staff_department_assignments[staff_department_assignments['job_title_code']=='clerical staff']['date_assigned_to'].max()]['staff_id']
return the id of the staff whose staff department assignment was earlier than that of any clerical staff.,staff_department_assignments[staff_department_assignments['date_assigned_to'] < staff_department_assignments[staff_department_assignments['job_title_code']=='clerical staff']['date_assigned_to'].max()]['staff_id']
what are the names and ids of customers whose address contains tn?,"customers.loc[lambda x: x['customer_address'].str.contains('tn'), ['customer_name', 'customer_id']]"
return the names and ids of customers who have tn in their address.,"customers.loc[lambda x: x['customer_address'].str.contains('tn'), ['customer_name', 'customer_id']]"
return the name and gender of the staff who was assigned in 2016.,"pd.merge(staff, staff_department_assignments, on='staff_id').loc[lambda x: x['date_assigned_from'].str.startswith('2016'), ['staff_name', 'staff_gender']]"
what are the names and genders of staff who were assigned in 2016?,"pd.merge(staff, staff_department_assignments, on='staff_id').loc[lambda x: x['date_assigned_from'].str.startswith('2016'), ['staff_name', 'staff_gender']]"
list the name of staff who has been assigned multiple jobs.,"pd.merge(staff, staff_department_assignments, on='staff_id').groupby('staff_id').filter(lambda x: len(x) > 1)['staff_name']"
what are the names of staff who have been assigned multiple jobs?,"pd.merge(staff, staff_department_assignments, on='staff_id').groupby('staff_id').filter(lambda x: len(x) > 1)['staff_name']"
list the name and phone number of all suppliers in the alphabetical order of their addresses.,"pd.merge(pd.merge(suppliers, supplier_addresses, on='supplier_id'), addresses, on='address_id').sort_values('address_details')[['supplier_name', 'supplier_phone']]"
"what are the names and phone numbers for all suppliers, sorted in alphabetical order of their addressed?","pd.merge(pd.merge(suppliers, supplier_addresses, on='supplier_id'), addresses, on='address_id').sort_values('address_details')[['supplier_name', 'supplier_phone']]"
what are the phone numbers of all customers and suppliers.,"pd.concat([customers['customer_phone'], suppliers['supplier_phone']]).unique()"
return the phone numbers for all customers and suppliers.,"pd.concat([customers['customer_phone'], suppliers['supplier_phone']]).unique()"
return the ids of all products that were ordered more than three times or supplied more than 80000.,"pd.concat([order_items.groupby('product_id').filter(lambda x: len(x) > 3)['product_id'].drop_duplicates(),product_suppliers.groupby('product_id').filter(lambda x: x['total_amount_purchased'].sum() > 80000)['product_id'].drop_duplicates()]).drop_duplicates()"
what are the ids of all products that were either ordered more than 3 times or have a cumulative amount purchased of above 80000?,"pd.concat([order_items.groupby('product_id').filter(lambda x: len(x) > 3)['product_id'].drop_duplicates(),product_suppliers.groupby('product_id').filter(lambda x: x['total_amount_purchased'].sum() > 80000)['product_id'].drop_duplicates()]).drop_duplicates()"
what are id and name of the products whose price is lower than 600 or higher than 900?,"products.loc[(products['product_price'] < 600) | (products['product_price'] > 900), ['product_id', 'product_name']]"
give the ids and names of products with price lower than 600 or higher than 900.,"products.loc[(products['product_price'] < 600) | (products['product_price'] > 900), ['product_id', 'product_name']]"
find the id of suppliers whose average amount purchased for each product is above 50000 or below 30000.,product_suppliers.groupby('supplier_id')['total_amount_purchased'].mean().loc[lambda x: (x>50000) | (x<30000)].index.tolist()
what are the ids of suppliers which have an average amount purchased of above 50000 or below 30000?,product_suppliers.groupby('supplier_id')['total_amount_purchased'].mean().loc[lambda x: (x>50000) | (x<30000)].index.tolist()
what are the average amount purchased and value purchased for the supplier who supplies the most products.,"product_suppliers[product_suppliers['supplier_id'] == product_suppliers.groupby('supplier_id').size().sort_values(ascending=false).index[0]][['total_amount_purchased', 'total_value_purchased']].mean()"
return the average total amount purchased and total value purchased for the supplier who supplies the greatest number of products.,"product_suppliers[product_suppliers['supplier_id'] == product_suppliers.groupby('supplier_id').size().sort_values(ascending=false).index[0]][['total_amount_purchased', 'total_value_purchased']].mean()"
what is the largest and smallest customer codes?,"customers['customer_code'].agg(['max', 'min'])"
return the maximum and minimum customer codes.,"customers['customer_code'].agg(['max', 'min'])"
list the names of all the distinct customers who bought a keyboard.,"pd.merge(pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').loc[lambda x: x['product_name'] == 'keyboard', 'customer_name'].unique()"
what are the distinct names of customers who have purchased a keyboard?,"pd.merge(pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').loc[lambda x: x['product_name'] == 'keyboard', 'customer_name'].unique()"
list the names and phone numbers of all the distinct suppliers who supply red jeans.,"pd.merge(pd.merge(suppliers, product_suppliers, on='supplier_id'), products, on='product_id').loc[lambda x: x['product_name']=='red jeans', ['supplier_name', 'supplier_phone']].drop_duplicates()"
what are the distinct names and phone numbers for suppliers who have red jeans?,"pd.merge(pd.merge(suppliers, product_suppliers, on='supplier_id'), products, on='product_id').loc[lambda x: x['product_name']=='red jeans', ['supplier_name', 'supplier_phone']].drop_duplicates()"
"what are the highest and lowest prices of products, grouped by and alphabetically ordered by product type?","products.groupby('product_type_code')['product_price'].agg(['max', 'min']).reset_index()"
"give the maximum and minimum product prices for each product type, grouped and ordered by product type.","products.groupby('product_type_code')['product_price'].agg(['max', 'min']).reset_index()"
"list the order id, customer id for orders in cancelled status, ordered by their order dates.","customer_orders.loc[lambda x: x['order_status_code']=='cancelled', ['order_id', 'customer_id']].sort_values('order_date')"
"what are the order ids and customer ids for orders that have been cancelled, sorted by their order dates?","customer_orders.loc[lambda x: x['order_status_code']=='cancelled', ['order_id', 'customer_id']].sort_values('order_date')"
find the names of products that were bought by at least two distinct customers.,"pd.merge(pd.merge(customer_orders, order_items, on='order_id'), products, on='product_id').groupby('product_id').filter(lambda x: x['customer_id'].nunique() >= 2)['product_name'].unique()"
what are the distinct names of products purchased by at least two different customers?,"pd.merge(pd.merge(customer_orders, order_items, on='order_id'), products, on='product_id').groupby('product_id').filter(lambda x: x['customer_id'].nunique() >= 2)['product_name'].unique()"
find the names of customers who have bought by at least three distinct products.,"pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id').groupby('customer_name').apply(lambda x: x['product_id'].nunique() >= 3).loc[lambda x: x].index"
what are the distinct names of customers who have purchased at least three different products?,"pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id').groupby('customer_name').apply(lambda x: x['product_id'].nunique() >= 3).loc[lambda x: x].index"
find the name and gender of the staff who has been assigned the job of sales person but never clerical staff.,"pd.merge(staff.loc[lambda x: x['job_title_code']=='sales person', ['staff_id', 'staff_name', 'staff_gender']],staff_department_assignments.loc[lambda x: x['job_title_code']=='sales person', 'staff_id']).drop_duplicates().merge(staff.loc[lambda x: x['job_title_code']=='clerical staff'].drop(columns='job_title_code'), how='left', on='staff_id').drop_duplicates().loc[lambda x: x['job_title_code'].isna()].loc[:, ['staff_name', 'staff_gender']]"
"what are the names and genders of staff who have held the title sales person, but never clerical staff?","pd.merge(staff.loc[lambda x: x['job_title_code']=='sales person', ['staff_id', 'staff_name', 'staff_gender']],staff_department_assignments.loc[lambda x: x['job_title_code']=='sales person', 'staff_id']).drop_duplicates().merge(staff.loc[lambda x: x['job_title_code']=='clerical staff'].drop(columns='job_title_code'), how='left', on='staff_id').drop_duplicates().loc[lambda x: x['job_title_code'].isna()].loc[:, ['staff_name', 'staff_gender']]"
find the id and name of customers whose address contains wy state and do not use credit card for payment.,"customers.loc[(customers['customer_address'].str.contains('wy')) & (customers['payment_method_code'] != 'credit card'), ['customer_id', 'customer_name']]"
what are the ids and names of customers with addressed that contain wy and who do not use a credit card for payment?,"customers.loc[(customers['customer_address'].str.contains('wy')) & (customers['payment_method_code'] != 'credit card'), ['customer_id', 'customer_name']]"
find the average price of all product clothes.,"products.loc[lambda x: x['product_type_code']=='clothes', 'product_price'].mean()"
what is the average price of clothes?,"products.loc[lambda x: x['product_type_code']=='clothes', 'product_price'].mean()"
find the name of the most expensive hardware product.,"products.loc[lambda x: x['product_type_code']=='hardware'].sort_values('product_price', ascending=false)['product_name'].iloc[0]"
what is the name of the hardware product with the greatest price?,"products.loc[lambda x: x['product_type_code']=='hardware'].sort_values('product_price', ascending=false)['product_name'].iloc[0]"
how many aircrafts are there?,aircraft.shape[0]
what is the number of aircraft?,aircraft.shape[0]
list the description of all aircrafts.,aircraft['description']
what are the descriptions for the aircrafts?,aircraft['description']
what is the average number of international passengers of all airports?,airport['international_passengers'].mean()
what is the average number of international passengers for an airport?,airport['international_passengers'].mean()
"what are the number of international and domestic passengers of the airport named london ""heathrow""?","airport.loc[lambda x: x['airport_name']=='london heathrow', ['international_passengers', 'domestic_passengers']]"
how many international and domestic passengers are there in the airport london heathrow?,"airport.loc[lambda x: x['airport_name']=='london heathrow', ['international_passengers', 'domestic_passengers']]"
"what are the total number of domestic passengers of airports that contain the word ""london"".","airport.loc[airport['airport_name'].str.contains('london', case=false), 'domestic_passengers'].sum()"
what are the total number of domestic passengers at all london airports?,"airport.loc[airport['airport_name'].str.contains('london', case=false), 'domestic_passengers'].sum()"
what are the maximum and minimum number of transit passengers of all aiports.,"airport['transit_passengers'].agg(['max', 'min'])"
what is the maximum and mininum number of transit passengers for all airports?,"airport['transit_passengers'].agg(['max', 'min'])"
what are the name of pilots aged 25 or older?,"pilot.loc[pilot['age'] >= 25, 'name']"
what is the name of every pilot who is at least 25 years old?,"pilot.loc[pilot['age'] >= 25, 'name']"
list all pilot names in ascending alphabetical order.,pilot.sort_values('name')['name']
what are the names of the pilots in alphabetical order?,pilot.sort_values('name')['name']
list names of all pilot aged 30 or younger in descending alphabetical order.,"pilot.loc[lambda x: x['age']<=30].sort_values('name', ascending=false)['name']"
what are the names of all pilots 30 years old or young in descending alphabetical order?,"pilot.loc[lambda x: x['age']<=30].sort_values('name', ascending=false)['name']"
"please show the names of aircrafts associated with airport with name ""london gatwick"".","pd.merge(pd.merge(aircraft, airport_aircraft, on='aircraft_id'), airport, on='airport_id').loc[lambda x: x['airport_name']=='london gatwick', 'aircraft']"
what are the names of all the aircrafts associated with london gatwick airport?,"pd.merge(pd.merge(aircraft, airport_aircraft, on='aircraft_id'), airport, on='airport_id').loc[lambda x: x['airport_name']=='london gatwick', 'aircraft']"
please show the names and descriptions of aircrafts associated with airports that have a total number of passengers bigger than 10000000.,"pd.merge(pd.merge(aircraft, airport_aircraft, on='aircraft_id'), airport, on='airport_id').query('total_passengers > 10000000')[['aircraft', 'description']]"
what are the names and descriptions of aircrafts associated with an airport that has more total passengers than 10000000?,"pd.merge(pd.merge(aircraft, airport_aircraft, on='aircraft_id'), airport, on='airport_id').query('total_passengers > 10000000')[['aircraft', 'description']]"
"what is the average total number of passengers of airports that are associated with aircraft ""robinson r-22""?","pd.merge(pd.merge(aircraft, airport_aircraft, on='aircraft_id'), airport, on='airport_id').loc[lambda x: x['aircraft']=='robinson r-22', 'total_passengers'].mean()"
"what is the average total number of passengers for all airports that the aircraft ""robinson r-22"" visits?","pd.merge(pd.merge(aircraft, airport_aircraft, on='aircraft_id'), airport, on='airport_id').loc[lambda x: x['aircraft']=='robinson r-22', 'total_passengers'].mean()"
please list the location and the winning aircraft name.,"pd.merge(aircraft, match, left_on='aircraft_id', right_on='winning_aircraft')[['location', 'aircraft']]"
what is the location and name of the winning aircraft?,"pd.merge(aircraft, match, left_on='aircraft_id', right_on='winning_aircraft')[['location', 'aircraft']]"
list the name of the aircraft that has been named winning aircraft the most number of times.,"pd.merge(aircraft, match, left_on='aircraft_id', right_on='winning_aircraft').groupby('winning_aircraft')['aircraft'].count().sort_values(ascending=false).index[0]"
what is the name of the aircraft that has won an award the most?,"pd.merge(aircraft, match, left_on='aircraft_id', right_on='winning_aircraft').groupby('winning_aircraft')['aircraft'].count().sort_values(ascending=false).index[0]"
list the names of aircrafts and the number of times it won matches.,"pd.merge(aircraft, match, left_on='aircraft_id', right_on='winning_aircraft').groupby('winning_aircraft').agg({'aircraft':'first', '*':'count'}).rename(columns={'*':'count'}).reset_index()[['aircraft', 'count']]"
"for each aircraft that has won an award, what is its name and how many time has it won?","pd.merge(aircraft, match, left_on='aircraft_id', right_on='winning_aircraft').groupby('winning_aircraft').agg({'aircraft':'first', '*':'count'}).rename(columns={'*':'count'}).reset_index()[['aircraft', 'count']]"
list names of all pilot in descending order of age.,"pilot.sort_values('age', ascending=false)['name']"
what are the names of all pilots listed by descending age?,"pilot.sort_values('age', ascending=false)['name']"
list the names of aircrafts and that won matches at least twice.,"aircraft.loc[aircraft['aircraft_id'].isin(match['winning_aircraft'].value_counts()[match['winning_aircraft'].value_counts()>=2].index), 'aircraft'].unique()"
what are the names of all aircrafts that have won a match at least twice?,"aircraft.loc[aircraft['aircraft_id'].isin(match['winning_aircraft'].value_counts()[match['winning_aircraft'].value_counts()>=2].index), 'aircraft'].unique()"
list the names of aircrafts and that did not win any match.,"aircraft.loc[~aircraft['aircraft_id'].isin(match['winning_aircraft']), 'aircraft']"
what are the names of all aicrafts that have never won any match?,"aircraft.loc[~aircraft['aircraft_id'].isin(match['winning_aircraft']), 'aircraft']"
"show the names of aircrafts that are associated with both an airport named ""london heathrow"" and an airport named ""london gatwick""","pd.merge(pd.merge(airport_aircraft.loc[airport_aircraft['airport_id'].isin(airport.query('airport_name == ""london heathrow""').index), 'aircraft_id'], aircraft, on='aircraft_id'), airport_aircraft.loc[airport_aircraft['airport_id'].isin(airport.query('airport_name == ""london gatwick""').index), 'aircraft_id'], on='aircraft_id')['aircraft']"
what are the names of all aircrafts that are associated with both london heathrow and gatwick airports?,"pd.merge(pd.merge(airport_aircraft.loc[airport_aircraft['airport_id'].isin(airport.query('airport_name == ""london heathrow""').index), 'aircraft_id'], aircraft, on='aircraft_id'), airport_aircraft.loc[airport_aircraft['airport_id'].isin(airport.query('airport_name == ""london gatwick""').index), 'aircraft_id'], on='aircraft_id')['aircraft']"
show all information on the airport that has the largest number of international passengers.,"airport.sort_values('international_passengers', ascending=false).iloc[:1]"
what is all the information on the airport with the largest number of international passengers?,"airport.sort_values('international_passengers', ascending=false).iloc[:1]"
find the name and age of the pilot who has won the most number of times among the pilots who are younger than 30.,"pilot[pilot['age'] < 30].merge(match, left_on='pilot_id', right_on='winning_pilot').groupby(['winning_pilot', 'name', 'age']).size().nlargest(1).reset_index()[['name', 'age']]"
what is the name and age of the pilot younger than 30 who has won the most number of times?,"pilot[pilot['age'] < 30].merge(match, left_on='pilot_id', right_on='winning_pilot').groupby(['winning_pilot', 'name', 'age']).size().nlargest(1).reset_index()[['name', 'age']]"
what is the name and age of the youngest winning pilot?,"pd.merge(pilot, match, left_on='pilot_id', right_on='winning_pilot').sort_values('age').iloc[0][['name', 'age']]"
how old is the youngest winning pilot and what is their name?,"pd.merge(pilot, match, left_on='pilot_id', right_on='winning_pilot').sort_values('age').iloc[0][['name', 'age']]"
find the name of pilots who did not win the matches held in the country of australia.,"pilot.loc[~pilot['pilot_id'].isin(match.loc[match['country']=='australia', 'winning_pilot']),'name']"
what are the names of the pilots that have not won any matches in australia?,"pilot.loc[~pilot['pilot_id'].isin(match.loc[match['country']=='australia', 'winning_pilot']),'name']"
how many residents does each property have? list property id and resident count.,"residents.groupby('property_id').size().reset_index(name='count').merge(properties, on='property_id')[['property_id', 'count']]"
what is the distinct service types that are provided by the organization which has detail 'denesik and sons party'?,"services.merge(organizations, on='organization_id').loc[lambda x: x['organization_details']=='denesik and sons party', 'service_type_code'].unique()"
"how many services has each resident requested? list the resident id, details, and the count in descending order of the count.","pd.merge(residents, residents_services, on='resident_id').groupby(['resident_id', 'other_details']).size().reset_index(name='count').sort_values(by='count', ascending=false)[['resident_id', 'other_details', 'count']]"
"what is the maximum number that a certain service is provided? list the service id, details and number.","services.merge(residents_services, on='service_id').groupby(['service_id', 'service_details']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
"list the id and type of each thing, and the details of the organization that owns it.","pd.merge(things, organizations, on='organization_id')[['thing_id', 'type_of_thing_code', 'organization_details']]"
what are the id and details of the customers who have at least 3 events?,"customers.merge(customer_events, on='customer_id').groupby(['customer_id', 'customer_details']).filter(lambda x: len(x) >= 3)[['customer_id', 'customer_details']].drop_duplicates()"
"what is each customer's move in date, and the corresponding customer id and details?","pd.merge(customers, customer_events, on='customer_id')[['date_moved_in', 'customer_id', 'customer_details']]"
which events have the number of notes between one and three? list the event id and the property id.,"pd.merge(customer_events, customer_event_notes, on='customer_event_id').groupby('customer_event_id').filter(lambda x: 1<=len(x)<=3)[['customer_event_id', 'property_id']]"
what are the distinct id and type of the thing that has the status 'close' or has a status record before the date '2017-06-19 02:59:21',"pd.merge(timed_status_of_things, things, on='thing_id').loc[(timed_status_of_things['status_of_thing_code']=='close') | (timed_status_of_things['date_and_date'] < '2017-06-19 02:59:21'), ['thing_id', 'type_of_thing_code']].drop_duplicates()"
how many distinct locations have the things with service detail 'unsatisfied' been located in?,"pd.merge(things, timed_locations_of_things, on='thing_id').loc[lambda x: x['service_details']=='unsatisfied', 'location_code'].nunique()"
how many different status codes of things are there?,timed_status_of_things['status_of_thing_code'].nunique()
which organizations are not a parent organization of others? list the organization id.,organizations['organization_id'][~organizations['organization_id'].isin(organizations['parent_organization_id'])]
when is the last day any resident moved in?,residents['date_moved_in'].max()
what are the resident details containing the substring 'miss'?,"residents.loc[residents['other_details'].str.contains('miss'), 'other_details']"
list the customer event id and the corresponding move in date and property id.,"customer_events[['customer_event_id', 'date_moved_in', 'property_id']]"
how many customers did not have any event?,customers['customer_id'].isin(customer_events['customer_id']).value_counts()[false]
what are the distinct move in dates of the residents?,residents['date_moved_in'].unique()
list the locations of schools in ascending order of enrollment.,school.sort_values('enrollment')['location']
what is the list of school locations sorted in ascending order of school enrollment?,school.sort_values('enrollment')['location']
list the locations of schools in descending order of founded year.,"school.sort_values('founded', ascending=false)['location']"
what is the list of school locations sorted in descending order of school foundation year?,"school.sort_values('founded', ascending=false)['location']"
"what are the enrollments of schools whose denomination is not ""catholic""?","school.loc[lambda x: x['denomination']!='catholic', 'enrollment']"
"list the enrollment for each school that does not have ""catholic"" as denomination.","school.loc[lambda x: x['denomination']!='catholic', 'enrollment']"
what is the average enrollment of schools?,school['enrollment'].mean()
take the average of the school enrollment.,school['enrollment'].mean()
"what are the teams of the players, sorted in ascending alphabetical order?",player.sort_values('team')['team']
find the team of each player and sort them in ascending alphabetical order.,player.sort_values('team')['team']
how many different positions of players are there?,player['position'].nunique()
count the number of distinct player positions.,player['position'].nunique()
find the team of the player of the highest age.,"player.sort_values('age', ascending=false).iloc[0]['team']"
which team has the oldest player?,"player.sort_values('age', ascending=false).iloc[0]['team']"
list the teams of the players with the top 5 largest ages.,"player.sort_values('age', ascending=false).head(5)['team']"
what are the teams that have the 5 oldest players?,"player.sort_values('age', ascending=false).head(5)['team']"
"for each player, show the team and the location of school they belong to.","pd.merge(player, school, on='school_id')[['team', 'location']]"
what are the team and the location of school each player belongs to?,"pd.merge(player, school, on='school_id')[['team', 'location']]"
show the locations of schools that have more than 1 player.,"player.merge(school, on='school_id').groupby('school_id').filter(lambda x: len(x) > 1)['location']"
which schools have more than 1 player? give me the school locations.,"player.merge(school, on='school_id').groupby('school_id').filter(lambda x: len(x) > 1)['location']"
show the denomination of the school that has the most players.,"pd.merge(player, school, on='school_id').groupby('denomination').size().sort_values(ascending=false).index[0]"
what is the denomination of the school the most players belong to?,"pd.merge(player, school, on='school_id').groupby('denomination').size().sort_values(ascending=false).index[0]"
show locations and nicknames of schools.,"pd.merge(school, school_details, on='school_id')[['location', 'nickname']]"
what are the location and nickname of each school?,"pd.merge(school, school_details, on='school_id')[['location', 'nickname']]"
please show different denominations and the corresponding number of schools.,school.groupby('denomination').size().reset_index(name='count')
"for each denomination, return the denomination and the count of schools with that denomination.",school.groupby('denomination').size().reset_index(name='count')
please show different denominations and the corresponding number of schools in descending order.,"school.groupby('denomination').size().reset_index(name='count').sort_values('count', ascending=false)"
order denominations in descending order of the count of schools with the denomination. return each denomination with the count of schools.,"school.groupby('denomination').size().reset_index(name='count').sort_values('count', ascending=false)"
list the school color of the school that has the largest enrollment.,"school.sort_values('enrollment', ascending=false).iloc[0]['school_colors']"
what is the school color of the school with the largest enrollment?,"school.sort_values('enrollment', ascending=false).iloc[0]['school_colors']"
list the locations of schools that do not have any player.,"school.loc[~school['school_id'].isin(player['school_id']), 'location']"
which schools do not have any player? give me the school locations.,"school.loc[~school['school_id'].isin(player['school_id']), 'location']"
show the denomination shared by schools founded before 1890 and schools founded after 1900,"school.loc[school['founded'] < 1890, 'denomination'].interesect(school.loc[school['founded'] > 1900, 'denomination'])"
what are the denominations used by both schools founded before 1890 and schools founded  after 1900?,"school.loc[school['founded'] < 1890, 'denomination'].interesect(school.loc[school['founded'] > 1900, 'denomination'])"
show the nicknames of schools that are not in division 1.,"school_details.loc[lambda x: x['division'] != 'division 1', 'nickname']"
what are the nicknames of schools whose division is not 1?,"school_details.loc[lambda x: x['division'] != 'division 1', 'nickname']"
show the denomination shared by more than one school.,school.groupby('denomination').filter(lambda x: len(x) > 1)['denomination'].unique()
what are the denomination more than one school have?,school.groupby('denomination').filter(lambda x: len(x) > 1)['denomination'].unique()
find all the distinct district names ordered by city area in descending.,"district.sort_values('city_area', ascending=false)['district_name'].unique()"
what are the different district names in order of descending city area?,"district.sort_values('city_area', ascending=false)['district_name'].unique()"
find the list of page size which have more than 3 product listed,product.groupby('max_page_size').filter(lambda x: len(x)>3)['max_page_size'].unique()
what is the maximum page size for everything that has more than 3 products listed?,product.groupby('max_page_size').filter(lambda x: len(x)>3)['max_page_size'].unique()
find the name and population of district with population between 200000 and 2000000,"district.loc[(district['city_population'] >= 200000) & (district['city_population'] <= 2000000), ['district_name', 'city_population']]"
"what are the district names and city populations for all districts that between 200,000 and 2,000,000 residents?","district.loc[(district['city_population'] >= 200000) & (district['city_population'] <= 2000000), ['district_name', 'city_population']]"
find the name all districts with city area greater than 10 or population larger than 100000,"district.loc[(district['city_area'] > 10) | (district['city_population'] > 100000), 'district_name']"
what are the names of all districts with a city area greater than 10 or have more than 100000 people living there?,"district.loc[(district['city_area'] > 10) | (district['city_population'] > 100000), 'district_name']"
which district has the largest population?,"district.sort_values('city_population', ascending=false).iloc[0]['district_name']"
what is the name of the district with the most residents?,"district.sort_values('city_population', ascending=false).iloc[0]['district_name']"
which district has the least area?,district.sort_values('city_area').iloc[0]['district_name']
what is the name of the district with the smallest area?,district.sort_values('city_area').iloc[0]['district_name']
find the total population of the top 3 districts with the largest area.,"district.sort_values('city_area', ascending=false).head(3)['city_population'].sum()"
what is the total number of residents for the districts with the 3 largest areas?,"district.sort_values('city_area', ascending=false).head(3)['city_population'].sum()"
find all types of store and number of them.,store.groupby('type').size()
"for each type of store, how many of them are there?",store.groupby('type').size()
find the names of all stores in khanewal district.,"pd.merge(pd.merge(store, store_district, on='store_id'), district, on='district_id').loc[lambda x: x['district_name']=='khanewal district', 'store_name']"
what are the names of all the stores located in khanewal district?,"pd.merge(pd.merge(store, store_district, on='store_id'), district, on='district_id').loc[lambda x: x['district_name']=='khanewal district', 'store_name']"
find all the stores in the district with the most population.,"store.merge(store_district).loc[lambda x: x['district_id']==district.sort_values('city_population', ascending=false).iloc[0]['district_id'], 'store_name']"
what are the names of all the stores in the largest district by population?,"store.merge(store_district).loc[lambda x: x['district_id']==district.sort_values('city_population', ascending=false).iloc[0]['district_id'], 'store_name']"
"which city is the headquarter of the store named ""blackville"" in?","pd.merge(pd.merge(store, store_district, on='store_id'), district, on='district_id').loc[lambda x: x['store_name']=='blackville', 'headquartered_city']"
what city is the headquarter of the store blackville?,"pd.merge(pd.merge(store, store_district, on='store_id'), district, on='district_id').loc[lambda x: x['store_name']=='blackville', 'headquartered_city']"
find the number of stores in each city.,"store.merge(store_district, on='store_id').merge(district, on='district_id').groupby('headquartered_city').size()"
how many stores are headquarted in each city?,"store.merge(store_district, on='store_id').merge(district, on='district_id').groupby('headquartered_city').size()"
find the city with the most number of stores.,"store_district.merge(district, on='district_id').merge(store, on='store_id').groupby('headquartered_city').size().idxmax()"
what is the city with the most number of flagship stores?,"store_district.merge(district, on='district_id').merge(store, on='store_id').groupby('headquartered_city').size().idxmax()"
what is the average pages per minute color?,product['pages_per_minute_color'].mean()
what is the average number of pages per minute color?,product['pages_per_minute_color'].mean()
"what products are available at store named ""miramichi""?","pd.merge(pd.merge(product, store_product, on='product_id'), store, on='store_id').loc[lambda x: x['store_name']=='miramichi', 'product']"
what products are sold at the store named miramichi?,"pd.merge(pd.merge(product, store_product, on='product_id'), store, on='store_id').loc[lambda x: x['store_name']=='miramichi', 'product']"
"find products with max page size as ""a4"" and pages per minute color smaller than 5.","product.loc[(product['max_page_size']=='a4') & (product['pages_per_minute_color']<5), 'product']"
what are the products with the maximum page size a4 that also have a pages per minute color smaller than 5?,"product.loc[(product['max_page_size']=='a4') & (product['pages_per_minute_color']<5), 'product']"
"find products with max page size as ""a4"" or pages per minute color smaller than 5.","product.loc[(product['max_page_size']=='a4') | (product['pages_per_minute_color']<5), 'product']"
what are the products with the maximum page size eqal to a4 or a pages per minute color less than 5?,"product.loc[(product['max_page_size']=='a4') | (product['pages_per_minute_color']<5), 'product']"
"find all the product whose name contains the word ""scanner"".","product.loc[product['product'].str.contains('scanner'), 'product']"
"what are all of the products whose name includes the substring ""scanner""?","product.loc[product['product'].str.contains('scanner'), 'product']"
find the most prominent max page size among all the products.,product.groupby('max_page_size').size().sort_values(ascending=false).index[0]
what is the most common maximum page size?,product.groupby('max_page_size').size().sort_values(ascending=false).index[0]
find the name of the products that are not using the most frequently-used max page size.,"product.loc[product['product'] != product.loc[product.groupby('max_page_size')['max_page_size'].transform('size').nlargest(1).index[0], 'max_page_size'], 'product']"
what are the names of all products that are not the most frequently-used maximum page size?,"product.loc[product['product'] != product.loc[product.groupby('max_page_size')['max_page_size'].transform('size').nlargest(1).index[0], 'max_page_size'], 'product']"
find the total population of the districts where the area is bigger than the average city area.,"district.loc[district['city_area'] > district['city_area'].mean(), 'city_population'].sum()"
what is the total population for all the districts that have an area larger tahn the average city area?,"district.loc[district['city_area'] > district['city_area'].mean(), 'city_population'].sum()"
find the names of districts where have both city mall and village store type stores.,"district.loc[pd.merge(store[store['type']=='city mall'], store_district, on='store_id').merge(district, on='district_id')['district_name'].isin(pd.merge(store[store['type']=='village store'], store_district, on='store_id').merge(district, on='district_id')['district_name'])]['district_name']"
what are the names of the districts that have both mall and village store style shops?,"district.loc[pd.merge(store[store['type']=='city mall'], store_district, on='store_id').merge(district, on='district_id')['district_name'].isin(pd.merge(store[store['type']=='village store'], store_district, on='store_id').merge(district, on='district_id')['district_name'])]['district_name']"
what is the total enrollment number of all colleges?,college['enr'].sum()
how many students are enrolled in college?,college['enr'].sum()
what is the average enrollment number?,college['enr'].mean()
"how many students, on average, does each college have enrolled?",college['enr'].mean()
how many colleges in total?,college.shape[0]
how many different colleges are there?,college.shape[0]
how many players have more than 1000 hours of training?,(player['hs'] > 1000).sum()
how many different players trained for more than 1000 hours?,(player['hs'] > 1000).sum()
how many colleges has more than 15000 students?,(college['enr'] > 15000).sum()
what is the number of colleges with a student population greater than 15000?,(college['enr'] > 15000).sum()
what is the average training hours of all players?,player['hs'].mean()
how many hours do the players train on average?,player['hs'].mean()
find the name and training hours of players whose hours are below 1500.,"player.loc[lambda x: x['hs'] < 1500, ['pname', 'hs']]"
what are the names and number of hours spent training for each player who trains for less than 1500 hours?,"player.loc[lambda x: x['hs'] < 1500, ['pname', 'hs']]"
how many different colleges do attend the tryout test?,tryout['cname'].nunique()
how many different colleges were represented at tryouts?,tryout['cname'].nunique()
what are the unique types of player positions in the tryout?,tryout['ppos'].nunique()
what are the different types of player positions?,tryout['ppos'].nunique()
how many students got accepted after the tryout?,(tryout['decision'] == 'yes').sum()
how many students received a yes from tryouts?,(tryout['decision'] == 'yes').sum()
how many students whose are playing the role of goalie?,(tryout['ppos'] == 'goalie').sum()
what is the number of students playing as a goalie?,(tryout['ppos'] == 'goalie').sum()
"find the max, average and min training hours of all players.","player['hs'].agg(['mean', 'max', 'min'])"
"what is the average, maximum, and minimum for the number of hours spent training?","player['hs'].agg(['mean', 'max', 'min'])"
what is average enrollment of colleges in the state fl?,"college.loc[lambda x: x['state']=='fl', 'enr'].mean()"
what is average number of students enrolled in florida colleges?,"college.loc[lambda x: x['state']=='fl', 'enr'].mean()"
what are the names of players whose training hours is between 500 and 1500?,"player.loc[lambda x: x['hs'].between(500, 1500), 'pname']"
what are the names of players who train between 500 and 1500 hours?,"player.loc[lambda x: x['hs'].between(500, 1500), 'pname']"
find the players whose names contain letter 'a'.,"player.loc[lambda x: x['pname'].str.contains('a'), 'pname'].unique()"
who are the players that have names containing the letter a?,"player.loc[lambda x: x['pname'].str.contains('a'), 'pname'].unique()"
"find the name, enrollment of the colleges whose size is bigger than 10000 and location is in state la.","college.loc[(college['enr'] > 10000) & (college['state'] == 'la'), ['cname', 'enr']]"
what are the names and enrollment numbers for colleges that have more than 10000 enrolled and are located in louisiana?,"college.loc[(college['enr'] > 10000) & (college['state'] == 'la'), ['cname', 'enr']]"
list all information about college sorted by enrollment number in the ascending order.,college.sort_values('enr')
what information do you have on colleges sorted by increasing enrollment numbers?,college.sort_values('enr')
list the name of the colleges whose enrollment is greater 18000 sorted by the college's name.,college.loc[lambda x: x['enr']>18000].sort_values('cname')['cname']
what is the name of every college in alphabetical order that has more than 18000 students enrolled?,college.loc[lambda x: x['enr']>18000].sort_values('cname')['cname']
find the name of players whose card is yes in the descending order of training hours.,"player.loc[lambda x: x['ycard']=='yes'].sort_values('hs', ascending=false)['pname']"
what are the name of the players who received a card in descending order of the hours of training?,"player.loc[lambda x: x['ycard']=='yes'].sort_values('hs', ascending=false)['pname']"
find the name of different colleges involved in the tryout in alphabetical order.,tryout['cname'].sort_values().unique()
what are the different names of the colleges involved in the tryout in alphabetical order?,tryout['cname'].sort_values().unique()
which position is most popular among players in the tryout?,tryout.groupby('ppos').size().sort_values(ascending=false).index[0]
what was the most popular position at tryouts?,tryout.groupby('ppos').size().sort_values(ascending=false).index[0]
find the number of students who participate in the tryout for each college ordered by descending count.,"tryout.groupby('cname').size().reset_index(name='count(*)').sort_values('count(*)', ascending=false)"
how many students participated in tryouts for each college by descennding count?,"tryout.groupby('cname').size().reset_index(name='count(*)').sort_values('count(*)', ascending=false)"
what is minimum hours of the students playing in different position?,"pd.merge(tryout, player, on='pid').groupby('ppos').agg({'hs': 'min', 'ppos': 'first'})['hs']"
"for each position, what is the minimum time students spent practicing?","pd.merge(tryout, player, on='pid').groupby('ppos').agg({'hs': 'min', 'ppos': 'first'})['hs']"
what are the names of schools with the top 3 largest size?,"college.sort_values('enr', ascending=false).iloc[:3]['cname']"
what are the names of the schools with the top 3 largest class sizes?,"college.sort_values('enr', ascending=false).iloc[:3]['cname']"
what is the name of school that has the smallest enrollment in each state?,"college.groupby('state').agg({'cname': 'first', 'enr': 'min'})"
what is the name of the school with smallest enrollment size per state?,"college.groupby('state').agg({'cname': 'first', 'enr': 'min'})"
find the states where have some college students in tryout.,"pd.merge(college, tryout, on='cname')['state'].unique()"
what are the different states that have students trying out?,"pd.merge(college, tryout, on='cname')['state'].unique()"
find the states where have some college students in tryout and their decisions are yes.,"pd.merge(college, tryout, on='cname').loc[lambda x: x['decision']=='yes', 'state'].unique()"
what are the different states that had students successfully try out?,"pd.merge(college, tryout, on='cname').loc[lambda x: x['decision']=='yes', 'state'].unique()"
find the name and college of students whose decisions are yes in the tryout.,"pd.merge(player, tryout[tryout['decision']=='yes'], on='pid')[['pname', 'cname']]"
"what are the names of all the players who received a yes during tryouts, and also what are the names of their colleges?","pd.merge(player, tryout[tryout['decision']=='yes'], on='pid')[['pname', 'cname']]"
find the name of all students who were in the tryout sorted in alphabetic order.,"pd.merge(player, tryout, on='pid').sort_values('pname')['pname']"
what are the names of all students who tried out in alphabetical order?,"pd.merge(player, tryout, on='pid').sort_values('pname')['pname']"
find the name and hours of the students whose tryout decision is yes.,"pd.merge(player, tryout.loc[lambda x: x['decision']=='yes'], on='pid')[['pname', 'hs']]"
what are the names and hours spent practicing of every student who received a yes at tryouts?,"pd.merge(player, tryout.loc[lambda x: x['decision']=='yes'], on='pid')[['pname', 'hs']]"
find the states of the colleges that have students in the tryout who played in striker position.,"pd.merge(college, tryout, on='cname').loc[lambda x: x['ppos']=='striker', 'state']"
what are the states of the colleges where students who tried out for the striker position attend?,"pd.merge(college, tryout, on='cname').loc[lambda x: x['ppos']=='striker', 'state']"
find the names of the students who are in the position of striker and got a yes tryout decision.,"pd.merge(player, tryout.loc[lambda x: (x['decision']=='yes') & (x['ppos']=='striker')], on='pid')['pname']"
what are the names of all students who successfully tried out for the position of striker?,"pd.merge(player, tryout.loc[lambda x: (x['decision']=='yes') & (x['ppos']=='striker')], on='pid')['pname']"
find the state of the college which player charles is attending.,"pd.merge(pd.merge(college, tryout, on='cname'), player, on='pid').loc[lambda x: x['pname']=='charles', 'state']"
in which state is the college that charles attends?,"pd.merge(pd.merge(college, tryout, on='cname'), player, on='pid').loc[lambda x: x['pname']=='charles', 'state']"
find the average and maximum hours for the students whose tryout decision is yes.,"pd.merge(player, tryout.loc[lambda x: x['decision']=='yes'], on='pid')['hs'].agg(['mean', 'max'])"
what is the average and maximum number of hours students who made the team practiced?,"pd.merge(player, tryout.loc[lambda x: x['decision']=='yes'], on='pid')['hs'].agg(['mean', 'max'])"
find the average hours for the students whose tryout decision is no.,"pd.merge(player, tryout.loc[lambda x: x['decision']=='no'], on='pid')['hs'].mean()"
what is the average number of hours spent practicing for students who got rejected?,"pd.merge(player, tryout.loc[lambda x: x['decision']=='no'], on='pid')['hs'].mean()"
what is the maximum training hours for the students whose training hours is greater than 1000 in different positions?,"pd.merge(player, tryout, on='pid').loc[lambda x: x['hs'] > 1000].groupby('ppos')['hs'].max()"
"for each position, what is the maximum number of  hours for students who spent more than 1000 hours training?","pd.merge(player, tryout, on='pid').loc[lambda x: x['hs'] > 1000].groupby('ppos')['hs'].max()"
which colleges do the tryout players whose name starts with letter d go to?,"pd.merge(tryout, player, on='pid').loc[lambda x: x['pname'].str.startswith('d'), 'cname']"
which colleges does each player with a name that starts with the letter d  who tried out go to?,"pd.merge(tryout, player, on='pid').loc[lambda x: x['pname'].str.startswith('d'), 'cname']"
which college has any student who is a goalie and succeeded in the tryout.,"tryout.loc[(tryout['decision']=='yes')&(tryout['ppos']=='goalie'), 'cname']"
what college has a student who successfully made the team in the role of a goalie?,"tryout.loc[(tryout['decision']=='yes')&(tryout['ppos']=='goalie'), 'cname']"
find the name of the tryout players who are from the college with largest size.,"player.merge(tryout, on='pid').loc[lambda x: x['cname']==college.sort_values('enr', ascending=false)['cname'].iloc[0], 'pname']"
what are the names of all tryout participants who are from the largest college?,"player.merge(tryout, on='pid').loc[lambda x: x['cname']==college.sort_values('enr', ascending=false)['cname'].iloc[0], 'pname']"
what is the state and enrollment of the colleges where have any students who got accepted in the tryout decision.,"pd.merge(college, tryout.loc[lambda x: x['decision']=='yes'], on='cname')[['state', 'enr']].drop_duplicates()"
"how many students are enrolled in colleges that have student accepted during tryouts, and in which states are those colleges?","pd.merge(college, tryout.loc[lambda x: x['decision']=='yes'], on='cname')[['state', 'enr']].drop_duplicates()"
find the names of either colleges in la with greater than 15000 size or in state az with less than 13000 enrollment.,"pd.concat([college.loc[(college['enr'] < 13000) & (college['state'] == 'az'), 'cname'],college.loc[(college['enr'] > 15000) & (college['state'] == 'la'), 'cname']]).drop_duplicates()"
"what are the names of colleges in la that have more than 15,000 students and of colleges in az with less than 13,000 students?","pd.concat([college.loc[(college['enr'] < 13000) & (college['state'] == 'az'), 'cname'],college.loc[(college['enr'] > 15000) & (college['state'] == 'la'), 'cname']]).drop_duplicates()"
find the names of schools that have some students playing in goalie and mid positions.,"set(tryout.loc[tryout['ppos'] == 'goalie', 'cname']).intersection(set(tryout.loc[tryout['ppos'] == 'mid', 'cname']))"
what are the names of all schools that have students trying out for the position of goal and 'mid'-field.,"set(tryout.loc[tryout['ppos'] == 'goalie', 'cname']).intersection(set(tryout.loc[tryout['ppos'] == 'mid', 'cname']))"
find the names of states that have some college students playing in goalie and mid positions.,"pd.merge(college.loc[college.merge(tryout.loc[tryout['ppos']=='goalie', ['cname']])['cname']], college.loc[college.merge(tryout.loc[tryout['ppos']=='mid', ['cname']])['cname']], how='inner')['state']"
what are the names of the states that have some college students playing in the positions of goalie and mid-field?,"pd.merge(college.loc[college.merge(tryout.loc[tryout['ppos']=='goalie', ['cname']])['cname']], college.loc[college.merge(tryout.loc[tryout['ppos']=='mid', ['cname']])['cname']], how='inner')['state']"
how many schools have some students playing in goalie and mid positions.,"len(pd.merge(tryout.loc[tryout['ppos']=='goalie', ['cname']], tryout.loc[tryout['ppos']=='mid', ['cname']], on='cname'))"
how many schools have students playing in goalie and mid-field positions?,"len(pd.merge(tryout.loc[tryout['ppos']=='goalie', ['cname']], tryout.loc[tryout['ppos']=='mid', ['cname']], on='cname'))"
find the names of schools that have some players in the mid position but not in the goalie position.,tryout[tryout['ppos']=='mid']['cname'].isin(tryout[tryout['ppos']=='goalie']['cname']).pipe(lambda x:x[~x]).index
what are the names of the schools with some players in the mid position but no goalies?,tryout[tryout['ppos']=='mid']['cname'].isin(tryout[tryout['ppos']=='goalie']['cname']).pipe(lambda x:x[~x]).index
find the names of states that have some college students playing in the mid position but not in the goalie position.,"college.merge(tryout.loc[lambda x: x['ppos']=='mid'], on='cname')['state'].drop_duplicates().append(college.merge(tryout.loc[lambda x: x['ppos']=='goalie'], on='cname')['state']).drop_duplicates(keep=false)"
what are the names of all the states with college students playing in the mid position but no goalies?,"college.merge(tryout.loc[lambda x: x['ppos']=='mid'], on='cname')['state'].drop_duplicates().append(college.merge(tryout.loc[lambda x: x['ppos']=='goalie'], on='cname')['state']).drop_duplicates(keep=false)"
how many states that have some college students playing in the mid position but not in the goalie position.,"((college.merge(tryout[tryout.ppos=='mid'], on='cname')).loc[~(college.merge(tryout[tryout.ppos=='goalie'], on='cname'))['state'].isin((college.merge(tryout[tryout.ppos=='mid'], on='cname'))['state'])])['state'].nunique()"
what is the count of states with college students playing in the mid position but not as goalies?,"((college.merge(tryout[tryout.ppos=='mid'], on='cname')).loc[~(college.merge(tryout[tryout.ppos=='goalie'], on='cname'))['state'].isin((college.merge(tryout[tryout.ppos=='mid'], on='cname'))['state'])])['state'].nunique()"
find the states where have the colleges whose enrollments are less than the largest size.,"college.loc[lambda x: x['enr'] < x['enr'].max(), 'state'].unique()"
what are the states with colleges that have enrollments less than the some other college?,"college.loc[lambda x: x['enr'] < x['enr'].max(), 'state'].unique()"
find names of colleges with enrollment greater than that of some (at least one) college in the fl state.,"college.loc[lambda x: x['enr'] > college.loc[lambda y: y['state']=='fl', 'enr'].min(), 'cname'].unique()"
what are the names of the colleges that are larger than at least one college in florida?,"college.loc[lambda x: x['enr'] > college.loc[lambda y: y['state']=='fl', 'enr'].min(), 'cname'].unique()"
find names of all colleges whose enrollment is greater than that of all colleges in the fl state.,"college.loc[college['enr'] > college.loc[college['state'] == 'fl', 'enr'].max(), 'cname']"
what are the names of all colleges with a larger enrollment than the largest college in florida?,"college.loc[college['enr'] > college.loc[college['state'] == 'fl', 'enr'].max(), 'cname']"
what is the total number of enrollment of schools that do not have any goalie player?,"college.loc[~college['cname'].isin(tryout.loc[tryout['ppos']=='goalie', 'cname']), 'enr'].sum()"
what is the total number of students enrolled in schools without any goalies?,"college.loc[~college['cname'].isin(tryout.loc[tryout['ppos']=='goalie', 'cname']), 'enr'].sum()"
what is the number of states that has some college whose enrollment is larger than the average enrollment?,"college.loc[lambda x: x['enr'] > x['enr'].mean(), 'state'].nunique()"
how many states have a college with more students than average?,"college.loc[lambda x: x['enr'] > x['enr'].mean(), 'state'].nunique()"
what is the number of states that has some colleges whose enrollment is smaller than the average enrollment?,"college.loc[lambda x: x['enr'] < x['enr'].mean(), 'state'].nunique()"
how many states have smaller colleges than average?,"college.loc[lambda x: x['enr'] < x['enr'].mean(), 'state'].nunique()"
how many devices are there?,device.shape[0]
count the number of devices.,device.shape[0]
list the carriers of devices in ascending alphabetical order.,device.sort_values('carrier')['carrier']
"what are the different carriers for devices, listed in alphabetical order?",device.sort_values('carrier')['carrier']
"what are the carriers of devices whose software platforms are not ""android""?","device.loc[lambda x: x['software_platform']!='android', 'carrier']"
return the device carriers that do not have android as their software platform.,"device.loc[lambda x: x['software_platform']!='android', 'carrier']"
what are the names of shops in ascending order of open year?,shop.sort_values('open_year')['shop_name']
"return the names of shops, ordered by year of opening ascending.",shop.sort_values('open_year')['shop_name']
what is the average quantity of stocks?,stock['quantity'].mean()
give the average quantity of stocks.,stock['quantity'].mean()
what are the names and location of the shops in ascending alphabetical order of name.,"shop[['shop_name', 'location']].sort_values('shop_name')"
"return the names and locations of shops, ordered by name in alphabetical order.","shop[['shop_name', 'location']].sort_values('shop_name')"
how many different software platforms are there for devices?,device['software_platform'].nunique()
count the number of different software platforms.,device['software_platform'].nunique()
"list the open date of open year of the shop named ""apple"".","shop.loc[shop['shop_name'] == 'apple', ['open_date', 'open_year']]"
what are the open dates and years for the shop named apple?,"shop.loc[shop['shop_name'] == 'apple', ['open_date', 'open_year']]"
list the name of the shop with the latest open year.,"shop.sort_values('open_year', ascending=false).iloc[0]['shop_name']"
what is the shop name corresponding to the shop that opened in the most recent year?,"shop.sort_values('open_year', ascending=false).iloc[0]['shop_name']"
show names of shops and the carriers of devices they have in stock.,"pd.merge(pd.merge(stock, device, on='device_id'), shop, on='shop_id')[['shop_name', 'carrier']]"
"what are the names of device shops, and what are the carriers that they carry devices in stock for?","pd.merge(pd.merge(stock, device, on='device_id'), shop, on='shop_id')[['shop_name', 'carrier']]"
show names of shops that have more than one kind of device in stock.,"pd.merge(stock, shop, on='shop_id').groupby('shop_name').filter(lambda x: len(x)>1)['shop_name'].unique()"
what are the names of shops that have more than a single kind of device in stock?,"pd.merge(stock, shop, on='shop_id').groupby('shop_name').filter(lambda x: len(x)>1)['shop_name'].unique()"
show the name of the shop that has the most kind of devices in stock.,"stock.merge(shop, on='shop_id').groupby('shop_name').size().sort_values(ascending=false).index[0]"
what is the name of the shop that has the most different kinds of devices in stock?,"stock.merge(shop, on='shop_id').groupby('shop_name').size().sort_values(ascending=false).index[0]"
show the name of the shop that have the largest quantity of devices in stock.,"pd.merge(stock, shop, on='shop_id').groupby('shop_id')['quantity'].sum().sort_values(ascending=false).head(1).index.get_level_values('shop_name')"
what is the name of the shop that has the greatest quantity of devices in stock?,"pd.merge(stock, shop, on='shop_id').groupby('shop_id')['quantity'].sum().sort_values(ascending=false).head(1).index.get_level_values('shop_name')"
please show different software platforms and the corresponding number of devices using each.,device.groupby('software_platform').size().reset_index(name='count')
"what are the different software platforms for devices, and how many devices have each?",device.groupby('software_platform').size().reset_index(name='count')
please show the software platforms of devices in descending order of the count.,device.groupby('software_platform').size().sort_values(ascending=false).index
"what are the different software platforms for devices, ordered by frequency descending?",device.groupby('software_platform').size().sort_values(ascending=false).index
list the software platform shared by the greatest number of devices.,device.groupby('software_platform').size().sort_values(ascending=false).head(1).index[0]
what is the software platform that is most common amongst all devices?,device.groupby('software_platform').size().sort_values(ascending=false).head(1).index[0]
list the names of shops that have no devices in stock.,"shop.loc[~shop['shop_id'].isin(stock['shop_id']), 'shop_name']"
what are the names of shops that do not have any devices in stock?,"shop.loc[~shop['shop_id'].isin(stock['shop_id']), 'shop_name']"
show the locations shared by shops with open year later than 2012 and shops with open year before 2008.,"shop.loc[shop['open_year'] > 2012, 'location'].interesect(shop.loc[shop['open_year'] < 2008, 'location'])"
which locations contains both shops that opened after the year 2012 and shops that opened before 2008?,"shop.loc[shop['open_year'] > 2012, 'location'].interesect(shop.loc[shop['open_year'] < 2008, 'location'])"
list the carriers of devices that have no devices in stock.,"device.loc[~device['device_id'].isin(stock['device_id']), 'carrier']"
what are the carriers of devices that are not in stock anywhere?,"device.loc[~device['device_id'].isin(stock['device_id']), 'carrier']"
show the carriers of devices in stock at more than one shop.,"pd.merge(stock, device, on='device_id').groupby('device_id').filter(lambda x: len(x) > 1)['carrier']"
what are the carriers of devices that are in stock in more than a single shop?,"pd.merge(stock, device, on='device_id').groupby('device_id').filter(lambda x: len(x) > 1)['carrier']"
how many bookings do we have?,bookings.shape[0] or len(bookings)
count the total number of bookings made.,bookings.shape[0] or len(bookings)
list the order dates of all the bookings.,bookings['order_date']
what is the order date of each booking?,bookings['order_date']
show all the planned delivery dates and actual delivery dates of bookings.,"bookings[['planned_delivery_date', 'actual_delivery_date']]"
what are the planned delivery date and actual delivery date for each booking?,"bookings[['planned_delivery_date', 'actual_delivery_date']]"
count the number of customers recorded.,customers.shape[0]
what are the phone and email for customer harold?,"customers.loc[lambda x: x['customer_name']=='harold', ['customer_phone', 'customer_email_address']]"
"find the phone number and email address of customer ""harold"".","customers.loc[lambda x: x['customer_name']=='harold', ['customer_phone', 'customer_email_address']]"
show all the store_name of drama workshop groups.,drama_workshop_groups['store_name']
what are the store names of drama workshop groups?,drama_workshop_groups['store_name']
"show the minimum, average, maximum order quantity of all invoices.","invoices['order_quantity'].agg(['min', 'mean', 'max'])"
"what are the minimum, average, and maximum quantities ordered? check all the invoices.","invoices['order_quantity'].agg(['min', 'mean', 'max'])"
what are the distinct payment method codes in all the invoices?,invoices['payment_method_code'].unique()
show me the distinct payment method codes from the invoice record.,invoices['payment_method_code'].unique()
what is the description of the marketing region china?,"marketing_regions.loc[lambda x: x['marketing_region_name']=='china', 'marketing_region_descriptrion']"
find the marketing region description of china?,"marketing_regions.loc[lambda x: x['marketing_region_name']=='china', 'marketing_region_descriptrion']"
show all the distinct product names with price higher than the average.,"products.loc[lambda x: x['product_price'] > x['product_price'].mean(), 'product_name'].unique()"
what are the distinct names of the products that cost more than the average?,"products.loc[lambda x: x['product_price'] > x['product_price'].mean(), 'product_name'].unique()"
what is the name of the most expensive product?,"products.sort_values('product_price', ascending=false)['product_name'].iloc[0]"
tell me the name of the most pricy product.,"products.sort_values('product_price', ascending=false)['product_name'].iloc[0]"
list all product names in ascending order of price.,products.sort_values('product_price')['product_name']
sort the names of products in ascending order of their price.,products.sort_values('product_price')['product_name']
what is the phone number of the performer ashley?,"performers.loc[performers['customer_name']=='ashley', 'customer_phone']"
"find the phone number of performer ""ashley"".","performers.loc[performers['customer_name']=='ashley', 'customer_phone']"
show all payment method codes and the number of orders for each code.,invoices.groupby('payment_method_code').size()
list the distinct payment method codes with the number of orders made,invoices.groupby('payment_method_code').size()
what is the payment method code used by the most orders?,invoices.groupby('payment_method_code').size().sort_values(ascending=false).index[0]
find the payment method that is used the most often in all the invoices. give me its code.,invoices.groupby('payment_method_code').size().sort_values(ascending=false).index[0]
"which city is the address of the store named ""fja filming"" located in?","addresses.merge(stores, on='address_id').loc[lambda x: x['store_name']=='fja filming', 'city_town']"
"find the city the store named ""fja filming"" is in.","addresses.merge(stores, on='address_id').loc[lambda x: x['store_name']=='fja filming', 'city_town']"
"what are the states or counties of the address of the stores with marketing region code ""ca""?","addresses.merge(stores.loc[lambda x: x['marketing_region_code']=='ca'], on='address_id')['state_county']"
"find the states or counties where the stores with marketing region code ""ca"" are located.","addresses.merge(stores.loc[lambda x: x['marketing_region_code']=='ca'], on='address_id')['state_county']"
what is the name of the marketing region that the store rob dinning belongs to?,"marketing_regions.loc[marketing_regions['marketing_region_code'].isin(stores.loc[stores['store_name']=='rob dinning', 'marketing_region_code']), 'marketing_region_name']"
return the name of the marketing region the store rob dinning is located in.,"marketing_regions.loc[marketing_regions['marketing_region_code'].isin(stores.loc[stores['store_name']=='rob dinning', 'marketing_region_code']), 'marketing_region_name']"
what are the descriptions of the service types with product price above 100?,"pd.merge(ref_service_types, services.loc[lambda x: x['product_price'] > 100], on='service_type_code')['service_type_description']"
give me the descriptions of the service types that cost more than 100.,"pd.merge(ref_service_types, services.loc[lambda x: x['product_price'] > 100], on='service_type_code')['service_type_description']"
"what is the description, code and the corresponding count of each service type?","pd.merge(ref_service_types, services, on='service_type_code').groupby(['service_type_code', 'service_type_description']).size().reset_index(name='count')[['service_type_description', 'service_type_code', 'count']]"
"list the description, code and the number of services for each service type.","pd.merge(ref_service_types, services, on='service_type_code').groupby(['service_type_code', 'service_type_description']).size().reset_index(name='count')[['service_type_description', 'service_type_code', 'count']]"
what is the description and code of the type of service that is performed the most often?,"pd.merge(ref_service_types, services, on='service_type_code').groupby(['service_type_code', 'service_type_description']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['service_type_description', 'service_type_code']]"
find the description and code of the service type that is performed the most times.,"pd.merge(ref_service_types, services, on='service_type_code').groupby(['service_type_code', 'service_type_description']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['service_type_description', 'service_type_code']]"
what are the phones and emails of workshop groups in which services are performed?,"pd.merge(drama_workshop_groups, services, on='workshop_group_id')[['store_phone', 'store_email_address']]"
give me all the phone numbers and email addresses of the workshop groups where services are performed.,"pd.merge(drama_workshop_groups, services, on='workshop_group_id')[['store_phone', 'store_email_address']]"
"what are the names of workshop groups in which services with product name ""film"" are performed?","pd.merge(drama_workshop_groups, services[lambda x: x['product_name']=='film'], on='workshop_group_id')[['store_phone', 'store_email_address']]"
"find the names of the workshop groups where services with product name ""film"" are performed.","pd.merge(drama_workshop_groups, services[lambda x: x['product_name']=='film'], on='workshop_group_id')[['store_phone', 'store_email_address']]"
what are the different product names? what is the average product price for each of them?,products.groupby('product_name')['product_price'].mean()
"for each distinct product name, show its average product price.",products.groupby('product_name')['product_price'].mean()
what are the product names with average product price smaller than 1000000?,products.groupby('product_name').filter(lambda x: x['product_price'].mean() < 1000000)['product_name'].unique()
find the product names whose average product price is below 1000000.,products.groupby('product_name').filter(lambda x: x['product_price'].mean() < 1000000)['product_name'].unique()
what are the total order quantities of photo products?,"order_items.merge(products, on='product_id').query('product_name == ""photo""')['order_quantity'].sum()"
"compute the total order quantities of the product ""photo"".","order_items.merge(products, on='product_id').query('product_name == ""photo""')['order_quantity'].sum()"
what are the order details of the products with price higher than 2000?,"pd.merge(order_items, products, on='product_id').loc[lambda x: x['product_price'] > 2000, 'other_item_details']"
find the order detail for the products with price above 2000.,"pd.merge(order_items, products, on='product_id').loc[lambda x: x['product_price'] > 2000, 'other_item_details']"
what are the actual delivery dates of orders with quantity 1?,"pd.merge(customer_orders, order_items.loc[lambda x: x['order_quantity']==1], on='order_id')['actual_delivery_date']"
list the actual delivery date for all the orders with quantity 1,"pd.merge(customer_orders, order_items.loc[lambda x: x['order_quantity']==1], on='order_id')['actual_delivery_date']"
what are the order dates of orders with price higher than 1000?,"pd.merge(pd.merge(customer_orders, order_items, on='order_id'), products, on='product_id').loc[lambda x: x['product_price'] > 1000, 'order_date']"
find the order dates of the orders with price above 1000.,"pd.merge(pd.merge(customer_orders, order_items, on='order_id'), products, on='product_id').loc[lambda x: x['product_price'] > 1000, 'order_date']"
how many distinct currency codes are there for all drama workshop groups?,drama_workshop_groups['currency_code'].nunique()
find the number of distinct currency codes used in drama workshop groups.,drama_workshop_groups['currency_code'].nunique()
what are the names of the drama workshop groups with address in feliciaberg city?,"pd.merge(addresses, drama_workshop_groups, on='address_id').loc[lambda x: x['city_town']=='feliciaberg', 'store_name']"
return the the names of the drama workshop groups that are located in feliciaberg city.,"pd.merge(addresses, drama_workshop_groups, on='address_id').loc[lambda x: x['city_town']=='feliciaberg', 'store_name']"
what are the email addresses of the drama workshop groups with address in alaska state?,"pd.merge(addresses, drama_workshop_groups, on='address_id').loc[lambda x: x['state_county']=='alaska', 'store_email_address']"
list the email addresses of the drama workshop groups located in alaska state.,"pd.merge(addresses, drama_workshop_groups, on='address_id').loc[lambda x: x['state_county']=='alaska', 'store_email_address']"
show all cities along with the number of drama workshop groups in each city.,"pd.merge(addresses, drama_workshop_groups, on='address_id').groupby('city_town').size().reset_index(name='count(*)')[['city_town', 'count(*)']]"
how many drama workshop groups are there in each city? return both the city and the count.,"pd.merge(addresses, drama_workshop_groups, on='address_id').groupby('city_town').size().reset_index(name='count(*)')[['city_town', 'count(*)']]"
what is the marketing region code that has the most drama workshop groups?,"drama_workshop_groups.groupby('marketing_region_code').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['marketing_region_code']"
which marketing region has the most drama workshop groups? give me the region code.,"drama_workshop_groups.groupby('marketing_region_code').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['marketing_region_code']"
show all cities where at least one customer lives in but no performer lives in.,"pd.merge(addresses, customers, on='address_id')['city_town'].drop_duplicates().append(pd.merge(addresses, performers, on='address_id')['city_town']).drop_duplicates(keep=false)"
which cities have at least one customer but no performer?,"pd.merge(addresses, customers, on='address_id')['city_town'].drop_duplicates().append(pd.merge(addresses, performers, on='address_id')['city_town']).drop_duplicates(keep=false)"
what is the most frequent status of bookings?,bookings.groupby('status_code').size().sort_values(ascending=false).index[0]
which status code is the most common of all the bookings?,bookings.groupby('status_code').size().sort_values(ascending=false).index[0]
"what are the names of the workshop groups that have bookings with status code ""stop""?","pd.merge(bookings, drama_workshop_groups, on='workshop_group_id').loc[lambda x: x['status_code']=='stop', 'store_name']"
"which workshop groups have bookings with status code ""stop""? give me the names.","pd.merge(bookings, drama_workshop_groups, on='workshop_group_id').loc[lambda x: x['status_code']=='stop', 'store_name']"
show the names of all the clients with no booking.,"clients['customer_name'].loc[~clients['customer_name'].isin(bookings.merge(clients, left_on='customer_id', right_on='client_id')['customer_name'].unique())]"
what are the names of the clients who do not have any booking?,"clients['customer_name'].loc[~clients['customer_name'].isin(bookings.merge(clients, left_on='customer_id', right_on='client_id')['customer_name'].unique())]"
"what is the average quantities ordered with payment method code ""mastercard"" on invoices?","invoices.loc[invoices['payment_method_code']=='mastercard', 'order_quantity'].mean()"
"check the invoices record and compute the average quantities ordered with the payment method ""mastercard"".","invoices.loc[invoices['payment_method_code']=='mastercard', 'order_quantity'].mean()"
what is the product id of the most frequently ordered item on invoices?,invoices.groupby('product_id').size().sort_values(ascending=false).index[0]
find the id of the product ordered the most often on invoices.,invoices.groupby('product_id').size().sort_values(ascending=false).index[0]
what is the description of the service type which offers both the photo product and the film product?,"pd.merge(ref_service_types.loc[lambda x: x['service_type_code'].isin(services.loc[lambda x: x['product_name'] == 'photo', 'service_type_code'])],services.loc[lambda x: x['product_name'] == 'film'],on='service_type_code',)['service_type_description']"
give me the description of the service type that offers not only the photo product but also the film product.,"pd.merge(ref_service_types.loc[lambda x: x['service_type_code'].isin(services.loc[lambda x: x['product_name'] == 'photo', 'service_type_code'])],services.loc[lambda x: x['product_name'] == 'film'],on='service_type_code',)['service_type_description']"
how many bands are there?,band.shape[0]
find the number of bands.,band.shape[0]
what are all the labels?,albums['label'].unique()
what are the different album labels listed?,albums['label'].unique()
find all the albums in 2012.,albums.loc[lambda x: x['year']==2012]
return all columns of the albums created in the year of 2012.,albums.loc[lambda x: x['year']==2012]
"find all the stage positions of the musicians with first name ""solveig""","pd.merge(performance, band, left_on='bandmate', right_on='id').loc[lambda x: x['firstname']=='solveig', 'stageposition'].unique()"
"what are the different stage positions for all musicians whose first name is ""solveig""?","pd.merge(performance, band, left_on='bandmate', right_on='id').loc[lambda x: x['firstname']=='solveig', 'stageposition'].unique()"
how many songs are there?,songs.shape[0]
count the number of songs.,songs.shape[0]
"find all the songs performed by artist with last name ""heilo""","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['lastname'] == 'heilo', 'title']"
"what are the names of the songs by the artist whose last name is ""heilo""?","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['lastname'] == 'heilo', 'title']"
"hom many musicians performed in the song ""flash""?","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['title']=='flash'].shape[0]"
"how many musicians play in the song ""flash""?","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['title']=='flash'].shape[0]"
"find all the songs produced by artists with first name ""marianne"".","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['firstname']=='marianne', 'title']"
"what are the names of all songs produced by the artist with the first name ""marianne""?","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['firstname']=='marianne', 'title']"
"who performed the song named ""badlands""? show the first name and the last name.","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['title']=='badlands', ['firstname', 'lastname']]"
"what are the first and last names of the artist who perfomed the song ""badlands""?","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['title']=='badlands', ['firstname', 'lastname']]"
"who is performing in the back stage position for the song ""badlands""? show the first name and the last name.","pd.merge(pd.merge(performance.loc[lambda x: x['stageposition']=='back'], band, left_on='bandmate', right_on='id'), songs.loc[lambda x: x['title']=='badlands'], left_on='songid', right_on='songid')[['firstname', 'lastname']]"
"what are the first and last names of the performer who was in the back stage position for the song ""badlands""?","pd.merge(pd.merge(performance.loc[lambda x: x['stageposition']=='back'], band, left_on='bandmate', right_on='id'), songs.loc[lambda x: x['title']=='badlands'], left_on='songid', right_on='songid')[['firstname', 'lastname']]"
how many unique labels are there for albums?,albums['label'].nunique()
what are the unique labels for the albums?,albums['label'].nunique()
what is the label that has the most albums?,albums.groupby('label').size().sort_values(ascending=false).index[0]
what is the label with the most albums?,albums.groupby('label').size().sort_values(ascending=false).index[0]
what is the last name of the musician that have produced the most number of songs?,"pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').groupby('lastname').size().sort_values(ascending=false).index[0]"
what is the last name of the musician who was in the most songs?,"pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').groupby('lastname').size().sort_values(ascending=false).index[0]"
what is the last name of the musician that has been at the back position the most?,"performance.merge(band, left_on='bandmate', right_on='id').loc[lambda x: x['stageposition']=='back'].groupby('lastname').size().sort_values(ascending=false).index[0]"
what is the last name of the musicians who has played back position the most?,"performance.merge(band, left_on='bandmate', right_on='id').loc[lambda x: x['stageposition']=='back'].groupby('lastname').size().sort_values(ascending=false).index[0]"
"find all the songs whose name contains the word ""the"".","songs.loc[songs['title'].str.contains(' the '), 'title']"
"what are the names of the songs whose title has the word ""the""?","songs.loc[songs['title'].str.contains(' the '), 'title']"
what are all the instruments used?,instruments['instrument'].unique()
what are the different instruments listed in the database?,instruments['instrument'].unique()
"what instrument did the musician with last name ""heilo"" use in the song ""le pop""?","pd.merge(pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid'), instruments, left_on=['songid', 'id'], right_on=['songid', 'bandmateid']).loc[(lambda x: (x['lastname'] == ""heilo"") & (x['title'] == ""le pop"")), 'instrument']"
"what instruments did the musician with the last name ""heilo"" play in the song ""le pop""?","pd.merge(pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid'), instruments, left_on=['songid', 'id'], right_on=['songid', 'bandmateid']).loc[(lambda x: (x['lastname'] == ""heilo"") & (x['title'] == ""le pop"")), 'instrument']"
what is the most used instrument?,instruments.groupby('instrument').size().sort_values(ascending=false).index[0]
what instrument is used the most?,instruments.groupby('instrument').size().sort_values(ascending=false).index[0]
"how many songs have used the instrument ""drums""?",(instruments['instrument'] == 'drums').sum()
how many songs use drums as an instrument?,(instruments['instrument'] == 'drums').sum()
"what instruments does the the song ""le pop"" use?","pd.merge(instruments, songs, on='songid').loc[lambda x: x['title']=='le pop', 'instrument']"
"what are the instruments are used in the song ""le pop""?","pd.merge(instruments, songs, on='songid').loc[lambda x: x['title']=='le pop', 'instrument']"
"how many instruments does the song ""le pop"" use?","pd.merge(instruments, songs, on='songid').loc[lambda x: x['title']=='le pop', 'instrument'].nunique()"
"how many different instruments are used in the song ""le pop""?","pd.merge(instruments, songs, on='songid').loc[lambda x: x['title']=='le pop', 'instrument'].nunique()"
"how many instrument does the musician with last name ""heilo"" use?","instruments.merge(band, left_on='bandmateid', right_on='id').loc[lambda x: x['lastname']=='heilo', 'instrument'].nunique()"
"how many different instruments does the musician with the last name ""heilo"" use?","instruments.merge(band, left_on='bandmateid', right_on='id').loc[lambda x: x['lastname']=='heilo', 'instrument'].nunique()"
"find all the instruments ever used by the musician with last name ""heilo""?","pd.merge(instruments, band, left_on='bandmateid', right_on='id').loc[lambda x: x['lastname']=='heilo', 'instrument']"
"what are all the instruments used by the musician with the last name ""heilo""?","pd.merge(instruments, band, left_on='bandmateid', right_on='id').loc[lambda x: x['lastname']=='heilo', 'instrument']"
which song has the most vocals?,"pd.merge(vocals, songs, on='songid').groupby('songid')['title'].count().nlargest(1).index.values[0]"
what is the song with the most vocals?,"pd.merge(vocals, songs, on='songid').groupby('songid')['title'].count().nlargest(1).index.values[0]"
which vocal type is the most frequently appearring type?,vocals.groupby('type').size().sort_values(ascending=false).index[0]
what is the type of vocables that appears most frequently?,vocals.groupby('type').size().sort_values(ascending=false).index[0]
"which vocal type has the band mate with last name ""heilo"" played the most?","pd.merge(vocals, band, left_on='bandmate', right_on='id').loc[lambda x: x['lastname']=='heilo'].groupby('type').size().sort_values(ascending=false).index[0]"
"what is the type of vocals that the band member with the last name ""heilo"" played the most?","pd.merge(vocals, band, left_on='bandmate', right_on='id').loc[lambda x: x['lastname']=='heilo'].groupby('type').size().sort_values(ascending=false).index[0]"
"what are the vocal types used in song ""le pop""?","pd.merge(vocals, songs, on='songid').loc[lambda x: x['title']=='le pop', 'type']"
"what are the types of vocals used in the song ""le pop""?","pd.merge(vocals, songs, on='songid').loc[lambda x: x['title']=='le pop', 'type']"
"find the number of vocal types used in song ""demon kitty rag""?","pd.merge(vocals, songs, on='songid').loc[lambda x: x['title'] == 'demon kitty rag'].shape[0]"
"what are the types of vocals used in the song ""demon kitty rag""?","pd.merge(vocals, songs, on='songid').loc[lambda x: x['title'] == 'demon kitty rag'].shape[0]"
how many songs have a lead vocal?,"vocals.merge(songs, on='songid').loc[lambda x: x['type']=='lead', 'title'].nunique()"
how many songs have vocals of type lead?,"vocals.merge(songs, on='songid').loc[lambda x: x['type']=='lead', 'title'].nunique()"
"which vocal type did the musician with first name ""solveig"" played in the song with title ""a bar in amsterdam""?","pd.merge(pd.merge(vocals, songs, on='songid'), band, left_on='bandmate', right_on='id').loc[(lambda x: x['firstname']=='solveig') & (lambda x: x['title']=='a bar in amsterdam'), 'type']"
"what are the types of vocals that the musician with the first name ""solveig"" played in the song ""a bar in amsterdam""?","pd.merge(pd.merge(vocals, songs, on='songid'), band, left_on='bandmate', right_on='id').loc[(lambda x: x['firstname']=='solveig') & (lambda x: x['title']=='a bar in amsterdam'), 'type']"
find all the songs that do not have a lead vocal.,"pd.merge(vocals, songs, on='songid')['title'].drop_duplicates().subtract(pd.merge(vocals[vocals['type']=='lead'], songs, on='songid')['title']).dropna()"
what are the names of the songs without a lead vocal?,"pd.merge(vocals, songs, on='songid')['title'].drop_duplicates().subtract(pd.merge(vocals[vocals['type']=='lead'], songs, on='songid')['title']).dropna()"
find all the vocal types.,vocals['type'].unique()
what are the different types of vocals?,vocals['type'].unique()
what are the albums produced in year 2010?,"albums.loc[lambda x: x['year']==2010, :]"
what information is there on albums from 2010?,"albums.loc[lambda x: x['year']==2010, :]"
"who performed the song named ""le pop""?","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['title']=='le pop', ['firstname', 'lastname']]"
"what is the first and last name of artist who performed ""le pop""?","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['title']=='le pop', ['firstname', 'lastname']]"
what is the last name of the musician that have produced the most songs?,"pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').groupby('lastname').size().sort_values(ascending=false).index[0]"
what is the last name of the artist who sang the most songs?,"pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').groupby('lastname').size().sort_values(ascending=false).index[0]"
"what instrument did the musician with last name ""heilo"" use in the song ""badlands""?","pd.merge(pd.merge(pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'),songs,left_on='songid',right_on='songid'),instruments,on=['songid', 'bandmateid']).loc[(lambda x: x['lastname']=='heilo')(band) & (lambda x: x['title']=='badlands')(songs)],on='instrument')['instrument']"
"what instruments did the musician with the last name ""heilo"" play in ""badlands""?","pd.merge(pd.merge(pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'),songs,left_on='songid',right_on='songid'),instruments,on=['songid', 'bandmateid']).loc[(lambda x: x['lastname']=='heilo')(band) & (lambda x: x['title']=='badlands')(songs)],on='instrument')['instrument']"
"how many instruments does the song ""badlands"" use?","pd.merge(instruments, songs, on='songid').loc[lambda x: x['title']=='badlands', 'instrument'].nunique()"
"how many different instruments are used in the song ""badlands""?","pd.merge(instruments, songs, on='songid').loc[lambda x: x['title']=='badlands', 'instrument'].nunique()"
"what are the vocal types used in song ""badlands""?","pd.merge(vocals, songs, on='songid').loc[lambda x: x['title']=='badlands', 'type']"
"what types of vocals are used in the song ""badlands""?","pd.merge(vocals, songs, on='songid').loc[lambda x: x['title']=='badlands', 'type']"
"find the number of vocal types used in song ""le pop""","pd.merge(vocals, songs, on='songid').loc[lambda x: x['title']=='le pop'].shape[0]"
"how many vocal types are used in the song ""le pop""?","pd.merge(vocals, songs, on='songid').loc[lambda x: x['title']=='le pop'].shape[0]"
how many songs have a shared vocal?,"pd.merge(vocals, songs, on='songid').loc[lambda x: x['type']=='shared', 'title'].nunique()"
how many different songs have shared vocals?,"pd.merge(vocals, songs, on='songid').loc[lambda x: x['type']=='shared', 'title'].nunique()"
find all the songs that do not have a back vocal.,"pd.merge(vocals, songs, on='songid', how='inner').loc[lambda x: x['type']!='back', 'title'].drop_duplicates()"
what are the different names of all songs without back vocals?,"pd.merge(vocals, songs, on='songid', how='inner').loc[lambda x: x['type']!='back', 'title'].drop_duplicates()"
"which vocal type has the band mate with first name ""solveig"" played the most?","pd.merge(vocals, band, left_on='bandmate', right_on='id').query('firstname == ""solveig""').groupby('type').size().sort_values(ascending=false).head(1).index[0]"
"what are the types of vocals that the band member with the first name ""solveig"" played the most?","pd.merge(vocals, band, left_on='bandmate', right_on='id').query('firstname == ""solveig""').groupby('type').size().sort_values(ascending=false).head(1).index[0]"
"which vocal type did the musician with last name ""heilo"" played in the song with title ""der kapitan""?","pd.merge(pd.merge(vocals, songs, on='songid'), band, left_on='bandmate', right_on='id').loc[lambda x: (x['lastname'] == 'heilo') & (x['title'] == 'der kapitan'), 'type']"
"what are the types of vocals that the musician with the last name ""heilo"" played in ""der kapitan""?","pd.merge(pd.merge(vocals, songs, on='songid'), band, left_on='bandmate', right_on='id').loc[lambda x: (x['lastname'] == 'heilo') & (x['title'] == 'der kapitan'), 'type']"
find the first name of the band mate that has performed in most songs.,"pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, left_on='songid', right_on='songid').groupby('firstname').size().sort_values(ascending=false).index[0]"
what is the first name of the band mate who perfomed in the most songs?,"pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, left_on='songid', right_on='songid').groupby('firstname').size().sort_values(ascending=false).index[0]"
"which vocal type has the band mate with first name ""marianne"" played the most?","vocals.merge(band, left_on='bandmate', right_on='id').query('firstname==""marianne""').groupby('type').size().sort_values(ascending=false).index[0]"
"what is the vocal type of the band mate whose first name is ""marianne"" played the most?","vocals.merge(band, left_on='bandmate', right_on='id').query('firstname==""marianne""').groupby('type').size().sort_values(ascending=false).index[0]"
"who is performing in the back stage position for the song ""der kapitan""? show the first name and last name.","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[(lambda x: x['title']=='der kapitan') & (lambda x: x['stageposition']=='back'), ['firstname', 'lastname']]"
"what is the first and last name of the artist who performed back stage for the song ""der kapitan""?","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[(lambda x: x['title']=='der kapitan') & (lambda x: x['stageposition']=='back'), ['firstname', 'lastname']]"
find the name of songs that does not have a back vocal.,"pd.merge(vocals, songs, on='songid', how='inner').loc[lambda x: x['type']!='back', 'title'].drop_duplicates()"
what are the names of the songs that do not have back vocals?,"pd.merge(vocals, songs, on='songid', how='inner').loc[lambda x: x['type']!='back', 'title'].drop_duplicates()"
"what are the songs in album ""a kiss before you go: live in hamburg""?","pd.merge(pd.merge(albums, tracklists, left_on='aid', right_on='albumid'), songs, on='songid').loc[lambda x: x['title_x'] == 'a kiss before you go: live in hamburg', 'title_y']"
"what are the song titles on the album ""a kiss before you go: live in hamburg""?","pd.merge(pd.merge(albums, tracklists, left_on='aid', right_on='albumid'), songs, on='songid').loc[lambda x: x['title_x'] == 'a kiss before you go: live in hamburg', 'title_y']"
"what are all the songs in albums under label ""universal music group""?","albums.merge(tracklists, left_on='aid', right_on='albumid').merge(songs, on='songid').loc[lambda x: x['label']=='universal music group', 'title']"
"what are the names of all the songs whose album is under the label of ""universal music group""?","albums.merge(tracklists, left_on='aid', right_on='albumid').merge(songs, on='songid').loc[lambda x: x['label']=='universal music group', 'title']"
find the number of songs in all the studio albums.,"pd.merge(pd.merge(albums.loc[lambda x: x['type']=='studio'], tracklists, left_on='aid', right_on='albumid'), songs, on='songid')['title'].nunique()"
how many songs appear in studio albums?,"pd.merge(pd.merge(albums.loc[lambda x: x['type']=='studio'], tracklists, left_on='aid', right_on='albumid'), songs, on='songid')['title'].nunique()"
who is the founder of sony?,"manufacturers.loc[lambda x: x['name']=='sony', 'founder']"
return the founder of sony.,"manufacturers.loc[lambda x: x['name']=='sony', 'founder']"
where is the headquarter of the company founded by james?,"manufacturers.loc[lambda x: x['founder']=='james', 'headquarter']"
what is the headquarter of the company whose founder is james?,"manufacturers.loc[lambda x: x['founder']=='james', 'headquarter']"
"find all manufacturers' names and their headquarters, sorted by the ones with highest revenue first.","manufacturers[['name', 'headquarter']].sort_values('revenue', ascending=false)"
"what are the names and headquarters of all manufacturers, ordered by revenue descending?","manufacturers[['name', 'headquarter']].sort_values('revenue', ascending=false)"
"what are the average, maximum and total revenues of all companies?","manufacturers['revenue'].agg(['mean', 'max', 'sum'])"
"return the average, maximum, and total revenues across all manufacturers.","manufacturers['revenue'].agg(['mean', 'max', 'sum'])"
how many companies were created by andy?,(manufacturers['founder'] == 'andy').sum()
return the number of companies created by andy.,(manufacturers['founder'] == 'andy').sum()
find the total revenue created by the companies whose headquarter is located at austin.,"manufacturers.loc[manufacturers['headquarter']=='austin', 'revenue'].sum()"
what is the sum of revenue from companies with headquarters in austin?,"manufacturers.loc[manufacturers['headquarter']=='austin', 'revenue'].sum()"
what are the different cities listed?,manufacturers['headquarter'].unique()
give the distinct headquarters of manufacturers.,manufacturers['headquarter'].unique()
find the number of manufactures that are based in tokyo or beijing.,"manufacturer.loc[lambda x: x['headquarter'].isin(['tokyo', 'beijing'])].shape[0]"
how many manufacturers have headquarters in either tokyo or beijing?,"manufacturer.loc[lambda x: x['headquarter'].isin(['tokyo', 'beijing'])].shape[0]"
find the founder of the company whose name begins with the letter 's'.,"manufacturers.loc[manufacturers['name'].str.startswith('s'), 'founder']"
who is the founders of companies whose first letter is s?,"manufacturers.loc[manufacturers['name'].str.startswith('s'), 'founder']"
find the name of companies whose revenue is between 100 and 150.,"manufacturers.loc[(manufacturers['revenue'] >= 100) & (manufacturers['revenue'] <= 150), 'name']"
what are the names of companies with revenue between 100 and 150?,"manufacturers.loc[(manufacturers['revenue'] >= 100) & (manufacturers['revenue'] <= 150), 'name']"
what is the total revenue of all companies whose main office is at tokyo or taiwan?,"manufacturers.loc[manufacturers['headquarter'].isin(['tokyo','taiwan']), 'revenue'].sum()"
return the total revenue of companies with headquarters in tokyo or taiwan.,"manufacturers.loc[manufacturers['headquarter'].isin(['tokyo','taiwan']), 'revenue'].sum()"
find the name of product that is produced by both companies creative labs and sony.,"products.loc[lambda x: x['manufacturer'].isin(manufacturers.loc[manufacturers['name']=='creative labs', 'code'])]['name'].intersect(products.loc[lambda x: x['manufacturer'].isin(manufacturers.loc[manufacturers['name']=='sony', 'code'])]['name'])"
what are the names of products produced by both creative labs and sony?,"products.loc[lambda x: x['manufacturer'].isin(manufacturers.loc[manufacturers['name']=='creative labs', 'code'])]['name'].intersect(products.loc[lambda x: x['manufacturer'].isin(manufacturers.loc[manufacturers['name']=='sony', 'code'])]['name'])"
"find the name, headquarter and founder of the manufacturer that has the highest revenue.","manufacturers.sort_values('revenue', ascending=false).iloc[0][['name', 'headquarter', 'founder']]"
"what are the names, headquarters and founders of the company with the highest revenue?","manufacturers.sort_values('revenue', ascending=false).iloc[0][['name', 'headquarter', 'founder']]"
"find the name, headquarter and revenue of all manufacturers sorted by their revenue in the descending order.","manufacturers[['name', 'headquarter', 'revenue']].sort_values('revenue', ascending=false)"
"what are the names, headquarters and revenues for manufacturers, sorted by revenue descending?","manufacturers[['name', 'headquarter', 'revenue']].sort_values('revenue', ascending=false)"
find the name of companies whose revenue is greater than the average revenue of all companies.,"manufacturers.loc[manufacturers['revenue'] > manufacturers['revenue'].mean(), 'name']"
what are the names of manufacturers with revenue greater than the average of all revenues?,"manufacturers.loc[manufacturers['revenue'] > manufacturers['revenue'].mean(), 'name']"
find the name of companies whose revenue is smaller than the revenue of all companies based in austin.,"manufacturers.loc[lambda x: x['revenue']<manufacturers.loc[lambda x: x['headquarter']=='austin', 'revenue'].min(), 'name']"
what are the names of companies with revenue less than the lowest revenue of any manufacturer in austin?,"manufacturers.loc[lambda x: x['revenue']<manufacturers.loc[lambda x: x['headquarter']=='austin', 'revenue'].min(), 'name']"
find the total revenue of companies whose revenue is larger than the revenue of some companies based in austin.,"manufacturers.loc[lambda x: x['revenue'] > manufacturers.loc[lambda y: y['headquarter']=='austin', 'revenue'].min(), 'revenue'].sum()"
what is the total revenue of companies with revenue greater than the lowest revenue of any manufacturer in austin?,"manufacturers.loc[lambda x: x['revenue'] > manufacturers.loc[lambda y: y['headquarter']=='austin', 'revenue'].min(), 'revenue'].sum()"
find the total revenue of companies of each founder.,manufacturers.groupby('founder')['revenue'].sum()
what is the total revenue of companies started by founder?,manufacturers.groupby('founder')['revenue'].sum()
find the name and revenue of the company that earns the highest revenue in each city.,"manufacturers.groupby('headquarter').agg({'name': 'first', 'revenue': 'max', 'headquarter': 'first'})[['name', 'revenue', 'headquarter']]"
what are the names and revenues of the companies with the highest revenues in each headquarter city?,"manufacturers.groupby('headquarter').agg({'name': 'first', 'revenue': 'max', 'headquarter': 'first'})[['name', 'revenue', 'headquarter']]"
find the total revenue for each manufacturer.,manufacturers.groupby('name')['revenue'].sum()
what is the total revenue of each manufacturer?,manufacturers.groupby('name')['revenue'].sum()
"find the average prices of all products from each manufacture, and list each company's name.","pd.merge(products, manufacturers, left_on='manufacturer', right_on='code').groupby('name').agg({'price': 'mean'})"
what are the average prices of products for each manufacturer?,"pd.merge(products, manufacturers, left_on='manufacturer', right_on='code').groupby('name').agg({'price': 'mean'})"
find the number of different products that are produced by companies at different headquarter cities.,"pd.merge(products, manufacturers, left_on='manufacturer', right_on='code').groupby('headquarter')['name'].nunique()"
how many different products are produced in each headquarter city?,"pd.merge(products, manufacturers, left_on='manufacturer', right_on='code').groupby('headquarter')['name'].nunique()"
find number of products which sony does not make.,"products.loc[~products['name'].isin(products.merge(manufacturers.loc[manufacturers['name']=='sony', 'code'], how='inner', left_on='manufacturer', right_on='code', suffixes=['', '_sony'])['name']), 'name'].nunique()"
how many products are not made by sony?,"products.loc[~products['name'].isin(products.merge(manufacturers.loc[manufacturers['name']=='sony', 'code'], how='inner', left_on='manufacturer', right_on='code', suffixes=['', '_sony'])['name']), 'name'].nunique()"
find the name of companies that do not make dvd drive.,"manufacturers.loc[~manufacturers['name'].isin(pd.merge(products.loc[products['name']=='dvd drive', 'manufacturer'], manufacturers, left_on='manufacturer', right_on='code')['name_y'])]['name']"
what are the names of companies that do not make dvd drives?,"manufacturers.loc[~manufacturers['name'].isin(pd.merge(products.loc[products['name']=='dvd drive', 'manufacturer'], manufacturers, left_on='manufacturer', right_on='code')['name_y'])]['name']"
"find the number of products for each manufacturer, showing the name of each company.","pd.merge(products, manufacturers, left_on='manufacturer', right_on='code').groupby('name').size().reset_index(name='count')"
how many products are there for each manufacturer?,"pd.merge(products, manufacturers, left_on='manufacturer', right_on='code').groupby('name').size().reset_index(name='count')"
select the names of all the products in the store.,products['name']
what are the names of all products?,products['name']
select the names and the prices of all the products in the store.,"products[['name', 'price']]"
what are the names and prices of all products in the store?,"products[['name', 'price']]"
select the name of the products with a price less than or equal to $200.,"products.loc[lambda x: x['price']<=200, 'name']"
what are the names of products with price at most 200?,"products.loc[lambda x: x['price']<=200, 'name']"
find all information of all the products with a price between $60 and $120.,products[(products['price'] >= 60) & (products['price'] <= 120)]
what is all the information of all the products that have a price between 60 and 120?,products[(products['price'] >= 60) & (products['price'] <= 120)]
compute the average price of all the products.,products['price'].mean()
what is the average price across all products?,products['price'].mean()
compute the average price of all products with manufacturer code equal to 2.,"products.loc[lambda x: x['manufacturer']==2, 'price'].mean()"
what is the average price of products with manufacturer codes equal to 2?,"products.loc[lambda x: x['manufacturer']==2, 'price'].mean()"
compute the number of products with a price larger than or equal to $180.,(products['price'] >= 180).sum()
how many products have prices of at least 180?,(products['price'] >= 180).sum()
"what are the names and prices of products that cost at least 180, sorted by price decreasing and name ascending?","products.loc[lambda x: x['price'] >= 180].sort_values(['price', 'name'], ascending=[false, true])[['name', 'price']]"
select all the data from the products and each product's manufacturer.,"pd.merge(products, manufacturers, left_on='manufacturer', right_on='code')"
"what is all the product data, as well as  each product's manufacturer?","pd.merge(products, manufacturers, left_on='manufacturer', right_on='code')"
"select the average price of each manufacturer's products, showing only the manufacturer's code.",products.groupby('manufacturer')['price'].mean()
"what are the average prices of products, grouped by manufacturer code?",products.groupby('manufacturer')['price'].mean()
"select the average price of each manufacturer's products, showing the manufacturer's name.","products.merge(manufacturers, left_on='manufacturer', right_on='code').groupby('name')['price'].mean()"
"what are the average prices of products, grouped by manufacturer name?","products.merge(manufacturers, left_on='manufacturer', right_on='code').groupby('name')['price'].mean()"
select the names of manufacturer whose products have an average price higher than or equal to $150.,"products.merge(manufacturers, left_on='manufacturer', right_on='code').groupby('name').filter(lambda x: x['price'].mean() >= 150).groupby('name').agg(avg_price=('price', 'mean'))"
what are the names and average prices of products for manufacturers whose products cost on average 150 or more?,"products.merge(manufacturers, left_on='manufacturer', right_on='code').groupby('name').filter(lambda x: x['price'].mean() >= 150).groupby('name').agg(avg_price=('price', 'mean'))"
select the name and price of the cheapest product.,"products[['name', 'price']].sort_values('price').head(1)"
what is the name and price of the cheapest product?,"products[['name', 'price']].sort_values('price').head(1)"
select the name of each manufacturer along with the name and price of its most expensive product.,"products.merge(manufacturers, left_on='manufacturer', right_on='code').groupby('name_y').agg({'name': 'max', 'price': 'max'})"
"for each manufacturer name, what are the names and prices of their most expensive product?","products.merge(manufacturers, left_on='manufacturer', right_on='code').groupby('name_y').agg({'name': 'max', 'price': 'max'})"
select the code of the product that is cheapest in each product category.,"products.groupby('name').agg({'code':'first', 'price':'min'}).reset_index()[['code','name','price']]"
what are the codes and names of the cheapest products in each category?,"products.groupby('name').agg({'code':'first', 'price':'min'}).reset_index()[['code','name','price']]"
what is the id of the problem log that is created most recently?,"problem_log.sort_values('log_entry_date', ascending=false).iloc[0]['problem_log_id']"
which problem log was created most recently? give me the log id.,"problem_log.sort_values('log_entry_date', ascending=false).iloc[0]['problem_log_id']"
what is the oldest log id and its corresponding problem id?,"problem_log[['problem_log_id', 'problem_id']].sort_values('log_entry_date').head(1)"
find the oldest log id and its corresponding problem id.,"problem_log[['problem_log_id', 'problem_id']].sort_values('log_entry_date').head(1)"
find all the ids and dates of the logs for the problem whose id is 10.,"problem_log.loc[problem_log['problem_id'] == 10, ['problem_log_id', 'log_entry_date']]"
"for the problem with id 10, return the ids and dates of its problem logs.","problem_log.loc[problem_log['problem_id'] == 10, ['problem_log_id', 'log_entry_date']]"
list all the log ids and their descriptions from the problem logs.,"problem_log[['problem_log_id', 'log_entry_description']]"
what are the log id and entry description of each problem?,"problem_log[['problem_log_id', 'log_entry_description']]"
list the first and last names of all distinct staff members who are assigned to the problem whose id is 1.,"pd.merge(staff, problem_log[problem_log['problem_id']==1], left_on='staff_id', right_on='assigned_to_staff_id')[['staff_first_name', 'staff_last_name']].drop_duplicates()"
which staff members are assigned to the problem with id 1? give me their first and last names.,"pd.merge(staff, problem_log[problem_log['problem_id']==1], left_on='staff_id', right_on='assigned_to_staff_id')[['staff_first_name', 'staff_last_name']].drop_duplicates()"
list the problem id and log id which are assigned to the staff named rylan homenick.,"pd.merge(staff.loc[(staff['staff_first_name']=='rylan')&(staff['staff_last_name']=='homenick'), ['staff_id']], problem_log, left_on='staff_id', right_on='assigned_to_staff_id')[['problem_id', 'problem_log_id']].drop_duplicates()"
which problem id and log id are assigned to the staff named rylan homenick?,"pd.merge(staff.loc[(staff['staff_first_name']=='rylan')&(staff['staff_last_name']=='homenick'), ['staff_id']], problem_log, left_on='staff_id', right_on='assigned_to_staff_id')[['problem_id', 'problem_log_id']].drop_duplicates()"
how many problems are there for product voluptatem?,"pd.merge(product.loc[lambda x: x['product_name']=='voluptatem'], problems, on='product_id').shape[0]"
"how many problems did the product called ""voluptatem"" have in record?","pd.merge(product.loc[lambda x: x['product_name']=='voluptatem'], problems, on='product_id').shape[0]"
how many problems does the product with the most problems have? list the number of the problems and product name.,"pd.merge(product, problems, on='product_id').groupby('product_name').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
which product has the most problems? give me the number of problems and the product name.,"pd.merge(product, problems, on='product_id').groupby('product_name').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
give me a list of descriptions of the problems that are reported by the staff whose first name is christop.,"problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id').loc[lambda x: x['staff_first_name']=='christop', 'problem_description']"
"which problems are reported by the staff with first name ""christop""? show the descriptions of the problems.","problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id').loc[lambda x: x['staff_first_name']=='christop', 'problem_description']"
find the ids of the problems that are reported by the staff whose last name is bosco.,"pd.merge(problems, staff, left_on='reported_by_staff_id', right_on='staff_id').loc[lambda x: x['staff_last_name']=='bosco', 'problem_id']"
"which problems are reported by the staff with last name ""bosco""? show the ids of the problems.","pd.merge(problems, staff, left_on='reported_by_staff_id', right_on='staff_id').loc[lambda x: x['staff_last_name']=='bosco', 'problem_id']"
what are the ids of the problems which are reported after 1978-06-26?,"problems.loc[lambda x: x['date_problem_reported'] > '1978-06-26', 'problem_id']"
find the ids of the problems reported after 1978-06-26.,"problems.loc[lambda x: x['date_problem_reported'] > '1978-06-26', 'problem_id']"
what are the ids of the problems which are reported before 1978-06-26?,"problems.loc[lambda x: x['date_problem_reported'] < ""1978-06-26"", 'problem_id']"
which problems are reported before 1978-06-26? give me the ids of the problems.,"problems.loc[lambda x: x['date_problem_reported'] < ""1978-06-26"", 'problem_id']"
"for each product which has problems, what are the number of problems and the product id?","problems.merge(product, on='product_id').groupby('product_id').size().reset_index(name='count')"
"for each product with some problems, list the count of problems and the product id.","problems.merge(product, on='product_id').groupby('product_id').size().reset_index(name='count')"
"for each product that has problems, find the number of problems reported after 1986-11-13 and the product id?","(pd.merge(problems, product, on='product_id').loc[lambda x: x['date_problem_reported'] > ""1986-11-13""].groupby('product_id').size().reset_index(name='count(*)'))"
what are the products that have problems reported after 1986-11-13? give me the product id and the count of problems reported after 1986-11-13.,"(pd.merge(problems, product, on='product_id').loc[lambda x: x['date_problem_reported'] > ""1986-11-13""].groupby('product_id').size().reset_index(name='count(*)'))"
list the names of all the distinct product names in alphabetical order?,product['product_name'].sort_values().unique()
sort all the distinct product names in alphabetical order.,product['product_name'].sort_values().unique()
list all the distinct product names ordered by product id?,product.sort_values('product_id')['product_name'].unique()
what is the list of distinct product names sorted by product id?,product.sort_values('product_id')['product_name'].unique()
what are the id of problems reported by the staff named dameon frami or jolie weber?,"pd.concat([problems.merge(staff.loc[(staff['staff_first_name']=='dameon')&(staff['staff_last_name']=='frami')], left_on='reported_by_staff_id', right_on='staff_id')['product_id'],problems.merge(staff.loc[(staff['staff_first_name']=='jolie')&(staff['staff_last_name']=='weber')], left_on='reported_by_staff_id', right_on='staff_id')['product_id']]).drop_duplicates()"
which problems were reported by the staff named dameon frami or jolie weber? give me the ids of the problems.,"pd.concat([problems.merge(staff.loc[(staff['staff_first_name']=='dameon')&(staff['staff_last_name']=='frami')], left_on='reported_by_staff_id', right_on='staff_id')['product_id'],problems.merge(staff.loc[(staff['staff_first_name']=='jolie')&(staff['staff_last_name']=='weber')], left_on='reported_by_staff_id', right_on='staff_id')['product_id']]).drop_duplicates()"
what are the product ids for the problems reported by christop berge with closure authorised by ashley medhurst?,"pd.merge(problems.loc[lambda x: x['reported_by_staff_id'].isin(staff.loc[(staff['staff_first_name']=='christop') & (staff['staff_last_name']=='berge'), 'staff_id'])],problems.loc[lambda x: x['closure_authorised_by_staff_id'].isin(staff.loc[(staff['staff_first_name']=='ashley') & (staff['staff_last_name']=='medhurst'), 'staff_id'])])['product_id']"
"for which product was there a problem reported by christop berge, with closure authorised by ashley medhurst? return the product ids.","pd.merge(problems.loc[lambda x: x['reported_by_staff_id'].isin(staff.loc[(staff['staff_first_name']=='christop') & (staff['staff_last_name']=='berge'), 'staff_id'])],problems.loc[lambda x: x['closure_authorised_by_staff_id'].isin(staff.loc[(staff['staff_first_name']=='ashley') & (staff['staff_last_name']=='medhurst'), 'staff_id'])])['product_id']"
what are the ids of the problems reported before the date of any problem reported by lysanne turcotte?,"problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id').loc[lambda x: x['date_problem_reported'] < problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id').loc[lambda y: (y['staff_first_name']=='lysanne')&(y['staff_last_name']=='turcotte'), 'date_problem_reported'].min(), 'problem_id']"
which problems were reported before the date of any problem reported by the staff lysanne turcotte? give me the ids of the problems.,"problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id').loc[lambda x: x['date_problem_reported'] < problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id').loc[lambda y: (y['staff_first_name']=='lysanne')&(y['staff_last_name']=='turcotte'), 'date_problem_reported'].min(), 'problem_id']"
what are the ids of the problems reported after the date of any problems reported by rylan homenick?,"problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id')[lambda x: x['date_problem_reported'] > problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id')[lambda y: (y['staff_first_name'] == 'rylan') & (y['staff_last_name'] == 'homenick')]['date_problem_reported'].max()]['problem_id']"
find the ids of the problems reported after the date of any problems reported by the staff rylan homenick.,"problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id')[lambda x: x['date_problem_reported'] > problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id')[lambda y: (y['staff_first_name'] == 'rylan') & (y['staff_last_name'] == 'homenick')]['date_problem_reported'].max()]['problem_id']"
find the top 3 products which have the largest number of problems?,"(pd.merge(problems, product, on='product_id').groupby('product_name').size().sort_values(ascending=false).head(3).reset_index())['product_name']"
what are the three products that have the most problems?s,"(pd.merge(problems, product, on='product_id').groupby('product_name').size().sort_values(ascending=false).head(3).reset_index())['product_name']"
"list the ids of the problems from the product ""voluptatem"" that are reported after 1995?","problems.merge(product, on='product_id').loc[lambda x: (x['product_name']=='voluptatem') & (x['date_problem_reported'] > '1995'), 'problem_id']"
"what are the ids of the problems that are from the product ""voluptatem"" and are reported after 1995?","problems.merge(product, on='product_id').loc[lambda x: (x['product_name']=='voluptatem') & (x['date_problem_reported'] > '1995'), 'problem_id']"
"find the first and last name of the staff members who reported problems from the product ""rem"" but not ""aut""?","pd.merge(pd.merge(problems, product, on='product_id'), staff, on='staff_id').loc[lambda x: x['product_name']=='rem', ['staff_first_name', 'staff_last_name']].merge(pd.merge(problems, product, on='product_id'), staff, on='staff_id').loc[lambda x: x['product_name']=='aut', ['staff_first_name', 'staff_last_name']].drop_duplicates(subset=['staff_first_name', 'staff_last_name'], keep=false)"
"which staff members who reported problems from the product ""rem"" but not ""aut""? give me their first and last names.","pd.merge(pd.merge(problems, product, on='product_id'), staff, on='staff_id').loc[lambda x: x['product_name']=='rem', ['staff_first_name', 'staff_last_name']].merge(pd.merge(problems, product, on='product_id'), staff, on='staff_id').loc[lambda x: x['product_name']=='aut', ['staff_first_name', 'staff_last_name']].drop_duplicates(subset=['staff_first_name', 'staff_last_name'], keep=false)"
find the products which have problems reported by both lacey bosco and kenton champlin?,"pd.merge(pd.merge(problems, product, on='product_id'), staff, left_on='reported_by_staff_id', right_on='staff_id').loc[(lambda x: x['staff_first_name']=='lacey') & (lambda x: x['staff_last_name']=='bosco'), 'product_name'].intersect(pd.merge(pd.merge(problems, product, on='product_id'), staff, left_on='reported_by_staff_id', right_on='staff_id').loc[(lambda x: x['staff_first_name']=='kenton') & (lambda x: x['staff_last_name']=='champlin'), 'product_name']).tolist()"
which products have problems reported by both the staff named lacey bosco and the staff named kenton champlin?,"pd.merge(pd.merge(problems, product, on='product_id'), staff, left_on='reported_by_staff_id', right_on='staff_id').loc[(lambda x: x['staff_first_name']=='lacey') & (lambda x: x['staff_last_name']=='bosco'), 'product_name'].intersect(pd.merge(pd.merge(problems, product, on='product_id'), staff, left_on='reported_by_staff_id', right_on='staff_id').loc[(lambda x: x['staff_first_name']=='kenton') & (lambda x: x['staff_last_name']=='champlin'), 'product_name']).tolist()"
how many branches where have more than average number of memberships are there?,(branch['membership_amount'] > branch['membership_amount'].mean()).sum()
what is the number of branches that have more than the average number of memberships?,(branch['membership_amount'] > branch['membership_amount'].mean()).sum()
"show name, address road, and city for all branches sorted by open year.","branch[['name', 'address_road', 'city']].sort_values('open_year')"
"what are the names, address roads, and cities of the branches ordered by opening year?","branch[['name', 'address_road', 'city']].sort_values('open_year')"
what are names for top three branches with most number of membership?,"branch.nlargest(3, 'membership_amount')['name']"
what are the names for the 3 branches that have the most memberships?,"branch.nlargest(3, 'membership_amount')['name']"
show all distinct city where branches with at least 100 memberships are located.,"branch.loc[lambda x: x['membership_amount'] >= 100, 'city'].unique()"
what are the different cities that have more than 100 memberships?,"branch.loc[lambda x: x['membership_amount'] >= 100, 'city'].unique()"
list all open years when at least two shops are opened.,branch.groupby('open_year').filter(lambda x: len(x) >= 2)['open_year'].unique()
what are the opening years in which at least two shops opened?,branch.groupby('open_year').filter(lambda x: len(x) >= 2)['open_year'].unique()
show minimum and maximum amount of memberships for all branches opened in 2011 or located at city london.,"branch.loc[(branch['open_year']==2011) | (branch['city']=='london'), 'membership_amount'].agg(['min','max'])"
what are the minimum and maximum membership amounts for all branches that either opened in 2011 or are located in london?,"branch.loc[(branch['open_year']==2011) | (branch['city']=='london'), 'membership_amount'].agg(['min','max'])"
show the city and the number of branches opened before 2010 for each city.,branch.loc[lambda x: x['open_year'] < 2010].groupby('city').size()
"for each city, how many branches opened before 2010?",branch.loc[lambda x: x['open_year'] < 2010].groupby('city').size()
how many different levels do members have?,member['level'].nunique()
what are the different membership levels?,member['level'].nunique()
"show card number, name, and hometown for all members in a descending order of level.","member[['card_number', 'name', 'hometown']].sort_values('level', ascending=false)"
"what are the card numbers, names, and hometowns of every member ordered by descending level?","member[['card_number', 'name', 'hometown']].sort_values('level', ascending=false)"
show the membership level with most number of members.,member.groupby('level').size().sort_values(ascending=false).index[0]
what is the membership level with the most people?,member.groupby('level').size().sort_values(ascending=false).index[0]
show all member names and registered branch names sorted by register year.,"pd.merge(pd.merge(membership_register_branch, branch, on='branch_id'), member, on='member_id').sort_values('register_year')[['name_x', 'name_y']]"
what are the names of the members and branches at which they are registered sorted by year of registration?,"pd.merge(pd.merge(membership_register_branch, branch, on='branch_id'), member, on='member_id').sort_values('register_year')[['name_x', 'name_y']]"
show all branch names with the number of members in each branch registered after 2015.,"membership_register_branch.merge(branch, on='branch_id').loc[lambda x: x['register_year'] > 2015].groupby('name').size()"
"for each branch id, what are the names of the branches that were registered after 2015?","membership_register_branch.merge(branch, on='branch_id').loc[lambda x: x['register_year'] > 2015].groupby('name').size()"
show member names without any registered branch.,"member.loc[~member['member_id'].isin(membership_register_branch['member_id']), 'name']"
what are the names of the members that have never registered at any branch?,"member.loc[~member['member_id'].isin(membership_register_branch['member_id']), 'name']"
list the branch name and city without any registered members.,"branch.loc[~branch['branch_id'].isin(membership_register_branch['branch_id']), ['name', 'city']]"
what are the names and cities of the branches that do not have any registered members?,"branch.loc[~branch['branch_id'].isin(membership_register_branch['branch_id']), ['name', 'city']]"
what is the name and open year for the branch with most number of memberships registered in 2016?,"pd.merge(membership_register_branch[membership_register_branch['register_year']==2016], branch, on='branch_id').groupby(['branch_id', 'name', 'open_year']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'open_year']]"
what is the name and opening year for the branch that registered the most members in 2016?,"pd.merge(membership_register_branch[membership_register_branch['register_year']==2016], branch, on='branch_id').groupby(['branch_id', 'name', 'open_year']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'open_year']]"
show the member name and hometown who registered a branch in 2016.,"pd.merge(membership_register_branch.loc[lambda x: x['register_year']==2016], member, on='member_id')[['name', 'hometown']]"
what are the member names and hometowns of those who registered at a branch in 2016?,"pd.merge(membership_register_branch.loc[lambda x: x['register_year']==2016], member, on='member_id')[['name', 'hometown']]"
show all city with a branch opened in 2001 and a branch with more than 100 membership.,"branch.loc[(branch['open_year'] == 2001) & (branch['membership_amount'] > 100), 'city']"
what are the cities that have a branch that opened in 2001 and a branch with more than 100 members?,"branch.loc[(branch['open_year'] == 2001) & (branch['membership_amount'] > 100), 'city']"
show all cities without a branch having more than 100 memberships.,"branch.loc[lambda x: x['membership_amount'] > 100, 'city'].drop_duplicates(keep=false)"
what are the cities that do not have any branches with more than 100 members?,"branch.loc[lambda x: x['membership_amount'] > 100, 'city'].drop_duplicates(keep=false)"
what is the sum of total pounds of purchase in year 2018 for all branches in london?,"pd.merge(purchase, branch, on='branch_id').loc[lambda x: (x['city']=='london') & (x['year']==2018), 'total_pounds'].sum()"
how many total pounds were purchased in the year 2018 at all london branches?,"pd.merge(purchase, branch, on='branch_id').loc[lambda x: (x['city']=='london') & (x['year']==2018), 'total_pounds'].sum()"
what is the total number of purchases for members with level 6?,"pd.merge(purchase, member, on='member_id').loc[lambda x: x['level']==6, :].shape[0]"
what are the total purchases for members rated at level 6?,"pd.merge(purchase, member, on='member_id').loc[lambda x: x['level']==6, :].shape[0]"
"find the name of branches where have some members whose hometown is in louisville, kentucky and some in hiram, georgia.","branch.loc[pd.merge(pd.merge(membership_register_branch, member.loc[member['hometown']=='louisville ,kentucky'], on='member_id'), branch, on='branch_id')['name'].intersect(pd.merge(pd.merge(membership_register_branch, member.loc[member['hometown']=='hiram ,georgia'], on='member_id'), branch, on='branch_id')['name']).index, 'name']"
"what are the names of the branches that have some members with a hometown in louisville, kentucky and also those from hiram, goergia?","branch.loc[pd.merge(pd.merge(membership_register_branch, member.loc[member['hometown']=='louisville ,kentucky'], on='member_id'), branch, on='branch_id')['name'].intersect(pd.merge(pd.merge(membership_register_branch, member.loc[member['hometown']=='hiram ,georgia'], on='member_id'), branch, on='branch_id')['name']).index, 'name']"
"list the card number of all members whose hometown address includes word ""kentucky"".","member.loc[lambda x: x['hometown'].str.contains('kentucky'), 'card_number']"
what are the card numbers of members from kentucky?,"member.loc[lambda x: x['hometown'].str.contains('kentucky'), 'card_number']"
how many students are there in total?,student.shape[0]
find the number of voting records in total.,voting_record.shape[0]
how many voting records do we have?,voting_record.shape[0]
find the distinct number of president votes.,voting_record['president_vote'].nunique()
how many distinct president votes are recorded?,voting_record['president_vote'].nunique()
find the maximum age of all the students.,student['age'].max()
what is the oldest age among the students?,student['age'].max()
find the last names of students with major 50.,"student.loc[lambda x: x['major'] == 50, 'lname']"
what are the last names of students studying major 50?,"student.loc[lambda x: x['major'] == 50, 'lname']"
find the first names of students with age above 22.,"student.loc[lambda x: x['age']>22, 'fname']"
what are the first names of all the students aged above 22?,"student.loc[lambda x: x['age']>22, 'fname']"
what are the majors of male (sex is m) students?,"student.loc[lambda x: x['sex']=='m', 'major']"
list the major of each male student.,"student.loc[lambda x: x['sex']=='m', 'major']"
what is the average age of female (sex is f) students?,"student.loc[lambda x: x['sex']=='f', 'age'].mean()"
find the average age of female students.,"student.loc[lambda x: x['sex']=='f', 'age'].mean()"
what are the maximum and minimum age of students with major 600?,"student.loc[lambda x: x['major']==600, 'age'].agg(['max', 'min'])"
tell me the ages of the oldest and youngest students studying major 600.,"student.loc[lambda x: x['major']==600, 'age'].agg(['max', 'min'])"
"who are the advisors for students that live in a city with city code ""bal""?","student.loc[lambda x: x['city_code']=='bal', 'advisor']"
"show the advisors of the students whose city of residence has city code ""bal"".","student.loc[lambda x: x['city_code']=='bal', 'advisor']"
what are the distinct secretary votes in the fall election cycle?,"voting_record.loc[lambda x: x['election_cycle']=='fall', 'secretary_vote'].unique()"
return all the distinct secretary votes made in the fall election cycle.,"voting_record.loc[lambda x: x['election_cycle']=='fall', 'secretary_vote'].unique()"
what are the distinct president votes on 08/30/2015?,"voting_record.loc[lambda x: x['registration_date'] == '08/30/2015', 'president_vote'].unique()"
show all the distinct president votes made on 08/30/2015.,"voting_record.loc[lambda x: x['registration_date'] == '08/30/2015', 'president_vote'].unique()"
report the distinct registration date and the election cycle.,"voting_record[['registration_date', 'election_cycle']].drop_duplicates()"
what are the distinct registration dates and the election cycles?,"voting_record[['registration_date', 'election_cycle']].drop_duplicates()"
report the distinct president vote and the vice president vote.,"voting_record[['president_vote', 'vice_president_vote']].drop_duplicates()"
list all the distinct president votes and the vice president votes.,"voting_record[['president_vote', 'vice_president_vote']].drop_duplicates()"
find the distinct last names of the students who have class president votes.,"pd.merge(student, voting_record, left_on='stuid', right_on='class_president_vote')['lname'].unique()"
what are the distinct last names of the students who have class president votes?,"pd.merge(student, voting_record, left_on='stuid', right_on='class_president_vote')['lname'].unique()"
find the distinct first names of the students who have class senator votes.,"pd.merge(student, voting_record, left_on='stuid', right_on='class_senator_vote')['fname'].unique()"
what are the distinct first names of the students who have class president votes?,"pd.merge(student, voting_record, left_on='stuid', right_on='class_senator_vote')['fname'].unique()"
find the distinct ages of students who have secretary votes in the fall election cycle.,"pd.merge(student, voting_record, left_on='stuid', right_on='secretary_vote').loc[lambda x: x['election_cycle']=='fall', 'age'].unique()"
what are the distinct ages of students who have secretary votes in the fall election cycle?,"pd.merge(student, voting_record, left_on='stuid', right_on='secretary_vote').loc[lambda x: x['election_cycle']=='fall', 'age'].unique()"
find the distinct advisor of students who have treasurer votes in the spring election cycle.,"pd.merge(student, voting_record, left_on='stuid', right_on='treasurer_vote').loc[lambda x: x['election_cycle']=='spring', 'advisor'].unique()"
who served as an advisor for students who have treasurer votes in the spring election cycle?,"pd.merge(student, voting_record, left_on='stuid', right_on='treasurer_vote').loc[lambda x: x['election_cycle']=='spring', 'advisor'].unique()"
find the distinct majors of students who have treasurer votes.,"pd.merge(student, voting_record, left_on='stuid', right_on='treasurer_vote')['major'].unique()"
what are the distinct majors that students with treasurer votes are studying?,"pd.merge(student, voting_record, left_on='stuid', right_on='treasurer_vote')['major'].unique()"
find the first and last names of all the female (sex is f) students who have president votes.,"pd.merge(student, voting_record.loc[:, ['president_vote']], left_on='stuid', right_on='president_vote').loc[lambda x: x['sex']=='f', ['fname', 'lname']].drop_duplicates()"
what are the first and last names of all the female students who have president votes?,"pd.merge(student, voting_record.loc[:, ['president_vote']], left_on='stuid', right_on='president_vote').loc[lambda x: x['sex']=='f', ['fname', 'lname']].drop_duplicates()"
find the first and last name of all the students of age 18 who have vice president votes.,"pd.merge(student, voting_record, left_on='stuid', right_on='vice_president_vote').loc[lambda x: x['age']==18, ['fname', 'lname']].drop_duplicates()"
what are the first names and last names of the students who are 18 years old and have vice president votes.,"pd.merge(student, voting_record, left_on='stuid', right_on='vice_president_vote').loc[lambda x: x['age']==18, ['fname', 'lname']].drop_duplicates()"
how many male (sex is m) students have class senator votes in the fall election cycle?,"pd.merge(student, voting_record, left_on='stuid', right_on='class_senator_vote').loc[lambda x: (x['sex']=='m') & (x['election_cycle']=='fall'), :].shape[0]"
count the number of male students who had class senator votes in the fall election cycle.,"pd.merge(student, voting_record, left_on='stuid', right_on='class_senator_vote').loc[lambda x: (x['sex']=='m') & (x['election_cycle']=='fall'), :].shape[0]"
find the number of students whose city code is nyc and who have class senator votes in the spring election cycle.,"pd.merge(student.loc[lambda x: x['city_code']=='nyc'], voting_record.loc[lambda x: x['election_cycle']=='spring'], left_on='stuid', right_on='class_senator_vote').shape[0]"
"which students live in the city with code ""nyc"" and have class senator votes in the spring election cycle? count the numbers.","pd.merge(student.loc[lambda x: x['city_code']=='nyc'], voting_record.loc[lambda x: x['election_cycle']=='spring'], left_on='stuid', right_on='class_senator_vote').shape[0]"
"find the average age of students who live in the city with code ""nyc"" and have secretary votes in the spring election cycle.","pd.merge(student, voting_record, left_on='stuid', right_on='secretary_vote').loc[(lambda x: x['city_code'] == 'nyc') & (lambda x: x['election_cycle'] == 'spring'), 'age'].mean()"
"what is the average age of students who have city code ""nyc"" and have secretary votes for the spring election cycle?","pd.merge(student, voting_record, left_on='stuid', right_on='secretary_vote').loc[(lambda x: x['city_code'] == 'nyc') & (lambda x: x['election_cycle'] == 'spring'), 'age'].mean()"
find the average age of female (sex is f) students who have secretary votes in the spring election cycle.,"pd.merge(student[student['sex']=='f'], voting_record[voting_record['election_cycle']=='spring'], left_on='stuid', right_on='secretary_vote')['age'].mean()"
what is the average age of the female students with secretary votes in the spring election cycle?,"pd.merge(student[student['sex']=='f'], voting_record[voting_record['election_cycle']=='spring'], left_on='stuid', right_on='secretary_vote')['age'].mean()"
find the distinct first names of all the students who have vice president votes and whose city code is not pit.,"student.merge(voting_record, left_on='stuid', right_on='vice_president_vote')['fname'].drop_duplicates().loc[lambda x: x != 'pit']"
what are the distinct first names of the students who have vice president votes and reside in a city whose city code is not pit?,"student.merge(voting_record, left_on='stuid', right_on='vice_president_vote')['fname'].drop_duplicates().loc[lambda x: x != 'pit']"
find the distinct last names of all the students who have president votes and whose advisor is not 2192.,"student.merge(voting_record, left_on='stuid', right_on='president_vote')['lname'].drop_duplicates().except_(student[student['advisor']=='2192']['lname'])"
what are the distinct last names of the students who have president votes but do not have 2192 as the advisor?,"student.merge(voting_record, left_on='stuid', right_on='president_vote')['lname'].drop_duplicates().except_(student[student['advisor']=='2192']['lname'])"
find the distinct last names of all the students who have president votes and whose advisor is 8741.,"student.merge(voting_record, left_on='stuid', right_on='president_vote')['lname'].unique().tolist() & student.loc[lambda x: x['advisor']=='8741', 'lname'].unique().tolist()"
what are the distinct last names of the students who have president votes and have 8741 as the advisor?,"student.merge(voting_record, left_on='stuid', right_on='president_vote')['lname'].unique().tolist() & student.loc[lambda x: x['advisor']=='8741', 'lname'].unique().tolist()"
"for each advisor, report the total number of students advised by him or her.",student.groupby('advisor').size().reset_index(name='count')
report all advisors that advise more than 2 students.,student.groupby('advisor').filter(lambda x: len(x) > 2)['advisor'].unique()
which advisors have more than two students?,student.groupby('advisor').filter(lambda x: len(x) > 2)['advisor'].unique()
report all majors that have less than 3 students.,student.groupby('major').filter(lambda x: len(x) < 3)['major'].unique()
what are the majors only less than three students are studying?,student.groupby('major').filter(lambda x: len(x) < 3)['major'].unique()
"for each election cycle, report the number of voting records.",voting_record.groupby('election_cycle').size().reset_index(name='count(*)')
count the number of voting records for each election cycle.,voting_record.groupby('election_cycle').size().reset_index(name='count(*)')
which major has the most students?,student['major'].value_counts().index[0]
find the major that is studied by the largest number of students.,student['major'].value_counts().index[0]
what is the most common major among female (sex is f) students?,student.loc[lambda x: x['sex'] == 'f'].groupby('major').size().sort_values(ascending=false).index[0]
find the major that is studied by the most female students.,student.loc[lambda x: x['sex'] == 'f'].groupby('major').size().sort_values(ascending=false).index[0]
what is the city_code of the city that the most students live in?,student.groupby('city_code').size().sort_values(ascending=false).index[0]
return the code of the city that has the most students.,student.groupby('city_code').size().sort_values(ascending=false).index[0]
report the distinct advisors who have more than 2 students.,students.groupby('advisor').filter(lambda x: len(x) > 2)['advisor'].unique()
which advisors are advising more than 2 students?,students.groupby('advisor').filter(lambda x: len(x) > 2)['advisor'].unique()
count the number of products.,products.shape[0]
how many colors are there?,ref_colors.shape[0]
count the number of colors.,ref_colors.shape[0]
how many characteristics are there?,characteristics.shape[0]
count the number of characteristics.,characteristics.shape[0]
what are the names and buying prices of all the products?,"products[['product_name', 'typical_buying_price']]"
return the names and typical buying prices for all products.,"products[['product_name', 'typical_buying_price']]"
list the description of all the colors.,ref_colors['color_description']
what are the descriptions for each color?,ref_colors['color_description']
find the names of all the product characteristics.,characteristics['characteristic_name'].unique()
what are the different names of the product characteristics?,characteristics['characteristic_name'].unique()
"what are the names of products with category ""spices""?","products.loc[lambda x: x['product_category_code']=='spices', 'product_name']"
return the names of products in the category 'spices'.,"products.loc[lambda x: x['product_category_code']=='spices', 'product_name']"
"list the names, color descriptions and product descriptions of products with category ""herbs"".","pd.merge(products.loc[lambda x: x['product_category_code']=='herbs'], ref_colors, on='color_code')[['product_name', 'color_description', 'product_description']]"
"what are the names, color descriptions, and product descriptions for products in the 'herbs' category?","pd.merge(products.loc[lambda x: x['product_category_code']=='herbs'], ref_colors, on='color_code')[['product_name', 'color_description', 'product_description']]"
"how many products are there under the category ""seeds""?",(products['product_category_code'] == 'seeds').sum()
count the number of products in the category 'seeds'.,(products['product_category_code'] == 'seeds').sum()
"find the number of products with category ""spices"" and typically sold above 1000.",(products['product_category_code']=='spices') & (products['typical_buying_price'] > 1000).sum()
how many products are in the 'spices' category and have a typical price of over 1000?,(products['product_category_code']=='spices') & (products['typical_buying_price'] > 1000).sum()
"what is the category and typical buying price  of the product with name ""cumin""?","products.loc[lambda x: x['product_name']=='cumin', ['product_category_code', 'typical_buying_price']]"
return the category code and typical price of 'cumin'.,"products.loc[lambda x: x['product_name']=='cumin', ['product_category_code', 'typical_buying_price']]"
"which category does the product named ""flax"" belong to?","products.loc[lambda x: x['product_name']=='flax', 'product_category_code']"
what is the code of the category that the product with the name 'flax' belongs to?,"products.loc[lambda x: x['product_name']=='flax', 'product_category_code']"
what is the name of the product with the color description 'yellow'?,"products.merge(ref_colors, on='color_code').loc[lambda x: x['color_description']=='yellow', 'product_name']"
give the name of the products that have a color description 'yellow'.,"products.merge(ref_colors, on='color_code').loc[lambda x: x['color_description']=='yellow', 'product_name']"
find the category descriptions of the products whose descriptions include letter 't'.,"ref_product_categories.merge(products[products['product_description'].str.contains('t')], on='product_category_code', how='inner')['product_category_description']"
what are the descriptions of the categories that products with product descriptions that contain the letter t are in?,"ref_product_categories.merge(products[products['product_description'].str.contains('t')], on='product_category_code', how='inner')['product_category_description']"
"what is the color description of the product with name ""catnip""?","pd.merge(products.loc[lambda x: x['product_name'] == 'catnip'], ref_colors, on='color_code')['color_description']"
give the color description for the product 'catnip'.,"pd.merge(products.loc[lambda x: x['product_name'] == 'catnip'], ref_colors, on='color_code')['color_description']"
"what is the color code and description of the product named ""chervil""?","pd.merge(products, ref_colors, on='color_code').loc[lambda x: x['product_name']=='chervil', ['color_code', 'color_description']]"
return the color code and description for the product with the name 'chervil'.,"pd.merge(products, ref_colors, on='color_code').loc[lambda x: x['product_name']=='chervil', ['color_code', 'color_description']]"
find the id and color description of the products with at least 2 characteristics.,"(pd.merge(pd.merge(products, ref_colors, on='color_code'), product_characteristics, on='product_id').groupby('product_id').filter(lambda x: len(x) >= 2).loc[:, ['product_id', 'color_description']].drop_duplicates('product_id'))"
what are the product ids and color descriptions for products with two or more characteristics?,"(pd.merge(pd.merge(products, ref_colors, on='color_code'), product_characteristics, on='product_id').groupby('product_id').filter(lambda x: len(x) >= 2).loc[:, ['product_id', 'color_description']].drop_duplicates('product_id'))"
"list all the product names with the color description ""white"".","products.merge(ref_colors, on='color_code').loc[lambda x: x['color_description']=='white', 'product_name']"
what are the names of products with 'white' as their color description?,"products.merge(ref_colors, on='color_code').loc[lambda x: x['color_description']=='white', 'product_name']"
"what are the name and typical buying and selling prices of the products that have color described as ""yellow""?","pd.merge(products, ref_colors.loc[lambda x: x['color_description']=='yellow'], on='color_code')[['product_name', 'typical_buying_price', 'typical_selling_price']]"
return the names and typical buying and selling prices for products that have 'yellow' as their color description.,"pd.merge(products, ref_colors.loc[lambda x: x['color_description']=='yellow'], on='color_code')[['product_name', 'typical_buying_price', 'typical_selling_price']]"
"how many characteristics does the product named ""sesame"" have?","pd.merge(products.loc[lambda x: x['product_name']=='sesame'], product_characteristics, on='product_id').shape[0]"
count the number of characteristics the product 'sesame' has.,"pd.merge(products.loc[lambda x: x['product_name']=='sesame'], product_characteristics, on='product_id').shape[0]"
"how many distinct characteristic names does the product ""cumin"" have?","(products.merge(product_characteristics).merge(characteristics, on='characteristic_id').pipe(lambda x: x[x['product_name'] == 'sesame']).nunique()['characteristic_name'])"
count the number of different characteristic names the product 'cumin' has.,"(products.merge(product_characteristics).merge(characteristics, on='characteristic_id').pipe(lambda x: x[x['product_name'] == 'sesame']).nunique()['characteristic_name'])"
"what are all the characteristic names of product ""sesame""?","pd.merge(pd.merge(products.loc[lambda x: x['product_name']=='sesame'], product_characteristics, on='product_id'), characteristics, on='characteristic_id')['characteristic_name']"
return the characteristic names of the 'sesame' product.,"pd.merge(pd.merge(products.loc[lambda x: x['product_name']=='sesame'], product_characteristics, on='product_id'), characteristics, on='characteristic_id')['characteristic_name']"
"list all the characteristic names and data types of product ""cumin"".","pd.merge(pd.merge(products.loc[lambda x: x['product_name']=='cumin'], product_characteristics, on='product_id'), characteristics, on='characteristic_id')[['characteristic_name', 'characteristic_data_type']]"
what are the names and data types of the characteristics of the 'cumin' product?,"pd.merge(pd.merge(products.loc[lambda x: x['product_name']=='cumin'], product_characteristics, on='product_id'), characteristics, on='characteristic_id')[['characteristic_name', 'characteristic_data_type']]"
"list all characteristics of product named ""sesame"" with type code ""grade"".","pd.merge(pd.merge(products.loc[lambda x: x['product_name']=='sesame'], product_characteristics, on='product_id'), characteristics.loc[lambda x: x['characteristic_type_code']=='grade'], on='characteristic_id')['characteristic_name']"
what are the names of the characteristics of the product 'sesame' that have the characteristic type code 'grade'?,"pd.merge(pd.merge(products.loc[lambda x: x['product_name']=='sesame'], product_characteristics, on='product_id'), characteristics.loc[lambda x: x['characteristic_type_code']=='grade'], on='characteristic_id')['characteristic_name']"
"how many characteristics does the product named ""laurel"" have?","pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').loc[lambda x: x['product_name']=='laurel'].shape[0]"
count the number of characteristics of the product named 'laurel'.,"pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').loc[lambda x: x['product_name']=='laurel'].shape[0]"
"find the number of characteristics that the product ""flax"" has.","pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').loc[lambda x: x['product_name']=='flax'].shape[0]"
count the number of characteristics of the 'flax' product.,"pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').loc[lambda x: x['product_name']=='flax'].shape[0]"
"find the name of the products that have the color description ""red"" and have the characteristic name ""fast"".","pd.merge(pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id'), ref_colors, on='color_code').loc[(lambda x: x['color_description']=='red') & (lambda x: x['characteristic_name']=='fast'), 'product_name']"
what are the names of the products that have a color description of 'red' and the 'fast' characteristic?,"pd.merge(pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id'), ref_colors, on='color_code').loc[(lambda x: x['color_description']=='red') & (lambda x: x['characteristic_name']=='fast'), 'product_name']"
"how many products have the characteristic named ""hot""?","pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').loc[lambda x: x['characteristic_name']=='hot'].shape[0]"
count the number of products with the 'hot' charactersitic.,"pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').loc[lambda x: x['characteristic_name']=='hot'].shape[0]"
list the all the distinct names of the products with the characteristic name 'warm'.,"pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').loc[lambda x: x['characteristic_name']=='warm', 'product_name'].unique()"
what are the different product names for products that have the 'warm' characteristic:?,"pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').loc[lambda x: x['characteristic_name']=='warm', 'product_name'].unique()"
"find the number of the products that have their color described as ""red"" and have a characteristic named ""slow"".","pd.merge(pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id'), ref_colors, on='color_code').loc[lambda x: (x['color_description']=='red')&(x['characteristic_name']=='slow')].shape[0]"
how many products have the color description 'red' and the characteristic name 'slow'?,"pd.merge(pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id'), ref_colors, on='color_code').loc[lambda x: (x['color_description']=='red')&(x['characteristic_name']=='slow')].shape[0]"
"count the products that have the color description ""white"" or have the characteristic name ""hot"".","pd.merge(pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id'), ref_colors, on='color_code').loc[lambda x: (x['color_description']=='white') | (x['characteristic_name']=='hot'),:].shape[0]"
how many products have their color described as 'white' or have a characteristic with the name 'hot'?,"pd.merge(pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id'), ref_colors, on='color_code').loc[lambda x: (x['color_description']=='white') | (x['characteristic_name']=='hot'),:].shape[0]"
"what is the unit of measuerment of the product category code ""herbs""?","ref_product_categories.loc[lambda x: x['product_category_code'] == 'herbs', 'unit_of_measure']"
return the unit of measure for 'herb' products.,"ref_product_categories.loc[lambda x: x['product_category_code'] == 'herbs', 'unit_of_measure']"
"find the product category description of the product category with code ""spices"".","ref_product_categories.loc[lambda x: x['product_category_code'] == 'spices', 'product_category_description']"
what is the description of the product category with the code 'spices'?,"ref_product_categories.loc[lambda x: x['product_category_code'] == 'spices', 'product_category_description']"
"what is the product category description and unit of measurement of category ""herbs""?","ref_product_categories.loc[ref_product_categories['product_category_code'] == 'herbs', ['product_category_description', 'unit_of_measure']]"
return the description and unit of measurement for products in the 'herbs' category.,"ref_product_categories.loc[ref_product_categories['product_category_code'] == 'herbs', ['product_category_description', 'unit_of_measure']]"
"what is the unit of measurement of product named ""cumin""?","pd.merge(products.loc[lambda x: x['product_name']=='cumin'], ref_product_categories, on='product_category_code')['unit_of_measure']"
give the unit of measure for the product with the name 'cumin'.,"pd.merge(products.loc[lambda x: x['product_name']=='cumin'], ref_product_categories, on='product_category_code')['unit_of_measure']"
"find the unit of measurement and product category code of product named ""chervil"".","pd.merge(products.loc[lambda x: x['product_name']=='chervil'], ref_product_categories, on='product_category_code')[['unit_of_measure', 'product_category_code']]"
what are the unit of measure and category code for the 'chervil' product?,"pd.merge(products.loc[lambda x: x['product_name']=='chervil'], ref_product_categories, on='product_category_code')[['unit_of_measure', 'product_category_code']]"
"find the product names that are colored 'white' but do not have unit of measurement ""handful"".","pd.merge(pd.merge(products, ref_product_categories, on='product_category_code'), ref_colors, on='color_code').loc[lambda x: (x['color_description'] == 'white') & (x['unit_of_measure'] != 'handful'), 'product_name']"
what are the names of products that are not 'white' in color and are not measured by the unit 'handful'?,"pd.merge(pd.merge(products, ref_product_categories, on='product_category_code'), ref_colors, on='color_code').loc[lambda x: (x['color_description'] == 'white') & (x['unit_of_measure'] != 'handful'), 'product_name']"
what is the description of the color for most products?,"pd.merge(products, ref_colors, on='color_code').groupby('color_description').size().sort_values(ascending=false).index[0]"
return the color description that is most common across all products.,"pd.merge(products, ref_colors, on='color_code').groupby('color_description').size().sort_values(ascending=false).index[0]"
what is the description of the color used by least products?,"pd.merge(products, ref_colors, on='color_code').groupby('color_description').size().sort_values().index[0]"
give the color description that is least common across products.,"pd.merge(products, ref_colors, on='color_code').groupby('color_description').size().sort_values().index[0]"
what is the characteristic name used by most number of the products?,"pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').groupby('characteristic_name').size().nlargest(1).index[0]"
return the name of the characteristic that is most common across all products.,"pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').groupby('characteristic_name').size().nlargest(1).index[0]"
"what are the names, details and data types of the characteristics which are never used by any product?","characteristics[['characteristic_name', 'other_characteristic_details', 'characteristic_data_type']].loc[~characteristics['characteristic_id'].isin(product_characteristics['characteristic_id'])]"
"give the names, details, and data types of characteristics that are not found in any product.","characteristics[['characteristic_name', 'other_characteristic_details', 'characteristic_data_type']].loc[~characteristics['characteristic_id'].isin(product_characteristics['characteristic_id'])]"
what are characteristic names used at least twice across all products?,"products.merge(product_characteristics, on='product_id').merge(characteristics, on='characteristic_id').groupby('characteristic_name').filter(lambda x: len(x) >= 2)['characteristic_name'].unique()"
give the names of characteristics that are in two or more products?,"products.merge(product_characteristics, on='product_id').merge(characteristics, on='characteristic_id').groupby('characteristic_name').filter(lambda x: len(x) >= 2)['characteristic_name'].unique()"
how many colors are never used by any product?,ref_colors[~ref_colors['color_code'].isin(products['color_code'])].shape[0]
count the number of colors that are not used in any products.,ref_colors[~ref_colors['color_code'].isin(products['color_code'])].shape[0]
how many events are there?,event.shape[0]
list all the event names by year from the most recent to the oldest.,"event.sort_values('year', ascending=false)['name']"
what is the name of the event that happened in the most recent year?,"event.sort_values('year', ascending=false).iloc[0]['name']"
how many stadiums are there?,stadium.shape[0]
find the name of the stadium that has the maximum capacity.,"stadium.sort_values('capacity', ascending=false).iloc[0]['name']"
find the names of stadiums whose capacity is smaller than the average capacity.,"stadium.loc[lambda x: x['capacity'] < stadium['capacity'].mean(), 'name']"
find the country that has the most stadiums.,stadium.groupby('country').size().sort_values(ascending=false).index[0]
which country has at most 3 stadiums listed?,stadium.groupby('country').filter(lambda x: len(x) <= 3)['country'].unique()
which country has both stadiums with capacity greater than 60000 and stadiums with capacity less than 50000?,"pd.merge(stadium.loc[stadium['capacity'] > 60000, ['country']], stadium.loc[stadium['capacity'] < 50000, ['country']]).drop_duplicates()"
how many cities have a stadium that was opened before the year of 2006?,"stadium.loc[lambda x: x['opening_year'] < 2006, 'city'].nunique()"
how many stadiums does each country have?,stadium.groupby('country').size()
which countries do not have a stadium that was opened after 2006?,"stadium['country'].drop_duplicates().reset_index(drop=true).drop(stadium.loc[stadium['opening_year'] > 2006, 'country'].sort_values().index)"
"how many stadiums are not in country ""russia""?",(stadium['country'] != 'russia').sum()
"find the names of all swimmers, sorted by their 100 meter scores in ascending order.",swimmer.sort_values('meter_100')['name']
how many different countries are all the swimmers from?,swimmer['nationality'].nunique()
list countries that have more than one swimmer.,swimmer.groupby('nationality').filter(lambda x: len(x) > 1).groupby('nationality').size()
"find all 200 meter and 300 meter results of swimmers with nationality ""australia"".","swimmer.loc[lambda x: x['nationality']=='australia', ['meter_200', 'meter_300']]"
"find the names of swimmers who has a result of ""win"".","swimmer.merge(record, on='swimmer_id').loc[lambda x: x['result']=='win', 'name']"
what is the name of the stadium which held the most events?,"pd.merge(stadium, event, on='id').groupby('stadium_id')['name'].count().idxmax()"
"find the name and capacity of the stadium where the event named ""world junior"" happened.","stadium.merge(event.loc[lambda x: x['name']=='world junior'], left_on='id', right_on='stadium_id')[['name', 'capacity']]"
find the names of stadiums which have never had any event.,stadium[~stadium['id'].isin(event['stadium_id'])]['name']
find the name of the swimmer who has the most records.,"swimmer.merge(record, on='id').groupby('swimmer_id')['name'].count().idxmax()"
find the name of the swimmer who has at least 2 records.,"swimmer.merge(record, on='swimmer_id').groupby('swimmer_id').filter(lambda x: len(x) >= 2)['name']"
"find the name and nationality of the swimmer who has won (i.e., has a result of ""win"") more than 1 time.","swimmer.merge(record[record['result'] == 'win'], on='id').groupby(['swimmer_id', 'name', 'nationality']).filter(lambda x: len(x) > 1).drop_duplicates(subset=['swimmer_id'])[['name', 'nationality']]"
find the names of the swimmers who have no record.,"swimmer.loc[~swimmer['id'].isin(record['swimmer_id']), 'name']"
"find the names of the swimmers who have both ""win"" and ""loss"" results in the record.","swimmer.merge(record).loc[lambda x: x['result']=='win', 'name'].to_frame().merge(swimmer.merge(record).loc[lambda x: x['result']=='loss', 'name'].to_frame(), on='name')['name']"
find the names of stadiums that some australian swimmers have been to.,"pd.merge(pd.merge(pd.merge(swimmer, record, on='id'), event, left_on='event_id', right_on='id'), stadium, left_on='stadium_id', right_on='id').loc[lambda x: x['nationality']=='australia', 'name']"
find the names of stadiums that the most swimmers have been to.,"pd.merge(pd.merge(record, event, left_on='event_id', right_on='id'), stadium, left_on='stadium_id', right_on='id').groupby('stadium_id')['name'].count().idxmax()"
find all details for each swimmer.,swimmer
what is the average capacity of the stadiums that were opened in year 2005?,"stadium.loc[lambda x: x['opening_year']==2005, 'capacity'].mean()"
how many railways are there?,railway.shape[0]
list the builders of railways in ascending alphabetical order.,railway.sort_values('builder')['builder']
list the wheels and locations of the railways.,"railway[['wheels', 'location']]"
"what is the maximum level of managers in countries that are not ""australia""?","manager.loc[lambda x: x['country'] != 'australia', 'level'].max()"
what is the average age for all managers?,manager['age'].mean()
what are the names of managers in ascending order of level?,manager.sort_values('level')['name']
what are the names and arrival times of trains?,"train[['name', 'arrival']]"
what is the name of the oldest manager?,"manager.sort_values('age', ascending=false).iloc[0]['name']"
show the names of trains and locations of railways they are in.,"pd.merge(railway, train, on='railway_id')[['name', 'location']]"
"show the builder of railways associated with the trains named ""andaman exp"".","railway.merge(train[train['name'] == 'andaman exp'], on='railway_id')['builder']"
show id and location of railways that are associated with more than one train.,"pd.merge(railway, train, on='railway_id').groupby('railway_id').filter(lambda x: x.shape[0] > 1).loc[:, ['railway_id', 'location']]"
show the id and builder of the railway that are associated with the most trains.,"pd.merge(railway, train, on='railway_id').groupby('railway_id')['builder'].count().idxmax()"
"show different builders of railways, along with the corresponding number of railways using each builder.",railway.groupby('builder').size().reset_index(name='count')
show the most common builder of railways.,railway.groupby('builder').size().sort_values(ascending=false).index[0]
show different locations of railways along with the corresponding number of railways at each location.,railway.groupby('location').size()
show the locations that have more than one railways.,railway.groupby('location').filter(lambda x: len(x) > 1)['location'].unique()
list the object number of railways that do not have any trains.,"railway.loc[~railway['railway_id'].isin(train['railway_id']), 'objectnumber']"
show the countries that have both managers of age above 50 and managers of age below 46.,"set(manager.loc[lambda x: x['age'] > 50, 'country']) & set(manager.loc[lambda x: x['age'] < 46, 'country'])"
show the distinct countries of managers.,manager['country'].unique()
show the working years of managers in descending order of their level.,"manager.sort_values('level', ascending=false)['working_year_starts']"
show the countries that have managers of age above 50 or below 46.,"manager.loc[(manager['age'] > 50) | (manager['age'] < 46), 'country']"
how many addresses are there in country usa?,(addresses['country'] == 'usa').sum()
show all distinct cities in the address record.,addresses['city'].unique()
show each state and the number of addresses in each state.,addresses.groupby('state_province_county').size().reset_index(name='count')
show names and phones of customers who do not have address information.,"customers.loc[~customers['customer_id'].isin(customer_address_history['customer_id']), ['customer_name', 'customer_phone']]"
show the name of the customer who has the most orders.,"pd.merge(customers, customer_orders, on='customer_id').groupby('customer_name').size().sort_values(ascending=false).index[0]"
show the product type codes which have at least two products.,products.groupby('product_type_code').filter(lambda x: len(x) >= 2)['product_type_code'].unique()
show the names of customers who have both an order in completed status and an order in part status.,"customers.merge(customer_orders).loc[lambda x: x['order_status_code']=='completed', 'customer_name'].intersec(customers.merge(customer_orders).loc[lambda x: x['order_status_code']=='part', 'customer_name'])"
"show the name, phone, and payment method code for all customers in descending order of customer number.","customers[['customer_name', 'customer_phone', 'payment_method_code']].sort_values('customer_number', ascending=false)"
show the product name and total order quantity for each product.,"pd.merge(products, order_items, on='product_id').groupby('product_id')['order_quantity'].sum().reset_index().merge(products, on='product_id')[['product_name', 'order_quantity']]"
"show the minimum, maximum, average price for all products.","products['product_price'].agg(['min', 'max', 'mean'])"
how many products have a price higher than the average?,(products['product_price'] > products['product_price'].mean()).sum()
"show the customer name, customer address city, date from, and date to for each customer address history.","pd.merge(pd.merge(customer_address_history, customers, on='customer_id'), addresses, on='address_id')[['customer_name', 'city', 'date_from', 'date_to']]"
show the names of customers who use credit card payment method and have more than 2 orders.,"customers.merge(customer_orders, on='customer_id').loc[lambda x: x['payment_method_code']=='credit card'].groupby('customer_name').filter(lambda x: len(x) > 2)['customer_name']"
what are the name and phone of the customer with the most ordered product quantity?,"customers.merge(customer_orders, on='customer_id').merge(order_items, on='order_id').groupby(['customer_id', 'customer_name', 'customer_phone'])[['order_quantity']].sum().sort_values('order_quantity', ascending=false).reset_index()[['customer_name', 'customer_phone']].iloc[0]"
show the product type and name for the products with price higher than 1000 or lower than 500.,"products.loc[(products['product_price']>1000) | (products['product_price']<500), ['product_type_code', 'product_name']]"
find the name of dorms only for female (f gender).,"dorm.loc[dorm['gender']=='f', 'dorm_name']"
what are the names of the all-female dorms?,"dorm.loc[dorm['gender']=='f', 'dorm_name']"
find the name of dorms that can accommodate more than 300 students.,"dorm.loc[dorm['student_capacity'] > 300, 'dorm_name']"
what are the names of all the dorms that can accomdate more than 300 students?,"dorm.loc[dorm['student_capacity'] > 300, 'dorm_name']"
how many female students (sex is f) whose age is below 25?,"student.loc[(student['sex'] == ""f"") & (student['age'] < 25), :].shape[0]"
how many girl students who are younger than 25?,"student.loc[(student['sex'] == ""f"") & (student['age'] < 25), :].shape[0]"
find the first name of students who is older than 20.,"student.loc[lambda x: x['age'] > 20, 'fname']"
what are the first names of all students who are older than 20?,"student.loc[lambda x: x['age'] > 20, 'fname']"
find the first name of students living in city phl whose age is between 20 and 25.,"student.loc[(student['city_code']=='phl') & (student['age'].between(20, 25)), 'fname']"
what is the first name of the students who are in age 20 to 25 and living in phl city?,"student.loc[(student['city_code']=='phl') & (student['age'].between(20, 25)), 'fname']"
how many dorms are there?,dorm.shape[0]
how many dorms are in the database?,dorm.shape[0]
find the number of distinct amenities.,dorm_amenity.shape[0]
how many diffrent dorm amenities are there?,dorm_amenity.shape[0]
find the total capacity of all dorms.,dorm['student_capacity'].sum()
what is the total student capacity of all dorms?,dorm['student_capacity'].sum()
how many students exist?,student.shape[0]
find the average age of all students living in the each city.,student.groupby('city_code')['age'].mean()
what is the average age for each city and what are those cities?,student.groupby('city_code')['age'].mean()
find the average and total capacity of dorms for the students with gender x.,"dorm.loc[dorm['gender']=='x', 'student_capacity'].agg(['mean', 'sum'])"
what is the average and total capacity for all dorms who are of gender x?,"dorm.loc[dorm['gender']=='x', 'student_capacity'].agg(['mean', 'sum'])"
find the number of dorms that have some amenity.,has_amenity['dormid'].nunique()
how many dorms have amenities?,has_amenity['dormid'].nunique()
find the name of dorms that do not have any amenity,dorm[~dorm['dormid'].isin(has_amenity['dormid'])]['dorm_name']
what are the names of all the dorms that don't have any amenities?,dorm[~dorm['dormid'].isin(has_amenity['dormid'])]['dorm_name']
find the number of distinct gender for dorms.,dorm['gender'].nunique()
how many different genders are there in the dorms?,dorm['gender'].nunique()
find the capacity and gender type of the dorm whose name has substring ‘donor’.,"dorm.loc[dorm['dorm_name'].str.contains('donor'), ['student_capacity', 'gender']]"
what is the student capacity and type of gender for the dorm whose name as the phrase donor in it?,"dorm.loc[dorm['dorm_name'].str.contains('donor'), ['student_capacity', 'gender']]"
find the name and gender type of the dorms whose capacity is greater than 300 or less than 100.,"dorm.loc[(dorm['student_capacity'] > 300) | (dorm['student_capacity'] < 100), ['dorm_name', 'gender']]"
what are the names and types of the dorms that have a capacity greater than 300 or less than 100?,"dorm.loc[(dorm['student_capacity'] > 300) | (dorm['student_capacity'] < 100), ['dorm_name', 'gender']]"
find the numbers of different majors and cities.,"(student['major'].nunique(), student['city_code'].nunique())"
how many different majors are there and how many different city codes are there for each student?,"(student['major'].nunique(), student['city_code'].nunique())"
find the name of dorms which have both tv lounge and study room as amenities.,"set(dorm.loc[dorm['dormid'].isin(has_amenity.loc[has_amenity['amenid'].isin(dorm_amenity.loc[dorm_amenity['amenity_name'] == 'tv lounge', 'amenid']), 'dormid']), 'dorm_name']).intersection(set(dorm.loc[dorm['dormid'].isin(has_amenity.loc[has_amenity['amenid'].isin(dorm_amenity.loc[dorm_amenity['amenity_name'] == 'study room', 'amenid']), 'dormid']), 'dorm_name']))"
what is the name of the dorm with both a tv lounge and study room listed as amenities?,"set(dorm.loc[dorm['dormid'].isin(has_amenity.loc[has_amenity['amenid'].isin(dorm_amenity.loc[dorm_amenity['amenity_name'] == 'tv lounge', 'amenid']), 'dormid']), 'dorm_name']).intersection(set(dorm.loc[dorm['dormid'].isin(has_amenity.loc[has_amenity['amenid'].isin(dorm_amenity.loc[dorm_amenity['amenity_name'] == 'study room', 'amenid']), 'dormid']), 'dorm_name']))"
find the name of dorms which have tv lounge but no study room as amenity.,"pd.merge(pd.merge(dorm, has_amenity, on='dormid'), dorm_amenity, on='amenid').query('amenity_name == ""tv lounge""')['dorm_name'].drop_duplicates().drop(pd.merge(pd.merge(dorm, has_amenity, on='dormid'), dorm_amenity, on='amenid').query('amenity_name == ""study room""')['dorm_name']).tolist()"
what is the name of each dorm that has a tv lounge but no study rooms?,"pd.merge(pd.merge(dorm, has_amenity, on='dormid'), dorm_amenity, on='amenid').query('amenity_name == ""tv lounge""')['dorm_name'].drop_duplicates().drop(pd.merge(pd.merge(dorm, has_amenity, on='dormid'), dorm_amenity, on='amenid').query('amenity_name == ""study room""')['dorm_name']).tolist()"
what is the last name of every student who is either female or living in a city with the code bal or male and under 20?,"student.loc[(student['sex']=='f')&(student['city_code']=='bal'), 'lname'].append(student.loc[(student['sex']=='m')&(student['age']<20), 'lname']).drop_duplicates()"
find the name of the dorm with the largest capacity.,"dorm.sort_values('student_capacity', ascending=false).iloc[0]['dorm_name']"
what are the names of the dorm with the largest capacity?,"dorm.sort_values('student_capacity', ascending=false).iloc[0]['dorm_name']"
list in alphabetic order all different amenities.,dorm_amenity['amenity_name'].sort_values()
what are the different dorm amenity names in alphabetical order?,dorm_amenity['amenity_name'].sort_values()
find the code of city where most of students are living in.,student.groupby('city_code').size().sort_values(ascending=false).index[0]
what is the code of the city with the most students?,student.groupby('city_code').size().sort_values(ascending=false).index[0]
find the first and last name of students whose age is younger than the average age.,"student.loc[lambda x: x['age'] < x['age'].mean(), ['fname', 'lname']]"
what is the first and last name of all students who are younger than average?,"student.loc[lambda x: x['age'] < x['age'].mean(), ['fname', 'lname']]"
"list the first and last name of students who are not living in the city with code hkg, and sorted the results by their ages.","student.loc[lambda x: x['city_code']!='hkg'][['fname', 'lname']].sort_values('age')"
what are the first and last names of all students who are not living in the city hkg and order the results by age?,"student.loc[lambda x: x['city_code']!='hkg'][['fname', 'lname']].sort_values('age')"
"list name of all amenities which anonymous donor hall has, and sort the results in alphabetic order.","pd.merge(pd.merge(dorm_amenity, has_amenity, on='amenid'), dorm, on='dormid').loc[lambda x: x['dorm_name']=='anonymous donor hall', 'amenity_name'].sort_values()"
what are the amenities in alphabetical order that anonymous donor hall has?,"pd.merge(pd.merge(dorm_amenity, has_amenity, on='amenid'), dorm, on='dormid').loc[lambda x: x['dorm_name']=='anonymous donor hall', 'amenity_name'].sort_values()"
find the number of dorms and total capacity for each gender.,"dorm.groupby('gender').agg(count=('gender', 'count'),sum=('student_capacity', 'sum'))['count', 'sum']"
how many dorms are there and what is the total capacity for each gender?,"dorm.groupby('gender').agg(count=('gender', 'count'),sum=('student_capacity', 'sum'))['count', 'sum']"
find the average and oldest age for students with different sex.,"student.groupby('sex')['age'].agg(['mean', 'max']).reset_index()"
what is the average and oldest age for each gender of student?,"student.groupby('sex')['age'].agg(['mean', 'max']).reset_index()"
find the number of students in each major.,student.groupby('major').size().reset_index(name='count')
how many students are there in each major?,student.groupby('major').size().reset_index(name='count')
find the number and average age of students living in each city.,"student.groupby('city_code').agg(count=('age', 'count'), average=('age', 'mean'), city_code=('city_code', 'max'))"
how many students live in each city and what are their average ages?,"student.groupby('city_code').agg(count=('age', 'count'), average=('age', 'mean'), city_code=('city_code', 'max'))"
find the average age and number of male students (with sex m) from each city.,"student.loc[lambda x: x['sex']=='m'].groupby('city_code').agg({'age': 'mean', 'sex': 'count'})"
what is the average age and how many male students are there in each city?,"student.loc[lambda x: x['sex']=='m'].groupby('city_code').agg({'age': 'mean', 'sex': 'count'})"
find the number of students for the cities where have more than one student.,student.groupby('city_code').filter(lambda x: len(x) > 1).groupby('city_code').size().reset_index(name='count')
"how many students are from each city, and which cities have more than one cities?",student.groupby('city_code').filter(lambda x: len(x) > 1).groupby('city_code').size().reset_index(name='count')
find the first and last name of students who are not in the largest major.,"student.loc[lambda x: x['major'] != student.groupby('major').size().idxmax(), ['fname', 'lname']]"
what is the first and last name of the students who are not in the largest major?,"student.loc[lambda x: x['major'] != student.groupby('major').size().idxmax(), ['fname', 'lname']]"
find the number of students whose age is older than the average age for each gender.,student.loc[lambda x: x['age'] > x['age'].mean()].groupby('sex')['age'].count()
how many students are older than average for each gender?,student.loc[lambda x: x['age'] > x['age'].mean()].groupby('sex')['age'].count()
find the average age of students living in each dorm and the name of dorm.,"pd.merge(pd.merge(student, lives_in, on='stuid'), dorm, on='dormid').groupby('dorm_name')['age'].mean()"
what is the average age for each dorm and what are the names of each dorm?,"pd.merge(pd.merge(student, lives_in, on='stuid'), dorm, on='dormid').groupby('dorm_name')['age'].mean()"
find the number of amenities for each of the dorms that can accommodate more than 100 students.,dorm.merge(has_amenity).loc[lambda x: x['student_capacity']>100].groupby('dormid').size().reset_index(name='count(*)')
"for each dorm, how many amenities does it have?",dorm.merge(has_amenity).loc[lambda x: x['student_capacity']>100].groupby('dormid').size().reset_index(name='count(*)')
find the number of students who is older than 20 in each dorm.,student.merge(lives_in).merge(dorm).loc[lambda x: x['age']>20].groupby('dorm_name').size().reset_index(name='count')
how many students are older than 20 in each dorm?,student.merge(lives_in).merge(dorm).loc[lambda x: x['age']>20].groupby('dorm_name').size().reset_index(name='count')
find the first name of students who are living in the smith hall.,"pd.merge(pd.merge(student, lives_in, on='stuid'), dorm, on='dormid').loc[lambda x: x['dorm_name']=='smith hall', 'fname']"
what are the first names of all students in smith hall?,"pd.merge(pd.merge(student, lives_in, on='stuid'), dorm, on='dormid').loc[lambda x: x['dorm_name']=='smith hall', 'fname']"
find the average age of students who are living in the dorm with the largest capacity.,"student.merge(lives_in).merge(dorm).loc[lambda x: x['student_capacity']==dorm['student_capacity'].max(), 'age'].mean()"
what is the average age of students who are living in the dorm with the largest capacity?,"student.merge(lives_in).merge(dorm).loc[lambda x: x['student_capacity']==dorm['student_capacity'].max(), 'age'].mean()"
find the total number of students living in the male dorm (with gender m).,"pd.merge(pd.merge(student, lives_in, on='stuid'), dorm, on='dormid').loc[lambda x: x['gender']=='m'].shape[0]"
what are the total number of students who are living in a male dorm?,"pd.merge(pd.merge(student, lives_in, on='stuid'), dorm, on='dormid').loc[lambda x: x['gender']=='m'].shape[0]"
find the number of female students (with f sex) living in smith hall,"pd.merge(pd.merge(student, lives_in, on='stuid'), dorm, on='dormid').loc[lambda x: (x['dorm_name']=='smith hall') & (x['sex']=='f'), :].shape[0]"
how many female students live in smith hall?,"pd.merge(pd.merge(student, lives_in, on='stuid'), dorm, on='dormid').loc[lambda x: (x['dorm_name']=='smith hall') & (x['sex']=='f'), :].shape[0]"
find the name of amenities smith hall dorm have.,"pd.merge(pd.merge(dorm[dorm['dorm_name']=='smith hall'], has_amenity, on='dormid'), dorm_amenity, on='amenid')['amenity_name']"
what are the names of the amenities that smith hall has?,"pd.merge(pd.merge(dorm[dorm['dorm_name']=='smith hall'], has_amenity, on='dormid'), dorm_amenity, on='amenid')['amenity_name']"
find the name of amenities smith hall dorm have. ordered the results by amenity names.,"pd.merge(pd.merge(dorm[dorm['dorm_name']=='smith hall'], has_amenity, on='dormid'), dorm_amenity, on='amenid').sort_values('amenity_name')['amenity_name']"
what amenities does smith hall have in alphabetical order?,"pd.merge(pd.merge(dorm[dorm['dorm_name']=='smith hall'], has_amenity, on='dormid'), dorm_amenity, on='amenid').sort_values('amenity_name')['amenity_name']"
find the name of amenity that is most common in all dorms.,"has_amenity.merge(dorm_amenity, on='amenid').groupby('amenid')['amenity_name'].count().reset_index().sort_values(by='amenity_name', ascending=false).iloc[0, 1]"
what is the most common amenity in the dorms?,"has_amenity.merge(dorm_amenity, on='amenid').groupby('amenid')['amenity_name'].count().reset_index().sort_values(by='amenity_name', ascending=false).iloc[0, 1]"
find the first name of students who are living in the dorm that has most number of amenities.,"student.merge(lives_in).loc[lambda x: x['dormid'].isin(dorm.merge(has_amenity).merge(dorm_amenity).groupby('dormid').size().sort_values().tail(1).index), 'fname']"
what are the first names of all students who live in the dorm with the most amenities?,"student.merge(lives_in).loc[lambda x: x['dormid'].isin(dorm.merge(has_amenity).merge(dorm_amenity).groupby('dormid').size().sort_values().tail(1).index), 'fname']"
find the name and capacity of the dorm with least number of amenities.,"(pd.merge(pd.merge(dorm, has_amenity, on='dormid'), dorm_amenity, on='amenid').groupby('dorm_name').agg({'student_capacity': 'first', 'amenity': 'count'}).sort_values('amenity').head(1))"
what is the name and capacity of the dorm with the fewest amount of amenities?,"(pd.merge(pd.merge(dorm, has_amenity, on='dormid'), dorm_amenity, on='amenid').groupby('dorm_name').agg({'student_capacity': 'first', 'amenity': 'count'}).sort_values('amenity').head(1))"
find the name of dorms that do not have amenity tv lounge.,"dorm['dorm_name'].iloc[~dorm['dormid'].isin(pd.merge(pd.merge(has_amenity, dorm_amenity, on='amenid'), dorm, on='dormid').loc[lambda x: x['amenity_name']=='tv lounge', 'dormid'])]"
what are the names of the dorm that does not have a tv lounge?,"dorm['dorm_name'].iloc[~dorm['dormid'].isin(pd.merge(pd.merge(has_amenity, dorm_amenity, on='amenid'), dorm, on='dormid').loc[lambda x: x['amenity_name']=='tv lounge', 'dormid'])]"
find the first and last name of students who are living in the dorms that have amenity tv lounge.,"student.merge(lives_in).loc[lambda x: x['dormid'].isin(has_amenity.merge(dorm_amenity.loc[lambda x: x['amenity_name']=='tv lounge']).dormid), ['fname', 'lname']]"
what are the first and last names of all students who are living in a dorm with a tv lounge?,"student.merge(lives_in).loc[lambda x: x['dormid'].isin(has_amenity.merge(dorm_amenity.loc[lambda x: x['amenity_name']=='tv lounge']).dormid), ['fname', 'lname']]"
find the first name and age of students who are living in the dorms that do not have amenity tv lounge.,"student.merge(lives_in).loc[~lives_in['dormid'].isin(has_amenity.merge(dorm_amenity.loc[lambda x: x['amenity_name'] == 'tv lounge'], on='amenid')['dormid']), ['fname', 'age']]"
what is the first name and age of every student who lives in a dorm with a tv lounge?,"student.merge(lives_in).loc[~lives_in['dormid'].isin(has_amenity.merge(dorm_amenity.loc[lambda x: x['amenity_name'] == 'tv lounge'], on='amenid')['dormid']), ['fname', 'age']]"
find the name of amenities of the dorm where the student with last name smith is living in.,"pd.merge(pd.merge(pd.merge(pd.merge(dorm, has_amenity, on='dormid'), dorm_amenity, on='amenid'), lives_in, on='dormid'), student, on='stuid').loc[lambda x: x['lname']=='smith', 'amenity_name']"
what are the amenities in the dorm that a student who has the last name of smith lives in?,"pd.merge(pd.merge(pd.merge(pd.merge(dorm, has_amenity, on='dormid'), dorm_amenity, on='amenid'), lives_in, on='dormid'), student, on='stuid').loc[lambda x: x['lname']=='smith', 'amenity_name']"
"find the emails and phone numbers of all the customers, ordered by email address and phone number.","customers[['email_address', 'phone_number']].sort_values(by=['email_address', 'phone_number'])"
"what are the emails and phone numbers of all customers, sorted by email address and phone number?","customers[['email_address', 'phone_number']].sort_values(by=['email_address', 'phone_number'])"
"which city has the least number of customers whose type code is ""good credit rating""?",customers.loc[lambda x: x['customer_type_code']=='good credit rating'].groupby('town_city').size().sort_values().head(1).index[0]
"return the city with the customer type code ""good credit rating"" that had the fewest customers.",customers.loc[lambda x: x['customer_type_code']=='good credit rating'].groupby('town_city').size().sort_values().head(1).index[0]
list the name of all products along with the number of complaints that they have received.,"pd.merge(products, complaints, on='product_id').groupby('product_name').size().reset_index(name='count')"
"what are all the different product names, and how many complains has each received?","pd.merge(products, complaints, on='product_id').groupby('product_name').size().reset_index(name='count')"
find the emails of customers who has filed a complaints of the product with the most complaints.,"pd.merge(customers, complaints, on='customer_id').groupby('customer_id')['email_address'].count().sort_values().head(1)"
what are the emails of customers who have filed complaints on the product which has had the greatest number of complaints?,"pd.merge(customers, complaints, on='customer_id').groupby('customer_id')['email_address'].count().sort_values().head(1)"
which products has been complained by the customer who has filed least amount of complaints?,"pd.merge(pd.merge(products, complaints, on='product_id'), customers, on='customer_id').groupby('customer_id')['product_name'].nunique().sort_values().head(1).index[0]"
return the names of products that have had complaints filed by the customer who has filed the fewest complaints.,"pd.merge(pd.merge(products, complaints, on='product_id'), customers, on='customer_id').groupby('customer_id')['product_name'].nunique().sort_values().head(1).index[0]"
what is the phone number of the customer who has filed the most recent complaint?,"customers.merge(complaints, on='customer_id').sort_values('date_complaint_raised', ascending=false).iloc[0]['phone_number']"
return the phone number of the customer who filed the complaint that was raised most recently.,"customers.merge(complaints, on='customer_id').sort_values('date_complaint_raised', ascending=false).iloc[0]['phone_number']"
find the email and phone number of the customers who have never filed a complaint before.,"customers.loc[~customers['customer_id'].isin(complaints['customer_id']), ['email_address', 'phone_number']]"
what are the emails and phone numbers of custoemrs who have never filed a complaint?,"customers.loc[~customers['customer_id'].isin(complaints['customer_id']), ['email_address', 'phone_number']]"
find the phone number of all the customers and staff.,"pd.concat([customers['phone_number'], staff['phone_number']]).drop_duplicates()"
what are the phone numbers of all customers and all staff members?,"pd.concat([customers['phone_number'], staff['phone_number']]).drop_duplicates()"
"what is the description of the product named ""chocolate""?","products.loc[lambda x: x['product_name']=='chocolate', 'product_description']"
"return the description of the product called ""chocolate"".","products.loc[lambda x: x['product_name']=='chocolate', 'product_description']"
find the name and category of the most expensive product.,"products[['product_name', 'product_category_code']].nlargest(1, 'product_price')"
what is the name and category code of the product with the highest price?,"products[['product_name', 'product_category_code']].nlargest(1, 'product_price')"
find the prices of products which has never received a single complaint.,"products.loc[~products['product_id'].isin(complaints['product_id']), 'product_price']"
what are the prices of products that have never gotten a complaint?,"products.loc[~products['product_id'].isin(complaints['product_id']), 'product_price']"
what is the average price of the products for each category?,products.groupby('product_category_code')['product_price'].mean()
return the average price of products that have each category code.,products.groupby('product_category_code')['product_price'].mean()
find the last name of the staff member who processed the complaint of the cheapest product.,"pd.merge(pd.merge(staff, complaints, on='staff_id'), products, on='product_id').sort_values('product_price').iloc[0]['last_name']"
what is the last name of the staff member in charge of the complaint on the product with the lowest price?,"pd.merge(pd.merge(staff, complaints, on='staff_id'), products, on='product_id').sort_values('product_price').iloc[0]['last_name']"
which complaint status has more than 3 records on file?,complaints.groupby('complaint_status_code').filter(lambda x: len(x) > 3)['complaint_status_code'].unique()
return complaint status codes have more than 3 corresponding complaints?,complaints.groupby('complaint_status_code').filter(lambda x: len(x) > 3)['complaint_status_code'].unique()
"find the last name of the staff whose email address contains ""wrau"".","staff.loc[lambda x: x['email_address'].str.contains('wrau', case=false), 'last_name']"
"what are the last names of staff with email addressed containing the substring ""wrau""?","staff.loc[lambda x: x['email_address'].str.contains('wrau', case=false), 'last_name']"
how many customers are there in the customer type with the most customers?,customers.groupby('customer_type_code').size().sort_values(ascending=false).iloc[[0]].reset_index(drop=true)
count the number of customers that have the customer type that is most common.,customers.groupby('customer_type_code').size().sort_values(ascending=false).iloc[[0]].reset_index(drop=true)
what is the last name of the staff who has handled the first ever complaint?,"pd.merge(staff, complaints, on='staff_id').sort_values('date_complaint_raised').iloc[0]['last_name']"
return the last name of the staff member who handled the complaint with the earliest date raised.,"pd.merge(staff, complaints, on='staff_id').sort_values('date_complaint_raised').iloc[0]['last_name']"
how many distinct complaint type codes are there in the database?,complaints['complaint_type_code'].nunique()
count the number of different complaint type codes.,complaints['complaint_type_code'].nunique()
"find the address line 1 and 2 of the customer with email ""vbogisich@example.org"".","customers.loc[customers['email_address'] == ""vbogisich@example.org"", ['address_line_1', 'address_line_2']]"
"what are lines 1 and 2 of the addressed of the customer with the email ""vbogisich@example.org""?","customers.loc[customers['email_address'] == ""vbogisich@example.org"", ['address_line_1', 'address_line_2']]"
find the number of complaints with product failure type for each complaint status.,complaints.loc[lambda x: x['complaint_type_code']=='product failure'].groupby('complaint_status_code').size().reset_index(name='count')
"of complaints with the type code ""product failure"", how many had each different status code?",complaints.loc[lambda x: x['complaint_type_code']=='product failure'].groupby('complaint_status_code').size().reset_index(name='count')
what is first names of the top 5 staff who have handled the greatest number of complaints?,staff.merge(complaints).groupby('staff_id')['first_name'].agg(['count']).sort_values('count').head(5)
return the first names of the 5 staff members who have handled the most complaints.,staff.merge(complaints).groupby('staff_id')['first_name'].agg(['count']).sort_values('count').head(5)
which state has the most customers?,customers.groupby('state').size().sort_values().index[0]
give the state that has the most customers.,customers.groupby('state').size().sort_values().index[0]
how many submissions are there?,len(submission)
count the number of submissions.,len(submission)
list the authors of submissions in ascending order of scores.,submission.sort_values('scores')['author']
find the author for each submission and list them in ascending order of submission score.,submission.sort_values('scores')['author']
what are the authors of submissions and their colleges?,"submission[['author', 'college']]"
"for each submission, show the author and their affiliated college.","submission[['author', 'college']]"
"show the names of authors from college ""florida"" or ""temple""","submission.loc[lambda x: x['college'].isin(['florida', 'temple']), 'author']"
"which authors with submissions are from college ""florida"" or ""temple""?","submission.loc[lambda x: x['college'].isin(['florida', 'temple']), 'author']"
what is the average score of submissions?,submission['scores'].mean()
compute the average score of submissions.,submission['scores'].mean()
what is the author of the submission with the highest score?,"submission.sort_values('scores', ascending=false).iloc[0]['author']"
find the author who achieved the highest score in a submission.,"submission.sort_values('scores', ascending=false).iloc[0]['author']"
show different colleges along with the number of authors of submission from each college.,submission.groupby('college').size().reset_index(name='count')
"for each college, return the college name and the count of authors with submissions from that college.",submission.groupby('college').size().reset_index(name='count')
show the most common college of authors of submissions.,submission.groupby('college').size().nlargest(1).index[0]
which college has the most authors with submissions?,submission.groupby('college').size().nlargest(1).index[0]
show the colleges that have both authors with submission score larger than 90 and authors with submission score smaller than 80.,"submission.loc[lambda x: x['scores'] > 90, 'college'].intersect(submission.loc[lambda x: x['scores'] < 80, 'college'])"
which colleges have both authors with submission score above 90 and authors with submission score below 80?,"submission.loc[lambda x: x['scores'] > 90, 'college'].intersect(submission.loc[lambda x: x['scores'] < 80, 'college'])"
show the authors of submissions and the acceptance results of their submissions.,"pd.merge(acceptance, submission, on='submission_id')[['author', 'result']]"
"for each submission, find its author and acceptance result.","pd.merge(acceptance, submission, on='submission_id')[['author', 'result']]"
show the result of the submission with the highest score.,"acceptance.merge(submission, on='submission_id').sort_values('scores', ascending=false).iloc[0]['result']"
which submission received the highest score in acceptance result. show me the result.,"acceptance.merge(submission, on='submission_id').sort_values('scores', ascending=false).iloc[0]['result']"
show each author and the number of workshops they submitted to.,"pd.merge(acceptance, submission, on='submission_id').groupby('author')['workshop_id'].nunique()"
how many workshops did each author submit to? return the author name and the number of workshops.,"pd.merge(acceptance, submission, on='submission_id').groupby('author')['workshop_id'].nunique()"
show the authors who have submissions to more than one workshop.,"pd.merge(acceptance, submission, on='submission_id').groupby('author').filter(lambda x: x['workshop_id'].nunique() > 1)['author'].unique()"
which authors have submitted to more than one workshop?,"pd.merge(acceptance, submission, on='submission_id').groupby('author').filter(lambda x: x['workshop_id'].nunique() > 1)['author'].unique()"
show the date and venue of each workshop in ascending alphabetical order of the venue.,"workshop[['date', 'venue']].sort_values('venue')"
sort the each workshop in alphabetical order of the venue. return the date and venue of each workshop.,"workshop[['date', 'venue']].sort_values('venue')"
list the authors who do not have submission to any workshop.,"submission.loc[~submission['submission_id'].isin(acceptance['submission_id']), 'author']"
which authors did not submit to any workshop?,"submission.loc[~submission['submission_id'].isin(acceptance['submission_id']), 'author']"
find the number of investors in total.,investors['investor_id'].count()
show all investor details.,investors['investor_details']
show all distinct lot details.,lots['lot_details'].unique()
show the maximum amount of transaction.,transactions['amount_of_transaction'].max()
show all date and share count of transactions.,"transactions[['date_of_transaction', 'share_count']]"
what is the total share of transactions?,transactions['share_count'].sum()
show all transaction ids with transaction code 'pur'.,"transactions.loc[lambda x: x['transaction_type_code']=='pur', 'transaction_id']"
"show all dates of transactions whose type code is ""sale"".","transactions.loc[lambda x: x['transaction_type_code']=='sale', 'date_of_transaction']"
"show the average amount of transactions with type code ""sale"".","transactions.loc[lambda x: x['transaction_type_code']=='sale', 'amount_of_transaction'].mean()"
"show the description of transaction type with code ""pur"".","ref_transaction_types.loc[lambda x: x['transaction_type_code']=='pur', 'transaction_type_description']"
"show the minimum amount of transactions whose type code is ""pur"" and whose share count is bigger than 50.","transactions.loc[(transactions['transaction_type_code']=='pur') & (transactions['share_count']>50), 'amount_of_transaction'].min()"
show the maximum share count of transactions where the amount is smaller than 10000,"transactions.loc[lambda x: x['amount_of_transaction'] < 10000, 'share_count'].max()"
show the dates of transactions if the share count is bigger than 100 or the amount is bigger than 1000.,"transactions.loc[(transactions['share_count'] > 100) | (transactions['amount_of_transaction'] > 1000), 'date_of_transaction']"
show the transaction type descriptions and dates if the share count is smaller than 10.,"pd.merge(ref_transaction_types, transactions, on='transaction_type_code').loc[lambda x: x['share_count'] < 10, ['transaction_type_description','date_of_transaction']]"
show details of all investors if they make any transaction with share count greater than 100.,"pd.merge(investors, transactions, on='investor_id').loc[lambda x: x['share_count']>100, 'investor_details']"
how many distinct transaction types are used in the transactions?,transactions['transaction_type_code'].nunique()
return the lot details and investor ids.,"lots[['lot_details', 'investor_id']]"
"return the lot details of lots that belong to investors with details ""l""?","pd.merge(investors, lots, on='investor_id').loc[lambda x: x['investor_details']=='l', 'lot_details']"
what are the purchase details of transactions with amount bigger than 10000?,"purchases.merge(transactions, left_on='purchase_transaction_id', right_on='transaction_id').query('amount_of_transaction > 10000')['purchase_details']"
what are the sale details and dates of transactions with amount smaller than 3000?,"pd.merge(sales, transactions, left_on='sales_transaction_id', right_on='transaction_id').loc[lambda x: x['amount_of_transaction']<3000, ['sales_details', 'date_of_transaction']]"
what are the lot details of lots associated with transactions with share count smaller than 50?,"pd.merge(pd.merge(lots, transactions_lots, on='lot_id'), transactions, on='transaction_id').loc[lambda x: x['share_count']<50, 'lot_details']"
"what are the lot details of lots associated with transactions whose share count is bigger than 100 and whose type code is ""pur""?","pd.merge(pd.merge(lots, transactions_lots, on='lot_id'), transactions, on='transaction_id').loc[lambda x: (x['share_count']>100) & (x['transaction_type_code']=='pur'), 'lot_details']"
show the average transaction amount for different transaction types.,transactions.groupby('transaction_type_code')['amount_of_transaction'].mean()
show the maximum and minimum share count of different transaction types.,"transactions.groupby('transaction_type_code').agg({'share_count': ['max', 'min']}).reset_index()"
show the average share count of transactions for different investors.,transactions.groupby('investor_id')['share_count'].mean()
"show the average share count of transactions each each investor, ordered by average share count.",transactions.groupby('investor_id')['share_count'].mean().sort_values()
show the average amount of transactions for different investors.,transactions.groupby('investor_id')['amount_of_transaction'].mean()
show the average amount of transactions for different lots.,"pd.merge(transactions, transactions_lots, on='transaction_id').groupby('lot_id').agg(avg_amount_of_transaction=('amount_of_transaction', 'mean'))"
"show the average amount of transactions for different lots, ordered by average amount of transactions.","pd.merge(transactions, transactions_lots, on='transaction_id').groupby('lot_id')['amount_of_transaction'].mean().sort_values().reset_index()"
"show the number of transactions with transaction type code ""sale"" for different investors if it is larger than 0.",transactions.loc[transactions['transaction_type_code']=='sale'].groupby('investor_id').size().reset_index(name='count')
show the number of transactions for different investors.,transactions.groupby('investor_id').size().reset_index(name='count')
show the transaction type code that occurs the fewest times.,transactions.groupby('transaction_type_code').size().reset_index(name='counts').sort_values('counts').iloc[0]['transaction_type_code']
show the transaction type code that occurs the most frequently.,transactions.groupby('transaction_type_code').size().sort_values(ascending=false).index[0]
show the description of the transaction type that occurs most frequently.,"pd.merge(ref_transaction_types, transactions, on='transaction_type_code').groupby('transaction_type_code')['transaction_type_description'].count().nlargest(1).index.item()"
show the id and details of the investor that has the largest number of transactions.,"pd.merge(investors, transactions, on='investor_id').groupby('investor_id')['investor_details'].first().reset_index().sort_values(by=pd.merge(investors, transactions, on='investor_id').groupby('investor_id').size(), ascending=false).iloc[0]"
show the id and details for the investors who have the top 3 number of transactions.,"pd.merge(investors, transactions, on='investor_id').groupby(['investor_id', 'investor_details']).size().reset_index(name='count').sort_values('count', ascending=false).head(3)[['investor_id', 'investor_details']]"
show the ids of the investors who have at least two transactions.,"transactions.merge(investors, on='investor_id').groupby('investor_id').filter(lambda x: len(x)>=2)['investor_id'].unique()"
"show the ids and details of the investors who have at least two transactions with type code ""sale"".","investors.merge(transactions[transactions['transaction_type_code'] == 'sale'], on='investor_id').groupby('investor_id')['investor_details'].first().loc[lambda x: x.groupby('investor_id').transform('count').ge(2)]"
what are the dates of transactions with at least 100 share count or amount bigger than 100?,"transactions.loc[(transactions['share_count']>=100) | (transactions['amount_of_transaction']>=100), 'date_of_transaction']"
what are the details of all sales and purchases?,"pd.concat([sales['sales_details'], purchases['purchase_details']])"
what are the details of the lots which are not used in any transactions?,lots['lot_details'].loc[~lots['lot_id'].isin(transactions_lots['lot_id'])]
how many available hotels are there in total?,hotels.shape[0]
find the total number of available hotels.,hotels.shape[0]
what are the price ranges of hotels?,hotels['price_range']
tell me the price ranges for all the hotels.,hotels['price_range']
show all distinct location names.,locations['location_name'].unique()
what are the distinct location names?,locations['location_name'].unique()
show the names and details of all the staff members.,"staff[['name', 'other_details']]"
what is the name and detail of each staff member?,"staff[['name', 'other_details']]"
show details of all visitors.,visitors['tourist_details']
what is the detail of each visitor?,visitors['tourist_details']
show the price ranges of hotels with 5 star ratings.,"hotels.loc[lambda x: x['star_rating_code'] == '5', 'price_range']"
what are the price ranges of five star hotels?,"hotels.loc[lambda x: x['star_rating_code'] == '5', 'price_range']"
show the average price range of hotels that have 5 star ratings and allow pets.,"hotels.loc[(hotels['star_rating_code'] == '5') & (hotels['pets_allowed_yn'] == 1), 'price_range'].mean()"
what is the average price range of five star hotels that allow pets?,"hotels.loc[(hotels['star_rating_code'] == '5') & (hotels['pets_allowed_yn'] == 1), 'price_range'].mean()"
"what is the address of the location ""uk gallery""?","locations.loc[lambda x: x['location_name']=='uk gallery', 'address']"
"find the address of the location named ""uk gallery"".","locations.loc[lambda x: x['location_name']=='uk gallery', 'address']"
what is the detail of the location uk gallery?,"locations.loc[lambda x: x['location_name']=='uk gallery', 'other_details']"
"return the detail of the location named ""uk gallery"".","locations.loc[lambda x: x['location_name']=='uk gallery', 'other_details']"
"which location names contain the word ""film""?","locations.loc[locations['location_name'].str.contains('film', case=false), 'location_name']"
"find all the locations whose names contain the word ""film"".","locations.loc[locations['location_name'].str.contains('film', case=false), 'location_name']"
how many distinct names are associated with all the photos?,photos['name'].nunique()
count the number of distinct names associated with the photos.,photos['name'].nunique()
what are the distinct visit dates?,visits['visit_date'].unique()
find all the distinct visit dates.,visits['visit_date'].unique()
what are the names of the tourist attractions that can be accessed by bus?,"tourist_attractions.loc[lambda x: x['how_to_get_there']=='bus', 'name']"
which tourist attractions can we get to by bus? tell me the names of the attractions.,"tourist_attractions.loc[lambda x: x['how_to_get_there']=='bus', 'name']"
what are the names and opening hours of the tourist attractions that can be accessed by bus or walk?,"tourist_attractions.loc[tourist_attractions['how_to_get_there'].isin(['bus', 'walk']), ['name', 'opening_hours']]"
find the names and opening hours of the tourist attractions that we get to by bus or walk.,"tourist_attractions.loc[tourist_attractions['how_to_get_there'].isin(['bus', 'walk']), ['name', 'opening_hours']]"
what are the star rating descriptions of the hotels with price above 10000?,"pd.merge(hotels, ref_hotel_star_ratings, on='star_rating_code').loc[lambda x: x['price_range']>10000, 'star_rating_description']"
give me the star rating descriptions of the hotels that cost more than 10000.,"pd.merge(hotels, ref_hotel_star_ratings, on='star_rating_code').loc[lambda x: x['price_range']>10000, 'star_rating_description']"
what are the details and opening hours of the museums?,"pd.merge(museums, tourist_attractions, left_on='museum_id', right_on='tourist_attraction_id')[['museum_details', 'opening_hours']]"
give me the detail and opening hour for each museum.,"pd.merge(museums, tourist_attractions, left_on='museum_id', right_on='tourist_attraction_id')[['museum_details', 'opening_hours']]"
"what is the name of the tourist attraction that is associated with the photo ""game1""?","pd.merge(photos, tourist_attractions, on='tourist_attraction_id').loc[lambda x: x['name_x']=='game1', 'name_y']"
"which tourist attraction is associated with the photo ""game1""? return its name.","pd.merge(photos, tourist_attractions, on='tourist_attraction_id').loc[lambda x: x['name_x']=='game1', 'name_y']"
"what are the names and descriptions of the photos taken at the tourist attraction ""film festival""?","pd.merge(photos, tourist_attractions, on='tourist_attraction_id').loc[lambda x: x['name']=='film festival', ['name', 'description']]"
"find the names and descriptions of the photos taken at the tourist attraction called ""film festival"".","pd.merge(photos, tourist_attractions, on='tourist_attraction_id').loc[lambda x: x['name']=='film festival', ['name', 'description']]"
what are the details and ways to get to tourist attractions related to royal family?,"pd.merge(royal_family, tourist_attractions, left_on='royal_family_id', right_on='tourist_attraction_id')[['royal_family_details', 'how_to_get_there']]"
which tourist attractions are related to royal family? tell me their details and how we can get there.,"pd.merge(royal_family, tourist_attractions, left_on='royal_family_id', right_on='tourist_attraction_id')[['royal_family_details', 'how_to_get_there']]"
what are the details of the shops that can be accessed by walk?,"pd.merge(shops, tourist_attractions, left_on='shop_id', right_on='tourist_attraction_id').query('how_to_get_there == ""walk""')['shop_details']"
find the details of the shops that can be reached by walk.,"pd.merge(shops, tourist_attractions, left_on='shop_id', right_on='tourist_attraction_id').query('how_to_get_there == ""walk""')['shop_details']"
"what is the name of the staff that is in charge of the attraction named ""us museum""?","staff.merge(tourist_attractions.loc[lambda x: x['name']=='us museum'], on='tourist_attraction_id')['name_x']"
"tell me the name of the staff in charge of the attraction called ""us museum"".","staff.merge(tourist_attractions.loc[lambda x: x['name']=='us museum'], on='tourist_attraction_id')['name_x']"
what are the details of the markets that can be accessed by walk or bus?,"street_markets.merge(tourist_attractions.loc[lambda x: x['how_to_get_there'].isin(['walk','bus'])], left_on='market_id', right_on='tourist_attraction_id')['market_details']"
find the details of all the markets that are accessible by walk or bus.,"street_markets.merge(tourist_attractions.loc[lambda x: x['how_to_get_there'].isin(['walk','bus'])], left_on='market_id', right_on='tourist_attraction_id')['market_details']"
what are the visit date and details of the visitor whose detail is 'vincent'?,"visitors.merge(visits, on='tourist_id').loc[lambda x: x['tourist_details']=='vincent', ['visit_date', 'visit_details']]"
find the visit date and details of the tourist whose detail is 'vincent',"visitors.merge(visits, on='tourist_id').loc[lambda x: x['tourist_details']=='vincent', ['visit_date', 'visit_details']]"
which tourist attractions does the visitor with detail 'vincent' visit?,"pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='vincent', 'name']"
show the tourist attractions visited by the tourist whose detail is 'vincent'.,"pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='vincent', 'name']"
what are the names of the tourist attractions and the dates when the tourists named vincent or vivian visited there?,"tourist_attractions.merge(visits.merge(visitors[visitors['tourist_details'].isin(['vincent', 'vivian'])], on='tourist_id').drop('tourist_id', axis=1), on='tourist_attraction_id')[['name', 'visit_date']]"
"for each tourist attraction, return its name and the date when the tourists named vincent or vivian visited there.","tourist_attractions.merge(visits.merge(visitors[visitors['tourist_details'].isin(['vincent', 'vivian'])], on='tourist_id').drop('tourist_id', axis=1), on='tourist_attraction_id')[['name', 'visit_date']]"
show the average price of hotels for each star rating code.,hotels.groupby('star_rating_code')['price_range'].mean()
what is the average price range of hotels for each each star rating code?,hotels.groupby('star_rating_code')['price_range'].mean()
show the average price of hotels for different pet policy.,hotels.groupby('pets_allowed_yn')['price_range'].mean().reset_index()
what are the average prices of hotels grouped by their pet policy.,hotels.groupby('pets_allowed_yn')['price_range'].mean().reset_index()
"show the id and star rating of each hotel, ordered by its price from low to high.","hotels[['hotel_id', 'star_rating_code']].sort_values('price_range')"
find the id and star rating of each hotel and sort them in increasing order of price.,"hotels[['hotel_id', 'star_rating_code']].sort_values('price_range')"
show the details of the top 3 most expensive hotels.,"hotels.sort_values('price_range', ascending=false)['other_hotel_details'][:3]"
what are the details of the three most expensive hotels?,"hotels.sort_values('price_range', ascending=false)['other_hotel_details'][:3]"
show the details and star ratings of the 3 least expensive hotels.,"hotels[['other_hotel_details', 'star_rating_code', 'price_range']].sort_values('price_range').head(3)[['other_hotel_details', 'star_rating_code']]"
what are the details and star ratings of the three hotels with the lowest price ranges?,"hotels[['other_hotel_details', 'star_rating_code', 'price_range']].sort_values('price_range').head(3)[['other_hotel_details', 'star_rating_code']]"
show the transportation method most people choose to get to tourist attractions.,tourist_attractions.groupby('how_to_get_there')['how_to_get_there'].count().sort_values(ascending=false).head(1).index.values[0]
which transportation method is used the most often to get to tourist attractions?,tourist_attractions.groupby('how_to_get_there')['how_to_get_there'].count().sort_values(ascending=false).head(1).index.values[0]
show the description and code of the attraction type most tourist attractions belong to.,"pd.merge(ref_attraction_types, tourist_attractions, on='attraction_type_code').groupby('attraction_type_code')['attraction_type_description'].agg(lambda x: x.iloc[0]).sort_values(ascending=false).head(1).reset_index().drop(columns=['attraction_type_code'])"
which attraction type does the most tourist attractions belong to? tell me its  attraction type description and code.,"pd.merge(ref_attraction_types, tourist_attractions, on='attraction_type_code').groupby('attraction_type_code')['attraction_type_description'].agg(lambda x: x.iloc[0]).sort_values(ascending=false).head(1).reset_index().drop(columns=['attraction_type_code'])"
show different ways to get to attractions and the number of attractions that can be accessed in the corresponding way.,tourist_attractions.groupby('how_to_get_there').size().reset_index(name='count')
"list all the possible ways to get to attractions, together with the number of attractions accessible by these methods.",tourist_attractions.groupby('how_to_get_there').size().reset_index(name='count')
"show different tourist attractions' names, ids, and the corresponding number of visits.","pd.merge(tourist_attractions, visits, on='tourist_attraction_id').groupby(['name', 'tourist_attraction_id']).size().reset_index(name='count')"
"what are the name, id and the corresponding number of visits for each  tourist attraction?","pd.merge(tourist_attractions, visits, on='tourist_attraction_id').groupby(['name', 'tourist_attraction_id']).size().reset_index(name='count')"
show the names and ids of tourist attractions that are visited at least two times.,"pd.merge(tourist_attractions, visits, on='tourist_attraction_id').groupby('tourist_attraction_id').filter(lambda x: len(x) >= 2)[['name', 'tourist_attraction_id']]"
which tourist attractions are visited at least twice? give me their names and ids.,"pd.merge(tourist_attractions, visits, on='tourist_attraction_id').groupby('tourist_attraction_id').filter(lambda x: len(x) >= 2)[['name', 'tourist_attraction_id']]"
show the names and ids of tourist attractions that are visited at most once.,"pd.merge(tourist_attractions, visits, on='tourist_attraction_id').groupby('tourist_attraction_id').filter(lambda x: x['tourist_attraction_id'].count()<=1)[['name', 'tourist_attraction_id']]"
what are the names and ids of the tourist attractions that are visited at most once?,"pd.merge(tourist_attractions, visits, on='tourist_attraction_id').groupby('tourist_attraction_id').filter(lambda x: x['tourist_attraction_id'].count()<=1)[['name', 'tourist_attraction_id']]"
what are the names of tourist attractions that can be reached by walk or is at address 660 shea crescent?,"pd.merge(locations, tourist_attractions, on='location_id').loc[(locations['address']=='660 shea crescent') | (tourist_attractions['how_to_get_there']=='walk'), 'name']"
find the names of the tourist attractions that is either accessible by walk or at address 660 shea crescent.,"pd.merge(locations, tourist_attractions, on='location_id').loc[(locations['address']=='660 shea crescent') | (tourist_attractions['how_to_get_there']=='walk'), 'name']"
what are the names of the tourist attractions that have parking or shopping as their feature details?,"(pd.merge(pd.merge(tourist_attractions, tourist_attraction_features, on='tourist_attraction_id'), features, on='feature_id').loc[lambda x: x['feature_details']=='park', 'name'].append(pd.merge(pd.merge(tourist_attractions, tourist_attraction_features, on='tourist_attraction_id'), features, on='feature_id').loc[lambda x: x['feature_details']=='shopping', 'name'])).unique()"
find the tourist attractions that have parking or shopping as their feature details. what are the names of the attractions?,"(pd.merge(pd.merge(tourist_attractions, tourist_attraction_features, on='tourist_attraction_id'), features, on='feature_id').loc[lambda x: x['feature_details']=='park', 'name'].append(pd.merge(pd.merge(tourist_attractions, tourist_attraction_features, on='tourist_attraction_id'), features, on='feature_id').loc[lambda x: x['feature_details']=='shopping', 'name'])).unique()"
what are the names of tourist attractions that can be reached by bus or is at address 254 ottilie junction?,"pd.merge(locations, tourist_attractions, on='location_id').loc[lambda x: (x['address'] == '254 ottilie junction') | (x['how_to_get_there'] == 'bus'), 'name']"
find the names of the tourist attractions that is either accessible by bus or at address 254 ottilie junction.,"pd.merge(locations, tourist_attractions, on='location_id').loc[lambda x: (x['address'] == '254 ottilie junction') | (x['how_to_get_there'] == 'bus'), 'name']"
what are the names of the tourist attractions vincent and marcelle visit?,"pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='vincent', 'name'].unique() & pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='marcelle', 'name'].unique()"
which tourist attractions do the tourists vincent and marcelle visit? tell me the names of the attractions.,"pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='vincent', 'name'].unique() & pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='marcelle', 'name'].unique()"
what are the names of tourist attraction that alison visited but rosalind did not visit?,"pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='alison', 'name'].unique().difference(pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='rosalind', 'name'].unique())"
find the the names of the tourist attractions that the tourist named alison visited but rosalind did not visit.,"pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='alison', 'name'].unique().difference(pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='rosalind', 'name'].unique())"
how many tourists did not make any visit?,"visitors.loc[~visitors['tourist_id'].isin(visits['tourist_id']), :].shape[0]"
count the number of tourists who did not visit any place.,"visitors.loc[~visitors['tourist_id'].isin(visits['tourist_id']), :].shape[0]"
how many video games exist?,video_games.shape[0]
how many video games do you have?,video_games.shape[0]
how many video game types exist?,video_games['gtype'].nunique()
what is the count of different game types?,video_games['gtype'].nunique()
show all video game types.,video_games['gtype'].unique()
what are the different types of video games?,video_games['gtype'].unique()
show all video games and their types in the order of their names.,"video_games[['gname', 'gtype']].sort_values('gname')"
what are the names of all the video games and their types in alphabetical order?,"video_games[['gname', 'gtype']].sort_values('gname')"
show all video games with type collectible card game.,"video_games.loc[lambda x: x['gtype']==""collectible card game"", 'gname']"
what are the names of all video games that are collectible cards?,"video_games.loc[lambda x: x['gtype']==""collectible card game"", 'gname']"
what is the type of video game call of destiny.,"video_games.loc[lambda x: x['gname']=='call of destiny', 'gtype']"
what type of game is call of destiny?,"video_games.loc[lambda x: x['gname']=='call of destiny', 'gtype']"
how many video games have type massively multiplayer online game?,(video_games['gtype'] == 'massively multiplayer online game').sum()
count the number of video games with massively multiplayer online game type .,(video_games['gtype'] == 'massively multiplayer online game').sum()
show all video game types and the number of video games in each type.,video_games.groupby('gtype').size()
what are the types of video games and how many are in each type?,video_games.groupby('gtype').size()
which game type has most number of games?,video_games.groupby('gtype').size().sort_values(ascending=false).index[0]
what type has the most games?,video_games.groupby('gtype').size().sort_values(ascending=false).index[0]
which game type has least number of games?,video_games.groupby('gtype').size().sort_values().index[0]
what is the type with the fewest games?,video_games.groupby('gtype').size().sort_values().index[0]
show ids for all students who live in chi.,"student.loc[lambda x: x['city_code']=='chi', 'stuid']"
what are the ids of all students who live in chi?,"student.loc[lambda x: x['city_code']=='chi', 'stuid']"
show ids for all students who have advisor 1121.,"student.loc[lambda x: x['advisor'] == 1121, 'stuid']"
what are the ids of all students who have advisor number 1121?,"student.loc[lambda x: x['advisor'] == 1121, 'stuid']"
show first name for all students with major 600.,"student.loc[lambda x: x['major']==600, 'fname']"
what are the first names for all students who are from the major numbered 600?,"student.loc[lambda x: x['major']==600, 'fname']"
"show the average, minimum, and maximum age for different majors.","student.groupby('major')['age'].agg(['mean', 'min', 'max'])"
"what are the average, minimum, and max ages for each of the different majors?","student.groupby('major')['age'].agg(['mean', 'min', 'max'])"
show all advisors who have at least two students.,student.groupby('advisor').filter(lambda x: len(x)>=2)['advisor'].unique()
what are the advisors,student.groupby('advisor').filter(lambda x: len(x)>=2)['advisor'].unique()
how many sports do we have?,sportsinfo['sportname'].nunique()
how many different types of sports do we offer?,sportsinfo['sportname'].nunique()
how many students play sports?,sportsinfo['stuid'].nunique()
how many different students are involved in sports?,sportsinfo['stuid'].nunique()
list ids for all student who are on scholarship.,"sportsinfo.loc[lambda x: x['onscholarship']=='y', 'stuid']"
what are the ids for all sporty students who are on scholarship?,"sportsinfo.loc[lambda x: x['onscholarship']=='y', 'stuid']"
show last names for all student who are on scholarship.,"pd.merge(sportsinfo[sportsinfo['onscholarship']=='y'], student, on='stuid')['lname']"
what are the last names for all scholarship students?,"pd.merge(sportsinfo[sportsinfo['onscholarship']=='y'], student, on='stuid')['lname']"
how many games are played for all students?,sportsinfo['gamesplayed'].sum()
what is the total number of games played?,sportsinfo['gamesplayed'].sum()
how many games are played for all football games by students on scholarship?,"sportsinfo.loc[(sportsinfo['sportname'] == 'football') & (sportsinfo['onscholarship'] == 'y'), 'gamesplayed'].sum()"
what is the total number of all football games played by scholarship students?,"sportsinfo.loc[(sportsinfo['sportname'] == 'football') & (sportsinfo['onscholarship'] == 'y'), 'gamesplayed'].sum()"
show all sport name and the number of students.,sportsinfo.groupby('sportname').size().reset_index(name='count(*)')
how many students play each sport?,sportsinfo.groupby('sportname').size().reset_index(name='count(*)')
show all student ids with the number of sports and total number of games played,"sportsinfo.groupby('stuid').agg(num_entries=('stuid', 'count'), total_gamesplayed=('gamesplayed', 'sum'))"
what are the ids of all students along with how many sports and games did they play?,"sportsinfo.groupby('stuid').agg(num_entries=('stuid', 'count'), total_gamesplayed=('gamesplayed', 'sum'))"
show all student ids with more than total 10 hours per week on all sports played.,sportsinfo.groupby('stuid').filter(lambda x: x['hoursperweek'].sum() > 10)['stuid'].unique()
what are the student ids for everybody who worked for more than 10 hours per week on all sports?,sportsinfo.groupby('stuid').filter(lambda x: x['hoursperweek'].sum() > 10)['stuid'].unique()
what is the first name and last name of the student who have most number of sports?,"sportsinfo.merge(student, on='stuid').groupby(['fname', 'lname']).size().reset_index(name='count').sort_values(by='count', ascending=false).head(1)[['fname', 'lname']]"
what is the first and last name of the student who played the most sports?,"sportsinfo.merge(student, on='stuid').groupby(['fname', 'lname']).size().reset_index(name='count').sort_values(by='count', ascending=false).head(1)[['fname', 'lname']]"
which sport has most number of students on scholarship?,"sportsinfo.query(""onscholarship == 'y'"").groupby('sportname').size().sort_values(ascending=false).index[0]"
what is the sport with the most scholarship students?,"sportsinfo.query(""onscholarship == 'y'"").groupby('sportname').size().sort_values(ascending=false).index[0]"
show student ids who don't have any sports.,"student.loc[~student['stuid'].isin(sportsinfo['stuid']), 'stuid']"
what are the ids of all students who don't play sports?,"student.loc[~student['stuid'].isin(sportsinfo['stuid']), 'stuid']"
show student ids who are on scholarship and have major 600.,"student.loc[lambda x: x['major']==600, 'stuid'].isin(sportsinfo.loc[lambda x: x['onscholarship']=='y', 'stuid']).astype(int).loc[lambda x: x==1].index.values"
what are the student ids for those on scholarship in major number 600?,"student.loc[lambda x: x['major']==600, 'stuid'].isin(sportsinfo.loc[lambda x: x['onscholarship']=='y', 'stuid']).astype(int).loc[lambda x: x==1].index.values"
show student ids who are female and play football.,"pd.merge(student.loc[lambda x: x['sex']=='f', ['stuid']], sportsinfo.loc[lambda x: x['sportname']=='football', ['stuid']])['stuid']"
what are the ids of all female students who play football?,"pd.merge(student.loc[lambda x: x['sex']=='f', ['stuid']], sportsinfo.loc[lambda x: x['sportname']=='football', ['stuid']])['stuid']"
show all male student ids who don't play football.,"student.loc[lambda x: x['sex']=='m'].loc[lambda x: ~x['stuid'].isin(sportsinfo.query('sportname==""football""')['stuid'])]['stuid']"
what are the ids of all male students who do not play football?,"student.loc[lambda x: x['sex']=='m'].loc[lambda x: ~x['stuid'].isin(sportsinfo.query('sportname==""football""')['stuid'])]['stuid']"
show total hours per week and number of games played for student david shieber.,"pd.merge(sportsinfo, student, on='stuid').loc[(lambda x: x['fname']=='david')&(lambda x: x['lname']=='shieber'), ['hoursperweek', 'gamesplayed']].sum()"
what is the total number of hours per work and number of games played by david shieber?,"pd.merge(sportsinfo, student, on='stuid').loc[(lambda x: x['fname']=='david')&(lambda x: x['lname']=='shieber'), ['hoursperweek', 'gamesplayed']].sum()"
show total hours per week and number of games played for students under 20.,"pd.merge(sportsinfo, student, on='stuid').loc[lambda x: x['age']<20, ['hoursperweek', 'gamesplayed']].agg('sum')"
what is the total number of hours per week and number of games played by students under 20?,"pd.merge(sportsinfo, student, on='stuid').loc[lambda x: x['age']<20, ['hoursperweek', 'gamesplayed']].agg('sum')"
how many students play video games?,plays_games['stuid'].nunique()
how many different students play games?,plays_games['stuid'].nunique()
show ids of students who don't play video game.,"student.loc[~student['stuid'].isin(plays_games['stuid']), 'stuid']"
what are the ids of all students who are not video game players?,"student.loc[~student['stuid'].isin(plays_games['stuid']), 'stuid']"
show ids of students who play video game and play sports.,pd.series(list(set(sportsinfo['stuid']) & set(plays_games['stuid'])))
what are the ids of all students who played video games and sports?,pd.series(list(set(sportsinfo['stuid']) & set(plays_games['stuid'])))
show all game ids and the number of hours played.,plays_games.groupby('gameid')['hours_played'].sum()
what are ids and total number of hours played for each game?,plays_games.groupby('gameid')['hours_played'].sum()
show all student ids and the number of hours played.,plays_games.groupby('stuid')['hours_played'].sum()
what are the ids of all students and number of hours played?,plays_games.groupby('stuid')['hours_played'].sum()
show the game name that has most number of hours played.,"pd.merge(plays_games, video_games, on='gameid').groupby('gameid').agg(hours_played=('hours_played', 'sum'), gname=('gname', 'first')).sort_values('hours_played', ascending=false).iloc[[0], ['gname']]"
what is the name of the game that has been played the most?,"pd.merge(plays_games, video_games, on='gameid').groupby('gameid').agg(hours_played=('hours_played', 'sum'), gname=('gname', 'first')).sort_values('hours_played', ascending=false).iloc[[0], ['gname']]"
show all game names played by at least 1000 hours.,"pd.merge(plays_games, video_games, on='gameid').groupby('gname').filter(lambda x: x['hours_played'].sum() >= 1000)['gname']"
what are the names of all the games that have been played for at least 1000 hours?,"pd.merge(plays_games, video_games, on='gameid').groupby('gname').filter(lambda x: x['hours_played'].sum() >= 1000)['gname']"
show all game names played by linda smith,"pd.merge(pd.merge(plays_games, video_games, on='gameid'), student, on='stuid').loc[(student['lname']=='smith')&(student['fname']=='linda'), 'gname']"
what are the names of all games played by linda smith?,"pd.merge(pd.merge(plays_games, video_games, on='gameid'), student, on='stuid').loc[(student['lname']=='smith')&(student['fname']=='linda'), 'gname']"
find the last and first name of students who are playing football or lacrosse.,"pd.merge(sportsinfo.query('sportname in [""football"", ""lacrosse""]'), student, on='stuid')[['lname', 'fname']]"
what is the first and last name of all students who play football or lacrosse?,"pd.merge(sportsinfo.query('sportname in [""football"", ""lacrosse""]'), student, on='stuid')[['lname', 'fname']]"
find the first name and age of the students who are playing both football and lacrosse.,"student.loc[student['stuid'].isin(sportsinfo.loc[sportsinfo['sportname'] == 'football', 'stuid'].values.tolist() & sportsinfo.loc[sportsinfo['sportname'] == 'lacrosse', 'stuid'].values.tolist()), ['fname', 'age']]"
what are the first names and ages of all students who are playing both football and lacrosse?,"student.loc[student['stuid'].isin(sportsinfo.loc[sportsinfo['sportname'] == 'football', 'stuid'].values.tolist() & sportsinfo.loc[sportsinfo['sportname'] == 'lacrosse', 'stuid'].values.tolist()), ['fname', 'age']]"
find the last name and gender of the students who are playing both call of destiny and works of widenius games.,"plays_games.merge(video_games, on='gameid').query('gname == ""call of destiny""').merge(plays_games.merge(video_games, on='gameid').query('gname == ""works of widenius"")', on='stuid')[['lname', 'sex']]"
what is the last name and gender of all students who played both call of destiny and works of widenius?,"plays_games.merge(video_games, on='gameid').query('gname == ""call of destiny""').merge(plays_games.merge(video_games, on='gameid').query('gname == ""works of widenius"")', on='stuid')[['lname', 'sex']]"
find the name of all customers.,customers['customer_name']
what are the names of all the customers?,customers['customer_name']
return the total number of distinct customers.,customers.shape[0]
what is the average amount of items ordered in each order?,order_items['order_quantity'].mean()
find the average order quantity per order.,order_items['order_quantity'].mean()
"what are the names of customers who use payment method ""cash""?","customers.loc[lambda x: x['payment_method']=='cash', 'customer_name']"
"which customers use ""cash"" for payment method? return the customer names.","customers.loc[lambda x: x['payment_method']=='cash', 'customer_name']"
"find the ""date became customers"" of the customers whose id is between 10 and 20.","customers.loc[lambda x: (x['customer_id'] >= 10) & (x['customer_id'] <= 20), 'date_became_customer']"
what are the dates when customers with ids between 10 and 20 became customers?,"customers.loc[lambda x: (x['customer_id'] >= 10) & (x['customer_id'] <= 20), 'date_became_customer']"
which payment method is used by most customers?,customers.groupby('payment_method').size().sort_values(ascending=false).index[0]
what are the names of customers using the most popular payment method?,customers.loc[lambda x: x['payment_method'] == customers['payment_method'].value_counts().index[0]]['customer_name']
find the name of the customers who use the most frequently used payment method.,customers.loc[lambda x: x['payment_method'] == customers['payment_method'].value_counts().index[0]]['customer_name']
what are all the payment methods?,customers['payment_method'].unique()
return all the distinct payment methods used by customers.,customers['payment_method'].unique()
what are the details of all products?,products['product_details'].unique()
return the the details of all products.,products['product_details'].unique()
"find the name of all customers whose name contains ""alex"".","customers.loc[customers['customer_name'].str.contains('alex'), 'customer_name']"
"which customer's name contains ""alex""? find the full name.","customers.loc[customers['customer_name'].str.contains('alex'), 'customer_name']"
"find the detail of products whose detail contains the word ""latte"" or the word ""americano""","products.loc[lambda x: x['product_details'].str.contains('latte|americano'), 'product_details']"
"which product's detail contains the word ""latte"" or ""americano""? return the full detail.","products.loc[lambda x: x['product_details'].str.contains('latte|americano'), 'product_details']"
"what is the address content of the customer named ""maudie kertzmann""?","pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').loc[lambda x: x['customer_name']=='maudie kertzmann', 'address_content']"
"return the address content for the customer whose name is ""maudie kertzmann"".","pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').loc[lambda x: x['customer_name']=='maudie kertzmann', 'address_content']"
"how many customers are living in city ""lake geovannyton""?","pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').loc[lambda x: x['city']=='lake geovannyton'].shape[0]"
find the number of customers who live in the city called lake geovannyton.,"pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').loc[lambda x: x['city']=='lake geovannyton'].shape[0]"
find the name of customers who are living in colorado?,"pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').loc[lambda x: x['state_province_county']=='colorado', 'customer_name']"
what are the names of customers who live in colorado state?,"pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').loc[lambda x: x['state_province_county']=='colorado', 'customer_name']"
find the list of cities that no customer is living in.,"addresses.loc[~addresses['city'].isin(pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id')['city'].unique()), 'city']"
what are the cities no customers live in?,"addresses.loc[~addresses['city'].isin(pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id')['city'].unique()), 'city']"
which city has the most customers living in?,"pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').groupby('city').size().sort_values(ascending=false).reset_index(name='count').iloc[0]['city']"
find the city where the most customers live.,"pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').groupby('city').size().sort_values(ascending=false).reset_index(name='count').iloc[0]['city']"
retrieve the list of all cities.,addresses['city'].unique()
list all the distinct cities,addresses['city'].unique()
find the city with post code 255.,"addresses.loc[lambda x: x['zip_postcode']==255, 'city']"
which city is post code 255 located in?,"addresses.loc[lambda x: x['zip_postcode']==255, 'city']"
find the state and country of all cities with post code starting with 4.,"addresses.loc[lambda x: x['zip_postcode'].str.startswith('4'), ['state_province_county', 'country']]"
what are the state and country of all the cities that have post codes starting with 4.\,"addresses.loc[lambda x: x['zip_postcode'].str.startswith('4'), ['state_province_county', 'country']]"
list the countries having more than 4 addresses listed.,addresses.groupby('country').filter(lambda x: len(x) > 4)['country'].unique()
for which countries are there more than four distinct addresses listed?,addresses.groupby('country').filter(lambda x: len(x) > 4)['country'].unique()
list all the contact channel codes that were used less than 5 times.,customer_contact_channels.groupby('channel_code').filter(lambda x: x['customer_id'].nunique() < 5)['channel_code'].unique()
which contact channel codes were used less than 5 times?,customer_contact_channels.groupby('channel_code').filter(lambda x: x['customer_id'].nunique() < 5)['channel_code'].unique()
"which contact channel has been used by the customer with name ""tillman ernser""?","pd.merge(customers[customers['customer_name']=='tillman ernser'], customer_contact_channels, on='customer_id')['channel_code'].unique()"
"find the contact channel code that was used by the customer named ""tillman ernser"".","pd.merge(customers[customers['customer_name']=='tillman ernser'], customer_contact_channels, on='customer_id')['channel_code'].unique()"
"what is the ""active to date"" of the latest contact channel used by ""tillman ernser""?","customer_contact_channels.merge(customers.query('customer_name == ""tillman ernser""'), on='customer_id')['active_to_date'].max()"
"return the the ""active to date"" of the latest contact channel used by the customer named ""tillman ernser"".","customer_contact_channels.merge(customers.query('customer_name == ""tillman ernser""'), on='customer_id')['active_to_date'].max()"
what is the average time span of contact channels in the database?,(customer_contact_channels['active_to_date'] - customer_contact_channels['active_from_date']).mean()
compute the average active time span of contact channels.,(customer_contact_channels['active_to_date'] - customer_contact_channels['active_from_date']).mean()
what is the channel code and contact number of the customer contact channel that was active for the longest time?,"customer_contact_channels.loc[lambda x: x['active_to_date'] - x['active_from_date'] == customer_contact_channels['active_to_date'] - customer_contact_channels['active_from_date'].max(), ['channel_code', 'contact_number']]"
return the channel code and contact number of the customer contact channel whose active duration was the longest.,"customer_contact_channels.loc[lambda x: x['active_to_date'] - x['active_from_date'] == customer_contact_channels['active_to_date'] - customer_contact_channels['active_from_date'].max(), ['channel_code', 'contact_number']]"
find the name and active date of the customer that use email as the contact channel.,"pd.merge(customers, customer_contact_channels.loc[lambda x: x['channel_code']=='email'], on='customer_id')[['customer_name', 'active_from_date']]"
what are the name and active date of the customers whose contact channel code is email?,"pd.merge(customers, customer_contact_channels.loc[lambda x: x['channel_code']=='email'], on='customer_id')[['customer_name', 'active_from_date']]"
what is the name of the customer that made the order with the largest quantity?,"customer_orders.merge(customers, on='customer_id').merge(order_items, on='order_id').loc[lambda x: x['order_quantity'] == order_items['order_quantity'].max(), 'customer_name']"
find the name of the customer who made the order of the largest amount of goods.,"customer_orders.merge(customers, on='customer_id').merge(order_items, on='order_id').loc[lambda x: x['order_quantity'] == order_items['order_quantity'].max(), 'customer_name']"
what is the name of the customer that has purchased the most items?,"(pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id').groupby('customer_name').agg({'order_quantity': 'sum'}).sort_values('order_quantity', ascending=false).head(1).index[0])"
give me the name of the customer who ordered the most items in total.,"(pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id').groupby('customer_name').agg({'order_quantity': 'sum'}).sort_values('order_quantity', ascending=false).head(1).index[0])"
what is the payment method of the customer that has purchased the least quantity of items?,"customers.merge(customer_orders, on='customer_id').merge(order_items, on='order_id').groupby('customer_name').agg({'payment_method': 'first', 'order_quantity': 'sum'}).sort_values(by='order_quantity').head(1)['payment_method']"
tell me the payment method used by the customer who ordered the least amount of goods in total.,"customers.merge(customer_orders, on='customer_id').merge(order_items, on='order_id').groupby('customer_name').agg({'payment_method': 'first', 'order_quantity': 'sum'}).sort_values(by='order_quantity').head(1)['payment_method']"
how many types of products have rodrick heaney bought in total?,"pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id').loc[lambda x: x['customer_name']=='rodrick heaney', 'product_id'].nunique()"
find the number of distinct products rodrick heaney has bought so far.,"pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id').loc[lambda x: x['customer_name']=='rodrick heaney', 'product_id'].nunique()"
"what is the total quantity of products purchased by ""rodrick heaney""?","pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id').loc[lambda x: x['customer_name']=='rodrick heaney', 'order_quantity'].sum()"
"tell me the total quantity of products bought by the customer called ""rodrick heaney"".","pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id').loc[lambda x: x['customer_name']=='rodrick heaney', 'order_quantity'].sum()"
"how many customers have at least one order with status ""cancelled""?","customer_orders.loc[lambda x: x['order_status']=='cancelled', 'customer_id'].nunique()"
"return the number of customers who have at least one order with ""cancelled"" status.","customer_orders.loc[lambda x: x['order_status']=='cancelled', 'customer_id'].nunique()"
"how many orders have detail ""second time""?",(customer_orders['order_details'] == 'second time').sum()
"tell me the number of orders with ""second time"" as order detail.",(customer_orders['order_details'] == 'second time').sum()
"find the customer name and date of the orders that have the status ""delivered"".","pd.merge(customers, customer_orders, on='customer_id').loc[lambda x: x['order_status']=='delivered', ['customer_name', 'order_date']]"
"what are the customer name and date of the orders whose status is ""delivered"".","pd.merge(customers, customer_orders, on='customer_id').loc[lambda x: x['order_status']=='delivered', ['customer_name', 'order_date']]"
"what is the total number of products that are in orders with status ""cancelled""?","pd.merge(customer_orders.loc[lambda x: x['order_status']=='cancelled'], order_items, on='order_id')['order_quantity'].sum()"
"find the total quantity of products associated with the orders in the ""cancelled"" status.","pd.merge(customer_orders.loc[lambda x: x['order_status']=='cancelled'], order_items, on='order_id')['order_quantity'].sum()"
find the total amount of products ordered before 2018-03-17 07:13:53.,"pd.merge(customer_orders, order_items, on='order_id').loc[lambda x: x['order_date'] < '2018-03-17 07:13:53', 'order_quantity'].sum()"
what is the total amount of products purchased before 2018-03-17 07:13:53?,"pd.merge(customer_orders, order_items, on='order_id').loc[lambda x: x['order_date'] < '2018-03-17 07:13:53', 'order_quantity'].sum()"
who made the latest order?,"pd.merge(customers, customer_orders, on='customer_id').sort_values(by='order_date', ascending=false).iloc[0]['customer_name']"
find the name of the customer who made an order most recently.,"pd.merge(customers, customer_orders, on='customer_id').sort_values(by='order_date', ascending=false).iloc[0]['customer_name']"
which product has been ordered most number of times?,"pd.merge(order_items, products, on='product_id').groupby('product_id')['product_details'].first().sort_values(ascending=false).head(1)"
what is the most frequently ordered product? tell me the detail of the product,"pd.merge(order_items, products, on='product_id').groupby('product_id')['product_details'].first().sort_values(ascending=false).head(1)"
find the name and id of the product whose total order quantity is the largest.,"pd.merge(order_items, products, on='product_id').groupby('product_id').agg({'order_quantity': 'sum', 'product_details': 'first'}).sort_values('order_quantity', ascending=true).head(1)[['product_details', 'product_id']]"
what are the name and id of the product bought the most.,"pd.merge(order_items, products, on='product_id').groupby('product_id').agg({'order_quantity': 'sum', 'product_details': 'first'}).sort_values('order_quantity', ascending=true).head(1)[['product_details', 'product_id']]"
"find all the addresses in east julianaside, texas or in gleasonmouth, arizona.","pd.concat([addresses.loc[(addresses['city'] == 'east julianaside') & (addresses['state_province_county'] == 'texas'), 'address_content'],addresses.loc[(addresses['city'] == 'gleasonmouth') & (addresses['state_province_county'] == 'arizona'), 'address_content']]).drop_duplicates()"
"what are all the addresses in east julianaside, texas or in gleasonmouth, arizona.","pd.concat([addresses.loc[(addresses['city'] == 'east julianaside') & (addresses['state_province_county'] == 'texas'), 'address_content'],addresses.loc[(addresses['city'] == 'gleasonmouth') & (addresses['state_province_county'] == 'arizona'), 'address_content']]).drop_duplicates()"
find the name of customers who did not pay with cash.,"customers.loc[lambda x: x['payment_method'] != 'cash', 'customer_name']"
what is the name of customers who do not use cash as payment method.,"customers.loc[lambda x: x['payment_method'] != 'cash', 'customer_name']"
find the names of customers who never ordered product latte.,"customers[~customers['customer_name'].isin(pd.merge(pd.merge(pd.merge(customer_orders, order_items, on='order_id'), products, on='product_id'), customers, on='customer_id').loc[lambda x: x['product_details']=='latte', 'customer_name'])]['customer_name']"
what are names of customers who never ordered product latte.,"customers[~customers['customer_name'].isin(pd.merge(pd.merge(pd.merge(customer_orders, order_items, on='order_id'), products, on='product_id'), customers, on='customer_id').loc[lambda x: x['product_details']=='latte', 'customer_name'])]['customer_name']"
find the names of customers who never placed an order.,"customers.loc[~customers['customer_id'].isin(customer_orders['customer_id']), 'customer_name']"
what are the names of customers who never made an order.,"customers.loc[~customers['customer_id'].isin(customer_orders['customer_id']), 'customer_name']"
find the names of customers who ordered both products latte and americano.,"pd.merge(pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').loc[lambda x: x['product_details']=='latte', 'customer_name'].unique() & pd.merge(pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').loc[lambda x: x['product_details']=='americano', 'customer_name'].unique()"
what are the names of customers who have purchased both products latte and americano?,"pd.merge(pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').loc[lambda x: x['product_details']=='latte', 'customer_name'].unique() & pd.merge(pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').loc[lambda x: x['product_details']=='americano', 'customer_name'].unique()"
how many artists are there?,artist.shape[0]
list the age of all music artists.,artist['age']
what are the ages of all music artists?,artist['age']
what is the average age of all artists?,artist['age'].mean()
return the average age across all artists.,artist['age'].mean()
"what are the famous titles of the artist ""triumfall""?","artist.loc[lambda x: x['artist'] == 'triumfall', 'famous_title']"
"return the famous titles of the artist called ""triumfall"".","artist.loc[lambda x: x['artist'] == 'triumfall', 'famous_title']"
what are the distinct famous release dates?,artist['famous_release_date'].unique()
give the distinct famous release dates for all artists.,artist['famous_release_date'].unique()
return the dates of ceremony and the results of all music festivals,"music_festival[['date_of_ceremony', 'result']]"
what are the dates of ceremony and results for each music festival?,"music_festival[['date_of_ceremony', 'result']]"
"what are the category of music festivals with result ""awarded""?","music_festival.loc[music_festival['result'] == 'awarded', 'category']"
"return the categories of music festivals that have the result ""awarded"".","music_festival.loc[music_festival['result'] == 'awarded', 'category']"
what are the maximum and minimum week on top of all volumes?,"volume['weeks_on_top'].agg(['max', 'min'])"
give the maximum and minimum weeks on top across all volumes.,"volume['weeks_on_top'].agg(['max', 'min'])"
what are the songs in volumes with more than 1 week on top?,"volume.loc[volume['weeks_on_top'] > 1, 'song']"
give the songs included in volumes that have more than 1 week on top.,"volume.loc[volume['weeks_on_top'] > 1, 'song']"
please list all songs in volumes in ascending alphabetical order.,volume['song'].sort_values()
"what are the the songs in volumes, listed in ascending order?",volume['song'].sort_values()
how many distinct artists do the volumes associate to?,volume['artist_id'].nunique()
count the number of distinct artists who have volumes.,volume['artist_id'].nunique()
please show the date of ceremony of the volumes that last more than 2 weeks on top.,"pd.merge(music_festival, volume, left_on='volume', right_on='volume_id').loc[lambda x: x['weeks_on_top'] > 2, 'date_of_ceremony']"
what are the dates of ceremony at music festivals corresponding to volumes that lasted more than 2 weeks on top?,"pd.merge(music_festival, volume, left_on='volume', right_on='volume_id').loc[lambda x: x['weeks_on_top'] > 2, 'date_of_ceremony']"
"please show the songs that have result ""nominated"" at music festivals.","music_festival.merge(volume, left_on='volume', right_on='volume_id').loc[lambda x: x['result']=='nominated', 'song']"
what are the songs in volumes that have resulted in a nomination at music festivals?,"music_festival.merge(volume, left_on='volume', right_on='volume_id').loc[lambda x: x['result']=='nominated', 'song']"
"what are the issue dates of volumes associated with the artist ""gorgoroth""?","volume.loc[volume['artist_id'].isin(artist.loc[artist['artist']=='gorgoroth', 'artist_id']), 'issue_date']"
return the issue dates of volumes that are by the artist named gorgoroth.,"volume.loc[volume['artist_id'].isin(artist.loc[artist['artist']=='gorgoroth', 'artist_id']), 'issue_date']"
what are the songs in volumes associated with the artist aged 32 or older?,"pd.merge(artist, volume, on='artist_id').loc[lambda x: x['age'] >= 32, 'song']"
return names of songs in volumes that are by artists that are at least 32 years old.,"pd.merge(artist, volume, on='artist_id').loc[lambda x: x['age'] >= 32, 'song']"
what is the average weeks on top of volumes associated with the artist aged 25 or younger?,"pd.merge(artist.loc[lambda x: x['age']<=25], volume, on='artist_id')['weeks_on_top'].mean()"
return the average number of weeks on top for volumes by artists that are at most 25 years old.,"pd.merge(artist.loc[lambda x: x['age']<=25], volume, on='artist_id')['weeks_on_top'].mean()"
what are the famous title of the artists associated with volumes with more than 2 weeks on top?,"pd.merge(artist, volume, on='artist_id').loc[lambda x: x['weeks_on_top']>2, 'famous_title']"
return the famous titles for artists that have volumes that lasted more than 2 weeks on top.,"pd.merge(artist, volume, on='artist_id').loc[lambda x: x['weeks_on_top']>2, 'famous_title']"
please list the age and famous title of artists in descending order of age.,"artist[['famous_title', 'age']].sort_values('age', ascending=false)"
"what are the famous titles and ages of each artist, listed in descending order by age?","artist[['famous_title', 'age']].sort_values('age', ascending=false)"
what is the famous release date of the artist with the oldest age?,"artist.sort_values('age', ascending=false)['famous_release_date'].iloc[0]"
return the famous release date for the oldest artist.,"artist.sort_values('age', ascending=false)['famous_release_date'].iloc[0]"
please show the categories of the music festivals and the count.,music_festival.groupby('category').size().reset_index(name='count')
return the number of music festivals of each category.,music_festival.groupby('category').size().reset_index(name='count')
what is the most common result of the music festival?,music_festival.groupby('result').size().sort_values(ascending=false).index[0]
return the result that is most frequent at music festivals.,music_festival.groupby('result').size().sort_values(ascending=false).index[0]
please show the categories of the music festivals with count more than 1.,music_festival.groupby('category').filter(lambda x: len(x) > 1)['category'].unique()
what are the categories of music festivals for which there have been more than 1 music festival?,music_festival.groupby('category').filter(lambda x: len(x) > 1)['category'].unique()
what is the song in the volume with the maximum weeks on top?,"volume.sort_values('weeks_on_top', ascending=false).iloc[0]['song']"
return the song in the volume that has spent the most weeks on top?,"volume.sort_values('weeks_on_top', ascending=false).iloc[0]['song']"
find the famous titles of artists that do not have any volume.,"artist.loc[~artist['artist_id'].isin(volume['artist_id']), 'famous_title']"
what are the famous titles of artists who do not have any volumes?,"artist.loc[~artist['artist_id'].isin(volume['artist_id']), 'famous_title']"
show the famous titles of the artists with both volumes that lasted more than 2 weeks on top and volumes that lasted less than 2 weeks on top.,"pd.merge(artist.loc[lambda x: pd.merge(x, volume, on='artist_id').eval('weeks_on_top > 2'), 'famous_title'], artist.loc[lambda x: pd.merge(x, volume, on='artist_id').eval('weeks_on_top < 2'), 'famous_title']).drop_duplicates()"
"what are the date of ceremony of music festivals with category ""best song"" and result ""awarded""?","music_festival.query('category == ""best song"" and result == ""awarded""')['date_of_ceremony']"
"return the dates of ceremony corresponding to music festivals that had the category ""best song"" and result ""awarded"".","music_festival.query('category == ""best song"" and result == ""awarded""')['date_of_ceremony']"
what is the issue date of the volume with the minimum weeks on top?,volume.sort_values('weeks_on_top').iloc[0]['issue_date']
return the issue date of the volume that has spent the fewest weeks on top.,volume.sort_values('weeks_on_top').iloc[0]['issue_date']
how many distinct artists have volumes?,volume['artist_id'].nunique()
count the number of artists who have had volumes.,volume['artist_id'].nunique()
"please show the results of music festivals and the number of music festivals that have had each, ordered by this count.",music_festival.groupby('result').size().sort_values(ascending=false)
"how many music festivals have had each kind of result, ordered descending by count?",music_festival.groupby('result').size().sort_values(ascending=false)
what are the issue dates of volumes associated with the artist aged 23 or younger?,"pd.merge(artist.loc[lambda x: x['age']<=23], volume, on='artist_id')['issue_date']"
return the issue dates of volumes by artists who are at most 23 years old?,"pd.merge(artist.loc[lambda x: x['age']<=23], volume, on='artist_id')['issue_date']"
how many roller coasters are there?,roller_coaster.shape[0]
list the names of roller coasters by ascending order of length.,roller_coaster.sort_values('length')['name']
what are the lengths and heights of roller coasters?,"roller_coaster[['length', 'height']]"
"list the names of countries whose language is not ""german"".","country.loc[lambda x: x['languages']!='german', 'name']"
show the statuses of roller coasters longer than 3300 or higher than 100.,"roller_coaster.loc[(roller_coaster['length'] > 3300) | (roller_coaster['height'] > 100), 'status']"
what are the speeds of the longest roller coaster?,"roller_coaster.sort_values('length', ascending=false).iloc[0]['speed']"
what is the average speed of roller coasters?,roller_coaster['speed'].mean()
show the different statuses and the numbers of roller coasters for each status.,roller_coaster.groupby('status').size().reset_index(name='count')
please show the most common status of roller coasters.,roller_coaster.groupby('status').size().sort_values(ascending=false).index[0]
list the status shared by more than two roller coaster.,roller_coaster.groupby('status').filter(lambda x: len(x) > 2)['status'].unique()
show the park of the roller coaster with the highest speed.,"roller_coaster.sort_values('speed', ascending=false).iloc[0]['park']"
show the names of roller coasters and names of country they are in.,"pd.merge(country, roller_coaster, on='country_id')[['name_x', 'name_y']]"
show the names of countries that have more than one roller coaster.,"pd.merge(country, roller_coaster, on='country_id').groupby('name').filter(lambda x: len(x) > 1)['name']"
show the name and population of the country that has the highest roller coaster.,"pd.merge(country, roller_coaster, on='country_id').sort_values('height', ascending=false).iloc[0][['name', 'population']]"
show the names of countries and the average speed of roller coasters from each country.,"pd.merge(country, roller_coaster, on='country_id').groupby('name')['speed'].mean()"
how many countries do not have an roller coaster longer than 3000?,"country.loc[~country['country_id'].isin(roller_coaster.loc[roller_coaster['length'] > 3000, 'country_id']), :].shape[0]"
"what are the country names, area and population which has both roller coasters with speed higher","country.merge(roller_coaster.query('speed > 60')[['country_id']], on='country_id')[['name', 'area', 'population']].merge(country.merge(roller_coaster.query('speed < 55')[['country_id']], on='country_id')[['name', 'area', 'population']]).drop_duplicates()"
how many different captain ranks are there?,captain['rank'].nunique()
count the number of different ranks of captain.,captain['rank'].nunique()
how many captains are in each rank?,captain.groupby('rank').size().reset_index(name='count')
count the number of captains that have each rank.,captain.groupby('rank').size().reset_index(name='count')
how many captains with younger than 50 are in each rank?,captain.loc[captain['age'] < 50].groupby('rank').size().reset_index(name='count')
count the number of captains younger than 50 of each rank.,captain.loc[captain['age'] < 50].groupby('rank').size().reset_index(name='count')
sort all captain names by their ages from old to young.,"captain.sort_values('age', ascending=false)['name']"
"what are the names of captains, sorted by age descending?","captain.sort_values('age', ascending=false)['name']"
"find the name, class and rank of all captains.","captain[['name', 'class', 'rank']]"
"what are the names, classes, and ranks of all captains?","captain[['name', 'class', 'rank']]"
which rank is the most common among captains?,captain.groupby('rank').size().sort_values(ascending=false).index[0]
return the rank for which there are the fewest captains.,captain.groupby('rank').size().sort_values(ascending=false).index[0]
which classes have more than two captains?,captain.groupby('class').filter(lambda x: len(x) > 2)['class'].unique()
give the classes that have more than two captains.,captain.groupby('class').filter(lambda x: len(x) > 2)['class'].unique()
find the name of captains whose rank are either midshipman or lieutenant.,"captain.loc[captain['rank'].isin(['midshipman', 'lieutenant']), 'name']"
what are the names of captains that have either the rank midshipman or lieutenant?,"captain.loc[captain['rank'].isin(['midshipman', 'lieutenant']), 'name']"
what are the average and minimum age of captains in different class?,"captain.groupby('class')['age'].agg(['mean', 'min'])"
return the average and minimum age of captains in each class.,"captain.groupby('class')['age'].agg(['mean', 'min'])"
find the captain rank that has some captains in both cutter and armed schooner classes.,"pd.merge(captain.loc[captain['class']=='cutter', 'rank'], captain.loc[captain['class']=='armed schooner', 'rank'], on='rank', how='inner')"
what are the ranks of captains that are both in the cutter and armed schooner classes?,"pd.merge(captain.loc[captain['class']=='cutter', 'rank'], captain.loc[captain['class']=='armed schooner', 'rank'], on='rank', how='inner')"
find the captain rank that has no captain in third-rate ship of the line class.,"captain.loc[~(captain['class']=='third-rate ship of the line'), 'rank']"
what are the ranks of captains that have no captain that are in the third-rate ship of the line class?,"captain.loc[~(captain['class']=='third-rate ship of the line'), 'rank']"
what is the name of the youngest captain?,captain.sort_values('age').iloc[0]['name']
return the name of the youngest captain.,captain.sort_values('age').iloc[0]['name']
how many ships are there?,ship.shape[0]
count the number of ships.,ship.shape[0]
"find the name, type, and flag of the ship that is built in the most recent year.","ship[['name', 'type', 'flag', 'built_year']].sort_values('built_year', ascending=false).head(1)[['name', 'type', 'flag']]"
"what is the name, type, and flag of the ship that was built in the most recent year?","ship[['name', 'type', 'flag', 'built_year']].sort_values('built_year', ascending=false).head(1)[['name', 'type', 'flag']]"
"group by ships by flag, and return number of ships that have each flag.",ship.groupby('flag').size().reset_index(name='count')
"what are the different ship flags, and how many ships have each?",ship.groupby('flag').size().reset_index(name='count')
which flag is most widely used among all ships?,ship.groupby('flag').size().sort_values(ascending=false).index[0]
return the flag that is most common among all ships.,ship.groupby('flag').size().sort_values(ascending=false).index[0]
list all ship names in the order of built year and class.,"ship.sort_values(['built_year', 'class'])['name']"
"what are the names of ships, ordered by year they were built and their class?","ship.sort_values(['built_year', 'class'])['name']"
find the ship type that are used by both ships with panama and malta flags.,"set(ship.loc[ship['flag']=='panama', 'type']).intersection(set(ship.loc[ship['flag']=='malta', 'type']))"
what types of ships have both ships that have panama flags and malta flags?,"set(ship.loc[ship['flag']=='panama', 'type']).intersection(set(ship.loc[ship['flag']=='malta', 'type']))"
in which year were most of ships built?,"ship.groupby('built_year').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['built_year']"
what is the year in which most ships were built?,"ship.groupby('built_year').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['built_year']"
find the name of the ships that have more than one captain.,"ship.merge(captain, on='ship_id').groupby('ship_id').filter(lambda x: len(x) > 1)['name']"
what are the names of ships that have more than one captain?,"ship.merge(captain, on='ship_id').groupby('ship_id').filter(lambda x: len(x) > 1)['name']"
what are the names and classes of the ships that do not have any captain yet?,"ship.loc[~ship['ship_id'].isin(captain['ship_id']), ['name', 'class']]"
return the names and classes of ships that do not have a captain?,"ship.loc[~ship['ship_id'].isin(captain['ship_id']), ['name', 'class']]"
find the name of the ship that is steered by the youngest captain.,"pd.merge(ship, captain, on='ship_id').sort_values('age').iloc[0]['name']"
what is the name of the ship that is commanded by the youngest captain?,"pd.merge(ship, captain, on='ship_id').sort_values('age').iloc[0]['name']"
find the name and flag of ships that are not steered by any captain with midshipman rank.,"ship[~ship['ship_id'].isin(captain.loc[captain['rank']=='midshipman', 'ship_id'])][['name', 'flag']]"
what are the names and flags of ships that do not have a captain with the rank of midshipman?,"ship[~ship['ship_id'].isin(captain.loc[captain['rank']=='midshipman', 'ship_id'])][['name', 'flag']]"
find the name of the ships that are steered by both a captain with midshipman rank and a captain with lieutenant rank.,"pd.merge(ship.loc[ship['captain_id'].isin(captain.query('rank==""midshipman""')['captain_id']), ['name', 'ship_id']], captain.query('rank==""lieutenant""')[['captain_id', 'ship_id']], on='ship_id')['name']"
what are the names of ships that are commanded by both captains with the rank of midshipman and captains with the rank of lieutenant?,"pd.merge(ship.loc[ship['captain_id'].isin(captain.query('rank==""midshipman""')['captain_id']), ['name', 'ship_id']], captain.query('rank==""lieutenant""')[['captain_id', 'ship_id']], on='ship_id')['name']"
what is id of the city that hosted events in the most recent year?,"hosting_city.sort_values('year', ascending=false).iloc[0]['host_city']"
find the city that hosted some events in the most recent year. what is the id of this city?,"hosting_city.sort_values('year', ascending=false).iloc[0]['host_city']"
"find the match ids of the cities that hosted competition ""1994 fifa world cup qualification""?","match.loc[lambda x: x['competition']==""1994 fifa world cup qualification"", 'match_id']"
"what is the match id of the competition called ""1994 fifa world cup qualification""?","match.loc[lambda x: x['competition']==""1994 fifa world cup qualification"", 'match_id']"
find the cities which were once a host city after 2010?,"pd.merge(city, hosting_city.loc[lambda x: x['year'] > 2010], left_on='city_id', right_on='host_city')['city']"
which cities served as a host city after 2010?,"pd.merge(city, hosting_city.loc[lambda x: x['year'] > 2010], left_on='city_id', right_on='host_city')['city']"
which city has hosted the most events?,"pd.merge(city, hosting_city, left_on='city_id', right_on='host_city').groupby('host_city').size().idxmax()"
find the city that hosted the most events.,"pd.merge(city, hosting_city, left_on='city_id', right_on='host_city').groupby('host_city').size().idxmax()"
"what is the venue of the competition ""1994 fifa world cup qualification"" hosted by ""nanjing ( jiangsu )""?","(pd.merge(pd.merge(city, hosting_city, on='city_id'), match, on='match_id').loc[lambda x: (x['city'] == 'nanjing ( jiangsu )') & (x['competition'] == '1994 fifa world cup qualification'), 'venue'])"
"find the venue of the competition ""1994 fifa world cup qualification"" which was hosted by ""nanjing ( jiangsu )"".","(pd.merge(pd.merge(city, hosting_city, on='city_id'), match, on='match_id').loc[lambda x: (x['city'] == 'nanjing ( jiangsu )') & (x['competition'] == '1994 fifa world cup qualification'), 'venue'])"
give me the temperature of shanghai in january.,"pd.merge(city.loc[lambda x: x['city']=='shanghai', 'city_id'], temperature, on='city_id')['jan']"
"what is the temperature of ""shanghai"" city in january?","pd.merge(city.loc[lambda x: x['city']=='shanghai', 'city_id'], temperature, on='city_id')['jan']"
"what is the host year of city ""taizhou ( zhejiang )""?","hosting_city.merge(city.query(""city == 'taizhou ( zhejiang )'""), on='host_city')['year']"
"in which year did city ""taizhou ( zhejiang )"" serve as a host city?","hosting_city.merge(city.query(""city == 'taizhou ( zhejiang )'""), on='host_city')['year']"
which three cities have the largest regional population?,"city.sort_values('regional_population', ascending=false).iloc[:3]['city']"
what are the three largest cities in terms of regional population?,"city.sort_values('regional_population', ascending=false).iloc[:3]['city']"
which city has the lowest gdp? please list the city name and its gdp.,"city[['city', 'gdp']].sort_values('gdp').iloc[0]"
what is the city with the smallest gdp? return the city and its gdp.,"city[['city', 'gdp']].sort_values('gdp').iloc[0]"
which city has the highest temperature in february?,"pd.merge(city, temperature, on='city_id').sort_values('feb', ascending=false).iloc[0]['city']"
"in february, which city marks the highest temperature?","pd.merge(city, temperature, on='city_id').sort_values('feb', ascending=false).iloc[0]['city']"
give me a list of cities whose temperature in march is lower than that in july or higher than that in oct?,"pd.merge(city, temperature, on='city_id').query('mar < jul or mar > oct')['city']"
which cities' temperature in march is lower than that in july or higher than that in oct?,"pd.merge(city, temperature, on='city_id').query('mar < jul or mar > oct')['city']"
give me a list of cities whose temperature in mar is lower than that in july and which have also served as host cities?,"pd.merge(city.loc[lambda x: temperature['mar']<temperature['jul']], hosting_city, on='city_id')['city']"
which cities have lower temperature in march than in july and have been once host cities?,"pd.merge(city.loc[lambda x: temperature['mar']<temperature['jul']], hosting_city, on='city_id')['city']"
give me a list of cities whose temperature in mar is lower than that in dec and which have never been host cities.,"city.loc[city['city_id'].isin(temperature.loc[temperature['mar'] < temperature['dec'], 'city_id']).tolist()].loc[~city['city_id'].isin(hosting_city['host_city'].tolist()), 'city']"
which cities have lower temperature in march than in dec and have never served as host cities?,"city.loc[city['city_id'].isin(temperature.loc[temperature['mar'] < temperature['dec'], 'city_id']).tolist()].loc[~city['city_id'].isin(hosting_city['host_city'].tolist()), 'city']"
give me a list of cities whose temperature in feb is higher than that in jun or cities that were once host cities?,"pd.merge(city.loc[lambda x: x.merge(temperature, on='city_id').eval('feb > jun')], hosting_city, on='city_id')['city'].unique()"
which cities have higher temperature in feb than in jun or have once served as host cities?,"pd.merge(city.loc[lambda x: x.merge(temperature, on='city_id').eval('feb > jun')], hosting_city, on='city_id')['city'].unique()"
please give me a list of cities whose regional population is over 10000000.,"city.loc[lambda x: x['regional_population'] > 10000000, 'city']"
which cities have regional population above 10000000?,"city.loc[lambda x: x['regional_population'] > 10000000, 'city']"
please give me a list of cities whose regional population is over 8000000 or under 5000000.,"pd.concat([city.loc[lambda x: x['regional_population'] > 10000000, 'city'], city.loc[lambda x: x['regional_population'] < 5000000, 'city']]).drop_duplicates()"
which cities have regional population above 8000000 or below 5000000?,"pd.concat([city.loc[lambda x: x['regional_population'] > 10000000, 'city'], city.loc[lambda x: x['regional_population'] < 5000000, 'city']]).drop_duplicates()"
find the number of matches in different competitions.,match.groupby('competition').size().reset_index(name='count(*)')
"for each competition, count the number of matches.",match.groupby('competition').size().reset_index(name='count(*)')
list venues of all matches in the order of their dates starting from the most recent one.,"match.sort_values('date', ascending=false)['venue']"
what are the venues of all the matches? sort them in the descending order of match date.,"match.sort_values('date', ascending=false)['venue']"
what is the gdp of the city with the largest population.,"city.sort_values('regional_population', ascending=false).iloc[0]['gdp']"
find the gdp of the city with the largest regional population.,"city.sort_values('regional_population', ascending=false).iloc[0]['gdp']"
what are the gdp and population of the city that already served as a host more than once?,"city.merge(hosting_city, left_on='city_id', right_on='host_city').groupby('host_city').filter(lambda x: len(x) > 1)[['gdp', 'regional_population']]"
which cities have served as host cities more than once? return me their gdp and population.,"city.merge(hosting_city, left_on='city_id', right_on='host_city').groupby('host_city').filter(lambda x: len(x) > 1)[['gdp', 'regional_population']]"
"list every individual's first name, middle name and last name in alphabetical order by last name.","individuals[['individual_first_name', 'individual_middle_name', 'individual_last_name']].sort_values('individual_last_name')"
"what are the first, middle, and last names of all individuals, ordered by last name?","individuals[['individual_first_name', 'individual_middle_name', 'individual_last_name']].sort_values('individual_last_name')"
list all the types of forms.,forms['form_type_code'].unique()
what are the different types of forms?,forms['form_type_code'].unique()
find the name of the most popular party form.,forms.merge(party_forms).groupby('form_id')['form_name'].first().value_counts().index[0]
what is the name of the party form that is most common?,forms.merge(party_forms).groupby('form_id')['form_name'].first().value_counts().index[0]
"find the payment method and phone of the party with email ""enrico09@example.com"".","parties.loc[lambda x: x['party_email']=='enrico09@example.com', ['payment_method_code', 'party_phone']]"
what is the payment method code and party phone of the party with the email 'enrico09@example.com'?,"parties.loc[lambda x: x['party_email']=='enrico09@example.com', ['payment_method_code', 'party_phone']]"
find the emails of parties with the most popular party form.,"parties.merge(party_forms[party_forms['form_id'] == party_forms['form_id'].value_counts().index[0]], on='party_id')['party_email']"
what are the party emails associated with parties that used the party form that is the most common?,"parties.merge(party_forms[party_forms['form_id'] == party_forms['form_id'].value_counts().index[0]], on='party_id')['party_email']"
list all the name of organizations in order of the date formed.,organizations.sort_values('date_formed')['organization_name']
"what are the names of organizations, ordered by the date they were formed, ascending?",organizations.sort_values('date_formed')['organization_name']
find the name of the youngest organization.,"organizations.sort_values('date_formed', ascending=false).iloc[0]['organization_name']"
what is the name of the organization that was formed most recently?,"organizations.sort_values('date_formed', ascending=false).iloc[0]['organization_name']"
"find the last name of the latest contact individual of the organization ""labour party"".","individuals.loc[individuals['individual_id'].isin(organization_contact_individuals.loc[organization_contact_individuals['organization_id'].isin(organizations.loc[organizations['organization_name'] == 'labour party', 'organization_id']) & (organization_contact_individuals['date_contact_to'] == organization_contact_individuals['date_contact_to'].max()), 'individual_id'].values), 'individual_last_name']"
what is the last name of the contact individual from the labour party organization who was contacted most recently?,"individuals.loc[individuals['individual_id'].isin(organization_contact_individuals.loc[organization_contact_individuals['organization_id'].isin(organizations.loc[organizations['organization_name'] == 'labour party', 'organization_id']) & (organization_contact_individuals['date_contact_to'] == organization_contact_individuals['date_contact_to'].max()), 'individual_id'].values), 'individual_last_name']"
find the last name of the first ever contact person of the organization with the highest uk vat number.,"(pd.merge(pd.merge(organizations,organization_contact_individuals,on='organization_id'),individuals,on='individual_id').loc[lambda x: x['uk_vat_number']==organizations['uk_vat_number'].max()].sort_values('date_contact_to').iloc[0]['individual_last_name'])"
what is the last name of the first individual contacted from the organization with the maximum uk vat number across all organizations?,"(pd.merge(pd.merge(organizations,organization_contact_individuals,on='organization_id'),individuals,on='individual_id').loc[lambda x: x['uk_vat_number']==organizations['uk_vat_number'].max()].sort_values('date_contact_to').iloc[0]['individual_last_name'])"
count the number of services.,services.shape[0]
find name of the services that has never been used.,"services.loc[~services['service_name'].isin(pd.merge(services, party_services, on='service_id')['service_name_y'])]['service_name']"
what are the names of the services that have never been used?,"services.loc[~services['service_name'].isin(pd.merge(services, party_services, on='service_id')['service_name_y'])]['service_name']"
find the name of all the cities and states.,addresses['town_city'].append(addresses['state_province_county']).drop_duplicates()
what are the names of all cities and states?,addresses['town_city'].append(addresses['state_province_county']).drop_duplicates()
"how many cities are there in state ""colorado""?","(addresses['state_province_county'] == ""colorado"").sum()"
count the number of cities in the state of colorado.,"(addresses['state_province_county'] == ""colorado"").sum()"
find the payment method code used by more than 3 parties.,parties.groupby('payment_method_code').filter(lambda x: len(x) > 3)['payment_method_code'].unique()
what are the payment method codes that have been used by more than 3 parties?,parties.groupby('payment_method_code').filter(lambda x: len(x) > 3)['payment_method_code'].unique()
"find the name of organizations whose names contain ""party"".","organizations.loc[organizations['organization_name'].str.contains('party'), 'organization_name']"
"what are the names of organizations that contain the word ""party""?","organizations.loc[organizations['organization_name'].str.contains('party'), 'organization_name']"
how many distinct payment methods are used by parties?,parties['payment_method_code'].nunique()
count the number of different payment method codes used by parties.,parties['payment_method_code'].nunique()
which is the email of the party that has used the services the most number of times?,"pd.merge(parties, party_services, left_on='party_id', right_on='customer_id').groupby('party_email').size().sort_values(ascending=false).head(1).index[0]"
return the party email that has used party services the greatest number of times.,"pd.merge(parties, party_services, left_on='party_id', right_on='customer_id').groupby('party_email').size().sort_values(ascending=false).head(1).index[0]"
"which state can address ""6862 kaitlyn knolls"" possibly be in?","addresses.loc[lambda x: x['line_1_number_building'].str.contains('6862 kaitlyn knolls'), 'state_province_county']"
"give the state corresponding to the line number building ""6862 kaitlyn knolls"".","addresses.loc[lambda x: x['line_1_number_building'].str.contains('6862 kaitlyn knolls'), 'state_province_county']"
what is the name of organization that has the greatest number of contact individuals?,"organizations.merge(organization_contact_individuals, on='organization_id').groupby('organization_name').size().sort_values(ascending=false).index[0]"
return the name of the organization which has the most contact individuals.,"organizations.merge(organization_contact_individuals, on='organization_id').groupby('organization_name').size().sort_values(ascending=false).index[0]"
find the last name of the individuals that have been contact individuals of an organization.,"pd.merge(individuals, organization_contact_individuals, on='individual_id')['individual_last_name'].unique()"
what are the last names of individuals who have been contact individuals for an organization?,"pd.merge(individuals, organization_contact_individuals, on='individual_id')['individual_last_name'].unique()"
how many drivers are there?,driver.shape[0]
"show the name, home city, and age for all drivers.","driver.loc[:, ['name', 'home_city', 'age']]"
show the party and the number of drivers in each party.,driver.groupby('party').size()
show the name of drivers in descending order of age.,"driver.sort_values('age', ascending=false)['name']"
show all different home cities.,driver['home_city'].unique()
show the home city with the most number of drivers.,driver.groupby('home_city').size().sort_values(ascending=false).index[0]
show the party with drivers from hartford and drivers older than 40.,"driver.loc[(driver['home_city'] == 'hartford') & (driver['age'] > 40), 'party']"
show home city where at least two drivers older than 40 are from.,driver.loc[lambda x: x['age'] > 40].groupby('home_city').filter(lambda x: len(x) >= 2)['home_city'].unique()
show all home cities except for those having a driver older than 40.,"driver.loc[lambda x: x['age'] <= 40, 'home_city'].drop_duplicates()"
show the names of the drivers without a school bus.,"driver.loc[~driver['driver_id'].isin(school_bus['driver_id']), 'name']"
show the types of schools that have two schools.,school.groupby('type').filter(lambda x: len(x)==2)['type'].unique()
show the school name and driver name for all school buses.,"pd.merge(pd.merge(school_bus, school, on='school_id'), driver, on='driver_id')[['school', 'name']]"
"what is the maximum, minimum and average years spent working on a school bus?","school_bus['years_working'].agg(['max', 'min', 'mean'])"
show the school name and type for schools without a school bus.,"school.loc[~school['school_id'].isin(school_bus['school_id']),['school', 'type']]"
show the type of school and the number of buses for each type.,"school_bus.merge(school, on='school_id').groupby('type').size().reset_index(name='count')"
how many drivers are from hartford city or younger than 40?,((driver['home_city'] == 'hartford') | (driver['age'] < 40)).sum()
list names for drivers from hartford city and younger than 40.,"driver.loc[(driver['home_city'] == 'hartford') & (driver['age'] < 40), 'name']"
find the name of driver who is driving the school bus with the longest working history.,"pd.merge(driver, school_bus, on='driver_id').sort_values('years_working', ascending=false).iloc[0]['name']"
how many flights have a velocity larger than 200?,(flight['velocity'] > 200).sum()
"list the vehicle flight number, date and pilot of all the flights, ordered by altitude.","flight.sort_values('altitude')[['vehicle_flight_number', 'date', 'pilot']]"
"list the id, country, city and name of the airports ordered alphabetically by the name.","airport[['id', 'country', 'city', 'name']].sort_values('name')"
what is maximum group equity shareholding of the companies?,operate_company['group_equity_shareholding'].max()
what is the velocity of the pilot named 'thompson'?,"flight.loc[lambda x: x['pilot']=='thompson', 'velocity'].mean()"
what are the names and types of the companies that have ever operated a flight?,"pd.merge(operate_company, flight, on='company_id')[['name', 'type']]"
what are the names of the airports which are not in the country 'iceland'?,"airport.loc[lambda x: x['country']!='iceland', 'name']"
what are the distinct types of the companies that have operated any flights with velocity less than 200?,"pd.merge(operate_company, flight, on='company_id').loc[lambda x: x['velocity']<200,'type'].unique()"
what are the ids and names of the companies that operated more than one flight?,"pd.merge(operate_company, flight, on='company_id').groupby(['id', 'name']).filter(lambda x: len(x) > 1)[['id', 'name']].drop_duplicates()"
"what is the id, name and iata code of the airport that had most number of flights?","airport.merge(flight, on='id').groupby('id')[['name', 'iata']].first().reset_index().sort_values(by=flight.groupby('id').size().name, ascending=false).iloc[[0]]"
what are the different pilot names who had piloted a flight in the country 'united states' or in the airport named 'billund airport'?,"flight.merge(airport, on='airport_id').loc[lambda x: (x['country']=='united states') | (x['name']=='billund airport'), 'pilot'].unique()"
"what is the most common company type, and how many are there?",operate_company.groupby('type').size().sort_values(ascending=false).head(1)
how many airports haven't the pilot 'thompson' driven an aircraft?,"airport[~airport['id'].isin(flight.loc[flight['pilot']=='thompson', 'airport_id'])].shape[0]"
list the name of the pilots who have flied for both a company that mainly provide 'cargo' services and a company that runs 'catering services' activities.,"set(pd.merge(flight.merge(operate_company.query(""principal_activities=='cargo'""), on='company_id')['pilot'], flight.merge(operate_company.query(""principal_activities=='catering services'""), on='company_id')['pilot']).values)"
which of the airport names contains the word 'international'?,"airport.loc[airport['name'].str.contains('international'), 'name']"
how many companies operates airlines in each airport?,"flight.merge(operate_company, on='id').merge(airport, on='airport_id').groupby('id').size().reset_index(name='count')"
how many airports are there in each country?,airport.groupby('country').size().rename('count').reset_index()
which countries have more than 2 airports?,airport.groupby('country').filter(lambda x: len(x)>2)['country'].unique()
which pilot is in charge of the most number of flights?,flight.groupby('pilot').size().sort_values(ascending=false).index[0]
show all account ids and account details.,"accounts[['account_id', 'account_details']]"
what are the ids and details of all accounts?,"accounts[['account_id', 'account_details']]"
how many statements do we have?,statements.shape[0]
count the number of statements.,statements.shape[0]
list all statement ids and statement details.,"statements[['statement_id', 'statement_details']]"
what are the ids and details of all statements?,"statements[['statement_id', 'statement_details']]"
"show statement id, statement detail, account detail for accounts.","pd.merge(accounts, statements, on='statement_id')[['statement_id', 'statement_details', 'account_details']]"
"what are the statement ids, statement details, and account details, for all accounts?","pd.merge(accounts, statements, on='statement_id')[['statement_id', 'statement_details', 'account_details']]"
show all statement id and the number of accounts for each statement.,accounts.groupby('statement_id').size().reset_index(name='count(*)')
"what are the different statement ids on accounts, and the number of accounts for each?",accounts.groupby('statement_id').size().reset_index(name='count(*)')
show the statement id and the statement detail for the statement with most number of accounts.,"pd.merge(accounts, statements, on='statement_id').groupby('statement_id').size().nlargest(1).reset_index(name='count').merge(statements, on='statement_id')[['statement_id', 'statement_details']]"
what are the statement id and statement detail for the statement that has the most corresponding accounts?,"pd.merge(accounts, statements, on='statement_id').groupby('statement_id').size().nlargest(1).reset_index(name='count').merge(statements, on='statement_id')[['statement_id', 'statement_details']]"
show the number of documents.,documents.shape[0]
count the number of documents.,documents.shape[0]
"list the document type code, document name, and document description for the document with name 'noel cv' or name 'king book'.","documents.loc[lambda x: x['document_name'].isin(['noel cv', 'king book']), ['document_type_code', 'document_name', 'document_description']]"
"what are the type come, name, and description of the document that has either the name 'noel cv' or 'king book'?","documents.loc[lambda x: x['document_name'].isin(['noel cv', 'king book']), ['document_type_code', 'document_name', 'document_description']]"
show the ids and names of all documents.,"documents[['document_id', 'document_name']]"
what are the ids and names for each of the documents?,"documents[['document_id', 'document_name']]"
find names and ids of all documents with document type code bk.,"documents.loc[lambda x: x['document_type_code']=='bk', ['document_name', 'document_id']]"
what are the names and ids of documents that have the type code bk?,"documents.loc[lambda x: x['document_type_code']=='bk', ['document_name', 'document_id']]"
how many documents are with document type code bk for each product id?,documents.loc[lambda x: x['document_type_code']=='bk'].groupby('project_id').size().reset_index(name='count(*)')
count the number of documents with the type code bk that correspond to each product id.,documents.loc[lambda x: x['document_type_code']=='bk'].groupby('project_id').size().reset_index(name='count(*)')
show the document name and the document date for all documents on project with details 'graph database project'.,"pd.merge(documents, projects.query('project_details==""graph database project""'), on='project_id')[['document_name', 'document_date']]"
what are the names and dates for documents corresponding to project that has the details 'graph database project'?,"pd.merge(documents, projects.query('project_details==""graph database project""'), on='project_id')[['document_name', 'document_date']]"
show project ids and the number of documents in each project.,documents.groupby('project_id').size().reset_index(name='count')
how many documents correspond with each project id?,documents.groupby('project_id').size().reset_index(name='count')
what is the id of the project with least number of documents?,documents.groupby('project_id').size().sort_values().index[0]
return the id of the project that has the fewest corresponding documents.,documents.groupby('project_id').size().sort_values().index[0]
show the ids for projects with at least 2 documents.,documents.groupby('project_id').filter(lambda x: len(x) >= 2)['project_id'].unique()
what are project ids of projects that have 2 or more corresponding documents?,documents.groupby('project_id').filter(lambda x: len(x) >= 2)['project_id'].unique()
list document type codes and the number of documents in each code.,documents.groupby('document_type_code').size().reset_index(name='count')
how many documents are there of each type?,documents.groupby('document_type_code').size().reset_index(name='count')
what is the document type code with most number of documents?,documents.groupby('document_type_code').size().sort_values(ascending=false).index[0]
return the code of the document type that is most common.,documents.groupby('document_type_code').size().sort_values(ascending=false).index[0]
show the document type code with fewer than 3 documents.,documents.groupby('document_type_code').filter(lambda x: len(x) < 3)['document_type_code'].unique()
what are the codes corresponding to document types for which there are less than 3 documents?,documents.groupby('document_type_code').filter(lambda x: len(x) < 3)['document_type_code'].unique()
show the statement detail and the corresponding document name for the statement with detail 'private project'.,"pd.merge(statements, documents, left_on='statement_id', right_on='document_id').loc[lambda x: x['statement_details']=='private project', ['statement_details', 'document_name']]"
"what are the details for statements with the details 'private project', and what are the names of the corresponding documents?","pd.merge(statements, documents, left_on='statement_id', right_on='document_id').loc[lambda x: x['statement_details']=='private project', ['statement_details', 'document_name']]"
"show all document type codes, document type names, document type descriptions.","ref_document_types[['document_type_code', 'document_type_name', 'document_type_description']]"
"what are the codes, names, and descriptions of the different document types?","ref_document_types[['document_type_code', 'document_type_name', 'document_type_description']]"
what is the document type description for document type named film?,"ref_document_types.loc[lambda x: x['document_type_name']=='film', 'document_type_description']"
return the description of the document type name 'film'.,"ref_document_types.loc[lambda x: x['document_type_name']=='film', 'document_type_description']"
what is the document type name and the document type description and creation date for all the documents?,"pd.merge(ref_document_types, documents, on='document_type_code')[['document_type_name', 'document_type_description', 'document_date']]"
"return the type name, type description, and date of creation for each document.","pd.merge(ref_document_types, documents, on='document_type_code')[['document_type_name', 'document_type_description', 'document_date']]"
show the number of projects.,projects.shape[0]
how many projects are there?,projects.shape[0]
list ids and details for all projects.,"projects[['project_id', 'project_details']]"
what are the ids and details for each project?,"projects[['project_id', 'project_details']]"
what is the project id and detail for the project with at least two documents?,"pd.merge(projects, documents, on='project_id').groupby(['project_id', 'project_details']).filter(lambda x: len(x) > 2)[['project_id', 'project_details']].drop_duplicates()"
return the ids and details corresponding to projects for which there are more than two documents.,"pd.merge(projects, documents, on='project_id').groupby(['project_id', 'project_details']).filter(lambda x: len(x) > 2)[['project_id', 'project_details']].drop_duplicates()"
"what is the project detail for the project with document ""king book""?","projects.merge(documents.loc[lambda x: x['document_name']=='king book'], on='project_id')['project_details']"
give the details of the project with the document name 'king book'.,"projects.merge(documents.loc[lambda x: x['document_name']=='king book'], on='project_id')['project_details']"
how many budget types do we have?,ref_budget_codes.shape[0]
count the number of budget codes.,ref_budget_codes.shape[0]
list all budget type codes and descriptions.,"ref_budget_codes[['budget_type_code', 'budget_type_description']]"
what are the type codes and descriptions of each budget type?,"ref_budget_codes[['budget_type_code', 'budget_type_description']]"
what is the description for the budget type with code org?,"ref_budget_codes.loc[lambda x: x['budget_type_code']=='org', 'budget_type_description']"
return the description of the budget type that has the code org.,"ref_budget_codes.loc[lambda x: x['budget_type_code']=='org', 'budget_type_description']"
how many documents have expenses?,documents_with_expenses.shape[0]
count the number of documents with expenses.,documents_with_expenses.shape[0]
what are the document ids for the budget type code 'sf'?,"documents_with_expenses.loc[lambda x: x['budget_type_code']=='sf', 'document_id']"
give the ids of documents with expenses that have the budget code 'sf'.,"documents_with_expenses.loc[lambda x: x['budget_type_code']=='sf', 'document_id']"
show the budget type code and description and the corresponding document id.,"pd.merge(documents_with_expenses, ref_budget_codes, on='budget_type_code')[['budget_type_code', 'budget_type_description', 'document_id']]"
"return the budget type codes, budget type descriptions and document ids for documents with expenses.","pd.merge(documents_with_expenses, ref_budget_codes, on='budget_type_code')[['budget_type_code', 'budget_type_description', 'document_id']]"
show ids for all documents with budget types described as 'government'.,"pd.merge(documents_with_expenses, ref_budget_codes, on='budget_type_code').loc[lambda x: x['budget_type_description'] == 'government', 'document_id']"
give the ids for documents that have the budget description 'government'.,"pd.merge(documents_with_expenses, ref_budget_codes, on='budget_type_code').loc[lambda x: x['budget_type_description'] == 'government', 'document_id']"
show budget type codes and the number of documents in each budget type.,documents_with_expenses.groupby('budget_type_code').size()
"what are the different budget type codes, and how many documents are there for each?",documents_with_expenses.groupby('budget_type_code').size()
what is the budget type code with most number of documents.,documents_with_expenses.groupby('budget_type_code').size().sort_values(ascending=false).index[0]
give the budget type code that is most common among documents with expenses.,documents_with_expenses.groupby('budget_type_code').size().sort_values(ascending=false).index[0]
what are the ids of documents which don't have expense budgets?,documents[~documents['document_id'].isin(documents_with_expenses['document_id'])]['document_id']
return the ids of documents that do not have expenses.,documents[~documents['document_id'].isin(documents_with_expenses['document_id'])]['document_id']
show ids for all documents in type cv without expense budgets.,"documents.query('document_type_code == ""cv""')['document_id'].drop_duplicates().reset_index(drop=true).loc[~documents_with_expenses['document_id'].isin(documents.query('document_type_code == ""cv""')['document_id'])]"
what are the ids of documents with the type code cv that do not have expenses.,"documents.query('document_type_code == ""cv""')['document_id'].drop_duplicates().reset_index(drop=true).loc[~documents_with_expenses['document_id'].isin(documents.query('document_type_code == ""cv""')['document_id'])]"
what are the ids of documents with letter 's' in the name with any expense budgets.,"pd.merge(documents, documents_with_expenses, on='document_id').loc[lambda x: x['document_name'].str.contains('s', regex=false), 'document_id']"
give the ids of documents that have expenses and contain the letter s in their names.,"pd.merge(documents, documents_with_expenses, on='document_id').loc[lambda x: x['document_name'].str.contains('s', regex=false), 'document_id']"
how many documents do not have any expense?,"documents.loc[~documents['document_id'].isin(documents_with_expenses['document_id']), :].shape[0]"
count the number of documents that do not have expenses.,"documents.loc[~documents['document_id'].isin(documents_with_expenses['document_id']), :].shape[0]"
what are the dates for the documents with both 'gv' type and 'sf' type expenses?,"pd.merge(documents, documents_with_expenses.loc[lambda x: x['budget_type_code'] == 'gv'], on='document_id')['document_date'].interesect(pd.merge(documents, documents_with_expenses.loc[lambda x: x['budget_type_code'] == 'sf'], on='document_id')['document_date'])"
give the dates of creation for documents that have both budget type codes 'gv' and 'sf'.,"pd.merge(documents, documents_with_expenses.loc[lambda x: x['budget_type_code'] == 'gv'], on='document_id')['document_date'].interesect(pd.merge(documents, documents_with_expenses.loc[lambda x: x['budget_type_code'] == 'sf'], on='document_id')['document_date'])"
what are the account details with the largest value or with value having char '5' in it?,"pd.concat([accounts['account_details'].max(),accounts.loc[accounts['account_details'].str.contains('5'), 'account_details']])"
"return the account details with the greatest value, as well as those that include the character 5.","pd.concat([accounts['account_details'].max(),accounts.loc[accounts['account_details'].str.contains('5'), 'account_details']])"
find the total number of scientists.,scientists.shape[0]
how many scientists are there?,scientists.shape[0]
find the total hours of all projects.,projects['hours'].sum()
what is the total number of hours for all projects?,projects['hours'].sum()
how many different scientists are assigned to any project?,assignedto['scientist'].nunique()
count the number of different scientists assigned to any project.,assignedto['scientist'].nunique()
find the number of distinct projects.,projects['name'].nunique()
how many different projects are there?,projects['name'].nunique()
find the average hours of all projects.,projects['hours'].mean()
what is the average hours across all projects?,projects['hours'].mean()
find the name of project that continues for the longest time.,"projects.sort_values('hours', ascending=false).iloc[0]['name']"
what is the name of the project with the most hours?,"projects.sort_values('hours', ascending=false).iloc[0]['name']"
list the name of all projects that are operated longer than the average working hours of all projects.,"projects.loc[lambda x: x['hours'] > x['hours'].mean(), 'name']"
what are the names of projects that have taken longer than the average number of hours for all projects?,"projects.loc[lambda x: x['hours'] > x['hours'].mean(), 'name']"
find the name and hours of project that has the most number of scientists.,"pd.merge(projects, assignedto, left_on='code', right_on='project').groupby('project')[['name', 'hours']].sum().reset_index().nlargest(1, 'name')[['name', 'hours']]"
what is the name and hours for the project which has the most scientists assigned to it?,"pd.merge(projects, assignedto, left_on='code', right_on='project').groupby('project')[['name', 'hours']].sum().reset_index().nlargest(1, 'name')[['name', 'hours']]"
find the name of the project for which a scientist whose name contains ‘smith’ is assigned to.,"pd.merge(pd.merge(assignedto, projects, left_on='project', right_on='code'), scientists.loc[lambda x: x['name'].str.contains('smith'), :], left_on='scientist', right_on='ssn')['name']"
what is the name of the project that has a scientist assigned to it whose name contains 'smith'?,"pd.merge(pd.merge(assignedto, projects, left_on='project', right_on='code'), scientists.loc[lambda x: x['name'].str.contains('smith'), :], left_on='scientist', right_on='ssn')['name']"
find the total hours of the projects that scientists named michael rogers or carol smith are assigned to.,"pd.merge(pd.merge(assignedto, projects, left_on='project', right_on='code'), scientists, left_on='scientist', right_on='ssn').loc[lambda x: x['name'].isin(['michael rogers', 'carol smith']), 'hours'].sum()"
what is the sum of hours for projects that scientists with the name michael rogers or carol smith are assigned to?,"pd.merge(pd.merge(assignedto, projects, left_on='project', right_on='code'), scientists, left_on='scientist', right_on='ssn').loc[lambda x: x['name'].isin(['michael rogers', 'carol smith']), 'hours'].sum()"
find the name of projects that require between 100 and 300 hours of work.,"projects.loc[(projects['hours'] >= 100) & (projects['hours'] <= 300), 'name']"
what are the names of projects that require between 100 and 300 hours?,"projects.loc[(projects['hours'] >= 100) & (projects['hours'] <= 300), 'name']"
find the name of the scientist who worked on both a project named 'matter of time' and a project named 'a puzzling parallax'.,"scientists.loc[set(assignedto.merge(projects.loc[lambda x: x['name'] == 'matter of time'], left_on='project', right_on='code').merge(scientists, on='scientist')['name']) & set(assignedto.merge(projects.loc[lambda x: x['name'] == 'a puzzling parallax'], left_on='project', right_on='code').merge(scientists, on='scientist')['name']), 'name']"
what are the names of any scientists who worked on projects named 'matter of time' and 'a puzzling pattern'?,"scientists.loc[set(assignedto.merge(projects.loc[lambda x: x['name'] == 'matter of time'], left_on='project', right_on='code').merge(scientists, on='scientist')['name']) & set(assignedto.merge(projects.loc[lambda x: x['name'] == 'a puzzling parallax'], left_on='project', right_on='code').merge(scientists, on='scientist')['name']), 'name']"
list the names of all scientists sorted in alphabetical order.,scientists.sort_values('name')['name']
what are the names of all the scientists in alphabetical order?,scientists.sort_values('name')['name']
find the number of scientists involved for each project name.,"pd.merge(projects, assignedto, left_on='code', right_on='project').groupby('name').size().reset_index(name='count')"
"what are the naems of all the projects, and how many scientists were assigned to each of them?","pd.merge(projects, assignedto, left_on='code', right_on='project').groupby('name').size().reset_index(name='count')"
find the number of scientists involved for the projects that require more than 300 hours.,"pd.merge(projects, assignedto, left_on='code', right_on='project').loc[lambda x: x['hours'] > 300].groupby('name').size().reset_index(name='count')"
"what are the names of projects that require more than 300 hours, and how many scientists are assigned to each?","pd.merge(projects, assignedto, left_on='code', right_on='project').loc[lambda x: x['hours'] > 300].groupby('name').size().reset_index(name='count')"
find the number of projects which each scientist is working on and scientist's name.,"pd.merge(scientists, assignedto, left_on='ssn', right_on='scientist').groupby('name').size().reset_index(name='count')"
"what are the names of the scientists, and how many projects are each of them working on?","pd.merge(scientists, assignedto, left_on='ssn', right_on='scientist').groupby('name').size().reset_index(name='count')"
find the ssn and name of scientists who are assigned to the project with the longest hours.,"scientists.merge(assignedto.merge(projects.query(""hours == hours.max()""), on='project'), on='ssn')[['ssn', 'name']]"
what are the ssn and names of scientists working on the project with the most hours?,"scientists.merge(assignedto.merge(projects.query(""hours == hours.max()""), on='project'), on='ssn')[['ssn', 'name']]"
find the name of scientists who are assigned to some project.,"pd.merge(assignedto, scientists, left_on='scientist', right_on='ssn')['name']"
what are the names of scientists who are assigned to any project?,"pd.merge(assignedto, scientists, left_on='scientist', right_on='ssn')['name']"
select the project names which are not assigned yet.,"projects.loc[~projects['code'].isin(assigned_to['project']), 'name']"
what are the names of projects that have not been assigned?,"projects.loc[~projects['code'].isin(assigned_to['project']), 'name']"
find the name of scientists who are not assigned to any project.,"scientists.loc[~scientists['ssn'].isin(assignedto['scientist']), 'name']"
what are the names of scientists who have not been assigned a project?,"scientists.loc[~scientists['ssn'].isin(assignedto['scientist']), 'name']"
find the number of scientists who are not assigned to any project.,scientists.query('ssn not in assignedto.scientist').shape[0]
how many scientists do not have any projects assigned to them?,scientists.query('ssn not in assignedto.scientist').shape[0]
find the names of scientists who are not working on the project with the highest hours.,"scientists[~scientists['name'].isin(pd.merge(pd.merge(assignedto, projects, left_on='project', right_on='code'), scientists, left_on='scientist', right_on='ssn').loc[lambda x: x['hours']==projects['hours'].max(), 'name'])]['name']"
what are the names of scientists who are not working on the project with the most hours?,"scientists[~scientists['name'].isin(pd.merge(pd.merge(assignedto, projects, left_on='project', right_on='code'), scientists, left_on='scientist', right_on='ssn').loc[lambda x: x['hours']==projects['hours'].max(), 'name'])]['name']"
"list all the scientists' names, their projects' names, and the hours worked by that scientist on each project, in alphabetical order of project name, and then scientist name.","pd.merge(pd.merge(scientists, assignedto, on='ssn'), projects, left_on='project', right_on='code')[['name_x', 'name_y', 'hours']].sort_values(['name_y', 'name_x'])"
find name of the project that needs the least amount of time to finish and the name of scientists who worked on it.,"(pd.merge(pd.merge(assignedto, projects, left_on='project', right_on='code'), scientists, left_on='scientist', right_on='ssn').loc[lambda x: x['hours']==projects['hours'].min(), ['name_x', 'name_y']])"
"what is the name of the project that requires the fewest number of hours, and the names of the scientists assigned to it?","(pd.merge(pd.merge(assignedto, projects, left_on='project', right_on='code'), scientists, left_on='scientist', right_on='ssn').loc[lambda x: x['hours']==projects['hours'].min(), ['name_x', 'name_y']])"
what is the name of the highest rated wine?,wine.sort_values('score').iloc[0]['name']
give the name of the wine with the highest score.,wine.sort_values('score').iloc[0]['name']
which winery is the wine that has the highest score from?,wine.sort_values('score').iloc[0]['winery']
what is the winery at which the wine with the highest score was made?,wine.sort_values('score').iloc[0]['winery']
find the names of all wines produced in 2008.,"wine.loc[lambda x: x['year']=='2008', 'name']"
what are the names of all wines produced in 2008?,"wine.loc[lambda x: x['year']=='2008', 'name']"
list the grapes and appelations of all wines.,"wine[['grape', 'appelation']]"
what are the grapes and appelations of each wine?,"wine[['grape', 'appelation']]"
list the names and scores of all wines.,"wine[['name', 'score']]"
what are the names and scores of all wines?,"wine[['name', 'score']]"
list the area and county of all appelations.,"appellations[['area', 'county']]"
what are the areas and counties for all appelations?,"appellations[['area', 'county']]"
what are the prices of wines produced before the year of 2010?,"wine.loc[wine['year'] < 2010, 'price']"
return the prices of wines produced before 2010.,"wine.loc[wine['year'] < 2010, 'price']"
list the names of all distinct wines that have scores higher than 90.,"wine.loc[wine['score'] > 90, 'name']"
what are the names of wines with scores higher than 90?,"wine.loc[wine['score'] > 90, 'name']"
list the names of all distinct wines that are made of red color grape.,"pd.merge(grapes.loc[lambda x: x['color']=='red'], wine, on='grape')['name'].unique()"
what are the names of wines made from red grapes?,"pd.merge(grapes.loc[lambda x: x['color']=='red'], wine, on='grape')['name'].unique()"
find the names of all distinct wines that have appellations in north coast area.,"pd.merge(appellations, wine, on='appelation').loc[lambda x: x['area']=='north coast', 'name'].unique()"
what are the distinct names of wines that have appellations in the north coast area?,"pd.merge(appellations, wine, on='appelation').loc[lambda x: x['area']=='north coast', 'name'].unique()"
how many wines are produced at robert biale winery?,(wine['winery'] == 'robert biale').sum()
count the number of wines produced at robert biale winery.,(wine['winery'] == 'robert biale').sum()
how many appelations are in napa country?,(apellations['county'] == 'napa').sum()
count the number of appelations in napa county.,(apellations['county'] == 'napa').sum()
give me the average prices of wines that are produced by appelations in sonoma county.,"pd.merge(applations, wine, on='appelation').loc[lambda x: x['county']=='sonoma', 'price'].mean()"
what is the average price of wines produced in appelations in sonoma county?,"pd.merge(applations, wine, on='appelation').loc[lambda x: x['county']=='sonoma', 'price'].mean()"
what are the names and scores of wines that are made of white color grapes?,"pd.merge(grapes.loc[lambda x: x['color'] == 'white'], wine, on='grape')[['name', 'score']]"
give the names and scores of wines made from white grapes.,"pd.merge(grapes.loc[lambda x: x['color'] == 'white'], wine, on='grape')[['name', 'score']]"
find the maximum price of wins from the appelations in central coast area and produced before the year of 2005.,"wine.merge(apellations, left_on='appelation', right_on='appelation').loc[(wine['year'] < 2005) & (apellations['area'] == 'central coast'), 'price'].max()"
"what is the maximum price of wines from the appelation in the central coast area, which was produced before 2005?","wine.merge(apellations, left_on='appelation', right_on='appelation').loc[(wine['year'] < 2005) & (apellations['area'] == 'central coast'), 'price'].max()"
find the the grape whose white color grapes are used to produce wines with scores higher than 90.,"pd.merge(grapes[grapes['color']=='white'], wine[wine['score']>90], on='grape')['grape'].unique()"
find the white grape used to produce wines with scores above 90.,"pd.merge(grapes[grapes['color']=='white'], wine[wine['score']>90], on='grape')['grape'].unique()"
what are the wines that have prices higher than 50 and made of red color grapes?,"pd.merge(grapes.loc[lambda x: x['color']=='red'], wine.loc[lambda x: x['price']>50], on='grape')['name']"
what are the names of wines made from red grapes and with prices above 50?,"pd.merge(grapes.loc[lambda x: x['color']=='red'], wine.loc[lambda x: x['price']>50], on='grape')['name']"
what are the wines that have prices lower than 50 and have appelations in monterey county?,"pd.merge(appellations, wine, on='appelation').loc[(lambda x: x['county']=='monterey') & (lambda x: x['price'] < 50), 'name']"
give the neames of wines with prices below 50 and with appelations in monterey county.,"pd.merge(appellations, wine, on='appelation').loc[(lambda x: x['county']=='monterey') & (lambda x: x['price'] < 50), 'name']"
what are the numbers of wines for different grapes?,wine.groupby('grape').size().reset_index(name='count')
how many wines are there for each grape?,wine.groupby('grape').size().reset_index(name='count')
what are the average prices of wines for different years?,wine.groupby('year')['price'].mean()
what is the average prices of wines for each each?,wine.groupby('year')['price'].mean()
find the distinct names of all wines that have prices higher than some wines from john anthony winery.,"wine.loc[wine['price'] > wine.loc[wine['winery'] == 'john anthony', 'price'].min(), 'name'].unique()"
what are the distinct names of wines with prices higher than any wine from john anthony winery.,"wine.loc[wine['price'] > wine.loc[wine['winery'] == 'john anthony', 'price'].min(), 'name'].unique()"
list the names of all distinct wines in alphabetical order.,wine['name'].sort_values().unique()
"what are the names of wines, sorted in alphabetical order?",wine['name'].sort_values().unique()
list the names of all distinct wines ordered by price.,wine.sort_values('price')['name'].unique()
"what are the names of wines, sorted by price ascending?",wine.sort_values('price')['name'].unique()
what is the area of the appelation that produces the highest number of wines before the year of 2010?,"appellations.merge(wine.loc[lambda x: x['year']<2010], left_on='appelation', right_on='appelation').groupby('appelation')['area'].count().sort_values(ascending=false).index[0]"
what is the area for the appelation which produced the most wines prior to 2010?,"appellations.merge(wine.loc[lambda x: x['year']<2010], left_on='appelation', right_on='appelation').groupby('appelation')['area'].count().sort_values(ascending=false).index[0]"
what is the color of the grape whose wine products has the highest average price?,"pd.merge(grapes, wine, on='grape').groupby('grape')['price'].mean().sort_values(ascending=false).index[0]"
give the color of the grape whose wine products have the highest average price?,"pd.merge(grapes, wine, on='grape').groupby('grape')['price'].mean().sort_values(ascending=false).index[0]"
find the distinct names of wines produced before the year of 2000 or after the year of 2010.,"wine.loc[lambda x: (x['year'] < 2000) | (x['year'] > 2010), 'name'].unique()"
give the distinct names of wines made before 2000 or after 2010.,"wine.loc[lambda x: (x['year'] < 2000) | (x['year'] > 2010), 'name'].unique()"
find the distinct winery of wines having price between 50 and 100.,"wine.loc[lambda x: x['price'].between(50, 100), 'winery'].unique()"
what are the distinct wineries which produce wines costing between 50 and 100?,"wine.loc[lambda x: x['price'].between(50, 100), 'winery'].unique()"
what are the average prices and cases of wines produced in the year of 2009 and made of zinfandel grape?,"wine.loc[(wine['year']==2009) & (wine['grape']=='zinfandel'), ['price', 'cases']].mean()"
give the average price and case of wines made from zinfandel grapes in the year 2009.,"wine.loc[(wine['year']==2009) & (wine['grape']=='zinfandel'), ['price', 'cases']].mean()"
what are the maximum price and score of wines produced by st. helena appelation?,"wine.loc[wine['appelation'] == 'st. helena', ['price', 'score']].max()"
give the maximum price and score for wines produced in the appelation st. helena.,"wine.loc[wine['appelation'] == 'st. helena', ['price', 'score']].max()"
what are the maximum price and score of wines in each year?,"wine.groupby('year').agg({'price': 'max', 'score': 'max'})"
what are the maximum price and score of wines for each year?,"wine.groupby('year').agg({'price': 'max', 'score': 'max'})"
what are the average price and score of wines grouped by appelation?,"wine.groupby('appelation').agg({'price': 'mean', 'score': 'mean'})"
what are the average price and score of wines for each appelation?,"wine.groupby('appelation').agg({'price': 'mean', 'score': 'mean'})"
find the wineries that have at least four wines.,wine.groupby('winery').filter(lambda x: len(x) >= 4)['winery'].unique()
which wineries produce at least four wines?,wine.groupby('winery').filter(lambda x: len(x) >= 4)['winery'].unique()
find the country of all appelations who have at most three wines.,"pd.merge(applations, wine, left_on='appelation', right_on='appelation').groupby('appelation').filter(lambda x: x.shape[0] <= 3)['county']"
what are the countries for appelations with at most 3 wines?,"pd.merge(applations, wine, left_on='appelation', right_on='appelation').groupby('appelation').filter(lambda x: x.shape[0] <= 3)['county']"
what are the names of wines whose production year are before the year of all wines by brander winery?,"wine.loc[wine['year'] < wine.loc[wine['winery']=='brander', 'year'].min(), 'name']"
what are the names of wines produced before any wine from the brander winery?,"wine.loc[wine['year'] < wine.loc[wine['winery']=='brander', 'year'].min(), 'name']"
what are the names of wines that are more expensive then all wines made in the year 2006?,"wine.loc[wine['price'] > wine['price'].loc[wine['year'] == 2006].max(), 'name']"
give the names of wines with prices above any wine produced in 2006.,"wine.loc[wine['price'] > wine['price'].loc[wine['year'] == 2006].max(), 'name']"
find the top 3 wineries with the greatest number of wines made of white color grapes.,"grapes.merge(wine, on='grape').loc[lambda x: x['color']=='white'].groupby('winery').size().sort_values(ascending=false)[:3].reset_index()['winery']"
which 3 wineries produce the most wines made from white grapes?,"grapes.merge(wine, on='grape').loc[lambda x: x['color']=='white'].groupby('winery').size().sort_values(ascending=false)[:3].reset_index()['winery']"
"list the grape, winery and year of the wines whose price is bigger than 100 ordered by year.","wine.loc[lambda x: x['price'] > 100, ['grape', 'winery', 'year']].sort_values('year')"
"what are the grapes, wineries and years for wines with price higher than 100, sorted by year?","wine.loc[lambda x: x['price'] > 100, ['grape', 'winery', 'year']].sort_values('year')"
"list the grape, appelation and name of wines whose score is higher than 93 ordered by name.","wine.loc[lambda x: x['score'] > 93, ['grape', 'appelation', 'name']].sort_values('name')"
"what are the grapes, appelations, and wines with scores above 93, sorted by name?","wine.loc[lambda x: x['score'] > 93, ['grape', 'appelation', 'name']].sort_values('name')"
find the appelations that produce wines after the year of 2008 but not in central coast area.,"wine.loc[lambda x: x['year'] > 2008, 'appelation'].drop_duplicates().reset_index(drop=true).loc[lambda x: ~(x.isin(appellations.loc[lambda y: y['area']=='central coast', 'appelation']))]"
what are the appelations for wines produced after 2008 but not in the central coast area?,"wine.loc[lambda x: x['year'] > 2008, 'appelation'].drop_duplicates().reset_index(drop=true).loc[lambda x: ~(x.isin(appellations.loc[lambda y: y['area']=='central coast', 'appelation']))]"
find the average price of wines that are not produced from sonoma county.,"wine.loc[~wine['appelation'].isin(pd.merge(appellations.loc[appellations['county']=='sonoma', 'appelation'], wine, on='appelation')['appelation']), 'price'].mean()"
what is the average price for wines not produced in sonoma county?,"wine.loc[~wine['appelation'].isin(pd.merge(appellations.loc[appellations['county']=='sonoma', 'appelation'], wine, on='appelation')['appelation']), 'price'].mean()"
find the county where produces the most number of wines with score higher than 90.,"pd.merge(apellations, wine, left_on='appelation', right_on='appelation').loc[lambda x: x['score'] > 90].groupby('county').size().sort_values(ascending=false).head(1).index[0]"
what is the county that produces the most wines scoring higher than 90?,"pd.merge(apellations, wine, left_on='appelation', right_on='appelation').loc[lambda x: x['score'] > 90].groupby('county').size().sort_values(ascending=false).head(1).index[0]"
how many train stations are there?,station.shape[0]
"show the name, location, and number of platforms for all stations.","station[['name', 'location', 'number_of_platforms']]"
what are all locations of train stations?,station['location'].unique()
show the names and total passengers for all train stations not in london.,"station.loc[lambda x: x['location']!='london', ['name', 'total_passengers']]"
show the names and main services for train stations that have the top three total number of passengers.,"station[['name', 'main_services']].sort_values('total_passengers', ascending=false).head(3)"
what is the average and maximum number of total passengers for train stations in london or glasgow?,"station.loc[lambda x: x['location'].isin(['london', 'glasgow'])].agg({'total_passengers': ['mean', 'max']})"
show all locations and the total number of platforms and passengers for all train stations in each location.,"station.groupby('location').agg({'number_of_platforms': 'sum', 'total_passengers': 'sum'})"
show all locations that have train stations with at least 15 platforms and train stations with more than 25 total passengers.,"station.loc[(station['number_of_platforms'] >= 15) & (station['total_passengers'] > 25), 'location'].unique()"
show all locations which don't have a train station with at least 15 platforms.,"station.loc[~(station['number_of_platforms'] >= 15), 'location']"
show the location with most number of train stations.,station.groupby('location').size().sort_values(ascending=false).index[0]
"show the name, time, and service for all trains.","train[['name','time','service']]"
show the number of trains,train.shape[0]
show the name and service for all trains in order by time.,"train.sort_values('time')[['name', 'service']]"
show the station name and number of trains in each station.,"train_station.merge(station, on='station_id').groupby('name')['name'].count()"
show the train name and station name for each train.,"pd.merge(pd.merge(train_station, station, on='station_id'), train, on='train_id')[['name_x', 'name_y']]"
show all train names and times in stations in london in descending order by train time.,"pd.merge(pd.merge(train_station, station, on='station_id'), train, on='train_id').loc[lambda x: x['location']=='london', ['name', 'time']].sort_values('time', ascending=false)"
show the station name with greatest number of trains.,"pd.merge(train_station, station, on='station_id').groupby('station_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['name']"
show the station name with at least two trains.,"station.merge(train_station, on='station_id').groupby('station_id').filter(lambda x: len(x) >= 2)['name']"
show all locations with only 1 station.,station.groupby('location').filter(lambda x: len(x)==1)['location']
show station names without any trains.,station[~station['station_id'].isin(train_station['station_id'])]['name']
"what are the names of the stations which serve both ""ananthapuri express"" and ""guruvayur express"" trains?","station.loc[pd.merge(train_station.loc[train_station['train_id'].isin(train.loc[train['name']=='ananthapuri express', 'train_id'])], station, on='station_id')['name'].isin(pd.merge(train_station.loc[train_station['train_id'].isin(train.loc[train['name']=='guruvayur express', 'train_id'])], station, on='station_id')['name'])]['name']"
find the names of the trains that do not pass any station located in london.,"train_station.merge(train, on='train_id').loc[~train_station['station_id'].isin(station.loc[station['location']=='london', 'station_id']), 'name']"
list the names and locations of all stations ordered by their yearly entry exit and interchange amounts.,"station[['name', 'location', 'annual_entry_exit', 'annual_interchanges']].sort_values(['annual_entry_exit', 'annual_interchanges'])[['name', 'location']]"
list all vehicle id,vehicles['vehicle_id']
what are the ids of all vehicles?,vehicles['vehicle_id']
how many vehicle in total?,vehicles.shape[0]
how many vehicles exist?,vehicles.shape[0]
show the detail of vehicle with id 1.,"vehicles.loc[lambda x: x['vehicle_id']==1, 'vehicle_details']"
what are the details of the car with id 1?,"vehicles.loc[lambda x: x['vehicle_id']==1, 'vehicle_details']"
list the first name middle name and last name of all staff.,"staff[['first_name', 'middle_name', 'last_name']]"
"what are the first, middle, and last names of all staff?","staff[['first_name', 'middle_name', 'last_name']]"
what is the birthday of the staff member with first name as janessa and last name as sawayn?,"staff.loc[(staff['first_name'] == 'janessa') & (staff['last_name'] == 'sawayn'), 'date_of_birth']"
what is the date of birth for the staff member named janessa sawayn?,"staff.loc[(staff['first_name'] == 'janessa') & (staff['last_name'] == 'sawayn'), 'date_of_birth']"
when did the staff member with first name as janessa and last name as sawayn join the company?,"staff.loc[(staff['first_name']=='janessa') & (staff['last_name']=='sawayn'), 'date_joined_staff']"
when did the staff member named janessa sawayn join the company?,"staff.loc[(staff['first_name']=='janessa') & (staff['last_name']=='sawayn'), 'date_joined_staff']"
when did the staff member with first name as janessa and last name as sawayn leave the company?,"staff.loc[(staff['first_name']=='janessa')&(staff['last_name']=='sawayn'), 'date_left_staff']"
when did the staff member janessa sawayn leave the company?,"staff.loc[(staff['first_name']=='janessa')&(staff['last_name']=='sawayn'), 'date_left_staff']"
how many staff have the first name ludie?,(staff['first_name'] == 'ludie').sum()
how many employees have a first name of ludie?,(staff['first_name'] == 'ludie').sum()
what is the nickname of staff with first name as janessa and last name as sawayn?,"staff.loc[(staff['first_name']=='janessa') & (staff['last_name']=='sawayn'), 'nickname']"
what is the nickname of the employee named janessa sawayn?,"staff.loc[(staff['first_name']=='janessa') & (staff['last_name']=='sawayn'), 'nickname']"
how many staff in total?,staff.shape[0]
how many employees are there?,staff.shape[0]
which city does staff with first name as janessa and last name as sawayn live?,"addresses.loc[lambda x: ((x['address_id'].isin(staff.loc[lambda y: (y['first_name']=='janessa')&(y['last_name']=='sawayn'), 'staff_address_id']))),'city']"
in what city does janessa sawayn live?,"addresses.loc[lambda x: ((x['address_id'].isin(staff.loc[lambda y: (y['first_name']=='janessa')&(y['last_name']=='sawayn'), 'staff_address_id']))),'city']"
which country and state does staff with first name as janessa and last name as sawayn lived?,"addresses.merge(staff.loc[(staff['first_name']=='janessa') & (staff['last_name']=='sawayn'), ['staff_address_id']], left_on='address_id', right_on='staff_address_id')[['country', 'state_province_county']]"
in which country and state does janessa sawayn live?,"addresses.merge(staff.loc[(staff['first_name']=='janessa') & (staff['last_name']=='sawayn'), ['staff_address_id']], left_on='address_id', right_on='staff_address_id')[['country', 'state_province_county']]"
how long is the total lesson time took by customer with first name as rylan and last name as goodwin?,"lessons.merge(customers).loc[lambda x: (x['first_name']=='rylan') & (x['last_name']=='goodwin'), 'lesson_time'].sum()"
how long is the total lesson time took by the customer named rylan goodwin?,"lessons.merge(customers).loc[lambda x: (x['first_name']=='rylan') & (x['last_name']=='goodwin'), 'lesson_time'].sum()"
what is the zip code of staff with first name as janessa and last name as sawayn lived?,"addresses.merge(staff.loc[(staff['first_name']=='janessa') & (staff['last_name']=='sawayn'), ['staff_address_id']], left_on='address_id', right_on='staff_address_id')['zip_postcode']"
what is the zip code of the hosue of the employee named janessa sawayn?,"addresses.merge(staff.loc[(staff['first_name']=='janessa') & (staff['last_name']=='sawayn'), ['staff_address_id']], left_on='address_id', right_on='staff_address_id')['zip_postcode']"
how many staff live in state georgia?,(len(addresses.loc[lambda x: x['state_province_county']=='georgia']))
how many employees live in georgia?,(len(addresses.loc[lambda x: x['state_province_county']=='georgia']))
find out the first name and last name of staff lived in city damianfort.,"pd.merge(addresses, staff, left_on='address_id', right_on='staff_address_id').loc[lambda x: x['city']=='damianfort', ['first_name', 'last_name']]"
what is the first and last name of all employees who live in the city damianfort?,"pd.merge(addresses, staff, left_on='address_id', right_on='staff_address_id').loc[lambda x: x['city']=='damianfort', ['first_name', 'last_name']]"
which city lives most of staffs? list the city name and number of staffs.,"pd.merge(addresses, staff, left_on='address_id', right_on='staff_address_id').groupby('city').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
in which city do the most employees live and how many of them live there?,"pd.merge(addresses, staff, left_on='address_id', right_on='staff_address_id').groupby('city').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
list the states which have between 2 to 4 staffs living there.,"addresses.merge(staff, left_on='address_id', right_on='staff_address_id').groupby('state_province_county').filter(lambda x: 2<=x.shape[0]<=4).state_province_county.unique()"
what are the names of the states that have 2 to 4 employees living there?,"addresses.merge(staff, left_on='address_id', right_on='staff_address_id').groupby('state_province_county').filter(lambda x: 2<=x.shape[0]<=4).state_province_county.unique()"
list the first name and last name of all customers.,"customers[['first_name', 'last_name']]"
what are the first and last names for all customers?,"customers[['first_name', 'last_name']]"
list email address and birthday of customer whose first name as carole.,"customers.loc[lambda x: x['first_name']=='carole', ['email_address', 'date_of_birth']]"
what are the email addresses and date of births for all customers who have a first name of carole?,"customers.loc[lambda x: x['first_name']=='carole', ['email_address', 'date_of_birth']]"
list phone number and email address of customer with more than 2000 outstanding balance.,"customers.loc[lambda x: x['amount_outstanding'] > 2000, ['phone_number', 'email_address']]"
what are the phone numbers and email addresses of all customers who have an outstanding balance of more than 2000?,"customers.loc[lambda x: x['amount_outstanding'] > 2000, ['phone_number', 'email_address']]"
"what is the status code, mobile phone number and email address of customer with last name as kohler or first name as marina?","customers.loc[(customers['first_name']=='marina') | (customers['last_name']=='kohler'), ['customer_status_code', 'cell_mobile_phone_number', 'email_address']]"
"what is the status code, phone number, and email address of the customer whose last name is kohler or whose first name is marina?","customers.loc[(customers['first_name']=='marina') | (customers['last_name']=='kohler'), ['customer_status_code', 'cell_mobile_phone_number', 'email_address']]"
when are the birthdays of customer who are classified as 'good customer' status?,"customers.loc[lambda x: x['customer_status_code']=='good customer', 'date_of_birth']"
what is the date of birth of every customer whose status code is 'good customer'?,"customers.loc[lambda x: x['customer_status_code']=='good customer', 'date_of_birth']"
when did customer with first name as carole and last name as bernhard became a customer?,"customers.loc[(customers['first_name']=='carole') & (customers['last_name']=='bernhard'), 'date_became_customer']"
when did carole bernhard first become a customer?,"customers.loc[(customers['first_name']=='carole') & (customers['last_name']=='bernhard'), 'date_became_customer']"
how many customers in total?,customers.shape[0]
list all customer status codes and the number of customers having each status code.,customers.groupby('customer_status_code').size()
"for each customer status code, how many customers are classified that way?",customers.groupby('customer_status_code').size()
which customer status code has least number of customers?,customers.groupby('customer_status_code').size().nsmallest(n=1).index[0]
what is the status code with the least number of customers?,customers.groupby('customer_status_code').size().nsmallest(n=1).index[0]
how many lessons taken by customer with first name as rylan and last name as goodwin were completed?,"pd.merge(lessons, customers, on='customer_id').loc[(lambda x: x['first_name']=='rylan') & (lambda x: x['last_name']=='goodwin') & (lambda x: x['lesson_status_code']=='completed'),:].shape[0]"
how many lessons did the customer ryan goodwin complete?,"pd.merge(lessons, customers, on='customer_id').loc[(lambda x: x['first_name']=='rylan') & (lambda x: x['last_name']=='goodwin') & (lambda x: x['lesson_status_code']=='completed'),:].shape[0]"
"what is maximum, minimum and average amount of outstanding of customer?","customers['amount_outstanding'].agg(['max', 'min', 'mean'])"
"what is the maximum, minimum, and average amount of money outsanding for all customers?","customers['amount_outstanding'].agg(['max', 'min', 'mean'])"
list the first name and last name of customers have the amount of outstanding between 1000 and 3000.,"customers.loc[(customers['amount_outstanding'] >= 1000) & (customers['amount_outstanding'] <= 3000), ['first_name', 'last_name']]"
what are the first and last names of all customers with between 1000 and 3000 dollars outstanding?,"customers.loc[(customers['amount_outstanding'] >= 1000) & (customers['amount_outstanding'] <= 3000), ['first_name', 'last_name']]"
list first name and last name of customers lived in city lockmanfurt.,"pd.merge(customers, addresses, left_on='customer_address_id', right_on='address_id').loc[lambda x: x['city']=='lockmanfurt', ['first_name', 'last_name']]"
what are the first and last names of all customers who lived in lockmanfurt?,"pd.merge(customers, addresses, left_on='customer_address_id', right_on='address_id').loc[lambda x: x['city']=='lockmanfurt', ['first_name', 'last_name']]"
which country does customer with first name as carole and last name as bernhard lived in?,"addresses.loc[lambda x: x['address_id'].isin(customers.loc[lambda y: (y['first_name'] == 'carole') & (y['last_name'] == 'bernhard'), 'customer_address_id']), 'country']"
what is the country in which the customer carole bernhard lived?,"addresses.loc[lambda x: x['address_id'].isin(customers.loc[lambda y: (y['first_name'] == 'carole') & (y['last_name'] == 'bernhard'), 'customer_address_id']), 'country']"
what is zip code of customer with first name as carole and last name as bernhard?,"customers.merge(addresses, left_on='customer_address_id', right_on='address_id').loc[(customers['first_name']=='carole')&(customers['last_name']=='bernhard'), 'zip_postcode']"
what is the zip code of the customer carole bernhard?,"customers.merge(addresses, left_on='customer_address_id', right_on='address_id').loc[(customers['first_name']=='carole')&(customers['last_name']=='bernhard'), 'zip_postcode']"
which city does has most number of customers?,"(pd.merge(customers, addresses, left_on='customer_address_id', right_on='address_id').groupby('city').size().sort_values(ascending=false).index[0])"
what is the city with the most customers?,"(pd.merge(customers, addresses, left_on='customer_address_id', right_on='address_id').groupby('city').size().sort_values(ascending=false).index[0])"
how much in total does customer with first name as carole and last name as bernhard paid?,"pd.merge(customer_payments, customers, on='customer_id').query('first_name == ""carole"" and last_name == ""bernhard""')['amount_payment'].sum()"
what is the total amount of moeny paid by the customer carole bernhard?,"pd.merge(customer_payments, customers, on='customer_id').query('first_name == ""carole"" and last_name == ""bernhard""')['amount_payment'].sum()"
list the number of customers that did not have any payment history.,customers.loc[~customers['customer_id'].isin(customer_payments['customer_id'])].shape[0]
how many customers have no payment histories?,customers.loc[~customers['customer_id'].isin(customer_payments['customer_id'])].shape[0]
list first name and last name of customers that have more than 2 payments.,"payments.merge(customers, on='customer_id').groupby(['customer_id', 'first_name', 'last_name']).filter(lambda x: len(x) > 2)[['first_name', 'last_name']].drop_duplicates()"
what are the first and last names of all customers with more than 2 payments?,"payments.merge(customers, on='customer_id').groupby(['customer_id', 'first_name', 'last_name']).filter(lambda x: len(x) > 2)[['first_name', 'last_name']].drop_duplicates()"
list all payment methods and number of payments using each payment methods.,customer_payments.groupby('payment_method_code').size()
"for each payment method, how many payments were made?",customer_payments.groupby('payment_method_code').size()
how many lessons were in cancelled state?,(lessons['lesson_status_code']=='cancelled').sum()
how many lessons have been cancelled?,(lessons['lesson_status_code']=='cancelled').sum()
"list lesson id of all lessons taught by staff with first name as janessa, last name as sawayn and nickname containing letter 's'.","lessons.merge(staff.loc[(staff['first_name']=='janessa')&(staff['last_name']=='sawayn')&(staff['nickname'].str.contains('s'))], on='staff_id')['lesson_id']"
what are the the lesson ids of all staff taught by janessa sawayn whose nickname has the letter s?,"lessons.merge(staff.loc[(staff['first_name']=='janessa')&(staff['last_name']=='sawayn')&(staff['nickname'].str.contains('s'))], on='staff_id')['lesson_id']"
how many lessons taught by staff whose first name has letter 'a' in it?,"pd.merge(lessons, staff, on='staff_id').loc[lambda x: x['first_name'].str.contains('a'), :].shape[0]"
how many lessons were taught by a staff member whose first name has the letter 'a' in it?,"pd.merge(lessons, staff, on='staff_id').loc[lambda x: x['first_name'].str.contains('a'), :].shape[0]"
how long is the total lesson time taught by staff with first name as janessa and last name as sawayn?,"pd.merge(lessons, staff, on='staff_id').loc[lambda x: (x['first_name']=='janessa')&(x['last_name']=='sawayn'), 'lesson_time'].sum()"
what is the total time for all lessons taught by janessa sawayn?,"pd.merge(lessons, staff, on='staff_id').loc[lambda x: (x['first_name']=='janessa')&(x['last_name']=='sawayn'), 'lesson_time'].sum()"
what is average lesson price taught by staff with first name as janessa and last name as sawayn?,"pd.merge(lessons, staff, on='staff_id').loc[lambda x: (x['first_name'] == 'janessa') & (x['last_name'] == 'sawayn'), 'price'].mean()"
what is the average price for a lesson taught by janessa sawayn?,"pd.merge(lessons, staff, on='staff_id').loc[lambda x: (x['first_name'] == 'janessa') & (x['last_name'] == 'sawayn'), 'price'].mean()"
how many lesson does customer with first name ray took?,"pd.merge(lessons, customers, on='customer_id').loc[lambda x: x['first_name']=='ray'].shape[0]"
how many lessons did the customer with the first name ray take?,"pd.merge(lessons, customers, on='customer_id').loc[lambda x: x['first_name']=='ray'].shape[0]"
which last names are both used by customers and by staff?,pd.series(list(set(customers['last_name']) & set(staff['last_name'])))
what are the last names that are used by customers and staff?,pd.series(list(set(customers['last_name']) & set(staff['last_name'])))
what is the first name of the staff who did not give any lesson?,"staff['first_name'].loc[~staff['staff_id'].isin(lessons.merge(staff, on='staff_id')['staff_id'])]"
what is the first name of all employees who do not give any lessons?,"staff['first_name'].loc[~staff['staff_id'].isin(lessons.merge(staff, on='staff_id')['staff_id'])]"
what is the id and detail of the vehicle used in lessons for most of the times?,"vehicles.merge(lessons, on='vehicle_id').groupby(['vehicle_id', 'vehicle_details']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['vehicle_id', 'vehicle_details']]"
how many faculty do we have?,faculty.shape[0]
what is the total number of faculty members?,faculty.shape[0]
what ranks do we have for faculty?,faculty['rank'].unique()
find the list of distinct ranks for faculty.,faculty['rank'].unique()
show all the distinct buildings that have faculty rooms.,faculty['building'].unique()
what buildings have faculty offices?,faculty['building'].unique()
"show the rank, first name, and last name for all the faculty.","faculty[['rank', 'fname', 'lname']]"
"what are the rank, first name, and last name of the faculty members?","faculty[['rank', 'fname', 'lname']]"
"show the first name, last name, and phone number for all female faculty members.","faculty.loc[faculty['sex']=='f', ['fname', 'lname', 'phone']]"
"what are the first name, last name, and phone number of all the female faculty members?","faculty.loc[faculty['sex']=='f', ['fname', 'lname', 'phone']]"
show ids for all the male faculty.,"faculty.loc[lambda x: x['sex']=='m', 'facid']"
what are the faculty ids of all the male faculty members?,"faculty.loc[lambda x: x['sex']=='m', 'facid']"
how many female professors do we have?,"faculty.loc[(faculty['sex']=='f') & (faculty['rank'] == 'professor'), :].shape[0]"
count the number of female professors we have.,"faculty.loc[(faculty['sex']=='f') & (faculty['rank'] == 'professor'), :].shape[0]"
"show the phone, room, and building for the faculty named jerry prince.","faculty.loc[(faculty['fname']=='jerry') & (faculty['lname']=='prince'), ['phone', 'room', 'building']]"
"what are the phone, room, and building of the faculty member called jerry prince?","faculty.loc[(faculty['fname']=='jerry') & (faculty['lname']=='prince'), ['phone', 'room', 'building']]"
how many professors are in building neb?,faculty[(faculty['rank']=='professor') & (faculty['building']=='neb')].shape[0]
count the number of professors who have office in building neb.,faculty[(faculty['rank']=='professor') & (faculty['building']=='neb')].shape[0]
show the first name and last name for all the instructors.,"faculty.loc[lambda x: x['rank']=='instructor', ['fname', 'lname']]"
what are the first name and last name of all the instructors?,"faculty.loc[lambda x: x['rank']=='instructor', ['fname', 'lname']]"
show all the buildings along with the number of faculty members the buildings have.,faculty.groupby('building').size()
how many faculty members does each building have? list the result with the name of the building.,faculty.groupby('building').size()
which building has most faculty members?,faculty['building'].value_counts().index[0]
find the building that has the largest number of faculty members.,faculty['building'].value_counts().index[0]
show all the buildings that have at least 10 professors.,faculty.loc[lambda x: x['rank']=='professor'].groupby('building').filter(lambda x: len(x)>=10)['building'].unique()
in which buildings are there at least ten professors?,faculty.loc[lambda x: x['rank']=='professor'].groupby('building').filter(lambda x: len(x)>=10)['building'].unique()
"for each faculty rank, show the number of faculty members who have it.",faculty.groupby('rank').size().reset_index(name='count')
how many faculty members do we have for each faculty rank?,faculty.groupby('rank').size().reset_index(name='count')
show all the ranks and the number of male and female faculty for each rank.,"faculty.groupby(['rank', 'sex']).size().reset_index(name='count')"
how many faculty members do we have for each rank and gender?,"faculty.groupby(['rank', 'sex']).size().reset_index(name='count')"
which rank has the smallest number of faculty members?,faculty.groupby('rank').size().sort_values().index[0]
find the faculty rank that has the least members.,faculty.groupby('rank').size().sort_values().index[0]
show the number of male and female assistant professors.,faculty.loc[faculty['rank']=='asstprof'].groupby('sex').size()
how many male and female assistant professors do we have?,faculty.loc[faculty['rank']=='asstprof'].groupby('sex').size()
what are the first name and last name of linda smith's advisor?,"pd.merge(student.loc[(student['fname']=='linda') & (student['lname']=='smith')], faculty, left_on='advisor', right_on='facid')[['fname_x', 'lname_x']]"
who is the advisor of linda smith? give me the first name and last name.,"pd.merge(student.loc[(student['fname']=='linda') & (student['lname']=='smith')], faculty, left_on='advisor', right_on='facid')[['fname_x', 'lname_x']]"
show the ids of students whose advisors are professors.,"pd.merge(faculty.loc[lambda x: x['rank']=='professor', ['facid']], student, left_on='facid', right_on='advisor')['stuid']"
which students have professors as their advisors? find their student ids.,"pd.merge(faculty.loc[lambda x: x['rank']=='professor', ['facid']], student, left_on='facid', right_on='advisor')['stuid']"
show first name and last name for all the students advised by michael goodrich.,"faculty.merge(student, how='inner', left_on='facid', right_on='advisor').loc[(faculty['fname']=='michael')&(faculty['lname']=='goodrich'), ['fname','lname']]"
which students are advised by michael goodrich? give me their first and last names.,"faculty.merge(student, how='inner', left_on='facid', right_on='advisor').loc[(faculty['fname']=='michael')&(faculty['lname']=='goodrich'), ['fname','lname']]"
"show the faculty id of each faculty member, along with the number of students he or she advises.","student.groupby('advisor').size().reset_index(name='count').merge(faculty, left_on='advisor', right_on='facid')[['facid', 'count']]"
what are the faculty id and the number of students each faculty has?,"student.groupby('advisor').size().reset_index(name='count').merge(faculty, left_on='advisor', right_on='facid')[['facid', 'count']]"
show all the faculty ranks and the number of students advised by each rank.,"faculty.merge(student, left_on='facid', right_on='advisor').groupby('rank', as_index=false)['rank'].agg({'count': 'count'})[['rank', 'count']]"
how many students are advised by each rank of faculty? list the rank and the number of students.,"faculty.merge(student, left_on='facid', right_on='advisor').groupby('rank', as_index=false)['rank'].agg({'count': 'count'})[['rank', 'count']]"
what are the first and last name of the faculty who has the most students?,"pd.merge(faculty, student, left_on='facid', right_on='advisor').groupby(['facid', 'fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0, :2]"
give me the the first and last name of the faculty who advises the most students.,"pd.merge(faculty, student, left_on='facid', right_on='advisor').groupby(['facid', 'fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0, :2]"
show the ids for all the faculty members who have at least 2 students.,"pd.merge(faculty, student, left_on='facid', right_on='advisor').groupby('facid').filter(lambda x: len(x) >= 2)['facid']"
which faculty members advise two ore more students? give me their faculty ids.,"pd.merge(faculty, student, left_on='facid', right_on='advisor').groupby('facid').filter(lambda x: len(x) >= 2)['facid']"
show ids for the faculty members who don't advise any student.,faculty['facid'].difference(student['advisor'])
what are the ids of the faculty members who do not advise any student.,faculty['facid'].difference(student['advisor'])
what activities do we have?,activity['activity_name']
list all the activities we have.,activity['activity_name']
how many activities do we have?,activity.shape[0]
find the number of activities available.,activity.shape[0]
how many faculty members participate in an activity?,faculty_participates_in['facid'].nunique()
give me the number of faculty members who participate in an activity,faculty_participates_in['facid'].nunique()
show the ids of the faculty who don't participate in any activity.,"pd.concat([faculty['facid'], faculty_participates_in['facid']]).drop_duplicates(keep=false)"
which faculty do not participate in any activity? find their faculty ids.,"pd.concat([faculty['facid'], faculty_participates_in['facid']]).drop_duplicates(keep=false)"
show the ids of all the faculty members who participate in an activity and advise a student.,faculty_participates_in['facid'].interesect(student['advisor'])
what are ids of the faculty members who not only participate in an activity but also advise a student.,faculty_participates_in['facid'].interesect(student['advisor'])
how many activities does mark giuliano participate in?,"pd.merge(faculty, faculty_participates_in, on='facid').loc[lambda x: (x['fname']=='mark') & (x['lname']=='giuliano'), :].shape[0]"
find the number of activities mark giuliano is involved in.,"pd.merge(faculty, faculty_participates_in, on='facid').loc[lambda x: (x['fname']=='mark') & (x['lname']=='giuliano'), :].shape[0]"
show the names of all the activities mark giuliano participates in.,"pd.merge(pd.merge(faculty, faculty_participates_in, on='facid'), activity, on='actid').loc[lambda x: (x['fname']=='mark') & (x['lname']=='giuliano'), 'activity_name']"
what are the names of the activities mark giuliano is involved in,"pd.merge(pd.merge(faculty, faculty_participates_in, on='facid'), activity, on='actid').loc[lambda x: (x['fname']=='mark') & (x['lname']=='giuliano'), 'activity_name']"
"show the first and last name of all the faculty members who participated in some activity, together with the number of activities they participated in.","pd.merge(faculty, faculty_participates_in, on='facid').groupby(['facid', 'fname', 'lname'])['facid'].count().reset_index(name='count')"
show all the activity names and the number of faculty involved in each activity.,"activity.merge(faculty_participates_in, on='actid').groupby('activity_name')['actid'].count()"
how many faculty members participate in each activity? return the activity names and the number of faculty members.,"activity.merge(faculty_participates_in, on='actid').groupby('activity_name')['actid'].count()"
what is the first and last name of the faculty participating in the most activities?,"faculty_participates_in.merge(faculty, on='facid').groupby(['facid', 'fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['fname', 'lname']]"
find the first and last name of the faculty who is involved in the largest number of activities.,"faculty_participates_in.merge(faculty, on='facid').groupby(['facid', 'fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['fname', 'lname']]"
what is the name of the activity that has the most faculty members involved in?,"activity.loc[faculty_participates_in['actid']].groupby('actid').agg({'activity_name': 'first'}).reset_index().merge(faculty_participates_in.groupby('actid').size().to_frame('count'), on='actid').sort_values('count', ascending=false).iloc[0]['activity_name']"
which activity has the most faculty members participating in? find the activity name.,"activity.loc[faculty_participates_in['actid']].groupby('actid').agg({'activity_name': 'first'}).reset_index().merge(faculty_participates_in.groupby('actid').size().to_frame('count'), on='actid').sort_values('count', ascending=false).iloc[0]['activity_name']"
show the ids of the students who don't participate in any activity.,student[~student['stuid'].isin(participates_in['stuid'])]['stuid']
what are the ids of the students who are not involved in any activity,student[~student['stuid'].isin(participates_in['stuid'])]['stuid']
show the ids for all the students who participate in an activity and are under 20.,"pd.series(list(set(participates_in['stuid'])).intersection(set(student.loc[lambda x: x['age'] < 20, 'stuid'])))"
what are the ids of the students who are under 20 years old and are involved in at least one activity.,"pd.series(list(set(participates_in['stuid'])).intersection(set(student.loc[lambda x: x['age'] < 20, 'stuid'])))"
what is the first and last name of the student participating in the most activities?,"pd.merge(student, participates_in, on='stuid').groupby(['stuid', 'fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['fname', 'lname']]"
tell me the first and last name of the student who has the most activities.,"pd.merge(student, participates_in, on='stuid').groupby(['stuid', 'fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['fname', 'lname']]"
what is the name of the activity with the most students?,"pd.merge(activity, participates_in, on='actid').groupby('actid')['activity_name'].count().sort_values(ascending=false).index[0]"
find the name of the activity that has the largest number of student participants.,"pd.merge(activity, participates_in, on='actid').groupby('actid')['activity_name'].count().sort_values(ascending=false).index[0]"
find the first names of the faculty members who are playing canoeing or kayaking.,"pd.merge(pd.merge(faculty, faculty_participates_in, on='facid'), activity, on='actid').loc[lambda x: x['activity_name'].isin(['canoeing', 'kayaking']), 'lname'].unique()"
which faculty members are playing either canoeing or kayaking? tell me their first names.,"pd.merge(pd.merge(faculty, faculty_participates_in, on='facid'), activity, on='actid').loc[lambda x: x['activity_name'].isin(['canoeing', 'kayaking']), 'lname'].unique()"
find the first names of professors who are not playing canoeing or kayaking.,"faculty.loc[lambda x: x['rank']=='professor', 'lname'].reset_index(drop=true).loc[~faculty_participates_in.merge(activity, on='actid').loc[lambda x: ((x['activity_name']=='canoeing') | (x['activity_name']=='kayaking'))]['facid'].isin(faculty.loc[lambda x: x['rank']=='professor', 'facid']),]"
what are the first names of the professors who do not play canoeing or kayaking as activities?,"faculty.loc[lambda x: x['rank']=='professor', 'lname'].reset_index(drop=true).loc[~faculty_participates_in.merge(activity, on='actid').loc[lambda x: ((x['activity_name']=='canoeing') | (x['activity_name']=='kayaking'))]['facid'].isin(faculty.loc[lambda x: x['rank']=='professor', 'facid']),]"
find the first names of the faculty members who participate in canoeing and kayaking.,"pd.merge(pd.merge(faculty, faculty_participates_in, on='facid'), activity, on='actid').loc[lambda x: x['activity_name']=='canoeing', 'lname'].intersect(pd.merge(pd.merge(faculty, faculty_participates_in, on='facid'), activity, on='actid').loc[lambda x: x['activity_name']=='kayaking', 'lname'])"
what are the first names of the faculty members playing both canoeing and kayaking?,"pd.merge(pd.merge(faculty, faculty_participates_in, on='facid'), activity, on='actid').loc[lambda x: x['activity_name']=='canoeing', 'lname'].intersect(pd.merge(pd.merge(faculty, faculty_participates_in, on='facid'), activity, on='actid').loc[lambda x: x['activity_name']=='kayaking', 'lname'])"
find the ids of the students who participate in canoeing and kayaking.,"pd.merge(participates_in.loc[lambda x: x.merge(activity.loc[lambda x: x['activity_name']=='canoeing'], on='actid').index],activity.loc[lambda x: x['activity_name']=='kayaking'],on='actid')['stuid'].unique()"
which students participate in both canoeing and kayaking as their activities? tell me their student ids.,"pd.merge(participates_in.loc[lambda x: x.merge(activity.loc[lambda x: x['activity_name']=='canoeing'], on='actid').index],activity.loc[lambda x: x['activity_name']=='kayaking'],on='actid')['stuid'].unique()"
find the name of the airport in the city of goroka.,"airports.loc[lambda x: x['city']=='goroka', 'name']"
what are the names of the airports in the city of goroka?,"airports.loc[lambda x: x['city']=='goroka', 'name']"
"find the name, city, country, and altitude (or elevation) of the airports in the city of new york.","airports.loc[lambda x: x['city']=='new york', ['name', 'city', 'country', 'elevation']]"
"what is the name, city, country, and elevation for every airport in the city of new york?","airports.loc[lambda x: x['city']=='new york', ['name', 'city', 'country', 'elevation']]"
how many airlines are there?,airlines.shape[0]
what is the total number of airlines?,airlines.shape[0]
how many airlines does russia has?,(airlines['country'] == 'russia').sum()
what is the number of airlines based in russia?,(airlines['country'] == 'russia').sum()
what is the maximum elevation of all airports in the country of iceland?,"airports.loc[airports['country']=='iceland', 'elevation'].max()"
what is the highest elevation of an airport in the country of iceland?,"airports.loc[airports['country']=='iceland', 'elevation'].max()"
find the name of the airports located in cuba or argentina.,"airports.loc[lambda x: x['country'].isin(['cuba', 'argentina']), 'name']"
what are the names of all airports in cuba or argentina?,"airports.loc[lambda x: x['country'].isin(['cuba', 'argentina']), 'name']"
find the country of the airlines whose name starts with 'orbit'.,"airlines.loc[lambda x: x['name'].str.startswith('orbit'), 'country']"
what are the countries of all airlines whose names start with orbit?,"airlines.loc[lambda x: x['name'].str.startswith('orbit'), 'country']"
find the name of airports whose altitude is between -50 and 50.,"airports.loc[(airports['elevation'] >= -50) & (airports['elevation'] <= 50), 'name']"
what are the names of all airports whose elevation is between -50 and 50?,"airports.loc[(airports['elevation'] >= -50) & (airports['elevation'] <= 50), 'name']"
which country is the airport that has the highest altitude located in?,"airports.sort_values('elevation', ascending=false).iloc[0]['country']"
what is the country of the airport with the highest elevation?,"airports.sort_values('elevation', ascending=false).iloc[0]['country']"
find the number of airports whose name contain the word 'international'.,airports['name'].str.contains('international').sum()
how many airports' names have the word interanation in them?,airports['name'].str.contains('international').sum()
how many different cities do have some airport in the country of greenland?,"airports.loc[airports['country'] == 'greenland', 'city'].nunique()"
in how many cities are there airports in the country of greenland?,"airports.loc[airports['country'] == 'greenland', 'city'].nunique()"
find the number of routes operated by american airlines.,"pd.merge(airlines, routes, on='alid').loc[lambda x: x['name']=='american airlines'].shape[0]"
how many routes does american airlines operate?,"pd.merge(airlines, routes, on='alid').loc[lambda x: x['name']=='american airlines'].shape[0]"
find the number of routes whose destination airports are in canada.,"pd.merge(airports, routes, left_on='apid', right_on='dst_apid').loc[lambda x: x['country']=='canada'].shape[0]"
how many routes end in a canadian airport?,"pd.merge(airports, routes, left_on='apid', right_on='dst_apid').loc[lambda x: x['country']=='canada'].shape[0]"
"find the name, city, and country of the airport that has the lowest altitude.","airports[['name', 'city', 'country', 'elevation']].sort_values('elevation').head(1).reset_index(drop=true).loc[0, ['name', 'city', 'country']]"
"what is the name, city, and country of the airport with the lowest altitude?","airports[['name', 'city', 'country', 'elevation']].sort_values('elevation').head(1).reset_index(drop=true).loc[0, ['name', 'city', 'country']]"
"find the name, city, and country of the airport that has the highest latitude.","airports[['name', 'city', 'country']].sort_values('elevation', ascending=false).iloc[0]"
"what is the name, city, and country of the airport with the highest elevation?","airports[['name', 'city', 'country']].sort_values('elevation', ascending=false).iloc[0]"
find the name and city of the airport which is the destination of the most number of routes.,"airports.merge(routes, left_on='apid', right_on='dst_apid').groupby('dst_apid').size().sort_values(ascending=false).reset_index(name='count').merge(airports, left_on='dst_apid', right_on='apid').iloc[0][['name', 'city', 'dst_apid']]"
what is the name and city of the airport that the most routes end at?,"airports.merge(routes, left_on='apid', right_on='dst_apid').groupby('dst_apid').size().sort_values(ascending=false).reset_index(name='count').merge(airports, left_on='dst_apid', right_on='apid').iloc[0][['name', 'city', 'dst_apid']]"
find the names of the top 10 airlines that operate the most number of routes.,"pd.merge(airlines, routes, on='alid').groupby('alid').size().nlargest(10).rename('count').reset_index().merge(airlines, on='alid')[['name', 'alid']]"
"for the airline ids with the top 10 most routes operated, what are their names?","pd.merge(airlines, routes, on='alid').groupby('alid').size().nlargest(10).rename('count').reset_index().merge(airlines, on='alid')[['name', 'alid']]"
find the name and city of the airport which is the source for the most number of flight routes.,"pd.merge(airports, routes, left_on='apid', right_on='src_apid').groupby('src_apid').agg({'name':'first', 'city':'first', 'src_apid':'first', 'dst_apid':'count'}).sort_values('dst_apid', ascending=false).iloc[0][['name', 'city', 'src_apid']]"
what is the name and city of the airport from most of the routes start?,"pd.merge(airports, routes, left_on='apid', right_on='src_apid').groupby('src_apid').agg({'name':'first', 'city':'first', 'src_apid':'first', 'dst_apid':'count'}).sort_values('dst_apid', ascending=false).iloc[0][['name', 'city', 'src_apid']]"
find the number of different airports which are the destinations of the american airlines.,"pd.merge(airlines, routes, on='alid').loc[lambda x: x['name']=='american airlines', 'dst_apid'].nunique()"
what is the number of different different airports that are destinations for american airlines?,"pd.merge(airlines, routes, on='alid').loc[lambda x: x['name']=='american airlines', 'dst_apid'].nunique()"
which countries has the most number of airlines?,airlines.groupby('country').size().sort_values(ascending=false).index[0]
what is the name of the country with the most number of home airlines?,airlines.groupby('country').size().sort_values(ascending=false).index[0]
which countries has the most number of airlines whose active status is 'y'?,airlines.loc[lambda x: x['active']=='y'].groupby('country').size().sort_values(ascending=false).head(1).index[0]
what are the countries with the most airlines whose active status is y?,airlines.loc[lambda x: x['active']=='y'].groupby('country').size().sort_values(ascending=false).head(1).index[0]
list all countries and their number of airlines in the descending order of number of airlines.,airlines.groupby('country').size().sort_values(ascending=false)
how many airlines operate out of each country in descending order?,airlines.groupby('country').size().sort_values(ascending=false)
how many airports are there per country? order the countries by decreasing number of airports.,airports.groupby('country').size().sort_values(ascending=false).reset_index(name='count(*)')
"what is the number of airports per country, ordered from most to least?",airports.groupby('country').size().sort_values(ascending=false).reset_index(name='count(*)')
how many airports are there per city in the united states? order the cities by decreasing number of airports.,"airports.loc[lambda x: x['country']=='united states'].groupby('city').size().reset_index(name='count').sort_values('count', ascending=false)"
how many airports are there per city in the us ordered from most to least?,"airports.loc[lambda x: x['country']=='united states'].groupby('city').size().reset_index(name='count').sort_values('count', ascending=false)"
return the cities with more than 3 airports in the united states.,airports.loc[lambda x: x['country']=='united states'].groupby('city').filter(lambda x: len(x) > 3)['city'].unique()
what is the number of cities in the united states with more than 3 airports?,airports.loc[lambda x: x['country']=='united states'].groupby('city').filter(lambda x: len(x) > 3)['city'].unique()
how many cities are there that have more than 3 airports?,(airports.groupby('city')['city'].count() > 3).sum()
what is the count of cities with more than 3 airports?,(airports.groupby('city')['city'].count() > 3).sum()
list the cities which have more than one airport and number of airports.,airports.groupby('city').filter(lambda x: len(x) > 1).groupby('city').size()
what are the names of all cities with more than one airport and how many airports do they have?,airports.groupby('city').filter(lambda x: len(x) > 1).groupby('city').size()
list the cities which have more than 2 airports sorted by the number of airports.,airports.groupby('city').filter(lambda x: len(x) > 2).groupby('city').size().sort_values()
what are the cities that have more than 2 airports sorted by number of airports?,airports.groupby('city').filter(lambda x: len(x) > 2).groupby('city').size().sort_values()
find the number of routes for each source airport and the airport name.,"routes.merge(airports, left_on='src_apid', right_on='apid').groupby('name').size().reset_index(name='count')"
"for each airport name, how many routes start at that airport?","routes.merge(airports, left_on='src_apid', right_on='apid').groupby('name').size().reset_index(name='count')"
"find the number of routes and airport name for each source airport, order the results by decreasing number of routes.","pd.merge(airports, routes, left_on='apid', right_on='src_apid').groupby('name').size().reset_index(name='count').sort_values('count', ascending=false)"
"for each  airport name, how many routes start at that airport, ordered from most to least?","pd.merge(airports, routes, left_on='apid', right_on='src_apid').groupby('name').size().reset_index(name='count').sort_values('count', ascending=false)"
find the average elevation of all airports for each country.,airports.groupby('country')['elevation'].mean()
"for each country, what is the average elevation of that country's airports?",airports.groupby('country')['elevation'].mean()
find the cities which have exactly two airports.,airports.groupby('city').filter(lambda x: len(x) == 2)['city'].unique()
what are the cities with exactly two airports?,airports.groupby('city').filter(lambda x: len(x) == 2)['city'].unique()
"for each country and airline name, how many routes are there?","routes.merge(airlines, on='alid').groupby(['country', 'name']).size().reset_index(name='count')"
what is the total number of routes for each country and airline in that country?,"routes.merge(airlines, on='alid').groupby(['country', 'name']).size().reset_index(name='count')"
find the number of routes with destination airports in italy.,"pd.merge(routes, airports, left_on='dst_apid', right_on='apid').loc[lambda x: x['country']=='italy'].shape[0]"
what is the number of routes whose destinations are italian airports?,"pd.merge(routes, airports, left_on='dst_apid', right_on='apid').loc[lambda x: x['country']=='italy'].shape[0]"
return the number of routes with destination airport in italy operated by the airline with name 'american airlines'.,"pd.merge(pd.merge(routes, airports, left_on='dst_apid', right_on='apid'), airlines, on='alid').loc[(lambda x: (x['country']=='italy') & (x['name']=='american airlines'))].shape[0]"
what is the number of routes operated by the airline american airlines whose destinations are in italy?,"pd.merge(pd.merge(routes, airports, left_on='dst_apid', right_on='apid'), airlines, on='alid').loc[(lambda x: (x['country']=='italy') & (x['name']=='american airlines'))].shape[0]"
find the number of routes that have destination john f kennedy international airport.,"pd.merge(airports, routes, left_on='apid', right_on='dst_apid').loc[lambda x: x['name']=='john f kennedy international airport'].shape[0]"
what is the number of routes that end at john f kennedy international airport?,"pd.merge(airports, routes, left_on='apid', right_on='dst_apid').loc[lambda x: x['name']=='john f kennedy international airport'].shape[0]"
find the number of routes from the united states to canada.,"routes.loc[routes['dst_apid'].isin(airports.loc[airports['country']=='canada', 'apid']) & routes['src_apid'].isin(airports.loc[airports['country']=='united states', 'apid']), :].shape[0]"
how many routes go from the united states to canada?,"routes.loc[routes['dst_apid'].isin(airports.loc[airports['country']=='canada', 'apid']) & routes['src_apid'].isin(airports.loc[airports['country']=='united states', 'apid']), :].shape[0]"
find the id of routes whose source and destination airports are in the united states.,"routes.loc[routes['dst_apid'].isin(airports.loc[airports['country'] == 'united states', 'apid']) & routes['src_apid'].isin(airports.loc[airports['country'] == 'united states', 'apid']), 'rid']"
what is the id of the routes whose source and destination airports are in the united states?,"routes.loc[routes['dst_apid'].isin(airports.loc[airports['country'] == 'united states', 'apid']) & routes['src_apid'].isin(airports.loc[airports['country'] == 'united states', 'apid']), 'rid']"
find the name of airline which runs the most number of routes.,"airlines.merge(routes, on='alid').groupby('name').size().sort_values(ascending=false).index[0]"
what is the name of the airline with the most routes?,"airlines.merge(routes, on='alid').groupby('name').size().sort_values(ascending=false).index[0]"
find the busiest source airport that runs most number of routes in china.,"pd.merge(airports, routes, left_on='apid', right_on='src_apid').loc[lambda x: x['country']=='china'].groupby('name').size().sort_values(ascending=false).index[0]"
what is the name of the airport with the most number of routes that start in china?,"pd.merge(airports, routes, left_on='apid', right_on='src_apid').loc[lambda x: x['country']=='china'].groupby('name').size().sort_values(ascending=false).index[0]"
find the busiest destination airport that runs most number of routes in china.,"airports.merge(routes, left_on='apid', right_on='dst_apid').loc[lambda x: x['country']=='china'].groupby('name').size().sort_values(ascending=false).index[0]"
what is the name of the airport that is the destination of the most number of routes that start in china?,"airports.merge(routes, left_on='apid', right_on='dst_apid').loc[lambda x: x['country']=='china'].groupby('name').size().sort_values(ascending=false).index[0]"
what is the id of the most recent order?,"orders.sort_values('date_order_placed', ascending=false).iloc[0]['order_id']"
find the id of the order made most recently.,"orders.sort_values('date_order_placed', ascending=false).iloc[0]['order_id']"
what are the order id and customer id of the oldest order?,"orders[['order_id', 'customer_id']].sort_values('date_order_placed').head(1)"
find the order id and customer id associated with the oldest order.,"orders[['order_id', 'customer_id']].sort_values('date_order_placed').head(1)"
"find the id of the order whose shipment tracking number is ""3452"".","shipments.loc[lambda x: x['shipment_tracking_number']=='3452', 'order_id']"
"which order's shipment tracking number is ""3452""? give me the id of the order.","shipments.loc[lambda x: x['shipment_tracking_number']=='3452', 'order_id']"
find the ids of all the order items whose product id is 11.,"order_items.loc[order_items['product_id']==11, 'order_item_id']"
find all the order items whose product id is 11. what are the order item ids?,"order_items.loc[order_items['product_id']==11, 'order_item_id']"
"list the name of all the distinct customers who have orders with status ""packing"".","pd.merge(customers, orders.loc[orders['order_status']=='packing'], on='customer_id')['customer_name'].unique()"
"which customers have orders with status ""packing""? give me the customer names.","pd.merge(customers, orders.loc[orders['order_status']=='packing'], on='customer_id')['customer_name'].unique()"
"find the details of all the distinct customers who have orders with status ""on road"".","pd.merge(customers, orders[orders['order_status']=='on road'], on='customer_id')['customer_details'].unique()"
"what are the distinct customers who have orders with status ""on road""? give me the customer details?","pd.merge(customers, orders[orders['order_status']=='on road'], on='customer_id')['customer_details'].unique()"
what is the name of the customer who has the most orders?,"pd.merge(customers, orders, on='customer_id').groupby('customer_name').size().sort_values(ascending=false).index[0]"
which customer made the most orders? find the customer name.,"pd.merge(customers, orders, on='customer_id').groupby('customer_name').size().sort_values(ascending=false).index[0]"
what is the customer id of the customer who has the most orders?,"pd.merge(customers, orders, on='customer_id').groupby('customer_id').size().idxmax()"
find the id of the customer who made the most orders.,"pd.merge(customers, orders, on='customer_id').groupby('customer_id').size().idxmax()"
"give me a list of id and status of orders which belong to the customer named ""jeramie"".","pd.merge(customers.loc[lambda x: x['customer_name']=='jeramie'], orders, on='customer_id')[['order_id', 'order_status']]"
"which orders are made by the customer named ""jeramie""? give me the order ids and status.","pd.merge(customers.loc[lambda x: x['customer_name']=='jeramie'], orders, on='customer_id')[['order_id', 'order_status']]"
"find the dates of orders which belong to the customer named ""jeramie"".","pd.merge(customers[customers['customer_name']=='jeramie'], orders, on='customer_id')['date_order_placed']"
"what are the dates of the orders made by the customer named ""jeramie""?","pd.merge(customers[customers['customer_name']=='jeramie'], orders, on='customer_id')['date_order_placed']"
give me the names of customers who have placed orders between 2009-01-01 and 2010-01-01.,"pd.merge(customers, orders, on='customer_id').loc[lambda x: (x['date_order_placed'] >= '2009-01-01') & (x['date_order_placed'] <= '2010-01-01'), 'customer_name']"
which customers made orders between 2009-01-01 and 2010-01-01? find their names.,"pd.merge(customers, orders, on='customer_id').loc[lambda x: (x['date_order_placed'] >= '2009-01-01') & (x['date_order_placed'] <= '2010-01-01'), 'customer_name']"
give me a list of distinct product ids from orders placed between 1975-01-01 and 1976-01-01?,"pd.merge(orders.loc[lambda x: (x['date_order_placed']>='1975-01-01') & (x['date_order_placed']<='1976-01-01')], order_items, on='order_id')['product_id'].unique()"
what are the distinct ids of products ordered between 1975-01-01 and 1976-01-01??,"pd.merge(orders.loc[lambda x: (x['date_order_placed']>='1975-01-01') & (x['date_order_placed']<='1976-01-01')], order_items, on='order_id')['product_id'].unique()"
"find the names of the customers who have order status both ""on road"" and ""shipped"".","pd.merge(orders.loc[orders['order_status']=='on road', ['customer_id']], customers, on='customer_id')['customer_name'].iloc[np.where(pd.merge(orders.loc[orders['order_status']=='shipped', ['customer_id']], customers, on='customer_id')['customer_name'].isin(pd.merge(orders.loc[orders['order_status']=='on road', ['customer_id']], customers, on='customer_id')['customer_name']))]"
"which customers have both ""on road"" and ""shipped"" as order status? list the customer names.","pd.merge(orders.loc[orders['order_status']=='on road', ['customer_id']], customers, on='customer_id')['customer_name'].iloc[np.where(pd.merge(orders.loc[orders['order_status']=='shipped', ['customer_id']], customers, on='customer_id')['customer_name'].isin(pd.merge(orders.loc[orders['order_status']=='on road', ['customer_id']], customers, on='customer_id')['customer_name']))]"
"find the id of the customers who have order status both ""on road"" and ""shipped"".","pd.merge(customers.loc[lambda x: x['order_status'] == 'on road', 'customer_id'], customers.loc[lambda x: x['order_status'] == 'shipped', 'customer_id'], how='inner')"
"which customers have both ""on road"" and ""shipped"" as order status? list the customer ids.","pd.merge(customers.loc[lambda x: x['order_status'] == 'on road', 'customer_id'], customers.loc[lambda x: x['order_status'] == 'shipped', 'customer_id'], how='inner')"
when was the order placed whose shipment tracking number is 3452? give me the date.,"pd.merge(orders, shipments, on='order_id').loc[lambda x: x['shipment_tracking_number'] == 3452, 'date_order_placed']"
on which day was the order placed whose shipment tracking number is 3452?,"pd.merge(orders, shipments, on='order_id').loc[lambda x: x['shipment_tracking_number'] == 3452, 'date_order_placed']"
what is the placement date of the order whose invoice number is 10?,"pd.merge(orders, shipments, on='order_id').loc[lambda x: x['invoice_number']==10, 'date_order_placed']"
on what day was the order with invoice number 10 placed?,"pd.merge(orders, shipments, on='order_id').loc[lambda x: x['invoice_number']==10, 'date_order_placed']"
list the count and id of each product in all the orders.,"pd.merge(pd.merge(orders, order_items, on='order_id'), products, on='product_id').groupby('product_id').size().reset_index(name='count')"
"for each product, return its id and the number of times it was ordered.","pd.merge(pd.merge(orders, order_items, on='order_id'), products, on='product_id').groupby('product_id').size().reset_index(name='count')"
list the name and count of each product in all orders.,"pd.merge(pd.merge(orders, order_items, on='order_id'), products, on='product_id').groupby('product_id')['product_name'].agg(['count'])"
"for each product, show its name and the number of times it was ordered.","pd.merge(pd.merge(orders, order_items, on='order_id'), products, on='product_id').groupby('product_id')['product_name'].agg(['count'])"
find the ids of orders which are shipped after 2000-01-01.,"shipments.loc[lambda x: x['shipment_date'] > ""2000-01-01"", 'order_id']"
which orders have shipment after 2000-01-01? give me the order ids.,"shipments.loc[lambda x: x['shipment_date'] > ""2000-01-01"", 'order_id']"
find the id of the order which is shipped most recently.,"shipments.loc[lambda x: x['shipment_date']==shipments['shipment_date'].max(), 'order_id']"
which order has the most recent shipment? give me the order id.,"shipments.loc[lambda x: x['shipment_date']==shipments['shipment_date'].max(), 'order_id']"
list the names of all distinct products in alphabetical order.,products['product_name'].sort_values().unique()
sort all the distinct products in alphabetical order.,products['product_name'].sort_values().unique()
list the ids of all distinct orders ordered by placed date.,orders.drop_duplicates('order_id').sort_values('date_order_placed')['order_id']
"what are ids of the all distinct orders, sorted by placement date?",orders.drop_duplicates('order_id').sort_values('date_order_placed')['order_id']
what is the id of the order which has the most items?,"pd.merge(orders, order_items, on='order_id').groupby('order_id').size().sort_values(ascending=false).index[0]"
which order deals with the most items? return the order id.,"pd.merge(orders, order_items, on='order_id').groupby('order_id').size().sort_values(ascending=false).index[0]"
what is the name of the customer who has the largest number of orders?,"pd.merge(customers, orders, on='customer_id').groupby('customer_name').size().sort_values(ascending=false).index[0]"
find the name of the customer who made the most orders.,"pd.merge(customers, orders, on='customer_id').groupby('customer_name').size().sort_values(ascending=false).index[0]"
find the invoice numbers which are created before 1989-09-03 or after 2007-12-25.,"invoices.loc[(invoices['invoice_date'] < '1989-09-03') | (invoices['invoice_date'] > '2007-12-25'), 'invoice_number']"
what are the invoice numbers created before 1989-09-03 or after 2007-12-25?,"invoices.loc[(invoices['invoice_date'] < '1989-09-03') | (invoices['invoice_date'] > '2007-12-25'), 'invoice_number']"
find the distinct details of invoices which are created before 1989-09-03 or after 2007-12-25.,"invoices.loc[(invoices['invoice_date'] < '1989-09-03') | (invoices['invoice_date'] > '2007-12-25'), 'invoice_details'].unique()"
what are the distinct details of invoices created before 1989-09-03 or after 2007-12-25?,"invoices.loc[(invoices['invoice_date'] < '1989-09-03') | (invoices['invoice_date'] > '2007-12-25'), 'invoice_details'].unique()"
"for each customer who has at least two orders, find the customer name and number of orders made.","pd.merge(orders, customers, on='customer_id').groupby('customer_name').filter(lambda x: len(x) >= 2)['customer_name'].value_counts()"
which customers have made at least two orders? give me each customer name and number of orders made.,"pd.merge(orders, customers, on='customer_id').groupby('customer_name').filter(lambda x: len(x) >= 2)['customer_name'].value_counts()"
find the name of the customers who have at most two orders.,"pd.merge(orders, customers, on='customer_id').groupby('customer_name').filter(lambda x: len(x) <= 2)['customer_name']"
what are the names of the customers who have made two or less orders?,"pd.merge(orders, customers, on='customer_id').groupby('customer_name').filter(lambda x: len(x) <= 2)['customer_name']"
"list the names of the customers who have once bought product ""food"".","pd.merge(pd.merge(pd.merge(customers, orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').query('product_name == ""food""').groupby('customer_id').filter(lambda x: len(x) >= 1)['customer_name'].unique()"
"what are the names of the customers who bought product ""food"" at least once?","pd.merge(pd.merge(pd.merge(customers, orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').query('product_name == ""food""').groupby('customer_id').filter(lambda x: len(x) >= 1)['customer_name'].unique()"
"list the names of customers who have once canceled the purchase of the product ""food"" (the item status is ""cancel"").","pd.merge(pd.merge(pd.merge(customers, orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').query('order_item_status == ""cancel"" & product_name == ""food""').groupby('customer_id').filter(lambda x: len(x)>=1)['customer_name'].unique()"
"which customers have ever canceled the purchase of the product ""food"" (the item status is ""cancel"")?","pd.merge(pd.merge(pd.merge(customers, orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').query('order_item_status == ""cancel"" & product_name == ""food""').groupby('customer_id').filter(lambda x: len(x)>=1)['customer_name'].unique()"
how many architects are female?,(architect['gender']=='female').sum()
"list the name, nationality and id of all male architects ordered by their names lexicographically.","architect.loc[lambda x: x['gender']=='male', ['name', 'nationality', 'id']].sort_values('name')"
what is the maximum length in meters for the bridges and what are the architects' names?,"pd.merge(bridge, architect, left_on='architect_id', right_on='id').agg({'length_meters': 'max', 'name': 'first'})"
what is the average length in feet of the bridges?,bridge['length_feet'].mean()
what are the names and year of construction for the mills of 'grondzeiler' type?,"mill.loc[mill['type']=='grondzeiler', ['name', 'built_year']]"
what are the distinct names and nationalities of the architects who have ever built a mill?,"pd.merge(architect, mill, on='architect_id')[['name', 'nationality']].drop_duplicates()"
what are the names of the mills which are not located in 'donceel'?,"mill.loc[lambda x: x['location'] != 'donceel', 'name']"
what are the distinct types of mills that are built by american or canadian architects?,"mill.merge(architect, left_on='architect_id', right_on='id').query(""nationality in ['american', 'canadian']"")['type'].unique()"
what are the ids and names of the architects who built at least 3 bridges ?,"architect.merge(bridge, on='architect_id').groupby(['id', 'name']).filter(lambda x: len(x) >= 3).iloc[:, :2].drop_duplicates()"
"what is the id, name and nationality of the architect who built most mills?","pd.merge(architect, mill, on='architect_id').groupby(['id', 'name', 'nationality']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[[0]][['id', 'name', 'nationality']]"
"what are the ids, names and genders of the architects who built two bridges or one mill?","pd.concat([architect.merge(bridge, on='architect_id').groupby('id').filter(lambda x: len(x)==2), architect.merge(mill, on='architect_id').groupby('id').filter(lambda x: len(x)==1)])[['id', 'name', 'gender']]"
what is the location of the bridge named 'kolob arch' or 'rainbow bridge'?,"bridge.loc[bridge['name'].isin(['kolob arch', 'rainbow bridge']), 'location']"
which of the mill names contains the french word 'moulin'?,"mill.loc[mill['name'].str.contains('moulin'), 'name']"
what are the distinct name of the mills built by the architects who have also built a bridge longer than 80 meters?,"pd.merge(pd.merge(mill, architect, left_on='architect_id', right_on='id'), bridge, on='architect_id').loc[lambda x: x['length_meters'] > 80, 'name'].unique()"
"what is the most common mill type, and how many are there?",mill.groupby('type').size().nlargest(1)
how many architects haven't built a mill before year 1850?,"architect.loc[~architect['id'].isin(mill.loc[mill['built_year']<1850, 'architect_id']), :].shape[0]"
"show the name of all bridges that was designed by american archtect, and sort the result by the bridge feet length.","pd.merge(bridge, architect, left_on='architect_id', right_on='id').loc[lambda x: x['nationality']=='american', 'name'].sort_values(by='length_feet')"
how many book clubs are there?,book_club.shape[0]
count the number of book clubs.,book_club.shape[0]
"show the titles, and authors or editors for all books made after the year 1989.","book_club.loc[lambda x: x['year'] > 1989, ['book_title', 'author_or_editor']]"
what are the titles and authors or editors that correspond to books made after 1989?,"book_club.loc[lambda x: x['year'] > 1989, ['book_title', 'author_or_editor']]"
show all distinct publishers for books.,book_club['publisher'].unique()
what are all the different book publishers?,book_club['publisher'].unique()
"show the years, book titles, and publishers for all books, in descending order by year.","book_club[['year', 'book_title', 'publisher']].sort_values('year', ascending=false)"
"what are the years, titles, and publishers for all books, ordered by year descending?","book_club[['year', 'book_title', 'publisher']].sort_values('year', ascending=false)"
show all publishers and the number of books for each publisher.,book_club.groupby('publisher').size()
how many books are there for each publisher?,book_club.groupby('publisher').size()
what is the publisher with most number of books?,book_club.groupby('publisher').size().sort_values(ascending=false).index[0]
return the publisher that has published the most books.,book_club.groupby('publisher').size().sort_values(ascending=false).index[0]
show all book categories and the number of books in each category.,book_club.groupby('category').size()
how many books fall into each category?,book_club.groupby('category').size()
list categories that have at least two books after year 1989.,book_club.loc[lambda x: x['year'] > 1989].groupby('category').filter(lambda x: len(x) >= 2)['category'].unique()
what categories have two or more corresponding books that were made after 1989?,book_club.loc[lambda x: x['year'] > 1989].groupby('category').filter(lambda x: len(x) >= 2)['category'].unique()
show publishers with a book published in 1989 and a book in 1990.,"book_club.loc[book_club['year']==1989, 'publisher'].drop_duplicates().reset_index(drop=true).loc[lambda x : x.isin(book_club.loc[book_club['year']==1990, 'publisher'].unique())]"
what are the publishers who have published a book in both 1989 and 1990?,"book_club.loc[book_club['year']==1989, 'publisher'].drop_duplicates().reset_index(drop=true).loc[lambda x : x.isin(book_club.loc[book_club['year']==1990, 'publisher'].unique())]"
show all publishers which do not have a book in 1989.,"book_club.loc[lambda x: x['year']!=1989, 'publisher'].unique()"
which publishers did not publish a book in 1989?,"book_club.loc[lambda x: x['year']!=1989, 'publisher'].unique()"
"show all movie titles, years, and directors, ordered by budget.","movie[['title', 'year', 'director', 'budget_million']].sort_values('budget_million')"
"what are the titles, years, and directors of all movies, ordered by budget in millions?","movie[['title', 'year', 'director', 'budget_million']].sort_values('budget_million')"
how many movie directors are there?,movie['director'].nunique()
count the number of different directors.,movie['director'].nunique()
what is the title and director for the movie with highest worldwide gross in the year 2000 or before?,"movie.loc[lambda x: x['year']<=2000].sort_values('gross_worldwide', ascending=false).iloc[0][['title', 'director']]"
return the title and director of the movie released in the year 2000 or earlier that had the highest worldwide gross.,"movie.loc[lambda x: x['year']<=2000].sort_values('gross_worldwide', ascending=false).iloc[0][['title', 'director']]"
show all director names who have a movie in both year 1999 and 2000.,"set(movie.loc[movie['year']==2000, 'director']).intersection(set(movie.loc[movie['year']==1999, 'director']))"
which directors had a movie both in the year 1999 and 2000?,"set(movie.loc[movie['year']==2000, 'director']).intersection(set(movie.loc[movie['year']==1999, 'director']))"
show all director names who have a movie in the year 1999 or 2000.,"movie.loc[movie['year'].isin([1999, 2000]), 'director']"
which directors had a movie in either 1999 or 2000?,"movie.loc[movie['year'].isin([1999, 2000]), 'director']"
"what is the average, maximum, and minimum budget for all movies before 2000.","movie.loc[movie['year']<2000, 'budget_million'].agg(['mean', 'max', 'min'])"
"return the average, maximum, and minimum budgets in millions for movies made before the year 2000.","movie.loc[movie['year']<2000, 'budget_million'].agg(['mean', 'max', 'min'])"
list all company names with a book published by alyson.,"culture_company.merge(book_club.loc[lambda x: x['publisher']=='alyson'], on='book_club_id')['company_name']"
what are all the company names that have a book published by alyson?,"culture_company.merge(book_club.loc[lambda x: x['publisher']=='alyson'], on='book_club_id')['company_name']"
show the movie titles and book titles for all companies in china.,"pd.merge(pd.merge(movie, culture_company, on='movie_id'), book_club, on='book_club_id').loc[lambda x: x['incorporated_in']=='china', ['title', 'book_title']]"
what are the titles of movies and books corresponding to companies incorporated in china?,"pd.merge(pd.merge(movie, culture_company, on='movie_id'), book_club, on='book_club_id').loc[lambda x: x['incorporated_in']=='china', ['title', 'book_title']]"
show all company names with a movie directed in year 1999.,"pd.merge(movie, culture_company, on='movie_id').loc[lambda x: x['year']==1999, 'company_name']"
what are all company names that have a corresponding movie directed in the year 1999?,"pd.merge(movie, culture_company, on='movie_id').loc[lambda x: x['year']==1999, 'company_name']"
what is the biggest city in wyoming,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
what wyoming city has the largest population,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
what is the largest city in wyoming,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
where is the most populated area of wyoming,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
which city in wyoming has the largest population,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
what cities in wyoming have the highest number of citizens,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
what cities in wyoming have the highest populations,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
what is the most populous city in wyoming,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
what is the largest city in wyoming by population,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
what is the largest city of wyoming,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
what is the city in wyoming with the largest population,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
which rivers run through the state with the largest city in the us,"river.loc[lambda x: x['traverse'].isin(city.loc[lambda x: x['population']==city['population'].max(), 'state_name']), 'river_name']"
how big is new mexico,"state.loc[state['state_name'] == 'new mexico', 'area']"
what is the area of new mexico,"state.loc[state['state_name'] == 'new mexico', 'area']"
how large is new mexico,"state.loc[state['state_name'] == 'new mexico', 'area']"
what is the area of the new mexico state,"state.loc[state['state_name'] == 'new mexico', 'area']"
what is the size of new mexico,"state.loc[state['state_name'] == 'new mexico', 'area']"
what is the area of new mexico in square kilometers,"state.loc[state['state_name'] == 'new mexico', 'area']"
how many people live in california,"state.loc[state['state_name'] == 'california', 'population']"
how many people reside in california,"state.loc[state['state_name'] == 'california', 'population']"
how many residents live in california,"state.loc[state['state_name'] == 'california', 'population']"
how much population does california have,"state.loc[state['state_name'] == 'california', 'population']"
what are the population of california,"state.loc[state['state_name'] == 'california', 'population']"
what is the population of california,"state.loc[state['state_name'] == 'california', 'population']"
how many people are in the state of california,"state.loc[state['state_name'] == 'california', 'population']"
what can you tell me about the population of california,"state.loc[state['state_name'] == 'california', 'population']"
how many people are there in california,"state.loc[state['state_name'] == 'california', 'population']"
how many citizens in california,"state.loc[state['state_name'] == 'california', 'population']"
how many people stay in california,"state.loc[state['state_name'] == 'california', 'population']"
how many citizens live in california,"state.loc[state['state_name'] == 'california', 'population']"
what state has the smallest population,"state.loc[state['population'] == state['population'].min(), 'state_name']"
what is the least populous state,"state.loc[state['population'] == state['population'].min(), 'state_name']"
what is the state with the lowest population,"state.loc[state['population'] == state['population'].min(), 'state_name']"
give me the cities in texas,"city.loc[city['state_name']=='texas', 'city_name']"
tell me what cities are in texas,"city.loc[city['state_name']=='texas', 'city_name']"
what cities are located in texas,"city.loc[city['state_name']=='texas', 'city_name']"
what are the cities in texas,"city.loc[city['state_name']=='texas', 'city_name']"
what cities in texas,"city.loc[city['state_name']=='texas', 'city_name']"
give me the cities which are in texas,"city.loc[city['state_name']=='texas', 'city_name']"
what is the area of the state with the capital albany,"state.loc[state['capital'] == 'albany', 'area']"
give me the lakes in california,"lake.loc[lake['state_name'] == 'california', 'lake_name']"
name the major lakes in michigan,"lake.loc[(lake['area'] > 750) & (lake['state_name'] == 'michigan'), 'lake_name']"
what are the states,state['state_name']
list the states,state['state_name']
give me all the states of usa,state['state_name']
which states do ohio river flow through,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
what states does the ohio river run through,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
what states border the ohio river,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
which states border the ohio river,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
what states does the ohio run through,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
where is the ohio river,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
which states does the ohio river run through,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
which states does the ohio run through,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
which states does the ohio river pass through,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
what are the states that the ohio run through,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
which state has the ohio river,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
what states have rivers named ohio,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
through which states does the ohio flow,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
what states are next to the ohio,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
through which states does the ohio run,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
what states does the ohio river go through,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
what state has the largest population,"state.loc[state['population'] == state['population'].max(), 'state_name']"
what is the most populous state,"state.loc[state['population'] == state['population'].max(), 'state_name']"
what state is the largest in population,"state.loc[state['population'] == state['population'].max(), 'state_name']"
which state has the biggest population,"state.loc[state['population'] == state['population'].max(), 'state_name']"
which state has the greatest population,"state.loc[state['population'] == state['population'].max(), 'state_name']"
which state has the most population,"state.loc[state['population'] == state['population'].max(), 'state_name']"
what state has the most people,"state.loc[state['population'] == state['population'].max(), 'state_name']"
which state has the most people,"state.loc[state['population'] == state['population'].max(), 'state_name']"
what is the most populous state in the us,"state.loc[state['population'] == state['population'].max(), 'state_name']"
what state has the highest population,"state.loc[state['population'] == state['population'].max(), 'state_name']"
what is the lowest elevation in pennsylvania,"highlow.loc[highlow['state_name']=='pennsylvania', 'lowest_elevation']"
what is the highest point in each state whose lowest point is sea level,"highlow.loc[lambda x: x['lowest_elevation']==0, ['highest_point', 'state_name']]"
what is the length of the longest river in the usa,"river.loc[lambda x: x['length'] == river['length'].max(), 'length']"
how long is the longest river in the usa,"river.loc[lambda x: x['length'] == river['length'].max(), 'length']"
what is the longest river flowing through texas,"river.loc[lambda x: (x['traverse']=='texas') & (x['length']==river.loc[lambda y: y['traverse']=='texas', 'length'].max()), 'river_name']"
what is the largest river in texas state,"river.loc[lambda x: (x['traverse']=='texas') & (x['length']==river.loc[lambda y: y['traverse']=='texas', 'length'].max()), 'river_name']"
what is the longest river in texas,"river.loc[lambda x: (x['traverse']=='texas') & (x['length']==river.loc[lambda y: y['traverse']=='texas', 'length'].max()), 'river_name']"
what is the biggest river in texas,"river.loc[lambda x: (x['traverse']=='texas') & (x['length']==river.loc[lambda y: y['traverse']=='texas', 'length'].max()), 'river_name']"
what is the longest river that flows through texas,"river.loc[lambda x: (x['traverse']=='texas') & (x['length']==river.loc[lambda y: y['traverse']=='texas', 'length'].max()), 'river_name']"
what are the biggest rivers in texas,"river.loc[lambda x: (x['traverse']=='texas') & (x['length']==river.loc[lambda y: y['traverse']=='texas', 'length'].max()), 'river_name']"
how many rivers are in idaho,(river['traverse'] == 'idaho')['river_name'].count()
give me the number of rivers in idaho,(river['traverse'] == 'idaho')['river_name'].count()
how many rivers does idaho have,(river['traverse'] == 'idaho')['river_name'].count()
how many rivers are there in idaho,(river['traverse'] == 'idaho')['river_name'].count()
how many rivers run through idaho,(river['traverse'] == 'idaho')['river_name'].count()
how many rivers are found in idaho,(river['traverse'] == 'idaho')['river_name'].count()
how many rivers in idaho,(river['traverse'] == 'idaho')['river_name'].count()
what states neighbor kentucky,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
which states border kentucky,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
what states border kentucky,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
give me the states that border kentucky,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
what state borders kentucky,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
what states are next to kentucky,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
what states surround kentucky,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
which state borders kentucky,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
what are the neighboring states for kentucky,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
which states adjoin kentucky,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
states bordering kentucky,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
which state border kentucky,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
what is the adjacent state of kentucky,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
name all the rivers in illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
rivers in illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what are all the rivers in illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what are the rivers in illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what rivers are in illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what rivers are there in illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what rivers run through illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what rivers flow through illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what river flows through illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what are the rivers in the state of illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
name the rivers in illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what are the rivers of illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
which rivers are in illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
which rivers flow through illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what is the river that cross over illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what river runs through illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what state is springfield in,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
where is springfield,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
springfield is in what state,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
what states have cities named springfield,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
which states have cities named springfield,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
which state is springfield in,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
what states have a city named springfield,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
what state has the city springfield,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
what states have towns named springfield,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
what state is springfield located in,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
in which state is springfield,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
which state is the city springfield located in,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
what states in the united states have a city of springfield,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
what is the population of the state with the largest area,"state.loc[state['area'] == state['area'].max(), 'population']"
what is the population of the largest state,"state.loc[state['area'] == state['area'].max(), 'population']"
how many people live in boulder,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
what is the population of boulder,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
how many people lived in boulder,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
number of people in boulder,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
what is the population of boulder city,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
how big is the city of boulder,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
population of boulder,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
what is the population in boulder,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
people in boulder,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
how many people in boulder,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
how many inhabitants does boulder have,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
number of citizens in boulder,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
how many citizens in boulder,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
what is the smallest city in alaska,"city.loc[(city['population'] == city.loc[city['state_name']=='alaska', 'population'].min()) & (city['state_name']=='alaska'), 'city_name']"
which states lie on the largest river in the united states,"river.loc[river['length']==river['length'].max(), 'traverse']"
which states does the longest river run through,"river.loc[river['length']==river['length'].max(), 'traverse']"
which state has the longest river,"river.loc[river['length']==river['length'].max(), 'traverse']"
what are the states through which the longest river runs,"river.loc[river['length']==river['length'].max(), 'traverse']"
which states does the longest river cross,"river.loc[river['length']==river['length'].max(), 'traverse']"
what is the population density of the state with the smallest area,"state.loc[state['area']==state['area'].min(), 'density']"
what is the population density of the smallest state,"state.loc[state['area']==state['area'].min(), 'density']"
which states have points higher than the highest point in colorado,"highlow.loc[lambda x: x['highest_elevation'] > highlow.loc[highlow['state_name']=='colorado', 'highest_elevation'].iloc[0], 'state_name']"
which states have points that are higher than the highest point in colorado,"highlow.loc[lambda x: x['highest_elevation'] > highlow.loc[highlow['state_name']=='colorado', 'highest_elevation'].iloc[0], 'state_name']"
what states high point are higher than that of colorado,"highlow.loc[lambda x: x['highest_elevation'] > highlow.loc[highlow['state_name']=='colorado', 'highest_elevation'].iloc[0], 'state_name']"
what is the highest elevation in delaware,"highlow.loc[lambda x: x['state_name'] == 'delaware', 'highest_elevation'].iloc[0]"
how high is the highest point of delaware,"highlow.loc[lambda x: x['state_name'] == 'delaware', 'highest_elevation'].iloc[0]"
how tall is the highest point in delaware,"highlow.loc[lambda x: x['state_name'] == 'delaware', 'highest_elevation'].iloc[0]"
what is the highest point in delaware in meters,"highlow.loc[lambda x: x['state_name'] == 'delaware', 'highest_elevation'].iloc[0]"
how high is the highest point in delaware,"highlow.loc[lambda x: x['state_name'] == 'delaware', 'highest_elevation'].iloc[0]"
give me the longest river that passes through the us,"river.loc[lambda x: x['length'] == river['length'].max(), 'river_name']"
which is the longest river in usa,"river.loc[lambda x: x['length'] == river['length'].max(), 'river_name']"
what is the longest river in america,"river.loc[lambda x: x['length'] == river['length'].max(), 'river_name']"
name the longest river in us,"river.loc[lambda x: x['length'] == river['length'].max(), 'river_name']"
what river is the longest one in the united states,"river.loc[lambda x: x['length'] == river['length'].max(), 'river_name']"
what is the longest river in the us,"river.loc[lambda x: x['length'] == river['length'].max(), 'river_name']"
what is the longest river,"river.loc[lambda x: x['length'] == river['length'].max(), 'river_name']"
what is the longest river in the united states,"river.loc[lambda x: x['length'] == river['length'].max(), 'river_name']"
what state has the city with the largest population,"city.loc[city['population'] == city['population'].max(), 'state_name']"
what state has the largest city,"city.loc[city['population'] == city['population'].max(), 'state_name']"
which state has the largest city,"city.loc[city['population'] == city['population'].max(), 'state_name']"
what state has the city with the most population,"city.loc[city['population'] == city['population'].max(), 'state_name']"
what is the smallest city in the largest state,"city.loc[(city['population'] == city.loc[state.loc[state['area'] == state['area'].max(), 'state_name'].values, 'population'].min()) & (city['state_name'].isin(state.loc[state['area'] == state['area'].max(), 'state_name'])), 'city_name']"
what state is the biggest,"state.loc[state['area']==state['area'].max(), 'state_name']"
what is the state with the largest area,"state.loc[state['area']==state['area'].max(), 'state_name']"
what state has the largest area,"state.loc[state['area']==state['area'].max(), 'state_name']"
what is the biggest state in continental us,"state.loc[state['area']==state['area'].max(), 'state_name']"
state the state with the largest area,"state.loc[state['area']==state['area'].max(), 'state_name']"
what is the largest state in usa,"state.loc[state['area']==state['area'].max(), 'state_name']"
what is the biggest state,"state.loc[state['area']==state['area'].max(), 'state_name']"
what is the biggest state in the usa,"state.loc[state['area']==state['area'].max(), 'state_name']"
give me the largest state,"state.loc[state['area']==state['area'].max(), 'state_name']"
what is the largest state in the us,"state.loc[state['area']==state['area'].max(), 'state_name']"
what is the largest state,"state.loc[state['area']==state['area'].max(), 'state_name']"
what are the highest points of states surrounding mississippi,"highlow.loc[highlow['state_name'].isin(border_info.loc[border_info['state_name']=='mississippi', 'border']), 'highest_point']"
what are the high points of states surrounding mississippi,"highlow.loc[highlow['state_name'].isin(border_info.loc[border_info['state_name']=='mississippi', 'border']), 'highest_point']"
what is the highest point in states bordering colorado,"highlow.loc[highlow['state_name'].isin(border_info.loc[border_info['state_name']=='colorado', 'border']), 'highest_point'].sort_values(ascending=false).iloc[0]"
what is the highest point in the states bordering colorado,"highlow.loc[highlow['state_name'].isin(border_info.loc[border_info['state_name']=='colorado', 'border']), 'highest_point'].sort_values(ascending=false).iloc[0]"
what is the state with the lowest population density,"state.loc[state['density']==state['density'].min(),'state_name']"
what state has the lowest population density,"state.loc[state['density']==state['density'].min(),'state_name']"
which state has the lowest population density,"state.loc[state['density']==state['density'].min(),'state_name']"
which state has the smallest population density,"state.loc[state['density']==state['density'].min(),'state_name']"
what state has the sparsest population density,"state.loc[state['density']==state['density'].min(),'state_name']"
which state has the sparsest population density,"state.loc[state['density']==state['density'].min(),'state_name']"
what state has the least population density,"state.loc[state['density']==state['density'].min(),'state_name']"
which state has the least population density,"state.loc[state['density']==state['density'].min(),'state_name']"
what state has the smallest population density,"state.loc[state['density']==state['density'].min(),'state_name']"
where is the highest point in texas,"highlow.loc[lambda x: x['state_name']==""texas"", 'highest_point']"
what is the highest point in texas,"highlow.loc[lambda x: x['state_name']==""texas"", 'highest_point']"
what is the high point of texas,"highlow.loc[lambda x: x['state_name']==""texas"", 'highest_point']"
what is the highest mountain in texas,"highlow.loc[lambda x: x['state_name']==""texas"", 'highest_point']"
could you tell me what is the highest point in the state of texas,"highlow.loc[lambda x: x['state_name']==""texas"", 'highest_point']"
what states have no bordering state,state[~state['state_name'].isin(border_info['state_name'])]['state_name']
name the states which have no surrounding states,state[~state['state_name'].isin(border_info['state_name'])]['state_name']
which states border no other states,state[~state['state_name'].isin(border_info['state_name'])]['state_name']
what is the area of the state with the smallest population density,"state.loc[state['density'] == state['density'].min(), 'area']"
count the states which have elevations lower than what alabama has,"(highlow['lowest_elevation'] < highlow.loc[highlow['state_name']=='alabama', 'lowest_elevation'].item())['state_name'].count()"
how high is guadalupe peak,"highlow.loc[lambda x: x['highest_point'] == 'guadalupe peak', 'highest_elevation']"
how tall is guadalupe peak,"highlow.loc[lambda x: x['highest_point'] == 'guadalupe peak', 'highest_elevation']"
what is the maximum elevation of guadalupe peak,"highlow.loc[lambda x: x['highest_point'] == 'guadalupe peak', 'highest_elevation']"
how high is the highest point in america,highlow['highest_elevation'].max()
what is the highest elevation in the united states,highlow['highest_elevation'].max()
what is the elevation of the highest point in the usa,highlow['highest_elevation'].max()
what is the height of the highest point in the usa,highlow['highest_elevation'].max()
how long is the rio grande river,"river.loc[river['river_name']=='rio grande', 'length']"
what is the length of the rio grande river,"river.loc[river['river_name']=='rio grande', 'length']"
what length is the rio grande,"river.loc[river['river_name']=='rio grande', 'length']"
how long is the rio grande,"river.loc[river['river_name']=='rio grande', 'length']"
how long is the rio grande river in miles,"river.loc[river['river_name']=='rio grande', 'length']"
how long is rio grande,"river.loc[river['river_name']=='rio grande', 'length']"
how long is the longest river in texas,"river.loc[(river['traverse'] == 'texas') & (river['length'] == river.loc[river['traverse'] == 'texas', 'length'].max()), 'length']"
what is the length of the longest river that runs through texas,"river.loc[(river['traverse'] == 'texas') & (river['length'] == river.loc[river['traverse'] == 'texas', 'length'].max()), 'length']"
how many capitals does rhode island have,"state.loc[state['state_name'] == 'rhode island', 'capital'].count()"
how many cities are there in the united states,city['city_name'].count()
how many cities does the usa have,city['city_name'].count()
how many cities are there in the us,city['city_name'].count()
how many cities are there in usa,city['city_name'].count()
how many cities are there in us,city['city_name'].count()
how many major cities are there,(city['population'] > 150000).sum()
how many citizens does the biggest city have in the usa,"city.loc[city['population'] == city['population'].max(), 'population']"
how many colorado rivers are there,(river['river_name'] == 'colorado').sum()
how many rivers are called colorado,(river['river_name'] == 'colorado').sum()
what is the population of seattle washington,"city.loc[(city['city_name'] == 'seattle') & (city['state_name'] == 'washington'), 'population']"
how many people live in seattle washington,"city.loc[(city['city_name'] == 'seattle') & (city['state_name'] == 'washington'), 'population']"
how many people live in the biggest city in alaska state,"city.loc[(city['state_name']=='alaska')&(city['population']==city.loc[city['state_name']=='alaska', 'population'].max()), 'population']"
how large is the largest city in alaska,"city.loc[(city['state_name']=='alaska')&(city['population']==city.loc[city['state_name']=='alaska', 'population'].max()), 'population']"
how many people live in the capital of texas,"city.loc[lambda x: x['city_name'].eq(state.loc[state['state_name'].eq('texas'), 'capital'].values[0]), 'population']"
what is the size of the capital of texas,"city.loc[lambda x: x['city_name'].eq(state.loc[state['state_name'].eq('texas'), 'capital'].values[0]), 'population']"
how many people live in the united states,state['population'].sum()
what is the combined population of all 50 states,state['population'].sum()
how many states are in the usa,state['state_name'].count()
how many states are there,state['state_name'].count()
how many states are there in the usa,state['state_name'].count()
how many states does usa have,state['state_name'].count()
how many states are in the united states,state['state_name'].count()
how many states are there in united states,state['state_name'].count()
how many states border kentucky,"border_info.loc[lambda x: x['state_name']=='kentucky', 'border'].count()"
how many states does kentucky border,"border_info.loc[lambda x: x['state_name']=='kentucky', 'border'].count()"
kentucky borders how many states,"border_info.loc[lambda x: x['state_name']=='kentucky', 'border'].count()"
number of states bordering kentucky,"border_info.loc[lambda x: x['state_name']=='kentucky', 'border'].count()"
what is the number of neighboring states for kentucky,"border_info.loc[lambda x: x['state_name']=='kentucky', 'border'].count()"
how many states border the state with the largest population,"border_info.loc[border_info['state_name'].isin(state.loc[state['population'] == state['population'].max(), 'state_name']), 'border'].count()"
how many states do not have rivers,"state.loc[~state['state_name'].isin(river['traverse'].unique()), 'state_name'].nunique()"
how many states have a higher point than the highest point of the state with the largest capital city in the us,(highlow['highest_elevation'] > highlow[highlow['state_name'] == state[state['capital'] == city[city['population'] == city['population'].max()]['city_name'].iloc[0]]['state_name'].iloc[0]]['highest_elevation'].iloc[0])['state_name'].count()
name the major rivers in illinois,"river.loc[(river['length']>750)&(river['traverse']=='illinois'), 'river_name']"
what are the major rivers in illinois,"river.loc[(river['length']>750)&(river['traverse']=='illinois'), 'river_name']"
what are major rivers in illinois,"river.loc[(river['length']>750)&(river['traverse']=='illinois'), 'river_name']"
what major rivers run through illinois,"river.loc[(river['length']>750)&(river['traverse']=='illinois'), 'river_name']"
through which states does the longest river in texas run,"river.loc[lambda x: x['traverse']=='texas', 'length'].max()"
what are the capital city in texas,"state.loc[state['state_name']=='texas', 'capital']"
what is the capital of texas,"state.loc[state['state_name']=='texas', 'capital']"
what is the capital of the texas state,"state.loc[state['state_name']=='texas', 'capital']"
what is capital of texas,"state.loc[state['state_name']=='texas', 'capital']"
what is the capital of the state texas,"state.loc[state['state_name']=='texas', 'capital']"
can you tell me the capital of texas,"state.loc[state['state_name']=='texas', 'capital']"
what are the capitals of states that border texas,"pd.merge(state, border_info, left_on='state_name', right_on='border').loc[lambda x: x['state_name']=='texas', 'capital']"
what are the capital cities of the states which border texas,"pd.merge(state, border_info, left_on='state_name', right_on='border').loc[lambda x: x['state_name']=='texas', 'capital']"
what are the capitals of the states that border texas,"pd.merge(state, border_info, left_on='state_name', right_on='border').loc[lambda x: x['state_name']=='texas', 'capital']"
which capitals are in the states that border texas,"pd.merge(state, border_info, left_on='state_name', right_on='border').loc[lambda x: x['state_name']=='texas', 'capital']"
what are the cities in states through which the mississippi runs,"city.loc[lambda x: x['state_name'].isin(river.loc[lambda x: x['river_name']=='mississippi', 'traverse'].unique()), 'city_name']"
what are the cities of the state with the highest point,"city.loc[city['state_name'].isin(highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']), 'city_name']"
what are the highest points of all the states,highlow['highest_point']
what are the major cities in kansas,"city.loc[(city['population'] > 150000) & (city['state_name'] == ""kansas""), 'city_name']"
what are the major cities in the state of kansas,"city.loc[(city['population'] > 150000) & (city['state_name'] == ""kansas""), 'city_name']"
what major cities are located in kansas,"city.loc[(city['population'] > 150000) & (city['state_name'] == ""kansas""), 'city_name']"
show major cities in kansas,"city.loc[(city['population'] > 150000) & (city['state_name'] == ""kansas""), 'city_name']"
what are the names of the major cities in kansas,"city.loc[(city['population'] > 150000) & (city['state_name'] == ""kansas""), 'city_name']"
what are the major cities of kansas,"city.loc[(city['population'] > 150000) & (city['state_name'] == ""kansas""), 'city_name']"
what is the major cities in kansas,"city.loc[(city['population'] > 150000) & (city['state_name'] == ""kansas""), 'city_name']"
what are the major cities in states through which the mississippi runs,"city.loc[(city['population'] > 150000) & (city['state_name'].isin(river.loc[(river['length'] > 750) & (river['river_name'] == 'mississippi'), 'traverse'])), 'city_name']"
what are the major cities in the usa,"city.loc[lambda x: x['population'] > 150000, 'city_name']"
what are the major cities of the united states,"city.loc[lambda x: x['population'] > 150000, 'city_name']"
what are the major cities of the us,"city.loc[lambda x: x['population'] > 150000, 'city_name']"
what are the population densities of each us state,state['density']
what are the populations of states through which the mississippi river run,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'population']"
what are the populations of states through which the mississippi runs,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'population']"
what are the populations of the states through which the mississippi runs,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'population']"
what are the populations of states through which the mississippi river runs,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'population']"
what are the populations of the states through which the mississippi run,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'population']"
what are the populations of the states through which the mississippi river run,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'population']"
what are the populations of states through which the mississippi run,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'population']"
what are the populations of the states through which the mississippi river runs,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'population']"
what are the populations of states which border texas,"state.merge(border_info, left_on='state_name', right_on='border').loc[lambda x: x['state_name']=='texas', 'population']"
what are the populations of the major cities of wisconsin,"city.loc[(city['population'] > 150000) & (city['state_name'] == 'wisconsin'), 'population']"
what are the populations of all the major cities in wisconsin,"city.loc[(city['population'] > 150000) & (city['state_name'] == 'wisconsin'), 'population']"
what is the population of the major cities in wisconsin,"city.loc[(city['population'] > 150000) & (city['state_name'] == 'wisconsin'), 'population']"
what city has the most people,"city.loc[city['population'] == city['population'].max(), 'city_name']"
what city in the united states has the highest population density,"city.loc[city['population'] == city['population'].max(), 'city_name']"
what is the most populous city,"city.loc[city['population'] == city['population'].max(), 'city_name']"
which us city has the highest population density,"city.loc[city['population'] == city['population'].max(), 'city_name']"
what is the biggest city in the usa,"city.loc[city['population'] == city['population'].max(), 'city_name']"
whats the largest city,"city.loc[city['population'] == city['population'].max(), 'city_name']"
what city has the largest population,"city.loc[city['population'] == city['population'].max(), 'city_name']"
what is the biggest city in the us,"city.loc[city['population'] == city['population'].max(), 'city_name']"
what is the biggest city in usa,"city.loc[city['population'] == city['population'].max(), 'city_name']"
what is the biggest capital city in the us,"city.loc[lambda x: x['population'] == (city.merge(state, left_on='city_name', right_on='capital')['population_y']).max(), 'city_name']"
what is the largest capital city in the usa,"city.loc[lambda x: x['population'] == (city.merge(state, left_on='city_name', right_on='capital')['population_y']).max(), 'city_name']"
what is the largest state capital in population,"city.loc[lambda x: x['population'] == (city.merge(state, left_on='city_name', right_on='capital')['population_y']).max(), 'city_name']"
what is the largest capital,"city.loc[lambda x: x['population'] == (city.merge(state, left_on='city_name', right_on='capital')['population_y']).max(), 'city_name']"
what is the most populated capital in the usa,"city.loc[lambda x: x['population'] == (city.merge(state, left_on='city_name', right_on='capital')['population_y']).max(), 'city_name']"
what capital is the largest in the us,"city.loc[lambda x: x['population'] == (city.merge(state, left_on='city_name', right_on='capital')['population_y']).max(), 'city_name']"
what capital has the largest population,"city.loc[lambda x: x['population'] == (city.merge(state, left_on='city_name', right_on='capital')['population_y']).max(), 'city_name']"
what is largest capital,"city.loc[lambda x: x['population'] == (city.merge(state, left_on='city_name', right_on='capital')['population_y']).max(), 'city_name']"
what is the capital of states that have cities named durham,"state.merge(city, on='state_name').loc[lambda x: x['city_name']=='durham', 'capital']"
what is the capital of the smallest state,"state.loc[state['area'] == state['area'].min(), 'capital']"
what is the capital of the state with the largest population density,"state.loc[state['density'] == state['density'].max(), 'capital'].unique()"
what is the capital of the state with the largest population,"state.loc[state['population'] == state['population'].max(), 'capital']"
what is the capital of the state with the most inhabitants,"state.loc[state['population'] == state['population'].max(), 'capital']"
what is the capital of the state with the longest river,"state.loc[state['state_name'].isin(river.loc[river['length']==river['length'].max(), 'traverse']), 'capital']"
what is the combined area of all 50 states,state['area'].sum()
what is the area of all the states combined,state['area'].sum()
how many square kilometers in the us,state['area'].sum()
what is the total area of the usa,state['area'].sum()
what is the density of the wyoming,"state.loc[state['state_name']=='wyoming', 'density']"
what is the population density of wyoming,"state.loc[state['state_name']=='wyoming', 'density']"
what is the density of wyoming,"state.loc[state['state_name']=='wyoming', 'density']"
what is the highest mountain in the us,"mountain.loc[mountain['mountain_altitude'] == mountain['mountain_altitude'].max(), 'mountain_name']"
what is the highest mountain in us,"mountain.loc[mountain['mountain_altitude'] == mountain['mountain_altitude'].max(), 'mountain_name']"
what is the tallest mountain in america,"mountain.loc[mountain['mountain_altitude'] == mountain['mountain_altitude'].max(), 'mountain_name']"
what is the tallest mountain in the united states,"mountain.loc[mountain['mountain_altitude'] == mountain['mountain_altitude'].max(), 'mountain_name']"
what is the highest point in the state with capital des moines,"highlow.loc[lambda x: x['state_name'].isin(state.loc[state['capital']=='des moines', 'state_name']), 'highest_point']"
what is the highest point in the state with the capital des moines,"highlow.loc[lambda x: x['state_name'].isin(state.loc[state['capital']=='des moines', 'state_name']), 'highest_point']"
what is the highest point in the usa,"highlow.loc[highlow['highest_elevation']==highlow['highest_elevation'].max(), 'highest_point']"
what is the highest point of the usa,"highlow.loc[highlow['highest_elevation']==highlow['highest_elevation'].max(), 'highest_point']"
what is the highest point in the country,"highlow.loc[highlow['highest_elevation']==highlow['highest_elevation'].max(), 'highest_point']"
what is the highest point in the us,"highlow.loc[highlow['highest_elevation']==highlow['highest_elevation'].max(), 'highest_point']"
what is the highest point in the united states,"highlow.loc[highlow['highest_elevation']==highlow['highest_elevation'].max(), 'highest_point']"
what is the highest point of the state with the smallest population density,"highlow.loc[highlow['state_name'].isin(state.loc[state['density'] == state['density'].min(), 'state_name']), 'highest_point']"
what is the largest city in smallest state through which the mississippi runs,"city.loc[city['state_name'].isin(state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'state_name']) & (city['area'] == state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'area'].min()), 'city_name'].sort_values('population', ascending=false).iloc[0]"
what is the largest city in the smallest state in the usa,"city.loc[lambda x: (x['population'] == city.loc[city['state_name'].isin(state.loc[state['area'] == state['area'].min(), 'state_name']) ,'population'].max()) & x['state_name'].isin(state.loc[state['area'] == state['area'].min(), 'state_name']) ,'city_name']"
what is the biggest city in the smallest state,"city.loc[lambda x: (x['population'] == city.loc[city['state_name'].isin(state.loc[state['area'] == state['area'].min(), 'state_name']) ,'population'].max()) & x['state_name'].isin(state.loc[state['area'] == state['area'].min(), 'state_name']) ,'city_name']"
what is the largest state bordering california,"state.loc[(state['area'] == state.loc[state_name.isin(border_info.loc[border_info['state_name'] == 'california', 'border']), 'area'].max()) & state_name.isin(border_info.loc[border_info['state_name'] == 'california', 'border']), 'state_name']"
what is the largest state that borders california,"state.loc[(state['area'] == state.loc[state_name.isin(border_info.loc[border_info['state_name'] == 'california', 'border']), 'area'].max()) & state_name.isin(border_info.loc[border_info['state_name'] == 'california', 'border']), 'state_name']"
what state that borders california is the largest,"state.loc[(state['area'] == state.loc[state_name.isin(border_info.loc[border_info['state_name'] == 'california', 'border']), 'area'].max()) & state_name.isin(border_info.loc[border_info['state_name'] == 'california', 'border']), 'state_name']"
what is the longest river in the largest state,"river.loc[(river['length'] == river.loc[river['traverse'].isin(state.loc[state['area'] == state['area'].max(), 'state_name']), 'length'].max()) & (river['traverse'].isin(state.loc[state['area'] == state['area'].max(), 'state_name'])), 'river_name']"
what is the longest river in the states that border tennessee,"river.loc[lambda df: (df['length'] == river.loc[lambda df: df['traverse'].isin(border_info.loc[lambda df: df['state_name'] == ""tennessee"", 'border'])]['length'].max()) & (df['traverse'].isin(border_info.loc[lambda df: df['state_name'] == ""tennessee"", 'border'])), 'river_name']"
what is the longest river that flows through a state that borders tennessee,"river.loc[lambda df: (df['length'] == river.loc[lambda df: df['traverse'].isin(border_info.loc[lambda df: df['state_name'] == ""tennessee"", 'border'])]['length'].max()) & (df['traverse'].isin(border_info.loc[lambda df: df['state_name'] == ""tennessee"", 'border'])), 'river_name']"
what is the longest river that runs through a state that borders tennessee,"river.loc[lambda df: (df['length'] == river.loc[lambda df: df['traverse'].isin(border_info.loc[lambda df: df['state_name'] == ""tennessee"", 'border'])]['length'].max()) & (df['traverse'].isin(border_info.loc[lambda df: df['state_name'] == ""tennessee"", 'border'])), 'river_name']"
what is the longest river in the state with the most major cities,"river.loc[river['traverse']==city.loc[city['population']>150000].groupby('state_name')['city_name'].count().idxmax(), 'river_name'].str.len().nlargest(1)"
what is the lowest point in iowa,"highlow.loc[lambda x: x['state_name']=='iowa', 'lowest_point']"
what is the lowest point in iowa in meters,"highlow.loc[lambda x: x['state_name']=='iowa', 'lowest_point']"
what is the lowest point in the state of iowa,"highlow.loc[lambda x: x['state_name']=='iowa', 'lowest_point']"
where is the lowest point in iowa,"highlow.loc[lambda x: x['state_name']=='iowa', 'lowest_point']"
what is the lowest point of iowa,"highlow.loc[lambda x: x['state_name']=='iowa', 'lowest_point']"
where is the lowest spot in iowa,"highlow.loc[lambda x: x['state_name']=='iowa', 'lowest_point']"
what is the lowest point in usa,"highlow.loc[lambda x: x['lowest_elevation']==highlow['lowest_elevation'].min(), 'lowest_point']"
what is the lowest point in the united states,"highlow.loc[lambda x: x['lowest_elevation']==highlow['lowest_elevation'].min(), 'lowest_point']"
where is the lowest point in the us,"highlow.loc[lambda x: x['lowest_elevation']==highlow['lowest_elevation'].min(), 'lowest_point']"
what is the lowest point of the us,"highlow.loc[lambda x: x['lowest_elevation']==highlow['lowest_elevation'].min(), 'lowest_point']"
what is the lowest point of all states through which the mississippi river runs through,"highlow.loc[lambda x: x['state_name'].isin(river.loc[lambda x: x['river_name']=='mississippi', 'traverse']), 'lowest_point'].sort_values().iloc[0]"
which is the lowest point of the states that the mississippi runs through,"highlow.loc[lambda x: x['state_name'].isin(river.loc[lambda x: x['river_name']=='mississippi', 'traverse']), 'lowest_point'].sort_values().iloc[0]"
what is the most dense state in the usa,"state.loc[state['density'] == state['density'].max(), 'state_name']"
which state has the highest population density,"state.loc[state['density'] == state['density'].max(), 'state_name']"
which state has the greatest density,"state.loc[state['density'] == state['density'].max(), 'state_name']"
what state has the highest population density,"state.loc[state['density'] == state['density'].max(), 'state_name']"
what state has the greatest population density,"state.loc[state['density'] == state['density'].max(), 'state_name']"
what state has the largest population density,"state.loc[state['density'] == state['density'].max(), 'state_name']"
what is the state with the largest density in usa,"state.loc[state['density'] == state['density'].max(), 'state_name']"
what is the state with the largest population density,"state.loc[state['density'] == state['density'].max(), 'state_name']"
which state has the largest density,"state.loc[state['density'] == state['density'].max(), 'state_name']"
what is the most populous state through which the mississippi runs,"state.loc[(state['population'] == state.loc[state['state_name'].isin(river.loc[river['river_name'] == 'mississippi', 'traverse'])]['population'].max()) & state['state_name'].isin(river.loc[river['river_name'] == 'mississippi', 'traverse']), 'state_name']"
what state which the mississippi runs through has the largest population,"state.loc[(state['population'] == state.loc[state['state_name'].isin(river.loc[river['river_name'] == 'mississippi', 'traverse'])]['population'].max()) & state['state_name'].isin(river.loc[river['river_name'] == 'mississippi', 'traverse']), 'state_name']"
what is the population density of the largest state,"state.loc[state['area']==state['area'].max(), 'density']"
what is the population of the largest city in the state with the largest area,"city.loc[lambda x: (x['population'] == city.loc[lambda x: x['state_name'].isin(state.loc[state['area'] == state['area'].max(), 'state_name']), 'population'].max()) & x['state_name'].isin(state.loc[state['area'] == state['area'].max(), 'state_name'])]['population']"
what is the population of the smallest state,"state.loc[state['area'] == state['area'].min(), 'population']"
what is the population of the state with the highest population density,"state.loc[state['density'] == state['density'].max(), 'population']"
how many people live in the state with the largest population density,"state.loc[state['density'] == state['density'].max(), 'population']"
what is the smallest city in the usa,"city.loc[lambda x: x['population']==city['population'].min(), 'city_name']"
what is the smallest city in the us,"city.loc[lambda x: x['population']==city['population'].min(), 'city_name']"
what city has the least population,"city.loc[lambda x: x['population']==city['population'].min(), 'city_name']"
what is the city with the smallest population,"city.loc[lambda x: x['population']==city['population'].min(), 'city_name']"
what is the smallest state bordering texas,"state.loc[lambda x: (x['area'] == state.loc[state['state_name'].isin(border_info.loc[border_info['state_name']=='texas', 'border']), 'area'].min()) & (x['state_name'].isin(border_info.loc[border_info['state_name']=='texas', 'border']))]['state_name']"
what is the smallest state that borders texas,"state.loc[lambda x: (x['area'] == state.loc[state['state_name'].isin(border_info.loc[border_info['state_name']=='texas', 'border']), 'area'].min()) & (x['state_name'].isin(border_info.loc[border_info['state_name']=='texas', 'border']))]['state_name']"
which state has the smallest area that borders texas,"state.loc[lambda x: (x['area'] == state.loc[state['state_name'].isin(border_info.loc[border_info['state_name']=='texas', 'border']), 'area'].min()) & (x['state_name'].isin(border_info.loc[border_info['state_name']=='texas', 'border']))]['state_name']"
what is the smallest state that the mississippi river runs through,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse'].values) & (state['area'] == state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse'].values), 'area'].min()), 'state_name']"
what is the state with the smallest area,"state.loc[state['area'] == state['area'].min(), 'state_name']"
which is the smallest state,"state.loc[state['area'] == state['area'].min(), 'state_name']"
which state is the smallest,"state.loc[state['area'] == state['area'].min(), 'state_name']"
what is the smallest state in the usa,"state.loc[state['area'] == state['area'].min(), 'state_name']"
what is the smallest state by area,"state.loc[state['area'] == state['area'].min(), 'state_name']"
what state has the smallest area,"state.loc[state['area'] == state['area'].min(), 'state_name']"
what is the total length of all rivers in the usa,river['length'].sum()
what river flows through the most states,river.groupby('river_name')['traverse'].nunique().sort_values(ascending=false).iloc[:1].index.tolist()
which river goes through the most states,river.groupby('river_name')['traverse'].nunique().sort_values(ascending=false).iloc[:1].index.tolist()
which river runs through most states,river.groupby('river_name')['traverse'].nunique().sort_values(ascending=false).iloc[:1].index.tolist()
which river traverses most states,river.groupby('river_name')['traverse'].nunique().sort_values(ascending=false).iloc[:1].index.tolist()
what river traverses the most states,river.groupby('river_name')['traverse'].nunique().sort_values(ascending=false).iloc[:1].index.tolist()
which river runs through the most states,river.groupby('river_name')['traverse'].nunique().sort_values(ascending=false).iloc[:1].index.tolist()
what river runs through the most states,river.groupby('river_name')['traverse'].nunique().sort_values(ascending=false).iloc[:1].index.tolist()
what rivers are in states that border alabama,"river.loc[river['traverse'].isin(border_info.loc[border_info['state_name']=='alabama', 'border']), 'river_name']"
which rivers run through states bordering alabama,"river.loc[river['traverse'].isin(border_info.loc[border_info['state_name']=='alabama', 'border']), 'river_name']"
what rivers flow through states that alabama borders,"river.loc[river['traverse'].isin(border_info.loc[border_info['state_name']=='alabama', 'border']), 'river_name']"
what state bordering oklahoma has the largest population,"state.loc[state['state_name'].isin(border_info.loc[border_info['state_name']=='oklahoma', 'border']), 'state_name'].sort_values('population', ascending=false).iloc[:1]"
which of the states bordering oklahoma has the largest population,"state.loc[state['state_name'].isin(border_info.loc[border_info['state_name']=='oklahoma', 'border']), 'state_name'].sort_values('population', ascending=false).iloc[:1]"
what state that borders oklahoma has the highest population,"state.loc[state['state_name'].isin(border_info.loc[border_info['state_name']=='oklahoma', 'border']), 'state_name'].sort_values('population', ascending=false).iloc[:1]"
what is the most populated state bordering oklahoma,"state.loc[state['state_name'].isin(border_info.loc[border_info['state_name']=='oklahoma', 'border']), 'state_name'].sort_values('population', ascending=false).iloc[:1]"
what state contains the highest point of those the colorado river traverses,"highlow.loc[highlow['highest_elevation'] == highlow.loc[highlow['state_name'].isin(river.loc[river['river_name'] == 'colorado', 'traverse'].tolist()), 'highest_elevation'].max(), 'state_name']"
what state has the largest capital,"city.loc[city['population'] == city.merge(state.loc[state['capital'] == city['city_name']], on='city_name')['population'].max(), 'state_name']"
which state 's capital city is the largest,"city.loc[city['population'] == city.merge(state.loc[state['capital'] == city['city_name']], on='city_name')['population'].max(), 'state_name']"
what state has the longest river,"river.loc[river['length']==river['length'].max(), 'traverse'].unique()"
what state has the smallest urban population,city.groupby('state_name')['population'].sum().sort_values().index[0]
what states border states that border colorado,border_info[border_info['state_name'].isin(border_info[border_info['state_name']=='colorado']['border'])]['border']
what states border states that the mississippi runs through,"border_info.loc[border_info['state_name'].isin(river.loc[river['river_name'] == 'mississippi', 'traverse']), 'border']"
which states border states through which the mississippi traverses,"border_info.loc[border_info['state_name'].isin(river.loc[river['river_name'] == 'mississippi', 'traverse']), 'border']"
what states border states which the mississippi runs through,"border_info.loc[border_info['state_name'].isin(river.loc[river['river_name'] == 'mississippi', 'traverse']), 'border']"
what states border texas and have a major river,"border_info.loc[lambda x: (x['border']=='texas') & (x['state_name'].isin(river.loc[lambda y: y['length']>750, 'traverse'])), 'state_name']"
what states border the most populous state,"border_info.loc[border_info['state_name'].eq(state.loc[state['population'].idxmax(), 'state_name']), 'border']"
what are the states that border the state with the greatest population,"border_info.loc[border_info['state_name'].eq(state.loc[state['population'].idxmax(), 'state_name']), 'border']"
what states border the state with the smallest area,"border_info.loc[border_info['state_name'] == state.loc[state['area'] == state['area'].min(), 'state_name'].item(), 'border']"
which states border the state with the smallest area,"border_info.loc[border_info['state_name'] == state.loc[state['area'] == state['area'].min(), 'state_name'].item(), 'border']"
what states contain at least one major rivers,"river.loc[lambda x: x['length'] > 750, 'traverse']"
where are mountains,mountain['state_name']
where is the highest mountain of the united states,"mountain.loc[mountain['mountain_altitude'] == mountain['mountain_altitude'].max(), 'state_name']"
which state has the highest peak in the country,"mountain.loc[mountain['mountain_altitude'] == mountain['mountain_altitude'].max(), 'state_name']"
where is the smallest city,"city.loc[city['population'] == city['population'].min(), 'state_name']"
which is the density of the state that the largest river in the united states runs through,"state.loc[state['state_name'].isin(river.loc[river['length'] == river['length'].max(), 'traverse']), 'density']"
which is the highest peak not in alaska,mountain[mountain['mountain_altitude'] == mountain[mountain['state_name'] != 'alaska']['mountain_altitude'].max()]['mountain_name']
which rivers do not run through tennessee,"river.loc[~river['river_name'].isin(river.loc[river['traverse'] == 'tennessee', 'river_name']), 'river_name']"
what rivers do not run through tennessee,"river.loc[~river['river_name'].isin(river.loc[river['traverse'] == 'tennessee', 'river_name']), 'river_name']"
which rivers do not run through usa,"river.loc[lambda x: x['country_name']!=""usa"", 'river_name']"
which rivers run through states that border the state with the capital atlanta,"river.loc[river['traverse'].isin(border_info.loc[border_info['state_name'].isin(state.loc[state['capital']=='atlanta', 'state_name']), 'border']), 'river_name']"
what rivers run through the states that border the state with the capital atlanta,"river.loc[river['traverse'].isin(border_info.loc[border_info['state_name'].isin(state.loc[state['capital']=='atlanta', 'state_name']), 'border']), 'river_name']"
which state capital has the smallest population,"city.loc[city['population'] == city.merge(state, left_on='city_name', right_on='capital')['population'].min(), 'city_name']"
which state has the highest elevation,"highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']"
which state has the highest point,"highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']"
what state has the highest elevation,"highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']"
in which state does the highest point in usa exist,"highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']"
what state has highest elevation,"highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']"
what is the state with the highest elevation in the united states,"highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']"
what is the state that contains the highest point,"highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']"
what state contains the highest point in the us,"highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']"
which state has the lowest elevation,"highlow.loc[highlow['lowest_elevation']==highlow['lowest_elevation'].min(), 'state_name']"
what is the name of the state with the lowest point,"highlow.loc[highlow['lowest_elevation']==highlow['lowest_elevation'].min(), 'state_name']"
what is the state with the lowest point,"highlow.loc[highlow['lowest_elevation']==highlow['lowest_elevation'].min(), 'state_name']"
which state has the lowest point that borders idaho,"highlow[(highlow['lowest_elevation'] == highlow[highlow['state_name'].isin(border_info.query('state_name == ""idaho""')['border'])]['lowest_elevation'].min())& highlow['state_name'].isin(border_info.query('state_name == ""idaho""')['border'])]['state_name']"
which state has the smallest average urban population,"city.groupby('state_name').agg(avg_population=('population', 'mean')).sort_values('avg_population').iloc[:1].index"
which state is mount whitney in,"mountain.loc[mountain['mountain_name'] == 'whitney', 'state_name']"
in what state is mount whitney,"mountain.loc[mountain['mountain_name'] == 'whitney', 'state_name']"
where is mount whitney,"mountain.loc[mountain['mountain_name'] == 'whitney', 'state_name']"
where is mount whitney located,"mountain.loc[mountain['mountain_name'] == 'whitney', 'state_name']"
which states have a river,river['traverse']
what states have rivers running through them,river['traverse']
which states have a major city named austin,"city.loc[(city['city_name'] == 'austin') & (city['population']>150000), 'state_name']"
what is the largest city in a state that borders california,"city.query('state_name in (border_info.query(""state_name == 'california'"").border.tolist()) and population == (city.query(""state_name in (border_info.query('state_name == ""california""').border.tolist())"").population.max())')['city_name']"
what is the largest city in states that border california,"city.query('state_name in (border_info.query(""state_name == 'california'"").border.tolist()) and population == (city.query(""state_name in (border_info.query('state_name == ""california""').border.tolist())"").population.max())')['city_name']"
how many rivers do not traverse the state with the capital albany,"river.loc[~river['traverse'].isin(state.loc[state['capital']=='albany', 'state_name']), 'river_name'].count()"
what is the shortest river in texas,"river.loc[(river['length'] == river.loc[river['traverse'] == 'texas', 'length'].min()) & (river['traverse'] == 'texas'), 'river_name']"
what are the major cities in the smallest state in the us,"city.loc[(city['population'] > 150000) & (city['state_name'] == state.loc[state['area'] == state['area'].min(), 'state_name'].iloc[0]), 'city_name']"
what is the population of the capital of the largest state through which the mississippi runs,"city.loc[city['city_name'] == state.loc[state['area'] == state.merge(river.loc[river['river_name'] == 'mississippi'], left_on='state_name', right_on='traverse').area.max(), 'capital'].values[0], 'population'].values[0]"
what is the shortest river in the usa,"river.loc[lambda x: x['length'] == river['length'].min(), 'river_name']"
what is the shortest river,"river.loc[lambda x: x['length'] == river['length'].min(), 'river_name']"
what is the shortest river in the us,"river.loc[lambda x: x['length'] == river['length'].min(), 'river_name']"
what is the shortest river in the united states,"river.loc[lambda x: x['length'] == river['length'].min(), 'river_name']"
which is the shortest river,"river.loc[lambda x: x['length'] == river['length'].min(), 'river_name']"
what is the capital of the state that borders the state that borders texas,state[state['state_name'].isin(border_info[border_info['state_name'].isin(border_info[border_info['state_name'] == 'texas']['border'])]['border'])]['capital']
what is the smallest city of the smallest state in the us,"city.loc[(city['population'] == city.loc[city['state_name'].isin(state.loc[state['area'] == state['area'].min(), 'state_name']), 'population'].min()) & (city['state_name'].isin(state.loc[state['area'] == state['area'].min(), 'state_name'])),'city_name']"
what is the population of the largest state that borders texas,state[(state['area'] == state[state['state_name'].isin(border_info[border_info['state_name'] == 'texas']['border'])]['area'].max()) &state['state_name'].isin(border_info[border_info['state_name'] == 'texas']['border'])]['population']
what state is salem the capital of,"state.loc[lambda x: x['capital']=='salem', 'state_name']"
what states capital is salem,"state.loc[lambda x: x['capital']=='salem', 'state_name']"
salem is the capital of which state,"state.loc[lambda x: x['capital']=='salem', 'state_name']"
what state has the capital salem,"state.loc[lambda x: x['capital']=='salem', 'state_name']"
what rivers flow through the state with the largest population,"river.loc[river['traverse'].isin(state.loc[state['population'].idxmax(), 'state_name']), 'river_name']"
what is the largest state that borders the state with the highest population,state[state['area']==state[state['state_name'].isin(border_info[border_info['border'].isin(state[state['population']==state['population'].max()]['state_name'])]['state_name'])]['area'].max()]['state_name'][state[state['state_name'].isin(border_info[border_info['border'].isin(state[state['population']==state['population'].max()]['state_name'])]['state_name'])]['state_name'].isin(border_info[border_info['border'].isin(state[state['population']==state['population'].max()]['state_name'])]['border'])]
how many rivers are there in us,river['river_name'].count()
name the 50 capitals in the usa,state['capital'].unique()
how many states have a city named springfield,(city['city_name'] == 'springfield').sum()
how many states have a city called springfield,(city['city_name'] == 'springfield').sum()
how many states have cities named springfield,(city['city_name'] == 'springfield').sum()
how many states have cities or towns named springfield,(city['city_name'] == 'springfield').sum()
what state borders the state with the smallest population,"border_info.loc[border_info['state_name'].isin(state.loc[state['population']==state['population'].min(), 'state_name']), 'border']"
what are the lakes in states bordering texas,"lake.loc[lake['state_name'].isin(border_info.loc[border_info['state_name']=='texas', 'border']), 'lake_name']"
how many major cities are in texas,"city.loc[(city['population'] > 150000) & (city['state_name'] == 'texas'), 'city_name'].count()"
how many big cities are in texas,"city.loc[(city['population'] > 150000) & (city['state_name'] == 'texas'), 'city_name'].count()"
how many major cities are there in texas,"city.loc[(city['population'] > 150000) & (city['state_name'] == 'texas'), 'city_name'].count()"
how high are the highest points of all the states,highlow['highest_elevation']
how many states does the missouri run through,"(river.loc[lambda x: x['river_name']=='missouri', 'traverse']).count()"
how many states does the missouri river flow through,"(river.loc[lambda x: x['river_name']=='missouri', 'traverse']).count()"
how many states does the missouri river run through,"(river.loc[lambda x: x['river_name']=='missouri', 'traverse']).count()"
what is the longest river in the smallest state in the usa,"river.loc[(river['length'] == river.loc[river['traverse'].isin(state.loc[state['area'] == state['area'].min(), 'state_name']), 'length'].max()) & river['traverse'].isin(state.loc[state['area'] == state['area'].min(), 'state_name']), 'river_name']"
what is the average population per square km in pennsylvania,"state.loc[state['state_name']=='pennsylvania', 'population']/state.loc[state['state_name']=='pennsylvania', 'area']"
what states border states that border states that border florida,"border_info.loc[lambda x: x['state_name'].isin(border_info.loc[lambda y: y['state_name'].isin(border_info.loc[lambda z: z['state_name']=='florida', 'border']), 'border']), 'border']"
how many states border at least one other state,border_info['state_name'].nunique()
what is the height of the highest mountain in texas,"highlow.loc[highlow['state_name']=='texas', 'highest_elevation'].max()"
how many states border colorado and border new mexico,"border_info.loc[(border_info['border'].isin(border_info.loc[border_info['state_name']=='new mexico', 'border'])) & (border_info['state_name']=='colorado'), 'border'].count()"
how many major cities are in states bordering nebraska,"city.loc[lambda x: (x['population'] > 150000) & (x['state_name'].isin(border_info.loc[lambda y: y['state_name']=='nebraska', 'border'])), 'city_name'].count()"
what is the total population of the states that border texas,"state.loc[state['state_name'] == 'texas', 'population'].sum()"
what are the major lakes in united states,"lake.loc[lake['area'] > 750, 'lake_name']"
show me all the major lakes in the us,"lake.loc[lake['area'] > 750, 'lake_name']"
name all the lakes of us,lake['lake_name']
how many major rivers cross ohio,"river.loc[(river['length'] > 750) & (river['traverse'] == 'ohio'), 'river_name'].count()"
what state has the shortest river,"river.loc[river['length'] == river['length'].nunique().idxmin(), 'traverse'].unique()"
how many states are next to major rivers,"river.loc[lambda x: x['length'] > 750, 'traverse'].nunique()"
what is the height of mount mckinley,"mountain.loc[mountain['mountain_name']=='mckinley', 'mountain_altitude']"
what states does the shortest river run through,"river.loc[river['length'] == river['length'].min(), 'traverse']"
what is the highest point in the state with the smallest population,"state[state['state_name'].isin(state[state['population']==state['population'].min()]['state_name'])].merge(highlow, on='state_name')['highest_point']"
which rivers run through the state with the lowest elevation in the usa,"river.loc[river['traverse'].isin(highlow.loc[highlow['lowest_elevation'] == highlow['lowest_elevation'].min(), 'state_name']), 'river_name']"
what rivers run through the state with the lowest point in the usa,"river.loc[river['traverse'].isin(highlow.loc[highlow['lowest_elevation'] == highlow['lowest_elevation'].min(), 'state_name']), 'river_name']"
what mountains are in alaska,"mountain.loc[mountain['state_name'] == 'alaska', 'mountain_name']"
how many states have major rivers,"(river.loc[lambda x: x['length'] > 750, 'traverse']).count()"
what is the smallest state through which the longest river runs,"state.loc[lambda x: (x['area'] == state.loc[state['state_name'].isin(river.loc[river['length'] == river['length'].max(), 'traverse'])]['area'].min())& (x['state_name'].isin(river.loc[river['length'] == river['length'].max(), 'traverse']))]['state_name']"
what is the largest state traversed by the rio grande river,"state.loc[state['state_name'].isin(river.loc[river['river_name'] == 'rio grande', 'traverse']) & (state['area'] == state.loc[state['state_name'].isin(river.loc[river['river_name'] == 'rio grande', 'traverse']), 'area'].max()), 'state_name']"
what is the largest of the state that the rio grande runs through,"state.loc[state['state_name'].isin(river.loc[river['river_name'] == 'rio grande', 'traverse']) & (state['area'] == state.loc[state['state_name'].isin(river.loc[river['river_name'] == 'rio grande', 'traverse']), 'area'].max()), 'state_name']"
how many rivers run through the states bordering colorado,"river.loc[river['traverse'].isin(border_info.loc[border_info['state_name']=='colorado', 'border']), 'river_name'].count()"
what state has no rivers,"state.loc[~state['state_name'].isin(river['traverse']), 'state_name']"
what is the capital of the largest state,"state.loc[state['area'] == state['area'].max(), 'capital']"
what is the capital city of the largest state in the us,"state.loc[state['area'] == state['area'].max(), 'capital']"
how many cities are in texas,(city['state_name'] == 'texas').sum()
how many cities does texas have,(city['state_name'] == 'texas').sum()
what is the area of the states,state['area']
how many states in the us does the shortest river run through,"river.loc[lambda x: x['length']==river['length'].nunique().idxmin(), 'traverse'].nunique()"
what rivers flow through states that border the state with the largest population,"river.loc[river['traverse'].isin(border_info.loc[border_info['state_name'].isin(state.loc[state['population'] == state['population'].max(), 'state_name']), 'border']), 'river_name']"
what are the major cities in the largest state,"city.loc[(city['population'] > 150000) & (city['state_name'] == state.loc[state['area'] == state['area'].max(), 'state_name'].iloc[0]), 'city_name']"
what is the area of the smallest state,"state.loc[state['area']==state['area'].min(), 'area']"
which states border the longest river in the usa,border_info[border_info['state_name'].isin(river[river['length'] == river['length'].max()]['traverse'])]['border']
what is the population density of the state with the smallest population,"state.loc[state['population'] == state['population'].min(), 'density']"
how many states border the mississippi river,"border_info.loc[border_info['state_name'].isin(river.loc[river['river_name'] == 'mississippi']['traverse'].tolist()), 'border'].nunique()"
what states have a capital that is the highest point in the state,"pd.merge(state, highlow, left_on='capital', right_on='highest_point')['state_name']"
what is the population of the capital of the smallest state,"state.loc[lambda x: x['area'] == state['area'].min(), 'capital'].map(city.set_index('city_name')['population']).squeeze()"
what is the population of the capital of the largest state,"city.loc[city['city_name'] == state.loc[state['area'] == state['area'].max(), 'capital'].values[0], 'population']"
what is the lowest point of the state with the largest area,"highlow.loc[highlow['state_name'].isin(state.loc[state['area'] == state['area'].max(), 'state_name']), 'lowest_point']"
what states border states that border the state with the largest population,"border_info.merge(border_info, left_on='state_name', right_on='border').query(""state_name_y in (state.query('population == population.max()')['state_name'])"")['border_x']"
what is the size of the largest state in the usa,state['area'].max()
what is the area of the largest state,state['area'].max()
which capitals are not major cities,"state.loc[state['capital'].isin(city.loc[city['population']<=150000, 'city_name']), 'capital']"
give me the cities in usa,city['city_name']
what is the highest point of the state with the largest area,"highlow.merge(state.query('area == @state[""area""].max()'), on='state_name')['highest_point']"
where is massachusetts,"state.loc[state['state_name']=='massachusetts', 'country_name']"
what state has the largest urban population,"city.groupby('state_name', as_index=false).agg({'population': 'sum'}).sort_values('population', ascending=false).iloc[0]['state_name']"
what are the major rivers in the us,river['river_name']
how many cities named austin are there in the usa,(city['city_name'] == 'austin').sum()
how many people live in the smallest state bordering wyoming,"state.loc[state['population'].eq(state.loc[state['state_name'].isin(border_info.loc[border_info['state_name'].eq('wyoming'), 'border']), 'population'].max()) & state['state_name'].isin(border_info.loc[border_info['state_name'].eq('wyoming'), 'border']), 'population']"
what is the length of the colorado river in texas,"river.loc[(river['river_name']=='colorado') & (river['traverse']=='texas'), 'length']"
what is the population density in the state with capital austin,"state.loc[state['capital']=='austin', 'density']"
how long is the shortest river in the usa,"river.loc[lambda x: x['length'] == river['length'].min(), 'length']"
what is the elevation of death valley,"highlow.loc[lambda x: x['lowest_point'] == 'death valley', 'lowest_elevation']"
what is the average population of the us by state,state['population'].mean()
what rivers flow through the largest state,"river.loc[river['traverses'].isin(state.loc[state['area']==state['area'].max(), 'state_name']), 'river_name']"
what states border states that border states that border states that border texas,"border_info.merge(border_info.merge(border_info.merge(border_info, on='border'), on='border'), on='border').loc[lambda x: x['state_name']=='texas', 'border']"
how many states border on the state whose capital is boston,"border_info.loc[lambda x: x['state_name']==state.loc[lambda y: y['capital']=='boston', 'state_name'].iloc[0], 'border'].count()"
what are the major cities in the states through which the major river in virginia runs,"city.loc[lambda x: (x['population'] > 150000) & (x['state_name'].isin(river.loc[lambda y: (y['length'] > 750) & (y['traverse']=='virginia'), 'river_name'])),'city_name']"
which states does not border texas,"state.loc[~state['state_name'].isin(border_info.query(""state_name == 'texas'"")['border']), 'state_name']"
how many states border the largest state,"border_info.loc[border_info['state_name'] == state.loc[state['area'] == state['area'].max(), 'state_name'].iloc[0], 'border'].count()"
which state is the largest city in montana in,"city.loc[lambda x: x['population']==city.loc[lambda y: y['state_name']=='montana', 'population'].max()].loc[lambda x: x['state_name']=='montana', 'state_name']"
what is capital of the state with the lowest point,"state.merge(highlow.loc[lambda x: x['lowest_elevation']==highlow['lowest_elevation'].min(), 'state_name'], on='state_name')['capital']"
what is the biggest american city in a state with a river,"city.loc[lambda x: x['population'] == city.merge(river, left_on='state_name', right_on='traverse')['population'].max(), 'city_name'].unique()"
how many rivers are in the state with the largest population,"(river.merge(state, left_on='traverse', right_on='state_name') ['river_name'].count() if state['state_name'].iloc[[state['population'].idxmax()]].values[0] == (river.merge(state, left_on='traverse', right_on='state_name')['state_name'].unique()[0]) else 0)"
what is the largest state that borders the state with the lowest point in the usa,"highlow.merge(border_info, left_on='state_name', right_on='border').merge(state, left_on='border', right_on='state_name').loc[lambda x: x['lowest_elevation'] == x['lowest_elevation'].min(), 'state_name'].iloc[0]"
what is the capital of the state with the highest point,"state.merge(highlow.loc[lambda x: x['highest_elevation'] == highlow['highest_elevation'].max(), ['state_name']], on='state_name')['capital']"
what is the capital of the state with the highest elevation,"state.merge(highlow.loc[lambda x: x['highest_elevation'] == highlow['highest_elevation'].max(), ['state_name']], on='state_name')['capital']"
what is the highest point in the smallest state,"pd.merge(highlow, state[state['area']==state['area'].min()], on='state_name')['highest_point']"
how many rivers are in the state with the highest point.,"pd.merge(highlow, river.loc[:, ['traverse', 'river_name']], left_on='state_name', right_on='traverse').loc[lambda x: x['highest_elevation']==highlow['highest_elevation'].max(), 'river_name'].count()"
how high is the highest point in the largest state,"highlow.merge(state.loc[state['area']==state['area'].max(), 'state_name'], on='state_name')['highest_elevation']"
what is the longest river in the state with the highest point,"river.loc[river['traverse'].isin(highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']), 'river_name'].sort_values('length', ascending=false).iloc[0]"
papers that are coauthored by peter mertens and dina barbian,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
papers written by peter mertens and dina barbian,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
what are the papers that have peter mertens and dina barbian as co-authors,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
what papers have peter mertens and dina barbian written ?,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
what paper did peter mertens and dina barbian write together ?,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
has peter mertens and dina barbian written a paper together ?,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
papers by peter mertens and dina barbian,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
papers by authors peter mertens and dina barbian,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
what papers were written by authors peter mertens and dina barbian,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
papers by peter mertens and dina barbian,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
papers written by authors peter mertens and dina barbian,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
when did peter mertens and dina barbian collaborate ?,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
what are the collaborations of peter mertens and dina barbian ?,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
have peter mertens and dina barbian written a paper together ?,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
peter mertens and dina barbian as co-authors,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
does peter mertens ever collaborated with dina barbian ?,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
which papers have peter mertens and dina barbian as co-authors ?,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
papers coauthored by peter mertens and dina barbian,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
what papers have been written by peter mertens and dina barbian ?,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
what papers have been written by both peter mertens and dina barbian ?,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
what papers have been written by peter mertens and dina barbian .,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
who has written the most syntactic parsing papers ?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
who is the most published author in syntactic parsing ?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
who has the most publications in syntactic parsing ?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
who has written the most papers on syntactic parsing ?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
list prominent scholars in syntactic parsing ?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
who wrote the most papers on syntactic parsing ?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
who are the authors with the most published papers in syntactic parsing ?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
top syntactic parsing author,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
top author in syntactic parsing,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
who published the most in syntactic parsing ?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
who published the most papers in syntactic parsing ?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
how many citation noah a smith has ?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['authorname']=='noah a smith']['citedpaperid'].nunique()"
noah a smith citation count,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['authorname']=='noah a smith']['citedpaperid'].nunique()"
how many citations does noah a smith have ?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['authorname']=='noah a smith']['citedpaperid'].nunique()"
how many citations does noah a smith have ?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['authorname']=='noah a smith']['citedpaperid'].nunique()"
number of citations of noah a smith,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['authorname']=='noah a smith']['citedpaperid'].nunique()"
how many citations does noah a smith have,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['authorname']=='noah a smith']['citedpaperid'].nunique()"
how many times was noah a smith cited ?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['authorname']=='noah a smith']['citedpaperid'].nunique()"
how many citations does noah a smith has ?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['authorname']=='noah a smith']['citedpaperid'].nunique()"
chi papers,"pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
papers at chi,"pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
papers in chi,"pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
chi,"pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
papers about chi,"pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
show me chi papers .,"pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
what papers did chi publish ?,"pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
list papers published in chi,"pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
papers on chi,"pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
has mirella lapata written any papers in 2016 ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: (x['authorname']=='mirella lapata') & (x['year']==2016)].groupby('authorid').agg({'paperid': 'nunique'})"
what papers has sharon goldwater written ?,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
what papers has written by sharon goldwater ?,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
papers by sharon goldwater,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
what did sharon goldwater write ?,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
papers where sharon goldwater is an author,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
papers authored by sharon goldwater,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
sharon goldwater papers,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
papers by sharon goldwater,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
papers written by sharon goldwater,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
which papers has sharon goldwater written ?,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
papers written by sharon goldwater,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
what has sharon goldwater published ?,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
does sharon goldwater have any papers published ?,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
sharon goldwater 's papers,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
show me papers by sharon goldwater .,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
what papers are authored by sharon goldwater ?,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
papers by sharon goldwater ?,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
what was oren etzioni 's latest paper ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='oren etzioni', 'paperid'].unique()"
latest paper by oren etzioni,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='oren etzioni', 'paperid'].unique()"
what is the latest paper by oren etzioni ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='oren etzioni', 'paperid'].unique()"
what is oren etzioni 's latest paper ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='oren etzioni', 'paperid'].unique()"
what are the latest papers by oren etzioni ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='oren etzioni', 'paperid'].unique()"
most recent papers by oren etzioni,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='oren etzioni', 'paperid'].unique()"
are there any monte carlo simulation papers since 2011 ?,"pd.merge(pd.merge(keyphrase[keyphrase['keyphrasename']=='monte carlo simulation'], paperkeyphrase, on='keyphraseid'), paper[paper['year']>2011], on='paperid')['paperid'].unique()"
monte carlo simulation papers later than 2011,"pd.merge(pd.merge(keyphrase[keyphrase['keyphrasename']=='monte carlo simulation'], paperkeyphrase, on='keyphraseid'), paper[paper['year']>2011], on='paperid')['paperid'].unique()"
monte carlo simulation later than 2011,"pd.merge(pd.merge(keyphrase[keyphrase['keyphrasename']=='monte carlo simulation'], paperkeyphrase, on='keyphraseid'), paper[paper['year']>2011], on='paperid')['paperid'].unique()"
monte carlo simulation papers published after 2011,"pd.merge(pd.merge(keyphrase[keyphrase['keyphrasename']=='monte carlo simulation'], paperkeyphrase, on='keyphraseid'), paper[paper['year']>2011], on='paperid')['paperid'].unique()"
monte carlo simulation papers since 2011,"pd.merge(pd.merge(keyphrase[keyphrase['keyphrasename']=='monte carlo simulation'], paperkeyphrase, on='keyphraseid'), paper[paper['year']>2011], on='paperid')['paperid'].unique()"
does ras bodik publish a lot ?,"writes.merge(author, on='authorid').merge(paper, on='paperid').query('authorname==""ras bodik""')['paperid'].nunique()"
how many papers did david m. blei publish at aistats ?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='david m. blei') & (lambda x: x['venuename']=='aistats'), 'paperid'].nunique()"
how many papers does david m. blei have in aistats ?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='david m. blei') & (lambda x: x['venuename']=='aistats'), 'paperid'].nunique()"
how many papers has david m. blei published in aistats ?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='david m. blei') & (lambda x: x['venuename']=='aistats'), 'paperid'].nunique()"
how many papers does david m. blei have at aistats,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='david m. blei') & (lambda x: x['venuename']=='aistats'), 'paperid'].nunique()"
how many papers does david m. blei have in aistats ?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='david m. blei') & (lambda x: x['venuename']=='aistats'), 'paperid'].nunique()"
how many david m. blei papers are in aistats ?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='david m. blei') & (lambda x: x['venuename']=='aistats'), 'paperid'].nunique()"
how many papers david m. blei has in aistats ?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='david m. blei') & (lambda x: x['venuename']=='aistats'), 'paperid'].nunique()"
how many papers does david m. blei have in aistats,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='david m. blei') & (lambda x: x['venuename']=='aistats'), 'paperid'].nunique()"
list all academic papers on machine networks for one shot learning,"paper.loc[lambda x: x['title'] == 'machine networks for one shot learning', 'paperid'].unique()"
machine networks for one shot learning,"paper.loc[lambda x: x['title'] == 'machine networks for one shot learning', 'paperid'].unique()"
which emnlp 2010 papers have the most citations ?,"(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, left_on='venueid', right_on='venueid')).loc[(paper['year']==2010) & (venue['venuename']=='emnlp'), 'citedpaperid'].value_counts().reset_index().rename(columns={'index':'citedpaperid', 'citedpaperid':'count'}).sort_values('count', ascending=false)"
which paper from emnlp 2010 was cited most ?,"(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, left_on='venueid', right_on='venueid')).loc[(paper['year']==2010) & (venue['venuename']=='emnlp'), 'citedpaperid'].value_counts().reset_index().rename(columns={'index':'citedpaperid', 'citedpaperid':'count'}).sort_values('count', ascending=false)"
most cited emnlp 2010 papers,"(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, left_on='venueid', right_on='venueid')).loc[(paper['year']==2010) & (venue['venuename']=='emnlp'), 'citedpaperid'].value_counts().reset_index().rename(columns={'index':'citedpaperid', 'citedpaperid':'count'}).sort_values('count', ascending=false)"
which emnlp 2010 papers have been cited the most ?,"(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, left_on='venueid', right_on='venueid')).loc[(paper['year']==2010) & (venue['venuename']=='emnlp'), 'citedpaperid'].value_counts().reset_index().rename(columns={'index':'citedpaperid', 'citedpaperid':'count'}).sort_values('count', ascending=false)"
what papers were published at cvpr in 2016 about class consistent multi-modal fusion with binary features applied to rgb-d object dataset ?,"(pd.merge(pd.merge(pd.merge(dataset, paperdataset, on='datasetid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['datasetname']=='rgb-d object dataset') & (x['title']=='class consistent multi-modal fusion with binary features') & (x['year']==2016) & (x['venuename']=='cvpr')]['paperid'].unique())"
what papers were published at cvpr '16 about class consistent multi-modal fusion with binary features applied to rgb-d object dataset ?,"(pd.merge(pd.merge(pd.merge(dataset, paperdataset, on='datasetid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['datasetname']=='rgb-d object dataset') & (x['title']=='class consistent multi-modal fusion with binary features') & (x['year']==2016) & (x['venuename']=='cvpr')]['paperid'].unique())"
how many papers are in deep learning ?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='deep learning', 'paperid'].nunique()"
how many papers are about deep learning ?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='deep learning', 'paperid'].nunique()"
how many papers about deep learning ?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='deep learning', 'paperid'].nunique()"
how many papers are related to deep learning ?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='deep learning', 'paperid'].nunique()"
how many papers has christopher d. manning written ?,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
how many papers does christopher d. manning have ?,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
how many papers has christopher d. manning ?,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
how many papers has christopher d. manning published ?,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
how many papers has christopher d. manning written ?,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
has christopher d. manning published any papers ?,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
how many papers has christopher d. manning published ?,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
how many papers does christopher d. manning have ?,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
how many paper does christopher d. manning have ?,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
how many publications does christopher d. manning have ?,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
how many papers does christopher d. manning have,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
number of papers written by christopher d. manning,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
what kind of papers does luke zettlemoyer publish,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
keyphrases used by luke zettlemoyer,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
what keywords are in papers by luke zettlemoyer ?,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
keywords used by luke zettlemoyer,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
what keywords are used by luke zettlemoyer,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
keyphrases used by luke zettlemoyer,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
keyphrases by luke zettlemoyer,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
give me the keywords used by luke zettlemoyer,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
what topic does luke zettlemoyer write about ?,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
what topics does luke zettlemoyer publish in,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
keywords in the papers written by luke zettlemoyer,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
keyphrases used by luke zettlemoyer .,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
topics used by luke zettlemoyer,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
what conference does daniella coelho publish in ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='daniella coelho', 'venueid'].unique()"
conferences that daniella coelho has published in,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='daniella coelho', 'venueid'].unique()"
in which conferences does daniella coelho typically publish ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='daniella coelho', 'venueid'].unique()"
in what conferences does daniella coelho publish ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='daniella coelho', 'venueid'].unique()"
what conferences does daniella coelho publish in ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='daniella coelho', 'venueid'].unique()"
at which conferences does daniella coelho publish ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='daniella coelho', 'venueid'].unique()"
what conferences does daniella coelho submit to ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='daniella coelho', 'venueid'].unique()"
how many papers are there ?,paper['paperid'].nunique()
how many papers by ed desmond contain the keyphrases semantic parsing ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='ed desmond') & (lambda x: x['keyphrasename']=='semantic parsing'), 'paperid'].nunique()"
how many papers does ed desmond have in semantic parsing area ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='ed desmond') & (lambda x: x['keyphrasename']=='semantic parsing'), 'paperid'].nunique()"
how many semantic parsing papers has ed desmond written ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='ed desmond') & (lambda x: x['keyphrasename']=='semantic parsing'), 'paperid'].nunique()"
how many paper has ed desmond written about semantic parsing ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='ed desmond') & (lambda x: x['keyphrasename']=='semantic parsing'), 'paperid'].nunique()"
what conferences did li dong submit to in 2016 ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[(lambda x: x['authorname']=='li dong')(author) & (paper['year']==2016), 'venueid'].unique()"
where did li dong publish in 2016,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[(lambda x: x['authorname']=='li dong')(author) & (paper['year']==2016), 'venueid'].unique()"
what conferences did li dong publish in in 2016 ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[(lambda x: x['authorname']=='li dong')(author) & (paper['year']==2016), 'venueid'].unique()"
where did li dong publish in 2016 ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[(lambda x: x['authorname']=='li dong')(author) & (paper['year']==2016), 'venueid'].unique()"
acl papers in 2012 on parsing,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
what papers were published in acl in 2012 about parsing ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
papers on parsing appeared at acl last year,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
parsing papers from acl 2012,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
papers about parsing in acl 2012,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
acl papers in 2012 in parsing,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
acl papers in 2012 about parsing,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
what papers were published at acl in 2012 were about parsing ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
papers on parsing appeared at acl in 2012,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
how many parsing papers did acl 2012 have ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
who published parsing papers at acl 2012,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
which papers in acl 2012 had parsing in them ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
what were some parsing based papers in acl 2012 ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
list the popular publications on dependent types,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='dependent types']['paperid'].unique()"
which paper should i read about dependent types ?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='dependent types']['paperid'].unique()"
top dependent types papers,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='dependent types']['paperid'].unique()"
list papers that has a keyword question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
question answering research papers,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
papers on question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
papers related to question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
papers about question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
papers about question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
papers published in the area of question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
question answering experiments,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
show me the papers on question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
papers that used question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
papers that mention question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
question answering papers,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
show me question answering papers .,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
question answering publications,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
fetch me some papers on question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
papers on question answering experiments,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
what papers talk about question answering ?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
what is the paper about question answering ?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
which papers are about about question answering ?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
list papers that used question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
papers for question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
list papers that has keyword question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
papers with question answering in keyphrases,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
keyphrases used by luke s zettlemoyer for each year,"pd.merge(pd.merge(pd.merge(paper, paperkeyphrase, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke s zettlemoyer', ['keyphraseid', 'year']].sort_values(['year', 'keyphraseid']).drop_duplicates()"
recent research interests of sanjeev arora,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='sanjeev arora'].sort_values('year', ascending=false).drop_duplicates(subset='keyphrasename')[['keyphrasename', 'year']]"
recent papers by sanjeev arora,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='sanjeev arora'].sort_values('year', ascending=false).drop_duplicates(subset='keyphrasename')[['keyphrasename', 'year']]"
recent papers written by sanjeev arora,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='sanjeev arora'].sort_values('year', ascending=false).drop_duplicates(subset='keyphrasename')[['keyphrasename', 'year']]"
list papers published by balakrishnan prabhakaran,"pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='balakrishnan prabhakaran', ['paperid', 'year']].drop_duplicates()"
citation count of zachary tatlock 's papers,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='zachary tatlock'][['paperid', 'year']].drop_duplicates()"
subhasis chaudhuri,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='subhasis chaudhuri', 'paperid'].unique()"
list papers by subhasis chaudhuri,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='subhasis chaudhuri', 'paperid'].unique()"
list of papers by subhasis chaudhuri,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='subhasis chaudhuri', 'paperid'].unique()"
conference papers of subhasis chaudhuri,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='subhasis chaudhuri', 'paperid'].unique()"
how many parsing papers in acl 2014,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[(lambda x: (x['keyphrasename']=='parsing')&(x['year']==2014)&(x['venuename']=='acl')), 'paperid'].nunique()"
how many parsing papers appeared in the proceeeding of acl 2014 ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[(lambda x: (x['keyphrasename']=='parsing')&(x['year']==2014)&(x['venuename']=='acl')), 'paperid'].nunique()"
how many parsing papers were published at acl 2014 ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[(lambda x: (x['keyphrasename']=='parsing')&(x['year']==2014)&(x['venuename']=='acl')), 'paperid'].nunique()"
brian curless convolution paper,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
convolution by brian curless,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
papers by brian curless about convolution,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
brian curless 's paper about convolution,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
what are the papers of brian curless in convolution ?,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
papers brian curless wrote about convolution,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
brian curless 's papers on convolution,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
what is the paper about convolution from brian curless ?,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
papers by brian curless in convolution topic,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
i want the papers on keyphrase0 by brian curless,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
convolution papers by brian curless,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
what papers has brian curless written on convolution ?,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
what papers has brian curless written about convolution ?,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
convolution paper by brian curless,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
does brian curless do convolution ?,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
what papers has liwen xiong written in 2015,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
papers by liwen xiong in 2015,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
what did liwen xiong published in 2015 ?,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
papers written by liwen xiong in 2015,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
what are the papers of liwen xiong in 2015,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
papers by liwen xiong from 2015,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
papers published in 2015 by liwen xiong,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
what has liwen xiong done in the past year,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
what papers did liwen xiong publish last year ?,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
papers published in 2015 by liwen xiong,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
liwen xiong 's papers in 2015 ?,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
liwen xiong 's papers in 2015,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
liwen xiong publication 2015,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
papers authored by liwen xiong in 2015,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
papers from liwen xiong in 2015,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
what papers are published by liwen xiong in 2015,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
what tail paper published in nips ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
list the papers on tail that were published in nips,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
what are the papers in nips about tail ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
papers about tail in nips,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
papers at nips related to tail,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
papers about tail published at nips,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
tail papers in nips,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
papers on tail nips,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
tail papers used in nips,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
how many co-authors has mark steedman had ?,len(writes[writes['paperid'].isin(writes[writes['authorid'].isin(author[author['authorname'] == 'mark steedman']['authorid'])]['paperid']) & ~(author['authorname'] == 'mark steedman')]['authorid'].unique())
keyphrases used by christof dallermassl in 2000,"pd.merge(pd.merge(pd.merge(paper, paperkeyphrase, on='paperid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname']=='christof dallermassl') & (x['year']==2000)), 'keyphraseid'].unique()"
keyphrases used by christof dallermassl in 2000,"pd.merge(pd.merge(pd.merge(paper, paperkeyphrase, on='paperid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname']=='christof dallermassl') & (x['year']==2000)), 'keyphraseid'].unique()"
keyphrases christof dallermassl used in papers written last year,"pd.merge(pd.merge(pd.merge(paper, paperkeyphrase, on='paperid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname']=='christof dallermassl') & (x['year']==2000)), 'keyphraseid'].unique()"
what are keyphrases by christof dallermassl in 2000 ?,"pd.merge(pd.merge(pd.merge(paper, paperkeyphrase, on='paperid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname']=='christof dallermassl') & (x['year']==2000)), 'keyphraseid'].unique()"
what author is most cited ?,"pd.merge(pd.merge(writes, author, on='authorid'), cite, left_on='paperid', right_on='citedpaperid').groupby('authorname').agg({'citingpaperid': 'count'}).sort_values('citingpaperid', ascending=false)"
journal articles by mohammad rastegari,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[(lambda x: x['authorname'] == 'mohammad rastegari')(x) & (x['journalid'] >= 0), 'paperid'].unique()"
journal papers by mohammad rastegari,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[(lambda x: x['authorname'] == 'mohammad rastegari')(x) & (x['journalid'] >= 0), 'paperid'].unique()"
best paper in tacl 2014 ?,"pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, on='venueid').loc[lambda x: (x['year']==2014) & (x['venuename']=='tacl')].groupby('paperid').agg({'citingpaperid': 'nunique'}).sort_values('citingpaperid', ascending=false)"
what was the best paper at tacl 2014 ?,"pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, on='venueid').loc[lambda x: (x['year']==2014) & (x['venuename']=='tacl')].groupby('paperid').agg({'citingpaperid': 'nunique'}).sort_values('citingpaperid', ascending=false)"
who published at acl 2016 ?,"pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').query('year == 2016 and venuename == ""acl""')['authorid'].unique()"
acl 2016 authors,"pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').query('year == 2016 and venuename == ""acl""')['authorid'].unique()"
authors of acl 2016 papers,"pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').query('year == 2016 and venuename == ""acl""')['authorid'].unique()"
list of authors acl 2016,"pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').query('year == 2016 and venuename == ""acl""')['authorid'].unique()"
author published acl 2016,"pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').query('year == 2016 and venuename == ""acl""')['authorid'].unique()"
who had papers at acl 2016 ?,"pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').query('year == 2016 and venuename == ""acl""')['authorid'].unique()"
list of authors in acl 2016,"pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').query('year == 2016 and venuename == ""acl""')['authorid'].unique()"
how many papers were written on multiuser receiver in the decision feedback this year ?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='multiuser receiver in the decision feedback'], on='keyphraseid').merge(paper[paper['year']==2016], on='paperid').groupby('paperid').filter(lambda x: x['keyphrasename'].nunique() > 1)['paperid'].unique()"
how many papers run experiments on imagenet ?,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname'].str.contains('imagenet'), 'paperid'].nunique()"
how many papers used imagenet dataset ?,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname'].str.contains('imagenet'), 'paperid'].nunique()"
how many papers written on imagenet ?,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname'].str.contains('imagenet'), 'paperid'].nunique()"
how many papers are based on imagenet,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname'].str.contains('imagenet'), 'paperid'].nunique()"
how many papers use imagenet ?,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname'].str.contains('imagenet'), 'paperid'].nunique()"
how many papers did mirella lapata cite ?,"pd.merge(pd.merge(writes, author, on='authorid'), cite, left_on='paperid', right_on='citingpaperid').loc[lambda x: x['authorname']=='mirella lapata', 'citedpaperid'].nunique()"
how many papers does mirella lapata cite,"pd.merge(pd.merge(writes, author, on='authorid'), cite, left_on='paperid', right_on='citingpaperid').loc[lambda x: x['authorname']=='mirella lapata', 'citedpaperid'].nunique()"
how many papers has mirella lapata cited ?,"pd.merge(pd.merge(writes, author, on='authorid'), cite, left_on='paperid', right_on='citingpaperid').loc[lambda x: x['authorname']=='mirella lapata', 'citedpaperid'].nunique()"
when does michael stonebraker publish the first vldb paper ?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), venue, on='venueid').loc[(lambda x: (x['authorname'] == 'michael stonebraker') & (x['venuename'] == 'vldb')),['year']].drop_duplicates().sort_values('year')"
semantic parsing dataset,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
data sets for semantic parsing,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
list datasets for semantic parsing,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
datasets for semantic parsing,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
datasets with semantic parsing information,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
datasets used by semantic parsing papers,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
datasets in semantic parsing papers,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
semantic parsing datasets,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
datasets in papers about semantic parsing,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
datasets used for semantic parsing,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
large-scale datasets used in semantic parsing,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
datasets with semantic parsing,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
datasets used for evaluating semantic parsing,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
where does peter mertens publish ?,"pd.merge(pd.merge(pd.merge(author[author['authorname']=='peter mertens'], writes, on='authorid'), paper, on='paperid'), venue, on='venueid')[['journalid', 'venueid']].drop_duplicates()"
in what venues does peter mertens publish ?,"pd.merge(pd.merge(pd.merge(author[author['authorname']=='peter mertens'], writes, on='authorid'), paper, on='paperid'), venue, on='venueid')[['journalid', 'venueid']].drop_duplicates()"
where does peter mertens publish ?,"pd.merge(pd.merge(pd.merge(author[author['authorname']=='peter mertens'], writes, on='authorid'), paper, on='paperid'), venue, on='venueid')[['journalid', 'venueid']].drop_duplicates()"
how many papers appeared at nature communications last year,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
how many papers were at nature communications 2015 ?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
how many papers accepted in nature communications 2015,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
how many papers were published in nature communications in 2015 ?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
how many papers on nature communications in 2015 ?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
how many papers in nature communications 2015,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
how many papers were accepted at nature communications 2015 ?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
how many papers are presented in nature communications 2015 ?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
how many papers published in nature communications in 2015 ?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
how many papers published in nature communications 2015 ?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
how many papers were published in nature communications 2015 conference ?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
how many papers was published in nature communications in 2015,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
what was the first deep learning paper ?,"pd.merge(pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paperkeyphrase, on='paperid'), paper, on='paperid'), keyphrase, on='keyphraseid').loc[lambda x: x['keyphrasename']=='deep learning'].sort_values('year')[['datasetid', 'year']].drop_duplicates()"
what year was the first deep learning paper published ?,"pd.merge(pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paperkeyphrase, on='paperid'), paper, on='paperid'), keyphrase, on='keyphraseid').loc[lambda x: x['keyphrasename']=='deep learning'].sort_values('year')[['datasetid', 'year']].drop_duplicates()"
datasets mentioned at acl,"pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: x['venuename']=='acl', 'datasetid'].unique()"
what datasets do papers at acl use most ?,"pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: x['venuename']=='acl', 'datasetid'].unique()"
the papers on semantic parsing by li dong at acl in 2016,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(author[author['authorname']=='li dong'], writes, on='authorid'), paperkeyphrase.merge(keyphrase, on='keyphraseid'), on='paperid'), paper[paper['year']==2016], on='paperid'), venue[venue['venuename']=='acl'], on='venueid'), on='paperid')['paperid'].unique()"
how many papers were written on convolutional neural networks in the past year ?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='convolutional neural networks'].loc[lambda x:x['year']==2016, 'paperid'].nunique()"
how many papers were published on convolutional neural networks in 2016 ?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='convolutional neural networks'].loc[lambda x:x['year']==2016, 'paperid'].nunique()"
how many papers were written on convolutional neural networks in 2016 ?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='convolutional neural networks'].loc[lambda x:x['year']==2016, 'paperid'].nunique()"
how many papers were written on the convolutional neural networks this year ?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='convolutional neural networks'].loc[lambda x:x['year']==2016, 'paperid'].nunique()"
how many papers on convolutional neural networks have been published in the past year ?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='convolutional neural networks'].loc[lambda x:x['year']==2016, 'paperid'].nunique()"
what papers were written on question answering this year ?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='question answering')&(x['year']==2016), 'paperid'].unique()"
which year had the most nips papers ?,"(pd.merge(venue[venue['venuename'] == 'nips'], paper, on='venueid').groupby('year').agg(num_papers=('paperid', 'nunique')).sort_values('num_papers', ascending=false).reset_index())"
what year had the most nips papers ?,"(pd.merge(venue[venue['venuename'] == 'nips'], paper, on='venueid').groupby('year').agg(num_papers=('paperid', 'nunique')).sort_values('num_papers', ascending=false).reset_index())"
what year had the most number of nips papers ?,"(pd.merge(venue[venue['venuename'] == 'nips'], paper, on='venueid').groupby('year').agg(num_papers=('paperid', 'nunique')).sort_values('num_papers', ascending=false).reset_index())"
when were most nips papers published ?,"(pd.merge(venue[venue['venuename'] == 'nips'], paper, on='venueid').groupby('year').agg(num_papers=('paperid', 'nunique')).sort_values('num_papers', ascending=false).reset_index())"
who writes papers with noah a smith ?,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
who is a coauthor with noah a smith ?,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
who are noah a smith 's co-authors,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
who has coauthored with noah a smith ?,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
co-authors of noah a smith,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
author who wrote papers with noah a smith,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
authors who collaborated with noah a smith,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
who does noah a smith author with ?,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
who are noah a smith 's coauthors,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
who are all the co-authors of noah a smith ?,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
who does noah a smith work with ?,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
who does noah a smith collaborate with ?,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
who are noah a smith 's coauthors ?,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
coauthors of noah a smith,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
what datasets did jitendra malik use ?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), paperdataset, on='paperid').loc[lambda x: x['authorname']=='jitendra malik', 'datasetid'].unique()"
what datasets are used in papers by jitendra malik,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), paperdataset, on='paperid').loc[lambda x: x['authorname']=='jitendra malik', 'datasetid'].unique()"
what datasets did jitendra malik use in his papers ?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), paperdataset, on='paperid').loc[lambda x: x['authorname']=='jitendra malik', 'datasetid'].unique()"
what datasets were used by jitendra malik ?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), paperdataset, on='paperid').loc[lambda x: x['authorname']=='jitendra malik', 'datasetid'].unique()"
datasets used in papers written by jitendra malik ?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), paperdataset, on='paperid').loc[lambda x: x['authorname']=='jitendra malik', 'datasetid'].unique()"
datasets by jitendra malik,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), paperdataset, on='paperid').loc[lambda x: x['authorname']=='jitendra malik', 'datasetid'].unique()"
what datasets have jitendra malik used,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), paperdataset, on='paperid').loc[lambda x: x['authorname']=='jitendra malik', 'datasetid'].unique()"
recent deep learning papers,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
new deep learning papers,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
what are the latest publications on deep learning ?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
most recent deep learning conference ?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
show me some recent papers on deep learning ?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
what are some recent papers written in deep learning ?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
what is the most recent paper of deep learning ?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
what are recent papers on deep learning ?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
current research on deep learning,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
latest deep learning papers,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
newest deep learning papers,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
what years did pedro domingos publish papers in ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='pedro domingos', 'year'].drop_duplicates().groupby('year').count().reset_index()['year']"
in what years did pedro domingos publish a paper ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='pedro domingos', 'year'].drop_duplicates().groupby('year').count().reset_index()['year']"
jamie callan 's publications by year,"pd.merge(pd.merge(author[author['authorname']=='jamie callan'], writes, on='authorid'), paper, on='paperid').loc[:, ['paperid', 'year']].drop_duplicates().sort_values('year')"
how many papers does jamie callan publish each year ?,"(writes.merge(author, on='authorid').merge(paper, on='paperid').query('authorname == ""jamie callan""').groupby('year').agg(count=('paperid', 'count')).reset_index())"
number of papers by year from jamie callan,"(writes.merge(author, on='authorid').merge(paper, on='paperid').query('authorname == ""jamie callan""').groupby('year').agg(count=('paperid', 'count')).reset_index())"
how many papers jamie callan published each year ?,"(writes.merge(author, on='authorid').merge(paper, on='paperid').query('authorname == ""jamie callan""').groupby('year').agg(count=('paperid', 'count')).reset_index())"
who does oren etzioni cite,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citingpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='oren etzioni', 'paperid'].unique()"
what papers does oren etzioni cite,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citingpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='oren etzioni', 'paperid'].unique()"
papers citing daniel jurafsky,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citingpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='daniel jurafsky', 'paperid'].unique()"
what papers cite daniel jurafsky ?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citingpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='daniel jurafsky', 'paperid'].unique()"
which papers cite daniel jurafsky ?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citingpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='daniel jurafsky', 'paperid'].unique()"
citations for daniel jurafsky,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citingpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='daniel jurafsky', 'paperid'].unique()"
journal papers for instance segmentation,"pd.merge(pd.merge(keyphrase[keyphrase['keyphrasename']=='instance segmentation'], paperkeyphrase, on='keyphraseid'), paper[paper['journalid'] >= 0], on='paperid')['paperid'].unique()"
who has the most papers in semantic parsing after 2005 ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid').loc[lambda x: (x['keyphrasename']=='semantic parsing') & (x['year']>2005)].groupby('authorid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
who has written the most papers on semantic parsing since 2005 ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid').loc[lambda x: (x['keyphrasename']=='semantic parsing') & (x['year']>2005)].groupby('authorid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
who published the most in semantic parsing after 2005 ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid').loc[lambda x: (x['keyphrasename']=='semantic parsing') & (x['year']>2005)].groupby('authorid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
how many citations does dan makumbi 's genetic identity paper have ?,"pd.merge(pd.merge(pd.merge(pd.merge(author, writes), paperkeyphrase), cite), keyphrase).query('authorname == ""dan makumbi"" and keyphrasename == ""genetic identity""')['citingpaperid'].nunique()"
character recognition papers earlier than 2010,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='character recognition')&(x['year']<2010), 'paperid'].unique()"
papers before 2010 about character recognition,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='character recognition')&(x['year']<2010), 'paperid'].unique()"
character recognition papers from before 2010,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='character recognition')&(x['year']<2010), 'paperid'].unique()"
papers about character recognition from before 2010,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='character recognition')&(x['year']<2010), 'paperid'].unique()"
character recognition papers before 2010,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='character recognition')&(x['year']<2010), 'paperid'].unique()"
what topics does oren etzioni write about most ?,"(df[['paperid', 'paperpublishyear']].merge(df2, how='left', on='paperid').merge(df3, how='left', on='paperid').merge(df4, how='left', on='authorid').loc[lambda x: x['authorname']=='oren etzioni'].groupby('keyphraseid').size().reset_index(name='count').sort_values('count', ascending=false))"
how many papers related to deep learning cited the dataset imagenet ?,"pd.merge(pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid'), paperkeyphrase, on='paperid'), keyphrase, on='keyphraseid').loc[(lambda x: x['datasetname']=='imagenet') & (lambda x: x['keyphrasename']=='deep learning'), 'paperid'].nunique()"
most cited papers on parsing,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
parsing top papers,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
list top papers for parsing,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
parsing papers that have the most citations,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
what is the paper about parsing of the most citation ?,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
paper on parsing with most citations,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
parsing papers with most citations,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
most cited parsing papers,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
what are the parsing papers that have the most citations ?,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
highly cited parsing papers,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
most cited papers for parsing,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
most cited papers on parsing,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
what paper did michael armstrong wrote in the 90s ?,"pd.merge(pd.merge(author[author['authorname']=='michael armstrong'], writes, on='authorid'), paper[paper['year'].str.startswith('199')], on='paperid')[['year', 'paperid']].drop_duplicates()"
what is the most cited paper by ohad shamir ?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='ohad shamir'].groupby('citedpaperid')['citedpaperid'].agg(['count']).sort_values('count', ascending=false).reset_index()[['citedpaperid', 'count']]"
what is the highest cited paper by ohad shamir ?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='ohad shamir'].groupby('citedpaperid')['citedpaperid'].agg(['count']).sort_values('count', ascending=false).reset_index()[['citedpaperid', 'count']]"
what is the most cited paper of ohad shamir ?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='ohad shamir'].groupby('citedpaperid')['citedpaperid'].agg(['count']).sort_values('count', ascending=false).reset_index()[['citedpaperid', 'count']]"
what is ohad shamir 's highest cited paper ?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='ohad shamir'].groupby('citedpaperid')['citedpaperid'].agg(['count']).sort_values('count', ascending=false).reset_index()[['citedpaperid', 'count']]"
what paper by ohad shamir has the most citation ?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='ohad shamir'].groupby('citedpaperid')['citedpaperid'].agg(['count']).sort_values('count', ascending=false).reset_index()[['citedpaperid', 'count']]"
what is the most cited paper of ohad shamir ?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='ohad shamir'].groupby('citedpaperid')['citedpaperid'].agg(['count']).sort_values('count', ascending=false).reset_index()[['citedpaperid', 'count']]"
what is ohad shamir 's most cited paper ?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='ohad shamir'].groupby('citedpaperid')['citedpaperid'].agg(['count']).sort_values('count', ascending=false).reset_index()[['citedpaperid', 'count']]"
how many papers did michael i. jordan publish in 2016 ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').query('authorname == ""michael i. jordan"" and year == 2016')['paperid'].nunique()"
how many papers does michael i. jordan have in 2016 ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').query('authorname == ""michael i. jordan"" and year == 2016')['paperid'].nunique()"
how many papers did michael i. jordan publish in 2016,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').query('authorname == ""michael i. jordan"" and year == 2016')['paperid'].nunique()"
count of acl papers by author,"pd.merge(pd.merge(venue[venue['venuename']=='acl'], paper, on='venueid'), writes, on='paperid').groupby('authorid')['paperid'].nunique().count()"
how many acl papers by author,"pd.merge(pd.merge(venue[venue['venuename']=='acl'], paper, on='venueid'), writes, on='paperid').groupby('authorid')['paperid'].nunique().count()"
number of acl papers by author,"pd.merge(pd.merge(venue[venue['venuename']=='acl'], paper, on='venueid'), writes, on='paperid').groupby('authorid')['paperid'].nunique().count()"
who wrote the most papers for cvpr 2007,"(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').loc[lambda x: (x['year'] == 2007) & (x['venuename'] == 'cvpr')].groupby('authorid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index())"
who published papers in cvpr 2007,"(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').loc[lambda x: (x['year'] == 2007) & (x['venuename'] == 'cvpr')].groupby('authorid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index())"
who wrote the most cvpr papers in 2007,"(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').loc[lambda x: (x['year'] == 2007) & (x['venuename'] == 'cvpr')].groupby('authorid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index())"
most published author at cvpr 2007,"(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').loc[lambda x: (x['year'] == 2007) & (x['venuename'] == 'cvpr')].groupby('authorid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index())"
who published the most papers in cvpr 2007,"(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').loc[lambda x: (x['year'] == 2007) & (x['venuename'] == 'cvpr')].groupby('authorid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index())"
who published the most papers in 2007 at cvpr ?,"(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').loc[lambda x: (x['year'] == 2007) & (x['venuename'] == 'cvpr')].groupby('authorid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index())"
how many papers in acl 2015 ?,"pd.merge(venue[venue['venuename']=='acl'], paper[paper['year']==2015], on='venueid')['paperid'].nunique()"
number of papers published in acl 2015,"pd.merge(venue[venue['venuename']=='acl'], paper[paper['year']==2015], on='venueid')['paperid'].nunique()"
papers from 2014,"paper.loc[paper['year'] == 2014, 'paperid'].unique()"
2014 papers,"paper.loc[paper['year'] == 2014, 'paperid'].unique()"
what papers does richard ladner have in chi ?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname'] == 'richard ladner') & (x['venuename'] == 'chi')), 'paperid'].unique()"
what paper has richard ladner published in chi journal ?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname'] == 'richard ladner') & (x['venuename'] == 'chi')), 'paperid'].unique()"
what paper has richard ladner published in chi ?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname'] == 'richard ladner') & (x['venuename'] == 'chi')), 'paperid'].unique()"
papers by richard ladner published at chi,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname'] == 'richard ladner') & (x['venuename'] == 'chi')), 'paperid'].unique()"
does richard ladner publish in chi ?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname'] == 'richard ladner') & (x['venuename'] == 'chi')), 'paperid'].unique()"
what has richard ladner published at chi ?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname'] == 'richard ladner') & (x['venuename'] == 'chi')), 'paperid'].unique()"
what papers has richard ladner written at chi ?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname'] == 'richard ladner') & (x['venuename'] == 'chi')), 'paperid'].unique()"
which paper did richard ladner present at chi ?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname'] == 'richard ladner') & (x['venuename'] == 'chi')), 'paperid'].unique()"
what is the paper with the most citation about artificial intelligence ?,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').query('keyphrasename == ""artificial intelligence""').groupby('citedpaperid').agg(num_citations=('citingpaperid', 'count')).sort_values('num_citations', ascending=false).reset_index() [['citedpaperid', 'num_citations']])"
fetch me the most cited publications for artificial intelligence,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').query('keyphrasename == ""artificial intelligence""').groupby('citedpaperid').agg(num_citations=('citingpaperid', 'count')).sort_values('num_citations', ascending=false).reset_index() [['citedpaperid', 'num_citations']])"
topics at acl 2014,"paperkeyphrase.merge(keyphrase, on='keyphraseid').merge(paper, on='paperid').merge(venue, on='venueid').loc[lambda x: (x['year'] == 2014) & (x['venuename'] == ""acl"")].groupby('keyphraseid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false)"
most common topics at nips 2015,"paperkeyphrase.merge(keyphrase, on='keyphraseid').merge(paper, on='paperid').merge(venue, on='venueid').loc[(paper.year==2015)&(venue.venuename=='nips')].groupby('keyphraseid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
most popular topics at nips 2015,"paperkeyphrase.merge(keyphrase, on='keyphraseid').merge(paper, on='paperid').merge(venue, on='venueid').loc[(paper.year==2015)&(venue.venuename=='nips')].groupby('keyphraseid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
hot topics at nips 2015,"paperkeyphrase.merge(keyphrase, on='keyphraseid').merge(paper, on='paperid').merge(venue, on='venueid').loc[(paper.year==2015)&(venue.venuename=='nips')].groupby('keyphraseid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
popular topics at nips 2015,"paperkeyphrase.merge(keyphrase, on='keyphraseid').merge(paper, on='paperid').merge(venue, on='venueid').loc[(paper.year==2015)&(venue.venuename=='nips')].groupby('keyphraseid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
which topics were most popular at nips 2015,"paperkeyphrase.merge(keyphrase, on='keyphraseid').merge(paper, on='paperid').merge(venue, on='venueid').loc[(paper.year==2015)&(venue.venuename=='nips')].groupby('keyphraseid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
topics popular at nips 2015,"paperkeyphrase.merge(keyphrase, on='keyphraseid').merge(paper, on='paperid').merge(venue, on='venueid').loc[(paper.year==2015)&(venue.venuename=='nips')].groupby('keyphraseid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
how many papers related to deep reinforcement learning in nips ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename']=='deep reinforcement learning') & (x['venuename']=='nips'), 'paperid'].nunique()"
papers on webkb,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
which papers used webkb ?,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
papers about webkb,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
list the papers that used webkb dataset,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
papers using webkb,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
papers that use webkb,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
webkb papers,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
papers that used webkb,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
papers that use the webkb dataset,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
conferences in 2013,"paper.loc[lambda x: x['year']==2013, 'venueid'].unique()"
how is the most cited author in cvpr ?,"(pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['venuename']=='cvpr'].groupby('authorid')['citingpaperid'].nunique().sort_values(ascending=false).rename('count').reset_index())"
who is the most cited author at cvpr ?,"(pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['venuename']=='cvpr'].groupby('authorid')['citingpaperid'].nunique().sort_values(ascending=false).rename('count').reset_index())"
what are some syntactic parsing papers that chris dyer did not write ?,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']!='chris dyer')&(x['keyphrasename']=='syntactic parsing'), ['authorname', 'paperid']].drop_duplicates())[['authorname', 'paperid']]"
are there any syntactic parsing papers not written by chris dyer ?,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']!='chris dyer')&(x['keyphrasename']=='syntactic parsing'), ['authorname', 'paperid']].drop_duplicates())[['authorname', 'paperid']]"
what are syntactic parsing papers not written by chris dyer,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']!='chris dyer')&(x['keyphrasename']=='syntactic parsing'), ['authorname', 'paperid']].drop_duplicates())[['authorname', 'paperid']]"
syntactic parsing papers not written by chris dyer,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']!='chris dyer')&(x['keyphrasename']=='syntactic parsing'), ['authorname', 'paperid']].drop_duplicates())[['authorname', 'paperid']]"
papers published in the last year,"paper.loc[paper['year'] == paper['year'].max(), 'paperid'].unique()"
when was benjamin mako hill 's first publication ?,"writes.merge(author[author.authorname == ""benjamin mako hill""], on='authorid').merge(paper, on='paperid').groupby('year').agg(count=('paperid', 'count')).reset_index().sort_values('year').reset_index(drop=true)"
when was benjamin mako hill 's first paper written ?,"writes.merge(author[author.authorname == ""benjamin mako hill""], on='authorid').merge(paper, on='paperid').groupby('year').agg(count=('paperid', 'count')).reset_index().sort_values('year').reset_index(drop=true)"
when did ameet soni publish ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='ameet soni'].groupby('year').agg(num_papers=('paperid','nunique')).reset_index().sort_values('year')"
who cites daniel a reed the most,"pd.merge(pd.merge(pd.merge(writes, author, on='authorid'), cite, left_on='paperid', right_on='citedpaperid'), writes, left_on='citingpaperid', right_on='paperid').loc[lambda x: x['authorname']=='daniel a reed'].groupby('authorid').agg({'citingpaperid': 'nunique'}).sort_values('citingpaperid', ascending=false)"
who cites daniel a reed most ?,"pd.merge(pd.merge(pd.merge(writes, author, on='authorid'), cite, left_on='paperid', right_on='citedpaperid'), writes, left_on='citingpaperid', right_on='paperid').loc[lambda x: x['authorname']=='daniel a reed'].groupby('authorid').agg({'citingpaperid': 'nunique'}).sort_values('citingpaperid', ascending=false)"
how many papers are in sigir ?,"pd.merge(venue.loc[lambda x: x['venuename'] == 'sigir'], paper, on='venueid')['paperid'].nunique()"
how many papers does sigir have ?,"pd.merge(venue.loc[lambda x: x['venuename'] == 'sigir'], paper, on='venueid')['paperid'].nunique()"
how many papers are published in sigir ?,"pd.merge(venue.loc[lambda x: x['venuename'] == 'sigir'], paper, on='venueid')['paperid'].nunique()"
number of papers in sigir conference,"pd.merge(venue.loc[lambda x: x['venuename'] == 'sigir'], paper, on='venueid')['paperid'].nunique()"
what papers have fewer than 5 citations by acl papers ?,"pd.merge(pd.merge(paper, cite, how='inner', left_on='paperid', right_on='citedpaperid'), venue, how='inner', on='venueid').loc[lambda x: x['venuename'] == 'acl'].groupby('citingpaperid').filter(lambda x: x['citedpaperid'].nunique() < 5)['citingpaperid'].unique()"
acl papers with less than 5 citations,"pd.merge(pd.merge(paper, cite, how='inner', left_on='paperid', right_on='citedpaperid'), venue, how='inner', on='venueid').loc[lambda x: x['venuename'] == 'acl'].groupby('citingpaperid').filter(lambda x: x['citedpaperid'].nunique() < 5)['citingpaperid'].unique()"
what acl papers have less than 5 citations ?,"pd.merge(pd.merge(paper, cite, how='inner', left_on='paperid', right_on='citedpaperid'), venue, how='inner', on='venueid').loc[lambda x: x['venuename'] == 'acl'].groupby('citingpaperid').filter(lambda x: x['citedpaperid'].nunique() < 5)['citingpaperid'].unique()"
what papers have fewer than 5 citations by acl papers,"pd.merge(pd.merge(paper, cite, how='inner', left_on='paperid', right_on='citedpaperid'), venue, how='inner', on='venueid').loc[lambda x: x['venuename'] == 'acl'].groupby('citingpaperid').filter(lambda x: x['citedpaperid'].nunique() < 5)['citingpaperid'].unique()"
what are the 5 most recent papers of mirella lapata ?,"pd.merge(pd.merge(author[author['authorname'] == 'mirella lapata'], writes, on='authorid'), paper, on='paperid')[['paperid','year']].drop_duplicates().sort_values('year', ascending=false).head(5)"
what were the papers published at pldi 2015 ?,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
papers from pldi 2015 conference,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
papers published at pldi 2015,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
what are the papers from pldi 2015 ?,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
papers from pldi 2015 ?,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
which papers were accepted in pldi 2015 ?,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
what papers were published during the conference pldi 2015 ?,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
papers in pldi 2015,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
list of papers in pldi 2015,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
pldi papers in 2015,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
what papers are published in pldi 2015,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
papers from pldi 2015,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
pldi papers 2015,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
pldi 2015 conference,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
pldi best paper award 2015,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
pldi 2015 list of papers,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
list today 's journals,paper.loc[lambda x: x['year'] == 2011].groupby('journalid').agg({'journalid': 'nunique'}).index
"list the journals published in march , 2011",paper.loc[lambda x: x['year'] == 2011].groupby('journalid').agg({'journalid': 'nunique'}).index
acl papers in 2016 with neural attention in the title,"paper.loc[(paper['title']=='neural attention') & (paper['year']==2016) & (pd.merge(venue, paper, on='venueid').loc[lambda x: x['venuename']=='acl', 'paperid']==paper['paperid']), 'paperid'].unique()"
who writes a lot of papers in machine learning ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['keyphrasename']=='machine learning'].groupby('authorname').agg({'paperid':'nunique'}).sort_values('paperid', ascending=false).reset_index()['authorname']"
who wrote sensor fusion ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['keyphrasename']=='sensor fusion', 'authorname'].unique()"
authors of papers on sensor fusion,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['keyphrasename']=='sensor fusion', 'authorname'].unique()"
people working on sensor fusion,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['keyphrasename']=='sensor fusion', 'authorname'].unique()"
who publishes in sensor fusion ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['keyphrasename']=='sensor fusion', 'authorname'].unique()"
who publishes papers about sensor fusion,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['keyphrasename']=='sensor fusion', 'authorname'].unique()"
how many papers by dan klein are cited by michael i. jordan,"pd.merge(pd.merge(pd.merge(writes.merge(author, on='authorid'), cite.merge(writes, left_on='citedpaperid', right_on='paperid').drop('paperid', axis=1), left_on='paperid', right_on='citingpaperid'), author.rename(columns={'authorname': 'authorname_x'}), left_on='authorid', right_on='authorid'), author.rename(columns={'authorname': 'authorname_y'})).query('authorname_x == ""michael i. jordan"" and authorname_y == ""dan klein""')['citingpaperid'].nunique()"
how many of dan klein 's papers cite michael i. jordan,"pd.merge(pd.merge(pd.merge(writes.merge(author, on='authorid'), cite.merge(writes, left_on='citedpaperid', right_on='paperid').drop('paperid', axis=1), left_on='paperid', right_on='citingpaperid'), author.rename(columns={'authorname': 'authorname_x'}), left_on='authorid', right_on='authorid'), author.rename(columns={'authorname': 'authorname_y'})).query('authorname_x == ""michael i. jordan"" and authorname_y == ""dan klein""')['citingpaperid'].nunique()"
who else was on the paper with ameet soni and ras bodik ?,"pd.merge(pd.merge(pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname_x'] == 'ameet soni') & (lambda x: x['authorname_y'] == 'ras bodik'), 'authorid_x'].unique()"
2014 papers using imagenet,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[(lambda x: (x['datasetname']=='imagenet') & (x['year']==2014))(dataset), 'paperid'].unique()"
what journals are takashi matsumoto 's articles published in ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='takashi matsumoto'].groupby('journalid')['journalid'].count().reset_index()['journalid']"
what journals has takashi matsumoto published in ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='takashi matsumoto'].groupby('journalid')['journalid'].count().reset_index()['journalid']"
in what scholarly journals does takashi matsumoto publish ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='takashi matsumoto'].groupby('journalid')['journalid'].count().reset_index()['journalid']"
what authors wrote papers about bacterial wilt in 2016 ?,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['keyphrasename']=='bacterial wilt') & (lambda x: x['year']==2016), 'authorid'].unique()"
who wrote on the topic of bacterial wilt in 2016 ?,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['keyphrasename']=='bacterial wilt') & (lambda x: x['year']==2016), 'authorid'].unique()"
when did luke s zettlemoyer publish ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='luke s zettlemoyer', 'year'].sort_values().unique()"
question answering 2016 papers,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='question answering')&(x['year']==2016), 'paperid'].unique()"
what papers were written on question answering in 2016 ?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='question answering')&(x['year']==2016), 'paperid'].unique()"
what keyphrases get most citations ?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), cite, left_on='paperid', right_on='citedpaperid').groupby('keyphrasename')['citingpaperid'].nunique().reset_index().sort_values('citingpaperid', ascending=false)"
find journals about temporal data .,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='temporal data'].groupby('journalid')['journalid'].first()"
list the journals related to temporal data,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='temporal data'].groupby('journalid')['journalid'].first()"
which acl 2014 papers about parsing used jeopardy! questions ?,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paperkeyphrase, on='paperid'), paper, on='paperid'), venue, on='venueid'), keyphrase, on='keyphraseid').loc[(lambda x: x['datasetname']=='jeopardy! questions')&(lambda x: x['keyphrasename']=='parsing')&(lambda x: x['year']==2014)&(lambda x: x['venuename']=='acl'), 'paperid'].unique()"
parsing papers using jeopardy! questions published at acl 2014,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paperkeyphrase, on='paperid'), paper, on='paperid'), venue, on='venueid'), keyphrase, on='keyphraseid').loc[(lambda x: x['datasetname']=='jeopardy! questions')&(lambda x: x['keyphrasename']=='parsing')&(lambda x: x['year']==2014)&(lambda x: x['venuename']=='acl'), 'paperid'].unique()"
parsing papers from acl 2014 using jeopardy! questions,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paperkeyphrase, on='paperid'), paper, on='paperid'), venue, on='venueid'), keyphrase, on='keyphraseid').loc[(lambda x: x['datasetname']=='jeopardy! questions')&(lambda x: x['keyphrasename']=='parsing')&(lambda x: x['year']==2014)&(lambda x: x['venuename']=='acl'), 'paperid'].unique()"
parsing papers from acl 2014 that used jeopardy! questions,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paperkeyphrase, on='paperid'), paper, on='paperid'), venue, on='venueid'), keyphrase, on='keyphraseid').loc[(lambda x: x['datasetname']=='jeopardy! questions')&(lambda x: x['keyphrasename']=='parsing')&(lambda x: x['year']==2014)&(lambda x: x['venuename']=='acl'), 'paperid'].unique()"
papers about parsing that used jeopardy! questions and were published at acl 2014,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paperkeyphrase, on='paperid'), paper, on='paperid'), venue, on='venueid'), keyphrase, on='keyphraseid').loc[(lambda x: x['datasetname']=='jeopardy! questions')&(lambda x: x['keyphrasename']=='parsing')&(lambda x: x['year']==2014)&(lambda x: x['venuename']=='acl'), 'paperid'].unique()"
in what journals does linda shapiro publish ?,"pd.merge(pd.merge(pd.merge(author.loc[lambda x: x['authorname']=='linda shapiro'], writes, on='authorid'), paper, on='paperid'), journal, on='journalid')['journalid'].unique()"
which journals did linda shapiro submit papers to ?,"pd.merge(pd.merge(pd.merge(author.loc[lambda x: x['authorname']=='linda shapiro'], writes, on='authorid'), paper, on='paperid'), journal, on='journalid')['journalid'].unique()"
nips authors,"pd.merge(pd.merge(venue[venue['venuename']=='nips'], paper, on='venueid'), writes, on='paperid')['authorid'].unique()"
who are the authors at nips ?,"pd.merge(pd.merge(venue[venue['venuename']=='nips'], paper, on='venueid'), writes, on='paperid')['authorid'].unique()"
who authored papers at nips ?,"pd.merge(pd.merge(venue[venue['venuename']=='nips'], paper, on='venueid'), writes, on='paperid')['authorid'].unique()"
who publishes in nips ?,"pd.merge(pd.merge(venue[venue['venuename']=='nips'], paper, on='venueid'), writes, on='paperid')['authorid'].unique()"
who has papers at nips ?,"pd.merge(pd.merge(venue[venue['venuename']=='nips'], paper, on='venueid'), writes, on='paperid')['authorid'].unique()"
which venue publishes the most papers about deep learning,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid').merge(venue, on='venueid').groupby('venueid')['paperid'].count().sort_values(ascending=false).reset_index(name='count')"
how many publications were added to the cell journal this year ?,"pd.merge(pd.merge(paper, journal, on='journalid'), paperkeyphrase, on='paperid').loc[(paper['year']==2015) & (journal['journalname']=='cell'), 'paperid'].nunique()"
how many articles were published in the cell journal in 2015 ?,"pd.merge(pd.merge(paper, journal, on='journalid'), paperkeyphrase, on='paperid').loc[(paper['year']==2015) & (journal['journalname']=='cell'), 'paperid'].nunique()"
what are all the publication titles by donald e knuth ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='donald e knuth', 'title'].unique()"
papers published in eccv 2016 by ali farhadi,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='ali farhadi')(lambda x: x['year']==2016)(lambda x: x['venuename']=='eccv'), 'paperid'].unique()"
does ali farhadi have a paper in eccv in 2016 ?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='ali farhadi')(lambda x: x['year']==2016)(lambda x: x['venuename']=='eccv'), 'paperid'].unique()"
papers of ali farhadi in eccv 2016,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='ali farhadi')(lambda x: x['year']==2016)(lambda x: x['venuename']=='eccv'), 'paperid'].unique()"
what are some papers dealing with semantic data in yago ?,"pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paperkeyphrase, on='paperid'), keyphrase, on='keyphraseid').loc[lambda x: (x['datasetname'] == 'yago') & (x['keyphrasename'] == 'semantic data'), 'paperid'].unique()"
who has published more papers in chi ?,"(pd.merge(pd.merge(venue[venue['venuename']=='chi'], paper, on='venueid'), writes, on='paperid').groupby('authorid').agg(num_papers=('paperid', 'nunique')).sort_values('num_papers', ascending=false).reset_index() [['num_papers', 'authorid']])"
who has written the most papers at chi ?,"(pd.merge(pd.merge(venue[venue['venuename']=='chi'], paper, on='venueid'), writes, on='paperid').groupby('authorid').agg(num_papers=('paperid', 'nunique')).sort_values('num_papers', ascending=false).reset_index() [['num_papers', 'authorid']])"
how is the most prolific author in chi ?,"(pd.merge(pd.merge(venue[venue['venuename']=='chi'], paper, on='venueid'), writes, on='paperid').groupby('authorid').agg(num_papers=('paperid', 'nunique')).sort_values('num_papers', ascending=false).reset_index() [['num_papers', 'authorid']])"
who published the most at chi,"(pd.merge(pd.merge(venue[venue['venuename']=='chi'], paper, on='venueid'), writes, on='paperid').groupby('authorid').agg(num_papers=('paperid', 'nunique')).sort_values('num_papers', ascending=false).reset_index() [['num_papers', 'authorid']])"
in what year did ye cao publish the most papers,"writes.merge(author[author.authorname.str.contains('ye cao')], on='authorid').merge(paper, on='paperid').groupby('year').paperid.nunique().sort_values(ascending=false).reset_index().rename(columns={'paperid': 'count'})"
what year did ye cao publish the most papers,"writes.merge(author).merge(paper).loc[lambda x: x['authorname']=='ye cao'].groupby('year')['paperid'].nunique().reset_index().sort_values(['paperid'], ascending=false).rename(columns={'paperid': 'count'}).reset_index(drop=true)"
conferences that mention imagenet,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='imagenet', 'venueid'].unique()"
first deep learning paper,"(pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='deep learning'].groupby('year').size().reset_index()[['year']].sort_values('year'))"
what was the first paper on deep learning written ?,"(pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='deep learning'].groupby('year').size().reset_index()[['year']].sort_values('year'))"
when was deep learning proposed ?,"(pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='deep learning'].groupby('year').size().reset_index()[['year']].sort_values('year'))"
when was the first deep learning paper published ?,"(pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='deep learning'].groupby('year').size().reset_index()[['year']].sort_values('year'))"
what papers were published in academic radiology in 1995 ?,"pd.merge(paper, journal, on='journalid').loc[(paper['year']==1995) &(journal['journalname']=='academic radiology'), 'paperid'].unique()"
what papers do parsing papers typically cite ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citingpaperid').loc[lambda x: x['keyphrasename']=='parsing', 'citedpaperid'].unique()"
papers typically cited by parsing papers,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citingpaperid').loc[lambda x: x['keyphrasename']=='parsing', 'citedpaperid'].unique()"
venue for trophic cascade,"pd.merge(pd.merge(keyphrase.rename(columns={'keyphraseid':'keyphraseid_'}), paperkeyphrase, on='keyphraseid_'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='trophic cascade', 'venueid'].unique()"
conferences for trophic cascade,"pd.merge(pd.merge(keyphrase.rename(columns={'keyphraseid':'keyphraseid_'}), paperkeyphrase, on='keyphraseid_'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='trophic cascade', 'venueid'].unique()"
what conferences are related to trophic cascade,"pd.merge(pd.merge(keyphrase.rename(columns={'keyphraseid':'keyphraseid_'}), paperkeyphrase, on='keyphraseid_'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='trophic cascade', 'venueid'].unique()"
what was the conference name that approved trophic cascade ?,"pd.merge(pd.merge(keyphrase.rename(columns={'keyphraseid':'keyphraseid_'}), paperkeyphrase, on='keyphraseid_'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='trophic cascade', 'venueid'].unique()"
how many papers were written on question answering in 2011 through 2016 ?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='question answering') & (x['year']>=2011), 'paperid'].nunique()"
what are the best nlp conferences ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename'] == 'nlp'].groupby('venueid')['citingpaperid'].nunique().reset_index().sort_values('citingpaperid', ascending=false)"
acl papers by author,"pd.merge(pd.merge(venue[venue['venuename']=='acl'], paper, on='venueid'), writes, on='paperid')[['paperid', 'authorid']].drop_duplicates()"
papers with more than 10 citations,"cite.merge(paper, left_on='citedpaperid', right_on='paperid').groupby('citingpaperid').filter(lambda group: group['citedpaperid'].nunique() > 10)['citingpaperid'].unique()"
which authors published papers in 2015 ?,"pd.merge(writes, paper, on='paperid').loc[lambda x: x['year']==2015, 'authorid'].unique()"
who wrote papers in 2015,"pd.merge(writes, paper, on='paperid').loc[lambda x: x['year']==2015, 'authorid'].unique()"
what keyphrase does brian derenzi write about that gets most citations ?,"(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname'] == 'brian derenzi'].groupby('keyphrasename').agg({'numcitedby': 'sum'}).sort_values('numcitedby', ascending=false))"
main topics of work by brian derenzi,"(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname'] == 'brian derenzi'].groupby('keyphrasename').agg({'numcitedby': 'sum'}).sort_values('numcitedby', ascending=false))"
authors with at least 5 papers,"writes.merge(paper, on='paperid').groupby('authorid').filter(lambda x: len(x) >= 5)['authorid'].value_counts().reset_index().rename(columns={'index':'authorid', 'authorid':'count'}).sort_values('count')['authorid'].unique()"
papers that were not published in the last year,"paper.loc[lambda x: x['year'] != 2015, 'paperid'].unique()"
when was michael stonebraker gis database published ?,"pd.merge(pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paperkeyphrase, left_on='paperid_x', right_on='paperid'), keyphrase, on='keyphraseid'), paper, on='paperid_y').loc[lambda x: (x['authorname']=='michael stonebraker') & (x['keyphrasename']=='gis database'), 'year'].unique()"
when did michael stonebraker publish his gis database paper ?,"pd.merge(pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paperkeyphrase, left_on='paperid_x', right_on='paperid'), keyphrase, on='keyphraseid'), paper, on='paperid_y').loc[lambda x: (x['authorname']=='michael stonebraker') & (x['keyphrasename']=='gis database'), 'year'].unique()"
when does michael stonebraker publish the gis database paper ?,"pd.merge(pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paperkeyphrase, left_on='paperid_x', right_on='paperid'), keyphrase, on='keyphraseid'), paper, on='paperid_y').loc[lambda x: (x['authorname']=='michael stonebraker') & (x['keyphrasename']=='gis database'), 'year'].unique()"
in 2010 what journal published an article about trophic cascade ?,"paperkeyphrase.merge(keyphrase).merge(paper.loc[paper['year'] == 2010], how='inner').loc[lambda x: x['keyphrasename'] == 'trophic cascade'].groupby('journalid')['journalid'].first()"
what is the most popular paper this year in cvpr ?,"pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, left_on='venueid', right_on='venueid')[['citedpaperid', 'citingpaperid']].loc[lambda x: (x['year']==2016) & (x['venuename']=='cvpr')].groupby('citedpaperid').count().rename(columns={'citingpaperid': 'count'}).sort_values('count', ascending=false)"
how many citations does luke zettlemoyer have per year,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer'].groupby('year').agg({'citedpaperid': 'nunique'})"
authors working on imagenet,"pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid'), writes, on='paperid').loc[lambda x: x['datasetname']=='imagenet'].groupby('paperid')['writes'].unique().apply(lambda x: x[0])"
what articles have been published since 2006 about the effects of juicing for cancer patients ?,"paper.loc[(paper['title']=='the effects of juicing for cancer patients') & (paper['year'] > 2006), ['paperid', 'title']].drop_duplicates()"
eric c. kerrigan 's liquid automatica paper,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), paper, on='paperid'), author, on='authorid'), venue, on='venueid').loc[(lambda x: x['authorname']=='eric c. kerrigan') & (lambda x: x['keyphrasename']=='liquid') & (lambda x: x['venuename']=='automatica'), 'paperid'].unique()"
where did sergey levine publish his last paper ?,"pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='sergey levine'].groupby(['venueid', 'year']).size().reset_index(name='count').sort_values('year', ascending=false)[['venueid', 'year']]"
keyphrases used by dan klein in his emnlp papers,"paperkeyphrase.merge(paper.merge(writes.merge(author.merge(venue.loc[lambda x: x['venuename']=='emnlp'], on='venueid'), on='authorid'), on='paperid'), on='paperid')['keyphraseid'].unique()"
who are the prominent researchers in neutralizing antibody in 2012 ?,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid').loc[lambda x: (x['keyphrasename'] == 'neutralizing antibody') & (x['year'] == 2012)].groupby('authorid')['paperid'].count().reset_index(name='count').sort_values('count', ascending=false))"
the papers at eccv in 2014 using imagenet dataset,"pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid'), venue, on='venueid').loc[(lambda x: x['datasetname']=='imagenet') & (x['year']==2014) & (x['venuename']=='eccv'), 'paperid'].unique()"
which papers in eccv 2014 use imagenet ?,"pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid'), venue, on='venueid').loc[(lambda x: x['datasetname']=='imagenet') & (x['year']==2014) & (x['venuename']=='eccv'), 'paperid'].unique()"
eccv 2014 papers using imagenet,"pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid'), venue, on='venueid').loc[(lambda x: x['datasetname']=='imagenet') & (x['year']==2014) & (x['venuename']=='eccv'), 'paperid'].unique()"
euclidean distance papers citing nips papers,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), cite, left_on='paperid', right_on='citingpaperid'), paper, left_on='citedpaperid', right_on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename']=='euclidean distance') & (x['venuename']=='nips'), 'citingpaperid'].unique()"
top authors working on imagenet ?,paper_dataset.merge(dataset[dataset['datasetname'] == 'imagenet']).merge(paper).merge(writes).groupby('paperid')['paperid'].count().sort_values(ascending=false)
how many acl 2012 papers have more than 7 citations ?,"pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, on='venueid').loc[(paper['year']==2012) & (venue['venuename']=='acl')].groupby('paperid').filter(lambda x: x['citingpaperid'].nunique() > 7)['paperid'].unique()"
what was the topic of best paper in 2012 emnlp-conll ?,"(pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), paperkeyphrase, on='paperid'), venue, on='venueid').loc[(lambda x: (x['year'] == 2012) & (x['venuename'] == 'emnlp-conll'))].groupby(['paperid', 'keyphraseid']).agg(distinct_citing_papers=('citingpaperid', 'nunique')).reset_index().groupby('keyphraseid').agg(distinct_count=('distinct_citing_papers', 'nunique')).sort_values('distinct_count', ascending=false).index)"
how many papers has noah smith co-authored since 2009 ?,len(writes.loc[lambda x: (x['paperid'].isin(writes.loc[writes['authorid'].isin(author.loc[lambda y: y['authorname'].str.contains('noah smith')]['authorid'])]['paperid']))& (x['authorid'].isin(author.loc[lambda y: y['authorname'] != 'noah smith']['authorid']))& (x['paperid'].isin(paper.loc[lambda z: z['year'] > 2009]['paperid']))] ['paperid'].drop_duplicates())
number of acl papers with more than 2 citations,"(paper.merge(cite, left_on='paperid', right_on='citedpaperid').merge(venue, on='venueid').query('venuename==""acl""').groupby('citingpaperid').agg({'citedpaperid': pd.series.nunique}).query('citedpaperid > 2').reset_index().nunique())"
what is the name of eric c. kerrigan 's liquid automatica paper ?,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), paper, on='paperid'), author, on='authorid'), venue, on='venueid').loc[lambda x: (x['authorname'] == 'eric c. kerrigan') & (x['keyphrasename'] == 'liquid') & (x['venuename'] == 'automatica'), 'title'].unique()"
how many papers used imagenet datasets in cvpr ?,"pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid'), venue, on='venueid').loc[(lambda x: x['datasetname']=='imagenet') & (lambda y: y['venuename']=='cvpr'), 'paperid'].nunique()"
what venues are for neuroscience ?,"venue.loc[lambda x: x['venuename']=='neuroscience', 'venueid'].unique()"
when was the last time mary crainie published a paper ?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='mary crainie', 'year'].max()"
i want the co-authors of papers on machine translation output with philipp koehn,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author.rename(columns={'authorid': 'authorid_1'}), on='authorid_1'), writes.rename(columns={'authorid': 'authorid_2'}), on='paperid'), author, on='authorid_2'), ).loc[lambda x: (x['authorname'] == 'philipp koehn') & (x['keyphrasename'] == 'machine translation output'), 'authorid'].unique()"
how many papers does samuel madden publish outside of pvldb area ?,"(pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='samuel madden') & (lambda x: x['venuename']!='pvldb'), 'paperid'].nunique())"
which journal did donald e knuth publish his last paper ?,"pd.merge(pd.merge(author[lambda x: x['authorname']=='donald e knuth'], writes, on='authorid'), paper, on='paperid').groupby(['journalid', 'year']).ngroup().reset_index().rename(columns={0: 'group'}).groupby(['journalid', 'year']).agg({'group': 'first'}).reset_index().sort_values('year', ascending=false)['journalid', 'year']"
what is the venue of fracture of acrylic bone cement ?,"paper.loc[lambda x: x['title']=='fracture of acrylic bone cement', 'venueid'].unique()"
how many authors published at sigcse in 2010 ?,"pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').loc[(lambda x: (x['year']==2010)&(x['venuename']=='sigcse')), 'paperid'].nunique()"
"what is the year of publication of "" a switching architecture for isdn "" ?","paper.loc[paper['title'] == 'a switching architecture for isdn', ['title', 'year']].drop_duplicates()"
what keywords are used by papers at uist,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: x['venuename']=='uist', 'keyphraseid'].unique()"
give me the papers written by su-in lee before 2012 .,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[(lambda x: x['authorname']=='su-in lee') & (lambda x: x['year']<2012), 'paperid'].unique()"
papers in semantic parsing for each year,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == ""semantic parsing""], on=""keyphraseid"").merge(paper, on=""paperid"").groupby('year')['paperid'].nunique().reset_index().rename(columns={'paperid': 'count'}).sort_values('year', ascending=false)"
papers with at least 5 citations,"pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid').groupby('citingpaperid').filter(lambda x: x['citedpaperid'].nunique()>=5)['citingpaperid'].unique()"
papers cited by at least 5 papers,"pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid').groupby('citingpaperid').filter(lambda x: x['citedpaperid'].nunique()>=5)['citingpaperid'].unique()"
what is the most cited paper at sigcomm ?,"pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, on='venueid').query('venuename==""sigcomm""').groupby('citedpaperid').agg({'citingpaperid': 'count'}).sort_values('citingpaperid', ascending=false).reset_index()"
what is the name of ranjit jhala 's liquid haskell paper ?,"(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), paper, on='paperid'), author, on='authorid').loc[lambda x: x['authorname'] == 'ranjit jhala'].loc[lambda x: x['keyphrasename'] == 'liquid haskell'] ['title'].unique())"
list all the businesses with more than 4.5 stars,"business.loc[business['rating'] > 4.5, 'name']"
list all businesses with rating 3.5,"business.loc[lambda x: x['rating'] == 3.5, 'name']"
list all user ids with name michelle,"user.loc[lambda x: x['name']=='michelle', 'user_id']"
find all states in which there is a whataburger,"business.loc[lambda x: x['name']=='whataburger', 'state']"
"find all cities in which there is a restaurant called "" mgm grand buffet ""","business[business['name']=='mgm grand buffet'].merge(category[category['category_name']=='category_category_name0'], on='business_id')['city']"
find the cities of businesses rated below 1.5,"business.loc[lambda x: x['rating'] < 1.5, 'city']"
"find all cities which has a "" taj mahal "" .","business.loc[lambda x: x['name']=='taj mahal', 'city']"
list all the reviews which rated a business less than 1,"review.loc[lambda x: x['rating'] < 1, 'text']"
list all the restaurant rated more than 3.5,"business.merge(category[category['category_name'] == 'restaurant'], on='business_id').query('rating > 3.5')['name']"
"find all cities which has a "" taj mahal "" restaurant","business.merge(category, on='business_id').loc[lambda x: (x['name'] == 'taj mahal') & (x['category_name'] == 'restaurant'), 'city']"
list all the reviews by niloofar,"pd.merge(user.loc[lambda x: x['name']=='niloofar', ['user_id']], review, on='user_id')['text']"
list all the businesses which have a review by niloofar,"pd.merge(pd.merge(review, business, on='business_id'), user, on='user_id').loc[lambda x: x['name']=='niloofar', 'name']"
list all the businesses which niloofar rated 5,"pd.merge(pd.merge(review, business, on='business_id'), user, on='user_id').loc[(lambda x: x['rating']==5) & (lambda x: x['name_y']==""niloofar""), 'name_x']"
list all the reviews by michelle for italian restaurant,"(pd.merge(pd.merge(pd.merge(pd.merge(category.loc[lambda x: x['category_name']=='italian'], business, on='business_id'), category.loc[lambda x: x['category_name']=='category_category_name1'], on='business_id'), review, on='business_id'), user, on='user_id').loc[lambda x: x['name']=='michelle', 'text'])"
"find the number of reviews written for "" cafe zinho "" restaurant in texas","pd.merge(pd.merge(category, business, on='business_id'), review, on='business_id').loc[(business['name']=='cafe zinho') & (business['state']=='texas') & (category['category_name']=='restaurant'), 'text'].nunique()"
list all 5 star italian restaurant,"pd.merge(pd.merge(category.loc[lambda x: x['category_name']=='italian'], business, on='business_id'), category.loc[lambda x: x['category_name']=='restaurant'], on='business_id').loc[lambda x: x['rating']==5, 'name']"
list all the neighbourhoods with italian restaurant in madison,"pd.merge(pd.merge(pd.merge(category.loc[lambda x: x['category_name']=='italian'],business.loc[lambda x: x['city']=='madison'], on='business_id'),category.loc[lambda x: x['category_name']=='restaurant'], on='business_id'),neighbourhood, on='business_id')['neighbourhood_name']"
list all the neighbourhoods with italian restaurant rated less than 2.5 in madison,"pd.merge(pd.merge(pd.merge(category[category['category_name']=='italian'], business[(business['city']=='madison')&(business['rating']<2.5)], on='business_id'), category[category['category_name']=='restaurant'], on='business_id'), neighbourhood, on='business_id')['neighbourhood_name']"
find all the restaurant in pennsylvania,"business.merge(category.loc[lambda x: (x['category_name'] == 'restaurant') & (business['state'] == 'pennsylvania')], on='business_id')['name']"
list all businesses that are restaurant in pennsylvania .,"business.merge(category.loc[lambda x: (x['category_name'] == 'restaurant') & (business['state'] == 'pennsylvania')], on='business_id')['name']"
find all the reviews for all pet groomers with more than 100 reviews,"pd.merge(pd.merge(category, business, on='business_id'), review, on='business_id').loc[lambda x: (x['review_count'] > 100) & (x['category_name'] == 'pet groomers'), 'text']"
"what are all the breweries in "" los angeles "" ?","business.merge(category, on='business_id').loc[(business['city'] == 'los angeles') & (category['category_name'] == 'breweries'), 'name']"
find all breweries in los angeles,"business.merge(category, on='business_id').loc[(business['city'] == 'los angeles') & (category['category_name'] == 'breweries'), 'name']"
"find all breweries in "" los angeles ""","business.merge(category, on='business_id').loc[(business['city'] == 'los angeles') & (category['category_name'] == 'breweries'), 'name']"
"find all users who reviewed restaurant "" mesa grill ""","category.merge(business).merge(review).merge(user).loc[(lambda x: x['name']=='mesa grill') & (lambda x: x['category_name']=='restaurant'), 'name']"
"list the addresses of all walmart in "" los angeles ""","business.loc[(business['city']=='los angeles') & (business['name']=='walmart'), 'full_address']"
"find all restaurant reviewed by patrick in "" dallas ""","pd.merge(pd.merge(pd.merge(category, business, on='business_id'), review, on='business_id'), user, on='user_id').loc[(lambda x: x['name_x'] == 'patrick') & (lambda x: x['category_name'] == 'restaurant') & (lambda x: x['city'] == 'dallas'), 'name_y']"
which restaurant in dallas were reviewed by user patrick ?,"pd.merge(pd.merge(pd.merge(category, business, on='business_id'), review, on='business_id'), user, on='user_id').loc[(lambda x: x['name_x'] == 'patrick') & (lambda x: x['category_name'] == 'restaurant') & (lambda x: x['city'] == 'dallas'), 'name_y']"
find all bars reviewed by patrick,"pd.merge(pd.merge(pd.merge(category, business, on='business_id'), review, on='business_id'), user, on='user_id').loc[(lambda x: x['category_name'] == 'bars') & (lambda x: x['name'] == 'patrick'), 'name']"
find all bars reviewed by patrick with at least 3 stars,"pd.merge(pd.merge(pd.merge(category, business), review), user).loc[(lambda x: x['rating']>=3)(business) & (category['category_name']=='bars') & (user['name']=='patrick'), 'name']"
"find all users who have written tips for "" barrio cafe "" in 2015","pd.merge(pd.merge(tip, business[business['name']=='barrio cafe'], on='business_id'), user, on='user_id').loc[lambda x: x['year']==2015, 'name']"
find all businesses in texas with a rating below 2,"business.loc[(business['rating'] < 2) & (business['state'] == 'texas'), 'name']"
find all restaurant seafood in los angeles,"pd.merge(pd.merge(category[category['category_name']=='seafood'], business[business['city']=='los angeles'], on='business_id'), category[category['category_name']=='restaurant'], on='business_id')['name']"
"list all the seafood restaurant in "" los angeles ""","pd.merge(pd.merge(category[category['category_name']=='seafood'], business[business['city']=='los angeles'], on='business_id'), category[category['category_name']=='restaurant'], on='business_id')['name']"
"find all restaurant that serve seafood in "" los angeles ""","pd.merge(pd.merge(category[category['category_name']=='seafood'], business[business['city']=='los angeles'], on='business_id'), category[category['category_name']=='restaurant'], on='business_id')['name']"
find all reviews by patrick with a rating above 4,"review.loc[(review['rating'] > 4) & (user['name'] == 'patrick'), 'text']"
"find all apple store in "" los angeles ""","business.loc[(business['city']=='los angeles') & (business['name']=='apple store'), 'business_id']"
find all dallas restaurant with a rating above 4.5,"business.merge(category[category['category_name'] == 'restaurant'], on='business_id').loc[lambda x: (x['city'] == 'dallas') & (x['rating'] > 4.5), 'name']"
"what neighbourhood is restaurant "" flat top grill "" in ?","neighbourhood.loc[(neighbourhood['business_id'].isin(business.loc[lambda x: x['name']=='flat top grill', 'business_id'])) &(category['category_name']=='category_category_name0') &(category['business_id'].isin(business.loc[lambda x: x['name']=='flat top grill', 'business_id'])), 'neighbourhood_name']"
"find all tips about "" vintner grill "" that received more than 9 likes","tip.merge(business[business['name'] == 'vintner grill'], on='business_id').loc[lambda x: x['likes'] > 9, 'text']"
"find all reviews about "" kabob palace "" in year 2014","review.merge(business, on='business_id').loc[(lambda x: (x['name'] == 'kabob palace') & (x['year'] == 2014)), 'text']"
find all users who have written tips about businesses in dallas,"pd.merge(pd.merge(tip, business, on='business_id'), user, on='user_id').loc[lambda x: x['city']=='dallas', 'name']"
"find all cities in texas in which there is a restaurant called "" mgm grand buffet ""","business.loc[lambda x: (x['name']=='mgm grand buffet')&(x['state']=='texas')].merge(category, on='business_id').loc[lambda x: x['category_name']=='restaurant', 'city']"
find the users who have given tips on pet groomers,"pd.merge(pd.merge(pd.merge(category, business, on='business_id'), tip, on='business_id'), user, on='user_id').loc[lambda x: x['category_name']=='pet groomers', 'name_y']"
"find all tips for "" cafe zinho "" in texas .","tip.merge(business.loc[(business['name']=='cafe zinho') & (business['state']=='texas'), 'business_id'], on='business_id')['text']"
list all users who reviewed businesses that are restaurant .,"pd.merge(pd.merge(pd.merge(category, business, on='business_id'), review, on='business_id'), user, on='user_id').loc[lambda x: x['category_name']=='restaurant', 'name']"
"list all tips for "" cafe zinho "" in pennsylvania in 2010 .","tip.merge(business[business['state']=='pennsylvania'][business['name']=='cafe zinho'], on='business_id').loc[lambda x: x['year']==2010, 'text']"
list all users who reviewed businesses that are restaurant in 2010 .,"pd.merge(pd.merge(pd.merge(category.loc[lambda x: x['category_name']=='restaurant'], business, on='business_id'), review.loc[lambda x: x['year']==2010], on='business_id'), user, on='user_id')['name'].unique()"
find all the tips from a user who has written a review in 2012,"pd.merge(pd.merge(user, review, on='user_id'), tip, on='user_id').loc[lambda x: x['year']==2012, 'text']"
find all reviews for businesses rated 2.5,"pd.merge(review, business, on='business_id').loc[lambda x: x['rating']==2.5, 'text']"
find the number of escape games in madison,"business.loc[lambda x: x['city']=='madison'].merge(category.loc[lambda x: x['category_name']=='escape games'], on='business_id')['name'].nunique()"
what is the number of escape games in madison,"business.loc[lambda x: x['city']=='madison'].merge(category.loc[lambda x: x['category_name']=='escape games'], on='business_id')['name'].nunique()"
how many escape games exist in madison,"business.loc[lambda x: x['city']=='madison'].merge(category.loc[lambda x: x['category_name']=='escape games'], on='business_id')['name'].nunique()"
"what is the number of escape games in "" madison "" ?","business.loc[lambda x: x['city']=='madison'].merge(category.loc[lambda x: x['category_name']=='escape games'], on='business_id')['name'].nunique()"
how many escape games are there in madison ?,"business.loc[lambda x: x['city']=='madison'].merge(category.loc[lambda x: x['category_name']=='escape games'], on='business_id')['name'].nunique()"
find the number of restaurant rated more than 3.5,"pd.merge(category[category['category_name']=='restaurant'], business[business['rating']>3.5], on='business_id')['name'].nunique()"
"find the total checkins in moroccan restaurant in "" los angeles ""","(business.merge(category, on='business_id').merge(checkin, on='business_id').merge(category.rename(columns={'category_name': 'category_name2'}), on='business_id').loc[(lambda x: x['city'] == 'los angeles') & (x['category_name'] == 'restaurant') & (x['category_name2'] == 'moroccan')].agg({'count': 'sum'}))"
"find the total checkins in moroccan restaurant in "" los angeles "" on friday","(pd.merge(pd.merge(pd.merge(category.rename(columns={'category_name': 'category_name_2'}), business, on='business_id'), category.rename(columns={'category_name': 'category_name_3'}), on='business_id'), checkin, on='business_id').loc[lambda x: (x['city'] == 'los angeles') & (x['category_name'] == 'moroccan') & (x['category_name_2'] == 'restaurant') & (x['day'] == 'friday'), 'count'].sum())"
"find the total checkins in moroccan restaurant in "" los angeles "" per day","(checkin.merge(category.merge(business.merge(category.loc[lambda x: x['category_name']=='moroccan'], on='business_id'), on='business_id').loc[lambda x: x['city']=='los angeles'], on='business_id').loc[lambda x: x['category_name']=='restaurant'].groupby('day')['count'].sum())"
find the total checkins in italian delis in each state on sunday,"business.loc[lambda x: x['categories'].str.contains('italian'), 'business_id'].merge(category.loc[lambda x: x['category_name']=='delis'], on='business_id', suffixes=('_a', '_b')).merge(checkin.loc[lambda x: x['day']=='sunday'], on='business_id').groupby('state').agg({'count':'sum'}).reset_index()[['state', 'count']]"
how many reviews has niloofar written in 2015,"pd.merge(user.loc[lambda x: x['name']=='niloofar'], review.loc[lambda x: x['year']==2015], on='user_id')['text'].nunique()"
what is the average rating given in michelle reviews,"review.merge(user, on='user_id').loc[lambda x: x['name']=='michelle', 'rating'].mean()"
"what is the number of checkins for "" cafe zinho "" on friday","checkin.merge(business[business['name']=='cafe zinho'], on='business_id').loc[lambda x: x['day']=='friday', 'count']"
"how many users reviewed "" sushi too "" in pittsburgh","pd.merge(pd.merge(review, business, on='business_id'), user, on='user_id').loc[(lambda x: x['city']=='pittsburgh') & (lambda x: x['name']=='sushi too'), 'name'].nunique()"
what is the number of restaurant in pittsburgh rated 4.5,"business.loc[(business['city']=='pittsburgh') & (business['rating']==4.5) & (category['category_name']=='restaurant'), 'name'].nunique()"
how many tips have been written in 2015,"tip.loc[lambda x: x['year']==2015, 'text'].nunique()"
what is the total likes on tips from niloofar,"pd.merge(user[user['name']=='niloofar'], tip, on='user_id')['likes'].sum()"
"what is the total likes on tips about "" cafe zinho ""","tip.merge(business, on='business_id').loc[lambda x: x['name']=='cafe zinho', 'likes'].sum()"
"what is the total likes on tips from niloofar about "" cafe zinho ""","pd.merge(pd.merge(tip, business, on='business_id'), user, on='user_id').loc[lambda x: (x['name_x']=='cafe zinho') & (x['name_y']=='niloofar'), 'likes'].sum()"
how many tips has michelle written in 2010,"pd.merge(user[user['name'] == 'michelle'], tip[tip['year'] == 2010], on='user_id')['text'].nunique()"
return me the number of tips that are written by michelle in 2010 .,"pd.merge(user[user['name'] == 'michelle'], tip[tip['year'] == 2010], on='user_id')['text'].nunique()"
how many tips has michelle written in april,"pd.merge(user[user['name']=='michelle'], tip[tip['month']=='april'], on='user_id')['text'].nunique()"
what is the number of restaurant in texas,"pd.merge(category[category['category_name']=='restaurant'], business[business['state']=='texas'], on='business_id')['name'].nunique()"
"how many bars in "" dallas "" have a rating above 3.5 ?","(business.loc[(business['city'] == 'dallas') & (business['rating'] > 3.5)].merge(category.loc[category['category_name'] == 'bars'], on ='business_id')['name'].nunique())"
how many bars in dallas have a rating above 3.5 ?,"(business.loc[(business['city'] == 'dallas') & (business['rating'] > 3.5)].merge(category.loc[category['category_name'] == 'bars'], on ='business_id')['name'].nunique())"
"how many people reviewed the restaurant "" texas de brazil "" in dallas texas ?","business.merge(category, on='business_id').merge(review, on='business_id').merge(user, on='user_id').loc[(business['city']=='dallas') & (business['name']=='texas de brazil') & (business['state']=='texas') & (category['category_name']=='restaurant')]['name'].nunique()"
"how many people reviewed "" bistro di napoli "" in 2015 ?","pd.merge(pd.merge(review, business.loc[lambda x: x['name']=='bistro di napoli', ['business_id']], on='business_id'), user, on='user_id').loc[lambda x: (x['year']==2015), 'name'].nunique()"
how many restaurant are there in the hazelwood district of dallas ?,"pd.merge(pd.merge(category[category['category_name'] == 'restaurant'], business[business['city'] == 'dallas'], on='business_id'), neighbourhood[neighbourhood['neighbourhood_name'] == 'hazelwood'], on='business_id')['name'].nunique()"
how many starbucks are there in dallas texas ?,"business.loc[(business['city']=='dallas') & (business['name']=='starbucks') & (business['state']=='texas'), 'business_id'].nunique()"
"how many reviews does "" acacia cafe "" have ?","business.loc[lambda x: x['name']=='acacia cafe', 'review_count']"
"find the average number of checkins in restaurant "" barrio cafe "" per day","checkin.merge(category.merge(business[business['name']=='barrio cafe'].reset_index().rename(columns={'business_id':'id'}), on='id'), on='business_id').loc[lambda x: x['category_name']=='restaurant'].groupby('day')['count'].mean()"
"how many businesses are there in the "" stone meadows "" neighbourhood in madison ?",neighbourhood.merge(business)['name'].loc[(neighbourhood['neighbourhood_name']=='stone meadows') & (business['city']=='madison')].nunique()
how many reviews has adrienne written ?,"pd.merge(user[user['name']=='adrienne'], review, on='user_id')['text'].nunique()"
how many reviews has michelle written in march 2014 ?,"review.merge(user.loc[lambda x: x['name']=='michelle'], on='user_id').loc[lambda x: (x['month']=='march') & (x['year']==2014), 'text'].nunique()"
how many businesses has michelle reviewed in 2010 ?,"pd.merge(pd.merge(review, business, on='business_id'), user, on='user_id').loc[lambda x: (x['year']==2010) & (x['name_y']=='michelle'), 'name_x'].nunique()"
"how many businesses in "" san diego "" has christine reviewed in 2010 ?","review.merge(business, on='business_id').merge(user, on='user_id').loc[(business['city'] == ""san diego"") & (review['year'] == 2010 ) & (user['name'] == 'christine'), 'name'].nunique()"
"how many target are there in "" los angeles "" ?","business.loc[(business['city']=='los angeles') & (business['name']=='target'), 'business_id'].nunique()"
how many users have reviewed irish pub in dallas ?,"business.merge(category).merge(review).merge(user).loc[lambda x: (x['city']=='dallas') &(x['category_name']=='irish pub'),'name'].nunique()"
what is the average rating of reviews written in year 2014 ?,"review.loc[lambda x: x['year']==2014, 'rating'].mean()"
"how many people reviewed restaurant "" vintner grill "" in 2010 ?","(business.query('name == ""vintner grill""').merge(category.query('category_name == ""category_category_name0""'), on='business_id').merge(review.query('year == 2010'), on='business_id').merge(user, on='user_id').loc[:, 'name'].nunique())"
"find the number of reviews on businesses located in "" south summerlin "" neighbourhood","pd.merge(pd.merge(neighbourhood[neighbourhood['neighbourhood_name']=='south summerlin'], business, on='business_id'), review, on='business_id')['text'].nunique()"
find the number of users called michelle,(user['name'] == 'michelle').sum()
return me the number of businesses that are restaurant .,"business.loc[business['business_id'].isin(category.loc[category['category_name']=='restaurant', 'business_id'].tolist()), 'name'].nunique()"
"return me the number of cities that has "" panda express "" .","business.loc[lambda x: x['name']=='panda express', 'city'].nunique()"
return me the number of tips that are written by michelle .,"tip.merge(user.loc[user['name']=='michelle', 'user_id']).nunique()['text']"
"find the total checkins in "" brighton heights "" neighbourhood","pd.merge(pd.merge(checkin, business, on='business_id'), neighbourhood, on='business_id').loc[lambda x: x['neighbourhood_name']==""brighton heights"", 'count'].sum()"
find the total number of reviews written in march,"review.loc[lambda x: x['month']=='march', 'text'].nunique()"
find the number of tips written in each month,tip.groupby('month')['text'].nunique()
how many neighbourhoods have a business with rating 5 in madison ?,"pd.merge(neighbourhood, business, on='business_id').loc[(lambda x: (x['city']=='madison') & (x['rating']==5))(business), 'neighbourhood_name'].nunique()"
give me all the moroccan restaurant in texas,"(pd.merge(pd.merge(category[category['category_name']=='moroccan'], business[business['state']=='texas'], on='business_id'), category[category['category_name']=='restaurant'], on='business_id'))['name']"
which business has the most number of checkins,"checkin.merge(business, on='business_id').groupby('name').count().sort_values('count', ascending=false).head(1).index[0]"
which neighbourhood has the most number of businesses in madison,"neighbourhood.merge(business.query('city == ""madison""'), on='business_id').groupby('neighbourhood_name').agg({'name': 'nunique'}).sort_values('name', ascending=false).head(1).index[0]"
find all mexican restaurant in dallas with at least 3.5 stars,"pd.merge(pd.merge(category.loc[lambda x: x['category_name']=='mexican'], business.loc[lambda x: (x['city']=='dallas') & (x['rating']>3.5)], on='business_id'), category.loc[lambda x: x['category_name']=='restaurant'], on='business_id')['name']"
find all mexican restaurant in dallas with a rating above 3.5,"pd.merge(pd.merge(category.loc[lambda x: x['category_name']=='mexican'], business.loc[lambda x: (x['city']=='dallas') & (x['rating']>3.5)], on='business_id'), category.loc[lambda x: x['category_name']=='restaurant'], on='business_id')['name']"
find all restaurant with valet service in dallas texas,"pd.merge(pd.merge(category.loc[lambda x: x['category_name'] == 'valet service'], business), category.loc[lambda x: x['category_name'] == 'restaurant'], on='business_id').loc[lambda x: (x['city']=='dallas')&(x['state']=='texas'), 'name']"
find all italian restaurant in the meadowood neighbourhood of madison,"pd.merge(pd.merge(pd.merge(category.loc[lambda x: x['category_name']=='italian'], category.loc[lambda x: x['category_name']=='restaurant'], on='business_id'), business.loc[lambda x: x['city']=='madison'], on='business_id'), neighbourhood.loc[lambda x: x['neighbourhood_name']=='meadowood'], on='business_id')['name']"
"find all bars in "" los angeles "" with at least 30 reviews and average rating above 3 stars","pd.merge(business.loc[(business['city']=='los angeles') & (business['rating']>3) & (business['review_count']>30)], category.loc[category['category_name']=='bars'], on='business_id')['name']"
how many egyptian restaurant are there in edinburgh ?,"pd.merge(pd.merge(category[category['category_name']=='restaurant'], business[business['city']=='edinburgh'], on='business_id'), category[category['category_name']=='egyptian'], on='business_id')['name'].nunique()"
find users whose average review rating is below 3,"user.merge(review, on='user_id').groupby('name').filter(lambda x: x['rating'].mean() < 3)['name']"
find the business with the most number of reviews in april,"review.merge(business, on='business_id').loc[lambda x: x['month']=='april'].groupby('name').agg({'text': pd.series.nunique}).sort_values('text', ascending=false).reset_index().iloc[0]['name']"
find the business which has the most number of categories,"business.merge(category, on='business_id').groupby('name').agg(num_categories=('category_name', 'nunique')).sort_values('num_categories', ascending=false).reset_index().iloc[0]['name']"
return me the homepage of pvldb .,"journal.loc[lambda x: x['name']=='pvldb', 'homepage']"
"return me the homepage of "" h. v. jagadish "" .","author.loc[author['name'] == ""h. v. jagadish"", 'homepage']"
"return me the abstract of "" making database systems usable "" .","publication.loc[lambda x: x['title']=='making database systems usable', 'abstract']"
"return me the year of "" making database systems usable ""","publication.loc[lambda x: x['title']=='making database systems usable', 'year']"
"return me the year of "" making database systems usable "" .","publication.loc[lambda x: x['title']=='making database systems usable', 'year']"
return me the papers after 2000 .,"publication.loc[lambda x: x['year']>2000, 'title']"
return me the homepage of the vldb conference .,"conference.loc[lambda x: x['name']=='vldb', 'homepage']"
return me all the keywords .,keyword['keyword']
return me all the organizations .,organization['name']
"return me all the organizations in "" north america "" .","organization.loc[lambda x: x['continent']=='north america', 'name']"
"return me the homepage of "" university of michigan "" .","organization.loc[lambda x: x['name']=='university of michigan', 'homepage']"
"return me the number of references of "" making database systems usable "" .","publication.loc[lambda x: x['title']=='making database systems usable', 'reference_num']"
"return me the references of "" making database systems usable "" .","publication.loc[lambda x: x['title']=='making database systems usable', 'reference_num']"
"return me the number of citations of "" making database systems usable "" .","publication.loc[lambda x: x['title'] == 'making database systems usable', 'citation_num']"
"return me the citations of "" making database systems usable "" .","publication.loc[lambda x: x['title'] == 'making database systems usable', 'citation_num']"
return me the paper with more than 200 citations .,"publication.loc[lambda x: x['citation_num'] > 200, 'title']"
return me the authors who have papers in pvldb 2010 .,"pd.merge(pd.merge(pd.merge(publication, journal, on='jid'), writes, on='pid'), author, on='aid').loc[(lambda x: (x['name']=='pvldb') & (x['year']==2010))(journal), 'name']"
return me the authors who have papers in pvldb after 2010 .,"pd.merge(pd.merge(pd.merge(author, writes, on='aid'), publication, on='pid'), journal, on='jid').loc[lambda x: (x['name']=='pvldb') & (x['year']>2010), 'name']"
return me the authors who have papers in vldb conference in 2002 .,"publication[publication['year'] == 2002].merge(conference[conference['name'] == 'vldb'], on='cid').merge(writes, on='pid').merge(author, on='aid')['name'].unique()"
return me the authors who have papers in vldb conference before 2002 .,"pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[(lambda x: (x['name'] == 'vldb') & (x['year'] < 2002)), 'name_y']"
return me the authors who have papers in vldb conference before 2002 after 1995 .,"publication.merge(conference, left_on='cid', right_on='cid').merge(writes, left_on='pid', right_on='pid').merge(author, left_on='aid', right_on='aid').loc[(publication['year'] < 2002) & (publication['year'] > 1995) & (conference['name'] == 'vldb')]['name'].unique()"
return me the area of pvldb .,"pd.merge(pd.merge(domain, domain_journal, on='did'), journal, on='jid').loc[lambda x: x['name']=='pvldb', 'name']"
return me the authors who have papers in pvldb .,"author.loc[author['aid'].isin(writes.merge(publication, on='pid').merge(journal.query(""name=='pvldb'""), on='jid')['aid']), 'name']"
"return me the organization "" h. v. jagadish "" is in .","organization.loc[organization['oid'].isin(author.loc[author['name']==""h. v. jagadish"", 'oid']), 'name']"
"return me the conferences, which have papers by "" h. v. jagadish "" .","pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='h. v. jagadish', 'name']"
"return me the journals, which have papers by "" h. v. jagadish "" .","pd.merge(pd.merge(pd.merge(publication, journal, on='jid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='h. v. jagadish', 'name']"
"return me the domain where "" h. v. jagadish "" is focused .","pd.merge(pd.merge(domain_author, author, on='aid'), domain, on='did').loc[lambda x: x['name']=='h. v. jagadish', 'name']"
"return me the authors of "" making database systems usable "" .","pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid').loc[lambda x: x['title']=='making database systems usable', 'name']"
"return me the conference, which published "" making database systems usable "" .","conference.merge(publication[publication['title']=='making database systems usable'], on='cid')['name']"
"return me the papers by "" h. v. jagadish "" .","pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid').loc[lambda x: x['name']=='h. v. jagadish', 'title']"
return me the papers on vldb conference .,"pd.merge(publication, conference, on='cid').loc[lambda x: x['name']=='vldb', 'title']"
return me the papers on pvldb .,"pd.merge(publication, journal, on='jid').loc[lambda x: x['name']=='pvldb', 'title']"
return me the papers on pvldb after 2000 .,"pd.merge(publication, journal, on='jid').loc[lambda x: (x['name']=='pvldb') & (x['year']>2000), 'title']"
return me the papers on vldb conference after 2000 .,"pd.merge(publication, conference, on='cid').loc[(lambda x: x['name']=='vldb')(conference) & (lambda x: x['year']>2000)(publication), 'title']"
"return me the papers by "" h. v. jagadish "" on pvldb .","pd.merge(pd.merge(pd.merge(publication, journal, on='jid'), writes, on='pid'), author, on='aid').loc[(lambda x: x['name_x']=='h. v. jagadish')&(lambda x: x['name_y']=='pvldb'), 'title']"
"return me the papers by "" h. v. jagadish "" on vldb conference .","pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[lambda x: (x['name_x']=='h. v. jagadish') & (x['name_y']=='vldb'), 'title']"
"return me the papers by "" h. v. jagadish "" after 2000 .","pd.merge(pd.merge(author[author['name']=='h. v. jagadish'], writes, on='aid'), publication[publication['year']>2000], on='pid')['title']"
"return me the papers by "" h. v. jagadish "" on pvldb after 2000 .","publication.merge(journal, on='jid').merge(writes, on='pid').merge(author, on='aid').loc[(lambda x: (x.name == 'h. v. jagadish') & (x.year > 2000) & (x['name_y'] == 'pvldb')), 'title']"
"return me the papers by "" h. v. jagadish "" on vldb conference after 2000 .","pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[lambda x: (x['name_x']=='h. v. jagadish') & (x['name_y']=='vldb') & (x['year']>2000), 'title']"
return me the area of the vldb conference .,"pd.merge(pd.merge(domain_conference, conference, on='cid'), domain, on='did').loc[lambda x: x['name']=='vldb', 'name']"
return me the authors who have papers in the vldb conference .,"pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='vldb', 'name']"
return me all the keywords in databases area .,"domain_keyword.merge(keyword, on='kid').merge(domain.loc[lambda x: x['name']=='databases'], on='did')['keyword']"
"return me all the papers, which contain the keyword "" natural language "" .","publication_keyword.merge(keyword.query('keyword == ""natural language""'), on='kid').merge(publication, on='pid')['title']"
"return me the keywords of "" making database systems usable "" .","pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid').loc[lambda x: x['title']=='making database systems usable', 'keyword']"
"return me the keywords related to "" h. v. jagadish "" .","pd.merge(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='h. v. jagadish', 'keyword']"
return me the keywords in vldb conference .,"(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), conference, on='cid').loc[lambda x: x['name'] == 'vldb', 'keyword'])"
return me the keywords in pvldb .,"pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), journal, on='jid').loc[lambda x: x['name']=='pvldb', 'keyword']"
"return me the keywords in the papers of "" university of michigan "" .","pd.merge(pd.merge(pd.merge(pd.merge(organization, author, on='oid'), writes, on='aid'), publication, on='pid'), pd.merge(publication_keyword, keyword, on='kid'), on='pid').loc[lambda x: x['name']=='university of michigan', 'keyword']"
"return me the papers of "" h. v. jagadish "" containing keyword "" user study "" .","publication_keyword.merge(keyword).merge(publication).merge(writes).merge(author).query('name==""h. v. jagadish"" and keyword==""user study""')['title']"
"return me the papers in pvldb containing keyword "" keyword search "" .","pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), journal, on='jid').loc[lambda x: (x['name']=='pvldb') & (x['keyword']=='keyword search'), 'title']"
"return me the papers in vldb conference containing keyword "" information retrieval "" .","pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), conference, on='cid').loc[(lambda x: (x['name']=='vldb') & (x['keyword']=='information retrieval')), 'title']"
"return me the authors who have papers containing keyword "" relational database "" .","pd.merge(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[lambda x: x['keyword']=='relational database', 'name']"
return me all the organizations in databases area .,"pd.merge(pd.merge(pd.merge(domain_author, author, on='aid'), domain, on='did'), organization, on='oid').loc[lambda x: x['name']=='databases', 'name']"
"return me all the organizations in databases area located in "" north america "" .","pd.merge(pd.merge(pd.merge(domain_author, author, on='aid'), domain, on='did'), organization, on='oid').loc[(lambda x: x['name_x']=='databases') & (lambda x: x['continent']=='north america'), 'name_y']"
"return me all the researchers in "" university of michigan "" .","author.loc[lambda x: pd.merge(x, organization.loc[lambda y: y['name']==""university of michigan"", 'oid'], on='oid'), 'name']"
"return me all the researchers in databases area in "" university of michigan "" .","pd.merge(pd.merge(pd.merge(domain_author, domain, on='did'), author, on='aid'), organization, on='oid').loc[(lambda x: x['name_x']=='databases') & (lambda x: x['name_y']=='university of michigan'), 'name_z']"
"return me all the papers in "" university of michigan "" .","pd.merge(pd.merge(pd.merge(author, organization, on='oid'), writes, on='aid'), publication, on='pid').loc[lambda x: x['name']=='university of michigan', 'title']"
"return me all the papers after 2000 in "" university of michigan "" .","pd.merge(pd.merge(pd.merge(organization.loc[lambda x: x['name']=='university of michigan'], author, on='oid'), writes, on='aid'), publication.loc[lambda x: x['year']>2000], on='pid')['title']"
"return me all the papers in vldb conference in "" university of michigan "" .","pd.merge(pd.merge(pd.merge(pd.merge(organization.loc[lambda x: x['name']=='university of michigan'], author, on='oid'), writes, on='aid'), publication, on='pid'), conference.loc[lambda x: x['name']=='vldb'], on='cid')['title']"
"return me all the papers in pvldb in "" university of michigan "" .","pd.merge(pd.merge(pd.merge(pd.merge(organization.loc[lambda x: x['name']=='university of michigan'], author, on='oid'), writes, on='aid'), publication, on='pid'), journal, on='jid').loc[lambda x: (x['name']=='pvldb') & (x['name_y']=='university of michigan'), 'title']"
"return me all the papers in pvldb after 2000 in "" university of michigan "" .","pd.merge(pd.merge(pd.merge(pd.merge(organization, author, on='oid'), writes, on='aid'), publication, on='pid'), journal, on='jid').loc[lambda x: (x['name_x']=='university of michigan') & (x['name_y']=='pvldb') & (x['year']>2000), 'title']"
return me the paper in databases area with more than 200 citations .,"pd.merge(pd.merge(domain, domain_publication, on='did'), publication, on='pid').loc[lambda x: (x['name']=='databases')&(x['citation_num']>200), 'title']"
return me the paper in pvldb with more than 200 citations .,"pd.merge(publication, journal, on='jid').loc[lambda x: (x['name']=='pvldb') & (x['citation_num']>200), 'title']"
return me the paper in vldb conference with more than 200 citations .,"pd.merge(publication, conference).loc[lambda x: (x['name']=='vldb') & (x['citation_num']>200), 'title']"
"return me the paper by "" h. v. jagadish "" with more than 200 citations .","pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid').loc[(lambda x: x['name']=='h. v. jagadish')(author) & (lambda x: x['citation_num']>200)(publication), 'title']"
"return me the papers by "" h. v. jagadish "" on pvldb with more than 200 citations .","pd.merge(pd.merge(pd.merge(publication, journal, on='jid'), writes, on='pid'), author, on='aid').loc[lambda x: (x['name']=='h. v. jagadish') & (x['citation_num']>200) & (x['name_y']=='pvldb'), 'title']"
"return me the papers by "" h. v. jagadish "" on vldb conference with more than 200 citations .","pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[(lambda x: x['name_x']=='h. v. jagadish') & (lambda x: x['name_y']=='vldb') & (lambda x: x['citation_num']>200), 'title']"
return me the paper after 2000 with more than 200 citations .,"publication.loc[(publication['citation_num']>200) & (publication['year']>2000), 'title']"
return me the paper after 2000 in databases area with more than 200 citations .,"pd.merge(pd.merge(domain, domain_publication, on='did'), publication, on='pid').loc[lambda x: (x['name']=='databases') & (x['citation_num']>200) & (x['year']>2000), 'title']"
return me the paper after 2000 in pvldb with more than 200 citations .,"publication.merge(journal[journal['name']=='pvldb'], on='jid').query('citation_num > 200 & year > 2000')['title']"
return me the paper after 2000 in vldb conference with more than 200 citations .,"pd.merge(publication, conference, on='cid').loc[(lambda x: x['name']=='vldb') & (x['citation_num']>200) & (x['year']>2000)].title"
"return me the number of conferences which have papers by "" h. v. jagadish "" .","pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='h. v. jagadish', 'name'].nunique()"
"return me the number of journals which have papers by "" h. v. jagadish "" .","publication.merge(journal, on='jid').merge(writes, on='pid').merge(author, on='aid').loc[lambda x: x['name']=='h. v. jagadish', 'name'].nunique()"
"return me the number of papers written by "" h. v. jagadish "" in each year .","pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid').loc[lambda x: x['name']=='h. v. jagadish'].groupby('year')['title'].nunique()"
"return me the number of authors of "" making database systems usable "" .","pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid').loc[lambda x: x['title']=='making database systems usable', 'name'].nunique()"
"return me the number of citations of "" making database systems usable "" in each year .",publication.loc[lambda x: x['title'] == 'making database systems usable'].groupby('year').agg({'citation_num': 'sum'})
"return me the number of citations of "" making database systems usable "" before 2010 .","pd.merge(pd.merge(publication, cite, left_on='pid', right_on='cited')['citing'], publication, on='pid').loc[lambda x: (x['title_x']=='making database systems usable') & (x['year_y']<2010), 'title_y'].nunique()"
"return me the number of papers by "" h. v. jagadish "" .","pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid').loc[lambda x: x['name']=='h. v. jagadish', 'title'].nunique()"
return me the number of papers on vldb conference .,"pd.merge(publication, conference, on='cid').loc[lambda x: x['name']=='vldb', 'title'].nunique()"
return me the number of papers on pvldb .,"pd.merge(publication, journal, on='jid').loc[lambda x: x['name']=='pvldb', 'title'].nunique()"
return me the number of papers after 2000 .,"publication.loc[lambda x: x['year'] > 2000, 'title'].nunique()"
return me the number of papers on pvldb after 2000 .,"pd.merge(journal[journal['name']=='pvldb'], publication[publication['year']>2000], on='jid')['title'].nunique()"
return me the number of papers on vldb conference after 2000 .,"pd.merge(publication.loc[lambda x: x['year']>2000], conference.loc[lambda x: x['name']=='vldb'], on='cid')['title'].nunique()"
"return me the number of papers by "" h. v. jagadish "" on pvldb .","pd.merge(pd.merge(pd.merge(author, writes, on='aid'), publication, on='pid'), journal, on='jid').loc[(lambda x: (x['name_x']=='h. v. jagadish') & (x['name_y']=='pvldb')), 'title'].nunique()"
"return me the number of papers by "" h. v. jagadish "" on vldb conference .","pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[lambda x: (x['name_x']=='h. v. jagadish') & (x['name_y']=='vldb'), 'title'].nunique()"
"return me the number of papers by "" h. v. jagadish "" after 2000 .","pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid').loc[(lambda x: (x['name']=='h. v. jagadish') & (x['year']>2000)), 'title'].nunique()"
"return me the number of papers by "" h. v. jagadish "" on pvldb after 2000 .","pd.merge(pd.merge(pd.merge(publication, journal, on='jid'), writes, on='pid'), author, on='aid').loc[lambda x: (x['name']=='h. v. jagadish') & (x['year']>2000) & (x['name_y']=='pvldb'), 'title'].nunique()"
"return me the number of papers by "" h. v. jagadish "" on vldb conference after 2000 .","pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[(lambda x: (x['name_x'] == 'h. v. jagadish') & (x['name_y'] == 'vldb') & (x['year'] > 2000)), 'title'].nunique()"
return me the number of keywords .,keyword['keyword'].nunique()
return me the number of keywords in databases area .,"pd.merge(pd.merge(domain, domain_keyword, on='did'), keyword, on='kid').loc[lambda x: x['name']=='databases', 'keyword'].nunique()"
"return me the number of papers which contain the keyword "" natural language "" .","publication_keyword.merge(keyword).merge(publication)[lambda x: x['keyword'] == ""natural language""]['title'].nunique()"
"return me the number of the keywords of "" making database systems usable "" .","pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid').loc[lambda x: x['title']=='making database systems usable', 'keyword'].nunique()"
"return me the number of the keywords related to "" h. v. jagadish "" .","pd.merge(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='h. v. jagadish', 'keyword'].nunique()"
return me the number of keywords in vldb conference .,"pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), conference, on='cid').loc[lambda x: x['name']=='vldb', 'keyword'].nunique()"
return me the number of keywords in pvldb .,"pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), journal, on='jid').loc[lambda x: x['name']=='pvldb', 'keyword'].nunique()"
"return me the number of keywords in the papers of "" university of michigan "" .","pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(organization, author, on='oid'), writes, on='aid'), publication, on='pid'), publication_keyword, on='pid'), keyword, on='kid').loc[lambda x: x['name']=='university of michigan', 'keyword'].nunique()"
"return me the number of the papers of "" h. v. jagadish "" containing keyword "" user study "" .","pd.merge(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[(lambda x: x['name']=='h. v. jagadish') & (lambda x: x['keyword']=='user study'), 'title'].nunique()"
"return me the number of papers in pvldb containing keyword "" keyword search "" .","len(publication_keyword.merge(keyword).merge(publication).merge(journal.loc[lambda x: x['name']=='pvldb'], on='jid').loc[lambda x: x['keyword']=='keyword search', 'title'].unique())"
"return me the number of papers in vldb conference containing keyword "" information retrieval "" .","(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'),publication, on='pid'),conference, on='cid').loc[lambda x: x['name']=='vldb' and x['keyword']=='information retrieval', 'title'].nunique())"
"return me the number of authors who have papers containing keyword "" relational database "" .","pd.merge(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[lambda x: x['keyword'] == 'relational database', 'name'].nunique()"
"return me the total citations of the papers containing keyword "" natural language ""","pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid').loc[lambda x: x['keyword']=='natural language', 'citation_num'].sum()"
return me the number of the organizations .,organization['name'].nunique()
"return me the number of the organizations in "" north america "" .","organization.loc[lambda x: x['continent']=='north america', 'name'].nunique()"
return me the number of organizations in databases area .,"(pd.merge(pd.merge(pd.merge(domain_author, author, on='aid'), domain, on='did'), organization, on='oid').loc[lambda x: x['name']=='databases', 'name'].nunique())"
"return me the number of organizations in databases area located in "" north america "" .","pd.merge(pd.merge(pd.merge(domain_author, author, on='aid'), domain, on='did'), organization, on='oid').loc[lambda x: (x['name']=='databases') & (x['continent']=='north america'), 'name'].nunique()"
"return me the number of papers in "" university of michigan "" .","pd.merge(pd.merge(pd.merge(organization, author, on='oid'), writes, on='aid'), publication, on='pid').loc[lambda x: x['name']=='university of michigan', 'title'].nunique()"
"return me the number of papers in "" university of michigan "" in databases area .","pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(domain_author, author, on='aid'), domain, on='did'), domain_publication, on='did'), organization, on='oid'), publication, on='pid').loc[lambda x: (x['name_x']=='databases') & (x['name_y']=='university of michigan'), 'title'].nunique()"
"return me the number of papers after 2000 in "" university of michigan "" .","pd.merge(pd.merge(pd.merge(organization.query('name == ""university of michigan""'), author, on='oid'), writes, on='aid'), publication, on='pid').loc[lambda x: x['year'] > 2000, 'title'].nunique()"
"return me the number of papers in vldb conference in "" university of michigan "" .","pd.merge(pd.merge(pd.merge(pd.merge(organization, author, on='oid'), writes, on='aid'), publication, on='pid'), conference, on='cid').loc[(lambda x: (x['name_x'] == 'university of michigan') & (x['name_y'] == 'vldb')), 'title'].nunique()"
"return me the number of papers in pvldb in "" university of michigan "" .","len(pd.merge(pd.merge(pd.merge(pd.merge(organization, author, on='oid'), writes, on='aid'), publication, on='pid'), journal, on='jid').loc[(lambda x: x['name_x']=='university of michigan') & (lambda x: x['name_y']=='pvldb'), 'title'].unique())"
"return me the number of papers in pvldb after 2000 in "" university of michigan "" .","pd.merge(pd.merge(pd.merge(pd.merge(organization.rename(columns={'oid':'oid_x', 'name':'name_x'}), author, on='oid_x'), writes, on='aid'), publication, on='pid'), journal, on='jid').loc[lambda x: (x['name']=='pvldb') & (x['name_x']=='university of michigan') & (x['year']>2000), 'title'].nunique()"
"return me the total citations of the papers in "" university of michigan "" .","pd.merge(pd.merge(pd.merge(organization, author, on='oid'), writes, on='aid'), publication, on='pid').loc[lambda x: x['name']=='university of michigan', 'citation_num'].sum()"
"return me the number of researchers in "" university of michigan "" .","pd.merge(organization.loc[lambda x: x['name']=='university of michigan'], author, on='oid')['name'].nunique()"
"return me the number of researchers in databases area in "" university of michigan "" .","pd.merge(pd.merge(pd.merge(domain_author, author, on='aid'), domain, on='did'), organization, on='oid').loc[(lambda x: (x['name_x']=='databases') & (x['name_y']=='university of michigan')), 'name'].nunique()"
return me the number of authors who have papers in pvldb .,"pd.merge(pd.merge(pd.merge(publication, journal[journal['name']=='pvldb'], on='jid'), writes, on='pid'), author, on='aid')['name'].nunique()"
return me the number of authors who have papers in the vldb conference .,"pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='vldb', 'name'].nunique()"
return me the number of papers published on pvldb before 2000 .,"pd.merge(journal.loc[lambda x: x['name']=='pvldb'], publication.loc[lambda x: x['year']<2000], on='jid')['title'].nunique()"
return me the number of papers published in the vldb conference before 2000 .,"pd.merge(publication[publication['year']<2000], conference[conference['name']=='vldb'], on='cid')['title'].nunique()"
return me the total citations of all the papers in pvldb .,"pd.merge(publication, journal, on='jid').loc[lambda x: x['name']=='pvldb', 'citation_num'].sum()"
return me the citations of each paper in pvldb .,"pd.merge(journal[journal['name']=='pvldb'], publication, on='jid')['citation_num']"
return me the total citations of papers in pvldb in 2005 .,"pd.merge(publication, journal, on='jid').loc[(lambda x: x['name']==""pvldb"")&(lambda x: x['year']==2005), 'citation_num'].sum()"
return me the total citations of papers in pvldb before 2005 .,"pd.merge(publication[publication['year'] < 2005], journal[journal['name'] == 'pvldb'], on='jid').citation_num.sum()"
return me the total citations of papers in pvldb in each year .,"pd.merge(publication, journal, on='jid').loc[lambda x: x['name']=='pvldb'].groupby('year')['citation_num'].sum()"
return me the number of papers published in pvldb in each year .,publication.merge(journal).loc[lambda x: x['name']=='pvldb'].groupby('year')['title'].nunique()
return me the total citations of all the papers in the vldb conference .,"pd.merge(publication, conference, on='cid').loc[lambda x: x['name']=='vldb', 'citation_num'].sum()"
return me the citations of each paper in the vldb conference .,"pd.merge(publication, conference, on='cid').loc[lambda x: x['name']=='vldb', 'citation_num']"
return me the total citations of papers in the vldb conference in 2005 .,"pd.merge(publication, conference, on='cid').loc[(publication['year']==2005) & (conference['name']=='vldb'), 'citation_num'].sum()"
return me the total citations of papers in the vldb conference before 2005 .,"pd.merge(publication.loc[lambda x: x['year']<2005], conference.loc[lambda x: x['name']=='vldb'], on='cid')['citation_num'].sum()"
return me the total citations of papers in the vldb conference in each year .,"pd.merge(publication, conference, on='cid').loc[lambda x: x['name']=='vldb'].groupby('year')['citation_num'].sum()"
return me the number of papers published in the vldb conference in each year .,"pd.merge(publication, conference, on='cid').loc[lambda x: x['name']=='vldb'].groupby('year')['title'].nunique()"
"return me the authors who have cooperated both with "" h. v. jagadish "" and "" divesh srivastava "" .","pd.merge(pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[(lambda x: x['name_x']=='h. v. jagadish')(lambda x: x['name_y']=='divesh srivastava')]['name_y']"
"return me the authors who have cooperated with "" h. v. jagadish "" after 2000 .","pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), pd.merge(writes, author, on='aid'), on='pid').loc[lambda x: (x['name_x']=='h. v. jagadish') & (x['year']>2000), 'name_y']"
"return me the papers written by "" h. v. jagadish "" and "" divesh srivastava "" .","pd.merge(pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[(lambda x: x['name_x']=='h. v. jagadish') & (lambda x: x['name_y']=='divesh srivastava'), 'title']"
"return me the papers written by "" h. v. jagadish "" and "" yunyao li "" after 2005 .","pd.merge(pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[(lambda x: x['name_x'] == 'h. v. jagadish' and x['name_y'] == 'yunyao li' and x['year'] > 2005), 'title']"
"return me the papers written by "" h. v. jagadish "" and "" yunyao li "" on pvldb .","pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(publication, journal, on='jid'), writes, on='pid'), writes, on='pid'), author, left_on='aid_x', right_on='aid'), author, left_on='aid_y', right_on='aid').loc[(lambda x: x['name_x']=='yunyao li') & (lambda x: x['name_y']=='h. v. jagadish') & (lambda x: x['name']=='pvldb'), 'title']"
"return me the papers written by "" h. v. jagadish "" and "" yunyao li "" on pvldb after 2005 .","pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(publication, journal, on='jid'), writes, on='pid'), writes, on='pid'), author, left_on='aid_y', right_on='aid'), author, left_on='aid_x', right_on='aid').loc[(lambda x: (x['name_x']=='yunyao li') & (x['name_y']=='h. v. jagadish') & (x['name']=='pvldb') & (x['year'] > 2005))]"
"return me the authors who have cooperated with "" h. v. jagadish "" .","pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), pd.merge(writes, author, on='aid', suffixes=('_1','_2')), on='pid').loc[lambda x: x['name_1']=='h. v. jagadish', 'name_2']"
"return me the papers written by "" h. v. jagadish "" and "" divesh srivastava "" before 2000 .","pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), pd.merge(writes, author, on='aid'), on='pid').loc[(lambda x: x['name_x']=='h. v. jagadish')&(lambda x: x['name_y']=='divesh srivastava')&(lambda x: x['year']<2000), 'title']"
"return me the authors who have cited the papers by "" h. v. jagadish "" .","pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(publication, cite,left_on='pid', right_on='citing'), publication,left_on='cited', right_on='pid',suffixes=['_citing', '_cited']), writes,on='pid', suffixes=['_citing', '_writter']), writes,on='pid', suffixes=['_cited', '_writter']), author,left_on='aid_citing', right_on='aid').loc[lambda x: x['name'] == 'h. v. jagadish', 'name']"
"return me the number of papers written by "" h. v. jagadish "" and "" divesh srivastava "" .","pd.merge(pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[(lambda x: x['name_x']=='h. v. jagadish')&(lambda x: x['name_y']=='divesh srivastava'), 'title'].nunique()"
"return me the number of papers written by "" h. v. jagadish "" and "" divesh srivastava "" before 2000 .","pd.merge(pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[(lambda x: (x['name_x']=='h. v. jagadish') & (x['name_y']=='divesh srivastava') & (x['year']<2000)), 'title'].nunique()"
"return me the number of papers written by "" h. v. jagadish "" , "" yunyao li "" , and "" cong yu "" .","(author.loc[author['name']=='cong yu', 'aid'].pipe(lambda x: writes.loc[writes['aid'].isin(x), 'pid']).pipe(lambda x: publication.loc[publication['pid'].isin(x), 'pid']).pipe(lambda x: writes.loc[writes['pid'].isin(x), 'aid']).loc[lambda x: x.isin(author.loc[author['name'].isin([""h. v. jagadish"", ""yunyao li""]), 'aid'])].pipe(lambda x: writes.loc[writes['aid'].isin(x), 'pid']).pipe(lambda x: publication.loc[publication['pid'].isin(x), 'title']).nunique())"
"return me the number of authors who have cooperated with "" h. v. jagadish "" .","pd.merge(pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name_y']=='h. v. jagadish', 'name_x'].nunique()"
"return me the number of authors who have cited the papers by "" h. v. jagadish "" .","publication.merge(cite, left_on='pid', right_on='citing').merge(publication, left_on='cited', right_on='pid').merge(writes, on='pid').merge(writes, suffixes=('_left', '_right'), on='pid').merge(author, left_on='aid_left', right_on='aid').merge(author, left_on='aid_right', right_on='aid').loc[lambda x: x['name_y'] == 'h. v. jagadish']['name_x'].nunique()"
"return me the papers written by "" h. v. jagadish "" and "" divesh srivastava "" with more than 200 citations .","(pd.merge(pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), writes, on='pid'), author, on='aid').query('name_x == ""h. v. jagadish"" and name_y == ""divesh srivastava"" and citation_num > 200').loc[:, 'title'])"
"return me the author who has the most number of papers containing keyword "" relational database "" .","author.loc[pd.merge(writes, publication_keyword).merge(keyword.loc[lambda x: x['keyword']=='relational database'], left_on='kid', right_on='kid').merge(publication, on='pid').groupby('name')['title'].nunique().nlargest(1).index[0]]"
"return me the conference that has the most number of papers containing keyword "" relational database "" .","(pd.merge(pd.merge(pd.merge(publication_keyword, keyword.loc[lambda x: x['keyword']=='relational database'], on='kid'), publication, on='pid'), conference, on='cid').groupby('name')['title'].nunique().sort_values(ascending=false).index[0])"
"return me the conference, which has the most number of papers containing keyword "" relational database "" .","(pd.merge(pd.merge(pd.merge(publication_keyword, keyword.loc[lambda x: x['keyword']=='relational database'], on='kid'), publication, on='pid'), conference, on='cid').groupby('name')['title'].nunique().sort_values(ascending=false).index[0])"
"return me the journal that has the most number of papers containing keyword "" relational database "" .","journal.loc[pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), journal, on='jid').loc[lambda x: x['keyword'] == 'relational database'].groupby('name').agg(unique_titles=('title', 'nunique')).sort_values('unique_titles', ascending=false).reset_index().iloc[0]['name']]"
"return me the journal, which has the most number of papers containing keyword "" relational database "" .","journal.loc[pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), journal, on='jid').loc[lambda x: x['keyword'] == 'relational database'].groupby('name').agg(unique_titles=('title', 'nunique')).sort_values('unique_titles', ascending=false).reset_index().iloc[0]['name']]"
"return me the keyword, which have been contained by the most number of papers in vldb conference .","publication_keyword.merge(keyword, on='kid').merge(publication, on='pid').merge(conference, on='cid').loc[lambda x: x['name'] == 'vldb'].groupby('keyword')['title'].nunique().sort_values(ascending=false).index[0]"
"return me the keyword, which have been contained by the most number of papers in pvldb .","pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), journal, on='jid').loc[lambda x: x['name']=='pvldb'].groupby('keyword')['title'].nunique().sort_values(ascending=false).index[0]"
"return me the keyword, which have been contained by the most number of papers by "" h. v. jagadish "" .","pd.merge(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='h. v. jagadish'].groupby('keyword').agg(num_titles=('title', pd.series.nunique)).sort_values('num_titles', ascending=false).iloc[0].name"
"return me the author in the "" university of michigan "" whose papers have the most total citations .","(pd.merge(pd.merge(pd.merge(author, writes, on='aid'),publication,on='pid'),organization,on='oid').query('name_x == ""university of michigan""').groupby('name_y').agg(total_citations=('citation_num', 'sum')).reset_index().sort_values('total_citations', ascending=false).iloc[0][0])"
"return me the author in the "" university of michigan "" whose papers in databases area have the most total citations .","author.merge(writes.merge(publication.merge(domain_publication.merge(domain), on='did'), on='pid'), on='aid').merge(organization, on='oid').loc[lambda x: (x['name_x'] == 'databases') & (x['name_y'] == 'university of michigan')].groupby('name')['citation_num'].sum().sort_values(ascending=false).head(1)"
"return me the papers written by "" h. v. jagadish "" and "" divesh srivastava "" with the most number of citations .","pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), pd.merge(writes, author, on='aid')).loc[(lambda x: x['name_x']=='divesh srivastava')&(lambda x: x['name_y']=='h. v. jagadish'), 'title'].sort_values('citation_num', ascending=false).iloc[0]"
"return me the conferences, which have more than 10 papers by "" h. v. jagadish "" .","author.query('name == ""h. v. jagadish""').merge(writes, on='aid').merge(publication, on='pid').merge(conference, on='cid').groupby('name').filter(lambda x: x['title'].nunique() > 10)['name']"
"return me the conference, which have the most number of papers by "" h. v. jagadish "" .","author.loc[lambda x: x['name']=='h. v. jagadish'].groupby(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid')['name_x']).agg({'title': 'nunique'}).sort_values('title', ascending=false).reset_index().iloc[0, 0]"
"return me the journals, which have more than 10 papers by "" h. v. jagadish "" .","pd.merge(pd.merge(pd.merge(publication, journal, on='jid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='h. v. jagadish'].groupby('name').filter(lambda x: x.groupby('name').apply(lambda x: x['title'].nunique())).groupby('name')['name'].count() > 10"
"return me the journal, which have the most number of papers by "" h. v. jagadish "" .","pd.merge(pd.merge(pd.merge(publication, writes, on='pid'),pd.merge(journal, publication, on='jid'),on='pid'),pd.merge(author, writes, on='aid'),on='aid').loc[lambda x: x['name']=='h. v. jagadish'].groupby('name')['name'].count().sort_values(ascending=false).head(1)"
return me the paper with the most citations .,"publication.sort_values('citation_num', ascending=false).iloc[0]['title']"
return me the paper in databases area with the most citations .,"pd.merge(pd.merge(domain, domain_publication, on='did'), publication, on='pid').loc[lambda x: x['name']=='databases'].sort_values('citation_num', ascending=false).iloc[0]['title']"
return me the paper in pvldb with the most citations .,"publication.merge(journal[journal['name']=='pvldb'], on='jid').sort_values('citation_num', ascending=false)['title'].iloc[0]"
return me the paper in vldb conference with the most citations .,"pd.merge(publication, conference, on='cid').loc[lambda x: x['name']=='vldb'].sort_values('citation_num', ascending=false).iloc[0]['title']"
"return me the paper by "" h. v. jagadish "" with the most citations .","author.loc[lambda x: x['name']=='h. v. jagadish'].merge(writes, on='aid').merge(publication, on='pid').sort_values('citation_num', ascending=false).iloc[0]['title']"
return me the paper after 2000 with the most citations .,"publication.loc[lambda x: x['year']>2000].sort_values('citation_num', ascending=false).iloc[0]['title']"
return me the paper after 2000 in databases area with the most citations .,"pd.merge(pd.merge(domain, domain_publication, on='did'), publication, on='pid').loc[(domain['name'] == ""databases"") & (publication['year'] > 2000)].nlargest(1, 'citation_num')['title']"
return me the paper after 2000 in pvldb with the most citations .,"publication.merge(journal[journal['name']=='pvldb'], on='jid').loc[lambda x: x['year'] > 2000].sort_values('citation_num', ascending=false).iloc[0]['title']"
return me the paper after 2000 in vldb conference with the most citations .,"pd.merge(publication, conference, on='cid').loc[(lambda x: x['name']=='vldb')&(lambda x: x['year']>2000), 'title'].sort_values(ascending=false).iloc[0]"
return me the authors who have more than 10 papers in pvldb .,"author.loc[pd.merge(pd.merge(pd.merge(publication, journal[journal['name'] == 'pvldb'], on='jid'), writes, on='pid'), author, on='aid').groupby('name').filter(lambda x: x['title'].nunique() > 10)['aid'].drop_duplicates()]"
return me the authors who have the most number of papers in pvldb .,"(author.merge(writes, on='aid').merge(publication, on='pid').merge(journal.loc[lambda x: x['name']=='pvldb'], on='jid').groupby('name')['title'].nunique().sort_values(ascending=false).index[0])"
"return me the authors who have more than 10 papers containing keyword "" relational database "" .","pd.merge(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[lambda x: x['keyword']=='relational database'].groupby('name').filter(lambda x: x['title'].nunique() > 10).sort_values('name')['name']"
"return me the conferences, which have more than 60 papers containing keyword "" relational database "" .","pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), conference, on='cid').loc[lambda x: x['keyword']=='relational database'].groupby('name').filter(lambda x: x['title'].nunique() > 60)['name']"
"return me the journals, which have more than 60 papers containing keyword "" relational database "" .","pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), journal, on='jid').loc[lambda x: x['keyword']=='relational database'].groupby('name').filter(lambda x: x['title'].nunique() > 60).drop_duplicates('name')[['name']]"
"return me the keywords, which have been contained by more than 100 papers in vldb conference .","pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), conference, on='cid').loc[lambda x: x['name']=='vldb'].groupby('keyword').filter(lambda x: x['title'].nunique() > 100)['keyword'].unique()"
"return me the keywords, which have been contained by more than 100 papers in pvldb .","pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), journal, on='jid').loc[lambda x: x['name']=='pvldb'].groupby('keyword').filter(lambda x: x['title'].nunique() > 100)['keyword']"
"return me the keywords, which have been contained by more than 10 papers of "" h. v. jagadish "" .","pd.merge(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='h. v. jagadish'].groupby('keyword').filter(lambda x: x['title'].nunique() > 10)['keyword'].unique()"
return me the authors who have more than 10 papers in the vldb conference .,"author.loc[lambda x: x['aid'].isin(writes.merge(publication).loc[lambda y: y['cid'].isin(conference.loc[lambda z: z['name']=='vldb', 'cid'])]['aid'].unique())].groupby('name').apply(lambda x: x.merge(writes.merge(publication))).loc[lambda x: x['title'].nunique()>10, 'name']"
return me the author who has the most number of papers in the vldb conference .,"pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='vldb'].groupby('name')['name'].count().sort_values(ascending=false).index[0]"
"return me the author in the "" university of michigan "" whose papers have more than 5000 total citations .","author.merge(writes).merge(publication).merge(organization).query('name == ""university of michigan""').groupby('name').filter(lambda x: x['citation_num'].sum() > 5000)['name']"
"return me the author in the "" university of michigan "" in databases area whose papers have more than 5000 total citations .","(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(domain_author, author, on='aid'), domain, on='did'), organization, on=['oid', 'aid']), writes, on='aid'), publication, on='pid').loc[(lambda x: x['name_x']=='databases')&(lambda x: x['name_y']=='university of michigan'), 'name'].groupby('name').agg(citation_sum=('citation_num', 'sum')).loc[lambda x: x['citation_sum']>5000].reset_index()['name'])"
"what year is the movie "" the imitation game "" from ?","movie.loc[movie['title'] == 'the imitation game', 'release_year']"
"what year was the movie "" the imitation game "" produced","movie.loc[movie['title'] == 'the imitation game', 'release_year']"
"what year was "" benedict cumberbatch "" born ?","actor.loc[lambda x: x['name']=='benedict cumberbatch', 'birth_year']"
"in what year was "" benedict cumberbatch "" born","actor.loc[lambda x: x['name']=='benedict cumberbatch', 'birth_year']"
"what is the nationality of the actress "" christoph waltz "" ?","actor.loc[actor['name'] == 'christoph waltz', 'nationality']"
"what is the nationality of the actor "" christoph waltz "" ?","actor.loc[actor['name'] == 'christoph waltz', 'nationality']"
find all movies produced in 2015,"movie.loc[movie['release_year']==2015, 'title']"
"find all actors born in "" tehran ""","actor.loc[lambda x: x['birth_city']=='tehran', 'name']"
find all actors born in tehran,"actor.loc[lambda x: x['birth_city']=='tehran', 'name']"
which actors were born in tehran,"actor.loc[lambda x: x['birth_city']=='tehran', 'name']"
find all actors who are from afghanistan,"actor.loc[lambda x: x['nationality']=='afghanistan', 'name']"
find all actors from afghanistan,"actor.loc[lambda x: x['nationality']=='afghanistan', 'name']"
give me the name of all the actors from afghanistan,"actor.loc[lambda x: x['nationality']=='afghanistan', 'name']"
find all actors who were born in 1984,"actor.loc[lambda x: x['birth_year']==1984, 'name']"
"when was "" kevin spacey "" born ?","actor.loc[lambda x: x['name']=='actor_name0', 'birth_year']"
"in what year was "" kevin spacey "" born ?","actor.loc[lambda x: x['name']=='actor_name0', 'birth_year']"
"where is the birth place of "" kevin spacey ""","director.loc[lambda x: x['name']=='director_name0', 'birth_city']"
"in what city was "" kevin spacey "" born ?","director.loc[lambda x: x['name']=='director_name0', 'birth_city']"
"what is the nationality of "" kevin spacey "" ?","director.loc[director['name'] == 'director_name0', 'nationality']"
"how much was the budget of "" finding nemo ""","movie.loc[movie['title']=='finding nemo', 'budget']"
"find all movies directed by "" steven spielberg "" after 2006","movie.loc[(movie.merge(directed_by, on='mid').merge(director, on='did').loc[(director['name'] == 'steven spielberg') & (movie['release_year'] > 2006), 'mid'],'title')]"
"who is the director of the movie "" james bond "" ?","pd.merge(pd.merge(director, directed_by, on='did'), movie, on='msid').loc[lambda x: x['title']=='james bond', 'name']"
"who directed the movie "" james bond "" ?","pd.merge(pd.merge(director, directed_by, on='did'), movie, on='msid').loc[lambda x: x['title']=='james bond', 'name']"
"list "" james bond "" directors","pd.merge(pd.merge(director, directed_by, on='did'), movie, on='msid').loc[lambda x: x['title']=='james bond', 'name']"
"find the actor who played "" alan turing "" in the movie "" the imitation game ""","pd.merge(pd.merge(cast.loc[cast['role']=='alan turing'], actor, on='aid'), movie.loc[movie['title']=='the imitation game'], left_on='msid', right_on='mid')['name']"
"who acted "" alan turing "" in the movie "" the imitation game "" ?","pd.merge(pd.merge(cast.loc[cast['role']=='alan turing'], actor, on='aid'), movie.loc[movie['title']=='the imitation game'], left_on='msid', right_on='mid')['name']"
"who was the actor that played "" alan turing "" in the movie "" the imitation game "" ?","pd.merge(pd.merge(cast.loc[cast['role']=='alan turing'], actor, on='aid'), movie.loc[movie['title']=='the imitation game'], left_on='msid', right_on='mid')['name']"
"who acts as "" alan turing "" in the movie "" the imitation game "" ?","pd.merge(pd.merge(cast.loc[cast['role']=='alan turing'], actor, on='aid'), movie.loc[movie['title']=='the imitation game'], left_on='msid', right_on='mid')['name']"
"who is the actor playing "" alan turing "" in "" the imitation game "" ?","pd.merge(pd.merge(cast.loc[cast['role']=='alan turing'], actor, on='aid'), movie.loc[movie['title']=='the imitation game'], left_on='msid', right_on='mid')['name']"
"what is the genre of the movie "" jurassic park "" ?","genre.merge(classification, on='gid').merge(movie, on='mid').query('title == ""jurassic park""')['genre']"
who was the director of the movie joy from 2015 ?,"pd.merge(pd.merge(director, directed_by, on='did'), movie, left_on='msid', right_on='mid').loc[lambda x: (x['release_year']==2015) & (x['title']=='joy'), 'name']"
"find all movies written by "" matt damon ""","written_by.merge(movie, left_on='msid', right_on='mid').merge(writer, on='wid').loc[lambda x: x['name']=='matt damon', 'title']"
"find all movies written and produced by "" woody allen ""","pd.merge(pd.merge(pd.merge(pd.merge(movie, made_by, left_on='mid', right_on='msid'), producer, on='pid'), written_by, on='msid'), writer, on='wid').loc[(lambda x: (x['name_x'] == 'woody allen') & (x['name_y'] == 'woody allen')), 'title']"
"find all movies featuring "" robin wright ""","pd.merge(pd.merge(cast, actor, on='aid'), movie, on='mid').loc[lambda x: x['name'] == 'robin wright', 'title']"
"what are all the movies featuring "" robin wright "" ?","pd.merge(pd.merge(cast, actor, on='aid'), movie, on='mid').loc[lambda x: x['name'] == 'robin wright', 'title']"
"find all movies in which "" robin wright "" appears","pd.merge(pd.merge(cast, actor, on='aid'), movie, on='mid').loc[lambda x: x['name'] == 'robin wright', 'title']"
what was the budget of the movie juno from 2007 ?,"movie.loc[(movie['release_year']==2007) & (movie['title']=='juno'), 'budget']"
find all sci-fi produced in year 2010,"pd.merge(pd.merge(genre.loc[lambda x: x['genre']=='sci-fi', ['gid']], classification, on='gid'), movie.loc[lambda x: x['release_year']==2010, ['mid', 'title']], left_on='msid', right_on='mid')['title']"
list all the sci-fi movies which released in 2010,"pd.merge(pd.merge(genre.loc[lambda x: x['genre']=='sci-fi', ['gid']], classification, on='gid'), movie.loc[lambda x: x['release_year']==2010, ['mid', 'title']], left_on='msid', right_on='mid')['title']"
"find all actors born in "" austin "" after 1980","actor.loc[(actor['birth_city'] == 'austin') & (actor['birth_year'] > 1980), 'name']"
"who are the actors born in "" austin "" after 1980 ?","actor.loc[(actor['birth_city'] == 'austin') & (actor['birth_year'] > 1980), 'name']"
find all actors from austin born after 1980,"actor.loc[(actor['birth_city'] == 'austin') & (actor['birth_year'] > 1980), 'name']"
"find all movies by directors born in "" los angeles ""","pd.merge(pd.merge(director, directed_by, on='did'), movie, on='mid').loc[lambda x: x['birth_city']=='los angeles', 'title']"
"find all actors who were born in "" new york city "" in 1984","actor.loc[(actor['birth_city']=='new york city') & (actor['birth_year']==1984), 'name']"
find all movies about nuclear weapons,"pd.merge(pd.merge(tags, keyword, left_on='kid', right_on='id'), movie, left_on='msid', right_on='mid').loc[lambda x: x['keyword']=='nuclear weapons', 'title']"
what are the movies related to nuclear weapons,"pd.merge(pd.merge(tags, keyword, left_on='kid', right_on='id'), movie, left_on='msid', right_on='mid').loc[lambda x: x['keyword']=='nuclear weapons', 'title']"
"which movies did "" alfred hitchcock "" direct ?","movie.merge(directed_by.merge(director[lambda x: x['name'] == 'alfred hitchcock'], on='did'), on='mid')['title']"
"find all movies directed by "" asghar farhadi "" and featuring "" taraneh alidoosti ""","(pd.merge(pd.merge(pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid'), directed_by, on='msid'), director, on='did').loc[lambda x: (x['name_x']=='taraneh alidoosti') & (x['name_y']=='asghar farhadi'), 'title'])"
"what are all the movies directed by "" asghar farhadi "" featuring "" taraneh alidoosti "" ?","(pd.merge(pd.merge(pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid'), directed_by, on='msid'), director, on='did').loc[lambda x: (x['name_x']=='taraneh alidoosti') & (x['name_y']=='asghar farhadi'), 'title'])"
"how many movies are there that are directed by "" asghar farhadi "" and featuring "" taraneh alidoosti "" ?","(pd.merge(pd.merge(pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid'), directed_by, on='msid'), director, on='did').loc[lambda x: (x['name_x']=='taraneh alidoosti') & (x['name_y']=='asghar farhadi'), 'title'])"
"list all the movies directed by "" asghar farhadi "" in which "" taraneh alidoosti "" played","(pd.merge(pd.merge(pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid'), directed_by, on='msid'), director, on='did').loc[lambda x: (x['name_x']=='taraneh alidoosti') & (x['name_y']=='asghar farhadi'), 'title'])"
"what are all the tv series created by "" shonda rhimes "" ?","tv_series.merge(made_by.merge(producer.loc[producer['name']=='shonda rhimes'], on='pid'), on='sid')['title']"
"who acts "" olivia pope "" in the series scandal ?","pd.merge(pd.merge(cast, actor, on='aid'), tv_series, left_on='msid', right_on='sid').loc[(lambda x: (x['role']=='olivia pope') & (x['title']=='scandal')), 'name']"
"who is the writer of the movie "" the truman show ""","pd.merge(pd.merge(written_by, movie, left_on='msid', right_on='mid'), writer, on='wid').loc[lambda x: x['title']=='the truman show', 'name']"
"who is the writer of "" the truman show ""","pd.merge(pd.merge(written_by, movie, left_on='msid', right_on='mid'), writer, on='wid').loc[lambda x: x['title']=='the truman show', 'name']"
"what are the series featuring "" scott foley "" ?","pd.merge(pd.merge(cast, actor, on='aid'), tv_series, left_on='msid', right_on='sid').loc[lambda x: x['name']=='scott foley', 'title']"
"what are the series in which "" scott foley "" is an actor ?","pd.merge(pd.merge(cast, actor, on='aid'), tv_series, left_on='msid', right_on='sid').loc[lambda x: x['name']=='scott foley', 'title']"
"find the directors of all movies featuring "" kate winslet ""","pd.merge(pd.merge(pd.merge(pd.merge(cast, actor, on='aid'), movie, left_on='msid_x', right_on='mid'), directed_by, on='msid_y'), director, on='did').loc[lambda x: x['name_x']=='kate winslet', 'name_y']"
"find the producers of all movies in which "" kate winslet "" is an actor","pd.merge(pd.merge(pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid'), made_by, on='msid'), producer, on='pid').loc[lambda x: x['name_y']=='kate winslet', 'name_x']"
"who is the director of the tv series "" house of cards "" from 2013 ?","pd.merge(pd.merge(director, directed_by, on='did'), tv_series, left_on='msid', right_on='sid').loc[lambda x: (x['release_year']==2013) & (x['title']=='house of cards'), 'name']"
find all the female actors from austin,"actor.loc[(actor['birth_city']=='austin')&(actor['gender']=='female'), 'name']"
find all actors from italy born after 1980,"actor.loc[(actor['birth_year'] > 1980) & (actor['nationality'] == 'italy'), 'name']"
"find all the female actors born in "" new york city "" after 1980","actor.loc[(actor['birth_city']=='new york city') & (actor['birth_year']>1980) & (actor['gender']=='female'), 'name']"
"find all the female actors in the movie "" saving private ryan ""","pd.merge(pd.merge(cast, actor, on='aid'), movie, left_on='msid', right_on='mid').loc[(lambda x: x['gender']=='female')&(lambda x: x['title']=='saving private ryan'), 'name']"
find all the directors who are from afghanistan,"director.loc[lambda x: x['nationality']=='afghanistan', 'name']"
"find the actors who played in the movie "" camp x-ray ""","pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid').loc[lambda x: x['title']=='camp x-ray', 'name']"
"find all actors from canada who acted in "" james bond "" movies","pd.merge(pd.merge(cast, actor, on='aid'), movie, left_on='msid', right_on='mid').loc[lambda x: (x['nationality']=='canada') & (x['title']=='james bond'), 'name']"
"find all films in which "" rowan atkinson "" acted as "" mr. bean ""","pd.merge(pd.merge(actor.loc[lambda x: x['name']=='rowan atkinson'], cast.loc[lambda x: x['role']=='mr. bean'], on='aid'), movie, on='mid')['title']"
"where is the director of "" the past "" from","director.merge(directed_by, on='did').merge(movie, left_on='msid', right_on='mid').loc[lambda x: x['title']=='the past', 'birth_city']"
"who acted the role of "" mr. bean ""","pd.merge(cast.loc[lambda x: x['role']=='mr. bean'], actor, on='aid')['name']"
"what are the genres of movies directed by "" asghar farhadi """,genre.loc[lambda x: x['gid'].isin(classification.loc[lambda x: x['msid'].isin(movie.loc[lambda x: x['mid'].isin(directed_by.loc[lambda x: x['did'].isin(director.loc[lambda x: x['name']=='asghar farhadi']['did'])]['msid'])]['msid'])]['gid'])]['genre']
"which movie had the character "" daffy duck ""","pd.merge(movie, cast, left_on='mid', right_on='msid').loc[lambda x: x['role']=='daffy duck', 'title']"
"what are the major roles in the movie "" daddy long legs ""","pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid').loc[lambda x: x['title']=='daddy long legs', 'role']"
list all the directors of movies about nuclear weapons,"tags.merge(keyword.loc[lambda x: x['keyword']=='nuclear weapons'], left_on='kid', right_on='id').merge(directed_by.merge(director)['name'])"
"what is the number of movies in which "" jennifer aniston "" acted after 2010 ?","pd.merge(pd.merge(cast, actor, on='aid'), movie, left_on='msid', right_on='mid').loc[lambda x: (x['name'] == 'jennifer aniston') & (x['release_year'] > 2010), 'title'].nunique()"
"what is the number of actors in the movie "" saving private ryan "" ?","pd.merge(pd.merge(actor, cast, on='aid'), movie, on='mid').loc[lambda x: x['title']=='saving private ryan', 'name'].nunique()"
"how many actors are in the movie "" saving private ryan "" ?","pd.merge(pd.merge(actor, cast, on='aid'), movie, on='mid').loc[lambda x: x['title']=='saving private ryan', 'name'].nunique()"
"how many movies did "" steven spielberg "" direct ?","pd.merge(pd.merge(director, directed_by, on='did'), movie, on='mid').loc[lambda x: x['name']=='steven spielberg', 'title'].nunique()"
how many movies were produced in the year 2013 ?,"movie.loc[lambda x: x['release_year']==2013, 'title'].nunique()"
what is the number of movies produced in 2013 ?,"movie.loc[lambda x: x['release_year']==2013, 'title'].nunique()"
"what is the number of movies directed by "" woody allen "" per year ?","movie.merge(directed_by.merge(director[director.name == 'woody allen'], on='did'), on='mid').groupby('release_year').agg({'title': pd.series.nunique}).reset_index().rename(columns={'title': 'count'}).loc[:, ['count', 'release_year']]"
"how many movies did "" shahab hosseini "" act in ?","pd.merge(pd.merge(cast, actor, on='aid'), movie, on='mid').loc[lambda x: x['name']=='shahab hosseini', 'title'].nunique()"
"what is the number of movies in which "" shahab hosseini "" acted ?","pd.merge(pd.merge(cast, actor, on='aid'), movie, on='mid').loc[lambda x: x['name']=='shahab hosseini', 'title'].nunique()"
"what is the number of movies featuring "" shahab hosseini "" ?","pd.merge(pd.merge(cast, actor, on='aid'), movie, on='mid').loc[lambda x: x['name']=='shahab hosseini', 'title'].nunique()"
"how many movies did "" shahab hosseini "" act in","pd.merge(pd.merge(cast, actor, on='aid'), movie, on='mid').loc[lambda x: x['name']=='shahab hosseini', 'title'].nunique()"
"how many actors were born in "" los angeles "" after 2000 ?","actor.loc[(actor['birth_city'] == 'los angeles') & (actor['birth_year'] > 2000), 'name'].nunique()"
"how many movies did "" humphrey bogart "" act in before 1942 ?","pd.merge(pd.merge(actor, cast, on='aid'), movie, left_on='msid', right_on='mid').loc[(lambda x: (x['name']=='humphrey bogart') & (x['release_year']<1942)), 'title'].nunique()"
"what is the number of movies that "" brad pitt "" acts in per year ?","pd.merge(pd.merge(cast, actor, on='aid'), movie, on='mid').loc[lambda x: x['name']=='brad pitt'].groupby('release_year')['title'].nunique()"
how many movies about iraq war were produced in 2015 ?,"pd.merge(pd.merge(tags, keyword, left_on='kid', right_on='id'), movie, left_on='msid', right_on='mid').loc[(lambda x: x['keyword']=='iraq war')&(lambda x: x['release_year']==2015), 'title'].nunique()"
how many movies about persians were released after 1990 ?,"pd.merge(pd.merge(tags, keyword, left_on='kid', right_on='id'), movie, left_on='msid', right_on='mid').loc[(lambda x: x['keyword']=='persians') & (lambda x: x['release_year']>1990), 'title'].nunique()"
"how many movies did "" quentin tarantino "" direct after 2010 ?","pd.merge(pd.merge(director.loc[lambda x: x['name']=='quentin tarantino'], directed_by, on='did'), movie, left_on='msid', right_on='mid').loc[lambda x: x['release_year']>2010, 'title'].nunique()"
"how many movies did "" quentin tarantino "" direct before 2010 ?","pd.merge(pd.merge(director, directed_by, on='did'), movie, on='msid').loc[(director['name']=='quentin tarantino') & (movie['release_year'] < 2010), 'title'].nunique()"
"how many movies did "" quentin tarantino "" direct before 2002 and after 2010 ?","pd.merge(pd.merge(pd.merge(pd.merge(director[director['name']=='quentin tarantino'], directed_by, on='did'), movie[movie['release_year'].between(2003, 2009)], on='mid'), made_by, on='msid'), producer, on='pid')['title'].nunique()"
"how many female actors were born in "" new york city "" after 1980 ?","actor.loc[(actor['birth_city']=='new york city') & (actor['birth_year']>1980) & (actor['gender']=='female'), 'name'].nunique()"
"find the number of actors from iran who played in "" jim jarmusch "" movies","pd.merge(pd.merge(pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid'), directed_by, on='msid'), director, on='did').loc[(lambda x: (x['nationality']=='iran') & (x['name']=='jim jarmusch')), 'name'].nunique()"
"how many actors from china have acted in "" rush hour 3 ""","pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid').loc[lambda x: (x['nationality']=='china') & (x['title']=='rush hour 3'), 'name'].nunique()"
"find all movies that star both "" woody strode "" and "" jason robards ""","pd.merge(pd.merge(pd.merge(pd.merge(cast, actor.rename(columns={'name': 'name1'}), on='aid'),cast.rename(columns={'msid': 'mid'}), on='mid'),movie, on='mid'), actor.rename(columns={'name': 'name2'}), on='aid')[lambda x: (x['name1']=='woody strode') & (x['name2']=='jason robards')]['title']"
"find all movies featuring "" woody strode "" and "" jason robards ""","pd.merge(pd.merge(pd.merge(pd.merge(cast, actor.rename(columns={'name': 'name1'}), on='aid'),cast.rename(columns={'msid': 'mid'}), on='mid'),movie, on='mid'), actor.rename(columns={'name': 'name2'}), on='aid')[lambda x: (x['name1']=='woody strode') & (x['name2']=='jason robards')]['title']"
"find all movies featuring both "" woody strode "" and "" jason robards ""","pd.merge(pd.merge(pd.merge(pd.merge(cast, actor.rename(columns={'name': 'name1'}), on='aid'),cast.rename(columns={'msid': 'mid'}), on='mid'),movie, on='mid'), actor.rename(columns={'name': 'name2'}), on='aid')[lambda x: (x['name1']=='woody strode') & (x['name2']=='jason robards')]['title']"
"find all movies featuring "" jason robards "" and "" woody strode ""","pd.merge(pd.merge(pd.merge(pd.merge(cast, actor.rename(columns={'name': 'name1'}), on='aid'),cast.rename(columns={'msid': 'mid'}), on='mid'),movie, on='mid'), actor.rename(columns={'name': 'name2'}), on='aid')[lambda x: (x['name1']=='woody strode') & (x['name2']=='jason robards')]['title']"
"find all actors who acted in the same movie as "" tom hanks ""","pd.merge(pd.merge(pd.merge(pd.merge(cast, actor.rename(columns={'aid': 'aid_1', 'name': 'name_1'}), on='aid'),movie.rename(columns={'mid': 'msid'}), on='msid'),cast.rename(columns={'aid': 'aid_2'}), on='msid'),actor.rename(columns={'aid': 'aid_2', 'name': 'name_2'}), on='aid_2').loc[lambda x: x['name_2']=='tom hanks', 'name_1']"
"what movies have the same director as the movie "" revolutionary road "" ?","pd.merge(pd.merge(pd.merge(director, directed_by, on='did'), movie, left_on='msid', right_on='mid'), movie, left_on=['did', 'msid'], right_on=['did', 'mid']).loc[lambda x: x['title_x'] == 'revolutionary road', 'title_y']"
find the movie which is classified in the most number of genres,"movie.merge(classification.merge(genre, on='gid'), on='mid').groupby('title').apply(lambda df: df['genre'].nunique()).sort_values(ascending=false).head(1).index[0]"
which movie has the most number of actors from china ?,"pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid').loc[lambda x: x['nationality']=='china'].groupby('title').apply(lambda x: x['name'].nunique()).sort_values(ascending=false).head(1).index.values[0]"
"find the actors who played in the latest movie by "" quentin tarantino ""","pd.merge(pd.merge(pd.merge(pd.merge(actor, _cast, on='aid'), movie, on='mid'), directed_by, on='msid'), director.loc[lambda x: x['name']=='quentin tarantino'], on='did').sort_values('release_year', ascending=false).iloc[0]['name']"
"find the name and budget of the latest movie by "" quentin tarantino ""","movie.merge(directed_by.merge(director.loc[lambda x: x['name'] == 'quentin tarantino'], on='did'), on='mid').sort_values('release_year', ascending=false).iloc[0][['budget', 'title']]"
"what is the latest movie by "" jim jarmusch ""","movie.loc[movie.merge(directed_by.merge(director.loc[lambda x: x['name']=='jim jarmusch'], on='did'), on='mid').sort_values('release_year', ascending=false).iloc[0]['mid']]['title']"
which producer has worked with the most number of directors ?,"pd.merge(pd.merge(pd.merge(pd.merge(director, directed_by, on='did'), movie, on='mid'), made_by, on='mid'), producer, on='pid').groupby('name').agg({'director_name': 'nunique'}).sort_values('director_name', ascending=false).iloc[0].name"
"find the latest movie which "" gabriele ferzetti "" acted in","pd.merge(pd.merge(actor, cast, on='aid'), movie, on='mid').loc[lambda x: x['name']=='gabriele ferzetti'].sort_values('release_year', ascending=false).iloc[0]['name']"
how many buttercup kitchen are there in san francisco ?,"pd.merge(restaurant, location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['name']=='buttercup kitchen')].shape[0]"
how many chinese restaurants are there in the bay area ?,"pd.merge(restaurant, geographic, on='city_name').loc[(lambda x: (x['region'] == 'bay area') & (x['food_type'] == 'chinese'))(restaurant), :].shape[0]"
how many places for chinese food are there in the bay area ?,"pd.merge(restaurant, geographic, on='city_name').loc[(lambda x: (x['region'] == 'bay area') & (x['food_type'] == 'chinese'))(restaurant), :].shape[0]"
how many chinese places are there in the bay area ?,"pd.merge(restaurant, geographic, on='city_name').loc[(lambda x: (x['region'] == 'bay area') & (x['food_type'] == 'chinese'))(restaurant), :].shape[0]"
how many places for chinese are there in the bay area ?,"pd.merge(restaurant, geographic, on='city_name').loc[(lambda x: (x['region'] == 'bay area') & (x['food_type'] == 'chinese'))(restaurant), :].shape[0]"
how many jamerican cuisine are there in santa cruz county ?,"len(pd.merge(restaurant.loc[lambda x: x['name']=='jamerican cuisine'], geographic.loc[lambda x: x['county']=='santa cruz county'], on='city_name'))"
where is jamerican cuisine ?,"location.merge(restaurant[restaurant['name']=='jamerican cuisine'], on='restaurant_id')[['house_number', 'name']]"
what is the best french restaurant in san francisco ?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
what is the best french in san francisco ?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
what is the best place in san francisco for french food ?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
give me the best place in san francisco for french food ?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
where is the best french in san francisco ?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
give me the best french in san francisco ?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
where is the best french restaurant in san francisco ?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
give me the best restaurant in san francisco for french food ?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
give me the best french restaurant in san francisco ?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
what is the best restaurant in san francisco for french food ?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
where is the best restaurant in san francisco for french food ?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
where is denny in the bay area ?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: x['region']=='bay area') & (lambda x: x['name']=='denny'), ['house_number', 'name']]"
what are some good restaurants on bethel island rd in bethel island ?,"pd.merge(restaurant, location, on='restaurant_id').loc[(location['city_name']=='bethel island') & (location['street_name']=='bethel island rd') & (restaurant['rating']>2.5), ['house_number', 'name']]"
give me some good restaurants on bethel island rd in bethel island ?,"pd.merge(restaurant, location, on='restaurant_id').loc[(location['city_name']=='bethel island') & (location['street_name']=='bethel island rd') & (restaurant['rating']>2.5), ['house_number', 'name']]"
give me a good restaurant on bethel island rd in bethel island ?,"pd.merge(restaurant, location, on='restaurant_id').loc[(location['city_name']=='bethel island') & (location['street_name']=='bethel island rd') & (restaurant['rating']>2.5), ['house_number', 'name']]"
what is a good restaurant on bethel island rd in bethel island ?,"pd.merge(restaurant, location, on='restaurant_id').loc[(location['city_name']=='bethel island') & (location['street_name']=='bethel island rd') & (restaurant['rating']>2.5), ['house_number', 'name']]"
where can we find a restaurant in alameda ?,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: x['city_name']=='alameda', ['house_number', 'name']]"
give me a restaurant in alameda ?,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: x['city_name']=='alameda', ['house_number', 'name']]"
where can we find some restaurants in alameda ?,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: x['city_name']=='alameda', ['house_number', 'name']]"
where is a restaurant in alameda ?,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: x['city_name']=='alameda', ['house_number', 'name']]"
give me some restaurants in alameda ?,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: x['city_name']=='alameda', ['house_number', 'name']]"
give me some restaurants good for french food ?,"pd.merge(restaurant.loc[(restaurant['food_type']=='french') & (restaurant['rating']>2.5), ['id', 'name']],location[['restaurant_id', 'house_number']], left_on='id', right_on='restaurant_id')[['house_number', 'name']]"
where are some restaurants good for french food ?,"pd.merge(restaurant.loc[(restaurant['food_type']=='french') & (restaurant['rating']>2.5), ['id', 'name']],location[['restaurant_id', 'house_number']], left_on='id', right_on='restaurant_id')[['house_number', 'name']]"
how many places for french food are there in palo alto ?,"pd.merge(restaurant, location, on='id').loc[lambda x: (x['city_name']=='palo alto') & (x['food_type']=='french'), :].shape[0]"
how many french restaurants are there in palo alto ?,"pd.merge(restaurant, location, on='id').loc[lambda x: (x['city_name']=='palo alto') & (x['food_type']=='french'), :].shape[0]"
how many french restaurant are there in palo alto ?,"pd.merge(restaurant, location, on='id').loc[lambda x: (x['city_name']=='palo alto') & (x['food_type']=='french'), :].shape[0]"
how many places for french are there in palo alto ?,"pd.merge(restaurant, location, on='id').loc[lambda x: (x['city_name']=='palo alto') & (x['food_type']=='french'), :].shape[0]"
how many italian restaurants are in the yolo county ?,"pd.merge(restaurant, geographic, on='city_name').loc[lambda x: (x['county']=='yolo county') & (x['food_type']=='italian'), :].shape[0]"
where can i eat french food in mountain view ?,"pd.merge(restaurant.loc[lambda x: x['food_type']=='french'], location.loc[lambda x: x['city_name']=='mountain view'], on='restaurant_id')[['house_number', 'name']]"
how many denny are there in the bay area ?,"pd.merge(restaurant, geographic, on='city_name').loc[(lambda x: x['region']=='bay area')&(lambda x: x['name']=='denny')].shape[0]"
give me a good restaurant in alameda ?,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: (x['city_name']=='alameda') & (x['rating'] > 2.5), ['house_number', 'name']]"
what are some good restaurants in alameda ?,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: (x['city_name']=='alameda') & (x['rating'] > 2.5), ['house_number', 'name']]"
what is a good restaurant in alameda ?,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: (x['city_name']=='alameda') & (x['rating'] > 2.5), ['house_number', 'name']]"
give me some good restaurants in alameda ?,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: (x['city_name']=='alameda') & (x['rating'] > 2.5), ['house_number', 'name']]"
where is a good restaurant on buchanan in san francisco for arabic food ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where are some good arabics on buchanan in san francisco ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where is a good arabic restaurant on buchanan in san francisco ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
what are some good places for arabic on buchanan in san francisco ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
give me a good arabic on buchanan in san francisco ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
give me some restaurants good for arabic food on buchanan in san francisco ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
give me a good place on buchanan in san francisco for arabic food ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where is a good place on buchanan in san francisco for arabic food ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where can i eat arabic food on buchanan in san francisco ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
give me some good places on buchanan in san francisco for arabic food ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where is a arabic restaurant on buchanan in san francisco ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
give me a restaurant on buchanan in san francisco that serves good arabic food ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
give me a good restaurant on buchanan in san francisco for arabic food ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where is a restaurant on buchanan in san francisco that serves good arabic food ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
give me some good restaurants on buchanan in san francisco for arabic food ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
give me some good places for arabic on buchanan in san francisco ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where can i eat some good arabic food on buchanan in san francisco ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where is a good arabic on buchanan in san francisco ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where are some restaurants good for arabic food on buchanan in san francisco ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where are some good places for arabic on buchanan in san francisco ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
give me a good arabic restaurant on buchanan in san francisco ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
give me some good arabics on buchanan in san francisco ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where can i eat french food in the bay area ?,"pd.merge(pd.merge(restaurant[restaurant['food_type'] == 'french'], geographic[geographic['region'] == 'bay area'], on='city_name'), location, on='restaurant_id')[['house_number', 'name']]"
give me some restaurants on bethel island rd in bethel island ?,"pd.merge(restaurant, location, on='restaurant_id').query('city_name==""bethel island"" and street_name==""bethel island rd""')[['house_number', 'name']]"
give me a restaurant on bethel island rd in bethel island ?,"pd.merge(restaurant, location, on='restaurant_id').query('city_name==""bethel island"" and street_name==""bethel island rd""')[['house_number', 'name']]"
where can we find a restaurant on bethel island rd in bethel island ?,"pd.merge(restaurant, location, on='restaurant_id').query('city_name==""bethel island"" and street_name==""bethel island rd""')[['house_number', 'name']]"
where can we find some restaurants on bethel island rd in bethel island ?,"pd.merge(restaurant, location, on='restaurant_id').query('city_name==""bethel island"" and street_name==""bethel island rd""')[['house_number', 'name']]"
where is the best restaurant in the bay area for american food ?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
where is the best restaurant in bay area for american food ?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
what is the best restaurant in bay area for american food ?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
what is the best american restaurant in the bay area ?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
where is the best american restaurant in the bay area ?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
what is the best american in the bay area ?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
give me the best restaurant in the bay area for american food ?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
give me the best restaurant in bay area for american food ?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
what is the best restaurant in the bay area for american food ?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
where is the best american in the bay area ?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
give me the best american in the bay area ?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
give me the best american restaurant in the bay area ?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
give me some restaurants good for french food in the yosemite and mono lake area ?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
what are some good places in the yosemite and mono lake area for french food ?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
give me a good restaurant in the yosemite and mono lake area for french food ?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
give me a good french restaurant in the yosemite and mono lake area ?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
where is a good place in the yosemite and mono lake area for french food ?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
where are some restaurants good for french food in the yosemite and mono lake area ?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
give me a good place in the yosemite and mono lake area for french food ?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
where is a good restaurant in the yosemite and mono lake area for french food ?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
what are some good restaurants in the yosemite and mono lake area for french food ?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
where is a good french restaurant in the yosemite and mono lake area ?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
where can i eat some good french food in the yosemite and mono lake area ?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
where are some restaurants good for arabic food in mountain view ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
what are some good places in mountain view for arabic food ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where are some good arabic restaurants in mountain view ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
show me a good arabic restaurant in mountain view ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
give me a good arabic in mountain view ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
give me a good arabic restaurant in mountain view ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
give me a good place in mountain view for arabic food ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where are some good arabics in mountain view ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where is a restaurant in mountain view that serves good arabic food ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
what are some good restaurants in mountain view for arabic food ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
give me some restaurants good for arabic food in mountain view ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where can i eat some good arabic food in mountain view ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
give me some good places for arabic in mountain view ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where is a good arabic in mountain view ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
give me a restaurant in mountain view that serves good arabic food ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
give me some good arabic restaurants in mountain view ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where are some good places for arabic in mountain view ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
give me some good arabics in mountain view ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
give me a good restaurant in mountain view for arabic food ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where is a good arabic restaurant in mountain view ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
what are some good places for arabic in mountain view ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where is a good restaurant in mountain view for arabic food ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where is a good place in mountain view for arabic food ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where can i find a jamerican cuisine in san francisco ?,"pd.merge(restaurant.loc[lambda x: x['name'] == 'jamerican cuisine'], location.loc[lambda x: x['city_name'] == 'san francisco'], on='restaurant_id')[['house_number', 'name']]"
where is jamerican cuisine in san francisco ?,"pd.merge(restaurant.loc[lambda x: x['name'] == 'jamerican cuisine'], location.loc[lambda x: x['city_name'] == 'san francisco'], on='restaurant_id')[['house_number', 'name']]"
where is a jamerican cuisine in san francisco ?,"pd.merge(restaurant.loc[lambda x: x['name'] == 'jamerican cuisine'], location.loc[lambda x: x['city_name'] == 'san francisco'], on='restaurant_id')[['house_number', 'name']]"
where can we find some restaurants in the bay area ?,"pd.merge(location, restaurant, left_on='restaurant_id', right_on='id').loc[lambda x: x['city_name'].isin(geographic.loc[geographic['region']=='bay area', 'city_name']), ['house_number', 'name']]"
give me some restaurants in the bay area ?,"pd.merge(location, restaurant, left_on='restaurant_id', right_on='id').loc[lambda x: x['city_name'].isin(geographic.loc[geographic['region']=='bay area', 'city_name']), ['house_number', 'name']]"
give me a restaurant in the bay area ?,"pd.merge(location, restaurant, left_on='restaurant_id', right_on='id').loc[lambda x: x['city_name'].isin(geographic.loc[geographic['region']=='bay area', 'city_name']), ['house_number', 'name']]"
where can i find a restaurant in the bay area ?,"pd.merge(location, restaurant, left_on='restaurant_id', right_on='id').loc[lambda x: x['city_name'].isin(geographic.loc[geographic['region']=='bay area', 'city_name']), ['house_number', 'name']]"
give me a good restaurant in the bay area ?,"pd.merge(location, restaurant, on='restaurant_id').loc[lambda x: x['city_name'].isin(geographic.loc[geographic['region']=='region0', 'city_name']) & (x['rating']>2.5), ['house_number', 'name']]"
what are some good restaurants in the bay area ?,"pd.merge(location, restaurant, on='restaurant_id').loc[lambda x: x['city_name'].isin(geographic.loc[geographic['region']=='region0', 'city_name']) & (x['rating']>2.5), ['house_number', 'name']]"
give me some good restaurants in the bay area ?,"pd.merge(location, restaurant, on='restaurant_id').loc[lambda x: x['city_name'].isin(geographic.loc[geographic['region']=='region0', 'city_name']) & (x['rating']>2.5), ['house_number', 'name']]"
what is a good restaurant in the bay area ?,"pd.merge(location, restaurant, on='restaurant_id').loc[lambda x: x['city_name'].isin(geographic.loc[geographic['region']=='region0', 'city_name']) & (x['rating']>2.5), ['house_number', 'name']]"
how many singers do we have?,singer.shape[0]
what is the total number of singers?,singer.shape[0]
"show name, country, age for all singers ordered by age from the oldest to the youngest.","singer[['name', 'country', 'age']].sort_values('age', ascending=false)"
"what are the names, countries, and ages for every singer in descending order of age?","singer[['name', 'country', 'age']].sort_values('age', ascending=false)"
"what is the average, minimum, and maximum age of all singers from france?","singer.loc[singer['country']=='france', 'age'].agg(['mean', 'min', 'max'])"
"what is the average, minimum, and maximum age for all french singers?","singer.loc[singer['country']=='france', 'age'].agg(['mean', 'min', 'max'])"
show the name and the release year of the song by the youngest singer.,"singer[['song_name', 'song_release_year', 'age']].sort_values('age').iloc[0, :2]"
what are the names and release years for all the songs of the youngest singer?,"singer[['song_name', 'song_release_year', 'age']].sort_values('age').iloc[0, :2]"
what are all distinct countries where singers above age 20 are from?,"singer.loc[lambda x: x['age']>20, 'country'].unique()"
what are  the different countries with singers above age 20?,"singer.loc[lambda x: x['age']>20, 'country'].unique()"
show all countries and the number of singers in each country.,singer.groupby('country').size()
how many singers are from each country?,singer.groupby('country').size()
list all song names by singers above the average age.,"singer.loc[singer['age'] > singer['age'].mean(), 'song_name']"
what are all the song names by singers who are older than average?,"singer.loc[singer['age'] > singer['age'].mean(), 'song_name']"
show location and name for all stadiums with a capacity between 5000 and 10000.,"stadium.loc[lambda x: x['capacity'].between(5000, 10000), ['location', 'name']]"
what are the locations and names of all stations with capacity between 5000 and 10000?,"stadium.loc[lambda x: x['capacity'].between(5000, 10000), ['location', 'name']]"
what is the maximum capacity and the average of all stadiums ?,"stadium.agg({'capacity': 'max', 'average': 'mean'})"
what is the average and maximum capacities for all stadiums ?,"stadium['capacity'].agg(['mean', 'max'])"
what is the name and capacity for the stadium with highest average attendance?,"stadium[['name', 'capacity']].sort_values('average', ascending=false).iloc[0]"
what is the name and capacity for the stadium with the highest average attendance?,"stadium[['name', 'capacity']].sort_values('average', ascending=false).iloc[0]"
how many concerts are there in year 2014 or 2015?,"concert.loc[lambda x: x['year'].isin([2014, 2015])]['year'].count()"
how many concerts occurred in 2014 or 2015?,"concert.loc[lambda x: x['year'].isin([2014, 2015])]['year'].count()"
show the stadium name and the number of concerts in each stadium.,"concert.merge(stadium, on='stadium_id').groupby('name').size()"
"for each stadium, how many concerts play there?","concert.merge(stadium, on='stadium_id').groupby('name').size()"
show the stadium name and capacity with most number of concerts in year 2014 or after.,"stadium.merge(concert.query('year >= 2014')).groupby(['name', 'capacity'], as_index=false).size().sort_values(ascending=false).iloc[[0]][['name', 'capacity']]"
what is the name and capacity of the stadium with the most concerts after 2013 ?,"concert.merge(stadium, on='stadium_id').loc[lambda x: x['year']>2013].groupby(['stadium_id', 'name', 'capacity']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0, [1,2]]"
which year has most number of concerts?,"concert.groupby('year').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['year']"
what is the year that had the most concerts?,"concert.groupby('year').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['year']"
show the stadium names without any concert.,stadium[~stadium['stadium_id'].isin(concert['stadium_id'])]['name']
what are the names of the stadiums without any concerts?,stadium[~stadium['stadium_id'].isin(concert['stadium_id'])]['name']
show countries where a singer above age 40 and a singer below 30 are from.,"singer.loc[lambda x: x['age'] > 40, 'country'].to_frame().merge(singer.loc[lambda x: x['age'] < 30, 'country'].to_frame()).squeeze()"
show names for all stadiums except for stadiums having a concert in year 2014.,stadium[~stadium['name'].isin(concert[concert['year']==2014].merge(stadium)['name'])]['name']
what are the names of all stadiums that did not have a concert in 2014?,stadium[~stadium['name'].isin(concert[concert['year']==2014].merge(stadium)['name'])]['name']
show the name and theme for all concerts and the number of singers in each concert.,"singer_in_concert.merge(concert, on='concert_id').groupby(['concert_name', 'theme']).size().reset_index().rename(columns={0:'count'})"
"what are the names , themes , and number of singers for every concert ?","singer_in_concert.merge(concert, on='concert_id').groupby(['concert_id', 'concert_name', 'theme']).size().reset_index(name='count')[['concert_name', 'theme', 'count']]"
list singer names and number of concerts for each singer.,"singer_in_concert.merge(singer, on='singer_id').groupby('name').size()"
what are the names of the singers and number of concerts for each person?,"singer_in_concert.merge(singer, on='singer_id').groupby('name').size()"
list all singer names in concerts in year 2014.,"pd.merge(pd.merge(singer_in_concert, singer, on='singer_id'), concert, on='concert_id').loc[lambda x: x['year']==2014, 'name']"
what are the names of the singers who performed in a concert in 2014?,"pd.merge(pd.merge(singer_in_concert, singer, on='singer_id'), concert, on='concert_id').loc[lambda x: x['year']==2014, 'name']"
what is the name and nation of the singer who have a song having 'hey' in its name?,"singer.loc[singer['song_name'].str.contains('hey'), ['name', 'country']]"
what is the name and country of origin of every singer who has a song with the word 'hey' in its title?,"singer.loc[singer['song_name'].str.contains('hey'), ['name', 'country']]"
find the name and location of the stadiums which some concerts happened in the years of both 2014 and 2015.,"pd.merge(concert.query('year==2014')[['stadium_id']].drop_duplicates(), concert.query('year==2015')[['stadium_id']].drop_duplicates(), on='stadium_id').merge(stadium, on='stadium_id')[['name', 'location']]"
what are the names and locations of the stadiums that had concerts that occurred in both 2014 and 2015?,"pd.merge(concert.query('year==2014')[['stadium_id']].drop_duplicates(), concert.query('year==2015')[['stadium_id']].drop_duplicates(), on='stadium_id').merge(stadium, on='stadium_id')[['name', 'location']]"
find the number of concerts happened in the stadium with the highest capacity .,"concert.loc[lambda x: x['stadium_id'] == stadium.sort_values('capacity', ascending=false)['stadium_id'].iloc[0]].shape[0]"
what are the number of concerts that occurred in the stadium with the largest capacity ?,"concert.loc[lambda x: x['stadium_id'] == stadium.sort_values('capacity', ascending=false)['stadium_id'].iloc[0]].shape[0]"
find the number of pets whose weight is heavier than 10.,(pets['weight'] > 10).sum()
how many pets have a greater weight than 10?,(pets['weight'] > 10).sum()
find the weight of the youngest dog.,pets.sort_values('pet_age')['weight'].iloc[0]
how much does the youngest dog weigh?,pets.sort_values('pet_age')['weight'].iloc[0]
find the maximum weight for each type of pet. list the maximum weight and pet type.,pets.groupby('pettype')['weight'].max()
list the maximum weight and type for each type of pet.,pets.groupby('pettype')['weight'].max()
find number of pets owned by students who are older than 20.,"pd.merge(student, has_pet, on='stuid').loc[lambda x: x['age']>20].shape[0]"
how many pets are owned by students that have an age greater than 20?,"pd.merge(student, has_pet, on='stuid').loc[lambda x: x['age']>20].shape[0]"
find the number of dog pets that are raised by female students (with sex f).,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: (x['sex']=='f') & (x['pettype']=='dog'), :].shape[0]"
how many dog pets are raised by female students?,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: (x['sex']=='f') & (x['pettype']=='dog'), :].shape[0]"
find the number of distinct type of pets.,pets['pettype'].nunique()
how many different types of pet are there?,pets['pettype'].nunique()
find the first name of students who have cat or dog pet.,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: x['pettype'].isin(['cat', 'dog']), 'fname'].unique()"
what are the first names of every student who has a cat or dog as a pet?,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: x['pettype'].isin(['cat', 'dog']), 'fname'].unique()"
find the first name of students who have both cat and dog pets .,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: x['pettype']=='cat', 'fname'].isin(pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: x['pettype']=='dog', 'fname']).unique()"
what are the students' first names who have both cats and dogs as pets?,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: x['pettype']=='cat', 'fname'].intersect(pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: x['pettype']=='dog', 'fname'])"
find the major and age of students who do not have a cat pet.,"student.loc[lambda x: ~x['stuid'].isin(pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: x['pettype']=='cat', 'stuid'] ), ['major', 'age']]"
"what major is every student who does not own a cat as a pet, and also how old are they?","student.loc[lambda x: ~x['stuid'].isin(pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: x['pettype']=='cat', 'stuid'] ), ['major', 'age']]"
find the id of students who do not have a cat pet.,"student[~student['stuid'].isin(has_pet.merge(pets.loc[pets['pettype']=='cat'], on='petid')['stuid'])]['stuid']"
what are the ids of the students who do not own cats as pets?,"student[~student['stuid'].isin(has_pet.merge(pets.loc[pets['pettype']=='cat'], on='petid')['stuid'])]['stuid']"
find the first name and age of students who have a dog but do not have a cat as a pet.,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').query('pettype==""dog"" and stuid not in @pd.merge(pd.merge(student, has_pet, on=""stuid""), pets, on=""petid"").query(""pettype=='cat'"")[""stuid""]')[['fname', 'age']]"
what is the first name of every student who has a dog but does not have a cat?,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').query('pettype==""dog"" and stuid not in @pd.merge(pd.merge(student, has_pet, on=""stuid""), pets, on=""petid"").query(""pettype=='cat'"")[""stuid""]')[['fname', 'age']]"
find the type and weight of the youngest pet.,"pets[['pettype', 'weight', 'pet_age']].sort_values('pet_age').iloc[0][['pettype', 'weight']]"
"what type of pet is the youngest animal, and how much does it weigh?","pets[['pettype', 'weight', 'pet_age']].sort_values('pet_age').iloc[0][['pettype', 'weight']]"
find the id and weight of all pets whose age is older than 1.,"pets.loc[pets['pet_age'] > 1, ['petid', 'weight']]"
what is the id and weight of every pet who is older than 1?,"pets.loc[pets['pet_age'] > 1, ['petid', 'weight']]"
find the average and maximum age for each type of pet.,"pets.groupby('pettype')['pet_age'].agg(['mean', 'max'])"
what is the average and maximum age for each pet type?,"pets.groupby('pettype')['pet_age'].agg(['mean', 'max'])"
find the average weight for each pet type.,"pets.groupby('pettype').agg(avg_weight=('weight', 'mean'))"
what is the average weight for each type of pet?,"pets.groupby('pettype').agg(avg_weight=('weight', 'mean'))"
find the first name and age of students who have a pet.,"pd.merge(student, has_pet, on='stuid')[['fname', 'age']].drop_duplicates()"
what are the different first names and ages of the students who do have pets?,"pd.merge(student, has_pet, on='stuid')[['fname', 'age']].drop_duplicates()"
find the id of the pet owned by student whose last name is ‘smith’.,"pd.merge(student.loc[lambda x: x['lname']=='smith', ['stuid']], has_pet, on='stuid')['petid']"
what is the id of the pet owned by the student whose last name is 'smith'?,"pd.merge(student.loc[lambda x: x['lname']=='smith', ['stuid']], has_pet, on='stuid')['petid']"
find the number of pets for each student who has any pet and student id.,"has_pet.groupby('stuid').size().reset_index(name='count').merge(student, on='stuid')[['count', 'stuid']]"
"for students who have pets , how many pets does each student have ? list their ids instead of names .","has_pet.merge(student, on='stuid').groupby('stuid').size().reset_index(name='count(*)')"
find the first name and gender of student who have more than one pet.,"student.merge(has_pet, on='stuid').groupby(['stuid', 'fname', 'sex']).size().reset_index(name='count').query('count > 1')[['fname', 'sex']]"
what is the first name and gender of the all the students who have more than one pet?,"student.merge(has_pet, on='stuid').groupby(['stuid', 'fname', 'sex']).size().reset_index(name='count').query('count > 1')[['fname', 'sex']]"
find the last name of the student who has a cat that is age 3.,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: (x['pettype']=='cat') & (x['pet_age']==3), 'lname']"
what is the last name of the student who has a cat that is 3 years old?,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: (x['pettype']=='cat') & (x['pet_age']==3), 'lname']"
find the average age of students who do not have any pet .,"student.loc[~student['stuid'].isin(has_pet['stuid']), 'age'].mean()"
what is the average age for all students who do not own any pets ?,"student.loc[~student['stuid'].isin(has_pet['stuid']), 'age'].mean()"
how many continents are there?,continents.shape[0]
what is the number of continents?,continents.shape[0]
"how many countries does each continent have? list the continent id, continent name and the number of countries.","countries.merge(continent, left_on='continent', right_on='contid').groupby(['contid','continent']).size().reset_index(name='count')[['contid','continent','count']]"
"for each continent, list its id, name, and how many countries it has?","countries.merge(continent, left_on='continent', right_on='contid').groupby(['contid','continent']).size().reset_index(name='count')[['contid','continent','count']]"
how many countries are listed?,countries.shape[0]
how many countries exist?,countries.shape[0]
"how many models does each car maker produce? list maker full name, id and the number.","pd.merge(car_makers, model_list, left_on='id', right_on='maker').groupby(['fullname', 'id']).size().reset_index(name='count')"
"what is the full name of each car maker, along with its id and how many models it produces?","pd.merge(car_makers, model_list, left_on='id', right_on='maker').groupby(['fullname', 'id']).size().reset_index(name='count')"
which model of the car has the minimum horsepower?,"pd.merge(car_names, cars_data, left_on='makeid', right_on='id').sort_values('horsepower').iloc[0]['model']"
what is the model of the car with the smallest amount of horsepower?,"pd.merge(car_names, cars_data, left_on='makeid', right_on='id').sort_values('horsepower').iloc[0]['model']"
find the model of the car whose weight is below the average weight.,"car_names.merge(cars_data.query('weight < @cars_data.weight.mean()'), left_on='makeid', right_on='id')['model']"
what is the model for the car with a weight smaller than the average?,"car_names.merge(cars_data.query('weight < @cars_data.weight.mean()'), left_on='makeid', right_on='id')['model']"
find the name of the makers that produced some cars in the year of 1970?,"pd.merge(pd.merge(pd.merge(car_makers, model_list, left_on='id', right_on='maker'), car_names, on='model'), cars_data, left_on='makeid', right_on='id').loc[lambda x: x['year']==1970,'maker'].unique()"
what is the name of the different car makers who produced a car in 1970?,"pd.merge(pd.merge(pd.merge(car_makers, model_list, left_on='id', right_on='maker'), car_names, on='model'), cars_data, left_on='makeid', right_on='id').loc[lambda x: x['year']==1970,'maker'].unique()"
find the make and production time of the cars that were produced in the earliest year?,"cars_data.merge(car_names, left_on='id', right_on='makeid').loc[lambda x: x['year'] == cars_data['year'].min(), ['make', 'year']]"
what is the maker of the carr produced in the earliest year and what year was it?,"cars_data.merge(car_names, left_on='id', right_on='makeid').loc[lambda x: x['year'] == cars_data['year'].min(), ['make', 'year']]"
which distinct car models are the produced after 1980?,"pd.merge(pd.merge(model_list, car_names, on='model'), cars_data, left_on='makeid', right_on='id').loc[lambda x: x['year']>1980, 'model'].unique()"
what are the different models for the cards produced after 1980?,"pd.merge(pd.merge(model_list, car_names, on='model'), cars_data, left_on='makeid', right_on='id').loc[lambda x: x['year']>1980, 'model'].unique()"
how many car makers are there in each continents? list the continent name and the count.,"pd.merge(pd.merge(continents, countries, left_on='contid', right_on='continent'), car_makers, left_on='countryid', right_on='country').groupby('continent').size()"
what is the name of each continent and how many car makers are there in each one?,"pd.merge(pd.merge(continents, countries, left_on='contid', right_on='continent'), car_makers, left_on='countryid', right_on='country').groupby('continent').size()"
which of the countries has the most car makers? list the country name.,"pd.merge(car_makers, countries, left_on='country', right_on='countryid').groupby('countryname').size().reset_index(name='counts').sort_values('counts', ascending=false).iloc[0]['countryname']"
what is the name of the country with the most car makers?,"pd.merge(car_makers, countries, left_on='country', right_on='countryid').groupby('countryname').size().reset_index(name='counts').sort_values('counts', ascending=false).iloc[0]['countryname']"
how many car models are produced by each maker ? only list the count and the maker full name .,"pd.merge(model_list, car_makers, left_on='maker', right_on='id').groupby('fullname').size().reset_index(name='count')"
what is the number of car models that are produced by each maker and what is the id and full name of each maker?,"pd.merge(model_list, car_makers, left_on='maker', right_on='id').groupby(['id', 'fullname'], as_index=false).agg({'index': 'count'}).rename(columns={'index': 'count'})[['count', 'fullname', 'id']]"
what is the accelerate of the car make amc hornet sportabout (sw)?,"cars_data.merge(car_names[car_names['make'] == 'amc hornet sportabout (sw)'], left_on='id', right_on='makeid')['accelerate']"
how much does the car accelerate that makes amc hornet sportabout (sw)?,"cars_data.merge(car_names[car_names['make'] == 'amc hornet sportabout (sw)'], left_on='id', right_on='makeid')['accelerate']"
how many car makers are there in france?,"pd.merge(car_makers, countries, left_on='country', right_on='countryid').loc[lambda x: x['countryname']=='france'].shape[0]"
what is the number of makers of care in france?,"pd.merge(car_makers, countries, left_on='country', right_on='countryid').loc[lambda x: x['countryname']=='france'].shape[0]"
how many car models are produced in the usa?,"pd.merge(pd.merge(model_list, car_makers, left_on='maker', right_on='id'), countries, left_on='country', right_on='countryid').loc[lambda x: x['countryname']=='usa'].shape[0]"
what is the count of the car models produced in the united states?,"pd.merge(pd.merge(model_list, car_makers, left_on='maker', right_on='id'), countries, left_on='country', right_on='countryid').loc[lambda x: x['countryname']=='usa'].shape[0]"
what is the average miles per gallon(mpg) of the cars with 4 cylinders?,"cars_data.loc[cars_data['cylinders']==4, 'mpg'].mean()"
what is the average miles per gallon of all the cards with 4 cylinders?,"cars_data.loc[cars_data['cylinders']==4, 'mpg'].mean()"
what is the smallest weight of the car produced with 8 cylinders on 1974 ?,"cars_data.loc[(cars_data['cylinders'] == 8) & (cars_data['year'] == 1974), 'weight'].min()"
what is the minimum weight of the car with 8 cylinders produced in 1974 ?,"cars_data.loc[(cars_data['cylinders'] == 8) & (cars_data['year'] == 1974), 'weight'].min()"
what are all the makers and models?,"model_list[['maker', 'model']]"
what are the makers and models?,"model_list[['maker', 'model']]"
what are the countries having at least one car maker? list name and id.,"pd.merge(countries, car_makers, on='countryid').groupby(['countryid', 'countryname']).filter(lambda x: len(x) >= 1)[['countryname', 'countryid']].drop_duplicates()"
what are the names and ids of all countries with at least one car maker?,"pd.merge(countries, car_makers, on='countryid').groupby(['countryid', 'countryname']).filter(lambda x: len(x) >= 1)[['countryname', 'countryid']].drop_duplicates()"
what is the number of the cars with horsepower more than 150?,(cars_data['horsepower'] > 150).sum()
what is the number of cars with a horsepower greater than 150?,(cars_data['horsepower'] > 150).sum()
what is the average weight of cars each year?,cars_data.groupby('year')['weight'].mean()
what is the average weight and year for each year?,cars_data.groupby('year')['weight'].mean()
which countries in europe have at least 3 car manufacturers?,"pd.merge(pd.merge(countries, continents, left_on='continent', right_on='contid'), car_makers, left_on='countryid', right_on='country').loc[lambda x: x['continent']=='europe'].groupby('countryname').filter(lambda x: len(x) >= 3)['countryname']"
what are the names of all european countries with at least 3 manufacturers?,"pd.merge(pd.merge(countries, continents, left_on='continent', right_on='contid'), car_makers, left_on='countryid', right_on='country').loc[lambda x: x['continent']=='europe'].groupby('countryname').filter(lambda x: len(x) >= 3)['countryname']"
what is the maximum horsepower and the make of the car models with 3 cylinders?,"pd.merge(car_names, cars_data, left_on='makeid', right_on='id').loc[lambda x: x['cylinders'] == 3, ['horsepower', 'make']].sort_values('horsepower', ascending=false).iloc[0]"
what is the largest amount of horsepower for the models with 3 cylinders and what make is it?,"pd.merge(car_names, cars_data, left_on='makeid', right_on='id').loc[lambda x: x['cylinders'] == 3, ['horsepower', 'make']].sort_values('horsepower', ascending=false).iloc[0]"
"which model saves the most gasoline? that is to say, have the maximum miles per gallon.","car_names.merge(cars_data, left_on='makeid', right_on='id').sort_values('mpg', ascending=false).iloc[0]['model']"
what is the car model with the highest mpg ?,"car_names.loc[car_names['makeid'].isin(cars_data.sort_values('mpg', ascending=false).iloc[[0]]['id']), 'model']"
what is the average horsepower of the cars before 1980?,"cars_data.loc[cars_data['year'] < 1980, 'horsepower'].mean()"
what is the average horsepower for all cars produced before 1980 ?,"cars_data.loc[cars_data['year'] < 1980, 'horsepower'].mean()"
what is the average edispl of the cars of model volvo?,"cars_data.merge(car_names, left_on='id', right_on='makeid').query('model == ""volvo""')['edispl'].mean()"
what is the average edispl for all volvos?,"cars_data.merge(car_names, left_on='id', right_on='makeid').query('model == ""volvo""')['edispl'].mean()"
what is the maximum accelerate for different number of cylinders?,cars_data.groupby('cylinders')['accelerate'].max()
what is the maximum accelerate for all the different cylinders?,cars_data.groupby('cylinders')['accelerate'].max()
which model has the most version(make) of cars?,car_names.groupby('model').size().sort_values(ascending=false).head(1).index[0]
what model has the most different versions?,car_names.groupby('model').size().sort_values(ascending=false).head(1).index[0]
how many cars have more than 4 cylinders?,cars_data['cylinders'].gt(4).sum()
what is the number of cars with more than 4 cylinders?,cars_data['cylinders'].gt(4).sum()
how many cars were produced in 1980?,(cars_data['year'] == 1980).sum()
"in 1980, how many cars were made?",(cars_data['year'] == 1980).sum()
how many car models were produced by the maker with full name american motor company?,"pd.merge(car_makers, model_list, left_on='id', right_on='maker')['id'].loc[lambda x: x['fullname']=='american motor company'].count()"
what is the number of car models created by the car maker american motor company?,"pd.merge(car_makers, model_list, left_on='id', right_on='maker')['id'].loc[lambda x: x['fullname']=='american motor company'].count()"
which makers designed more than 3 car models? list full name and the id.,"car_makers.merge(model_list, on='id').groupby(['fullname', 'id']).filter(lambda x: len(x) > 3).drop_duplicates(['fullname', 'id'])[['fullname', 'id']]"
what are the names and ids of all makers with more than 3 models?,"car_makers.merge(model_list, on='id').groupby(['fullname', 'id']).filter(lambda x: len(x) > 3).drop_duplicates(['fullname', 'id'])[['fullname', 'id']]"
which distinctive models are produced by maker with the full name general motors or weighing more than 3500?,"pd.merge(pd.merge(pd.merge(car_names, model_list, on='model'), car_makers, left_on='maker', right_on='id'), cars_data, left_on='makeid', right_on='id').loc[(lambda x: (x['fullname'] == 'general motors') | (x['weight'] > 3500)), 'model'].unique()"
what are the different models created by either the car maker general motors or weighed more than 3500?,"pd.merge(pd.merge(pd.merge(car_names, model_list, on='model'), car_makers, left_on='maker', right_on='id'), cars_data, left_on='makeid', right_on='id').loc[(lambda x: (x['fullname'] == 'general motors') | (x['weight'] > 3500)), 'model'].unique()"
in which years cars were produced weighing no less than 3000 and no more than 4000 ?,"cars_data.loc[cars_data['weight'].between(3000, 4000), 'year'].unique()"
what are the different years in which there were cars produced that weighed less than 4000 and also cars that weighted more than 3000 ?,"cars_data.loc[cars_data['weight'].between(3000, 4000), 'year'].unique()"
what is the horsepower of the car with the largest accelerate?,"cars_data.sort_values('accelerate', ascending=false).iloc[0]['horsepower']"
what is the horsepower of the car with the greatest accelerate?,"cars_data.sort_values('accelerate', ascending=false).iloc[0]['horsepower']"
"for model volvo, how many cylinders does the car with the least accelerate have?","cars_data.merge(car_names, left_on='id', right_on='makeid').loc[lambda x: x['model']=='volvo'].sort_values('accelerate').iloc[0]['cylinders']"
"for a volvo model, how many cylinders does the version with least accelerate have?","cars_data.merge(car_names, left_on='id', right_on='makeid').loc[lambda x: x['model']=='volvo'].sort_values('accelerate').iloc[0]['cylinders']"
how many cars have a larger accelerate than the car with the largest horsepower?,"(cars_data['accelerate'] > cars_data.sort_values('horsepower', ascending=false)['accelerate'].iloc[0]).sum()"
what is the number of cars with a greater accelerate than the one with the most horsepower?,"(cars_data['accelerate'] > cars_data.sort_values('horsepower', ascending=false)['accelerate'].iloc[0]).sum()"
how many countries has more than 2 car makers ?,"pd.merge(countries, car_makers, left_on='countryid', right_on='country').groupby('countryid').filter(lambda x: len(x) > 2)['countryid'].nunique()"
what is the number of countries with more than 2 car makers ?,"pd.merge(countries, car_makers, left_on='countryid', right_on='country').groupby('countryid').filter(lambda x: len(x) > 2)['countryid'].nunique()"
how many cars has over 6 cylinders?,(cars_data['cylinders'] > 6).sum()
what is the number of carsw ith over 6 cylinders?,(cars_data['cylinders'] > 6).sum()
"for the cars with 4 cylinders, which model has the largest horsepower?","car_names.loc[lambda x: x['makeid'].isin(cars_data.loc[lambda x: x['cylinders']==4, 'id'])].sort_values('horsepower', ascending=false).iloc[0]['model']"
"for all of the 4 cylinder cars, which model has the most horsepower?","car_names.loc[lambda x: x['makeid'].isin(cars_data.loc[lambda x: x['cylinders']==4, 'id'])].sort_values('horsepower', ascending=false).iloc[0]['model']"
"among the cars with more than lowest horsepower, which ones do not have more than 3 cylinders? list the car makeid and make name.","cars_data.merge(car_names, left_on='id', right_on='makeid').loc[lambda x: (x['horsepower'] > cars_data['horsepower'].min()) & (x['cylinders'] <= 3), ['makeid', 'make']]"
"among the cars that do not have the minimum horsepower , what are the make ids and names of all those with less than 4 cylinders ?","cars_data.merge(car_names, left_on='id', right_on='makeid').loc[lambda x: (x['horsepower'] > cars_data['horsepower'].min()) & (x['cylinders'] < 4), ['makeid', 'make']]"
what is the maximum miles per gallon of the car with 8 cylinders or produced before 1980 ?,"cars_data.loc[(cars_data['cylinders'] == 8) | (cars_data['year'] < 1980), 'mpg'].max()"
what is the maximum mpg of the cars that had 8 cylinders or that were produced before 1980 ?,"cars_data.loc[(cars_data['cylinders'] == 8) | (cars_data['year'] < 1980), 'mpg'].max()"
which models are lighter than 3500 but not built by the 'ford motor company'?,"pd.merge(pd.merge(pd.merge(model_list, car_names, on='model'), cars_data, left_on='makeid', right_on='id'), car_makers, left_on='maker', right_on='id').loc[(lambda x: (x['weight'] < 3500) & (x['fullname'] != 'ford motor company'))(x), 'model'].unique()"
what are the different models wthat are lighter than 3500 but were not built by the ford motor company?,"pd.merge(pd.merge(pd.merge(model_list, car_names, on='model'), cars_data, left_on='makeid', right_on='id'), car_makers, left_on='maker', right_on='id').loc[(lambda x: (x['weight'] < 3500) & (x['fullname'] != 'ford motor company'))(x), 'model'].unique()"
what are the name of the countries where there is not a single car maker?,"countries.loc[~countries['countryid'].isin(car_makers['country']), 'countryname']"
what are the names of the countries with no car makers?,"countries.loc[~countries['countryid'].isin(car_makers['country']), 'countryname']"
which are the car makers which produce at least 2 models and more than 3 car makers ? list the id and the maker .,"pd.merge(car_makers, model_list, left_on='id', right_on='maker').groupby(['id', 'maker']).filter(lambda x: len(x) >= 2).merge(model_list, on=['id', 'maker']).merge(car_names, on='model').groupby(['id', 'maker']).filter(lambda x: len(x) > 3)[['id', 'maker']].drop_duplicates()"
what are the ids and makers of all car makers that produce at least 2 models and make more than 3 cars?,"pd.merge(car_makers, model_list, left_on='id', right_on='maker').groupby(['id', 'maker']).filter(lambda group: len(group)>=2).merge(car_names, left_on='model', right_on='model').groupby(['id', 'maker']).filter(lambda group: len(group)>3)[['id', 'maker']].drop_duplicates()"
what are the id and names of the countries which have more than 3 car makers or produce the 'fiat' model?,"pd.concat([countries.merge(car_makers, left_on='countryid', right_on='country').groupby(['countryid', 'countryname']).filter(lambda x: len(x) > 3),countries.merge(car_makers, left_on='countryid', right_on='country').merge(model_list, left_on='id', right_on='maker').loc[lambda x: x['model']=='fiat', ['countryid', 'countryname']].drop_duplicates()])[['countryid', 'countryname']].sort_values('countryid')"
what are the ids and names of all countries that either have more than 3 car makers or produce fiat model ?,"pd.concat([countries.merge(car_makers, how='inner', left_on='countryid', right_on='country').groupby(['countryid', 'countryname']).filter(lambda x: len(x) > 3).drop_duplicates(subset=['countryid', 'countryname'])[['countryid', 'countryname']], countries.merge(car_makers, how='inner', left_on='countryid', right_on='country').merge(model_list, how='inner', left_on='id', right_on='maker').loc[lambda x: x['model'] == 'fiat', ['countryid', 'countryname']]]).drop_duplicates().sort_values('countryid')[['countryid', 'countryname']]"
"which country does airline ""jetblue airways"" belong to?","airlines.loc[lambda x: x['airline']=='jetblue airways', 'country']"
what country is jetblue airways affiliated with?,"airlines.loc[lambda x: x['airline']=='jetblue airways', 'country']"
"what is the abbreviation of airline ""jetblue airways""?","airlines.loc[lambda x: x['airline']=='jetblue airways', 'abbreviation']"
which abbreviation corresponds to jetblue airways?,"airlines.loc[lambda x: x['airline']=='jetblue airways', 'abbreviation']"
"list all airline names and their abbreviations in ""usa"".","airlines.loc[lambda x: x['country'] == 'usa', ['airline', 'abbreviation']]"
what are the airline names and abbreviations for airlines in the usa?,"airlines.loc[lambda x: x['country'] == 'usa', ['airline', 'abbreviation']]"
list the airport code and name in the city of anthony.,"airports.loc[airports['city'] == 'anthony', ['airportcode', 'airportname']]"
give the airport code and airport name corresonding to the city anthony.,"airports.loc[airports['city'] == 'anthony', ['airportcode', 'airportname']]"
how many airlines do we have?,airlines.shape[0]
how many airports do we have?,airports.shape[0]
return the number of  airports.,airports.shape[0]
return the number of flights.,flights.shape[0]
which airline has abbreviation 'ual'?,"airlines.loc[airlines['abbreviation']=='ual', 'airline']"
give the airline with abbreviation 'ual'.,"airlines.loc[airlines['abbreviation']=='ual', 'airline']"
how many airlines are from usa?,(airlines['country'] == 'usa').sum()
return the number of airlines in the usa.,(airlines['country'] == 'usa').sum()
which city and country is the alton airport at?,"airports.loc[lambda x: x['airportname']=='alton', ['city', 'country']]"
give the city and country for the alton airport.,"airports.loc[lambda x: x['airportname']=='alton', ['city', 'country']]"
what is the airport name for airport 'ako'?,"airports.loc[airports['airportcode']=='ako', 'airportname']"
return the name of the airport with code 'ako'.,"airports.loc[airports['airportcode']=='ako', 'airportname']"
what are airport names at city 'aberdeen'?,"airports.loc[airports['city'] == 'aberdeen', 'airportname']"
what are the names of airports in aberdeen?,"airports.loc[airports['city'] == 'aberdeen', 'airportname']"
how many flights depart from 'apg'?,"(flights['sourceairport'] == ""apg"").sum()"
count the number of flights departing from 'apg'.,"(flights['sourceairport'] == ""apg"").sum()"
how many flights have destination ato?,(flights['destairport'] == 'ato').sum()
count the number of flights into ato.,(flights['destairport'] == 'ato').sum()
how many flights depart from city aberdeen?,"pd.merge(flights, airports, left_on='sourceairport', right_on='airportcode').loc[lambda x: x['city']=='aberdeen'].shape[0]"
return the number of flights departing from aberdeen.,"pd.merge(flights, airports, left_on='sourceairport', right_on='airportcode').loc[lambda x: x['city']=='aberdeen'].shape[0]"
how many flights arriving in aberdeen city?,"pd.merge(flights, airports, left_on='destairport', right_on='airportcode').loc[lambda x: x['city']=='aberdeen'].shape[0]"
return the number of flights arriving in aberdeen.,"pd.merge(flights, airports, left_on='destairport', right_on='airportcode').loc[lambda x: x['city']=='aberdeen'].shape[0]"
how many flights depart from city 'aberdeen' and have destination city 'ashley'?,"pd.merge(pd.merge(flights, airports, left_on='destairport', right_on='airportcode'), airports, left_on='sourceairport', right_on='airportcode').loc[(lambda x: x['city_x']=='ashley') & (lambda x: x['city_y']=='aberdeen'), :].shape[0]"
how many flights fly from aberdeen to ashley?,"pd.merge(pd.merge(flights, airports, left_on='destairport', right_on='airportcode'), airports, left_on='sourceairport', right_on='airportcode').loc[(lambda x: x['city_x']=='ashley') & (lambda x: x['city_y']=='aberdeen'), :].shape[0]"
how many flights does airline 'jetblue airways' have?,"pd.merge(flights, airlines, left_on='airline', right_on='uid').loc[lambda x: x['airline']=='jetblue airways'].shape[0]"
give the number of jetblue airways flights.,"pd.merge(flights, airlines, left_on='airline', right_on='uid').loc[lambda x: x['airline']=='jetblue airways'].shape[0]"
how many 'united airlines' flights go to airport 'asy'?,"pd.merge(airlines.loc[lambda x: x['airline']=='united airlines'], flights.loc[lambda x: x['destairport']=='asy'], left_on='uid', right_on='airline').shape[0]"
count the number of united airlines flights arriving in asy airport.,"pd.merge(airlines.loc[lambda x: x['airline']=='united airlines'], flights.loc[lambda x: x['destairport']=='asy'], left_on='uid', right_on='airline').shape[0]"
how many 'united airlines' flights depart from airport 'ahd'?,"pd.merge(airlines, flights, left_on='uid', right_on='airline').loc[(airlines['airline']=='united airlines') & (flights['sourceairport']=='ahd'), :].shape[0]"
return the number of united airlines flights leaving from ahd airport.,"pd.merge(airlines, flights, left_on='uid', right_on='airline').loc[(airlines['airline']=='united airlines') & (flights['sourceairport']=='ahd'), :].shape[0]"
how many united airlines flights go to city 'aberdeen'?,"pd.merge(pd.merge(flights, airports, left_on='destairport', right_on='airportcode'), airlines, left_on='airline', right_on='uid').loc[lambda x: (x['city']=='aberdeen') & (x['airline']=='united airlines')].shape[0]"
count the number of united airlines flights that arrive in aberdeen.,"pd.merge(pd.merge(flights, airports, left_on='destairport', right_on='airportcode'), airlines, left_on='airline', right_on='uid').loc[lambda x: (x['city']=='aberdeen') & (x['airline']=='united airlines')].shape[0]"
which city has most number of arriving flights?,"pd.merge(airports, flights, left_on='airportcode', right_on='destairport').groupby('city').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['city']"
which city has the most frequent destination airport?,"pd.merge(airports, flights, left_on='airportcode', right_on='destairport').groupby('city').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['city']"
which city has most number of departing flights?,"pd.merge(airports, flights, left_on='airportcode', right_on='sourceairport').groupby('city').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['city']"
which city is the most frequent source airport?,"pd.merge(airports, flights, left_on='airportcode', right_on='sourceairport').groupby('city').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['city']"
what is the code of airport that has the highest number of flights?,"flights[['destairport', 'sourceairport']].stack().reset_index(drop=true).drop_duplicates().merge(airports, left_on=0, right_on='airportcode', how='inner').groupby('airportcode').size().sort_values(ascending=false).index[0]"
what is the airport code of the airport with the most flights?,"flights[['destairport', 'sourceairport']].stack().reset_index(drop=true).drop_duplicates().merge(airports, left_on=0, right_on='airportcode', how='inner').groupby('airportcode').size().sort_values(ascending=false).index[0]"
what is the code of airport that has fewest number of flights?,"flights[['destairport', 'sourceairport']].stack().unique().join(airports.set_index('airportcode'), how='inner').groupby('airportcode').size().sort_values().head(1).index[0]"
give the code of the airport with the least flights.,"flights[['destairport', 'sourceairport']].stack().unique().join(airports.set_index('airportcode'), how='inner').groupby('airportcode').size().sort_values().head(1).index[0]"
which airline has most number of flights?,"pd.merge(airlines, flights, left_on='uid', right_on='airline').groupby('airline').size().sort_values(ascending=false).index[0]"
what airline serves the most flights?,"pd.merge(airlines, flights, left_on='uid', right_on='airline').groupby('airline').size().sort_values(ascending=false).index[0]"
find the abbreviation and country of the airline that has fewest number of flights?,"pd.merge(airlines, flights, left_on='uid', right_on='airline').groupby('airline')['abbreviation', 'country'].first().sort_values(by=pd.merge(airlines, flights, left_on='uid', right_on='airline').groupby('airline').size(), ascending=true).head(1)"
what is the abbreviation of the airilne has the fewest flights and what country is it in?,"pd.merge(airlines, flights, left_on='uid', right_on='airline').groupby('airline')['abbreviation', 'country'].first().sort_values(by=pd.merge(airlines, flights, left_on='uid', right_on='airline').groupby('airline').size(), ascending=true).head(1)"
what are airlines that have some flight departing from airport 'ahd'?,"pd.merge(airlines, flights, left_on='uid', right_on='airline').loc[lambda x: x['sourceairport']=='ahd', 'airline']"
which airlines have a flight with source airport ahd?,"pd.merge(airlines, flights, left_on='uid', right_on='airline').loc[lambda x: x['sourceairport']=='ahd', 'airline']"
what are airlines that have flights arriving at airport 'ahd'?,"pd.merge(airlines, flights[flights['destairport']=='ahd'], left_on='uid', right_on='airline')['airline']"
which airlines have a flight with destination airport ahd?,"pd.merge(airlines, flights[flights['destairport']=='ahd'], left_on='uid', right_on='airline')['airline']"
find all airlines that have flights from both airports 'apg' and 'cvo'.,"pd.merge(airlines.loc[lambda x: x['uid'].isin(flights.loc[flights['sourceairport']=='apg', 'airline'].unique())], airlines.loc[lambda x: x['uid'].isin(flights.loc[flights['sourceairport']=='cvo', 'airline'].unique())])['airline']"
which airlines have departing flights from both apg and cvo airports?,"pd.merge(airlines.loc[lambda x: x['uid'].isin(flights.loc[flights['sourceairport']=='apg', 'airline'].unique())], airlines.loc[lambda x: x['uid'].isin(flights.loc[flights['sourceairport']=='cvo', 'airline'].unique())])['airline']"
find all airlines that have flights from airport 'cvo' but not from 'apg'.,"pd.merge(airlines,flights[flights['sourceairport']==""cvo""],left_on='uid', right_on='airline')['airline'].drop_duplicates().reset_index(drop=true).drop(pd.merge(airlines,flights[flights['sourceairport']==""apg""],left_on='uid', right_on='airline')['airline'].drop_duplicates().reset_index(drop=true).index)"
which airlines have departures from cvo but not from apg airports?,"pd.merge(airlines,flights[flights['sourceairport']==""cvo""],left_on='uid', right_on='airline')['airline'].drop_duplicates().reset_index(drop=true).drop(pd.merge(airlines,flights[flights['sourceairport']==""apg""],left_on='uid', right_on='airline')['airline'].drop_duplicates().reset_index(drop=true).index)"
find all airlines that have at least 10 flights.,"airlines.merge(flights, left_on='uid', right_on='airline').groupby('airline').filter(lambda x: len(x) > 10)['airline']"
which airlines have at least 10 flights?,"airlines.merge(flights, left_on='uid', right_on='airline').groupby('airline').filter(lambda x: len(x) > 10)['airline']"
find all airlines that have fewer than 200 flights.,"airlines.merge(flights, left_on='uid', right_on='airline').groupby('airline').filter(lambda x: len(x) < 200)['airline'].unique()"
which airlines have less than 200 flights?,"airlines.merge(flights, left_on='uid', right_on='airline').groupby('airline').filter(lambda x: len(x) < 200)['airline'].unique()"
"what are flight numbers of airline ""united airlines""?","pd.merge(flights, airlines, left_on='airline', right_on='uid').loc[lambda x: x['airline']=='united airlines', 'flightno']"
which flight numbers correspond to united airlines flights?,"pd.merge(flights, airlines, left_on='airline', right_on='uid').loc[lambda x: x['airline']=='united airlines', 'flightno']"
"what are flight numbers of flights departing from airport ""apg""?","flights.loc[lambda x: x['sourceairport']=='apg', 'flightno']"
give the flight numbers of flights leaving from apg.,"flights.loc[lambda x: x['sourceairport']=='apg', 'flightno']"
"what are flight numbers of flights arriving at airport ""apg""?","flights.loc[lambda x: x['destairport']=='apg', 'flightno']"
give the flight numbers of flights landing at apg.,"flights.loc[lambda x: x['destairport']=='apg', 'flightno']"
"what are flight numbers of flights departing from city ""aberdeen ""?","pd.merge(flights, airports, left_on='sourceairport', right_on='airportcode').loc[lambda x: x['city']=='aberdeen', 'flightno']"
give the flight numbers of flights leaving from aberdeen.,"pd.merge(flights, airports, left_on='sourceairport', right_on='airportcode').loc[lambda x: x['city']=='aberdeen', 'flightno']"
"what are flight numbers of flights arriving at city ""aberdeen""?","pd.merge(flights, airports, left_on='destairport', right_on='airportcode').loc[lambda x: x['city']=='aberdeen', 'flightno']"
give the flight numbers of flights arriving in aberdeen.,"pd.merge(flights, airports, left_on='destairport', right_on='airportcode').loc[lambda x: x['city']=='aberdeen', 'flightno']"
find the number of flights landing in the city of aberdeen or abilene.,"pd.merge(flights, airports, left_on='destairport', right_on='airportcode').loc[lambda x: x['city'].isin(['aberdeen', 'abilene']), :].shape[0]"
how many flights land in aberdeen or abilene?,"pd.merge(flights, airports, left_on='destairport', right_on='airportcode').loc[lambda x: x['city'].isin(['aberdeen', 'abilene']), :].shape[0]"
find the name of airports which do not have any flight in and out.,airports[~airports['airportcode'].isin(flights['sourceairport']).append(flights['destairport']).drop_duplicates()]['airportname']
which airports do not have departing or arriving flights?,airports[~airports['airportcode'].isin(flights['sourceairport']).append(flights['destairport']).drop_duplicates()]['airportname']
count the number of employees,employee.shape[0]
sort employee names by their age in ascending order.,employee.sort_values('age')['name']
list the names of employees and sort in ascending order of age.,employee.sort_values('age')['name']
what is the number of employees from each city?,employee.groupby('city').size().reset_index(name='count')
count the number of employees for each city.,employee.groupby('city').size().reset_index(name='count')
which cities do more than one employee under age 30 come from?,employee.loc[lambda x: x['age']<30].groupby('city').filter(lambda x: len(x)>1)['city']
find the cities that have more than one employee under age 30.,employee.loc[lambda x: x['age']<30].groupby('city').filter(lambda x: len(x)>1)['city']
find the number of shops in each location.,shop.groupby('location').size().reset_index(name='count(*)')
how many shops are there in each location?,shop.groupby('location').size().reset_index(name='count(*)')
find the manager name and district of the shop whose number of products is the largest.,"shop.sort_values('number_products', ascending=false).iloc[0][['manager_name', 'district']]"
what are the manager name and district of the shop that sells the largest number of products?,"shop.sort_values('number_products', ascending=false).iloc[0][['manager_name', 'district']]"
find the minimum and maximum number of products of all stores.,"shop['number_products'].agg(['min', 'max'])"
what are the minimum and maximum number of products across all the shops?,"shop['number_products'].agg(['min', 'max'])"
"return the name, location and district of all shops in descending order of number of products.","shop[['name', 'location', 'district']].sort_values('number_products', ascending=false)"
"sort all the shops by number products in descending order, and return the name, location and district of each shop.","shop[['name', 'location', 'district']].sort_values('number_products', ascending=false)"
find the names of stores whose number products is more than the average number of products.,"shop.loc[lambda x: x['number_products'] > x['number_products'].mean(), 'name']"
which shops' number products is above the average? give me the shop names.,"shop.loc[lambda x: x['number_products'] > x['number_products'].mean(), 'name']"
find the name of employee who was awarded the most times in the evaluation.,"employee.merge(evaluation, on='employee_id').groupby('employee_id')['name'].count().idxmax()"
which employee received the most awards in evaluations? give me the employee name.,"employee.merge(evaluation, on='employee_id').groupby('employee_id')['name'].count().idxmax()"
find the name of the employee who got the highest one time bonus.,"employee.merge(evaluation, on='employee_id').sort_values('bonus', ascending=false).iloc[0]['name']"
which employee received the biggest bonus? give me the employee name.,"employee.merge(evaluation, on='employee_id').sort_values('bonus', ascending=false).iloc[0]['name']"
find the names of employees who never won any award in the evaluation.,"employee.loc[~employee['employee_id'].isin(evaluation['employee_id']), 'name']"
what are the names of the employees who never received any evaluation?,"employee.loc[~employee['employee_id'].isin(evaluation['employee_id']), 'name']"
what is the name of the shop that is hiring the largest number of employees?,"hiring.merge(shop, on='shop_id').groupby('shop_id')['name'].count().sort_values(ascending=false).iloc[0]"
which shop has the most employees? give me the shop name.,"hiring.merge(shop, on='shop_id').groupby('shop_id')['name'].count().sort_values(ascending=false).iloc[0]"
find the name of the shops that do not hire any employee.,"shop.loc[~shop['shop_id'].isin(hiring['shop_id']), 'name']"
which shops run with no employees? find the shop names,"shop.loc[~shop['shop_id'].isin(hiring['shop_id']), 'name']"
find the number of employees hired in each shop; show the shop name as well.,"hiring.merge(shop, on='shop_id').groupby('name').size().reset_index(name='count')"
"for each shop, return the number of employees working there and the name of the shop.","hiring.merge(shop, on='shop_id').groupby('name').size().reset_index(name='count')"
what is total bonus given in all evaluations?,evaluation['bonus'].sum()
find the total amount of bonus given in all the evaluations.,evaluation['bonus'].sum()
give me all the information about hiring.,hiring
what is all the information about hiring?,hiring
which district has both stores with less than 3000 products and stores with more than 10000 products?,"shop.loc[shop['number_products'] < 3000, 'district'].interesect(shop.loc[shop['number_products'] > 10000, 'district'])"
find the districts in which there are both shops selling less than 3000 products and shops selling more than 10000 products.,"shop.loc[shop['number_products'] < 3000, 'district'].interesect(shop.loc[shop['number_products'] > 10000, 'district'])"
how many different store locations are there?,shop['location'].nunique()
count the number of distinct store locations.,shop['location'].nunique()
how many documents do we have?,documents.shape[0]
"list document ids, document names, and document descriptions for all documents.","documents[['document_id', 'document_name', 'document_description']]"
"what are the ids, names, and descriptions for all documents?","documents[['document_id', 'document_name', 'document_description']]"
what is the document name and template id for document with description with the letter 'w' in it?,"documents.loc[lambda x: x['document_description'].str.contains('w', case=false), ['document_name', 'template_id']]"
return the names and template ids for documents that contain the letter w in their description.,"documents.loc[lambda x: x['document_description'].str.contains('w', case=false), ['document_name', 'template_id']]"
"what is the document id, template id and description for document named ""robbin cv""?","documents.loc[lambda x: x['document_name']=='robbin cv', ['document_id', 'template_id', 'document_description']]"
"return the document id, template id, and description for the document with the name robbin cv.","documents.loc[lambda x: x['document_name']=='robbin cv', ['document_id', 'template_id', 'document_description']]"
how many different templates do all document use?,documents['template_id'].nunique()
count the number of different templates used for documents.,documents['template_id'].nunique()
how many documents are using the template with type code 'ppt'?,"pd.merge(documents, templates, on='template_id').loc[lambda x: x['template_type_code']=='ppt'].shape[0]"
count the number of documents that use the ppt template type.,"pd.merge(documents, templates, on='template_id').loc[lambda x: x['template_type_code']=='ppt'].shape[0]"
show all template ids and number of documents using each template.,documents.groupby('template_id').size().reset_index(name='count')
"what are all different template ids used for documents, and how many times were each of them used?",documents.groupby('template_id').size().reset_index(name='count')
what is the id and type code for the template used by the most documents?,"pd.merge(documents, templates, on='template_id').groupby('template_id').size().sort_values(ascending=false).index[0], pd.merge(documents, templates, on='template_id')['template_type_code'].iloc[0]"
return the id and type code of the template that is used for the greatest number of documents.,"pd.merge(documents, templates, on='template_id').groupby('template_id').size().sort_values(ascending=false).index[0], pd.merge(documents, templates, on='template_id')['template_type_code'].iloc[0]"
show ids for all templates that are used by more than one document.,documents.groupby('template_id').filter(lambda x: len(x) > 1)['template_id'].unique()
what are the template ids of any templates used in more than a single document?,documents.groupby('template_id').filter(lambda x: len(x) > 1)['template_id'].unique()
show ids for all templates not used by any document.,"pd.concat([templates['template_id'], documents['template_id']]).drop_duplicates(keep=false)"
what are the ids for templates that are not used in any documents?,"pd.concat([templates['template_id'], documents['template_id']]).drop_duplicates(keep=false)"
how many templates do we have?,templates.shape[0]
count the number of templates.,templates.shape[0]
"show template ids, version numbers, and template type codes for all templates.","templates[['template_id', 'version_number', 'template_type_code']]"
"what are the ids, version numbers, and type codes for each template?","templates[['template_id', 'version_number', 'template_type_code']]"
show all distinct template type codes for all templates.,templates['template_type_code'].unique()
what are the different template type codes?,templates['template_type_code'].unique()
what are the ids of templates with template type code pp or ppt?,"templates.loc[lambda x: x['template_type_code'].isin(['pp', 'ppt']), 'template_id']"
return the ids of templates that have the code pp or ppt.,"templates.loc[lambda x: x['template_type_code'].isin(['pp', 'ppt']), 'template_id']"
how many templates have template type code cv?,(templates['template_type_code'] == 'cv').sum()
count the number of templates of the type cv.,(templates['template_type_code'] == 'cv').sum()
what is the version number and template type code for the template with version number later than 5?,"templates.loc[lambda x: x['version_number'] > 5, ['version_number', 'template_type_code']]"
return the version numbers and template type codes of templates with a version number greater than 5.,"templates.loc[lambda x: x['version_number'] > 5, ['version_number', 'template_type_code']]"
show all template type codes and number of templates for each.,templates.groupby('template_type_code').size()
"what are the different template type codes, and how many templates correspond to each?",templates.groupby('template_type_code').size()
which template type code has most number of templates?,templates.groupby('template_type_code').size().sort_values(ascending=false).index[0]
return the type code of the template type that the most templates belong to.,templates.groupby('template_type_code').size().sort_values(ascending=false).index[0]
show all template type codes with less than three templates.,templates.groupby('template_type_code').filter(lambda x: len(x) < 3)['template_type_code'].unique()
what are the codes of template types that have fewer than 3 templates?,templates.groupby('template_type_code').filter(lambda x: len(x) < 3)['template_type_code'].unique()
what the smallest version number and its template type code?,templates.groupby('template_type_code')['version_number'].min()
"return the lowest version number, along with its corresponding template type code.",templates.groupby('template_type_code')['version_number'].min()
"what is the template type code of the template used by document with the name ""data base""?","pd.merge(templates, documents.loc[lambda x: x['document_name']=='data base'], on='template_id').loc[:, 'template_type_code']"
return the template type code of the template that is used by a document named data base.,"pd.merge(templates, documents.loc[lambda x: x['document_name']=='data base'], on='template_id').loc[:, 'template_type_code']"
show all document names using templates with template type code bk.,"pd.merge(templates.loc[lambda x: x['template_type_code']=='bk'], documents, on='template_id')['document_name']"
what are the names of documents that use templates with the code bk?,"pd.merge(templates.loc[lambda x: x['template_type_code']=='bk'], documents, on='template_id')['document_name']"
show all template type codes and the number of documents using each type.,"pd.merge(templates, documents, on='template_id').groupby('template_type_code')['template_id'].count()"
"what are the different template type codes, and how many documents use each type?","pd.merge(templates, documents, on='template_id').groupby('template_type_code')['template_id'].count()"
which template type code is used by most number of documents?,"pd.merge(templates, documents, on='template_id').groupby('template_type_code').size().sort_values(ascending=false).index[0]"
return the code of the template type that is most commonly used in documents.,"pd.merge(templates, documents, on='template_id').groupby('template_type_code').size().sort_values(ascending=false).index[0]"
show all template type codes that are not used by any document.,"templates['template_type_code'].loc[lambda x: ~x.isin(pd.merge(templates, documents, on='template_id')['template_type_code'])]"
what are the codes of template types that are not used for any document?,"templates['template_type_code'].loc[lambda x: ~x.isin(pd.merge(templates, documents, on='template_id')['template_type_code'])]"
show all template type codes and descriptions.,"ref_template_types[['template_type_code', 'template_type_description']]"
what are the type codes and descriptions for all template types?,"ref_template_types[['template_type_code', 'template_type_description']]"
"what is the template type descriptions for template type code ""ad"".","ref_template_types.loc[lambda x: x['template_type_code']=='ad', 'template_type_description']"
return the template type description of the template type with the code ad.,"ref_template_types.loc[lambda x: x['template_type_code']=='ad', 'template_type_description']"
"what is the template type code for template type description ""book"".","ref_template_types.loc[lambda x: x['template_type_description']=='book', 'template_type_code']"
"return the type code of the template type with the description ""book"".","ref_template_types.loc[lambda x: x['template_type_description']=='book', 'template_type_code']"
what are the distinct template type descriptions for the templates ever used by any document?,"pd.merge(pd.merge(ref_template_types, templates, on='template_type_code'), documents, on='template_id')['template_type_description'].unique()"
return the different descriptions for templates that have been used in a document.,"pd.merge(pd.merge(ref_template_types, templates, on='template_type_code'), documents, on='template_id')['template_type_description'].unique()"
"what are the template ids with template type description ""presentation"".","pd.merge(ref_template_types, templates, on='template_type_code').loc[lambda x: x['template_type_description']=='presentation', 'template_id']"
return the ids corresponding to templates with the description 'presentation'.,"pd.merge(ref_template_types, templates, on='template_type_code').loc[lambda x: x['template_type_description']=='presentation', 'template_id']"
how many paragraphs in total?,paragraphs.shape[0]
count the number of paragraphs.,paragraphs.shape[0]
how many paragraphs for the document with name 'summer show'?,"pd.merge(paragraphs, documents, on='document_id').loc[lambda x: x['document_name']=='summer show'].shape[0]"
count the number of paragraphs in the document named 'summer show'.,"pd.merge(paragraphs, documents, on='document_id').loc[lambda x: x['document_name']=='summer show'].shape[0]"
show paragraph details for paragraph with text 'korea ' .,"paragraphs.loc[paragraphs['paragraph_text'].str.contains('korea'), 'other_details']"
what are the details for the paragraph that includes the text 'korea ' ?,"paragraphs.loc[paragraphs['paragraph_text'].str.contains('korea'), 'other_details']"
show all paragraph ids and texts for the document with name 'welcome to ny'.,"pd.merge(paragraphs, documents, on='document_id').loc[lambda x: x['document_name']=='welcome to ny', ['paragraph_id', 'paragraph_text']]"
what are the ids and texts of paragraphs in the document titled 'welcome to ny'?,"pd.merge(paragraphs, documents, on='document_id').loc[lambda x: x['document_name']=='welcome to ny', ['paragraph_id', 'paragraph_text']]"
"show all paragraph texts for the document ""customer reviews"".","paragraphs.merge(documents.query('document_name == ""customer reviews""'), on='document_id')['paragraph_text']"
what are the paragraph texts for the document with the name 'customer reviews'?,"paragraphs.merge(documents.query('document_name == ""customer reviews""'), on='document_id')['paragraph_text']"
show all document ids and the number of paragraphs in each document. order by document id.,paragraphs.groupby('document_id').size().reset_index(name='count').sort_values('document_id')
"return the different document ids along with the number of paragraphs corresponding to each, ordered by id.",paragraphs.groupby('document_id').size().reset_index(name='count').sort_values('document_id')
"show all document ids, names and the number of paragraphs in each document.","pd.merge(paragraphs, documents, on='document_id').groupby(['document_id', 'document_name']).size().reset_index(name='count')"
"what are the ids and names of each document, as well as the number of paragraphs in each?","pd.merge(paragraphs, documents, on='document_id').groupby(['document_id', 'document_name']).size().reset_index(name='count')"
list all document ids with at least two paragraphs.,paragraphs.groupby('document_id').filter(lambda x: len(x) >=2).document_id.unique()
what are the ids of documents that have 2 or more paragraphs?,paragraphs.groupby('document_id').filter(lambda x: len(x) >=2).document_id.unique()
what is the document id and name with greatest number of paragraphs?,"pd.merge(paragraphs, documents, on='document_id').groupby('document_id').size().sort_values(ascending=false).reset_index(name='count').iloc[0][['document_id', 'document_name']]"
return the id and name of the document with the most paragraphs.,"pd.merge(paragraphs, documents, on='document_id').groupby('document_id').size().sort_values(ascending=false).reset_index(name='count').iloc[0][['document_id', 'document_name']]"
what is the document id with least number of paragraphs?,paragraphs.groupby('document_id').size().sort_values().head(1).index[0]
return the id of the document with the fewest paragraphs.,paragraphs.groupby('document_id').size().sort_values().head(1).index[0]
what is the document id with 1 to 2 paragraphs?,paragraphs.groupby('document_id').filter(lambda x: x.shape[0] >= 1 and x.shape[0] <=2)['document_id'].unique()
give the ids of documents that have between one and two paragraphs.,paragraphs.groupby('document_id').filter(lambda x: x.shape[0] >= 1 and x.shape[0] <=2)['document_id'].unique()
show the document id with paragraph text 'brazil' and 'ireland'.,"pd.merge(paragraphs.loc[lambda x: x['paragraph_text']=='brazil', 'document_id'], paragraphs.loc[lambda x: x['paragraph_text']=='ireland', 'document_id'], how='inner')"
what are the ids of documents that contain the paragraph text 'brazil' and 'ireland'?,"pd.merge(paragraphs.loc[lambda x: x['paragraph_text']=='brazil', 'document_id'], paragraphs.loc[lambda x: x['paragraph_text']=='ireland', 'document_id'], how='inner')"
how many teachers are there?,teacher.shape[0]
what is the total count of teachers?,teacher.shape[0]
list the names of teachers in ascending order of age.,teacher.sort_values('age')['name']
what are the names of the teachers ordered by ascending age?,teacher.sort_values('age')['name']
what are the age and hometown of teachers?,"teacher[['age', 'hometown']]"
what is the age and hometown of every teacher?,"teacher[['age', 'hometown']]"
list the name of teachers whose hometown is not `` little lever urban district '' .,"teacher.loc[lambda x: x['hometown'] != 'little lever urban district', 'name']"
what are the names of the teachers whose hometown is not `` little lever urban district '' ?,"teacher.loc[lambda x: x['hometown'] != 'little lever urban district', 'name']"
show the name of teachers aged either 32 or 33?,"teacher.loc[lambda x: x['age'].isin([32,33]), 'name']"
what are the names of the teachers who are aged either 32 or 33?,"teacher.loc[lambda x: x['age'].isin([32,33]), 'name']"
what is the hometown of the youngest teacher?,teacher.sort_values('age')['hometown'].iloc[0]
where is the youngest teacher from?,teacher.sort_values('age')['hometown'].iloc[0]
show different hometown of teachers and the number of teachers from each hometown.,teacher.groupby('hometown').size().reset_index(name='count')
"for each hometown, how many teachers are there?",teacher.groupby('hometown').size().reset_index(name='count')
list the most common hometown of teachers.,teacher.groupby('hometown').size().sort_values(ascending=false).index[0]
what is the most commmon hometowns for teachers?,teacher.groupby('hometown').size().sort_values(ascending=false).index[0]
show the hometowns shared by at least two teachers.,teacher.groupby('hometown').filter(lambda x: len(x) >= 2)['hometown'].unique()
what are the towns from which at least two teachers come from?,teacher.groupby('hometown').filter(lambda x: len(x) >= 2)['hometown'].unique()
show names of teachers and the courses they are arranged to teach.,"pd.merge(pd.merge(course_arrange, course, on='course_id'), teacher, on='teacher_id')[['name', 'course']]"
what is the name of each teacher and what course they teach?,"pd.merge(pd.merge(course_arrange, course, on='course_id'), teacher, on='teacher_id')[['name', 'course']]"
show names of teachers and the courses they are arranged to teach in ascending alphabetical order of the teacher's name.,"pd.merge(pd.merge(course_arrange, course, on='course_id'), teacher, on='teacher_id').sort_values('name')[['name', 'course']]"
what are the names of the teachers and the courses they teach in ascending alphabetical order by the name of the teacher?,"pd.merge(pd.merge(course_arrange, course, on='course_id'), teacher, on='teacher_id').sort_values('name')[['name', 'course']]"
show the name of the teacher for the math course.,"pd.merge(pd.merge(course_arrange, course, on='course_id'), teacher, on='teacher_id').loc[lambda x: x['course']=='math', 'name']"
what are the names of the people who teach math courses?,"pd.merge(pd.merge(course_arrange, course, on='course_id'), teacher, on='teacher_id').loc[lambda x: x['course']=='math', 'name']"
show names of teachers and the number of courses they teach.,"pd.merge(course_arrange, teacher, on='teacher_id').groupby('name').size()"
what are the names of the teachers and how many courses do they teach?,"pd.merge(course_arrange, teacher, on='teacher_id').groupby('name').size()"
show names of teachers that teach at least two courses.,"pd.merge(course_arrange, teacher, on='teacher_id').groupby('name').filter(lambda x: len(x) >= 2)['name'].unique()"
what are the names of the teachers who teach at least two courses?,"pd.merge(course_arrange, teacher, on='teacher_id').groupby('name').filter(lambda x: len(x) >= 2)['name'].unique()"
list the names of teachers who have not been arranged to teach courses.,teacher[~teacher['teacher_id'].isin(course_arrange['teacher_id'])]['name']
what are the names of the teachers whose courses have not been arranged?,teacher[~teacher['teacher_id'].isin(course_arrange['teacher_id'])]['name']
how many visitors below age 30 are there?,(visitor['age'] < 30).sum()
"find the names of the visitors whose membership level is higher than 4, and order the results by the level from high to low.","visitor.loc[lambda x: x['level_of_membership'] > 4].sort_values('level_of_membership', ascending=false)['name']"
what is the average age of the visitors whose membership level is not higher than 4?,"visitor.loc[lambda x: x['level_of_membership'] <= 4, 'age'].mean()"
"find the name and membership level of the visitors whose membership level is higher than 4, and sort by their age from old to young.","visitor.loc[lambda x: x['level_of_membership']>4, ['name', 'level_of_membership']].sort_values('age', ascending=false)"
find the id and name of the museum that has the most staff members?,"museum[['museum_id', 'name']].sort_values('num_of_staff', ascending=false).iloc[0]"
find the average number of staff working for the museums that were open before 2009.,"museum.loc[museum['open_year'] < 2009, 'num_of_staff'].mean()"
what are the opening year and staff number of the museum named plaza museum?,"museum.loc[museum['name']=='plaza museum', ['num_of_staff', 'open_year']]"
find the names of museums which have more staff than the minimum staff number of all museums opened after 2010.,"museum.loc[lambda x: x['num_of_staff'] > museum.loc[lambda y: y['open_year']>2010, 'num_of_staff'].min(), 'name']"
"find the id, name and age for visitors who visited some museums more than once.","visitor.merge(visit, on='id').groupby(['id', 'name', 'age']).filter(lambda x: len(x) > 1).drop_duplicates(subset=['id', 'name', 'age']).loc[:, ['id', 'name', 'age']]"
"what are the id, name and membership level of visitors who have spent the largest amount of money in total in all museum tickets?","visitor.merge(visit, on='id').groupby(['visitor_id', 'name', 'level_of_membership']).agg({'total_spent': 'sum'}).reset_index().sort_values('total_spent', ascending=false).iloc[0, [0, 1, 2]]"
what are the id and name of the museum visited most times?,"pd.merge(museum, visit, on='museum_id').groupby('museum_id')['name'].count().nlargest(1).reset_index(name='count').merge(museum, on='museum_id')[['museum_id', 'name']]"
what is the name of the museum that had no visitor yet?,"museum.loc[~museum['museum_id'].isin(visit['museum_id']), 'name']"
find the name and age of the visitor who bought the most tickets at once.,"pd.merge(visitor, visit, on='id').sort_values('num_of_ticket', ascending=false).iloc[0][['name', 'age']]"
what are the average and maximum number of tickets bought in all visits?,"visit['num_of_ticket'].agg(['mean', 'max'])"
what is the total ticket expense of the visitors whose membership level is 1?,"pd.merge(visitor[visitor['level_of_membership']==1], visit, left_on='id', right_on='visitor_id')['total_spent'].sum()"
what is the name of the visitor who visited both a museum opened before 2009 and a museum opened after 2011?,"visitor.loc[pd.merge(pd.merge(visit, museum.loc[lambda x: x['open_year']<2009]), visitor, left_on='visitor_id', right_on='id')['name_x'].unique().tolist() & pd.merge(pd.merge(visit, museum.loc[lambda x: x['open_year']>2011]), visitor, left_on='visitor_id', right_on='id')['name_x'].unique().tolist()].name"
find the number of visitors who did not visit any museum opened after 2010.,"visitor.loc[~visitor['id'].isin(visit.loc[museum['open_year']>2010, 'visitor_id']), :].shape[0]"
how many museums were opened after 2013 or before 2008?,((museum['open_year'] > 2013) | (museum['open_year'] < 2008)).sum()
find the total number of players.,players.shape[0]
find the total number of matches.,matches.shape[0]
count the number of matches.,matches.shape[0]
list the first name and birth date of all players from the country with code usa.,"players.loc[lambda x: x['country_code']=='usa', ['first_name', 'birth_date']]"
what are the first names and birth dates of players from the usa?,"players.loc[lambda x: x['country_code']=='usa', ['first_name', 'birth_date']]"
find the average age of losers and winners of all matches.,"matches.agg({'loser_age': 'mean', 'winner_age': 'mean'})"
what are the average ages of losers and winners across matches?,"matches.agg({'loser_age': 'mean', 'winner_age': 'mean'})"
find the average rank of winners in all matches.,matches['winner_rank'].mean()
what is the average rank for winners in all matches?,matches['winner_rank'].mean()
find the highest rank of losers in all matches.,matches['loser_rank'].min()
what is the best rank of losers across all matches?,matches['loser_rank'].min()
find the number of distinct country codes of all players.,players['country_code'].nunique()
how many distinct countries do players come from?,players['country_code'].nunique()
find the number of distinct name of losers.,matches['loser_name'].nunique()
how many different loser names are there?,matches['loser_name'].nunique()
find the name of tourney that has more than 10 matches.,matches.groupby('tourney_name').filter(lambda x: x['tourney_name'].count()>10)['tourney_name'].unique()
what are the names of tournaments that have more than 10 matches?,matches.groupby('tourney_name').filter(lambda x: x['tourney_name'].count()>10)['tourney_name'].unique()
list the names of all winners who played in both 2013 and 2016.,matches[matches['year']==2013]['winner_name'].interesect(matches[matches['year']==2016]['winner_name'])
what are the names of players who won in both 2013 and 2016?,matches[matches['year']==2013]['winner_name'].interesect(matches[matches['year']==2016]['winner_name'])
list the number of all matches who played in years of 2013 or 2016.,"matches.loc[matches['year'].isin([2013, 2016])].shape[0]"
how many matches were played in 2013 or 2016?,"matches.loc[matches['year'].isin([2013, 2016])].shape[0]"
what are the country code and first name of the players who won in both tourney wta championships and australian open?,"pd.merge(players.loc[lambda x: x['player_id'].isin(matches.loc[lambda y: y['tourney_name']=='wta championships', 'winner_id']), ['country_code', 'first_name']],players.loc[lambda x: x['player_id'].isin(matches.loc[lambda y: y['tourney_name']=='australian open', 'winner_id']), ['country_code', 'first_name']],on=['country_code', 'first_name'])"
what are the first names and country codes for players who won both the wta championships and the australian open?,"pd.merge(players.loc[lambda x: x['player_id'].isin(matches.loc[lambda y: y['tourney_name']=='wta championships', 'winner_id']), ['country_code', 'first_name']],players.loc[lambda x: x['player_id'].isin(matches.loc[lambda y: y['tourney_name']=='australian open', 'winner_id']), ['country_code', 'first_name']],on=['country_code', 'first_name'])"
find the first name and country code of the oldest player.,"players[['first_name', 'country_code']].sort_values('birth_date').head(1)"
what is the first name and country code of the oldest player?,"players[['first_name', 'country_code']].sort_values('birth_date').head(1)"
list the first and last name of all players in the order of birth date.,"players[['first_name', 'last_name']].sort_values('birth_date')"
"what are the full names of all players, sorted by birth date?","players[['first_name', 'last_name']].sort_values('birth_date')"
list the first and last name of all players who are left / l hand in the order of birth date.,"players.loc[lambda x: x['hand']=='l', ['first_name', 'last_name']].sort_values('birth_date')"
"what are the full names of all left handed players, in order of birth date?","players.loc[lambda x: x['hand']=='l', ['first_name', 'last_name']].sort_values('birth_date')"
find the first name and country code of the player who did the most number of tours.,"pd.merge(players, rankings, on='player_id').sort_values('tours', ascending=false).iloc[0][['country_code', 'first_name']]"
what is the first name and country code of the player with the most tours?,"pd.merge(players, rankings, on='player_id').sort_values('tours', ascending=false).iloc[0][['country_code', 'first_name']]"
find the year that has the most number of matches.,matches.groupby('year').size().sort_values(ascending=false).index[0]
which year had the most matches?,matches.groupby('year').size().sort_values(ascending=false).index[0]
find the name and rank points of the winner who won the most times.,matches.groupby('winner_name')['winner_rank_points'].agg(lambda x: x.sum()).sort_values(ascending=false).iloc[:1]
"what is the name of the winner who has won the most matches, and how many rank points does this player have?",matches.groupby('winner_name')['winner_rank_points'].agg(lambda x: x.sum()).sort_values(ascending=false).iloc[:1]
find the name of the winner who has the highest rank points and participated in the australian open tourney.,"matches.loc[lambda x: x['tourney_name']=='australian open', 'winner_name'].sort_values(ascending=false).iloc[0]"
what is the name of the winner with the most rank points who participated in the australian open tournament?,"matches.loc[lambda x: x['tourney_name']=='australian open', 'winner_name'].sort_values(ascending=false).iloc[0]"
find the names of loser and winner who played in the match with greatest number of minutes.,"matches.sort_values('minutes', ascending=false).iloc[0][['winner_name', 'loser_name']]"
what are the names of the winner and loser who played in the longest match?,"matches.sort_values('minutes', ascending=false).iloc[0][['winner_name', 'loser_name']]"
find the average ranking for each player and their first name.,"pd.merge(players, rankings, on='player_id').groupby('first_name')['ranking'].mean()"
"what are the first names of all players, and their average rankings?","pd.merge(players, rankings, on='player_id').groupby('first_name')['ranking'].mean()"
find the total ranking points for each player and their first name.,"pd.merge(players, rankings, on='player_id').groupby('first_name')['ranking_points'].sum()"
"what are the first names of all players, and their total ranking points?","pd.merge(players, rankings, on='player_id').groupby('first_name')['ranking_points'].sum()"
find the number of players for each country.,players.groupby('country_code').size().reset_index(name='count')
find the code of the country where has the greatest number of players.,players.groupby('country_code').size().sort_values(ascending=false).index[0]
what is the code of the country with the most players?,players.groupby('country_code').size().sort_values(ascending=false).index[0]
find the codes of countries that have more than 50 players.,players.groupby('country_code').filter(lambda x: len(x) > 50)['country_code'].unique()
what are the codes of countries with more than 50 players?,players.groupby('country_code').filter(lambda x: len(x) > 50)['country_code'].unique()
find the total number of tours for each ranking date.,rankings.groupby('ranking_date')['tours'].sum()
how many total tours were there for each ranking date?,rankings.groupby('ranking_date')['tours'].sum()
find the number of matches happened in each year.,matches.groupby('year').size().reset_index(name='count')
how many matches were played in each year?,matches.groupby('year').size().reset_index(name='count')
find the name and rank of the 3 youngest winners across all matches.,"matches[['winner_name', 'winner_rank', 'winner_age']].drop_duplicates().sort_values('winner_age').iloc[:3][['winner_name', 'winner_rank']]"
what are the names and ranks of the three youngest winners across all matches?,"matches[['winner_name', 'winner_rank', 'winner_age']].drop_duplicates().sort_values('winner_age').iloc[:3][['winner_name', 'winner_rank']]"
how many different winners both participated in the wta championships and were left handed?,"matches.loc[(matches['tourney_name']=='wta championships')&(matches['winner_hand']=='l'), 'winner_name'].nunique()"
find the number of left handed winners who participated in the wta championships.,"matches.loc[(matches['tourney_name']=='wta championships')&(matches['winner_hand']=='l'), 'winner_name'].nunique()"
"find the first name, country code and birth date of the winner who has the highest rank points in all matches.","pd.merge(players, matches, left_on='player_id', right_on='winner_id').sort_values('winner_rank_points', ascending=false).iloc[0][['first_name', 'country_code', 'birth_date']]"
"what is the first name, country code, and birth date of the player with the most winner rank points across all matches?","pd.merge(players, matches, left_on='player_id', right_on='winner_id').sort_values('winner_rank_points', ascending=false).iloc[0][['first_name', 'country_code', 'birth_date']]"
find the number of players for each hand type.,players.groupby('hand').size().reset_index(name='count')
how many players are there for each hand type?,players.groupby('hand').size().reset_index(name='count')
how many ships ended up being 'captured'?,(ship['disposition_of_ship'] == 'captured').sum()
list the name and tonnage ordered by in descending alphaetical order for the names.,"ship[['name', 'tonnage']].sort_values('name', ascending=false)"
"list the name, date and result of each battle.","battle[['name', 'date']]"
what is maximum and minimum death toll caused each time?,"death['killed'].agg(['max', 'min'])"
what is the average number of injuries caused each time?,death['injured'].mean()
what are the death and injury situations caused by the ship with tonnage 't'?,"pd.merge(death, ship, left_on='caused_by_ship_id', right_on='id').query('tonnage==""t""')[['killed','injured']]"
what are the name and results of the battles when the bulgarian commander is not 'boril',"battle.loc[battle['bulgarian_commander'] != 'boril', ['name', 'result']]"
what are the different ids and names of the battles that lost any 'brig' type shipes?,"pd.merge(battle, ship.loc[lambda x: x['ship_type'] == 'brig'], left_on='id', right_on='lost_in_battle')[['id', 'name']].drop_duplicates()"
what are the ids and names of the battles that led to more than 10 people killed in total.,"pd.merge(pd.merge(battle, ship, left_on='id', right_on='lost_in_battle'), death, left_on='lost_in_battle', right_on='caused_by_ship_id').groupby(['id', 'name']).sum().loc[lambda x: x['killed'] > 10].reset_index()[['id', 'name']]"
what is the ship id and name that caused most total injuries?,"death.merge(ship, left_on='caused_by_ship_id', right_on='id').groupby(['id', 'name']).size().sort_values(ascending=false).head(1).reset_index()[['id', 'name']]"
what are the distinct battle names which are between bulgarian commander 'kaloyan' and latin commander 'baldwin i'?,"battle.loc[(battle['bulgarian_commander'] == 'kaloyan') & (battle['latin_commander'] == 'baldwin i'), 'name']"
how many different results are there for the battles?,battle['result'].nunique()
how many battles did not lose any ship with tonnage '225'?,"len(battle[~battle['id'].isin(ship.loc[ship['tonnage']==225, 'lost_in_battle'])])"
list the name and date the battle that has lost the ship named 'lettice' and the ship named 'hms atalanta',"pd.merge(battle[battle['id'].isin(ship.query(""name == 'lettice' or name == 'hms atalanta'"")['lost_in_battle'])].query(""name == 'lettice'"").loc[:, ['name', 'date']], battle[battle['id'].isin(ship.query(""name == 'lettice' or name == 'hms atalanta'"")['lost_in_battle'])].query(""name == 'hms atalanta'"").loc[:, ['name', 'date']]).reset_index(drop=true)"
"show names, results and bulgarian commanders of the battles with no ships lost in the 'english channel'.","battle.merge(ship, left_on='id', right_on='lost_in_battle', how='left', indicator=true).loc[lambda x: x['_merge']=='left_only', ['name', 'result', 'bulgarian_commander']].reset_index(drop=true)"
what are the notes of the death events which has substring 'east'?,"death.loc[death['note'].str.contains('east'), 'note']"
what are all the addresses including line 1 and line 2?,"addresses[['line_1', 'line_2']]"
what is the first and second line for all addresses?,"addresses[['line_1', 'line_2']]"
how many courses in total are listed?,courses.shape[0]
how many courses are there?,courses.shape[0]
how is the math course described?,"courses.loc[courses['course_name'] == 'math', 'course_description']"
what are the descriptions for all the math courses?,"courses.loc[courses['course_name'] == 'math', 'course_description']"
what is the zip code of the address in the city port chelsea?,"addresses.loc[lambda x: x['city']=='port chelsea', 'zip_postcode']"
what is the zip code for port chelsea?,"addresses.loc[lambda x: x['city']=='port chelsea', 'zip_postcode']"
which department offers the most number of degrees? list department name and id.,"pd.merge(degree_programs, departments, on='department_id').groupby('department_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['department_name', 'department_id']]"
what is the name and id of the department with the most number of degrees ?,"degree_programs.merge(departments, on='department_id').groupby('department_name')['department_id'].count().sort_values(ascending=false).head(1).reset_index()[['department_name', 'department_id']]"
how many departments offer any degree?,degree_programs['department_id'].nunique()
how many different departments offer degrees?,degree_programs['department_id'].nunique()
how many different degree names are offered?,degree_programs['degree_summary_name'].nunique()
how many different degrees are offered?,degree_programs['degree_summary_name'].nunique()
how many degrees does the engineering department offer?,"department.loc[lambda x: x['department_name']=='engineer'].merge(degree_program, on='department_id').shape[0]"
how many degrees does the engineering department have?,"department.loc[lambda x: x['department_name']=='engineer'].merge(degree_program, on='department_id').shape[0]"
what are the names and descriptions of all the sections?,"sections[['section_name', 'section_description']]"
what are the names and descriptions for all the sections?,"sections[['section_name', 'section_description']]"
what are the names and id of courses having at most 2 sections?,"pd.merge(courses, sections, on='course_id').groupby(['course_id', 'course_name']).filter(lambda x: len(x) <= 2)[['course_id', 'course_name']].drop_duplicates()"
what are the names and ids of every course with less than 2 sections?,"pd.merge(courses, sections, on='course_id').groupby(['course_id', 'course_name']).filter(lambda x: len(x) <= 2)[['course_id', 'course_name']].drop_duplicates()"
list the section_name in reversed lexicographical order.,"sections.sort_values('section_name', ascending=false)['section_name']"
what are the names of the sections in reverse alphabetical order?,"sections.sort_values('section_name', ascending=false)['section_name']"
what is the semester which most student registered in? show both the name and the id.,"pd.merge(semesters, student_enrolment, on='semester_id').groupby('semester_id').agg({'semester_name': 'first', 'semester_id': 'count'}).sort_values('semester_id', ascending=false).iloc[0][['semester_name', 'semester_id']]"
"for each semester, what is the name and id of the one with the most students registered?","pd.merge(semesters, student_enrolment, on='semester_id').groupby('semester_id').agg({'semester_name': 'first', 'semester_id': 'count'}).sort_values('semester_id', ascending=false).iloc[0][['semester_name', 'semester_id']]"
what is the description of the department whose name has the substring the computer?,"departments.loc[departments['department_name'].str.contains('computer'), 'department_description']"
what is the department description for the one whose name has the word computer?,"departments.loc[departments['department_name'].str.contains('computer'), 'department_description']"
"who are enrolled in 2 degree programs in one semester? list the first name, middle name and last name and the id.","students.merge(student_enrolment, on='student_id').groupby(['first_name', 'middle_name', 'last_name', 'student_id']).filter(lambda x: len(x) == 2)[['first_name', 'middle_name', 'last_name', 'student_id']]"
"what are the first, middle, and last names, along with the ids, of all students who enrolled in 2 degree programs in one semester?","students.merge(student_enrolment, on='student_id').groupby(['first_name', 'middle_name', 'last_name', 'student_id']).filter(lambda x: len(x) == 2)[['first_name', 'middle_name', 'last_name', 'student_id']]"
"who is enrolled in a bachelor degree program? list the first name, middle name, last name.","pd.merge(pd.merge(students, student_enrollment, on='student_id'), degree_programs, on='degree_program_id').loc[lambda x: x['degree_summary_name']=='bachelor', ['first_name', 'middle_name', 'last_name']].drop_duplicates()"
"what are the first, middle, and last names for everybody enrolled in a bachelors program?","pd.merge(pd.merge(students, student_enrollment, on='student_id'), degree_programs, on='degree_program_id').loc[lambda x: x['degree_summary_name']=='bachelor', ['first_name', 'middle_name', 'last_name']].drop_duplicates()"
find the kind of program which most number of students are enrolled in?,"pd.merge(degree_programs, student_enrolment, on='degree_program_id').groupby('degree_summary_name').size().sort_values(ascending=false).index[0]"
what is the degree summary name that has the most number of students enrolled?,"pd.merge(degree_programs, student_enrolment, on='degree_program_id').groupby('degree_summary_name').size().sort_values(ascending=false).index[0]"
find the program which most number of students are enrolled in. list both the id and the summary.,"pd.merge(degree_programs, student_enrolment, on='degree_program_id').groupby('degree_program_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['degree_program_id', 'degree_summary_name']]"
what is the program id and the summary of the degree that has the most students enrolled?,"pd.merge(degree_programs, student_enrolment, on='degree_program_id').groupby('degree_program_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['degree_program_id', 'degree_summary_name']]"
"which student has enrolled for the most times in any program? list the id, first name, middle name, last name, the number of enrollments and student id.","students_enrolment.groupby('student_id').size().reset_index(name='count').merge(students, on='student_id').sort_values('count', ascending=false).iloc[0][['student_id', 'first_name', 'middle_name', 'last_name', 'count', 'student_id']]"
"what is the first, middle, and last name, along with the id and number of enrollments, for the student who enrolled the most in any program?","students_enrolment.groupby('student_id').size().reset_index(name='count').merge(students, on='student_id').sort_values('count', ascending=false).iloc[0][['student_id', 'first_name', 'middle_name', 'last_name', 'count', 'student_id']]"
which semesters do not have any student enrolled? list the semester name.,"semesters.loc[~semesters['semester_id'].isin(student_enrolment['semester_id']), 'semester_name']"
what is the name of the semester with no students enrolled?,"semesters.loc[~semesters['semester_id'].isin(student_enrolment['semester_id']), 'semester_name']"
what are all the course names of the courses which ever have students enrolled in?,"pd.merge(courses, student_enrolment_courses, on='course_id')['course_name'].unique()"
what are the names of all courses that have some students enrolled?,"pd.merge(courses, student_enrolment_courses, on='course_id')['course_name'].unique()"
what's the name of the course with most number of enrollments?,"pd.merge(courses, student_enrolment_courses, on='course_id').groupby('course_name').size().sort_values(ascending=false).index[0]"
what is the name of the course with the most students enrolled?,"pd.merge(courses, student_enrolment_courses, on='course_id').groupby('course_name').size().sort_values(ascending=false).index[0]"
find the last name of the students who currently live in the state of north carolina but have not registered in any degree program.,"students.merge(addresses, left_on='current_address_id', right_on='address_id').loc[lambda x: x['state_province_county']=='northcarolina', 'last_name'].drop_duplicates().append(students.merge(student_enrolment, on='student_id').drop_duplicates(subset=['student_id']).loc[:, 'last_name']).drop_duplicates(keep=false)"
what are the last name of the students who live in north carolina but have not registered in any degree programs?,"students.merge(addresses, left_on='current_address_id', right_on='address_id').loc[lambda x: x['state_province_county']=='northcarolina', 'last_name'].drop_duplicates().append(students.merge(student_enrolment, on='student_id').drop_duplicates(subset=['student_id']).loc[:, 'last_name']).drop_duplicates(keep=false)"
show the date and id of the transcript with at least 2 course results.,"pd.merge(transcript_contents, transcripts, on='transcript_id').groupby('transcript_id').filter(lambda x: len(x)>=2)[['transcript_date', 'transcript_id']]"
what is the date and id of the transcript with at least 2 courses listed?,"pd.merge(transcript_contents, transcripts, on='transcript_id').groupby('transcript_id').filter(lambda x: len(x)>=2)[['transcript_date', 'transcript_id']]"
what is the phone number of the man with the first name timmothy and the last name ward?,"students.loc[(students['first_name']=='timmothy') & (students['last_name']=='ward'), 'cell_mobile_number']"
what is the mobile phone number of the student named timmothy ward ?,"students.loc[(students['first_name']=='timmothy') & (students['last_name']=='ward'), 'cell_mobile_number']"
"who is the first student to register? list the first name, middle name and last name.",students.sort_values('date_first_registered')['first_name':'last_name'].iloc[:1]
"what is the first, middle, and last name of the first student to register?",students.sort_values('date_first_registered')['first_name':'last_name'].iloc[:1]
"who is the earliest graduate of the school? list the first name, middle name and last name.","students.sort_values('date_left').iloc[0, ['first_name', 'middle_name', 'last_name']]"
"what is the first, middle, and last name of the earliest school graduate?","students.sort_values('date_left').iloc[0, ['first_name', 'middle_name', 'last_name']]"
whose permanent address is different from his or her current address? list his or her first name.,"students.loc[students['current_address_id'] != students['permanent_address_id'], 'first_name']"
what is the first name of the student whose permanent address is different from his or her current one?,"students.loc[students['current_address_id'] != students['permanent_address_id'], 'first_name']"
which address holds the most number of students currently? list the address id and all lines.,"addresses.merge(students, left_on='address_id', right_on='current_address_id').groupby(['address_id', 'line_1', 'line_2']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['address_id', 'line_1', 'line_2']]"
"what is the id, line 1, and line 2 of the address with the most students?","addresses.merge(students, left_on='address_id', right_on='current_address_id').groupby(['address_id', 'line_1', 'line_2']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['address_id', 'line_1', 'line_2']]"
"on average, when were the transcripts printed?",transcripts['transcript_date'].mean()
what is the average transcript date?,transcripts['transcript_date'].mean()
when is the first transcript released? list the date and details.,"transcripts[['transcript_date', 'other_details']].sort_values('transcript_date').iloc[0]"
"what is the earliest date of a transcript release, and what details can you tell me?","transcripts[['transcript_date', 'other_details']].sort_values('transcript_date').iloc[0]"
how many transcripts are released?,transcripts.shape[0]
how many transcripts are listed?,transcripts.shape[0]
what is the last transcript release date?,transcripts['transcript_date'].sort_values(ascending=false).iloc[0]
when was the last transcript released?,transcripts['transcript_date'].sort_values(ascending=false).iloc[0]
how many times at most can a course enrollment result show in different transcripts? also show the course enrollment id.,"transcript_contents.groupby('student_course_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
what is the maximum number of times that a course shows up in different transcripts and what is that course's enrollment id?,"transcript_contents.groupby('student_course_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
"show the date of the transcript which shows the least number of results, also list the id.","pd.merge(transcript_contents, transcripts, on='transcript_id').groupby('transcript_id').size().sort_values().reset_index(name='count').iloc[0, :][['transcript_date', 'transcript_id']]"
what is the date and id of the transcript with the least number of results?,"pd.merge(transcript_contents, transcripts, on='transcript_id').groupby('transcript_id').size().sort_values().reset_index(name='count').iloc[0, :][['transcript_date', 'transcript_id']]"
find the semester when both master students and bachelor students got enrolled in.,"pd.merge(student_enrollment.loc[student_enrollment['degree_program_id'].isin(degree_programs.loc[degree_programs['degree_summary_name']=='master', 'degree_program_id'].unique()), ['semester_id']].drop_duplicates(), student_enrollment.loc[student_enrollment['degree_program_id'].isin(degree_programs.loc[degree_programs['degree_summary_name']=='bachelor', 'degree_program_id'].unique()), ['semester_id']].drop_duplicates(), on='semester_id')['semester_id']"
what is the id of the semester that had both masters and bachelors students enrolled?,"pd.merge(student_enrollment.loc[student_enrollment['degree_program_id'].isin(degree_programs.loc[degree_programs['degree_summary_name']=='master', 'degree_program_id'].unique()), ['semester_id']].drop_duplicates(), student_enrollment.loc[student_enrollment['degree_program_id'].isin(degree_programs.loc[degree_programs['degree_summary_name']=='bachelor', 'degree_program_id'].unique()), ['semester_id']].drop_duplicates(), on='semester_id')['semester_id']"
how many different addresses do the students currently live?,students['current_address_id'].nunique()
what are the different addresses that have students living there?,students['current_address_id'].nunique()
list all the student details in reversed lexicographical order.,students['other_student_details'].sort_values(ascending=false)
what other details can you tell me about students in reverse alphabetical order?,students['other_student_details'].sort_values(ascending=false)
describe the section h.,"sections.loc[lambda x: x['section_name']=='h', 'section_description']"
what is the description for the section named h?,"sections.loc[lambda x: x['section_name']=='h', 'section_description']"
find the first name of the students who permanently live in the country haiti or have the cell phone number 09700166582 .,"students.merge(addresses, left_on='permanent_address_id', right_on='address_id').loc[lambda x: (x['country']=='haiti') | (x['cell_mobile_number']=='09700166582'), 'first_name']"
what are the first names of the students who live in haiti permanently or have the cell phone number 09700166582 ?,"students.merge(addresses, left_on='permanent_address_id', right_on='address_id').loc[lambda x: (x['country']=='haiti') | (x['cell_mobile_number']=='09700166582'), 'first_name']"
list the title of all cartoons in alphabetical order.,cartoon.sort_values('title')['title']
what are the titles of the cartoons sorted alphabetically?,cartoon.sort_values('title')['title']
"list all cartoon directed by ""ben jones"".","cartoon.loc[lambda x: x['directed_by']=='ben jones', 'title']"
what are the names of all cartoons directed by ben jones?,"cartoon.loc[lambda x: x['directed_by']=='ben jones', 'title']"
"how many cartoons were written by ""joseph kuhr""?",(cartoon['written_by'] == 'joseph kuhr').sum()
what is the number of cartoones written by joseph kuhr?,(cartoon['written_by'] == 'joseph kuhr').sum()
list all cartoon titles and their directors ordered by their air date,"cartoon[['title', 'directed_by']].sort_values('original_air_date')"
what is the name and directors of all the cartoons that are ordered by air date?,"cartoon[['title', 'directed_by']].sort_values('original_air_date')"
"list the title of all cartoon directed by ""ben jones"" or ""brandon vietti"".","cartoon.loc[cartoon['directed_by'].isin(['ben jones', 'brandon vietti']), 'title']"
what are the titles of all cartoons directed by ben jones or brandon vietti?,"cartoon.loc[cartoon['directed_by'].isin(['ben jones', 'brandon vietti']), 'title']"
which country has the most of tv channels? list the country and number of tv channels it has.,tv_channel.groupby('country').size().sort_values(ascending=false).iloc[0:1]
what is the country with the most number of tv channels and how many does it have?,tv_channel.groupby('country').size().sort_values(ascending=false).iloc[0:1]
list the number of different series names and contents in the tv channel table.,"tv_channel.agg({'series_name': 'nunique', 'content': 'nunique'})"
how many different series and contents are listed in the tv channel table?,"tv_channel.agg({'series_name': 'nunique', 'content': 'nunique'})"
"what is the content of tv channel with serial name ""sky radio""?","tv_channel.loc[lambda x: x['series_name']=='sky radio', 'content']"
what is the content of the series sky radio?,"tv_channel.loc[lambda x: x['series_name']=='sky radio', 'content']"
"what is the package option of tv channel with serial name ""sky radio""?","tv_channel.loc[lambda x: x['series_name'] == 'sky radio', 'package_option']"
what are the package options of the tv channels whose series names are sky radio?,"tv_channel.loc[lambda x: x['series_name'] == 'sky radio', 'package_option']"
how many tv channel using language english?,"(tv_channel['language'] == ""english"").sum()"
how many tv channels use the english language?,"(tv_channel['language'] == ""english"").sum()"
list the language used least number of tv channel. list language and number of tv channel.,tv_channel.groupby('language').size().nsmallest(1)
what are the languages used by the least number of tv channels and how many channels use it?,tv_channel.groupby('language').size().nsmallest(1)
list each language and the number of tv channels using it.,tv_channel.groupby('language').size().reset_index(name='count')
"for each language, list the number of tv channels that use it.",tv_channel.groupby('language').size().reset_index(name='count')
"what is the tv channel that shows the cartoon ""the rise of the blue beetle!""? list the tv channel's series name.","tv_channel.merge(cartoon[cartoon['title'] == 'the rise of the blue beetle!'], left_on='id', right_on='channel')['series_name']"
"what is the series name of the tv channel that shows the cartoon ""the rise of the blue beetle""?","tv_channel.merge(cartoon[cartoon['title'] == 'the rise of the blue beetle!'], left_on='id', right_on='channel')['series_name']"
"list the title of all  cartoons showed on tv channel with series name ""sky radio"".","tv_channel.merge(cartoon, left_on='id', right_on='channel').loc[lambda x: x['series_name']=='sky radio', 'title']"
"what is the title of all the cartools that are on the tv channel with the series name ""sky radio""?","tv_channel.merge(cartoon, left_on='id', right_on='channel').loc[lambda x: x['series_name']=='sky radio', 'title']"
list the episode of all tv series sorted by rating.,tv_series.sort_values('rating')['episode']
what are all of the episodes ordered by ratings?,tv_series.sort_values('rating')['episode']
list top 3 highest rating  tv series. list the tv series's episode and rating.,"tv_series[['episode', 'rating']].sort_values('rating', ascending=false).head(3)"
what are 3 most highly rated episodes in the tv series table and what were those ratings?,"tv_series[['episode', 'rating']].sort_values('rating', ascending=false).head(3)"
what is minimum and maximum share of tv series?,"tv_series['share'].agg(['max', 'min'])"
what is the maximum and minimum share for the tv series?,"tv_series['share'].agg(['max', 'min'])"
"what is the air date of tv series with episode ""a love of a lifetime""?","tv_series.loc[tv_series['episode']=='a love of a lifetime', 'air_date']"
"when did the episode ""a love of a lifetime"" air?","tv_series.loc[tv_series['episode']=='a love of a lifetime', 'air_date']"
"what is weekly rank of tv series with episode ""a love of a lifetime""?","tv_series.loc[tv_series['episode'] == 'a love of a lifetime', 'weekly_rank']"
"what is the weekly rank for the episode ""a love of a lifetime""?","tv_series.loc[tv_series['episode'] == 'a love of a lifetime', 'weekly_rank']"
"what is the tv channel of tv series with episode ""a love of a lifetime""? list the tv channel's series name.","tv_channel.loc[tv_channel['id'].isin(tv_series.loc[tv_series['episode']==""a love of a lifetime"", 'channel']),'series_name']"
"what is the name of the series that has the episode ""a love of a lifetime""?","tv_channel.loc[tv_channel['id'].isin(tv_series.loc[tv_series['episode']==""a love of a lifetime"", 'channel']),'series_name']"
"list the episode of all  tv series showed on tv channel with series name ""sky radio"".","tv_channel.merge(tv_series, left_on='id', right_on='channel').loc[lambda x: x['series_name']=='sky radio', 'episode']"
"what is the episode for the tv series named ""sky radio""?","tv_channel.merge(tv_series, left_on='id', right_on='channel').loc[lambda x: x['series_name']=='sky radio', 'episode']"
find the number of cartoons directed by each of the listed directors.,cartoon.groupby('directed_by').size().reset_index(name='count(*)')
how many cartoons did each director create?,cartoon.groupby('directed_by').size().reset_index(name='count(*)')
find the production code and channel of the most recently aired cartoon .,"cartoon.sort_values('original_air_date', ascending=false).iloc[0][['production_code', 'channel']]"
what is the produdction code and channel of the most recent cartoon ?,"cartoon.sort_values('original_air_date', ascending=false).iloc[0][['production_code', 'channel']]"
find the package choice and series name of the tv channel that has high definition tv.,"tv_channel.loc[lambda x: x['hight_definition_tv']=='yes', ['package_option','series_name']]"
what are the package options and the name of the series for the tv channel that supports high definition tv?,"tv_channel.loc[lambda x: x['hight_definition_tv']=='yes', ['package_option','series_name']]"
which countries' tv channels are playing some cartoon written by todd casey?,"pd.merge(tv_channel, cartoon[cartoon['written_by']=='todd casey'], left_on='id', right_on='channel')['country']"
what are the countries that have cartoons on tv that were written by todd casey?,"pd.merge(tv_channel, cartoon[cartoon['written_by']=='todd casey'], left_on='id', right_on='channel')['country']"
which countries' tv channels are not playing any cartoon written by todd casey?,"tv_channel['country'].drop_duplicates().reset_index(drop=true).loc[lambda x: ~x.isin(cartoon.loc[cartoon['written_by'] == 'todd casey', 'channel'])]"
what are the countries that are not playing cartoons written by todd casey?,"tv_channel['country'].drop_duplicates().reset_index(drop=true).loc[lambda x: ~x.isin(cartoon.loc[cartoon['written_by'] == 'todd casey', 'channel'])]"
find the series name and country of the tv channel that is playing some cartoons directed by ben jones and michael chang?,"pd.merge(cartoon.loc[lambda x: x['directed_by']=='michael chang'], tv_channel, left_on='channel', right_on='id')[['series_name', 'country']].merge(cartoon.loc[lambda x: x['directed_by']=='ben jones'], on='channel', how='inner')[['series_name', 'country']]"
what is the series name and country of all tv channels that are playing cartoons directed by ben jones and cartoons directed by michael chang?,"pd.merge(cartoon.loc[lambda x: x['directed_by']=='michael chang'], tv_channel, left_on='channel', right_on='id')[['series_name', 'country']].merge(cartoon.loc[lambda x: x['directed_by']=='ben jones'], on='channel', how='inner')[['series_name', 'country']]"
find the pixel aspect ratio and nation of the tv channels that do not use english.,"tv_channel.loc[lambda x: x['language']!='english', ['pixel_aspect_ratio_par', 'country']]"
what is the pixel aspect ratio and country of origin for all tv channels that do not use english?,"tv_channel.loc[lambda x: x['language']!='english', ['pixel_aspect_ratio_par', 'country']]"
find id of the tv channels that from the countries where have more than two tv channels.,tv_channel.groupby('country').filter(lambda x: len(x) > 2)['id']
what are the ids of all tv channels that have more than 2 tv channels?,tv_channel.groupby('country').filter(lambda x: len(x) > 2)['id']
find the id of tv channels that do not play any cartoon directed by ben jones.,"tv_channel[~tv_channel['id'].isin(cartoon.loc[cartoon['directed_by']=='ben jones', 'channel'])]['id']"
what are the ids of the tv channels that do not have any cartoons directed by ben jones?,"tv_channel[~tv_channel['id'].isin(cartoon.loc[cartoon['directed_by']=='ben jones', 'channel'])]['id']"
find the package option of the tv channel that do not have any cartoon directed by ben jones.,"tv_channel[~tv_channel['id'].isin(cartoon.loc[cartoon['directed_by']=='ben jones', 'channel'])]['package_option']"
what are the package options of all tv channels that are not playing any cartoons directed by ben jones?,"tv_channel[~tv_channel['id'].isin(cartoon.loc[cartoon['directed_by']=='ben jones', 'channel'])]['package_option']"
how many poker players are there?,poker_player.shape[0]
count the number of poker players.,poker_player.shape[0]
list the earnings of poker players in descending order.,"poker_player.sort_values('earnings', ascending=false)['earnings']"
"what are the earnings of poker players, ordered descending by value?","poker_player.sort_values('earnings', ascending=false)['earnings']"
list the final tables made and the best finishes of poker players.,"poker_player[['final_table_made', 'best_finish']]"
what are the final tables made and best finishes for all poker players?,"poker_player[['final_table_made', 'best_finish']]"
what is the average earnings of poker players?,poker_player['earnings'].mean()
return the average earnings across all poker players.,poker_player['earnings'].mean()
what is the money rank of the poker player with the highest earnings?,"poker_player.sort_values('earnings', ascending=false).iloc[0]['money_rank']"
return the money rank of the player with the greatest earnings.,"poker_player.sort_values('earnings', ascending=false).iloc[0]['money_rank']"
what is the maximum number of final tables made among poker players with earnings less than 200000?,"poker_player.loc[poker_player['earnings'] < 200000, 'final_table_made'].max()"
return the maximum final tables made across all poker players who have earnings below 200000.,"poker_player.loc[poker_player['earnings'] < 200000, 'final_table_made'].max()"
what are the names of poker players?,"pd.merge(people, poker_player, on='people_id')['name']"
return the names of all the poker players.,"pd.merge(people, poker_player, on='people_id')['name']"
what are the names of poker players whose earnings is higher than 300000?,"pd.merge(people, poker_player, on='people_id').loc[lambda x: x['earnings']>300000, 'name']"
give the names of poker players who have earnings above 300000.,"pd.merge(people, poker_player, on='people_id').loc[lambda x: x['earnings']>300000, 'name']"
list the names of poker players ordered by the final tables made in ascending order.,"pd.merge(people, poker_player, on='people_id').sort_values('final_table_made')['name']"
"what are the names of poker players, ordered ascending by the number of final tables they have made?","pd.merge(people, poker_player, on='people_id').sort_values('final_table_made')['name']"
what is the birth date of the poker player with the lowest earnings?,"people.merge(poker_player, on='people_id').sort_values('earnings').iloc[0]['birth_date']"
return the birth date of the poker player with the lowest earnings.,"people.merge(poker_player, on='people_id').sort_values('earnings').iloc[0]['birth_date']"
what is the money rank of the tallest poker player?,"pd.merge(people, poker_player, on='people_id').sort_values('height', ascending=false)['money_rank'].iloc[0]"
return the money rank of the poker player with the greatest height.,"pd.merge(people, poker_player, on='people_id').sort_values('height', ascending=false)['money_rank'].iloc[0]"
what is the average earnings of poker players with height higher than 200?,"pd.merge(people.loc[lambda x: x['height'] > 200], poker_player, on='people_id')['earnings'].mean()"
give average earnings of poker players who are taller than 200.,"pd.merge(people.loc[lambda x: x['height'] > 200], poker_player, on='people_id')['earnings'].mean()"
what are the names of poker players in descending order of earnings?,"pd.merge(people, poker_player, on='people_id').sort_values('earnings', ascending=false)['name']"
return the names of poker players sorted by their earnings descending.,"pd.merge(people, poker_player, on='people_id').sort_values('earnings', ascending=false)['name']"
what are different nationalities of people and the corresponding number of people from each nation?,people.groupby('nationality').size().reset_index(name='count')
how many people are there of each nationality?,people.groupby('nationality').size().reset_index(name='count')
what is the most common nationality of people?,people.groupby('nationality').size().sort_values(ascending=false).index[0]
give the nationality that is most common across all people.,people.groupby('nationality').size().sort_values(ascending=false).index[0]
what are the nationalities that are shared by at least two people?,people.groupby('nationality').filter(lambda x: len(x) >= 2)['nationality'].unique()
return the nationalities for which there are two or more people.,people.groupby('nationality').filter(lambda x: len(x) >= 2)['nationality'].unique()
list the names and birth dates of people in ascending alphabetical order of name.,"people.sort_values('name')[['name', 'birth_date']]"
"what are the names and birth dates of people, ordered by their names in alphabetical order?","people.sort_values('name')[['name', 'birth_date']]"
"show names of people whose nationality is not ""russia"".","people.loc[people['nationality'] != 'russia', 'name']"
what are the names of people who are not from russia?,"people.loc[people['nationality'] != 'russia', 'name']"
list the names of people that are not poker players.,"people.loc[~people['people_id'].isin(poker_player['people_id']), 'name']"
what are the names of people who do not play poker?,"people.loc[~people['people_id'].isin(poker_player['people_id']), 'name']"
how many distinct nationalities are there?,people['nationality'].nunique()
count the number of different nationalities.,people['nationality'].nunique()
how many states are there?,area_code_state.shape[0]
"list the contestant numbers and names, ordered by contestant name descending.","contestants[['contestant_number', 'contestant_name']].sort_values('contestant_name', ascending=false)"
"list the vote ids, phone numbers and states of all votes.","votes[['vote_id', 'phone_number', 'state']]"
what are the maximum and minimum values of area codes?,"area_code_state['area_code'].agg(['max', 'min'])"
what is last date created of votes from the state 'ca'?,"votes.loc[votes['state']=='ca', 'created'].max()"
what are the names of the contestants whose names are not 'jessie alloway',"contestants.loc[lambda x: x['contestant_name']!='jessie alloway', 'contestant_name']"
what are the distinct states and create time of all votes?,"votes[['state', 'created']].drop_duplicates()"
what are the contestant numbers and names of the contestants who had at least two votes?,"pd.merge(contestants, votes, on='contestant_number').groupby('contestant_number').filter(lambda x: x.shape[0] >= 2)[['contestant_number', 'contestant_name']].drop_duplicates()"
"of all the contestants who got voted, what is the contestant number and name of the contestant who got least votes?","pd.merge(contestants, votes, on='contestant_number').groupby('contestant_number')[['contestant_number', 'contestant_name']].count().reset_index().sort_values(0).iloc[0]"
what are the number of votes from state 'ny' or 'ca'?,"votes.loc[votes['state'].isin(['ny', 'ca']), :].shape[0]"
how many contestants did not get voted?,(~contestants['contestant_number'].isin(votes['contestant_number'])).sum()
what is the area code in which the most voters voted?,"pd.merge(area_code_state, votes, on='state').groupby('area_code').size().idxmax()"
"what are the create dates, states, and phone numbers of the votes that were for the contestant named 'tabatha gehling'?","votes.merge(contestants.loc[lambda x: x['contestant_name']=='tabatha gehling', 'contestant_number'], on='contestant_number')[['created', 'state', 'phone_number']]"
list the area codes in which voters voted both for the contestant 'tabatha gehling' and the contestant 'kelly clauss'.,"pd.merge(pd.merge(contestants.loc[lambda x: x['contestant_name']=='tabatha gehling'], votes, on='contestant_number'), area_code_state, left_on='state', right_on='state').loc[:, 'area_code'].interesect(pd.merge(pd.merge(contestants.loc[lambda x: x['contestant_name']=='kelly clauss'], votes, on='contestant_number'), area_code_state, left_on='state', right_on='state').loc[:, 'area_code'])"
return the names of the contestants whose names contain the substring 'al' .,"contestants.loc[contestants['contestant_name'].str.contains('al'), 'contestant_name']"
what are the names of all the countries that became independent after 1950?,"country.loc[lambda x: x['indepyear'] > 1950, 'name']"
give the names of the nations that were founded after 1950.,"country.loc[lambda x: x['indepyear'] > 1950, 'name']"
how many countries have a republic as their form of government?,(country['governmentform'] == 'republic').sum()
how many countries have governments that are republics?,(country['governmentform'] == 'republic').sum()
what is the total surface area of the countries in the caribbean region?,"country.loc[lambda x: x['region'] == ""caribbean"", 'surfacearea'].sum()"
how much surface area do the countires in the carribean cover together?,"country.loc[lambda x: x['region'] == ""caribbean"", 'surfacearea'].sum()"
which continent is anguilla in?,"country.loc[lambda x: x['name']=='anguilla', 'continent']"
what is the continent name which anguilla belongs to?,"country.loc[lambda x: x['name']=='anguilla', 'continent']"
which region is the city kabul located in?,"pd.merge(country, city, left_on='code', right_on='countrycode').loc[lambda x: x['name']=='kabul', 'region']"
what region is kabul in?,"pd.merge(country, city, left_on='code', right_on='countrycode').loc[lambda x: x['name']=='kabul', 'region']"
which language is the most popular in aruba?,"pd.merge(country[country['name']=='aruba'], countrylanguage, left_on='code', right_on='countrycode').sort_values('percentage', ascending=false).iloc[0]['language']"
what language is predominantly spoken in aruba?,"pd.merge(country[country['name']=='aruba'], countrylanguage, left_on='code', right_on='countrycode').sort_values('percentage', ascending=false).iloc[0]['language']"
what are the population and life expectancies in brazil?,"country.loc[lambda x: x['name']=='brazil', ['population', 'lifeexpectancy']]"
give me brazil’s population and life expectancies.,"country.loc[lambda x: x['name']=='brazil', ['population', 'lifeexpectancy']]"
what are the region and population of angola?,"country.loc[lambda x: x['name']=='angola', ['population', 'region']]"
what region does angola belong to and what is its population?,"country.loc[lambda x: x['name']=='angola', ['population', 'region']]"
what is the average expected life expectancy for countries in the region of central africa?,"country.loc[lambda x: x['region']=='central africa', 'lifeexpectancy'].mean()"
how long is the people’s average life expectancy in central africa?,"country.loc[lambda x: x['region']=='central africa', 'lifeexpectancy'].mean()"
what is the name of country that has the shortest life expectancy in asia?,country.loc[lambda x: x['continent']=='asia'].sort_values('lifeexpectancy').iloc[0]['name']
give the name of the country in asia with the lowest life expectancy.,country.loc[lambda x: x['continent']=='asia'].sort_values('lifeexpectancy').iloc[0]['name']
what is the total population and maximum gnp in asia?,"country.loc[lambda x: x['continent']=='asia', ['population', 'gnp']].agg({'population': 'sum', 'gnp': 'max'})"
"how many people live in asia, and what is the largest gnp among them?","country.loc[lambda x: x['continent']=='asia', ['population', 'gnp']].agg({'population': 'sum', 'gnp': 'max'})"
what is the average life expectancy in african countries that are republics?,"country.loc[(country['continent']=='africa') & (country['governmentform']=='republic'), 'lifeexpectancy'].mean()"
give the average life expectancy for countries in africa which are republics?,"country.loc[(country['continent']=='africa') & (country['governmentform']=='republic'), 'lifeexpectancy'].mean()"
what is the total surface area of the continents asia and europe?,"country.loc[lambda x: x['continent'].isin(['asia', 'europe']), 'surfacearea'].sum()"
give the total surface area covered by countries in asia or europe.,"country.loc[lambda x: x['continent'].isin(['asia', 'europe']), 'surfacearea'].sum()"
how many people live in gelderland district?,"city.loc[lambda x: x['district']=='gelderland', 'population'].sum()"
what is the total population of gelderland district?,"city.loc[lambda x: x['district']=='gelderland', 'population'].sum()"
what is the average gnp and total population in all nations whose government is us territory?,"country.loc[country['governmentform'] == 'us territory', ['gnp', 'population']].agg({'gnp': 'mean', 'population': 'sum'})"
give the mean gnp and total population of nations which are considered us territory.,"country.loc[country['governmentform'] == 'us territory', ['gnp', 'population']].agg({'gnp': 'mean', 'population': 'sum'})"
how many unique languages are spoken in the world?,countrylanguage['language'].nunique()
what is the number of distinct languages used around the world?,countrylanguage['language'].nunique()
how many type of governments are in africa?,"country.loc[lambda x: x['continent']=='africa', 'governmentform'].nunique()"
how many different forms of governments are there in africa?,"country.loc[lambda x: x['continent']=='africa', 'governmentform'].nunique()"
what is the total number of languages used in aruba?,"country_language.merge(country[country['name'] == ""aruba""], left_on='countrycode', right_on='code')['language'].count()"
how many languages are spoken in aruba?,"country_language.merge(country[country['name'] == ""aruba""], left_on='countrycode', right_on='code')['language'].count()"
how many official languages does afghanistan have?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').loc[lambda x: (x['name']=='afghanistan') & (x['isofficial']=='t')].shape[0]"
how many official languages are spoken in afghanistan?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').loc[lambda x: (x['name']=='afghanistan') & (x['isofficial']=='t')].shape[0]"
what is name of the country that speaks the largest number of languages?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').groupby('name').size().nlargest(1).index[0]"
give the name of the nation that uses the greatest amount of languages.,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').groupby('name').size().nlargest(1).index[0]"
which continent has the most diverse languages?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').groupby('continent').size().sort_values(ascending=false).index[0]"
which continent speaks the most languages?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').groupby('continent').size().sort_values(ascending=false).index[0]"
how many countries speak both english and dutch?,"len(set(country.loc[country['code'].isin(countrylanguage.loc[countrylanguage['language'].isin(['english', 'dutch'])]['countrycode']) & (countrylanguage['language'] == 'english')]['name']) & set(country.loc[country['code'].isin(countrylanguage.loc[countrylanguage['language'].isin(['english', 'dutch'])]['countrycode']) & (countrylanguage['language'] == 'dutch')]['name']))"
what is the number of nations that use english and dutch?,"len(set(country.loc[country['code'].isin(countrylanguage.loc[countrylanguage['language'].isin(['english', 'dutch'])]['countrycode']) & (countrylanguage['language'] == 'english')]['name']) & set(country.loc[country['code'].isin(countrylanguage.loc[countrylanguage['language'].isin(['english', 'dutch'])]['countrycode']) & (countrylanguage['language'] == 'dutch')]['name']))"
what are the names of nations speak both english and french?,"pd.merge(country.loc[country['code'].isin(countrylanguage.loc[countrylanguage['language']=='english', 'countrycode'].unique()), 'name'], country.loc[country['code'].isin(countrylanguage.loc[countrylanguage['language']=='french', 'countrycode'].unique()), 'name'], on='name')"
give the names of nations that speak both english and french.,"pd.merge(country.loc[country['code'].isin(countrylanguage.loc[countrylanguage['language']=='english', 'countrycode'].unique()), 'name'], country.loc[country['code'].isin(countrylanguage.loc[countrylanguage['language']=='french', 'countrycode'].unique()), 'name'], on='name')"
what are the names of nations where both english and french are official languages?,"pd.merge(country[countrylanguage['language'] == 'english'][countrylanguage['isofficial'] == 't'][['code', 'name']], country[countrylanguage['language'] == 'french'][countrylanguage['isofficial'] == 't'][['code', 'name']])['name']"
give the names of countries with english and french as official languages.,"pd.merge(country[countrylanguage['language'] == 'english'][countrylanguage['isofficial'] == 't'][['code', 'name']], country[countrylanguage['language'] == 'french'][countrylanguage['isofficial'] == 't'][['code', 'name']])['name']"
what is the number of distinct continents where chinese is spoken?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').loc[lambda x: x['language']=='chinese', 'continent'].nunique()"
how many continents speak chinese?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').loc[lambda x: x['language']=='chinese', 'continent'].nunique()"
what are the regions that use english or dutch?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').loc[lambda x: x['language'].isin(['english', 'dutch']), 'region'].unique()"
which regions speak dutch or english?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').loc[lambda x: x['language'].isin(['english', 'dutch']), 'region'].unique()"
what are the countries where either english or dutch is the official language ?,"pd.concat([country.merge(countrylanguage[lambda x: x['language']=='english'].query('isofficial==""t""'), left_on='code', right_on='countrycode')['name'], country.merge(countrylanguage[lambda x: x['language']=='dutch'].query('isofficial==""t""'), left_on='code', right_on='countrycode')['name']], axis=0).drop_duplicates()"
which countries have either english or dutch as an official language?,"pd.merge(country, countrylanguage.loc[lambda x: (x['language']=='english') & (x['isofficial']=='t')], left_on='code', right_on='countrycode', how='inner').append(pd.merge(country, countrylanguage.loc[lambda x: (x['language']=='dutch') & (x['isofficial']=='t')], left_on='code', right_on='countrycode', how='inner'))"
which language is the most popular on the asian continent?,"countrylanguage.merge(country[country['continent']=='asia'], left_on='countrycode',right_on='code')['language'].value_counts().index[0]"
what is the language that is used by the largest number of asian nations?,"countrylanguage.merge(country[country['continent']=='asia'], left_on='countrycode',right_on='code')['language'].value_counts().index[0]"
which languages are spoken by only one country in republic governments?,"countrylanguage.merge(country[country['governmentform']=='republic'], left_on='countrycode', right_on='code').groupby('language').filter(lambda x: len(x)==1)['language']"
what languages are only used by a single country with a republic government?,"countrylanguage.merge(country[country['governmentform']=='republic'], left_on='countrycode', right_on='code').groupby('language').filter(lambda x: len(x)==1)['language']"
find the city with the largest population that uses english.,"city.merge(countrylanguage, on='countrycode').loc[lambda x: x['language']=='english', ['name', 'population']].sort_values('population', ascending=false).iloc[:1]"
what is the most populace city that speaks english?,"city.merge(countrylanguage, on='countrycode').loc[lambda x: x['language']=='english', ['name', 'population']].sort_values('population', ascending=false).iloc[:1]"
"find the name, population and expected life length of asian country with the largest area?","country.loc[lambda x: x['continent']=='asia', ['name', 'population', 'lifeexpectancy', 'surfacearea']].sort_values('surfacearea', ascending=false).iloc[:1, :-1]"
"what are the name, population, and life expectancy of the largest asian country by land?","country.loc[lambda x: x['continent']=='asia', ['name', 'population', 'lifeexpectancy', 'surfacearea']].sort_values('surfacearea', ascending=false).iloc[:1, :-1]"
what is average life expectancy in the countries where english is not the official language?,"country.loc[~country['name'].isin(countrylanguage.query('language == ""english"" and isofficial == ""t""')['name']), 'lifeexpectancy'].mean()"
give the mean life expectancy of countries in which english is not the official language.,"country.loc[~country['name'].isin(countrylanguage.query('language == ""english"" and isofficial == ""t""')['name']), 'lifeexpectancy'].mean()"
what is the total number of people living in the nations that do not use english?,"country[~country['name'].isin(countrylanguage.merge(country[[""name"", ""code""]], left_on=""countrycode"", right_on=""code"").loc[lambda x: x['language']=='english', 'name'])]['population'].sum()"
how many people live in countries that do not speak english?,"country[~country['name'].isin(countrylanguage.merge(country[[""name"", ""code""]], left_on=""countrycode"", right_on=""code"").loc[lambda x: x['language']=='english', 'name'])]['population'].sum()"
what is the official language spoken in the country whose head of state is beatrix?,"pd.merge(country, countrylanguage[countrylanguage['isofficial']=='t'], left_on='code', right_on='countrycode').loc[lambda x: x['headofstate']=='beatrix', 'language']"
what is the official language used in the country the name of whose head of state is beatrix.,"pd.merge(country, countrylanguage[countrylanguage['isofficial']=='t'], left_on='code', right_on='countrycode').loc[lambda x: x['headofstate']=='beatrix', 'language']"
what is the total number of unique official languages spoken in the countries that are founded before 1930?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').loc[lambda x: (x['indepyear']<1930) & (x['isofficial']=='t'), 'language'].nunique()"
"for the countries founded before 1930, what is the total number of distinct official languages?","pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').loc[lambda x: (x['indepyear']<1930) & (x['isofficial']=='t'), 'language'].nunique()"
what are the countries that have greater surface area than any country in europe?,"country.loc[lambda x: x['surfacearea'] > country.loc[country['continent'] == 'europe', 'surfacearea'].min(), 'name']"
which countries have greater area than that of any country in europe?,"country.loc[lambda x: x['surfacearea'] > country.loc[country['continent'] == 'europe', 'surfacearea'].min(), 'name']"
what are the african countries that have a  population less than any country in asia?,"country.loc[(country['continent']=='africa') & (country['population'] < country.loc[country['continent']=='asia', 'population'].max()), 'name']"
which african countries have a smaller population than that of any country in asia?,"country.loc[(country['continent'] == 'africa') & (country['population'] < country.loc[country['continent'] == 'asia', 'population'].min()), 'name']"
which asian countries have a population that is larger than any country in africa?,"country.loc[(country['continent']=='asia') & (country['population']>country.loc[country['continent']=='africa', 'population'].max()), 'name']"
what are the asian countries which have a population larger than that of any country in africa?,"country.loc[(country['continent'] == 'asia') & (country['population'] > country.loc[country['continent'] == 'africa', 'population'].min()), 'name']"
what are the country codes for countries that do not speak english?,"countrylanguage['countrycode'].drop_duplicates().isin(countrylanguage.loc[lambda x: x['language'] == 'english', 'countrycode']).pipe(lambda x: x[~x])"
return the country codes for countries that do not speak english.,"countrylanguage['countrycode'].drop_duplicates().isin(countrylanguage.loc[lambda x: x['language'] == 'english', 'countrycode']).pipe(lambda x: x[~x])"
what are the country codes of countries where people use languages other than english?,"countrylanguage.loc[lambda x: x['language'] != 'english', 'countrycode'].unique()"
give the country codes for countries in which people speak langauges that are not english.,"countrylanguage.loc[lambda x: x['language'] != 'english', 'countrycode'].unique()"
what are the codes of the countries that do not speak english and whose government forms are not republic?,"country.loc[lambda x: x['governmentform'] != 'republic', 'code'].isin(countrylanguage.loc[lambda x: x['language'] == 'english', 'countrycode']).astype(int).eq(0).where(lambda x: x, country.loc[lambda x: x['governmentform'] != 'republic', 'code']).dropna().astype(int)"
return the codes of countries that do not speak english and do not have republics for governments.,"country.loc[lambda x: x['governmentform'] != 'republic', 'code'].isin(countrylanguage.loc[lambda x: x['language'] == 'english', 'countrycode']).astype(int).eq(0).where(lambda x: x, country.loc[lambda x: x['governmentform'] != 'republic', 'code']).dropna().astype(int)"
which cities are in european countries where english is not the official language?,"city.merge(country[lambda x: x['continent']=='europe'], left_on='countrycode', right_on='code', how='inner').loc[lambda x: ~x['name_x'].isin(countrylanguage[lambda y: (y['isofficial']=='t') & (y['language']=='english')]['countrycode'].unique()), 'name_y'].unique()"
what are the names of cities in europe for which english is not the official language?,"city.merge(country[lambda x: x['continent']=='europe'], left_on='countrycode', right_on='code', how='inner').loc[lambda x: ~x['name_x'].isin(countrylanguage[lambda y: (y['isofficial']=='t') & (y['language']=='english')]['countrycode'].unique()), 'name_y'].unique()"
which unique cities are in asian countries where chinese is the official language ?,"pd.merge(pd.merge(country, countrylanguage, left_on='code', right_on='countrycode'), city, on='countrycode').loc[(lambda x: (x['isofficial']=='t') & (x['language']=='chinese') & (x['continent']=='asia')), 'name'].unique()"
return the different names of cities that are in asia and for which chinese is the official language.,"pd.merge(pd.merge(country, countrylanguage, left_on='code', right_on='countrycode'), city, on='countrycode').loc[lambda x: (x['language']=='chinese') & (x['isofficial']=='t') & (x['continent']=='asia'), 'name'].unique()"
"what are the name, independence year, and surface area of the country with the smallest population?","country[['name', 'surfacearea', 'indepyear', 'population']].sort_values('population').head(1)[['name', 'surfacearea', 'indepyear']]"
"give the name, year of independence, and surface area of the country that has the lowest population.","country[['name', 'surfacearea', 'indepyear', 'population']].sort_values('population').head(1)[['name', 'surfacearea', 'indepyear']]"
"what are the population, name and leader of the country with the largest area?","country[['name', 'population', 'headofstate']].sort_values('surfacearea', ascending=false).iloc[:1]"
"give the name, population, and head of state for the country that has the largest area.","country[['name', 'population', 'headofstate']].sort_values('surfacearea', ascending=false).iloc[:1]"
return the country name and the numbers of languages spoken for each country that speaks at least 3 languages.,"countrylanguage.merge(country, left_on='countrycode', right_on='code').groupby('name').filter(lambda x: len(x) > 2).groupby('name').size().reset_index(name='count').loc[:,['count','name']]"
"what are the names of countries that speak more than 2 languages, as well as how many languages they speak?","countrylanguage.merge(country, left_on='countrycode', right_on='code').groupby('name').filter(lambda x: len(x) > 2).groupby('name').size().reset_index(name='count').loc[:,['count','name']]"
find the number of cities in each district whose population is greater than the average population of cities?,city.loc[city['population'] > city['population'].mean()].groupby('district').agg({'population': 'count'}).rename(columns={'population': 'count(*)'})
how many cities in each district have a population that is above the average population across all cities?,city.loc[city['population'] > city['population'].mean()].groupby('district').agg({'population': 'count'}).rename(columns={'population': 'count(*)'})
find the government form name and total population for each government form whose average life expectancy is longer than 72.,"country.groupby('governmentform').agg({'population':'sum', 'lifeexpectancy':'mean'}).loc[lambda x: x['lifeexpectancy'] > 72, 'population']"
what are the different government forms and what is the total population of each for government forms that have an average life expectancy greater than 72?,"country.groupby('governmentform').agg({'population':'sum', 'lifeexpectancy':'mean'}).loc[lambda x: x['lifeexpectancy'] > 72, 'population']"
find the average life expectancy and total population for each continent where the average life expectancy is shorter than 72?,"country.groupby('continent').agg({'population': 'sum', 'lifeexpectancy': 'mean'}).loc[lambda x: x['lifeexpectancy'] < 72]"
"what are the different continents and the total popuation and average life expectancy corresponding to each, for continents that have an average life expectancy less than 72?","country.groupby('continent').agg({'population': 'sum', 'lifeexpectancy': 'mean'}).loc[lambda x: x['lifeexpectancy'] < 72]"
what are the names and areas of countries with the top 5 largest area?,"country[['name','surfacearea']].sort_values('surfacearea', ascending=false).head(5)"
return the names and surface areas of the 5 largest countries.,"country[['name','surfacearea']].sort_values('surfacearea', ascending=false).head(5)"
what are names of countries with the top 3 largest population?,"country.sort_values('population', ascending=false)['name'].head(3)"
return the names of the 3 most populated countries.,"country.sort_values('population', ascending=false)['name'].head(3)"
what are the names of the nations with the 3 lowest populations?,country.sort_values('population').head(3)['name']
return the names of the 3 countries with the fewest people.,country.sort_values('population').head(3)['name']
how many countries are in asia?,(country['continent'] == 'asia').sum()
count the number of countries in asia.,(country['continent'] == 'asia').sum()
what are the names of the countries that are in the continent of europe and have a population of 80000?,"country.loc[(country['continent'] == 'europe') & (country['population'] == 80000), 'name']"
give the names of countries that are in europe and have a population equal to 80000.,"country.loc[(country['continent'] == 'europe') & (country['population'] == 80000), 'name']"
what is the total population and average area of countries in the continent of north america whose area is bigger than 3000 ?,"country.loc[(country['continent'] == 'north america') & (country['surfacearea'] > 3000), ['population', 'surfacearea']].agg({'population': 'sum', 'surfacearea': 'mean'})"
give the total population and average surface area corresponding to countries in north america that have a surface area greater than 3000 .,"country.loc[(country['continent'] == 'north america') & (country['surfacearea'] > 3000), ['population', 'surfacearea']].agg({'population': 'sum', 'surfacearea': 'mean'})"
what are the cities whose population is between 160000 and 900000?,"city.loc[(city['population'] >= 160000) & (city['population'] <= 900000), 'name']"
return the names of cities that have a population between 160000 and 900000 .,"city.loc[(city['population'] >= 160000) & (city['population'] <= 900000), 'name']"
which language is spoken by the largest number of countries?,countrylanguage.groupby('language').size().sort_values(ascending=false).index[0]
give the language that is spoken in the most countries.,countrylanguage.groupby('language').size().sort_values(ascending=false).index[0]
what is the language spoken by the largest percentage of people in each country?,"countrylanguage.groupby('countrycode').agg({'language': 'first', 'percentage': 'max'}).reset_index()[['language', 'countrycode', 'percentage']]"
"what are the country codes of the different countries, and what are the languages spoken by the greatest percentage of people for each?","countrylanguage.groupby('countrycode').agg({'language': 'first', 'percentage': 'max'}).reset_index()[['language', 'countrycode', 'percentage']]"
what is the total number of countries where spanish is spoken by the largest percentage of people?,"countrylanguage[countrylanguage['language']=='spanish'].groupby('countrycode').agg({'countrycode':'count', 'percentage':'max'})"
count the number of countries for which spanish is the predominantly spoken language.,"countrylanguage.loc[countrylanguage['language']=='spanish'].groupby('countrycode').agg({'percentage': 'max', '*': 'count'})"
what are the codes of countries where spanish is spoken by the largest percentage of people?,countrylanguage.loc[countrylanguage['language']=='spanish'].groupby('countrycode')['percentage'].max()
return the codes of countries for which spanish is the predominantly spoken language.,countrylanguage.loc[countrylanguage['language']=='spanish'].groupby('countrycode')['percentage'].max()
how many conductors are there?,conductor.shape[0]
count the number of conductors.,conductor.shape[0]
list the names of conductors in ascending order of age.,conductor.sort_values('age')['name']
"what are the names of conductors, ordered by age?",conductor.sort_values('age')['name']
"what are the names of conductors whose nationalities are not ""usa""?","conductor.loc[lambda x: x['nationality'] != 'usa', 'name']"
"return the names of conductors that do not have the nationality ""usa"".","conductor.loc[lambda x: x['nationality'] != 'usa', 'name']"
what are the record companies of orchestras in descending order of years in which they were founded?,"orchestra.sort_values('year_of_founded', ascending=false)['record_company']"
"return the record companies of orchestras, sorted descending by the years in which they were founded.","orchestra.sort_values('year_of_founded', ascending=false)['record_company']"
what is the average attendance of shows?,show['attendance'].mean()
return the average attendance across all shows.,show['attendance'].mean()
"what are the maximum and minimum share of performances whose type is not ""live final"".","performance.query('type != ""live final""').agg({'share': ['max', 'min']})"
"return the maximum and minimum shares for performances that do not have the type ""live final"".","performance.query('type != ""live final""').agg({'share': ['max', 'min']})"
how many different nationalities do conductors have?,conductor['nationality'].nunique()
count the number of different nationalities of conductors.,conductor['nationality'].nunique()
list names of conductors in descending order of years of work.,"conductor.sort_values('year_of_work', ascending=false)['name']"
"what are the names of conductors, sorted descending by the number of years they have worked?","conductor.sort_values('year_of_work', ascending=false)['name']"
list the name of the conductor with the most years of work.,"conductor.sort_values('year_of_work', ascending=false)['name'].iloc[0]"
what is the name of the conductor who has worked the greatest number of years?,"conductor.sort_values('year_of_work', ascending=false)['name'].iloc[0]"
show the names of conductors and the orchestras they have conducted.,"pd.merge(conductor, orchestra, on='conductor_id')[['name', 'orchestra']]"
what are the names of conductors as well as the corresonding orchestras that they have conducted?,"pd.merge(conductor, orchestra, on='conductor_id')[['name', 'orchestra']]"
show the names of conductors that have conducted more than one orchestras.,"pd.merge(conductor, orchestra, on='conductor_id').groupby('conductor_id').filter(lambda x: len(x) > 1)['name']"
what are the names of conductors who have conducted at more than one orchestra?,"pd.merge(conductor, orchestra, on='conductor_id').groupby('conductor_id').filter(lambda x: len(x) > 1)['name']"
show the name of the conductor that has conducted the most number of orchestras.,"pd.merge(conductor, orchestra, on='conductor_id').groupby('conductor_id')['name'].count().sort_values(ascending=false).iloc[[0]]"
what is the name of the conductor who has conducted the most orchestras?,"pd.merge(conductor, orchestra, on='conductor_id').groupby('conductor_id')['name'].count().sort_values(ascending=false).iloc[[0]]"
please show the name of the conductor that has conducted orchestras founded after 2008.,"conductor.merge(orchestra, on='conductor_id').loc[lambda x: x['year_of_founded'] > 2008, 'name']"
what are the names of conductors who have conducted orchestras founded after the year 2008?,"conductor.merge(orchestra, on='conductor_id').loc[lambda x: x['year_of_founded'] > 2008, 'name']"
please show the different record companies and the corresponding number of orchestras.,orchestra.groupby('record_company').size()
how many orchestras does each record company manage?,orchestra.groupby('record_company').size()
please show the record formats of orchestras in ascending order of count.,orchestra.groupby('major_record_format')['major_record_format'].count().sort_values().index.tolist()
"what are the major record formats of orchestras, sorted by their frequency?",orchestra.groupby('major_record_format')['major_record_format'].count().sort_values().index.tolist()
list the record company shared by the most number of orchestras.,orchestra.groupby('record_company').size().idxmax()
what is the record company used by the greatest number of orchestras?,orchestra.groupby('record_company').size().idxmax()
list the names of orchestras that have no performance.,"orchestra.loc[~orchestra['orchestra_id'].isin(performance['orchestra_id']), 'orchestra']"
what are the orchestras that do not have any performances?,"orchestra.loc[~orchestra['orchestra_id'].isin(performance['orchestra_id']), 'orchestra']"
show the record companies shared by orchestras founded before 2003 and after 2003.,"set(orchestra.loc[orchestra['year_of_founded'] < 2003, 'record_company']).intersection(set(orchestra.loc[orchestra['year_of_founded'] > 2003, 'record_company']))"
what are the record companies that are used by both orchestras founded before 2003 and those founded after 2003?,"set(orchestra.loc[orchestra['year_of_founded'] < 2003, 'record_company']).intersection(set(orchestra.loc[orchestra['year_of_founded'] > 2003, 'record_company']))"
"find the number of orchestras whose record format is ""cd"" or ""dvd"".","orchestra.loc[lambda x: (x['major_record_format']=='cd') | (x['major_record_format']=='dvd'), :].shape[0]"
count the number of orchestras that have cd or dvd as their record format.,"orchestra.loc[lambda x: (x['major_record_format']=='cd') | (x['major_record_format']=='dvd'), :].shape[0]"
show the years in which orchestras that have given more than one performance are founded.,"pd.merge(orchestra, performance, on='orchestra_id').groupby('orchestra_id').filter(lambda x: len(x) > 1)['year_of_founded']"
what are years of founding for orchestras that have had more than a single performance?,"pd.merge(orchestra, performance, on='orchestra_id').groupby('orchestra_id').filter(lambda x: len(x) > 1)['year_of_founded']"
how many high schoolers are there?,highschooler.shape[0]
count the number of high schoolers.,highschooler.shape[0]
show the names and grades of each high schooler.,"highschooler[['name', 'grade']]"
what are the names and grades for each high schooler?,"highschooler[['name', 'grade']]"
show all the grades of the high schoolers.,highschooler['grade']
what is the grade of each high schooler?,highschooler['grade']
what grade is kyle in?,"highschooler.loc[lambda x: x['name']=='kyle', 'grade']"
return the grade for the high schooler named kyle.,"highschooler.loc[lambda x: x['name']=='kyle', 'grade']"
show the names of all high schoolers in grade 10.,"highschooler.loc[lambda x: x['grade']==10, 'name']"
what are the names of all high schoolers in grade 10?,"highschooler.loc[lambda x: x['grade']==10, 'name']"
show the id of the high schooler named kyle.,"highschooler.loc[lambda x: x['name'] == 'kyle', 'id']"
what is kyle's id?,"highschooler.loc[lambda x: x['name'] == 'kyle', 'id']"
how many high schoolers are there in grade 9 or 10?,(highschooler['grade']==9 | highschooler['grade']==10).sum()
count the number of high schoolers in grades 9 or 10.,(highschooler['grade']==9 | highschooler['grade']==10).sum()
show the number of high schoolers for each grade.,highschooler.groupby('grade').size().reset_index(name='count')
how many high schoolers are in each grade?,highschooler.groupby('grade').size().reset_index(name='count')
which grade has the most high schoolers?,highschooler.groupby('grade').size().sort_values(ascending=false).index[0]
return the grade that has the greatest number of high schoolers.,highschooler.groupby('grade').size().sort_values(ascending=false).index[0]
show me all grades that have at least 4 students.,highschooler.groupby('grade').filter(lambda x: len(x) >= 4)['grade'].unique()
which grades have 4 or more high schoolers?,highschooler.groupby('grade').filter(lambda x: len(x) >= 4)['grade'].unique()
show the student ids and numbers of friends corresponding to each.,friend.groupby('student_id').size().reset_index(name='count')
how many friends does each student have?,friend.groupby('student_id').size().reset_index(name='count')
show the names of high school students and their corresponding number of friends.,"friend.merge(highschooler, left_on='student_id', right_on='id').groupby('student_id')['name'].agg(['count'])"
what are the names of the high schoolers and how many friends does each have?,"friend.merge(highschooler, left_on='student_id', right_on='id').groupby('student_id')['name'].agg(['count'])"
what is the name of the high schooler who has the greatest number of friends?,"friend.merge(highschooler, left_on='student_id', right_on='id').groupby('student_id')['name'].count().sort_values(ascending=false).head(1).index.map(lambda x: highschooler.loc[x, 'name'])"
return the name of the high school student with the most friends.,"friend.merge(highschooler, left_on='student_id', right_on='id').groupby('student_id')['name'].count().sort_values(ascending=false).head(1).index.map(lambda x: highschooler.loc[x, 'name'])"
show the names of high schoolers who have at least 3 friends.,"pd.merge(friend, highschooler, left_on='student_id', right_on='id').groupby('student_id').filter(lambda x: len(x) >= 3)['name'].unique()"
what are the names of high schoolers who have 3 or more friends?,"pd.merge(friend, highschooler, left_on='student_id', right_on='id').groupby('student_id').filter(lambda x: len(x) >= 3)['name'].unique()"
show the names of all of the high schooler kyle's friends.,"pd.merge(pd.merge(friend, highschooler, left_on='student_id', right_on='id'), highschooler, left_on='friend_id', right_on='id').loc[lambda x: x['name_x']=='kyle', 'name_y']"
return the names of friends of the high school student kyle.,"pd.merge(pd.merge(friend, highschooler, left_on='student_id', right_on='id'), highschooler, left_on='friend_id', right_on='id').loc[lambda x: x['name_x']=='kyle', 'name_y']"
how many friends does the high school student kyle have?,"pd.merge(friend, highschooler, left_on='student_id', right_on='id').loc[lambda x: x['name']=='kyle'].shape[0]"
count the number of friends kyle has.,"pd.merge(friend, highschooler, left_on='student_id', right_on='id').loc[lambda x: x['name']=='kyle'].shape[0]"
show ids of all students who do not have any friends.,pd.series(list(set(highschooler['id']) - set(friend['student_id'])))
what are the ids of high school students who do not have friends?,pd.series(list(set(highschooler['id']) - set(friend['student_id'])))
show names of all high school students who do not have any friends.,"highschooler[~highschooler['id'].isin(friend.merge(highschooler, left_on='student_id', right_on='id')['name'])]['name']"
what are the names of students who have no friends?,"highschooler[~highschooler['id'].isin(friend.merge(highschooler, left_on='student_id', right_on='id')['name'])]['name']"
show the ids of high schoolers who have friends and are also liked by someone else.,pd.series(list(set(friend['student_id']) & set(likes['liked_id'])))
what are the ids of students who both have friends and are liked?,pd.series(list(set(friend['student_id']) & set(likes['liked_id'])))
show name of all students who have some friends and also are liked by someone else.,"pd.merge(friend, highschooler, left_on='student_id', right_on='id')['name'].interesect(pd.merge(likes, highschooler, left_on='liked_id', right_on='id')['name'])"
what are the names of high schoolers who both have friends and are liked?,"pd.merge(friend, highschooler, left_on='student_id', right_on='id')['name'].interesect(pd.merge(likes, highschooler, left_on='liked_id', right_on='id')['name'])"
count the number of likes for each student id.,likes.groupby('student_id').size().reset_index(name='count')
how many likes correspond to each student id?,likes.groupby('student_id').size().reset_index(name='count')
"show the names of high schoolers who have likes, and numbers of likes for each.","likes.merge(highschooler, left_on='student_id', right_on='id').groupby('student_id').agg({'name': 'first', 'color': 'count'}).rename(columns={'color': 'count'})[['name', 'count']]"
"what are the names of high schoolers who have likes, and how many likes does each have?","likes.merge(highschooler, left_on='student_id', right_on='id').groupby('student_id').agg({'name': 'first', 'color': 'count'}).rename(columns={'color': 'count'})[['name', 'count']]"
what is the name of the high schooler who has the greatest number of likes?,"highschooler.loc[highschooler['id'].isin(likes.merge(likes.groupby('student_id')['other_id'].count().idxmax(), on='student_id')['other_id']), 'name']"
give the name of the student with the most likes.,"highschooler.loc[highschooler['id'].isin(likes.merge(likes.groupby('student_id')['other_id'].count().idxmax(), on='student_id')['other_id']), 'name']"
show the names of students who have at least 2 likes.,"likes.merge(highschooler, left_on='student_id', right_on='id').groupby('student_id').filter(lambda x: len(x) >= 2)['name']"
what are the names of students who have 2 or more likes?,"likes.merge(highschooler, left_on='student_id', right_on='id').groupby('student_id').filter(lambda x: len(x) >= 2)['name']"
show the names of students who have a grade higher than 5 and have at least 2 friends.,"pd.merge(friend, highschooler, left_on='student_id', right_on='id').loc[lambda x: x['grade'] > 5].groupby('student_id').filter(lambda x: len(x) >= 2)['name'].unique()"
what are the names of high schoolers who have a grade of over 5 and have 2 or more friends?,"pd.merge(friend, highschooler, left_on='student_id', right_on='id').loc[lambda x: x['grade'] > 5].groupby('student_id').filter(lambda x: len(x) >= 2)['name'].unique()"
how many likes does kyle have?,"pd.merge(likes, highschooler, left_on='student_id', right_on='id').loc[lambda x: x['name']=='kyle'].shape[0]"
return the number of likes that the high schooler named kyle has.,"pd.merge(likes, highschooler, left_on='student_id', right_on='id').loc[lambda x: x['name']=='kyle'].shape[0]"
find the average grade of all students who have some friends.,"highschooler.loc[lambda x: x['id'].isin(friend.merge(highschooler, left_on='student_id', right_on='id')['id'])]['grade'].mean()"
what is the average grade of students who have friends?,"highschooler.loc[lambda x: x['id'].isin(friend.merge(highschooler, left_on='student_id', right_on='id')['id'])]['grade'].mean()"
find the minimum grade of students who have no friends.,"highschooler.loc[~highschooler['id'].isin(friend.merge(highschooler, left_on='student_id', right_on='id')['id_x']), 'grade'].min()"
what is the lowest grade of students who do not have any friends?,"highschooler.loc[~highschooler['id'].isin(friend.merge(highschooler, left_on='student_id', right_on='id')['id_x']), 'grade'].min()"
which states have both owners and professionals living there?,pd.series(list(set(owners['state']) & set(professionals['state'])))
find the states where both owners and professionals live.,pd.series(list(set(owners['state']) & set(professionals['state'])))
what is the average age of the dogs who have gone through any treatments?,"dogs.loc[dogs['dog_id'].isin(treatments['dog_id']), 'age'].mean()"
find the average age of the dogs who went through treatments.,"dogs.loc[dogs['dog_id'].isin(treatments['dog_id']), 'age'].mean()"
"which professionals live in the state of indiana or have done treatment on more than 2 treatments? list his or her id, last name and cell phone.","pd.concat([professionals.loc[lambda x: x['state'] == 'indiana', ['professional_id', 'last_name', 'cell_number']], professionals.merge(treatments, on='professional_id').groupby('professional_id').filter(lambda x: len(x) > 2).loc[:, ['professional_id', 'last_name', 'cell_number']].drop_duplicates()])[['professional_id', 'last_name', 'cell_number']]"
"find the id, last name and cell phone of the professionals who live in the state of indiana or have performed more than two treatments.","pd.concat([professionals.loc[lambda x: x['state'] == 'indiana', ['professional_id', 'last_name', 'cell_number']], professionals.merge(treatments, on='professional_id').groupby('professional_id').filter(lambda x: len(x) > 2).loc[:, ['professional_id', 'last_name', 'cell_number']].drop_duplicates()])[['professional_id', 'last_name', 'cell_number']]"
which dogs have not cost their owner more than 1000 for treatment ? list the dog names .,"dogs.loc[~dogs['dog_id'].isin(treatments.groupby('dog_id').filter(lambda x: x['cost_of_treatment'].sum() > 1000)['dog_id']), 'name']"
what are the names of the dogs for which the owner has not spend more than 1000 for treatment ?,"dogs.loc[~dogs['dog_id'].isin(treatments.groupby('dog_id').filter(lambda x: x['cost_of_treatment'].sum() > 1000)['dog_id']), 'name']"
which first names are used for professionals or owners but are not used as dog names?,"pd.concat([professionals['first_name'], owners['first_name']]).drop_duplicates().reset_index(drop=true).loc[lambda x: ~(x.isin(dogs['name']))]"
find the first names that are used for professionals or owners but are not used as dog names.,"pd.concat([professionals['first_name'], owners['first_name']]).drop_duplicates().reset_index(drop=true).loc[lambda x: ~(x.isin(dogs['name']))]"
"which professional did not operate any treatment on dogs? list the professional's id, role and email.","professionals[['professional_id', 'role_code', 'email_address']].merge(treatments[['professional_id']].rename(columns={'professional_id': 'id'}),how='left',left_on='professional_id',right_on='id').loc[lambda x: x['id'].isna()].drop('id', axis=1)"
"give me the id, role and email of the professionals who did not perform any treatment on dogs.","professionals[['professional_id', 'role_code', 'email_address']].merge(treatments[['professional_id']].rename(columns={'professional_id': 'id'}),how='left',left_on='professional_id',right_on='id').loc[lambda x: x['id'].isna()].drop('id', axis=1)"
"which owner owns the most dogs? list the owner id, first name and last name.","owners.loc[dogs.groupby('owner_id')['dog_id'].count().idxmax(), ['owner_id', 'first_name', 'last_name']]"
"return the owner id, first name and last name of the owner who has the most dogs.","owners.loc[dogs.groupby('owner_id')['dog_id'].count().idxmax(), ['owner_id', 'first_name', 'last_name']]"
"which professionals have done at least two treatments? list the professional's id, role, and first name.","professionals.merge(treatments, on='professional_id').groupby(['professional_id', 'role_code', 'first_name']).filter(lambda x: len(x) >= 2).drop_duplicates(['professional_id'])[['professional_id', 'role_code', 'first_name']]"
"what are the id, role, and first name of the professionals who have performed two or more treatments?","professionals.merge(treatments, on='professional_id').groupby(['professional_id', 'role_code', 'first_name']).filter(lambda x: len(x) >= 2).drop_duplicates(['professional_id'])[['professional_id', 'role_code', 'first_name']]"
what is the name of the breed with the most dogs?,"pd.merge(breeds, dogs, on='breed_code').groupby('breed_name').size().sort_values(ascending=false).index[0]"
which breed do the most dogs have? give me the breed name.,"pd.merge(breeds, dogs, on='breed_code').groupby('breed_name').size().sort_values(ascending=false).index[0]"
which owner has paid for the most treatments on his or her dogs? list the owner id and last name.,"owners.merge(dogs).merge(treatments).groupby(['owner_id', 'last_name']).size().idxmax()"
tell me the owner id and last name of the owner who spent the most on treatments of his or her dogs.,"owners.merge(dogs).merge(treatments).groupby(['owner_id', 'last_name']).size().idxmax()"
what is the description of the treatment type that costs the least money in total?,"pd.merge(treatment_types, treatments, on='treatment_type_code').groupby('treatment_type_description').agg({'cost_of_treatment': 'sum'}).sort_values('cost_of_treatment').index[0]"
give me the description of the treatment type whose total cost is the lowest.,"pd.merge(treatment_types, treatments, on='treatment_type_code').groupby('treatment_type_description').agg({'cost_of_treatment': 'sum'}).sort_values('cost_of_treatment').index[0]"
which owner has paid the largest amount of money in total for their dogs? show the owner id and zip code.,"pd.merge(pd.merge(owners, dogs, on='owner_id'), treatments, on='dog_id').groupby(['owner_id', 'zip_code'])['cost_of_treatment'].sum().reset_index().sort_values('cost_of_treatment', ascending=false).iloc[0, :2]"
find the owner id and zip code of the owner who spent the most money in total for his or her dogs.,"pd.merge(pd.merge(owners, dogs, on='owner_id'), treatments, on='dog_id').groupby(['owner_id', 'zip_code'])['cost_of_treatment'].sum().reset_index().sort_values('cost_of_treatment', ascending=false).iloc[0, :2]"
which professionals have done at least two types of treatments? list the professional id and cell phone.,"pd.merge(professionals, treatments, on='professional_id').groupby('professional_id').filter(lambda x: len(x) >= 2)[['professional_id', 'cell_number']].drop_duplicates()"
find the id and cell phone of the professionals who operate two or more types of treatments.,"pd.merge(professionals, treatments, on='professional_id').groupby('professional_id').filter(lambda x: len(x) >= 2)[['professional_id', 'cell_number']].drop_duplicates()"
what are the first name and last name of the professionals who have done treatment with cost below average?,"pd.merge(professionals, treatments.loc[lambda x: x['cost_of_treatment'] < treatments['cost_of_treatment'].mean()], on='professional_id')[['first_name', 'last_name']].drop_duplicates()"
which professionals have operated a treatment that costs less than the average? give me theor first names and last names.,"pd.merge(professionals, treatments.loc[lambda x: x['cost_of_treatment'] < treatments['cost_of_treatment'].mean()], on='professional_id')[['first_name', 'last_name']].drop_duplicates()"
"list the date of each treatment, together with the first name of the professional who operated it.","pd.merge(treatments, professionals, on='professional_id')[['date_of_treatment', 'first_name']]"
what are the date and the operating professional's first name of each treatment?,"pd.merge(treatments, professionals, on='professional_id')[['date_of_treatment', 'first_name']]"
list the cost of each treatment and the corresponding treatment type description.,"pd.merge(treatments, treatment_types, on='treatment_type_code')[['cost_of_treatment', 'treatment_type_description']]"
what are the cost and treatment type description of each treatment?,"pd.merge(treatments, treatment_types, on='treatment_type_code')[['cost_of_treatment', 'treatment_type_description']]"
"list each owner's first name, last name, and the size of his for her dog.","pd.merge(owners, dogs, on='owner_id')[['first_name', 'last_name', 'size_code']]"
"what are each owner's first name, last name, and the size of their dog?","pd.merge(owners, dogs, on='owner_id')[['first_name', 'last_name', 'size_code']]"
list pairs of the owner's first name and the dogs's name.,"pd.merge(owners, dogs, on='owner_id')[['first_name', 'name']]"
what are each owner's first name and their dogs's name?,"pd.merge(owners, dogs, on='owner_id')[['first_name', 'name']]"
list the names of the dogs of the rarest breed and the treatment dates of them.,"dogs.merge(treatments, on='dog_id').loc[lambda x: x['breed_code'] == dogs.groupby('breed_code').size().sort_values().index[0], ['name', 'date_of_treatment']]"
which dogs are of the rarest breed? show their names and treatment dates.,"dogs.merge(treatments, on='dog_id').loc[lambda x: x['breed_code'] == dogs.groupby('breed_code').size().sort_values().index[0], ['name', 'date_of_treatment']]"
which dogs are owned by someone who lives in virginia? list the owner's first name and the dog's name.,"pd.merge(owners, dogs, on='owner_id').loc[lambda x: x['state']=='virginia', ['first_name', 'name']]"
find the first names of owners living in virginia and the names of dogs they own.,"pd.merge(owners, dogs, on='owner_id').loc[lambda x: x['state']=='virginia', ['first_name', 'name']]"
what are the arriving date and the departing date of the dogs who have gone through a treatment?,"pd.merge(dogs, treatments, on='dog_id')[['date_arrived', 'date_departed']].drop_duplicates()"
find the arriving date and the departing date of the dogs that received a treatment.,"pd.merge(dogs, treatments, on='dog_id')[['date_arrived', 'date_departed']].drop_duplicates()"
list the last name of the owner owning the youngest dog.,"owners.merge(dogs, on='owner_id').loc[lambda x: x['age']==dogs['age'].max(), 'last_name']"
who owns the youngest dog? give me his or her last name.,"owners.merge(dogs, on='owner_id').loc[lambda x: x['age']==dogs['age'].max(), 'last_name']"
list the emails of the professionals who live in the state of hawaii or the state of wisconsin.,"professionals.loc[lambda x: x['state'].isin(['hawaii', 'wisconsin']), 'email_address']"
what are the emails of the professionals living in either the state of hawaii or the state of wisconsin?,"professionals.loc[lambda x: x['state'].isin(['hawaii', 'wisconsin']), 'email_address']"
what are the arriving date and the departing date of all the dogs?,"dogs[['date_arrived', 'date_departed']]"
list the arrival date and the departure date for all the dogs.,"dogs[['date_arrived', 'date_departed']]"
how many dogs went through any treatments?,treatments['dog_id'].nunique()
count the number of dogs that went through a treatment.,treatments['dog_id'].nunique()
how many professionals have performed any treatment to dogs?,treatments['professional_id'].nunique()
find the number of professionals who have ever treated dogs.,treatments['professional_id'].nunique()
"which professionals live in a city containing the substring 'west'? list his or her role, street, city and state.","professionals.loc[professionals['city'].str.contains('west', na=false), ['role_code', 'street', 'city', 'state']]"
"find the role, street, city and state of the professionals living in a city that contains the substring 'west'.","professionals.loc[professionals['city'].str.contains('west', na=false), ['role_code', 'street', 'city', 'state']]"
"which owners live in the state whose name contains the substring 'north'? list his first name, last name and email.","owners.loc[owners['state'].str.contains('north'), ['first_name', 'last_name', 'email_address']]"
"return the first name, last name and email of the owners living in a state whose name contains the substring 'north'.","owners.loc[owners['state'].str.contains('north'), ['first_name', 'last_name', 'email_address']]"
how many dogs have an age below the average?,(dogs['age'] < dogs['age'].mean()).sum()
count the number of dogs of an age below the average.,(dogs['age'] < dogs['age'].mean()).sum()
how much does the most recent treatment cost?,"treatments.sort_values('date_of_treatment', ascending=false).iloc[0]['cost_of_treatment']"
show me the cost of the most recently performed treatment.,"treatments.sort_values('date_of_treatment', ascending=false).iloc[0]['cost_of_treatment']"
how many dogs have not gone through any treatment?,"dogs.loc[~dogs['dog_id'].isin(treatments['dog_id']), 'dog_id'].count()"
tell me the number of dogs that have not received any treatment .,dogs['dog_id'].isin(treatments['dog_id']).value_counts()[false]
how many owners temporarily do not have any dogs?,"owners.loc[~owners['owner_id'].isin(dogs['owner_id']), :].shape[0]"
find the number of owners who do not own any dogs at this moment.,"owners.loc[~owners['owner_id'].isin(dogs['owner_id']), :].shape[0]"
how many professionals did not operate any treatment on dogs?,professionals['professional_id'].nunique() - treatments['professional_id'].nunique()
find the number of professionals who have not treated any dogs.,professionals['professional_id'].nunique() - treatments['professional_id'].nunique()
"list the dog name, age and weight of the dogs who have been abandoned? 1 stands for yes, and 0 stands for no.","dogs.loc[lambda x: x['abandoned_yn']==1, ['name', 'age', 'weight']]"
"what are the dog name, age and weight of the dogs that were abandoned? note that 1 stands for yes, and 0 stands for no in the tables.","dogs.loc[lambda x: x['abandoned_yn']==1, ['name', 'age', 'weight']]"
what is the average age of all the dogs?,dogs['age'].mean()
compute the average age of all the dogs.,dogs['age'].mean()
what is the age of the oldest dog?,dogs['age'].max()
tell me the age of the oldest dog.,dogs['age'].max()
how much does each charge type costs? list both charge type and amount.,"charges[['charge_type', 'charge_amount']]"
list each charge type and its amount.,"charges[['charge_type', 'charge_amount']]"
how much does the most expensive charge type costs?,charges['charge_amount'].max()
what is the charge amount of the most expensive charge type?,charges['charge_amount'].max()
"list the email, cell phone and home phone of all the professionals.","professionals[['email_address', 'cell_number', 'home_phone']]"
"what are the email, cell phone and home phone of each professional?","professionals[['email_address', 'cell_number', 'home_phone']]"
what are all the possible breed type and size type combinations?,"dogs[['breed_code', 'size_code']].drop_duplicates()"
find the distinct breed type and size type combinations for dogs.,"dogs[['breed_code', 'size_code']].drop_duplicates()"
list the first name of all the professionals along with the description of the treatment they have done.,"pd.merge(pd.merge(professionals, treatments, on='professional_id'), treatment_types, on='treatment_type_code')[['first_name', 'treatment_type_description']].drop_duplicates()"
what are each professional's first name and description of the treatment they have performed?,"pd.merge(pd.merge(professionals, treatments, on='professional_id'), treatment_types, on='treatment_type_code')[['first_name', 'treatment_type_description']].drop_duplicates()"
how many singers are there?,singer.shape[0]
what is the count of singers?,singer.shape[0]
list the name of singers in ascending order of net worth.,singer.sort_values('net_worth_millions')['name']
what are the names of singers ordered by ascending net worth?,singer.sort_values('net_worth_millions')['name']
what are the birth year and citizenship of singers?,"singer[['birth_year','citizenship']]"
what are the birth years and citizenships of the singers?,"singer[['birth_year','citizenship']]"
"list the name of singers whose citizenship is not ""france"".","singer.loc[lambda x: x['citizenship'] != 'france', 'name']"
what are the names of the singers who are not french citizens?,"singer.loc[lambda x: x['citizenship'] != 'france', 'name']"
show the name of singers whose birth year is either 1948 or 1949?,"singer.loc[singer['birth_year'].isin([1948, 1949]), 'name']"
what are the names of the singers whose birth years are either 1948 or 1949?,"singer.loc[singer['birth_year'].isin([1948, 1949]), 'name']"
what is the name of the singer with the largest net worth?,"singer.sort_values('net_worth_millions', ascending=false).iloc[0]['name']"
what is the name of the singer who is worth the most?,"singer.sort_values('net_worth_millions', ascending=false).iloc[0]['name']"
show different citizenship of singers and the number of singers of each citizenship.,singer.groupby('citizenship').size()
"for each citizenship, how many singers are from that country?",singer.groupby('citizenship').size()
please show the most common citizenship of singers.,"singer.groupby('citizenship').size().reset_index(name='counts').sort_values('counts', ascending=false).iloc[0, 0]"
what is the most common singer citizenship ?,singer.groupby('citizenship').size().sort_values(ascending=false).index[0]
show different citizenships and the maximum net worth of singers of each citizenship.,singer.groupby('citizenship')['net_worth_millions'].max()
"for each citizenship, what is the maximum net worth?",singer.groupby('citizenship')['net_worth_millions'].max()
show titles of songs and names of singers.,"pd.merge(singer, song, on='singer_id')[['title', 'name']]"
what are the song titles and singer names?,"pd.merge(singer, song, on='singer_id')[['title', 'name']]"
show distinct names of singers that have songs with sales more than 300000.,"pd.merge(singer, song, on='singer_id').loc[lambda x: x['sales']>300000, 'name'].nunique()"
what are the different names of the singers that have sales more than 300000?,"pd.merge(singer, song, on='singer_id').loc[lambda x: x['sales']>300000, 'name'].nunique()"
show the names of singers that have more than one song.,"singer.merge(song, on='singer_id').groupby('name').filter(lambda x: len(x) > 1)['name'].unique()"
what are the names of the singers that have more than one songs?,"singer.merge(song, on='singer_id').groupby('name').filter(lambda x: len(x) > 1)['name'].unique()"
show the names of singers and the total sales of their songs.,"song.merge(singer, on='singer_id').groupby('name')['sales'].sum()"
"for each singer name, what is the total sales for their songs?","song.merge(singer, on='singer_id').groupby('name')['sales'].sum()"
list the name of singers that do not have any song.,"singer.loc[~singer['singer_id'].isin(song['singer_id']), 'name']"
what is the sname of every sing that does not have any song?,"singer.loc[~singer['singer_id'].isin(song['singer_id']), 'name']"
show the citizenship shared by singers with birth year before 1945 and after 1955.,"singer.loc[singer['birth_year'] < 1945, 'citizenship'].intersects(singer.loc[singer['birth_year'] > 1955, 'citizenship'])"
what are the citizenships that are shared by singers with a birth year before 1945 and after 1955?,"singer.loc[singer['birth_year'] < 1945, 'citizenship'].intersects(singer.loc[singer['birth_year'] > 1955, 'citizenship'])"
how many available features are there in total?,other_available_features.shape[0]
what is the feature type name of feature aircon?,"pd.merge(other_available_features, ref_feature_types, on='feature_type_code').loc[lambda x: x['feature_name'] == 'aircon', 'feature_type_name']"
show the property type descriptions of properties belonging to that code.,"pd.merge(properties, ref_property_types, on='property_type_code').groupby('property_type_code')['property_type_description'].first()"
what are the names of properties that are either houses or apartments with more than 1 room?,"properties.loc[lambda x: x['property_type_code']=='house', 'property_name'].append(properties.loc[lambda x: (x['property_type_code']=='apartment') & (x['room_count']>1), 'property_name']).drop_duplicates()"
what is the total count of departments whose heads are older than 56?,(head['age'] > 56).sum()
"retrieve the names, residence states and ages of department heads arranged by their age.","head[['name', 'born_state', 'age']].sort_values('age')"
"produce a list of the creation year, name and budget of department.","department[['creation', 'name', 'budget_in_billions']]"
determine the maximum and minimum budget of each department.,"department['budget_in_billions'].agg(['max', 'min'])"
what is the average number of employees in departments whose rank falls between 10 and 15?,"department.loc[lambda x: x['ranking'].between(10,15), 'num_employees'].mean()"
what are the names of those heads who were born outside the california state?,"head.loc[lambda x: x['born_state'] != 'california', 'name']"
what is the creation year of the departments managed by secretaries born in alabama?,"pd.merge(pd.merge(department, management, on='department_id'), head, on='head_id').loc[lambda x: x['born_state']=='alabama', 'creation'].unique()"
what are the exact names of the states having at least 3 heads born there?,head.groupby('born_state').filter(lambda x: len(x) >= 3)['born_state'].unique()
what year saw the establishment of the majority of departments?,department.groupby('creation').size().sort_values(ascending=false).index[0]
how do i list the departments with temporary acting heads?,"pd.merge(department, management, on='department_id').loc[lambda x: x['temporary_acting']=='yes', ['name', 'num_employees']]"
what is the count of departments that have leaders not specified?,department[~department['department_id'].isin(management['department_id'])].shape[0]
which set of ages correspond to the heads of departments who are acting?,"pd.merge(head, management, on='head_id').loc[lambda x: x['temporary_acting']=='yes', 'age'].unique()"
list the states that have both the secretary of 'treasury' department and the secretary of 'homeland security' born from these states.,"pd.merge(pd.merge(department.loc[lambda x: x['name']=='treasury'], management, on='department_id'), head, on='head_id')['born_state'].unique() & pd.merge(pd.merge(department.loc[lambda x: x['name']=='homeland security'], management, on='department_id'), head, on='head_id')['born_state'].unique()"
"which department has more than one head at a time? list their id, name, and number of heads.","management.merge(department, on='department_id').groupby(['department_id', 'name']).size().reset_index(name='count').loc[lambda x: x['count']>1, ['department_id', 'name', 'count']]"
which head's name contains the substring ha? provide the id and fullname.,"head.loc[head['name'].str.contains('ha'), ['head_id', 'name']]"
how many farms are there in this dataset?,farm.shape[0]
what is the total count of farms?,farm.shape[0]
list the count of horses in ascending order on farms.,farm.sort_values('total_horses')['total_horses']
"please provide me with the total length for every horse record, arranged from largest to smallest.",farm.sort_values('total_horses')['total_horses']
"retrieve the names of competition hosts whose theme is not ""aliens"".","farm_competition.loc[lambda x: x['theme'] != 'aliens', 'hosts']"
provide me the lists of competitions that didn't have the theme of aliens.,"farm_competition.loc[lambda x: x['theme'] != 'aliens', 'hosts']"
sort the themes for such competitions by year in ascending order.,farm_competition.sort_values('year')['theme']
"please provide me with the themes of farm competitions, arranged in order of ascending year.",farm_competition.sort_values('year')['theme']
how many working horses are there in farms with more than 5000 total number of horses?,"farm.loc[lambda x: x['total_horses'] > 5000, 'working_horses'].mean()"
"how many horses does a farm owner have on average if the total number of horses held by the farm is 5,000 or more?","farm.loc[lambda x: x['total_horses'] > 5000, 'working_horses'].mean()"
which farm had the highest and the lowest number of cows?,"farm['cows'].agg(['max', 'min'])"
provide me with the minimum and maximum stock of cows across all farms.,"farm['cows'].agg(['max', 'min'])"
how many unique status values are there for each city?,city['status'].nunique()
determine the number of unique statuses.,city['status'].nunique()
enumerate the order of official names of cities by population.,"city.sort_values('population', ascending=false)['official_name']"
"display the list of official names of cities, in descending count by population.","city.sort_values('population', ascending=false)['official_name']"
retrieve the title and status of the city with the largest population.,"city[['official_name', 'status']].sort_values('population', ascending=false).head(1)"
what is the official name and status of the municipality with the largest population?,"city[['official_name', 'status']].sort_values('population', ascending=false).head(1)"
provide me with the years and official names of the host cities of competitions.,"pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id')[['year', 'official_name']]"
which years saw the hosting of the olympics? what were the names of the cities that hosted them?,"pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id')[['year', 'official_name']]"
"for each city, provide the name that has the most competitions.","pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id').groupby('host_city_id').filter(lambda x: len(x) > 1)['official_name']"
what are the officially designated names of the cities that hosted more than one competition?,"pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id').groupby('host_city_id').filter(lambda x: len(x) > 1)['official_name']"
please identify the status held by the host city that has hosted the highest number of competitions.,"pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id').groupby('host_city_id')['status'].count().sort_values(ascending=false).head(1)"
which is the largest city that has hosted many tournaments?,"pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id').groupby('host_city_id')['status'].count().sort_values(ascending=false).head(1)"
please list the competitions in which the host city has a population greater than 1000.,"city.merge(farm_competition, left_on='city_id', right_on='host_city_id').loc[lambda x: x['population'] > 1000, 'theme']"
"which competitions have such themes that are associated with host cities that harbor more than 1,000 residents?","city.merge(farm_competition, left_on='city_id', right_on='host_city_id').loc[lambda x: x['population'] > 1000, 'theme']"
please show the cities with respect to their status and the average population of cities with each status.,city.groupby('status')['population'].mean()
what is the count of cities and their populations?,city.groupby('status')['population'].mean()
"please display the statuses of the different cities, arranged by their relative number.",city.groupby('status').size().sort_values().index
"provide me with the distinct statuses of cities, arranged in ascending order of frequency.",city.groupby('status').size().sort_values().index
return me the most common type of status across all cities.,city.groupby('status').size().sort_values(ascending=false).index[0]
what is the status that is the most common across the cities?,city.groupby('status').size().sort_values(ascending=false).index[0]
list the names of cities that have not hosted any competition.,"city.loc[~city['city_id'].isin(farm_competition['host_city_id']), 'official_name']"
what are the official names of the cities that did not host a farm competition?,"city.loc[~city['city_id'].isin(farm_competition['host_city_id']), 'official_name']"
display the status shared by cities with population greater than 1500 and smaller than 500.,"set(city.loc[city['population'] > 1500, 'status']).intersection(set(city.loc[city['population'] < 500, 'status']))"
which statuses correspond to the cities that have a population exceeding 1500 and the cities that have a population below 500?,"set(city.loc[city['population'] > 1500, 'status']).intersection(set(city.loc[city['population'] < 500, 'status']))"
provide me with the official names of cities with a larger population than 1500 or smaller than 500.,"city.loc[(city['population']>1500) | (city['population']<500), 'official_name']"
what are the official names of cities in which the population exceeds or falls below the mentioned numeric range?,"city.loc[(city['population']>1500) | (city['population']<500), 'official_name']"
display the census rank of cities whose status are not village.,"city.loc[lambda x: x['status']!='village', 'census_ranking']"
"which cities are ranked as ""metropolitan"", or ""urbanized"", or ""suburban""?","city.loc[lambda x: x['status']!='village', 'census_ranking']"
which course has the most number of enrollments?,"pd.merge(courses, student_course_registrations, on='course_id').groupby('course_id')['course_name'].count().sort_values(ascending=false).head(1)"
which course registrations have the highest number of registered students?,"pd.merge(courses, student_course_registrations, on='course_id').groupby('course_id')['course_name'].count().sort_values(ascending=false).head(1)"
"determine the name of the student who has enrolled the least courses, and then return the corresponding id.",student_course_registrations.groupby('student_id').size().nsmallest(1).index[0]
what are the ids of students who took the fewest courses for all students?,student_course_registrations.groupby('student_id').size().nsmallest(1).index[0]
which candidates are named john and mary?,"pd.merge(candidates, people, left_on='candidate_id', right_on='person_id')[['first_name', 'last_name']]"
retrieve the first names and the last names of all those candidates for which data is collected.,"pd.merge(candidates, people, left_on='candidate_id', right_on='person_id')[['first_name', 'last_name']]"
"provide the names, ids, and scores of students who never attend courses.","students.loc[~students['student_id'].isin(student_course_attendance['student_id']), 'student_id']"
what is the number of each student who has never attended any courses?,"students.loc[~students['student_id'].isin(student_course_attendance['student_id']), 'student_id']"
please provide me with the ids of students who attended some courses.,student_course_attendance['student_id']
retrieve the primary key of each student who has taken at least one course.,student_course_attendance['student_id']
how many students are there for each course and what are their ids and names?,"pd.merge(student_course_registrations, courses, on='course_id')[['student_id', 'course_name']]"
provide me the information about the most recent student to register a course.,"pd.merge(student_course_registrations, students, on='student_id').sort_values('registration_date', ascending=false).iloc[0]['student_details']"
what is the list of courses recently taken by students?,"pd.merge(student_course_registrations, students, on='student_id').sort_values('registration_date', ascending=false).iloc[0]['student_details']"
what is the maximum number of students taking english courses?,"pd.merge(courses[courses['course_name']=='english'], student_course_attendance, on='course_id').shape[0]"
how many courses does the student whose _id is 171_ attend?,"pd.merge(courses, student_course_attendance, on='course_id').loc[lambda x: x['student_id'] == 171].shape[0]"
what is the count of courses that the student with id 171 actually attends?,"pd.merge(courses, student_course_attendance, on='course_id').loc[lambda x: x['student_id'] == 171].shape[0]"
id of the candidate who possess an email with the address stanley.monahan@example.org?,"candidates.merge(people, left_on='candidate_id', right_on='person_id').loc[lambda x: x['email_address']=='stanley.monahan@example.org', 'candidate_id']"
what is the id of a candidate whose email is stanley.monahan@example.org?,"candidates.merge(people, left_on='candidate_id', right_on='person_id').loc[lambda x: x['email_address']=='stanley.monahan@example.org', 'candidate_id']"
provide me with the id of the candidate that is the most recent user of the course.,"candidate_assessments.sort_values('assessment_date', ascending=false).iloc[0]['candidate_id']"
provide me with the id of the candidate who most recently accessed the course.,"candidate_assessments.sort_values('assessment_date', ascending=false).iloc[0]['candidate_id']"
which student registered the most number of courses?,"students.merge(student_course_registrations, on='student_id').groupby('student_id')['student_details'].unique().sort_values(ascending=false).iloc[0]"
please provide me with the details of a student who signed up for the highest number of courses.,"students.merge(student_course_registrations, on='student_id').groupby('student_id')['student_details'].unique().sort_values(ascending=false).iloc[0]"
give me the ids of students who registered some courses and their corresponding number of courses registered.,"student_course_registrations.groupby('student_id').size().reset_index(name='count').merge(students, on='student_id')[['student_id', 'count']]"
"for every student who is registered for any course, ascertain the number of courses in which they are registered.","student_course_registrations.groupby('student_id').size().reset_index(name='count').merge(students, on='student_id')[['student_id', 'count']]"
provide the name and count of registered students for each course.,"pd.merge(pd.merge(students, student_course_registrations, on='student_id'), courses, on='course_id').groupby('course_name').size()"
"for every course id, how many students are associated with it and what course title is it?","pd.merge(pd.merge(students, student_course_registrations, on='student_id'), courses, on='course_id').groupby('course_name').size()"
"retrieve the ids of candidates whose assessment code is ""pass"".","candidate_assessments.loc[candidate_assessments['asessment_outcome_code']=='pass', 'candidate_id']"
which candidate ids have an outcome code of pass?,"candidate_assessments.loc[candidate_assessments['asessment_outcome_code']=='pass', 'candidate_id']"
"retrieve the cell phone numbers of the candidates whose code assessment is ""fail"".","pd.merge(pd.merge(candidates, candidate_assessments, on='candidate_id'), people, left_on='candidate_id', right_on='person_id').loc[lambda x: x['asessment_outcome_code']=='fail', 'cell_mobile_number']"
"provide the cell phone numbers of the candidates who received a code of ""fail"" on their assessment.","pd.merge(pd.merge(candidates, candidate_assessments, on='candidate_id'), people, left_on='candidate_id', right_on='person_id').loc[lambda x: x['asessment_outcome_code']=='fail', 'cell_mobile_number']"
please provide me with the id number of students who registered for course 301.,"student_course_attendance.loc[lambda x: x['course_id']==301, 'student_id']"
provide me with the identifiers of students who had registered for course 301.,"student_course_attendance.loc[lambda x: x['course_id']==301, 'student_id']"
retrieve the id of student who teaches course 301 most recently.,"student_course_attendance.loc[lambda x: x['course_id']==301].sort_values('date_of_attendance', ascending=false)['student_id'].iloc[0]"
what is the id of the most recent student to register for the course 301?,"student_course_attendance.loc[lambda x: x['course_id']==301].sort_values('date_of_attendance', ascending=false)['student_id'].iloc[0]"
fetch names of cities from addresses of people.,"pd.merge(addresses, people_addresses, on='address_id')['city'].unique()"
what is the list of cities where people tend to reside?,"pd.merge(addresses, people_addresses, on='address_id')['city'].unique()"
enumerate the distinct cities in which students reside.,"pd.merge(pd.merge(addresses, people_addresses, on='address_id'), students, left_on='person_id', right_on='student_id')['city'].unique()"
obtain the list of cities in which students have resided.,"pd.merge(pd.merge(addresses, people_addresses, on='address_id'), students, left_on='person_id', right_on='student_id')['city'].unique()"
please alphabetize the names of courses.,courses['course_name'].sort_values()
what are the names of the courses arranged in alphabetical order?,courses['course_name'].sort_values()
organize the full name of people in alphabetical order.,people['first_name'].sort_values()
provide the names in alphabetical order of all the people.,people['first_name'].sort_values()
provide me with the id of students registering or taking courses.,"pd.concat([student_course_registrations['student_id'], student_course_attendance['student_id']]).drop_duplicates()"
which student ids either registered or attended courses?,"pd.concat([student_course_registrations['student_id'], student_course_attendance['student_id']]).drop_duplicates()"
"given student id 121, return the names of courses that student is registered or attends.","pd.concat([student_course_registrations.loc[student_course_registrations['student_id']==121, 'course_id'], student_course_attendance.loc[student_course_attendance['student_id']==121, 'course_id']]).drop_duplicates()"
determine the ids of courses that are registered or attended by the student whose id is 121.,"pd.concat([student_course_registrations.loc[student_course_registrations['student_id']==121, 'course_id'], student_course_attendance.loc[student_course_attendance['student_id']==121, 'course_id']]).drop_duplicates()"
retrieve the titles of courses that were attended by students but not registered.,student_course_registrations.loc[~student_course_registrations['student_id'].isin(student_course_attendance['student_id'])]
what were the details of students who registered but never participated in any course?,student_course_registrations.loc[~student_course_registrations['student_id'].isin(student_course_attendance['student_id'])]
retrieve the ids of students who registered course statistics in the chronological order of registration.,"student_course_registrations.merge(courses, on='course_id').loc[lambda x: x['course_name']=='statistics'].sort_values('registration_date')['student_id']"
retrieve the ids of the students who registered course statistics ordered by date of registration.,"student_course_registrations.merge(courses, on='course_id').loc[lambda x: x['course_name']=='statistics'].sort_values('registration_date')['student_id']"
provide the chronological order of attendance dates for the students with corresponding id's.,"pd.merge(courses.loc[courses['course_name']=='statistics', ['course_id']], student_course_attendance, on='course_id').sort_values('date_of_attendance')['student_id']"
fetch the ids of students that attended the courses in the statistics department in descending order of their attendance date.,"pd.merge(courses.loc[courses['course_name']=='statistics', ['course_id']], student_course_attendance, on='course_id').sort_values('date_of_attendance')['student_id']"
return me the dates of each year in which the highest temperature exceeded 85 degrees.,"weather.loc[lambda x: x['max_temperature_f'] > 85, 'date']"
what is the count of dates with a maximum temperature higher than 85 degrees?,"weather.loc[lambda x: x['max_temperature_f'] > 85, 'date']"
provide the titles of stations whose latitudes are less than or equal to 37.5.,"station.loc[lambda x: x['lat']<37.5, 'name']"
return me the names of all stations with a latitude smaller than 37.5.,"station.loc[lambda x: x['lat']<37.5, 'name']"
please provide me with the highest latitude of a city among all the stations situated in that city.,station.groupby('city')['lat'].max()
for which cities is the maximum latitude of their respective stations?,station.groupby('city')['lat'].max()
could you provide me with the start station and end station of all trips with the three oldest ids?,"trip[['start_station_name', 'end_station_name']].sort_values('id').head(3)"
prepare a list of the three shortest trip ids along with their corresponding end station and station station.,"trip[['start_station_name', 'end_station_name']].sort_values('id').head(3)"
what are the average latitude and longitude of stations located in san jose city?,"station.loc[lambda x: x['city'] == 'san jose', ['lat', 'long']].mean()"
what is the mean latitude and longitude of san jose?,"station.loc[lambda x: x['city'] == 'san jose', ['lat', 'long']].mean()"
please provide me with the trip id that necessitates the shortest duration.,trip.sort_values('duration')['id'].iloc[0]
how many trips did the bike have and how long did it take to complete those trips?,"trip.loc[trip['bike_id']==636, 'duration'].agg(['sum', 'max'])"
retrieve the total duration and maximum duration of all trips with the bike id 636.,"trip.loc[trip['bike_id']==636, 'duration'].agg(['sum', 'max'])"
"for each zip code, calculate the average mean temperature of august there.","weather.loc[weather['date'].str.startswith('8/'), ['zip_code', 'mean_temperature_f']].groupby('zip_code').mean()"
"for each zip code, determine the average temperature of all dates that start with '8'.","weather.loc[weather['date'].str.startswith('8/'), ['zip_code', 'mean_temperature_f']].groupby('zip_code').mean()"
find the number of motorcycles that are present in all trips.,trip['bike_id'].nunique()
how many bike ids are there?,trip['bike_id'].nunique()
what is the count of distinct cities where stations are located?,station['city'].nunique()
how many cities have these stations?,station['city'].nunique()
how many stations does the city of mountain view have?,(station['city'] == 'mountain view').sum()
please provide me with the total count of stations located in mountain view.,(station['city'] == 'mountain view').sum()
kindly return a list of names of stations that have had at least 7 bikes available for rentals.,"pd.merge(station, status, left_on='id', right_on='station_id').loc[lambda x: x['bikes_available'] == 7, 'name'].unique()"
find the titles that are given to stations that have had seven bicycles available.,"pd.merge(station, status, left_on='id', right_on='station_id').loc[lambda x: x['bikes_available'] == 7, 'name'].unique()"
which start station had the most departures in the month of august? please provide the name and id of this station.,"trip.loc[lambda x: x['start_date'].str.startswith('8/'), ['start_station_name', 'start_station_id']].groupby('start_station_name').size().sort_values(ascending=false).head(1).reset_index()[['start_station_name', 'start_station_id']]"
"provide me with the name of the station with the highest number of starts in the month of august, and the id of that station.","trip.loc[lambda x: x['start_date'].str.startswith('8/'), ['start_station_name', 'start_station_id']].groupby('start_station_name').size().sort_values(ascending=false).head(1).reset_index()[['start_station_name', 'start_station_id']]"
which bike was ridden the most frequently in the zip code 94002?,trip.loc[lambda x: x['zip_code']==94002].groupby('bike_id').size().sort_values(ascending=false).index[0]
provide me with the id of bike that went most in 1994.,trip.loc[lambda x: x['zip_code']==94002].groupby('bike_id').size().sort_values(ascending=false).index[0]
how many days have both mean humidity higher than 50 and mean visibility higher than 8?,(weather['mean_humidity'] > 50 & weather['mean_visibility_miles'] > 8).sum()
how many days had an average humidity above 50 and an average visibility above 8?,(weather['mean_humidity'] > 50 & weather['mean_visibility_miles'] > 8).sum()
"give the latitude and longitude, along with the city and state, of the station from which the shortest trip started.","pd.merge(station, trip, left_on='id', right_on='start_station_id').sort_values('duration').iloc[0][['lat', 'long', 'city']]"
"what is the latitude, longitude, and city of the station from which the trip with shortest duration was started?","pd.merge(station, trip, left_on='id', right_on='start_station_id').sort_values('duration').iloc[0][['lat', 'long', 'city']]"
provide the ids of stations that are located in san francisco and have average bike availability exceeding 10.,"station.loc[station['city'] == 'san francisco', 'id'].tolist() & status.groupby('station_id').filter(lambda x: x['bikes_available'].mean() > 10)['station_id'].tolist()"
provide the id and name of stations in san francisco that have more than 10 bikes available for use.,"station.loc[station['city'] == 'san francisco', 'id'].tolist() & status.groupby('station_id').filter(lambda x: x['bikes_available'].mean() > 10)['station_id'].tolist()"
provide me the titles and complete names of stations that had more than 14 bikes on average or that were installed in december.,"pd.concat([pd.merge(station, status, on='id').groupby('id').filter(lambda x: x['bikes_available'].mean() > 14)[['name', 'id']],station.loc[lambda x: x['installation_date'].str.startswith('12/'), ['name', 'id']]])"
retrieve the name of the stations having more than 14 bicycles on average and bicycles installed in december.,"pd.concat([pd.merge(station, status, on='id').groupby('id').filter(lambda x: x['bikes_available'].mean() > 14)[['name', 'id']],station.loc[lambda x: x['installation_date'].str.startswith('12/'), ['name', 'id']]])"
what is the 3 most common cloud cover rates in zip code 94107?,weather.loc[lambda x: x['zip_code']==94107].groupby('cloud_cover').size().sort_values(ascending=false).head(3).reset_index()['cloud_cover']
how many instances of the 3 cloud types that are most prevalent in the zip code 94107?,weather.loc[lambda x: x['zip_code']==94107].groupby('cloud_cover').size().sort_values(ascending=false).head(3).reset_index()['cloud_cover']
determine the zip code that reports the lowest mean sea level pressure.,weather.groupby('zip_code')['mean_sea_level_pressure_inches'].mean().sort_values().head(1).index[0]
which zip code has the lowest average mean sea level pressure?,weather.groupby('zip_code')['mean_sea_level_pressure_inches'].mean().sort_values().head(1).index[0]
what is the median quantity of bikes in stations that are not found in palo alto?,"status[~status['station_id'].isin(station.loc[station['city']=='palo alto', 'id'])]['bikes_available'].mean()"
please provide me with the average bike availability for stations not in palo alto.,"status[~status['station_id'].isin(station.loc[station['city']=='palo alto', 'id'])]['bikes_available'].mean()"
what is the average of longitude of stations where bike availability has never been more than 10?,"station.loc[~station['id'].isin(status.groupby('station_id').filter(lambda x: x['bikes_available'].max() > 10)['station_id']), 'long'].mean()"
what is the mean longitude for all stations that have never featured more than 10 bikes?,"station.loc[~station['id'].isin(status.groupby('station_id').filter(lambda x: x['bikes_available'].max() > 10)['station_id']), 'long'].mean()"
which year saw the highest temperature reach 80?,"weather.loc[lambda x: x['max_temperature_f'] >= 80, ['date', 'zip_code']]"
"provide me with the zip codes along with the exact temperature that was reached. also, provide me with the timestamp when that temperature was reached.","weather.loc[lambda x: x['max_temperature_f'] >= 80, ['date', 'zip_code']]"
please give me a list of zip codes in which more than 80 trips occur out of which at least 5 have a mean temperature above 60.,"trip.merge(weather, on='zip_code').groupby('zip_code').filter(lambda x: x['mean_temperature_f'].mean() > 60)['id']"
provide the output wherein the list of zip codes is provided along with a list of trips and the average temperature of each trip.,"trip.merge(weather, on='zip_code').groupby('zip_code').filter(lambda x: x['mean_temperature_f'].mean() > 60)['id']"
"for each zip code, determine the number of times that the maximum wind speed reached 25.",weather.loc[lambda x: x['max_wind_speed_mph']>=25].groupby('zip_code').size()
"for each zip code, how many instances has the maximum wind speed reached 25 mph?",weather.loc[lambda x: x['max_wind_speed_mph']>=25].groupby('zip_code').size()
what day and in which zip code was the minimum dew point lower than any day in zip code 94107?,"weather.loc[weather['min_dew_point_f'] < weather.loc[weather['zip_code'] == 94107, 'min_dew_point_f'].min(), ['date', 'zip_code']]"
"for each trip, return the installation date of the final station.","pd.merge(trip, station, left_on='end_station_id', right_on='id')[['id', 'installation_date']]"
what are the installation dates for the ending station on all the trips?,"pd.merge(trip, station, left_on='end_station_id', right_on='id')[['id', 'installation_date']]"
which trip started from the station with the largest dock count? provide me the trip id.,"trip.merge(station, left_on='start_station_id', right_on='id').sort_values('dock_count', ascending=false).iloc[0]['id']"
could you provide me with the unique identifier of the trip that started from the station with the highest count of docks?,"trip.merge(station, left_on='start_station_id', right_on='id').sort_values('dock_count', ascending=false).iloc[0]['id']"
what is the count of trips that did not result in the arrival at san francisco city?,"pd.merge(trip, station, left_on='end_station_id', right_on='id').loc[lambda x: x['city']!='san francisco'].shape[0]"
for how many trips did san francisco not serve as an endpoint?,"pd.merge(trip, station, left_on='end_station_id', right_on='id').loc[lambda x: x[""city""] != ""san francisco""].shape[0]"
in which day neither fog nor rain was observed by zip code 94107?,"weather.loc[(weather['zip_code']==94107) & (weather['events']!='fog') & (weather['events']!='rain'), 'date']"
on which day has neither been foggy nor rained in the zip code of 94107?,"weather.loc[(weather['zip_code']==94107) & (weather['events']!='fog') & (weather['events']!='rain'), 'date']"
which stations have a latitude higher than 37.4 and never had bike availability below 7?,"station.loc[lambda x: x['lat'] > 37.4].merge(status, on='station_id').groupby('station_id').min().loc[lambda x: x['bikes_available']>=7].reset_index()['station_id']"
give me the ids of all stations whose latitude is above 37.4 and that have never had less than 7 bikes available.,"station.loc[lambda x: x['lat'] > 37.4].merge(status, on='station_id').groupby('station_id').min().loc[lambda x: x['bikes_available']>=7].reset_index()['station_id']"
retrieve the names of stations that possess an average bike availability higher than 10 and are not located in san jose city.,"station.merge(status, on='id').groupby('station_id').filter(lambda x: x['bikes_available'].mean() > 10)['name'].drop_duplicates().loc[lambda x: x!='san jose']"
which stations are nearest to san jose and possess more than 10 bicycles?,"station.merge(status, on='id').groupby('station_id').filter(lambda x: x['bikes_available'].mean() > 10)['name'].drop_duplicates().loc[lambda x: x!='san jose']"
"provide me with the title, latitude, and city of the station that possesses the lowest latitude.","station[['name', 'lat', 'city']].sort_values('lat').head(1)"
"retrieve the title, latitude, and city of the station that is the furthest south.","station[['name', 'lat', 'city']].sort_values('lat').head(1)"
"provide the mean temperature, mean humidity and maximum gust speed for the top three highest values for each respective attribute.","weather[['date', 'mean_temperature_f', 'mean_humidity']].sort_values('max_gust_speed_mph', ascending=false).head(3)"
"for which dates, temperatures and humidity levels did the highest gusts occur?","weather[['date', 'mean_temperature_f', 'mean_humidity']].sort_values('max_gust_speed_mph', ascending=false).head(3)"
enumerate the names of the cities that have 15 or more stations.,station.groupby('city').filter(lambda x: len(x) >= 15).groupby('city').size()
"""list the names of all cities that have at least 15 stations. also provide the number of stations in each city.""",station.groupby('city').filter(lambda x: len(x) >= 15).groupby('city').size()
figure out the ids and names of stations from which at least 200 trips started.,"trip.groupby(['start_station_id', 'start_station_name']).filter(lambda x: len(x) >= 200)['start_station_id', 'start_station_name'].drop_duplicates(subset='start_station_id')"
what are the ids of stations that started at least 200 trips?,"trip.groupby(['start_station_id', 'start_station_name']).filter(lambda x: len(x) >= 200)['start_station_id', 'start_station_name'].drop_duplicates(subset='start_station_id')"
determine the zip code in which the maximum average mean visibility is observed below 10.,weather.groupby('zip_code').filter(lambda x: x['mean_visibility_miles'].mean() < 10)['zip_code'].unique()
"for each zip code, select all for which the mean visibility is below 10.",weather.groupby('zip_code').filter(lambda x: x['mean_visibility_miles'].mean() < 10)['zip_code'].unique()
write down the highest latitude of each city in descending order.,station.groupby('city')['lat'].max().sort_values(ascending=false).index.tolist()
list the names of cities in decreasing order by their highest latitude.,station.groupby('city')['lat'].max().sort_values(ascending=false).index.tolist()
"can you please provide me with the year when the top 5 cloud cover rates occurred? also, provide me with the cloud cover rates.","weather[['date', 'cloud_cover']].sort_values('cloud_cover',ascending=false).head(5)"
what are the dates that have the 5 highest cloud cover rates and which rates are they?,"weather[['date', 'cloud_cover']].sort_values('cloud_cover',ascending=false).head(5)"
could you please provide me with the ids and durations of the trips containing the top three durations?,"trip[['id', 'duration']].sort_values('duration', ascending=false).head(3)"
retrieve the ids of trips that went on for the longest time and the length of time those trips lasted.,"trip[['id', 'duration']].sort_values('duration', ascending=false).head(3)"
"for each station, please provide me with its longitude and the average duration of trips starting from the station.","trip.groupby('start_station_id').agg(avg_duration=('duration','mean')).reset_index().merge(station[['id','name','long']], left_on='start_station_id', right_on='id')[['name','long','avg_duration']]"
"for each start station code, what is its title, longitude and average duration of trips originated there?","trip.groupby('start_station_id').agg(avg_duration=('duration','mean')).reset_index().merge(station[['id','name','long']], left_on='start_station_id', right_on='id')[['name','long','avg_duration']]"
please provide me with the latitude and longitude of each station along with the minimum number of trips that ended at the station.,"pd.merge(station, trip, left_on='id', right_on='end_station_id').groupby('end_station_id').agg({'name': 'first', 'lat': 'first', 'duration': 'min'})[['name', 'lat', 'duration']]"
"for each end station id, retrieve its full name, latitude, and minimum duration for trips ended there.","pd.merge(station, trip, left_on='id', right_on='end_station_id').groupby('end_station_id').agg({'name': 'first', 'lat': 'first', 'duration': 'min'})[['name', 'lat', 'duration']]"
what is the list of all stations from which trips of duration less than 100 started?,"trip.loc[lambda x: x['duration'] < 100, 'start_station_name'].unique()"
provide me with the list of all start station names for a trip that lasted less than 100 minutes.,"trip.loc[lambda x: x['duration'] < 100, 'start_station_name'].unique()"
find all the zip codes in which the dew point has never reached 70.,"weather.loc[lambda x: x['max_dew_point_f'] < 70, 'zip_code'].unique()"
get a list of the zip codes that had a minimum average dew point smaller than 70.,"weather.loc[lambda x: x['max_dew_point_f'] < 70, 'zip_code'].unique()"
provide me the id for trips that can last at least as long as the average of the duration of trips in zip code 94103.,"trip.loc[lambda x: x['duration'] >= trip.loc[lambda y: y['zip_code'] == 94103, 'duration'].mean(), 'id']"
identify the ids of all trips whose duration was as long as the average duration of trips in the zip code 94103,"trip.loc[lambda x: x['duration'] >= trip.loc[lambda y: y['zip_code'] == 94103, 'duration'].mean(), 'id']"
determine when the mean sea level pressure is between 30.3 and 31.,"weather.loc[(weather['mean_sea_level_pressure_inches'] > 30.3) & (weather['mean_sea_level_pressure_inches'] < 31), 'date']"
what is the date corresponding to sea level pressures between 30.3 and 31?,"weather.loc[(weather['mean_sea_level_pressure_inches'] > 30.3) & (weather['mean_sea_level_pressure_inches'] < 31), 'date']"
determine the date in which the maximum temperature and the minimum temperature were the smallest. also provide the difference.,"weather.assign(temp_range=weather['max_temperature_f'] - weather['min_temperature_f']).sort_values('temp_range').iloc[0][['date', 'temp_range']]"
provide the count of days with the smallest variation in weather and their temperature range.,"weather.assign(temp_range=weather['max_temperature_f'] - weather['min_temperature_f']).sort_values('temp_range').iloc[0][['date', 'temp_range']]"
retrieve the list of stations along with the number of times they had more than 12 bikes available.,"pd.merge(station, status.query('bikes_available > 12')[['station_id']], left_on='id', right_on='station_id')[['id', 'name']].drop_duplicates()"
retrieve the names of stations at which 12 or more bikes were available.,"pd.merge(station, status.query('bikes_available > 12')[['station_id']], left_on='id', right_on='station_id')[['id', 'name']].drop_duplicates()"
find the zip code where the average mean humidity is under 70 and at least 100 trips have taken place.,weather.groupby('zip_code').mean().loc[lambda x: x['mean_humidity'] < 70].reset_index()['zip_code'].isin(trip['zip_code'].value_counts().loc[lambda x: x >= 100].index).values
please provide me with the zip codes with average mean humidity below 70 and at least 100 trips.,weather.groupby('zip_code').mean().loc[lambda x: x['mean_humidity'] < 70].reset_index()['zip_code'].isin(trip['zip_code'].value_counts().loc[lambda x: x >= 100].index).values
retrieve the names of stations residing in palo alto city that have never been the ending point of trips more than 100 times.,"station.loc[lambda x: x['city']=='palo alto', 'name'].loc[lambda x: ~x.isin(trip.groupby('end_station_name').filter(lambda x: len(x)>100).end_station_name.unique())]"
"please provide me with the names of stations that are not located in palo alto, and have never been the ending point of the trips.","station.loc[lambda x: x['city']=='palo alto', 'name'].loc[lambda x: ~x.isin(trip.groupby('end_station_name').filter(lambda x: len(x)>100).end_station_name.unique())]"
determine the number of trips from mountain view city that ended up at palo alto city.,"pd.merge(pd.merge(pd.merge(station, trip, left_on='id', right_on='start_station_id'), station, left_on='end_station_id', right_on='id', suffixes=('_start', '_end')),trip, on='id').loc[lambda x: (x['city_start'] == 'mountain view') & (x['city_end'] == 'palo alto'), :].shape[0]"
what is the count of journeys starting from a station in mountain view and terminating at a destination in palo alto?,"pd.merge(pd.merge(pd.merge(station, trip, left_on='id', right_on='start_station_id'), station, left_on='end_station_id', right_on='id', suffixes=('_start', '_end')),trip, on='id').loc[lambda x: (x['city_start'] == 'mountain view') & (x['city_end'] == 'palo alto'), :].shape[0]"
"how many trips have a start point that is within a 50-mile radius of downtown boston, massachusetts?","pd.merge(station, trip, left_on='id', right_on='start_station_id').agg({'lat': 'mean', 'long': 'mean'})"
what is the average longitude and latitude of all starting stations for the trips?,"pd.merge(station, trip, left_on='id', right_on='start_station_id').agg({'lat': 'mean', 'long': 'mean'})"
please provide me the number of books.,book.shape[0]
the author of the books in ascending alphabetical order is requested by you.,book.sort_values('writer')['writer']
present the titles of the books in ascending order of printings,book.sort_values('issues')['title']
"provide the names of the books whose author is not ""elaine lee.""","book.loc[lambda x: x['writer'] != 'elaine lee', 'title']"
determine the titles and publication dates of the books.,"book[['title', 'issues']]"
what is the order of publication dates in descending order of price?,"publication.sort_values('price', ascending=false)['publication_date']"
determine the sort of publishers for the journals with price higher than 5000000.,"publication.loc[lambda x: x['price'] > 5000000, 'publisher'].unique()"
provide the details of the publisher who published the publication with the maximum price.,"publication.sort_values('price', ascending=false).iloc[0]['publisher']"
enumerate the publication dates of the papers with the average price of 3 usd or less.,publication.sort_values('price').head(3)['publication_date']
display the title and year of publication of books.,"pd.merge(book, publication, on='book_id')[['title', 'publication_date']]"
display the names of writers who have published books with a price greater than 4000000,"book.merge(publication, on='book_id').loc[lambda x: x['price'] > 4000000, 'writer']"
show the titles of books in decreasing order of publishing price.,"pd.merge(book, publication, on='book_id').sort_values('price', ascending=false)['title']"
return the names of publishers that have at least two published materials.,publication.groupby('publisher').filter(lambda x: len(x) > 1)['publisher'].unique()
provide the names and counts of publishers.,publication.groupby('publisher').size().reset_index(name='count')
could you give me the most common publication date?,publication.groupby('publication_date').size().sort_values(ascending=false).index[0]
what are the full names of writers who have published more than one book?,book.groupby('writer').filter(lambda x: len(x) > 1)['writer']
identify the titles of the books that are not published.,"book.loc[~book['book_id'].isin(publication['book_id']), 'title']"
"please find publishers that have publications with price greater than 10,000,000 and publications with price less than 5,000,000.","pd.merge(publication.loc[lambda x: x['price'] > 10000000, 'publisher'], publication.loc[lambda x: x['price'] < 5000000, 'publisher']).drop_duplicates()"
what is the count of distinct publication dates?,publication['publication_date'].nunique()
how many distinct publication dates are there in our dataset?,publication['publication_date'].nunique()
"list down the prices of publications whose publisher is either ""person"" or ""wiley""","publication.loc[lambda x: x['publisher'].isin(['person', 'wiley']), 'price']"
provide the names of actors in a reverse chronological order.,actor.sort_values('name')['name']
"return the titles of actors, organized in alphabetical order.",actor.sort_values('name')['name']
what is the count of characters and duration of actors?,"actor[['character', 'duration']]"
provide me with the names and durations of actors.,"actor[['character', 'duration']]"
i need the names of actors whose age is not 20.,"actor.loc[lambda x: x['age'] != 20, 'name']"
please provide me with the titles of those actors who do not possess ages of 20 years.,"actor.loc[lambda x: x['age'] != 20, 'name']"
give the names of actors in descending order of age.,"actor.sort_values('age', ascending=false)['character']"
"provide me the details of the actors, ordered in descending order of age.","actor.sort_values('age', ascending=false)['character']"
how long is the oldest actor?,"actor.sort_values('age', ascending=false).iloc[0]['duration']"
what is the duration for the actor with the greatest age?,"actor.sort_values('age', ascending=false).iloc[0]['duration']"
"retrieve the names of musicals whose nominee is ""bob fosse""","musical.loc[musical['nominee']=='bob fosse', 'name']"
please return the names of musicals with bob fosse as a nominee.,"musical.loc[musical['nominee']=='bob fosse', 'name']"
identify the distinct titles of musicals with awards other than tony.,"musical.loc[lambda x: x['award'] != 'tony award', 'nominee'].unique()"
provide me with the titles of musicals that have an award that is not the tony award.,"musical.loc[lambda x: x['award'] != 'tony award', 'nominee'].unique()"
please list out the names of all actors and the musicals in which they have participated.,"pd.merge(actor, musical, on='musical_id')[['name_x', 'name_y']]"
retrieve the names of actors and the musicals in which they are performing.,"pd.merge(actor, musical, on='musical_id')[['name_x', 'name_y']]"
"what is the number of actors that have appeared in the musical ""the phantom of the opera""?","actor.merge(musical.loc[musical['name'] == 'the phantom of the opera', ['musical_id']], on='musical_id')['name']"
"retrieve the names of actors who were cast in the play titled ""the phantom of the opera"".","actor.merge(musical.loc[musical['name'] == 'the phantom of the opera', ['musical_id']], on='musical_id')['name']"
provide a list of actors in descending order of the year in which their musical was awarded.,"pd.merge(actor, musical, on='musical_id').sort_values('year', ascending=false)['name']"
provide me with the titles of actors ordered descending by the year when their particular musical was honored.,"pd.merge(actor, musical, on='musical_id').sort_values('year', ascending=false)['name']"
provide me with the titles of all the musicals and the number of actors who have appeared in these musicals.,"actor.merge(musical, on='musical_id').groupby('musical_id')['name'].count().reset_index().rename(columns={'name': 'count'}).merge(musical, on='musical_id')[['name', 'count']]"
how many times did each actor appear in each musical?,"actor.merge(musical, on='musical_id').groupby('musical_id')['name'].agg(['count', 'first'])"
list the titles of all musicals that have 3 or more performers.,"pd.merge(actor, musical, on='musical_id').groupby(['musical_id', 'name']).size().loc[lambda x: x>=3].reset_index().loc[:, 'name']"
retrieve the titles of plays that utilize at 3 or more actors.,"pd.merge(actor, musical, on='musical_id').groupby(['musical_id', 'name']).size().loc[lambda x: x>=3].reset_index().loc[:, 'name']"
provide the nomination information and the number of musicals for which each nominee was nominated.,musical.groupby('nominee').size().reset_index(name='count')
what is the count of musicals for which each nominee has been nominated?,musical.groupby('nominee').size().reset_index(name='count')
please list out the titles that have been nominated for the greatest number of times.,musical.groupby('nominee').size().sort_values(ascending=false).index[0]
find the names of nominees who have been nominated for the most musicals.,musical.groupby('nominee').size().sort_values(ascending=false).index[0]
return the most occurring genres of the musicals.,musical.groupby('result').size().sort_values(ascending=false).index[0]
please find the top-ranking result for all musicals.,musical.groupby('result').size().sort_values(ascending=false).index[0]
what are the titles of musicals that have been nominated more than two times?,musical.groupby('nominee').filter(lambda x: len(x) > 2)['nominee'].unique()
retrieve the persons who have been nominated more than twice.,musical.groupby('nominee').filter(lambda x: len(x) > 2)['nominee'].unique()
list the titles of any musicals that do not feature actors.,"musical.loc[~musical['musical_id'].isin(actor['musical_id']), 'name']"
retrieve the titles of musicals that do not have any actors.,"musical.loc[~musical['musical_id'].isin(actor['musical_id']), 'name']"
list the nominees that bagged the tony award and the drama desk award.,"musical.loc[musical['award']=='tony award', 'nominee'].interesect(musical.loc[musical['award']=='drama desk award', 'nominee'])"
who is the count of the people who have received a nomination for both a tony award and a drama desk award?,"musical.loc[musical['award']=='tony award', 'nominee'].interesect(musical.loc[musical['award']=='drama desk award', 'nominee'])"
please provide me with the nominee for an award with the name of bob fosse or cleavant derricks.,"musical.loc[musical['award'].isin(['tony award', 'cleavant derricks']), 'nominee']"
who are those nominees who were nominated for either the bob fosse or cleavant derricks awards?,"musical.loc[musical['award'].isin(['tony award', 'cleavant derricks']), 'nominee']"
"provide a name of an email belonging to the user ""mary"".","user_profiles.loc[lambda x: x['name']=='mary', 'email']"
"what is the id of the partition of the user named ""iron man"".","user_profiles.loc[lambda x: x['name']=='iron man', 'partitionid']"
how many users are there in the system?,user_profiles.shape[0]
what are the follower counts for each user?,follows.shape[0]
please provide me with the count of followers by each user.,follows.groupby('f1').size()
what is the count of tweets in the record?,tweets.shape[0]
provide the count of users who have some tweets.,tweets['uid'].nunique()
please find the user whose name contains the word ‘swift’.,"user_profiles.loc[user_profiles['name'].str.contains('swift'), ['name', 'email']]"
"retrieve the titles of users whose emails have either ‘superstar’, ‘edu’ or both.","user_profiles.loc[user_profiles['email'].str.contains('superstar|edu'), 'name']"
return the text of the tweets that mention the topic 'intern'.,"tweets.loc[tweets['text'].str.contains('intern', case=false), 'text']"
obtain the titles of users whose accounts have more than 1000 followers.,"user_profiles.loc[user_profiles['followers'] > 1000, ['name', 'email']]"
"select the names of users who are followed by more other users than the user named ""tyler swift"".","user_profiles.loc[lambda x: x['uid'].isin(follows['f1'].groupby(follows['f1']).count().pipe(lambda s:s[s > user_profiles['name'].eq('tyler swift').sum()]).index), 'name']"
obtain the name and email address of users which have more than 1 follower.,"user_profiles.merge(follows, left_on='uid', right_on='f1').groupby(['uid', 'name', 'email']).filter(lambda x: len(x) > 1).loc[:, ['name', 'email']].drop_duplicates()"
retrieve the names for the users who have at least one tweet.,"pd.merge(user_profiles, tweets, on='uid').groupby('uid').filter(lambda x: len(x) > 1)['name']"
determine the id of users who were followed by mary and susan.,"follows.merge(user_profiles[user_profiles['name'] == 'mary'], left_on='f2', right_on='uid')['f1'].intersec‌t(follows.merge(user_profiles[user_profiles['name'] == 'susan'], left_on='f2', right_on='uid')['f1'])"
determine the identities of users who follow mary or susan.,"pd.merge(user_profiles[user_profiles['name'].isin(['mary', 'susan'])], follows, left_on='uid', right_on='f2')['f1']"
match the name of the user followed in least number of contacts.,"user_profiles[['name', 'email', 'followers']].sort_values('followers').iloc[0, :2]"
"retrieve the titles of users and the number of followers, and sort the results by followers in descending order.","user_profiles[['name', 'followers']].sort_values('followers', ascending=false)"
list the names of the users followed by the highest number of other users.,"user_profiles.sort_values('followers', ascending=false).iloc[:5]['name']"
arrange the tweets in chronological order.,tweets.sort_values('createdate')['text']
provide me the names and counts of tweets written by each user.,"tweets.merge(user_profiles, on='uid').groupby('uid')['name'].count().reset_index()"
obtain the title and partition ids for users that tweeted fewer than twice.,"pd.merge(user_profiles, tweets, on='uid').groupby(['uid', 'name', 'partitionid']).filter(lambda x: len(x)<2)[['name', 'partitionid']].drop_duplicates()"
"retrieve the names of the users that tweeted more than once, and the count of tweets posted by them.","pd.merge(user_profiles, tweets, on='uid').groupby('uid')['name'].count().loc[lambda x: x > 1]"
determine the average number of followers for twitter users who do not have any tweet.,"user_profiles.loc[~user_profiles['uid'].isin(tweets['uid']), 'followers'].mean()"
obtain the average count of followers for users who had some tweets.,user_profiles.loc[user_profiles['uid'].isin(tweets['uid'])]['followers'].mean()
find the maximum count of followers and the total number of followers for all users.,"user_profiles['followers'].agg(['max', 'sum'])"
return the names of all catalog entries.,catalog_contents['catalog_entry_name'].unique()
could you provide me with the names of all catalog entries?,catalog_contents['catalog_entry_name'].unique()
generate the list of attribute data types possessed by more than three distinct attribute definitions.,attribute_definitions.groupby('attribute_data_type').filter(lambda x: len(x) > 3)['attribute_data_type'].unique()
which attribute data types have more than 3 defined attributes?,attribute_definitions.groupby('attribute_data_type').filter(lambda x: len(x) > 3)['attribute_data_type'].unique()
"what type of data is represented by the attribute named ""green""?","attribute_definitions.loc[lambda x: x['attribute_name']=='green', 'attribute_data_type']"
"what is the data type for the attribute named ""green""?","attribute_definitions.loc[lambda x: x['attribute_name']=='green', 'attribute_data_type']"
retrieve the title and catalog level of catalog structure with levels between 5 and 10.,"catalog_structure.loc[(catalog_structure['catalog_level_number'] >= 5) & (catalog_structure['catalog_level_number'] <= 10), ['catalog_level_name', 'catalog_level_number']]"
retrieve names of catalog structure with level number between 5 and 10,"catalog_structure.loc[(catalog_structure['catalog_level_number'] >= 5) & (catalog_structure['catalog_level_number'] <= 10), ['catalog_level_name', 'catalog_level_number']]"
"what catalog publishers have substring ""murray"" in their names?","catalogs.loc[catalogs['catalog_publisher'].str.contains('murray', case=false), 'catalog_publisher'].unique()"
which publisher has published the most catalogs?,catalogs.groupby('catalog_publisher').size().sort_values(ascending=false).index[0]
retrieve the publisher with the largest catalog collection.,catalogs.groupby('catalog_publisher').size().sort_values(ascending=false).index[0]
find the title and publication dates of all catalogs which have catalog number more than 5.,"pd.merge(catalogs, catalog_structure, on='catalog_id').loc[lambda x: x['catalog_level_number'] > 5, ['catalog_name', 'date_of_publication']]"
please give me the title and publication date of the catalogs that have catalog level number above 5.,"pd.merge(catalogs, catalog_structure, on='catalog_id').loc[lambda x: x['catalog_level_number'] > 5, ['catalog_name', 'date_of_publication']]"
retrieve the names of the catalog with the attribute that is possessed by the largest number of entries.,"catalog_contents.merge(catalog_contents_additional_attributes[catalog_contents_additional_attributes['attribute_value'] == catalog_contents_additional_attributes['attribute_value'].value_counts().index[0]], on='catalog_entry_id')['catalog_entry_name']"
determine the titles of the catalog that contains the most entries.,"catalog_contents.merge(catalog_contents_additional_attributes.query(""attribute_value == @catalog_contents_additional_attributes['attribute_value'].value_counts().index[0]""), on='catalog_entry_id')['catalog_entry_name']"
what are the names of the books that have the most expensive prices?,"catalog_contents.sort_values('price_in_dollars', ascending=false).iloc[0]['catalog_entry_name']"
retrieve the entry tag of catalogs with the highest price (in usd).,"catalog_contents.sort_values('price_in_dollars', ascending=false).iloc[0]['catalog_entry_name']"
what is the catalog that costs the least?,"pd.merge(catalog_contents, catalog_structure, on='catalog_level_number').sort_values('price_in_dollars').iloc[0]['catalog_level_name']"
retrieve the lowest-priced (in usd) catalog's name.,"pd.merge(catalog_contents, catalog_structure, on='catalog_level_number').sort_values('price_in_dollars').iloc[0]['catalog_level_name']"
please provide me with the average and minimum price of all products expressed in euro.,"catalog_contents['price_in_euros'].agg(['mean', 'min'])"
provide me with the average and minimum price (in euro) of the products.,"catalog_contents['price_in_euros'].agg(['mean', 'min'])"
what is the catalog entry (title) with the highest height?,"catalog_contents.sort_values('height', ascending=false).iloc[0]['catalog_entry_name']"
"determine the name of the product that possesses the least capacity.#### 0.1.0* _august 3, 2019_* initial release",catalog_contents.sort_values('capacity').iloc[0]['catalog_entry_name']
which catalog entry is the smallest? return the catalog entry name.,catalog_contents.sort_values('capacity').iloc[0]['catalog_entry_name']
"fetch titles of all products whose stock number starts with ""2"".","catalog_contents.loc[lambda x: x['product_stock_number'].str.startswith('2'), 'catalog_entry_name']"
"which catalog contents have a product stock number that starts with ""2""? show me the catalog entry names.","catalog_contents.loc[lambda x: x['product_stock_number'].str.startswith('2'), 'catalog_entry_name']"
retrieve the titles of catalog entries that have a level of 8.,"pd.merge(catalog_contents, catalog_contents_additional_attributes, on='catalog_entry_id').loc[lambda x: x['catalog_level_number']=='8', 'catalog_entry_name']"
what is the listing for entries of level 8 in catalog names?,"pd.merge(catalog_contents, catalog_contents_additional_attributes, on='catalog_entry_id').loc[lambda x: x['catalog_level_number']=='8', 'catalog_entry_name']"
"obtain the names of the products whose length or height is 3 or smaller, respectively, than 5.","catalog_contents.loc[(catalog_contents['length'] < 3) | (catalog_contents['width'] > 5), 'catalog_entry_name']"
which catalog contents have length below 3 or above 5? extract the catalog entry names.,"catalog_contents.loc[(catalog_contents['length'] < 3) | (catalog_contents['width'] > 5), 'catalog_entry_name']"
retrieve the id and name of the attribute definitions which have the attribute value 0.,"pd.merge(attribute_definitions, catalog_contents_additional_attributes.loc[lambda x: x['attribute_value']==0], on='attribute_id')[['attribute_name', 'attribute_id']]"
which attributes of record type x have attribute value 0? please provide me the attribute name and attribute id.,"pd.merge(attribute_definitions, catalog_contents_additional_attributes.loc[lambda x: x['attribute_value']==0], on='attribute_id')[['attribute_name', 'attribute_id']]"
return the names of the products that are sold for greater than $700 and their respective capacity.,"catalog_contents.loc[lambda x: x['price_in_dollars']>700, ['catalog_entry_name', 'capacity']]"
find the names of catalogs which have prices above 700 dollars. show the catalog entry names and the capacities.,"catalog_contents.loc[lambda x: x['price_in_dollars']>700, ['catalog_entry_name', 'capacity']]"
determine the dates on which more than one revisions of the document were made.,catalogs.groupby('date_of_latest_revision').filter(lambda x: len(x) > 1)['date_of_latest_revision'].unique()
retrieve the days on which multiple revisions were applied to the catalogs.,catalogs.groupby('date_of_latest_revision').filter(lambda x: len(x) > 1)['date_of_latest_revision'].unique()
what is the count of products in the dataset?,catalog_contents.shape[0]
retrieve the total number of catalog contents.,catalog_contents.shape[0]
retrieve the title of the products whose next entry id is greater than 8.,"catalog_contents.loc[lambda x: x['next_entry_id'] > 8, 'catalog_entry_name']"
determine the catalog entry names of the products with id above 8000.,"catalog_contents.loc[lambda x: x['next_entry_id'] > 8, 'catalog_entry_name']"
how many aircraft do we have?,len(aircraft)
how many aircrafts are present in our database?,len(aircraft)
list the names and distances of all aircrafts.,"aircraft[['name', 'distance']]"
retrieve the names of airplanes and their respective distances.,"aircraft[['name', 'distance']]"
"display the ids for all aircrafts with a distance of over 1,000 kilometers.","aircraft.loc[aircraft['distance'] > 1000, 'aid']"
kindly retrieve the ids of all aircraft that can cover a distance greater than 1000.,"aircraft.loc[aircraft['distance'] > 1000, 'aid']"
what is the count of aircrafts that have distances between 1000 and 5000?,"aircraft.loc[aircraft['distance'].between(1000, 5000)].shape[0]"
determine the total count of aircrafts that have a range between 1000 and 5000.,"aircraft.loc[aircraft['distance'].between(1000, 5000)].shape[0]"
retrieve the name and distance for aircraft with id 12.,"aircraft.loc[aircraft['aid']==12, ['name', 'distance']]"
what is the name and the distance of the aircraft that has an id of 12?,"aircraft.loc[aircraft['aid']==12, ['name', 'distance']]"
"please provide me with the average, minimum, and maximum distance of all aircrafts.","aircraft['distance'].agg(['min', 'mean', 'max'])"
"find the minimum, average and maximum distances traveled across all aircrafts.","aircraft['distance'].agg(['min', 'mean', 'max'])"
please provide me with the id and full name of the aircraft with the maximum range.,"aircraft[['aid', 'name']].sort_values('distance', ascending=false).head(1)"
for which aircraft is the max distance covered?,"aircraft[['aid', 'name']].sort_values('distance', ascending=false).head(1)"
how many aircrafts have least distances among the given set?,aircraft.sort_values('distance').head(3)['name']
list the names of aircrafts with top 3 shortest lengthes.,aircraft.sort_values('distance').head(3)['name']
list the names of all aircrafts which have distances more than the average.,"aircraft.loc[aircraft['distance'] > aircraft['distance'].mean(), 'name']"
which aircraft can cover more distances than average?,"aircraft.loc[aircraft['distance'] > aircraft['distance'].mean(), 'name']"
please provide the number of employees at our organization.,employee.shape[0]
what is the count of employees?,employee.shape[0]
provide me the names and salaries of all employees sorted by salary.,"employee[['name', 'salary']].sort_values('salary')"
provide me with the names and salaries of all staffs along with their salaries.,"employee[['name', 'salary']].sort_values('salary')"
provide me a list of employee ids with annual salary more than 100000.,"employee.loc[lambda x: x['salary'] > 100000, 'eid']"
"please provide me with the id of the employees having a salary of not less than $100,000.","employee.loc[lambda x: x['salary'] > 100000, 'eid']"
"what are the employees who gain salary between 100,000 and 200,000?",employee.loc[(employee['salary']>=100000) & (employee['salary']<=200000)].shape[0]
how many employees have a salary between 100000 and 200000?,employee.loc[(employee['salary']>=100000) & (employee['salary']<=200000)].shape[0]
"provide me with the id, name and salary for the employee with the id 242518965.","employee.loc[lambda x: x['eid']==242518965, ['name', 'salary']]"
"please provide me with the name of the employee with the id 242518965. moreover, let me know his salary.","employee.loc[lambda x: x['eid']==242518965, ['name', 'salary']]"
what is the average salary of all employees?,"employee['salary'].agg(['mean', 'max'])"
provide me with the average and largest salaries of all employees.,"employee['salary'].agg(['mean', 'max'])"
please give me the title and id of an employee whose salary is the highest.,"employee[['eid', 'name']].sort_values('salary', ascending=false).head(1)"
provide me with the names of employees whose salaries are the lowest among all those listed in the table.,employee.sort_values('salary')['name'].head(3)
what are the names and ranks of the employees who get the least pay?,employee.sort_values('salary')['name'].head(3)
list all the names of employees that are paid more than the average.,"employee.loc[lambda x: x['salary'] > employee['salary'].mean(), 'name']"
what is the list of employees whose salaries are higher than the average?,"employee.loc[lambda x: x['salary'] > employee['salary'].mean(), 'name']"
provide the id and salary for mark young.,"employee.loc[lambda x: x['name']=='mark young', ['eid', 'salary']]"
which employee named mark young has the corresponding id and salary?,"employee.loc[lambda x: x['name']=='mark young', ['eid', 'salary']]"
what number of flights do we possess?,len(flight)
what is the count of flights?,len(flight)
"present the flight number, origin, and destination of all flights in alphabetical order of the departure cities.","flight[['flno', 'origin', 'destination']].sort_values('origin')"
"please provide me with the flight number, origin, and destination (in that order) for all flights in alphabetical order by departure cities.","flight[['flno', 'origin', 'destination']].sort_values('origin')"
return to me the flight numbers from los angeles.,"flight.loc[lambda x: x['origin']=='los angeles', 'flno']"
what are the flight numbers that arrive from lax?,"flight.loc[lambda x: x['origin']=='los angeles', 'flno']"
reveal the details of the flights that travel to honolulu.,"flight.loc[lambda x: x['destination'] == 'honolulu', 'origin']"
retrieve the countries of origin for all the flights going to honolulu.,"flight.loc[lambda x: x['destination'] == 'honolulu', 'origin']"
provide the details for all the flights that depart from los angeles to honolulu.,"flight.loc[(flight['origin'] == 'los angeles') & (flight['destination'] == 'honolulu'), ['departure_date', 'arrival_date']]"
could you please provide me the departure and arrival dates of all flights from la to honolulu?,"flight.loc[(flight['origin'] == 'los angeles') & (flight['destination'] == 'honolulu'), ['departure_date', 'arrival_date']]"
return the flight numbers of all flights that had distances more than 2000.,"flight.loc[lambda x: x['distance'] > 2000, 'flno']"
which flight numbers have the maximum range?,"flight.loc[lambda x: x['distance'] > 2000, 'flno']"
please provide me with the average cost of flights from los angeles to honolulu.,"flight.loc[(flight['origin']=='los angeles') & (flight['destination']=='honolulu'), 'price'].mean()"
provide me with the average price for flights from los angeles to honolulu.,"flight.loc[(flight['origin']=='los angeles') & (flight['destination']=='honolulu'), 'price'].mean()"
provide me with origin and destination details for flights with price higher than 300.,"flight.loc[lambda x: x['price'] > 300, ['origin', 'destination']]"
provide me the name of all flights that have their price higher than 300.,"flight.loc[lambda x: x['price'] > 300, ['origin', 'destination']]"
locate the flight number and distance with high ticket price.,"flight[['flno', 'distance', 'price']].sort_values('price', ascending=false).iloc[0, :2]"
what is the flight number and its distance for the one with the maximum price tag?,"flight[['flno', 'distance', 'price']].sort_values('price', ascending=false).iloc[0, :2]"
provide me the flight numbers of flights which have minimum distances.,flight.sort_values('distance').iloc[:3]['flno']
i would like you to retrieve the number of flights with the shortest duration.,flight.sort_values('distance').iloc[:3]['flno']
calculate the mean distance and mean price for flights from los angeles.,"flight.loc[lambda x: x['origin']=='los angeles', ['distance', 'price']].mean()"
find the average of distance and price for flights from los angeles.,"flight.loc[lambda x: x['origin']=='los angeles', ['distance', 'price']].mean()"
display all origins and the number of flights from each origin.,flight.groupby('origin').size()
"for each origin, how many flights originated from there?",flight.groupby('origin').size()
"provide the heading, destination, and flight number for each flight.",flight.groupby('destination').size()
which country has the most number of flights?,flight.groupby('origin').size().sort_values(ascending=false).index[0]
which place receives the highest number of flights?,flight.groupby('origin').size().sort_values(ascending=false).index[0]
which destination has the least number of flights?,flight.groupby('destination').size().sort_values().index[0]
what are the destinations with the least number of aircrafts?,flight.groupby('destination').size().sort_values().index[0]
what is the aircraft name corresponding to the flight number 99,"pd.merge(flight.loc[lambda x: x['flno'] == 99], aircraft, on='aid')['name']"
what is the name of the aircraft that was flying on flight number 99?,"pd.merge(flight.loc[lambda x: x['flno'] == 99], aircraft, on='aid')['name']"
show all airlines that operate aircraft airbus a340-300.,"pd.merge(flight, aircraft, on='aid').loc[lambda x: x['name']=='airbus a340-300', 'flno']"
which flight numbers were employed for aircraft airbus a340-300?,"pd.merge(flight, aircraft, on='aid').loc[lambda x: x['name']=='airbus a340-300', 'flno']"
provide the aircraft names and the total number of flights for each aircraft.,"flight.merge(aircraft, on='aid').groupby('aid')['name'].agg(['count'])"
kindly segregate the name of each plane and the number of flights each completes.,"flight.merge(aircraft, on='aid').groupby('aid')['name'].agg(['count'])"
show all titles of aircraft that have flown at least twice.,"flight.merge(aircraft, on='aid').groupby('aid')['name'].filter(lambda x: len(x) >= 2)"
list all of the titles of aircrafts that have carried out at least two flights.,"flight.merge(aircraft, on='aid').groupby('aid')['name'].filter(lambda x: len(x) >= 2)"
count the number of employees that have certificates.,certificate['eid'].nunique()
what is the count of distinct employees holding certificates?,certificate['eid'].nunique()
retrieve the ids of all employees who do not possess a certificate.,employee[~employee['eid'].isin(certificate['eid'])]['eid']
what is the number of employee ids for which the certificates have not been submitted?,employee[~employee['eid'].isin(certificate['eid'])]['eid']
provide the titles of aircrafts that john williams is qualified to fly.,"pd.merge(pd.merge(employee, certificate, on='eid'), aircraft, on='aid').loc[lambda x: x['name']=='john williams', 'name']"
what are the names of all aircrafts which are certified by the federal aviation administration?,"pd.merge(pd.merge(employee, certificate, on='eid'), aircraft, on='aid').loc[lambda x: x['name']=='john williams', 'name']"
determine the names of the employees who have a certificate to fly boeing 737-800.,"pd.merge(pd.merge(employee, certificate, on='eid'), aircraft, on='aid').loc[lambda x: x['name']=='boeing 737-800', 'name']"
display the job titles of employees who are certified for both boeing 737-800 and airbus a340-300.,"set(employee.loc[pd.merge(pd.merge(certificate, aircraft.loc[aircraft['name']=='boeing 737-800'], on='aid'), employee, on='eid')['name']].tolist()).intersection(set(employee.loc[pd.merge(pd.merge(certificate, aircraft.loc[aircraft['name']=='airbus a340-300'], on='aid'), employee, on='eid')['name']].tolist()))"
retrieve the names of all the employees who are authorized to fly both the boeing 737-800 and the airbus a340-300.,"set(employee.loc[pd.merge(pd.merge(certificate, aircraft.loc[aircraft['name']=='boeing 737-800'], on='aid'), employee, on='eid')['name']].tolist()).intersection(set(employee.loc[pd.merge(pd.merge(certificate, aircraft.loc[aircraft['name']=='airbus a340-300'], on='aid'), employee, on='eid')['name']].tolist()))"
provide the names of the employees who do not possess the certificate of boeing 737-800.,"employee[~employee['name'].isin(pd.merge(pd.merge(employee, certificate, on='eid'), aircraft, on='aid').loc[lambda x: x['name']=='boeing 737-800', 'name'])]['name']"
retrieve the names of all employees who do not possess a set of credentials necessary for flying boeing 737-800s.,"employee[~employee['name'].isin(pd.merge(pd.merge(employee, certificate, on='eid'), aircraft, on='aid').loc[lambda x: x['name']=='boeing 737-800', 'name'])]['name']"
provide me the names of aircrafts in which fewest people have certificates.,"pd.merge(certificate, aircraft, on='aid').groupby('aid')['name'].count().idxmax()"
retrieve the names of aircraft that the fewest people are licensed for flying.,"pd.merge(certificate, aircraft, on='aid').groupby('aid')['name'].count().idxmax()"
"provide me with the full name, distance, and user of aircrafts which traveled more than 5000 km.","pd.merge(certificate, aircraft, on='aid').loc[lambda x: x['distance']>5000].groupby('aid')['name'].first().value_counts().loc[lambda x: x>=5].index.tolist()"
find the name of aircrafts that have a flying distance of more than 5000 kilometers and which at least 5 people can pilot.,"pd.merge(certificate, aircraft, on='aid').loc[lambda x: x['distance']>5000].groupby('aid')['name'].first().value_counts().loc[lambda x: x>=5].index.tolist()"
who among your employees has the highest salary and given that person's name?,"employee.merge(certificate, on='eid').groupby(['eid', 'name', 'salary']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'salary']]"
provide me with the employees' salaries and last name who are authorized to fly the most planes.,"employee.merge(certificate, on='eid').groupby(['eid', 'name', 'salary']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'salary']]"
who holds the title and salary of an employee who holds the maximum number of certificates in the aircrafts more than 5000 kilometers?,"employee.merge(certificate).merge(aircraft).loc[lambda x: x['distance'] > 5000].groupby('eid').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0].name"
what is the yearly salary and full name of employee who has maximum numbers of the certificates to fly planes more than 5000?,"employee.merge(certificate).merge(aircraft).loc[lambda x: x['distance'] > 5000].groupby('eid').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0].name"
how many allergies in total are there?,allergy_type['allergy'].nunique()
what is the count of allergy entries?,allergy_type['allergy'].nunique()
how many different types of allergies have been documented in the database?,allergy_type['allergytype'].nunique()
determine the total number of allergenic substances.,allergy_type['allergytype'].nunique()
please display all types of allergies.,allergy_type['allergytype'].unique()
what is the count of different allergy types?,allergy_type['allergytype'].unique()
list out all the allergy types and their corresponding names.,"allergy_type[['allergy', 'allergytype']]"
list the allergies and their corresponding types.,"allergy_type[['allergy', 'allergytype']]"
provide me with the list of all allergies with food as type.,"allergy_type.loc[lambda x: x['allergytype']=='food', 'allergy'].unique()"
what are the variety of food allergies?,"allergy_type.loc[lambda x: x['allergytype']=='food', 'allergy'].unique()"
what is the allergy type of cat?,"allergy_type.loc[lambda x: x['allergy']=='cat', 'allergytype']"
what is the allergy type of cat allergies?,"allergy_type.loc[lambda x: x['allergy']=='cat', 'allergytype']"
what is the count of allergens that have animal as type?,(allergy_type['allergytype']=='animal').sum()
how many animal type allergies exist for which no treatment is provided?,(allergy_type['allergytype']=='animal').sum()
please provide me with the count of allergies in each allergy type.,allergy_type.groupby('allergytype').size().reset_index(name='count')
provide me with the number of allergies for each allergy type.,allergy_type.groupby('allergytype').size().reset_index(name='count')
what is the count of allergy types that have most allergy cases?,"allergy_type.groupby('allergytype').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['allergytype']"
"list the allergy types, along with the number of occurrences.","allergy_type.groupby('allergytype').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['allergytype']"
which allergy type has the least number of allergins?,allergy_type.groupby('allergytype').size().sort_values().index[0]
what is the least common type of allergy?,allergy_type.groupby('allergytype').size().sort_values().index[0]
what is the cumulative total of all students?,student.shape[0]
generate a list of first names and corresponding last names for every student.,"student[['fname', 'lname']]"
return the complete names of all students.,"student[['fname', 'lname']]"
what is the count of advisors?,student['advisor'].nunique()
fetch names of advisors.,student['advisor'].nunique()
display all the majors.,student['major'].unique()
identify the different majors.,student['major'].unique()
provide a list of all cities that are the residences of students.,student['city_code'].unique()
which cities are most preferred by students for living?,student['city_code'].unique()
"provide me with the first name, last name, age and sex of female students.","student.loc[student['sex']=='f', ['fname', 'lname', 'age']]"
find the complete names and ages of the female students whose sex is f.,"student.loc[student['sex']=='f', ['fname', 'lname', 'age']]"
return the display ids of all students that are male.,"student.loc[lambda x : x['sex'] == 'm', 'stuid']"
i would like the list all ids for male students.,"student.loc[lambda x : x['sex'] == 'm', 'stuid']"
provide the count of students that are 18 years old.,(student['age']==18).sum()
what is the count of students who are 18 years of age?,(student['age']==18).sum()
locate the student ids of those students who are older than 20.,"student.loc[lambda x: x['age']>20, 'stuid']"
please provide me with the ids of students who are at least 20 years of age.,"student.loc[lambda x: x['age']>20, 'stuid']"
"what is the name of the student whose last name is ""kim"" and who lives in which city?","student.loc[lambda x: x['lname'] == 'kim', 'city_code']"
which city do students with the family name kim live in?,"student.loc[lambda x: x['lname'] == 'kim', 'city_code']"
who is the student advisor for the student whose id is 1004?,"student.loc[lambda x: x['stuid']==1004, 'advisor']"
on what subject does student 1004 receive advice?,"student.loc[lambda x: x['stuid']==1004, 'advisor']"
how many students live in hong-kong or china?,((student['city_code'] == 'hkg') | (student['city_code'] == 'chi')).sum()
provide the count of students living in either hong kong or china.,((student['city_code'] == 'hkg') | (student['city_code'] == 'chi')).sum()
"please list the min, avg, and max ages of all the students.","student['age'].agg(['min', 'mean', 'max'])"
what is the range of ages across every students?,"student['age'].agg(['min', 'mean', 'max'])"
provide the most junior student's surname.,"student.loc[student['age'] == student['age'].min(), 'lname']"
please provide the last name of the last student.,"student.loc[student['age'] == student['age'].min(), 'lname']"
identify the student id of the oldest student.,"student.loc[student['age'] == student['age'].max(), 'stuid']"
what student id corresponds to the oldest student?,"student.loc[student['age'] == student['age'].max(), 'stuid']"
provide me with the count of majors and their corresponding number of students.,student.groupby('major').size()
which major has the most number of students?,student.groupby('major').size().sort_values(ascending=false).index[0]
populate the columns of all age ranges and the number of students under each range.,student.groupby('age').size().reset_index(name='count')
what are the ages and numbers of students?,student.groupby('age').size().reset_index(name='count')
please return the average age for male and female students.,student.groupby('sex')['age'].mean()
what is the age range for male and female students?,student.groupby('sex')['age'].mean()
how many students reside in each city?,student.groupby('city_code').size().reset_index(name='count')
show the counts of advisors and associated number of students.,student.groupby('advisor').size()
what is the count of students that each advisor is responsible for?,student.groupby('advisor').size()
which professor has the most number of advisees?,student.groupby('advisor').size().sort_values(ascending=false).index[0]
please give me the name of advisor with the most students.,student.groupby('advisor').size().sort_values(ascending=false).index[0]
what is the count of students who possess cat allergies?,"(has_allergy['allergy'] == ""cat"").sum()"
what is the count of students who suffer from cat allergies?,"(has_allergy['allergy'] == ""cat"").sum()"
list all students having at least two allergies.,has_allergy.groupby('stuid').filter(lambda x: len(x)>=2)['stuid'].unique()
what is the student id of students with more than one allergy?,has_allergy.groupby('stuid').filter(lambda x: len(x)>=2)['stuid'].unique()
give me the student ids of students who don't have allergies.,student[~student['stuid'].isin(has_allergy['stuid'])]['stuid']
which students do not have allergies?,student[~student['stuid'].isin(has_allergy['stuid'])]['stuid']
how many female students have allergies to milk or eggs?,"pd.merge(has_allergy, student, on='stuid').loc[lambda x: (x['sex']=='f') & (x['allergy'].isin(['milk', 'eggs']))].shape[0]"
how many female students are allergic to milk or eggs?,"pd.merge(has_allergy, student, on='stuid').loc[lambda x: (x['sex']=='f') & (x['allergy'].isin(['milk', 'eggs']))].shape[0]"
what is the number of students who have food allergies?,"pd.merge(has_allergy, allergy_type.loc[lambda x: x['allergytype']=='food'], on='allergy').shape[0]"
what is the count of students who are allergic to foods?,"pd.merge(has_allergy, allergy_type.loc[lambda x: x['allergytype']=='food'], on='allergy').shape[0]"
which allergy has affected the biggest number of students?,has_allergy.groupby('allergy').size().sort_values(ascending=false).index[0]
what is the most prevalent allergy?,has_allergy.groupby('allergy').size().sort_values(ascending=false).index[0]
please list all allergies and the number of students affected by them,has_allergy['allergy'].value_counts()
what is the number of students having different allergies?,has_allergy['allergy'].value_counts()
provide me with a count of allergy type that is affecting students.,"has_allergy.merge(allergy_type, left_on='allergy', right_on='allergy').groupby('allergytype').size()"
determine the number of students affected by each allergy type.,"has_allergy.merge(allergy_type, left_on='allergy', right_on='allergy').groupby('allergytype').size()"
"tell me the student that has allergy to both, milk and cat, and their first and last name and age.","student.loc[lambda x: x['stuid'].isin(has_allergy.query('allergy in [""milk"", ""cat""]').stuid), ['lname', 'age']]"
provide me with the last name and age of the students who are allergic to milk and cat.,"student.loc[lambda x: x['stuid'].isin(has_allergy.query('allergy in [""milk"", ""cat""]').stuid), ['lname', 'age']]"
please provide me with the names of allergies and the type of allergies of the student with first name lisa.,"pd.merge(pd.merge(allergy_type, has_allergy, on='allergy'), student.loc[lambda x:x['fname']=='lisa'], on='stuid').sort_values('allergy')[['allergy', 'allergytype']]"
what are the allergies that lisa has? and what are the types of them? order the result by allergy names.,"pd.merge(pd.merge(allergy_type, has_allergy, on='allergy'), student.loc[lambda x:x['fname']=='lisa'], on='stuid').sort_values('allergy')[['allergy', 'allergytype']]"
identify the student who has an allergy to milk but not cat.,"student.loc[student['stuid'].isin(has_allergy.loc[has_allergy['allergy']=='milk', 'stuid'].values).difference(has_allergy.loc[has_allergy['allergy']=='cat', 'stuid'].values),['fname', 'sex']]"
for which students is milk allergy and cat allergy the case?,"student.loc[student['stuid'].isin(has_allergy.loc[has_allergy['allergy']=='milk', 'stuid'].values).difference(has_allergy.loc[has_allergy['allergy']=='cat', 'stuid'].values),['fname', 'sex']]"
find the average age of students who are allergic to food and animal types.,"student.loc[student['stuid'].isin(has_allergy.merge(allergy_type.query('allergytype==""food""'), on='allergy')['stuid'].interesect(has_allergy.merge(allergy_type.query('allergytype==""animal""'), on='allergy')['stuid']))]['age'].mean()"
how old are the students that have allergies to food and animal types on average?,"student.loc[student['stuid'].isin(has_allergy.merge(allergy_type.query('allergytype==""food""'), on='allergy')['stuid'].interesect(has_allergy.merge(allergy_type.query('allergytype==""animal""'), on='allergy')['stuid']))]['age'].mean()"
list the first name and complete name of students who do not have food allergy.,"student.loc[~student['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda x: x['allergytype'] == ""food""], on='allergy', how='inner')['stuid']), ['fname', 'lname']]"
provide me with the full names of all students who are not allergic to any specific types of food.,"student.loc[~student['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda x: x['allergytype'] == ""food""], on='allergy', how='inner')['stuid']), ['fname', 'lname']]"
determine the number of male students with allery to food types.,student.loc[lambda x: (x['sex']=='m') & (x['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda x: x['allergytype']=='food'])['stuid']))].shape[0]
how many male students are allergic to any item of food?,student.loc[lambda x: (x['sex']=='m') & (x['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda x: x['allergytype']=='food'])['stuid']))].shape[0]
list out the names of students along with their cities who have allergy to milk or cat.,"pd.merge(student, has_allergy.query('allergy==""milk"" or allergy==""cat""'), on='stuid')[['fname', 'city_code']].drop_duplicates()"
retrieve the names of students who have allergic response to milk or to cat.,"pd.merge(student, has_allergy.query('allergy==""milk"" or allergy==""cat""'), on='stuid')[['fname', 'city_code']].drop_duplicates()"
how many students do not have disease related to food or animal and are older than 18?,"student.loc[lambda x: (x['age'] > 18) & (~x['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda y: (y['allergytype']=='food') | (y['allergytype']=='animal')], on='allergy', how='inner')['stuid']))].shape[0]"
how many students are over 18 and do not have allergies to any food items or animal type?,"student.loc[lambda x: (x['age'] > 18) & (~x['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda y: (y['allergytype']=='food') | (y['allergytype']=='animal')], on='allergy', how='inner')['stuid']))].shape[0]"
find the names of students who exhibit no allergies to soy products.,"student.loc[~student['stuid'].isin(has_allergy.loc[has_allergy['allergy']=='soy', 'stuid']), ['fname', 'major']]"
determine the first names and areas of study of students who are able to consume soy.,"student.loc[~student['stuid'].isin(has_allergy.loc[has_allergy['allergy']=='soy', 'stuid']), ['fname', 'major']]"
provide a list of the top 5 countries by number of invoices. list the country name and total number of invoices.,invoices.groupby('billing_country').size().sort_values(ascending=false).head(5)
"what are the top 5 countries by number of invoices, and the number of invoices do they have?",invoices.groupby('billing_country').size().sort_values(ascending=false).head(5)
"please provide me with a list of the top 8 countries by gross/total invoice size. for each country listed, include the country name and gross invoice size.",invoices.groupby('billing_country')['total'].sum().sort_values(ascending=false).head(8)
what is the top 10 list of countries by invoice size? include country names.,invoices.groupby('billing_country')['total'].mean().sort_values(ascending=false).head(10)
retrieve the names of countries and the average invoice size of top countries by invoice size.,invoices.groupby('billing_country')['total'].mean().sort_values(ascending=false).head(10)
"list the names of 5 customers that most recently purchased something. also, list the names in the 1st and 2nd person.","customers.merge(invoices, on='customer_id')[['first_name', 'last_name']].sort_values('invoice_date', ascending=false).head(5)"
provide me with the names of 5 customers that purchased something most recently.,"customers.merge(invoices, on='customer_id')[['first_name', 'last_name']].sort_values('invoice_date', ascending=false).head(5)"
list the top 10 customers by the number of orders placed. list customers' first and last name and total number of orders.,"customers.merge(invoices, left_on='id', right_on='customer_id').groupby(['id','first_name','last_name']).size().reset_index(name='count').sort_values('count', ascending=false)[:10][['first_name', 'last_name', 'count']]"
"provide me with the first name, last name, and number of orders placed by the top 10 customers.","customers.merge(invoices, left_on='id', right_on='customer_id').groupby(['id','first_name','last_name']).size().reset_index(name='count').sort_values('count', ascending=false)[:10][['first_name', 'last_name', 'count']]"
list the top 10 customers by gross sales. provide customers' first/last name and total gross sales.,"invoices.merge(customers, left_on='customer_id', right_on='id').groupby(['first_name', 'last_name'], as_index=false)['total'].sum().sort_values('total', ascending=false).head(10)[['first_name', 'last_name', 'total']]"
provide me with the full names and sales of the 10 customers with the highest gross sales.,"invoices.merge(customers, left_on='customer_id', right_on='id').groupby(['first_name', 'last_name'], as_index=false)['total'].sum().sort_values('total', ascending=false).head(10)[['first_name', 'last_name', 'total']]"
retrieve the genres with the greatest number of tracks. display the genre names and total tracks.,"genres.merge(tracks, left_on='id', right_on='genre_id').groupby('name').size().reset_index(name='count').sort_values(by='count', ascending=false).head(5)"
what is the count of tracks each genre has and what is the full name of the top 5 genres?,"genres.merge(tracks, left_on='id', right_on='genre_id').groupby('name').size().reset_index(name='count').sort_values(by='count', ascending=false).head(5)"
provide me with the titles of all albums.,albums['title']
list all the albums and their titles.,albums['title']
provide a list of albums ordered by title in ascending order.,albums.sort_values('title')['title']
deliver me a list of albums which are alphabetically ordered.,albums.sort_values('title')['title']
retrieve the titles in alphabetic order of albums that start with a.,albums.loc[lambda x: x['title'].str.startswith('a')].sort_values('title')['title']
"please list down all titles of albums that start with the letter ""a"" in alphabetical order.",albums.loc[lambda x: x['title'].str.startswith('a')].sort_values('title')['title']
enumerate the first names and last names for customers of invoices having the lowest prices.,"pd.merge(customers, invoices, on='id').sort_values('total')[['first_name', 'last_name']].head(10)"
provide me with the first and last names of customers with 10 cheapest invoices.,"pd.merge(customers, invoices, on='id').sort_values('total')[['first_name', 'last_name']].head(10)"
"retrieve the total sum of invoices from chicago, il.","invoices.loc[(invoices['billing_city']=='chicago') & (invoices['billing_state']=='il'), 'total'].sum()"
"what is the total sum of the billing amount from chicago, illinois?","invoices.loc[(invoices['billing_city']=='chicago') & (invoices['billing_state']=='il'), 'total'].sum()"
"please provide me with the count of invoices from chicago, il.",invoices[(invoices['billing_city'] == 'chicago') & (invoices['billing_state'] == 'il')].shape[0]
"how many invoices were billed from chicago, illinois?",invoices[(invoices['billing_city'] == 'chicago') & (invoices['billing_state'] == 'il')].shape[0]
list the count of invoices from the united states and group by state.,"invoices.loc[invoices['billing_country']=='usa', 'billing_state'].value_counts()"
what are the invoices that were billed from each us state?,"invoices.loc[invoices['billing_country']=='usa', 'billing_state'].value_counts()"
provide me the states of usa that have the most number of invoices.,"(invoices.loc[invoices['billing_country']=='usa', :].groupby('billing_state').size().sort_values(ascending=false).head(1).reset_index(name='count')).iloc[0]"
what are the states with the most tax invoices?,"(invoices.loc[invoices['billing_country']=='usa', :].groupby('billing_state').size().sort_values(ascending=false).head(1).reset_index(name='count')).iloc[0]"
provide me with the count of invoices and the total amount of invoices from california.,"invoices.loc[invoices['billing_state']=='ca'].agg({'billing_state': 'first', 'total': 'sum', 'billing_state': 'count'})"
what is the total number of invoices and the total amount of money billed to ca?,"invoices.loc[invoices['billing_state']=='ca'].agg({'billing_state': 'first', 'total': 'sum', 'billing_state': 'count'})"
list the albums of aerosmith.,"albums.loc[lambda x: x['artist_id'].isin(artists.loc[lambda y: y['name']=='aerosmith', 'id']), 'title']"
retrieve the names of all aerosmith albums.,"albums.loc[lambda x: x['artist_id'].isin(artists.loc[lambda y: y['name']=='aerosmith', 'id']), 'title']"
determine the total number of albums possessed by billy cobham.,"pd.merge(albums, artists, left_on='artist_id', right_on='id').loc[lambda x: x['name']=='billy cobham'].shape[0]"
which company does eduardo martins work for?,"customers.loc[(customers['first_name'] == 'eduardo') & (customers['last_name'] == 'martins'), 'company']"
who is the owner of company where eduardo martins is a customer?,"customers.loc[(customers['first_name'] == 'eduardo') & (customers['last_name'] == 'martins'), 'company']"
please provide me with astrid gruber's email and phone number.,"customers.loc[(customers['first_name']=='astrid') & (customers['last_name']=='gruber'), ['email', 'phone']]"
could you please provide me with the contact info for the customer astrid gruber?,"customers.loc[(customers['first_name']=='astrid') & (customers['last_name']=='gruber'), ['email', 'phone']]"
how many customers reside in prague city?,(customers['city'] == 'prague').sum()
what is the total count of customers that live in the city prague?,(customers['city'] == 'prague').sum()
what is the count of customers residing in the state of california?,(customers['state'] == 'ca').sum()
please provide me with the count of customers that are from california.,(customers['state'] == 'ca').sum()
what country does roberto almeida reside in?,"customers.loc[(customers['first_name'] == 'roberto') & (customers['last_name'] == 'almeida'), 'country']"
where is roberto almeida located?,"customers.loc[(customers['first_name'] == 'roberto') & (customers['last_name'] == 'almeida'), 'country']"
"list the names of albums released by artists whose name contains ""led""","pd.merge(artists.loc[lambda x: x['name'].str.contains('led', case=false)], albums, on='artist_id')['title']"
which album was released by the artist whose name contains the three words 'led'?,"pd.merge(artists.loc[lambda x: x['name'].str.contains('led', case=false)], albums, on='artist_id')['title']"
what is the count of customers steve johnson is supporting?,"employees.merge(customers, left_on='id', right_on='support_rep_id').query('first_name == ""steve"" and last_name == ""johnson""').shape[0]"
"provide me with the title, phone number and hire date of the nancy edwards.","employees.loc[(employees['first_name'] == 'nancy') & (employees['last_name'] == 'edwards'), ['title', 'phone', 'hire_date']]"
"provide me with the details for the employee named nancy edwards, including their title, telephone number and hire date.","employees.loc[(employees['first_name'] == 'nancy') & (employees['last_name'] == 'edwards'), ['title', 'phone', 'hire_date']]"
get the full name of all employees who report to nancy edwards.,"employees.merge(employees[['id', 'first_name', 'last_name']].rename(columns={'id': 'reports_to'}), on='reports_to',suffixes=('', '_manager')).query('first_name_manager == ""nancy"" & last_name_manager == ""edwards""')[['first_name', 'last_name']]"
what is the first and last name of the person who reports to nancy edwards?,"employees.merge(employees[['id', 'first_name', 'last_name']].rename(columns={'id': 'reports_to'}), on='reports_to',suffixes=('', '_manager')).query('first_name_manager == ""nancy"" & last_name_manager == ""edwards""')[['first_name', 'last_name']]"
retrieve the address of employee nancy edwards.,"employees.loc[(employees['first_name'] == 'nancy') & (employees['last_name'] == 'edwards'), 'address']"
provide me nancy edwards's address.,"employees.loc[(employees['first_name'] == 'nancy') & (employees['last_name'] == 'edwards'), 'address']"
retrieve the complete name of employees who had provided the most assistance.,"pd.merge(employees, customers, left_on='id', right_on='support_rep_id').groupby(['id', 'first_name', 'last_name']).size().reset_index(name='counts').sort_values('counts', ascending=false).iloc[0][['first_name', 'last_name']]"
who is the employee with the most customers?,"pd.merge(employees, customers, left_on='id', right_on='support_rep_id').groupby(['id', 'first_name', 'last_name']).size().reset_index(name='counts').sort_values('counts', ascending=false).iloc[0][['first_name', 'last_name']]"
what is the direct phone number of nancy edwards?,"employees.loc[(employees['first_name']=='nancy') & (employees['last_name']=='edwards'), 'phone']"
what is the phone number of nancy edwards?,"employees.loc[(employees['first_name']=='nancy') & (employees['last_name']=='edwards'), 'phone']"
who are the employees that are younger than 40?,"employees.sort_values('birth_date', ascending=false).iloc[:1, ['first_name', 'last_name']]"
retrieve the full name and age of the youngest employee.,"employees.sort_values('birth_date', ascending=false).iloc[:1, ['first_name', 'last_name']]"
provide the titles of the ten employees who have been present with the firm for the longest time.,"employees[['first_name', 'last_name']].sort_values('hire_date').head(10)"
please provide me with the names of employees having it staff title from each city.,employees.loc[lambda x: x['title']=='it staff'].groupby('city').size().reset_index(name='count(*)')
what is the count of employees that are it staff and where they are from?,employees.loc[lambda x: x['title']=='it staff'].groupby('city').size().reset_index(name='count(*)')
"please list the first and last name of each employee managing the most number of people, along with the number of people reporting to that employee.","employees.merge(employees, left_on='reports_to', right_on='id', suffixes=('', '_manager')).groupby(by=['id_manager', 'first_name_manager', 'last_name_manager']).size().reset_index(name='count_reports_to').sort_values(by='count_reports_to', ascending=false).head(1)[['first_name_manager', 'last_name_manager', 'count_reports_to']]"
please list out the first and last names of all the employees and the number of reports they handle.,"employees.merge(employees, left_on='reports_to', right_on='id', suffixes=('', '_manager')).groupby(by=['id_manager', 'first_name_manager', 'last_name_manager']).size().reset_index(name='count_reports_to').sort_values(by='count_reports_to', ascending=false).head(1)[['first_name_manager', 'last_name_manager', 'count_reports_to']]"
what is the count of orders received by lucas mancini?,"pd.merge(customers.loc[lambda x: (x['first_name']=='lucas') & (x['last_name']=='mancini')], invoices, on='customer_id').shape[0]"
what is the count of luca mancini's invoices?,"pd.merge(customers.loc[lambda x: (x['first_name']=='lucas') & (x['last_name']=='mancini')], invoices, on='customer_id').shape[0]"
what is the total amount spent by lucas mancini?,"pd.merge(customers[customers['first_name']=='lucas'][customers['last_name']=='mancini'], invoices, on='customer_id')['total'].sum()"
what was the amount of money that lucas mancini spent?,"pd.merge(customers[customers['first_name']=='lucas'][customers['last_name']=='mancini'], invoices, on='customer_id')['total'].sum()"
retrieve a list of all media types in the search box.,media_types['name']
fetch the names of all the media types.,media_types['name']
provide the listing of all genres.,genres['name'].unique()
return the list of all playlists.,playlists['name']
"what is the composer of the track ""fast as a shark""?","tracks.loc[lambda x: x['name'] == 'fast as a shark', 'composer']"
"identify the composer who composed the track ""fast as a shark.""","tracks.loc[lambda x: x['name'] == 'fast as a shark', 'composer']"
what is the total time duration of the song fast as a shark?,"tracks.loc[lambda x: x['name'] == 'fast as a shark', 'milliseconds']"
how many milliseconds is the song fast as a shark?,"tracks.loc[lambda x: x['name'] == 'fast as a shark', 'milliseconds']"
which track titles are of the rock genre?,"tracks.merge(genres, left_on='genre_id', right_on='id').loc[lambda x: x['name']=='rock', 'name_y']"
what is the title of all tracks in the rock genre?,"tracks.merge(genres, left_on='genre_id', right_on='id').loc[lambda x: x['name']=='rock', 'name_y']"
"what is the album title that the track ""balls to the wall"" belongs to?","albums.loc[lambda x: x['id'].isin(tracks.loc[lambda y: y['name']=='balls to the wall', 'genre_id']), 'title']"
"what is the album title that has the tune ""ball to the wall""?","albums.loc[lambda x: x['id'].isin(tracks.loc[lambda y: y['name']=='balls to the wall', 'genre_id']), 'title']"
return the titles of tracks in the album balls to the wall.,"pd.merge(albums.loc[lambda x: x['title']=='balls to the wall'], tracks, left_on='id', right_on='genre_id')['name']"
list the track titles of the album balls to the wall.,"pd.merge(albums.loc[lambda x: x['title']=='balls to the wall'], tracks, left_on='id', right_on='genre_id')['name']"
fetch the documents whose titles contain a list of tracks larger than 10.,"albums.merge(tracks, on='album_id').groupby('id').filter(lambda x: len(x) > 10)['title']"
retrieve the names of albums that have more than 10 tracks.,"albums.merge(tracks, on='album_id').groupby('id').filter(lambda x: len(x) > 10)['title']"
identify the titles of all tracks that belong to the rock genre and have mpeg audio file type.,"pd.merge(pd.merge(genres[genres['name']=='rock'], tracks, on='genre_id'), media_types[media_types['name']=='mpeg audio file'], on='media_type_id')['name']"
list down the names of all rock tracks that are saved on mpeg audio files.,"pd.merge(pd.merge(genres[genres['name']=='rock'], tracks, on='genre_id'), media_types[media_types['name']=='mpeg audio file'], on='media_type_id')['name']"
please list the titles of tracks belonging to the genre of rock or the media type of mpeg audio files.,"pd.merge(pd.merge(genres.loc[genres['name']==""rock""], tracks, on='genre_id'), media_types.loc[media_types['name']=='mpeg audio file'], on='media_type_id')['name']"
retrieve the titles of tracks that belong to the rock genre and have media type of mpeg.,"pd.merge(pd.merge(genres.loc[genres['name']==""rock""], tracks, on='genre_id'), media_types.loc[media_types['name']=='mpeg audio file'], on='media_type_id')['name']"
retrieve titles of tracks that belong to the genre rock or genre jazz.,"pd.merge(genres.loc[lambda x: x['name'].isin(['rock', 'jazz'])], tracks, on='genre_id')['name_y']"
what are the names of the tracks that were either rock or jazz songs?,"pd.merge(genres.loc[lambda x: x['name'].isin(['rock', 'jazz'])], tracks, on='genre_id')['name_y']"
return me the names of all tracks in the playlists of movies.,"pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='movies', 'name']"
"list the names of all tracks that are included in playlists titled ""movies.""","pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='movies', 'name']"
retrieve the names of the playlists containing at least 100 songs.,"pd.merge(playlist_tracks, playlists, on='id').groupby('playlist_id').filter(lambda x: x['track_id'].count() > 100)['name']"
please retrieve all the title of playlists consisting of more than 100 tracks.,"pd.merge(playlist_tracks, playlists, on='id').groupby('playlist_id').filter(lambda x: x['track_id'].count() > 100)['name']"
list all tracks bought by daan peeters,"tracks.merge(invoice_lines, left_on='id', right_on='track_id').merge(invoices, on='invoice_id').merge(customers, on='customer_id').loc[(customers['first_name']=='daan') & (customers['last_name']=='peeters'), 'name']"
retrieve the titles of tracks that dean peeters bought.,"tracks.merge(invoice_lines, left_on='id', right_on='track_id').merge(invoices, on='invoice_id').merge(customers, on='customer_id').loc[(customers['first_name']=='daan') & (customers['last_name']=='peeters'), 'name']"
"what is the cost/price of the track ""fast as a shark""?","tracks.loc[lambda x: x['name']=='fast as a shark', 'unit_price']"
"what is the unit price of the song ""fast as a shark""?","tracks.loc[lambda x: x['name']=='fast as a shark', 'unit_price']"
"retrieve the names of tracks which are not present in the music playlist, but are contained within movie playlist.","set(tracks.merge(playlist_tracks, left_on='id', right_on='track_id').merge(playlists, left_on='playlist_id', right_on='id').loc[lambda x: x['name']=='movies', 'name']).difference(tracks.merge(playlist_tracks, left_on='id', right_on='track_id').merge(playlists, left_on='playlist_id', right_on='id').loc[lambda x: x['name']=='music', 'name'])"
which tracks that are not currently included in the music playlist?,"set(tracks.merge(playlist_tracks, left_on='id', right_on='track_id').merge(playlists, left_on='playlist_id', right_on='id').loc[lambda x: x['name']=='movies', 'name']).difference(tracks.merge(playlist_tracks, left_on='id', right_on='track_id').merge(playlists, left_on='playlist_id', right_on='id').loc[lambda x: x['name']=='music', 'name'])"
make note of the names of songs that are both present in movies and music playlists.,"pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='movies', 'name'].isin(pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='music', 'name']).unique()"
provide the names of the tracks that are present in both the movies and music playlists.,"pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='movies', 'name'].isin(pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='music', 'name']).unique()"
list the names of genres and number of tracks in each.,"pd.merge(genres, tracks, on='genre_id').groupby('name').size().reset_index(name='count')"
how many tracks are there in each genre?,"pd.merge(genres, tracks, on='genre_id').groupby('name').size().reset_index(name='count')"
what is the count of editors?,editor['editor_id'].count()
provide the name and age of each editor in the reverse order of their ages starting with the youngest.,editor.sort_values('age')['name']
what are the names and the ages (in years) of editors?,"editor[['name', 'age']]"
return the names of editors who are older than 25.,"editor.loc[lambda x: x['age'] > 25, 'name']"
provide names of the editorial staff whose age is either 24 or 25.,"editor.loc[lambda x: x['age'].isin([24, 25]), 'name']"
what is the first name of the editor who began working at the oldest age?,editor.sort_values('age').iloc[0]['name']
display the number of editors at each of the specified age groups.,editor.groupby('age').size().reset_index(name='count')
please provide me with the most common age of editors.,editor.groupby('age').size().sort_values(ascending=false).index[0]
present the titles of journals along with their distinct themes.,journal['theme'].unique()
return to me the names of editors that serve on the editorial boards of journals and the theme of these journals.,"pd.merge(pd.merge(journal_committee, editor, on='editor_id'), journal, on='journal_id')[['name', 'theme']]"
retrieve the names of the editors and the journal themes of every journal_committee.,"pd.merge(pd.merge(journal_committee, editor, on='editor_id'), journal, on='journal_id')[['name', 'theme']]"
"retrieve the names of editors and journals they serve on editorial boards of, in ascending alphabetical order of journal theme.","pd.merge(pd.merge(journal_committee, editor, on='editor_id'), journal, on='journal_id').sort_values('theme')[['name', 'age', 'theme']]"
show me the editors who are on the committee of journals with annual sales bigger than 3000.,"pd.merge(pd.merge(journal_committee, editor, on='editor_id'), journal, on='journal_id').loc[lambda x: x['sales'] > 3000, 'name']"
display the titles of editors who have memberships with at least two journal committees.,"pd.merge(editor, journal_committee, on='editor_id').groupby('name').filter(lambda x: len(x) >= 2)['name']"
tell me the names of editors that are not on any journal committee.,"editor.loc[~editor['editor_id'].isin(journal_committee['editor_id']), 'name']"
"provide the dates, themes and sales of the journals that did not list editors having served any committee.","journal[~journal.merge(journal_committee, on='journal_id').set_index(['date', 'theme', 'sales']).index.isin(journal.set_index(['date', 'theme', 'sales']).index)]"
calculate the total average of journal sales with an editor whose work type is 'photo'.,"journal_committee[journal_committee['work_type'] == 'photo'].merge(journal, on='journal_id')['sales'].mean()"
provide me with the count of accounts that exist in our database.,accounts.shape[0]
"please provide me with the ids, customer ids, and names of all accounts.","accounts[['account_id', 'customer_id', 'account_name']]"
"pull the corresponding ids, customer ids, and names of accounts.","accounts[['account_id', 'customer_id', 'account_name']]"
show me the details of account with id 338.,"accounts.loc[lambda x: x['account_name']=='338', 'other_account_details']"
provide me with other account details for the current account under the user 338.,"accounts.loc[lambda x: x['account_name']=='338', 'other_account_details']"
"retrieve the information of the first, last name, and phone number of the customer with account name 162.","pd.merge(accounts.loc[lambda x: x['account_name']=='162'], customers, on='customer_id')[['customer_first_name', 'customer_last_name', 'customer_phone']]"
please find the full name and phone number of the customer that has the account name 162.,"pd.merge(accounts.loc[lambda x: x['account_name']=='162'], customers, on='customer_id')[['customer_first_name', 'customer_last_name', 'customer_phone']]"
please provide me with the number of accounts that the customers listed as art turcotte owns.,"pd.merge(accounts, customers).loc[lambda x: (x['customer_first_name']=='art') & (x['customer_last_name']=='turcotte'), :].shape[0]"
please list all customers along with their number of accounts.,accounts.groupby('customer_id').size().reset_index(name='count')
how many customers id are there for each customer id?,accounts.groupby('customer_id').size().reset_index(name='count')
provide me with customer id and account count for accounts with most accounts.,"accounts.groupby('customer_id').size().nlargest(1).reset_index(name='count').loc[0, ['customer_id', 'count']]"
i would request you to list the customer whose id is maximum and also provide me the count of customer accounts.,"accounts.groupby('customer_id').size().nlargest(1).reset_index(name='count').loc[0, ['customer_id', 'count']]"
"fetch the names, ids, and account numbers of customers with the least number of accounts.","pd.merge(accounts, customers, on='customer_id').groupby('customer_id').agg({'customer_first_name': 'first', 'customer_last_name': 'first', 'customer_id': 'count'}).sort_values('customer_id').iloc[0][['customer_first_name', 'customer_last_name', 'customer_id']]"
provide me with the customer id and full name of the customer who has the fewest accounts.,"pd.merge(accounts, customers, on='customer_id').groupby('customer_id').agg({'customer_first_name': 'first', 'customer_last_name': 'first', 'customer_id': 'count'}).sort_values('customer_id').iloc[0][['customer_first_name', 'customer_last_name', 'customer_id']]"
reveal the count of customers not holding accounts.,customers['customer_id'].isin(accounts['customer_id']).value_counts()[false]
what is the count of customers that do not have an account?,customers['customer_id'].isin(accounts['customer_id']).value_counts()[false]
identify the first and last names of the clients without any accounts.,"customers.loc[~customers['customer_id'].isin(accounts['customer_id']), ['customer_first_name', 'customer_last_name']]"
what is the complete list of full names of customers who do not have accounts?,"customers.loc[~customers['customer_id'].isin(accounts['customer_id']), ['customer_first_name', 'customer_last_name']]"
display the distinct first and last names for all of the customers who have an account.,"pd.merge(customers, accounts, on='customer_id')[['customer_first_name', 'customer_last_name']].drop_duplicates()"
please give me the full names of the customers that have accounts,"pd.merge(customers, accounts, on='customer_id')[['customer_first_name', 'customer_last_name']].drop_duplicates()"
how many customers have accounts?,accounts['customer_id'].nunique()
provide the count of customers that have accounts.,accounts['customer_id'].nunique()
give me the total number of customers we have.,customers.shape[0]
determine the total count of customers.,customers.shape[0]
"please inform me of the ids, first names, last names, and phones for all customers.","customers[['customer_id', 'customer_first_name', 'customer_last_name', 'customer_phone']]"
"provide me with the ids, complete names, and phone numbers of each customer.","customers[['customer_id', 'customer_first_name', 'customer_last_name', 'customer_phone']]"
provide me with the phone and email of customer aniyah feest.,"customers.loc[(customers['customer_first_name'] == 'aniyah') & (customers['customer_last_name'] == 'feest'), ['customer_phone', 'customer_email']]"
retrieve the email address and phone number of the customer with the first name aniyah and last name feest.,"customers.loc[(customers['customer_first_name'] == 'aniyah') & (customers['customer_last_name'] == 'feest'), ['customer_phone', 'customer_email']]"
please count the number of customer cards.,customers_cards.shape[0]
how many customer cards exist?,customers_cards.shape[0]
"return a complete breakdown of all cards, their ids, and customer ids along with their card type codes and card numbers.","customers_cards[['card_id', 'customer_id', 'card_type_code', 'card_number']]"
"provide the names, ids, types, and numbers of the cardholders (if any).","customers_cards[['card_id', 'customer_id', 'card_type_code', 'card_number']]"
provide me with the valid dates for the credit card with card number 4560596484842.,"customers_cards.loc[lambda x: x['card_number']=='4560596484842', ['date_valid_from', 'date_valid_to']]"
can you give me the valid from and valid to dates of the card with the number 4560596484842?,"customers_cards.loc[lambda x: x['card_number']=='4560596484842', ['date_valid_from', 'date_valid_to']]"
"retrieve the full name, phone number, and address of the customer with card number 4560596484842.","pd.merge(customers_cards, customers, on='customer_id').loc[lambda x: x['card_number']=='4560596484842', ['customer_first_name', 'customer_last_name', 'customer_phone']]"
relay the full name and phone number of the customer who possesses the card number 4560596484842.,"pd.merge(customers_cards, customers, on='customer_id').loc[lambda x: x['card_number']=='4560596484842', ['customer_first_name', 'customer_last_name', 'customer_phone']]"
what number of cards does art turcotte have?,"pd.merge(customers_cards, customers.loc[(customers['customer_first_name']=='art') & (customers['customer_last_name']=='turcotte')], on='customer_id')['customer_id'].count()"
provide the total number of cards owned by the customer with first name art and last name turcotte.,"pd.merge(customers_cards, customers.loc[(customers['customer_first_name']=='art') & (customers['customer_last_name']=='turcotte')], on='customer_id')['customer_id'].count()"
how many debit cards do we have with our institution?,(customers_cards['card_type_code'] == 'debit').sum()
determine the number of debit cards possessed by the customers.,(customers_cards['card_type_code'] == 'debit').sum()
how many credit cards is owned by customer blanche huels?,"pd.merge(customers_cards, customers, on='customer_id').loc[(customers['customer_first_name']=='blanche') & (customers['customer_last_name']=='huels') & (customers_cards['card_type_code']=='credit'),:].shape[0]"
count the number of credit cards that the customer with first name blanche and last name huels possesses.,"pd.merge(customers_cards, customers, on='customer_id').loc[(customers['customer_first_name']=='blanche') & (customers['customer_last_name']=='huels') & (customers_cards['card_type_code']=='credit'),:].shape[0]"
please list out the ids and number of cards owned by each customer.,customers_cards.groupby('customer_id').size().reset_index(name='count')
"return me the names of customers, together with the number of cards each of them owns.",customers_cards.groupby('customer_id').size().reset_index(name='count')
which customer id holds the most number of cards? how many does he possess?,customers_cards.groupby('customer_id').size().idxmax()
"provide me with the id number of the customer who has the most cards, as well as the count of cards.",customers_cards.groupby('customer_id').size().idxmax()
provide me with the names of all customers who own at least two cards.,"pd.merge(customers_cards, customers, on='customer_id').groupby('customer_id').filter(lambda x: len(x) >= 2)[['customer_id', 'customer_first_name', 'customer_last_name']].drop_duplicates('customer_id')"
who are customers who hold at least two cards?,"pd.merge(customers_cards, customers, on='customer_id').groupby('customer_id').filter(lambda x: len(x) >= 2)[['customer_id', 'customer_first_name', 'customer_last_name']].drop_duplicates('customer_id')"
"please find the record with the least number of accounts that spans from customer id, first name and last name.","pd.merge(customers_cards, customers, on='customer_id').groupby('customer_id').agg({'customer_first_name': 'first', 'customer_last_name': 'first'}).sort_values(by='count').head(1)"
please provide me with the id and full name of the customer having the minimum accounts.,"pd.merge(customers_cards, customers, on='customer_id').groupby('customer_id').agg({'customer_first_name': 'first', 'customer_last_name': 'first'}).sort_values(by='count').head(1)"
provide me a list of all card type codes and their respective count.,customers_cards.groupby('card_type_code').size().reset_index(name='count')
list the card types along with their count.,customers_cards.groupby('card_type_code').size().reset_index(name='count')
what is the card type code which is most utilized?,customers_cards.groupby('card_type_code').size().sort_values(ascending=false).index[0]
provide me the id of card type that is most frequent.,customers_cards.groupby('card_type_code').size().sort_values(ascending=false).index[0]
provide me with the codes of card types which have a minimum count of 5 cards.,customers_cards.groupby('card_type_code').filter(lambda x: len(x) >= 5)['card_type_code'].unique()
what are the code for card types that have more than 5 cards?,customers_cards.groupby('card_type_code').filter(lambda x: len(x) >= 5)['card_type_code'].unique()
provide me with a list of all card type codes and the amount of customers who are holding cards of each type.,customers_cards.groupby('card_type_code')['customer_id'].nunique()
"determine the name of card type code, along with the count of customers holding each card type.",customers_cards.groupby('card_type_code')['customer_id'].nunique()
provide the given customer id and first name details without a credit card.,"customers[['customer_id', 'customer_first_name']].merge(customers_cards[lambda x: x['card_type_code'] == 'credit'][['customer_id']],how='left',on='customer_id',indicator=true).query(""_merge == 'left_only'"").drop('_merge', axis=1)"
retrieval of the first and last names of customers who are not holders of credit cards.,"customers[['customer_id', 'customer_first_name']].merge(customers_cards[lambda x: x['card_type_code'] == 'credit'][['customer_id']],how='left',on='customer_id',indicator=true).query(""_merge == 'left_only'"").drop('_merge', axis=1)"
please display the card type code list.,customers_cards['card_type_code'].unique()
"retrieve the number of types of cards.rules:input: sentence and output: resulta result can be a number, string, list, json, or data frame.",customers_cards['card_type_code'].nunique()
show me a list of transaction types.,financial_transactions['transaction_type'].unique()
provide the count of transaction types.,financial_transactions['transaction_type'].nunique()
what is the number of different types of transactions?,financial_transactions['transaction_type'].nunique()
how many transactions were made and the average total transaction amount?,"financial_transactions['transaction_amount'].agg(['mean', 'sum'])"
return both the average transaction amount and the total amount of transactions.,"financial_transactions['transaction_amount'].agg(['mean', 'sum'])"
provide me the card type codes and the number of transactions.,"pd.merge(financial_transactions, customers_cards, on='card_id').groupby('card_type_code').size()"
"how many different card types exist, and how many transactions have been made with each?","pd.merge(financial_transactions, customers_cards, on='card_id').groupby('card_type_code').size()"
show me the number of transactions and the kinds of transaction recorded in the database.,financial_transactions.groupby('transaction_type').size().reset_index(name='count')
how many transactions of each type have taken place?,financial_transactions.groupby('transaction_type').size().reset_index(name='count')
which transaction type processes the largest amount in total transactions?,financial_transactions.groupby('transaction_type').sum()['transaction_amount'].sort_values(ascending=false).index[0]
what is the transaction type with the highest total amount?,financial_transactions.groupby('transaction_type').sum()['transaction_amount'].sort_values(ascending=false).index[0]
provide the account id and the total count of transactions for each account.,financial_transactions.groupby('account_id').size().reset_index(name='count')
"give me the ids of all accounts that have participated in financial transactions, as well as the count of each.",financial_transactions.groupby('account_id').size().reset_index(name='count')
calculate the total count of tracks.,track.shape[0]
provide the details of all tracks along with their title and location.,"track[['name', 'location']]"
please return the titles of tracks along with the name and location.,"track[['name', 'location']]"
provide me a list of names and seating arrangements for all tracks opened after 2000.,"track.loc[lambda x: x['year_opened']>2000, ['name', 'seating']].sort_values('seating')"
"provide me with the details of all tracks that were established after 2000, in the order of the seat.","track.loc[lambda x: x['year_opened']>2000, ['name', 'seating']].sort_values('seating')"
"what is the name of the track, its location and seating capacity that was most recently built?","track.sort_values('year_opened', ascending=false).iloc[0][['name', 'location', 'seating']]"
"please return the name of the track, its location, and seating arrangement.","track.sort_values('year_opened', ascending=false).iloc[0][['name', 'location', 'seating']]"
"provide me with the minimum and maximum counts of seats for all the tracks, and the average count.","track['seating'].agg(['min', 'max', 'mean'])"
"please provide me with the minimum, maximum, and average seating across all tracks.","track['seating'].agg(['min', 'max', 'mean'])"
"provide me the names, locations, and opening years of all tracks with seats higher than the average.","track.loc[lambda x: x['seating'] > track['seating'].mean(), ['name', 'location', 'year_opened']]"
"find titles for tracks with higher than average capacity, along with their locations, years of opening, and the cost of tickets.","track.loc[lambda x: x['seating'] > track['seating'].mean(), ['name', 'location', 'year_opened']]"
get the names of locations where tracks are located.,track['location'].unique()
give the various locations for tracks.,track['location'].unique()
how many distinct races are there?,race.shape[0]
make a list of distinct classes of races.,race['class'].unique()
what is the list of all races?,race['class'].unique()
"produce the title, class, and date for all races.","race[['name', 'class', 'date']]"
"enumerate the titles of these races: their names, classes, and dates.","race[['name', 'class', 'date']]"
give me the count of races that fall in each of the classes.,race.groupby('class').size().reset_index(name='count')
which classes of races exist?,race.groupby('class').size().reset_index(name='count')
what are the total number of races for each race class?,race.groupby('class').size().sort_values(ascending=false).index[0]
retrieve the class of the most used race.,race.groupby('class').size().sort_values(ascending=false).index[0]
list the race class that contains more than one race.,race.groupby('class').filter(lambda x: len(x) >= 2)['class'].drop_duplicates()
what is the count of races that have at least 2 corresponding races?,race.groupby('class').filter(lambda x: len(x) >= 2)['class'].drop_duplicates()
retrieve the titles of those tracks for which 'gt' does not have a corresponding race.,"track.loc[~track['name'].isin(race.loc[race['class']=='gt', 'name'])]['name']"
list out the race of all the tracks that do not have races in the gt class.,"track.loc[~track['name'].isin(race.loc[race['class']=='gt', 'name'])]['name']"
list the track names that have not been raced.,"track.loc[~track['track_id'].isin(race['track_id']), 'name']"
please provide me with the names of tracks that have not had any races.,"track.loc[~track['track_id'].isin(race['track_id']), 'name']"
provide me the year in which a track with seating at least 5000 and a track with seating no more than 4000 opened.,"track.loc[lambda x: (x['seating'] >= 4000) & (x['seating'] <= 5000), 'year_opened']"
provide me with the years of opening of tracks having seating between 4000 and 5000.,"track.loc[lambda x: (x['seating'] >= 4000) & (x['seating'] <= 5000), 'year_opened']"
please mention the names of tracks and the number of races in each track.,"race.merge(track, on='track_id').groupby('name').size()"
what is the name of each track and the number of races that it has hosted?,"race.merge(track, on='track_id').groupby('name').size()"
provide the name of the track on which the maximum number of races have been held.,"pd.merge(race, track, on='track_id').groupby('track_id')['name'].agg(['count']).sort_values('count', ascending=false).iloc[:1]['name']"
what is the track with the highest number of races?,"pd.merge(race, track, on='track_id').groupby('track_id')['name'].agg(['count']).sort_values('count', ascending=false).iloc[:1]['name']"
list the title and date of each race as well as the track name.,"pd.merge(race, track, on='track_id')[['name_x', 'date', 'name_y']]"
"list the name and dates of races, along with the names of tracks where they are held.","pd.merge(race, track, on='track_id')[['name_x', 'date', 'name_y']]"
"show me the race center and name of each track (for each track, it should return name and location).","pd.merge(race, track, on='track_id').groupby(['track_id', 'name', 'location']).size().reset_index(name='count').loc[lambda x: x['count']==1, ['name', 'location']]"
retrieve the names and locations of tracks that had only one race.,"pd.merge(race, track, on='track_id').groupby(['track_id', 'name', 'location']).size().reset_index(name='count').loc[lambda x: x['count']==1, ['name', 'location']]"
"locate the locations that have both tracks with greater than 90,000 seats as well as tracks with fewer than 70,000 seats.","pd.merge(track.loc[lambda x: x['seating'] > 90000, 'location'].to_frame(),track.loc[lambda x: x['seating'] < 70000, 'location'].to_frame(),on='location')['location']"
what is the number of locations that have both tracks with more than 90000 seats and tracks with less than 70000 seats?,"pd.merge(track.loc[lambda x: x['seating'] > 90000, 'location'].to_frame(),track.loc[lambda x: x['seating'] < 70000, 'location'].to_frame(),on='location')['location']"
what is the count of members that have the black membership card?,(member['membership_card'] == 'black').sum()
compose the summary of the number of members in each address.,member.groupby('address').size().reset_index(name='count')
return the names of members whose address is located in harford or waterbury.,"member.loc[lambda x: x['address'].isin(['harford', 'waterbury']), 'name']"
find the title and id of the members that are under the age of 30 or have black membership card.,"member.loc[(member['membership_card']=='black') | (member['age']<30), ['name', 'member_id']]"
"return me the purchase time, age and address of each member, and show the results in ascending purchase time order.","member[['time_of_purchase', 'age', 'address']].sort_values('time_of_purchase')"
provide the count of membership cards that have more than 5 members.,member.groupby('membership_card').filter(lambda x: len(x) > 5)['membership_card'].unique()
retrieve the addresses having both members who are younger than 30 and members who are older than 40.,"pd.merge(member.loc[lambda x: x['age']<30, 'address'], member.loc[lambda x: x['age']>40, 'address'])"
what are the bachelor memberships held by two members living in hartford and ones living in waterbury?,"pd.merge(member.loc[lambda x: x['address']=='hartford', 'membership_card'], member.loc[lambda x: x['address']=='waterbury', 'membership_card'], how='inner')"
what is the count of members who are not living in hartford?,(member['address'] != 'hartford').sum()
which addresses do not have any member with the black membership card?,"member.loc[~(member['membership_card'] == 'black'), 'address']"
please return the names of the shops in the order in which they are opened.,shop.sort_values('open_year')['address']
retrieve the average score and average staff number of all shops.,"shop[['num_of_staff', 'score']].mean()"
find the names of the shops with scores below the average score.,"shop.loc[lambda x: x['score'] < x['score'].mean(), ['shop_id', 'address']]"
determine the names and addresses of the stores without happy hour.,"shop.loc[~shop['shop_id'].isin(happy_hour['shop_id']), ['address', 'num_of_staff']]"
what is the id and address of the shops that offer a happy hour in may?,"pd.merge(shop, happy_hour, on='shop_id').loc[lambda x: x['month']=='may', ['address', 'shop_id']]"
"please, list the id and number of happy hours for each of the shops.",happy_hour.groupby('shop_id').size().sort_values(ascending=false).iloc[[0]]
how many happy hours are there in a particular month?,happy_hour['month'].value_counts().index[0]
which months have more than two happy hours?,happy_hour.groupby('month').filter(lambda x: len(x) > 2)['month'].unique()
please calculate the total number of albums.,len(album)
determine the count of albums.,len(album)
retrieve the titles of all types of music.,genre['name']
what is the complete list of genres of music?,genre['name']
please list customer details in the state of ny.,"customer.loc[lambda x: x['state']=='ny', :]"
retrieve the complete customer data of customers located in the state of new york.,"customer.loc[lambda x: x['state']=='ny', :]"
retrieve the first names and last names of employees who live in the city of calgary.,"employee.loc[lambda x: x['city']=='calgary', ['firstname', 'lastname']]"
retrieve the full names of the employees residing in the city of calgary.,"employee.loc[lambda x: x['city']=='calgary', ['firstname', 'lastname']]"
identify the countries of billing from the invoices.,invoice['billingcountry'].unique()
what is the list of different billing countries for every invoice?,invoice['billingcountry'].unique()
"return the names of all musical artists that have the letters ""a"" in their names.","artist.loc[artist['name'].str.contains('a', case=false), 'name']"
retrieve the artists' names that contain the letter 'a'.,"artist.loc[artist['name'].str.contains('a', case=false), 'name']"
"for which titles are the albums of the artist ""ac/dc""?","pd.merge(album, artist, on='artistid').loc[lambda x: x['name']=='ac/dc', 'title']"
"retrieve the titles of albums manufactured by the rock band ""ac/dc"".","pd.merge(album, artist, on='artistid').loc[lambda x: x['name']=='ac/dc', 'title']"
"determine the number of albums produced by the artist ""metallica"".","pd.merge(album, artist, on='artistid').loc[lambda x: x['name']=='metallica'].shape[0]"
"enumerate the number of albums by the musician ""metallica"".","pd.merge(album, artist, on='artistid').loc[lambda x: x['name']=='metallica'].shape[0]"
"which artist is the author of the album ""balls to the wall""?","pd.merge(album, artist, on='artistid').loc[lambda x: x['title']=='balls to the wall', 'name']"
"find the name of the musician who produced the album ""balls to the wall.""","pd.merge(album, artist, on='artistid').loc[lambda x: x['title']=='balls to the wall', 'name']"
who has the most albums?,"pd.merge(album, artist, on='artistid').groupby('name').size().idxmax()"
which artist holds the title of having the highest number of albums?,"pd.merge(album, artist, on='artistid').groupby('name').size().idxmax()"
find the words mentioned in all the tracks.,"track.loc[lambda x: x['name'].str.contains('you'), 'name']"
retrieve the titles of all songs that contain the pronoun you.,"track.loc[lambda x: x['name'].str.contains('you'), 'name']"
what is the average price for all available tracks?,track['unitprice'].mean()
determine the average unit price per song.,track['unitprice'].mean()
what is the range of track lengths in milliseconds?,"track['milliseconds'].agg(['max', 'min'])"
retrieve the maximum and minimum durations in milliseconds of the tracks.,"track['milliseconds'].agg(['max', 'min'])"
"provide the album names, ids and number of tracks for each album.","album.merge(track, on='albumid').groupby(['title', 'albumid']).size().reset_index(name='count')"
determine the titles of albums and their corresponding id and count them.,"album.merge(track, on='albumid').groupby(['title', 'albumid']).size().reset_index(name='count')"
what is the genre that is the most common in all the tracks?,"pd.merge(genre, track, on='genreid').groupby('genreid')['name'].count().idxmax()"
retrieve the title of music genre that is the most common across all songs.,"pd.merge(genre, track, on='genreid').groupby('genreid')['name'].count().idxmax()"
what is the least common media type in all songs?,"pd.merge(media_type, track, on='mediatypeid').groupby('mediatypeid').size().sort_values().iloc[:1].index.map(lambda x: media_type.loc[x, 'name'])"
how many media types are the least common among all of the tracks?,"pd.merge(media_type, track, on='mediatypeid').groupby('mediatypeid').size().sort_values().iloc[:1].index.map(lambda x: media_type.loc[x, 'name'])"
find the album names and ids for albums which contain tracks with unit price bigger than 1.,"track.merge(album, on='albumid').query('unitprice > 1').groupby('albumid').agg({'title': 'first', 'albumid': 'count'}).rename(columns={'albumid':'count_of_tracks'})[['title', 'count_of_tracks']].reset_index()"
give me the titles and ids of albums that possess tracks with unit price greater than 1.,"track.merge(album, on='albumid').query('unitprice > 1').groupby('albumid').agg({'title': 'first', 'albumid': 'count'}).rename(columns={'albumid':'count_of_tracks'})[['title', 'count_of_tracks']].reset_index()"
how many tunes belonging to rock genre exist?,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='rock'].shape[0]"
what are the number of tracks that are associated with the rock genre?,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='rock'].shape[0]"
what is the average unit price of tracks that belong to the jazz genre?,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='jazz', 'unitprice'].mean()"
estimate the average unit price of jazz tunes.,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='jazz', 'unitprice'].mean()"
"please provide me with the first name and last name of the customer that has the email address ""luisg@embraer.com.br"".","customer.loc[lambda x: x['email']=='luisg@embraer.com.br', ['firstname', 'lastname']]"
"get the complete name for the customer with the email ""luisg@embraer.com.br"".","customer.loc[lambda x: x['email']=='luisg@embraer.com.br', ['firstname', 'lastname']]"
"please supply me with the count of customers with email addresses containing ""gmail.com"".",customer['email'].str.contains('gmail.com').sum()
"determine the count of customers with an email address containing ""gmail.com"".",customer['email'].str.contains('gmail.com').sum()
what is the name of the employee that initially helped the customer with first name leonie?,"employee.loc[lambda x: x['employeeid'].isin(customer.loc[lambda y: y['firstname']=='leonie', 'supportrepid']), ['firstname', 'lastname']]"
provide me with the full names of the employees who help customers with the first name leonie.,"employee.loc[lambda x: x['employeeid'].isin(customer.loc[lambda y: y['firstname']=='leonie', 'supportrepid']), ['firstname', 'lastname']]"
what is the address of the city where the employee who works with postal code 70174 resides?,"pd.merge(customer.loc[lambda x: x['postalcode']=='70174'], employee, left_on='supportrepid', right_on='employeeid')['city']"
reveal the cities in which employees who help customers with postal code 70174 reside.,"pd.merge(customer.loc[lambda x: x['postalcode']=='70174'], employee, left_on='supportrepid', right_on='employeeid')['city']"
what is the total number of distinct cities in which the employees live?,employee['city'].nunique()
retrieve the count of cities that employees reside in.,employee['city'].nunique()
list all invoice dates corresponding to customers named astrid and gruber.,"pd.merge(customer.loc[lambda x: (x['firstname']=='astrid') & (x['lastname']=='gruber')], invoice, on='customerid')['invoicedate']"
which invoice dates correspond to customers with the first name astrid and the last name gruber?,"pd.merge(customer.loc[lambda x: (x['firstname']=='astrid') & (x['lastname']=='gruber')], invoice, on='customerid')['invoicedate']"
retrieve the names of customers whose invoice totals exceeded 20.,"customer.loc[~customer['lastname'].isin(pd.merge(customer, invoice.loc[lambda x: x['total']>20], on='customerid')['lastname'])]['lastname']"
provide the last names of customers with no invoice totals exceeding 20.,"customer.loc[~customer['lastname'].isin(pd.merge(customer, invoice.loc[lambda x: x['total']>20], on='customerid')['lastname'])]['lastname']"
retrieve the first names of all customers residing in brazil and that have an invoice.,"pd.merge(customer, invoice, on='customerid').loc[lambda x: x['country']=='brazil', 'firstname'].unique()"
what is the count of first names that are associated with customers from brazil and who have also had an invoice?,"pd.merge(customer, invoice, on='customerid').loc[lambda x: x['country']=='brazil', 'firstname'].unique()"
provide me the addresses of all customers that live in germany and have an invoice.,"pd.merge(customer.loc[lambda x: x['country']=='germany'], invoice, on='customerid')['address'].unique()"
"provide me with the addresses for customers who reside in germany, of whom, have had an invoice.","pd.merge(customer.loc[lambda x: x['country']=='germany'], invoice, on='customerid')['address'].unique()"
return me all the employee phone numbers.,employee['phone']
kindly provide me with the contact number for each employee.,employee['phone']
how many tracks are in the aac media file type?,"pd.merge(mediatype, track, on='mediatypeid').loc[lambda x: x['name']=='aac audio file'].shape[0]"
"determine the total number of tracks with media type ""aac audio file"".","pd.merge(mediatype, track, on='mediatypeid').loc[lambda x: x['name']=='aac audio file'].shape[0]"
determine the average duration of tracks in milliseconds that belong to latin or pop genre.,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name'].isin(['latin', 'pop']), 'milliseconds'].mean()"
how many milliseconds are in latin and pop tracks on average?,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name'].isin(['latin', 'pop']), 'milliseconds'].mean()"
provide me the employees' first names and ids of employees who serve at least 10 customers.,"customer.merge(employee, left_on='supportrepid', right_on='employeeid').groupby(['firstname', 'supportrepid']).filter(lambda x: len(x) >= 10)[['firstname', 'supportrepid']].drop_duplicates()"
provide me with the first name and support rep id for employee with 10 or more customers,"customer.merge(employee, left_on='supportrepid', right_on='employeeid').groupby(['firstname', 'supportrepid']).filter(lambda x: len(x) >= 10)[['firstname', 'supportrepid']].drop_duplicates()"
please show me the employee last names of those that serve less than or equal to 20 customers.,"customer.merge(employee, left_on='supportrepid', right_on='employeeid').groupby('supportrepid').filter(lambda g: len(g) <= 20)['lastname']"
provide me with the full names of the employees who have served at most 20 customers.,"customer.merge(employee, left_on='supportrepid', right_on='employeeid').groupby('supportrepid').filter(lambda g: len(g) <= 20)['lastname']"
please list all the titles of albums in alphabetical order.,album['title'].sort_values()
return the album titles in alphabetical order.,album['title'].sort_values()
"retrieve the title, id, and name of all artists that have at least three albums in alphabetical order.","pd.merge(album, artist, on='artistid').groupby(['name', 'artistid']).filter(lambda x: len(x) >= 3).sort_values('name')[['name', 'artistid']]"
"retrieve the names of artists with three or more albums, listed alphabetically.","pd.merge(album, artist, on='artistid').groupby(['name', 'artistid']).filter(lambda x: len(x) >= 3).sort_values('name')[['name', 'artistid']]"
retrieve the names or names of artists who do not have a collection.,"artist[~artist['name'].isin(pd.merge(album, artist, on='artistid')['name'])]['name']"
find the names of artists who have not yet released any records.,"artist[~artist['name'].isin(pd.merge(album, artist, on='artistid')['name'])]['name']"
what is the median price of rock tracks?,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='rock', 'unitprice'].mean()"
determine the average cost of all tracks from the rock genre.,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='rock', 'unitprice'].mean()"
determine the longest and shortest pop tracks and their corresponding durations in milliseconds.,"pd.merge(genre.loc[lambda x: x['name']=='pop'], track, on='genreid').agg({'milliseconds': ['max', 'min']})"
find the minimum and maximum millisecond lengths of pop tracks.,"pd.merge(genre.loc[lambda x: x['name']=='pop'], track, on='genreid').agg({'milliseconds': ['max', 'min']})"
provide me with the birth dates of employees living in edmonton.,"employee.loc[lambda x: x['city']=='edmonton', 'birthdate']"
provide the birth dates of employees who live in the city of edmonton.,"employee.loc[lambda x: x['city']=='edmonton', 'birthdate']"
what is the set of unit prices of tracks that are not duplicated?,track['unitprice'].unique()
provide me with the distinct unit prices for tracks.,track['unitprice'].unique()
what is the count of artists who do not have any album?,artist[~artist['artistid'].isin(album['artistid'])].shape[0]
provide me the information of artists who have not released an album.,artist[~artist['artistid'].isin(album['artistid'])].shape[0]
find the album titles that have both tracks of reggae genre and rock.,"pd.merge(pd.merge(album, track, on='albumid'), genre, on='genreid').query(""name=='reggae'"")['title'].intersec(pd.merge(pd.merge(album, track, on='albumid'), genre, on='genreid').query(""name=='rock'"")['title'])"
fetch the phone number list.,available_policies['customer_phone']
calculate the total count of phone numbers.,available_policies['customer_phone']
"retrieve the customer phone numbers under the policy ""life insurance"".","available_policies.loc[lambda x: x['policy_type_code'] == 'life insurance', 'customer_phone']"
"please list the set of phone numbers and all the policy codes of customers using ""life insurance"".","available_policies.loc[lambda x: x['policy_type_code'] == 'life insurance', 'customer_phone']"
how many policy types are available and how many are registered in the db?,available_policies.groupby('policy_type_code').size().sort_values(ascending=false).index[0]
which policy type is commonly used in the available policies?,available_policies.groupby('policy_type_code').size().sort_values(ascending=false).index[0]
retrieve the names of customers along with their phone numbers under the most popular policy type.,"available_policies.loc[lambda x: x['policy_type_code']==available_policies['policy_type_code'].value_counts().index[0], 'customer_phone']"
retrieve the phone numbers of the customers using the most widespread policy type among the available policies.,"available_policies.loc[lambda x: x['policy_type_code']==available_policies['policy_type_code'].value_counts().index[0], 'customer_phone']"
determine the policy types referenced by more than 4 clients.,available_policies.groupby('policy_type_code').filter(lambda x: len(x) > 4)['policy_type_code'].unique()
determine the policy types favored by customers more than 4. show their type code.,available_policies.groupby('policy_type_code').filter(lambda x: len(x) > 4)['policy_type_code'].unique()
retrieve the total and average amount of settlements.,"settlements['settlement_amount'].agg(['sum', 'mean'])"
please return the sum and the average of all settlement amounts.,"settlements['settlement_amount'].agg(['sum', 'mean'])"
retrieve the names of services that have been utilized in at least two documents related to the initial notification of loss.,"pd.merge(first_notification_of_loss, services, on='service_id').groupby('service_id').filter(lambda x: len(x) > 2)['service_name'].unique()"
identify the ttl services that have been employed twice in the first notification of loss.,"pd.merge(first_notification_of_loss, services, on='service_id').groupby('service_id').filter(lambda x: len(x) > 2)['service_name'].unique()"
determine the year in which the claim with the maximum total settlement was enacted.,"pd.merge(claims, settlements, on='claim_id').groupby('claim_id')['settlement_amount'].sum().idxmax()"
what claim has the largest settlement amount? return the effective date of that claim.,"pd.merge(claims, settlements, on='claim_id').groupby('claim_id')['settlement_amount'].sum().idxmax()"
"what is the number of policies that are listed for the customer named ""dayana robel""?","(customers.merge(customers_policies, on='customer_id').loc[lambda x: x['customer_name']=='dayana robel', :].shape[0])"
what number of individuals named dayana robel utilize policies?,"(customers.merge(customers_policies, on='customer_id').loc[lambda x: x['customer_name']=='dayana robel', :].shape[0])"
what is the id of the customer who has the most policies listed?,"customers.merge(customers_policies, on='customer_id').groupby('customer_name').size().sort_values(ascending=false).index[0]"
provide me the customer name whose number of policies is the maximum.,"customers.merge(customers_policies, on='customer_id').groupby('customer_name').size().sort_values(ascending=false).index[0]"
"please list out all the policy types of the customer named ""dayana robel"".","customers_policies.merge(customers, on='customer_id').merge(available_policies, on='policy_id').loc[lambda x: x['customer_name']=='dayana robel', 'policy_type_code'].unique()"
please provide me the information about the type of policies used by customer dayana robel.,"customers_policies.merge(customers, on='customer_id').merge(available_policies, on='policy_id').loc[lambda x: x['customer_name']=='dayana robel', 'policy_type_code'].unique()"
what is the policy type of the customer that has listed the most policies?,"available_policies[np.in1d(available_policies['policy_id'], customers_policies[customers_policies['customer_id'].isin(customers[customers['customer_name']==customers['customer_name'].value_counts().index[0]]['customer_id'])]['policy_id'].unique())]['policy_type_code'].unique()"
list all the policy types that are utilized by the customer enrolled in the most policies.,"available_policies[np.in1d(available_policies['policy_id'], customers_policies[customers_policies['customer_id'].isin(customers[customers['customer_name']==customers['customer_name'].value_counts().index[0]]['customer_id'])]['policy_id'].unique())]['policy_type_code'].unique()"
v2,services['service_name'].sort_values()
provide me with a list of all service names sorted as alphabetically as possible.,services['service_name'].sort_values()
determine the total number of services.,services.shape[0]
retrieve the titles of those users who do not have a record for their first notification of loss.,"customers.loc[~customers['customer_id'].isin(first_notification_of_loss['customer_id']), 'customer_name']"
"where are the customers who are not listed in the first notification of loss record? also, provide their names.","customers.loc[~customers['customer_id'].isin(first_notification_of_loss['customer_id']), 'customer_name']"
"retrieve the names of customers who have utilized either the service ""close a policy"" or the service ""upgrade a policy"".","pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: (x['service_name']=='close a policy') | (x['service_name']=='upgrade a policy'), 'customer_name']"
"find the names of clients who have utilized the service named ""close a policy"" or ""upgrade a policy"".","pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: (x['service_name']=='close a policy') | (x['service_name']=='upgrade a policy'), 'customer_name']"
retrieve the names of clients who have applied for two services: close a policy and new policy application.,"pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: x['service_name']=='close a policy', 'customer_name'].intersect(pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: x['service_name']=='new policy application', 'customer_name'])"
"find the customers that have used both the services named ""close a policy"" and ""upgrade a policy"". give me customer names.","pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: x['service_name']=='close a policy', 'customer_name'].intersect(pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: x['service_name']=='new policy application', 'customer_name'])"
"retrieve the ids of customers with names containing ""diana"".","customers.loc[customers['customer_name'].str.contains('diana'), 'customer_id']"
"get the names of the customers who have titles with the word ""diana"".","customers.loc[customers['customer_name'].str.contains('diana'), 'customer_id']"
which are the minimum and maximum settlement amounts on records?,"settlements['settlement_amount'].agg(['max', 'min'])"
find the maximum and minimum settlement values.,"settlements['settlement_amount'].agg(['max', 'min'])"
provide the ids of customers in ascending order.,"customers[['customer_id', 'customer_name']].sort_values('customer_id')"
collect the ids of customers in an ordered list.,"customers[['customer_id', 'customer_name']].sort_values('customer_id')"
"retrieve the opening and closing dates of all the policies associated with the customer whose name contains ""diana"".","customers.merge(customers_policies, on='customer_id').loc[lambda x: x['customer_name'].str.contains('diana'), ['date_opened', 'date_closed']]"
"retrieve the opening and closing dates of all the policies that are used by the customer with names containing ""diana"".","customers.merge(customers_policies, on='customer_id').loc[lambda x: x['customer_name'].str.contains('diana'), ['date_opened', 'date_closed']]"
determine the count of enzymes.,enzyme.shape[0]
descending sort the list of enzymes.,"enzyme.sort_values('name', ascending=false)['name']"
please list the names of enzymes in order of decreasing count.,"enzyme.sort_values('name', ascending=false)['name']"
what are the locations that the enzyme is able to produce an effect?,"enzyme[['name', 'location']]"
provide the names and cities of enzymes that are listed.,"enzyme[['name', 'location']]"
what is the maximal value of the online mendelian inheritance in man (omim) of enzymes?,enzyme['omim'].max()
what is the maximal number of omim value in the database?,enzyme['omim'].max()
"what is the product of gene, chromosome and porphyria which are associated with enzymes that operate at the location 'cytosol'?","enzyme.loc[lambda x: x['location']=='cytosol', ['product', 'chromosome', 'porphyria']]"
retrieve the titles of enzymes that do not produce 'heme',"enzyme.loc[lambda x: x['product']!='heme', 'name']"
what is the total number of enzymes whose products are other than 'heme'?,"enzyme.loc[lambda x: x['product']!='heme', 'name']"
list the names of medicines having 'yes' value in the fda record.,"medicine.loc[medicine['fda_approved']=='yes', ['name', 'trade_name']]"
retrieve the names and trade names of the medications that receive approval from the food and drug administration.,"medicine.loc[medicine['fda_approved']=='yes', ['name', 'trade_name']]"
find the identities of enzyme types that are inhibitors in the composition of the medicine named 'amisulpride'.,"enzyme.loc[(enzyme.merge(medicine_enzyme_interaction.loc[lambda x: x['interaction_type']=='inhibitor'], on='id').merge(medicine.loc[lambda x: x['name']=='amisulpride'], on='id'))['name']]"
"identify the names of enzymes utilized in the manufacture of the medicine called amisulpride, which acts as a monoamine oxidase inhibitor.","enzyme.loc[(enzyme.merge(medicine_enzyme_interaction.loc[lambda x: x['interaction_type']=='inhibitor'], on='id').merge(medicine.loc[lambda x: x['name']=='amisulpride'], on='id'))['name']]"
retrieve the id and name of medication that can interact with at least two enzymes.,"medicine_enzyme_interaction.groupby('medicine_id').filter(lambda x: len(x) >= 2).merge(medicine[['id', 'name']], on='id')[['id', 'name']].drop_duplicates()"
for which medicine identifier are the medicines that can be administered to more than one patient's enzyme?,"medicine_enzyme_interaction.groupby('medicine_id').filter(lambda x: len(x) >= 2).merge(medicine[['id', 'name']], on='id')[['id', 'name']].drop_duplicates()"
"sort the medicines by id, name and approval status in descending order of the number of enzymes they interact with.","medicine.merge(medicine_enzyme_interaction, on='medicine_id').groupby(['id', 'name', 'fda_approved']).size().reset_index(name='count').sort_values('count', ascending=false)[['id', 'name', 'fda_approved']]"
"provide the ids, names, and fda approval status for medicines ordered by descending number of possible enzyme interactions.","medicine.merge(medicine_enzyme_interaction, on='medicine_id').groupby(['id', 'name', 'fda_approved']).size().reset_index(name='count').sort_values('count', ascending=false)[['id', 'name', 'fda_approved']]"
please provide me with the id and full name of the enzyme with the highest number of medicines that can be labeled as activators.,"medicine_enzyme_interaction.loc[lambda x: x['interaction_type']=='activitor'].merge(enzyme, on='id', how='inner').groupby(['id', 'name']).size().sort_values(ascending=false).head(1).reset_index()[['id', 'name']]"
please provide the id and name of the enzyme that is able to interact with the most medicines in the role of activator.,"medicine_enzyme_interaction.loc[lambda x: x['interaction_type']=='activitor'].merge(enzyme, on='id', how='inner').groupby(['id', 'name']).size().sort_values(ascending=false).head(1).reset_index()[['id', 'name']]"
which type of interaction is used for the enzyme named 'ala synthase' and the medicine named 'aripiprazole'?,"pd.merge(pd.merge(medicine_enzyme_interaction, medicine, left_on='medicine_id', right_on='id'), enzyme, left_on='enzyme_id', right_on='id').loc[(lambda x: (x['name_x']=='aripiprazole') & (x['name_y']=='ala synthase')),['interaction_type']]"
which interaction type is the most common between drugs and enzymes? what is the number of occurrences for this interaction?,medicine_enzyme_interaction.groupby('interaction_type').size().sort_values(ascending=false).head(1)
"what is the count of common types of interactions between enzymes and medicine, and what are their names?",medicine_enzyme_interaction.groupby('interaction_type').size().sort_values(ascending=false).head(1)
"which medicines have the fda's approval status ""no""?",(medicine['fda_approved']=='no').sum()
what is the number of medicines that did not receive approval from the fda?,(medicine['fda_approved']=='no').sum()
what is the number of enzymes that do not affiliate with any other molecule?,enzyme['id'].isin(medicine_enzyme_interaction['enzyme_id']).value_counts()[false]
what is the total number of enzymes without any interactions?,enzyme['id'].isin(medicine_enzyme_interaction['enzyme_id']).value_counts()[false]
"i am in need of a medicine that can bind with at least 3 enzymes. please provide the id, and trade names of the medicines.","pd.merge(medicine, medicine_enzyme_interaction, on='id').groupby(['id', 'trade_name']).filter(lambda x: x['id'].count() >= 3).loc[:, ['id', 'trade_name']].drop_duplicates()"
which medicine is capable of being partnered with up to 3 of the enzymes from the dataset?,"pd.merge(medicine, medicine_enzyme_interaction, on='id').groupby(['id', 'trade_name']).filter(lambda x: x['id'].count() >= 3).loc[:, ['id', 'trade_name']].drop_duplicates()"
"list out the distinct name, location and products of the enzymes that exhibit any 'inhibitor' interaction.","pd.merge(enzyme, medicine_enzyme_interaction.loc[lambda x: x['interaction_type']=='inhibitor'], left_on='id', right_on='enzyme_id')[['name', 'location', 'product']].drop_duplicates()"
"which enzymes have chemical names, locations, and products that are capable of inhibiting interactions?","pd.merge(enzyme, medicine_enzyme_interaction.loc[lambda x: x['interaction_type']=='inhibitor'], left_on='id', right_on='enzyme_id')[['name', 'location', 'product']].drop_duplicates()"
provide me with the medicine name and trade name which can both act as an 'inhibitor' and 'activator' with enzymes.,"medicine_enzyme_interaction.merge(medicine, on='id').loc[lambda x: x['interaction_type'] == 'inhibitor', ['name', 'trade_name']].merge(medicine_enzyme_interaction.merge(medicine, on='id').loc[lambda x: x['interaction_type'] == 'activitor', ['name', 'trade_name']]).drop_duplicates()"
what are the medicines and pharmaceutical brands that are inhibitors of and activators of enzymes?,"medicine_enzyme_interaction.merge(medicine, on='id').loc[lambda x: x['interaction_type'] == 'inhibitor', ['name', 'trade_name']].merge(medicine_enzyme_interaction.merge(medicine, on='id').loc[lambda x: x['interaction_type'] == 'activitor', ['name', 'trade_name']]).drop_duplicates()"
provide me the list of medicines and trade names that cannot interact with the enzyme with product 'heme'.,"medicine[['name', 'trade_name']].loc[~medicine.id.isin(medicine_enzyme_interaction.merge(enzyme.loc[lambda x: x['product'] == 'protoporphyrinogen ix'], left_on='enzyme_id', right_index=true)['medicine_id'])]"
what is the count of distinct fda approval statuses for the medicines?,medicine['fda_approved'].nunique()
return me the number of different statuses that the fda assigns to medicines.,medicine['fda_approved'].nunique()
"which enzyme names have the substring ""ala"" or ""ala""?","enzyme.loc[enzyme['name'].str.contains('ala'), 'name']"
"obtain the names of enzymes that consist of the string ""ala"".","enzyme.loc[enzyme['name'].str.contains('ala'), 'name']"
find out the number of medicines sold by each trade.,medicine.groupby('trade_name').size().reset_index(name='count')
what were the products offered by the trade name?,medicine.groupby('trade_name').size().reset_index(name='count')
order the schools by their year of founding and output the list.,"university[['school', 'nickname']].sort_values('founded')"
"what is the total count of schools and their nicknames, ordered chronologically?","university[['school', 'nickname']].sort_values('founded')"
provide me with the complete description of all public schools along with their location.,"university.loc[lambda x: x['affiliation']=='public', ['school', 'location']]"
could you provide me the details of the public schools along with their complete address and contact numbers?,"university.loc[lambda x: x['affiliation']=='public', ['school', 'location']]"
when was the school with the largest enrollment established?,"university.sort_values('enrollment', ascending=false).iloc[0]['founded']"
please provide me with the founded year for the university with the largest student enrollment.,"university.sort_values('enrollment', ascending=false).iloc[0]['founded']"
find the year in which the newest non public school was founded.,"university.loc[lambda x: x['affiliation'] != 'public', 'founded'].sort_values(ascending=false).iloc[0]"
please provide me with the year in which the most recently established non public school was founded.,"university.loc[lambda x: x['affiliation'] != 'public', 'founded'].sort_values(ascending=false).iloc[0]"
what is the number of schools that participate in the basketball match?,basketball_match['school_id'].nunique()
estimate the number of schools that have engaged in basketball matches.,basketball_match['school_id'].nunique()
what is the score obtained in the acme of acc in the competition.,basketball_match['acc_percent'].sort_values(ascending=false).iloc[0]
please provide me with the rank listing of top-performing basketball teams.,basketball_match['acc_percent'].sort_values(ascending=false).iloc[0]
what is the conference that yielded the lowest acceptance rate in the competition?,"university.merge(basketball_match, on='school_id').sort_values('acc_percent')['primary_conference'].iloc[0]"
please provide me with the primary conference of the school that has the lowest overall acc percentage.,"university.merge(basketball_match, on='school_id').sort_values('acc_percent')['primary_conference'].iloc[0]"
please provide me with the team name and score of the school that was founded for the longest time.,"pd.merge(university, basketball_match, on='school_id').sort_values('founded').iloc[0][['team_name', 'acc_regular_season']]"
provide me with the name of team and the abbreviation during regular season for the college that was founded the earliest.,"pd.merge(university, basketball_match, on='school_id').sort_values('founded').iloc[0][['team_name', 'acc_regular_season']]"
determine the name of all schools that play clemson as their athletic moniker and also provide the location and scores of their games.,"pd.merge(university, basketball_match, on='school_id').loc[lambda x: x['team_name']=='clemson', ['all_games', 'location']]"
retrieve the titles of scores and locations of the school called clemson.,"pd.merge(university, basketball_match, on='school_id').loc[lambda x: x['team_name']=='clemson', ['all_games', 'location']]"
what average enrollment size are universities founded before 1850?,"university.loc[lambda x: x['founded'] < 1850, 'enrollment'].mean()"
could you please provide me with the average enrollment of universities that were established before 1850?,"university.loc[lambda x: x['founded'] < 1850, 'enrollment'].mean()"
determine the oldest university and its primary conference.,"university[['enrollment', 'primary_conference', 'founded']].sort_values('founded').iloc[0, [0, 1]]"
which university had the earliest commencement date and primary conference?,"university[['enrollment', 'primary_conference', 'founded']].sort_values('founded').iloc[0, [0, 1]]"
"how many students were enrolled and, separately, the minimum enrollment in all schools?","university['enrollment'].agg(['sum', 'min'])"
retrieve the total number and minimum number of students across all schools.,"university['enrollment'].agg(['sum', 'min'])"
determine the total count of students enrolled in affiliation type schools.,university.groupby('affiliation')['enrollment'].sum()
determine the total count of students that are enrolled in universities of each affiliation type.,university.groupby('affiliation')['enrollment'].sum()
what is the count of schools that have not participated in the basketball game?,university['school_id'].loc[~university['school_id'].isin(basketball_match['school_id'])].count()
determine the number of universities that are not part of the basketball match.,university['school_id'].loc[~university['school_id'].isin(basketball_match['school_id'])].count()
list the names of schools that were either founded after 1850 or public.,"university.loc[(university['founded'] > 1850) | (university['affiliation'] == 'public'), 'school']"
what is the count of schools that were either founded earlier than 1850 or are public institutions?,"university.loc[(university['founded'] > 1850) | (university['affiliation'] == 'public'), 'school']"
find out the count of different affiliation types.,university['affiliation'].nunique()
please count the number of distinct affiliations.,university['affiliation'].nunique()
count the number of school locations that contain the word 'ny'.,university['location'].str.contains('ny').sum()
how many universities have a location that contains new york?,university['location'].str.contains('ny').sum()
list out the names of the universities whose enrollments are smaller than the mean enrollment size.,"university.merge(basketball_match, on='school_id').loc[lambda x: x['enrollment']<university['enrollment'].mean(), 'team_name']"
obtain the names of schools whose enrollment is below the average.,"university.merge(basketball_match, on='school_id').loc[lambda x: x['enrollment']<university['enrollment'].mean(), 'team_name']"
please provide me with the count of universities that have an enrollment size of over 20000 for each affiliation type.,university.loc[lambda x: x['enrollment'] > 20000].groupby('affiliation').size()
"determine the affiliations of organizations, and the number each school has a student enrollment of more than 20000.",university.loc[lambda x: x['enrollment'] > 20000].groupby('affiliation').size()
retrieve the number of students enrolled in each college that was established after the year 1850 for each affiliation type.,university.loc[lambda x: x['founded'] > 1850].groupby('affiliation').agg({'enrollment': 'sum'})
which school had the maximum enrollment across all the schools?,university['enrollment'].max()
please determine the maximal enrollment across all schools.,university['enrollment'].max()
provide all information regarding the basketball match.,basketball_match
please provide me with all the information about the basketball game.,basketball_match
"list the names and scores of all teams in the basketball competition, ordered by their respective scores in their home ground.","basketball_match.sort_values('all_home', ascending=false)['team_name']"
"retrieve the names of all the basketball teams in the championship, sorted by all home scores in descending order.","basketball_match.sort_values('all_home', ascending=false)['team_name']"
retrieve the names that correspond to models launched between 2002 and 2004.,"chip_model.loc[lambda x: x['launch_year'].between(2002, 2004), 'model_name']"
please list the model name and the amount of ram for each device that has the least amount of ram.,"chip_model[['model_name', 'ram_mib']].sort_values('ram_mib').head(1)"
"please provide the information for the phone and model ""lg-p760"", including the type and screen mode.","phone.loc[lambda x: x['hardware_model_name']=='lg-p760', ['chip_model', 'screen_mode']]"
"i would like to know the total number of phone hardware models produced by the ""nokia corporation"".","(phone['company_name'] == ""nokia corporation"").sum()"
please provide information about the maximum and minimum ram size of phones that were manufactured by the nokia corporation.,"pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model').loc[lambda x: x['company_name'] == ""nokia corporation"", 'ram_mib'].agg(['max', 'min'])"
"what is the mean rom size of phones manufactured by the company named ""nokia corporation""?","pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model').loc[lambda x: x['company_name'] == ""nokia corporation"", 'rom_mib'].mean()"
list the mobile phone model name and company name for all the phones that were launched in year 2002 or have ram size greater than 32.,"pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model').loc[(chip_model['launch_year']==2002) | (chip_model['ram_mib']>32), ['hardware_model_name', 'company_name']]"
list the phones that have the word 'full' in their accreditation type. include the model name and the company name for each phone.,"phone.loc[phone['accreditation_type'].str.contains('full'), ['hardware_model_name', 'company_name']]"
"retrieve the char cell, pixel and hardware color codes for the display of the phone whose hardware model is ""lg-p760"".","pd.merge(screen_mode, phone, left_on='graphics_mode', right_on='screen_mode').loc[lambda x: x['hardware_model_name']=='lg-p760', ['char_cells', 'pixels', 'hardware_colours']]"
provide me with the title of the phone's hardware model and their company name along with modes.,"pd.merge(screen_mode[screen_mode['type'] == 'graphics'], phone, left_on='graphics_mode', right_on='screen_mode')[['hardware_model_name', 'company_name']]"
retreive the name and number of phone models produced by the company with the lowest count.,"phone.groupby('company_name').size().sort_values().head(1).reset_index().rename(columns={'company_name': 'company_name', 0: 'count(*)'})[['company_name', 'count(*)']]"
list the names of companies producing more than one phone model.,phone.groupby('company_name').filter(lambda x: len(x) > 1)['company_name']
"provide me with the count of maximum, minimum and average number of utilized kb during screen mode.","screen_mode['used_kb'].agg(['max', 'min', 'mean'])"
list the title of the phone model launched by the company in 2002 and with the highest ram size.,"phone.merge(chip_model[chip_model['launch_year'] == 2002], left_on='chip_model', right_on='model_name').sort_values('ram_mib', ascending=false).iloc[0]['hardware_model_name']"
"is wifi or screen mode the type of hardware model named ""lg-p760""?","pd.merge(pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model'), screen_mode, left_on='screen_mode', right_on='graphics_mode').loc[lambda x: x['hardware_model_name']=='lg-p760', ['wifi', 'type']]"
"provide the title and model number for all phones with the screen mode type ""text"" or ram size greater than 32.","pd.merge(pd.merge(chip_model, phone, left_on='model_name', right_on='chip_model'), screen_mode, left_on='screen_mode', right_on='graphics_mode').loc[(lambda x:x['type']=='text')|(lambda x:x['ram_mib']>32), 'hardware_model_name']"
provide me with the full name and series of the hardware model name of all the phones manufactured by nokia corporation or that have a graphics screen mode type.,"pd.merge(screen_mode[screen_mode['type']=='graphics'], phone, left_on='graphics_mode', right_on='screen_mode').loc[lambda x: (x['type']=='graphics') | (x['company_name']=='nokia corporation'), 'hardware_model_name'].unique()"
retrieve the model names of hardware produced by nokia corporation whose screen mode type is other than text.,"pd.merge(screen_mode.query('type!=""text""'), phone.query('company_name==""nokia corporation""'), left_on='graphics_mode', right_on='screen_mode').loc[:, 'hardware_model_name'].unique()"
provide me with the details for the phone hardware model and domain name for the phones that have screen utilization values from 10 to 15 kb.,"pd.merge(screen_mode.loc[(screen_mode['used_kb'] >= 10) & (screen_mode['used_kb'] <= 15)], phone, left_on='graphics_mode', right_on='screen_mode')[['hardware_model_name', 'company_name']].drop_duplicates()"
provide me with the count of phones for each accreditation type.,phone.groupby('accreditation_type').size().reset_index(name='count')
determine the total number of phones owned by each accreditation.,phone.groupby('accreditation_type').size().reset_index(name='count')
find the accreditation level of mobile phones that has exceeded the average count.,phone.groupby('accreditation_level').filter(lambda x: len(x) > 3)['accreditation_level'].unique()
indicate the specifics of all chip models.,chip_model
what is the count of products that do not have wifi function?,(chip_model['wifi'] == 'no').sum()
calculate the count of chips that do not possess wifi.,(chip_model['wifi'] == 'no').sum()
present a model name list indicating the product model launch year.,chip_model.sort_values('launch_year')['model_name']
compute the average ram of chip models that are not used by any phone.,chip_model[~chip_model['model_name'].isin(phone['chip_model'])]['ram_mib'].mean()
retrieve the titles of all chip models that are not utilized by any phone with full accreditation type.,"chip_model[~chip_model['model_name'].isin(phone.loc[phone['accreditation_type']=='full', 'chip_model'].unique())]['model_name']"
enumerate the screen modes utilized by both the phones with full accreditation types and phones with provisional accreditation types.,"pd.merge(screen_mode.merge(phone.query('accreditation_type == ""provisional""'), left_on='graphics_mode', right_on='screen_mode', suffixes=('_l', '_r')), screen_mode.merge(phone.query('accreditation_type == ""full""'), left_on='graphics_mode', right_on='screen_mode', suffixes=('_l', '_r')))['pixels'].unique()"
what is the total number of countries?,country.shape[0]
determine the total count of countries.,country.shape[0]
display the name of countries and capital for all countries.,"country[['country_name', 'capital']]"
"list out the languages that use the word ""english"" in their definite names.","country.loc[country['official_native_language'].str.contains('english'), 'official_native_language']"
"find the official native names that contain the string ""english"".","country.loc[country['official_native_language'].str.contains('english'), 'official_native_language']"
show all the distinct positions of matches.,match_season['position'].unique()
find the names of positions for competition season.,match_season['position'].unique()
display the players affiliated with ucla college.,"match_season.loc[lambda x: x['college']=='ucla', 'player']"
list the players from ucla.,"match_season.loc[lambda x: x['college']=='ucla', 'player']"
"provide me the distinct positions of players, who are either from ucla or duke.","match_season.loc[lambda x: x['college'].isin(['ucla', 'duke']), 'position'].unique()"
what are the different positions of students from ucla or duke universities?,"match_season.loc[lambda x: x['college'].isin(['ucla', 'duke']), 'position'].unique()"
identify the players whose positions are defenders.,"match_season.loc[lambda x: x['position']=='defender', ['draft_pick_number', 'draft_class']]"
please provide the pick number and draft class for the players who play as a defender.,"match_season.loc[lambda x: x['position']=='defender', ['draft_pick_number', 'draft_class']]"
how many distinct teams are involved in  sports seasons?,match_season['team'].nunique()
what is the count of teams involved in the match season?,match_season['team'].nunique()
make me a list of players and the years played.,"player[['player', 'years_played']]"
what are the players' names and how many years have they played?,"player[['player', 'years_played']]"
display the names of all teams.,team['name']
please generate a list of all the team names.,team['name']
"list the season, the player, and the country that the player belongs to.","pd.merge(country, match_season, left_on='country_id', right_on='country')[['season', 'player', 'country_name']]"
"return the player name, season, and country which they are a part of.","pd.merge(country, match_season, left_on='country_id', right_on='country')[['season', 'player', 'country_name']]"
list the ids of the players that are indonesia.,"match_season.merge(country, left_on='country', right_on='country_id').loc[lambda x: x['country_name']=='indonesia', 'player']"
can you supply me the names of players originating from indonesia?,"match_season.merge(country, left_on='country', right_on='country_id').loc[lambda x: x['country_name']=='indonesia', 'player']"
what is the list of distinct positions of the players from a country whose capital is dublin?,"pd.merge(country, match_season, left_on='country_id', right_on='country').loc[lambda x: x['capital']=='dublin', 'position'].unique()"
please provide me with the positions played by players who play for ireland.,"pd.merge(country, match_season, left_on='country_id', right_on='country').loc[lambda x: x['capital']=='dublin', 'position'].unique()"
what languages are used by players of universities in maryland or duke?,"pd.merge(country, match_season, how='inner', left_on='country_id', right_on='country').loc[lambda x: x['college'].isin(['maryland', 'duke']), 'official_native_language']"
give the names of official native tongues of players on teams from maryland or duke colleges.,"pd.merge(country, match_season, how='inner', left_on='country_id', right_on='country').loc[lambda x: x['college'].isin(['maryland', 'duke']), 'official_native_language']"
how many official languages are there among countries whose players' positions are defenders?,"pd.merge(country, match_season, left_on='country_id', right_on='country').loc[lambda x: x['position']=='defender', 'official_native_language'].nunique()"
titles of official languages for countries that players of defender are from.,"pd.merge(country, match_season, left_on='country_id', right_on='country').loc[lambda x: x['position']=='defender', 'official_native_language'].nunique()"
"provide the title of a season, a player, and a team to the dataset.","pd.merge(match_season, team, left_on='team', right_on='team_id')[['season', 'player', 'name']]"
retrieve the names of players along with the season they participate in and the name of their team.,"pd.merge(match_season, team, left_on='team', right_on='team_id')[['season', 'player', 'name']]"
"traverse through the roster of players belonging to the team ""ryley goldner"" and list their positions.","match_season.merge(team, left_on='team', right_on='team_id').loc[lambda x: x['name']=='ryley goldner', 'position']"
provide the rows of data containing the positions and names of players on the ryley goldner team.,"match_season.merge(team, left_on='team', right_on='team_id').loc[lambda x: x['name']=='ryley goldner', 'position']"
"determine the total number of distinct colleges that are associated with players of the team named ""columbus crew"".","pd.merge(match_season, team, left_on='team', right_on='team_id').loc[lambda x: x['name']=='columbus crew', 'college'].nunique()"
determine the total count of colleges that players who play for columbus crew are from.,"pd.merge(match_season, team, left_on='team', right_on='team_id').loc[lambda x: x['name']=='columbus crew', 'college'].nunique()"
"list the players who were active on the team ""columbus crew"" along with their years of playing for the team.","player.merge(team, left_on='team', right_on='team_id').loc[lambda x: x['name']=='columbus crew', ['player', 'years_played']]"
provide me the positions of players along with their corresponding count.,match_season.groupby('position').size().reset_index(name='count')
identify the names of countries along with their corresponding number of players.,"pd.merge(country, match_season, left_on='country_id', right_on='country').groupby('country_name').size()"
what is the count of players from each nation?,"pd.merge(country, match_season, left_on='country_id', right_on='country').groupby('country_name').size()"
sort the players according to their college names in alphabetical order.,match_season.sort_values('college')['player']
"provide me with all the players who took part in the match season of the college, sorted in ascending order.",match_season.sort_values('college')['player']
what is the most common position played by players during match seasons?,match_season.groupby('position').size().sort_values(ascending=false).head(1).reset_index()['position']
what is the position that is most common among players of match seasons?,match_season.groupby('position').size().sort_values(ascending=false).head(1).reset_index()['position']
provide the top 3 most common colleges of players in match seasons.,match_season.groupby('college').size().sort_values(ascending=false).head(3).reset_index()['college']
which three colleges have the highest number of graduates?,match_season.groupby('college').size().sort_values(ascending=false).head(3).reset_index()['college']
list down the names of colleges in which at least two players have been enrolled.,match_season.groupby('college').filter(lambda x: len(x) >= 2)['college'].unique()
list all the colleges which include two or more students.,match_season.groupby('college').filter(lambda x: len(x) >= 2)['college'].unique()
provide me with the college names arranged in descending order of number of players.,"match_season.groupby('college').filter(lambda x: len(x) >= 2).sort_values('college', ascending=false)['college'].drop_duplicates()"
"list the names of the colleges that have two or more players, arranged in descending order of their names.","match_season.groupby('college').filter(lambda x: len(x) >= 2).sort_values('college', ascending=false)['college'].drop_duplicates()"
return the names of teams that do not have season records.,"team.loc[~team['team_id'].isin(match_season['team']), 'name']"
please provide the titles of the teams that do not have a complete match record.,"team.loc[~team['team_id'].isin(match_season['team']), 'name']"
provide me with the names of countries that have both players with position forward and players with position defender.,"pd.merge(country.loc[lambda x: pd.merge(x, match_season.loc[lambda x: x['position']=='forward'], left_on='country_id', right_on='country')['country_id'], 'country_name'], country.loc[lambda x: pd.merge(x, match_season.loc[lambda x: x['position']=='defender'], left_on='country_id', right_on='country')['country_id'], 'country_name'])['country_name']"
"list the pair of countries in which the pair of players, each of which plays either ""forward"" or ""defender"", exists.","pd.merge(country.loc[lambda x: pd.merge(x, match_season.loc[lambda x: x['position']=='forward'], left_on='country_id', right_on='country')['country_id'], 'country_name'], country.loc[lambda x: pd.merge(x, match_season.loc[lambda x: x['position']=='defender'], left_on='country_id', right_on='country')['country_id'], 'country_name'])['country_name']"
which college have participants of both positions midfielder and defender?,"match_season.loc[match_season['position']=='midfielder', 'college'].to_frame().merge(match_season.loc[match_season['position']=='defender', 'college'].to_frame(), on='college')['college']"
provide me the names of colleges that possess the players of both the midfielder as well as the defender positions.,"match_season.loc[match_season['position']=='midfielder', 'college'].to_frame().merge(match_season.loc[match_season['position']=='defender', 'college'].to_frame(), on='college')['college']"
what is the count of climbers?,len(climber)
find the total count of climbers.,climber.shape[0] or len(climber)
provide the names of climbers in order of descending points.,"climber.sort_values('points', ascending=false)['name']"
"list the first names of the climbers, ordered by descending points.","climber.sort_values('points', ascending=false)['name']"
provide me the name counts of climbers whose countries are not switzerland.,"climber.loc[lambda x: x['country'] != 'switzerland', 'name']"
retrieve the names of climbers who are not from switzerland.,"climber.loc[lambda x: x['country'] != 'switzerland', 'name']"
determine the ranking for climbers from united kingdom.,"climber.loc[lambda x: x['country']=='united kingdom', 'points'].max()"
obtain the maximum number of points that british climbers earned.,"climber.loc[lambda x: x['country']=='united kingdom', 'points'].max()"
what is the number of distinct nations the climbers come from?,climber['country'].nunique()
determine the number of different countries from which climbers are from.,climber['country'].nunique()
please list the names of the mountains in an alphabetical order.,mountain.sort_values('name')['name']
please list all mountains in ascending order.,mountain.sort_values('name')['name']
which countries possess mountains with height greater than 5000 feet?,"mountain.loc[mountain['height'] > 5000, 'country']"
provide the countries of the mountains whose elevation is no less than 5000 meters.,"mountain.loc[mountain['height'] > 5000, 'country']"
what is the name  of the highest summit?,"mountain.sort_values('height', ascending=false)['name'].iloc[0]"
please provide me with the name of the mountain with the greatest height.,"mountain.sort_values('height', ascending=false)['name'].iloc[0]"
provide the distinct ranges of mountain peaks along with their prominence.,"mountain['range'].unique()[mountain.sort_values('prominence', ascending=false)['range'].unique()][:3]"
what are the ranges of the three mountains with the highest prominence?,"mountain['range'].unique()[mountain.sort_values('prominence', ascending=false)['range'].unique()][:3]"
retrieve the titles of climbers and the corresponding names of mountains that they climb.,"pd.merge(climber, mountain, on='mountain_id')[['name_x', 'name_y']]"
list the titles and heights of climbers and the peaks they scaled.,"pd.merge(climber, mountain, on='mountain_id')[['name', 'height']]"
retrieve the list of climbers and the corresponding heights of the mountains that they climb.,"pd.merge(climber, mountain, on='mountain_id')[['name', 'height']]"
provide the name of the mountain climbed by the climber with the maximum points.,"climber.merge(mountain, on='mountain_id').sort_values('points', ascending=false).iloc[0]['height']"
what is the height of the mountain that was climbed by the climber who had the most points?,"climber.merge(mountain, on='mountain_id').sort_values('points', ascending=false).iloc[0]['height']"
"please list the names and countries of the mountains climbed by climbers from country ""west germany"".","pd.merge(climber.loc[lambda x: x['country']=='west germany'], mountain, on='mountain_id')['name'].unique()"
enumerate the names of mountains ascended by climbers from the country of west germany.,"pd.merge(climber.loc[lambda x: x['country']=='west germany'], mountain, on='mountain_id')['name'].unique()"
find the time that was utilized by climbers to climb mountains in country uganda.,"climber.merge(mountain, on='mountain_id').loc[lambda x: x['country']=='uganda', 'time']"
what are the frequently used times by the climbers who climbed mountains in uganda?,"climber.merge(mountain, on='mountain_id').loc[lambda x: x['country']=='uganda', 'time']"
please list the names of countries and the number of climbers from each country.,climber.groupby('country').size()
what are the number of climbers that hail from each country?,climber.groupby('country').size()
provide the names of the countries that have more than one mountain.,mountain.groupby('country').filter(lambda x: len(x) > 1)['country'].unique()
determine the number of countries that have more than one mountain.,mountain.groupby('country').filter(lambda x: len(x) > 1)['country'].unique()
what mountains do not have any climbers?,"mountain.loc[~mountain['mountain_id'].isin(climber['mountain_id']), 'name']"
retrieve the names of areas that no climber has climbed.,"mountain.loc[~mountain['mountain_id'].isin(climber['mountain_id']), 'name']"
"show the countries that include mountains with height over 5,600 m and mountains with height less than 5,200 m.","set(mountain.loc[mountain['height'] > 5600, 'country']) & set(mountain.loc[mountain['height'] < 5200, 'country'])"
what are those countries that contain mountains higher than 5600 and lower than 5200?,"set(mountain.loc[mountain['height'] > 5600, 'country']) & set(mountain.loc[mountain['height'] < 5200, 'country'])"
please display the range of mountains that has the most count.,mountain.groupby('range').size().sort_values(ascending=false).index.values[0]
what is the range of mountains that are maximum in quantity?,mountain.groupby('range').size().sort_values(ascending=false).index.values[0]
provide me the names of mountains having a height of more than 5000 meters or prominence of more than 1000 meters.,"mountain.loc[(mountain['height'] > 5000) | (mountain['prominence'] > 1000), 'name']"
please find the names of mountains that have a height greater than 5000 or a prominence greater than 1000.,"mountain.loc[(mountain['height'] > 5000) | (mountain['prominence'] > 1000), 'name']"
what is the count of body builders?,body_builder.shape[0]
what are the scores of bodybuilders in ascending order?,body_builder.sort_values('total')['total']
sort the body builder's snatch score and clean jerk score in ascending order of snatch score.,"body_builder.sort_values('snatch')[['snatch', 'clean_jerk']]"
what is the arithmetic mean of snatch scores of body builders?,body_builder['snatch'].mean()
determine the clean and jerk scores of the body builder with the overall highest score.,"body_builder.sort_values('total', ascending=false).iloc[0]['clean_jerk']"
in which birthday does the tallest person appear?,people.sort_values('height')['birth_date']
obtain the names of body builders.,"pd.merge(body_builder, people, on='people_id')['name']"
return the names of bodybuilders whose total score is higher than 300.,"pd.merge(body_builder, people, on='people_id').loc[lambda x: x['total'] > 300, 'name']"
what name of the body builder has the highest body weight?,"pd.merge(body_builder, people, on='people_id').sort_values('weight', ascending=false)['name'].iloc[0]"
provide me with the birth date and birth place of the body builder that earned the highest total score.,"pd.merge(people, body_builder, on='people_id').sort_values('total', ascending=false).iloc[0][['birth_date', 'birth_place']]"
determine the height of all body builders with total score smaller than 315.,"pd.merge(body_builder, people, on='people_id').loc[lambda x: x['total']<315, 'height']"
what is the average score of body builders whose heights are in excess of 200 inches?,"pd.merge(body_builder, people, on='people_id').loc[lambda x: x['height']>200, 'total'].mean()"
what is the descending order of the greatest number of body builders based on the total score?,"pd.merge(body_builder, people, on='people_id').sort_values('total', ascending=false)['name']"
list the birth places along with the number of individuals that come from each.,people.groupby('birth_place').size().reset_index(name='count')
what is the most frequently occurring birth place of people?,people.groupby('birth_place').size().sort_values(ascending=false).index[0]
list all the birthplaces that are shared by at least two people.,people.groupby('birth_place').filter(lambda x: len(x)>=2)['birth_place'].unique()
please list the height in ascending or descending order of height.,"people[['height', 'weight']].sort_values('height', ascending=false)"
retrieve all details about each bodybuilder.,body_builder
list the names and origins of non-body builders.,"people[['name', 'birth_place']].merge(body_builder['people_id'], how='outer', indicator=true).loc[lambda x : x['_merge']=='left_only'][['name', 'birth_place']]"
how many distinct places of birth are there?,people['birth_place'].nunique()
how many persons are not bodybuilders?,people[~people['people_id'].isin(body_builder['people_id'])].shape[0]
provide me with the name or id of all the bodybuilders that weigh more than 140 pounds and have the height more than 200 inches.,"pd.merge(body_builder, people, on='people_id').loc[(lambda x: x['snatch']>140) | (lambda x: x['height']>200), 'weight']"
"who are the body builders whose birthday string contains the string ""january""?","pd.merge(body_builder, people.loc[lambda x: x['birth_date'].str.contains(""january"")], on='people_id')['total']"
what is the minimum number of snatches in a weightlifting event?,body_builder['snatch'].min()
sort the votes by the order of elections in descending order.,"election.sort_values('votes', ascending=false)['votes']"
"list the dates, vote percentages, and candidates of elections.","election[['date', 'vote_percent']]"
what is the range of vote percentages cast in the elections?,"election['vote_percent'].agg(['min', 'max'])"
what parties are represented in the congress?,"representative[['name', 'party']]"
"retrieve the titles of those representatives whose party is not ""republican"".","representative.loc[lambda x: x['party'] != 'republican', 'name']"
what is the life span of each representative from new york or indiana?,"representative.loc[lambda x: x['state'].isin(['new york', 'indiana']), 'lifespan']"
"retrieve the titles, dates of elections, and the names of representatives.","pd.merge(election, representative, on='representative_id')[['name', 'date']]"
find the names of representatives having more than 10000 votes in an election.,"pd.merge(election, representative, on='representative_id').loc[lambda x: x['votes']>10000, 'name']"
provide me the names in descending order of votes of the representatives.,"pd.merge(election, representative, on='representative_id').sort_values('votes', ascending=false)['name']"
locate the party of a representative that has the fewest votes.,"pd.merge(election, representative, on='representative_id').sort_values('votes')['party'].iloc[0]"
sort the lifespans of the representatives by descending order of their vote percent.,"pd.merge(election, representative, on='representative_id').sort_values('vote_percent', ascending=false)['lifespan']"
what is the mean of total votes by representatives from republican party?,"pd.merge(election, representative, on='representative_id').loc[lambda x: x['party'] == 'republican', 'votes'].mean()"
provide the titles of different parties along with their count of representatives.,representative['party'].value_counts()
what is the number of representatives that belong to the largest political party?,representative.groupby('party').size().sort_values(ascending=false).head(1)
which political parties have at least three members?,representative.groupby('party').filter(lambda x: len(x) >= 3)['party'].drop_duplicates()
what is the count of states that have at least two representatives?,representative.groupby('state').filter(lambda x: len(x) >= 2)['state'].unique()
provide the names of the representatives who have not participated in any of the elections listed here.,representative[~representative['representative_id'].isin(election['representative_id'])]['name']
retrieve the parties which have representatives in both the new york and pennsylvania legislatures.,"representative.loc[representative['state']=='new york', 'party'].isin(representative.loc[representative['state']=='pennsylvania', 'party'])"
what is the count of distinct political parties for representatives?,representative['party'].nunique()
what is the total count of apartment bookings that have been made?,apartment_bookings.shape[0]
give me the count of apartments that are booked.,apartment_bookings.shape[0]
provide the start and finish dates of all apartments.,"apartment_bookings[['booking_start_date', 'booking_end_date']]"
fetch me the start date and end date of each apartment booking.,"apartment_bookings[['booking_start_date', 'booking_end_date']]"
retrieve all distinct descriptions of buildings.,apartment_buildings['building_description'].unique()
please list for me a list of all the building descriptions.,apartment_buildings['building_description'].unique()
find the names of buildings managed by emma.,"apartment_buildings.loc[lambda x: x['building_manager']=='emma', 'building_short_name']"
for which buildings is emma the property manager? retrieve their primary names.,"apartment_buildings.loc[lambda x: x['building_manager']=='emma', 'building_short_name']"
"obtain the addresses and phone numbers of all buildings managed by ""brenden"".","apartment_buildings.loc[lambda x: x['building_manager'] == 'brenden', ['building_address', 'building_phone']]"
"what is the address of the buildings managed by ""brenden""?","apartment_buildings.loc[lambda x: x['building_manager'] == 'brenden', ['building_address', 'building_phone']]"
"which building names contain the word ""court""?","apartment_buildings.loc[apartment_buildings['building_full_name'].str.contains('court', case=false), 'building_full_name']"
"retrieve the titles of buildings that mention the word ""court"".","apartment_buildings.loc[apartment_buildings['building_full_name'].str.contains('court', case=false), 'building_full_name']"
what is the minimum and maximum number of bathrooms present in each apartment?,"apartments['bathroom_count'].agg(['min', 'max'])"
provide information regarding the minimum and maximum number of bathrooms present in the apartments.,"apartments['bathroom_count'].agg(['min', 'max'])"
what is the average of the total number of bedrooms of apartments?,apartments['bedroom_count'].mean()
what is the mean number of bedrooms in all the apartments?,apartments['bedroom_count'].mean()
retrieve the room number and the number of rooms for each apartment.,"apartments[['apt_number', 'room_count']]"
retrieve the addresses and the room counts of each apartment.,"apartments[['apt_number', 'room_count']]"
"what is the average of the number of rooms in apartments with type code ""studio""?","apartments.loc[apartments['apt_type_code']=='studio', 'room_count'].mean()"
"what is the mean room count of the apartments which are coded as ""studio""?","apartments.loc[apartments['apt_type_code']=='studio', 'room_count'].mean()"
"please provide me with the count of apartments with type code ""flat"" and their corresponding apartments numbers.","apartments.loc[apartments['apt_type_code'] == ""flat"", 'apt_number']"
retrieve the complete names of all the guests.,"guests[['guest_first_name', 'guest_last_name']]"
"give me the birth date of all the guests with gender code ""male"".","guests.loc[lambda x: x['gender_code']=='male', 'date_of_birth']"
"list the birthdays of all the guests who belong to the ""male"" gender.","guests.loc[lambda x: x['gender_code']=='male', 'date_of_birth']"
"obtain the apartment numbers, start dates, and end dates of all the apartment bookings.","pd.merge(apartment_bookings[['apt_id', 'booking_start_date', 'booking_end_date']], apartments[['apt_id', 'apt_number']], on='apt_id')[['apt_number', 'booking_start_date', 'booking_end_date']]"
"obtain the room number, start date and time, and end date of each registered booking.","pd.merge(apartment_bookings[['apt_id', 'booking_start_date', 'booking_end_date']], apartments[['apt_id', 'apt_number']], on='apt_id')[['apt_number', 'booking_start_date', 'booking_end_date']]"
"what are the booking start and end dates of the apartments with the type code ""duplex""?","pd.merge(apartment_bookings, apartments[apartments['apt_type_code']=='duplex'], on='apt_id')[['booking_start_date', 'booking_start_date']]"
"please provide me with the start and end dates for the booking of apartments that have a type code of ""duplex"".","pd.merge(apartment_bookings, apartments[apartments['apt_type_code']=='duplex'], on='apt_id')[['booking_start_date', 'booking_start_date']]"
for which apartments may the rental dates span across more than 2 months?,"pd.merge(apartment_bookings, apartments, on='apt_id').loc[lambda x: x['bedroom_count'] > 2, ['booking_start_date', 'booking_end_date']]"
determine the booking start dates and end dates in the case of apartments having more bedrooms than two.,"pd.merge(apartment_bookings, apartments, on='apt_id').loc[lambda x: x['bedroom_count'] > 2, ['booking_start_date', 'booking_end_date']]"
what is the booking status of apartment suite 634?,"pd.merge(apartment_bookings, apartments, on='apt_id').loc[lambda x: x['apt_number']=='suite 634', 'booking_status_code']"
"could you furnish me with the code for the booking status for the apartment with number ""suite 634""?","pd.merge(apartment_bookings, apartments, on='apt_id').loc[lambda x: x['apt_number']=='suite 634', 'booking_status_code']"
"show the apartment ids that are reserved for the bookings whose status is ""confirmed"".","pd.merge(apartment_bookings.loc[lambda x: x['booking_status_code']=='confirmed'], apartments, on='apt_id')['apt_number'].unique()"
"please provide me with the names (or ids) of apartments that have bookings with status code ""confirmed"". also, please provide me with the apartment numbers.","pd.merge(apartment_bookings.loc[lambda x: x['booking_status_code']=='confirmed'], apartments, on='apt_id')['apt_number'].unique()"
"please calculate the average room count of all the apartments with the booking status ""provisional"".","pd.merge(apartment_bookings.loc[lambda x: x['booking_status_code']=='provisional'], apartments, on='apt_id')['room_count'].mean()"
"determine the average room count of the apartments that were labeled ""provisional"".","pd.merge(apartment_bookings.loc[lambda x: x['booking_status_code']=='provisional'], apartments, on='apt_id')['room_count'].mean()"
"please list the full name, start date, and end date of each guest who booked an apartment.","pd.merge(apartment_bookings, guests, on='guest_id')[['guest_first_name', 'booking_start_date']]"
"retrieve the first name, start date, and end date of guest for each apartment booking.","pd.merge(apartment_bookings, guests, on='guest_id')[['guest_first_name', 'booking_start_date']]"
"please list the start and end dates of all the apartment rentals made by guests with gender code ""female"".","pd.merge(apartment_bookings, guests, on='guest_id').loc[lambda x: x['gender_code']=='female', ['booking_start_date', 'booking_start_date']]"
could you provide me with the day and month in which most apartment bookings were made by female guests?,"pd.merge(apartment_bookings, guests, on='guest_id').loc[lambda x: x['gender_code']=='female', ['booking_start_date', 'booking_start_date']]"
"retrieve the names of guests who have apartment reservations with status code ""confirmed"".","pd.merge(apartment_bookings.query('booking_status_code == ""confirmed""'), guests, on='guest_id')[['guest_first_name', 'guest_last_name']]"
find the guests who have confirmed their apartment bookings. also list their first names and last names.,"pd.merge(apartment_bookings.query('booking_status_code == ""confirmed""'), guests, on='guest_id')[['guest_first_name', 'guest_last_name']]"
show me the facility codes of the apartments with more than 4 bedrooms.,"apartment_facilities.merge(apartments, on='apt_id').loc[lambda x: x['bedroom_count'] > 4, 'facility_code']"
provide the ids of apartment facilities that have more than four bedrooms.,"apartment_facilities.merge(apartments, on='apt_id').loc[lambda x: x['bedroom_count'] > 4, 'facility_code']"
"please provide me with the total number of rooms of apartments with facility code ""gym"".","pd.merge(apartment_facilities, apartments, on='apt_id').loc[lambda x: x['facility_code']=='gym', 'room_count'].sum()"
"provide me with the count of rooms in apartments with a facility code of ""gym"".","pd.merge(apartment_facilities, apartments, on='apt_id').loc[lambda x: x['facility_code']=='gym', 'room_count'].sum()"
"enumerate the total number of rooms in the apartments of building having a short name ""columbus square"".","pd.merge(apartment_buildings.loc[lambda x: x['building_short_name'] == 'columbus square'], apartments, on='building_id')['room_count'].sum()"
"what is the total count of apartments in the building with short name ""columbus square""?","pd.merge(apartment_buildings.loc[lambda x: x['building_short_name'] == 'columbus square'], apartments, on='building_id')['room_count'].sum()"
provide me with the addresses of the buildings that have apartments with more than 2 bathrooms.,"pd.merge(apartment_buildings, apartments, on='building_id').loc[lambda x: x['bathroom_count'] > 2, 'building_address']"
give me the ids of the buildings which have apartments that have more than two bathrooms.,"pd.merge(apartment_buildings, apartments, on='building_id').loc[lambda x: x['bathroom_count'] > 2, 'building_address']"
"provide the codes and numbers of apartment types in the buildings managed by ""kyle"".","pd.merge(apartment_buildings, apartments, on='building_id').loc[lambda x: x['building_manager']=='kyle', ['apt_type_code', 'apt_number']]"
"what are the apartment type codes and apartment numbers of the apartments managed by ""kyle""?","pd.merge(apartment_buildings, apartments, on='building_id').loc[lambda x: x['building_manager']=='kyle', ['apt_type_code', 'apt_number']]"
provide me the booking status code and the corresponding count of bookings.,apartment_bookings.groupby('booking_status_code').size()
send me the id and number of bookings for each booking status.,apartment_bookings.groupby('booking_status_code').size()
can you please list the apartment numbers in ascending order of the room count?,apartments.sort_values('room_count')['apt_number']
sort the apartment numbers in ascending order by room count.,apartments.sort_values('room_count')['apt_number']
please identify the address of the apartment with the largest number of bedrooms.,"apartments.sort_values('bedroom_count', ascending=false).iloc[0]['apt_number']"
i need the apartment number for the apartment with the most beds.,"apartments.sort_values('bedroom_count', ascending=false).iloc[0]['apt_number']"
what is the apartment type code and the number of apartments that are in descending order?,apartments.groupby('apt_type_code').size().sort_values()
provide me with the arrangement of apartment type code with the number of apartments having that apartment type in ascending order of the number of apartments.,apartments.groupby('apt_type_code').size().sort_values()
provide me with the 3 apartment type codes sorted by the average number of rooms in descending order.,apartments.groupby('apt_type_code')['room_count'].mean().sort_values(ascending=false).head(3).index.tolist()
what is the three apartment types having the maximum number of rooms? please provide me with their titles.,apartments.groupby('apt_type_code')['room_count'].mean().sort_values(ascending=false).head(3).index.tolist()
"obtain the code of apartment type that has the highest number of rooms, together with the number of bathrooms and bedrooms.","(apartments.groupby('apt_type_code').agg({'bathroom_count': 'first', 'bedroom_count': 'first', 'room_count': 'sum'}).sort_values('room_count', ascending=false).iloc[0][['bathroom_count', 'bedroom_count']])"
"return the apartment type code, its total number of bathrooms and bedrooms.","(apartments.groupby('apt_type_code').agg({'bathroom_count': 'first', 'bedroom_count': 'first', 'room_count': 'sum'}).sort_values('room_count', ascending=false).iloc[0][['bathroom_count', 'bedroom_count']])"
provide the title for the most common apartment type.,apartments.groupby('apt_type_code').size().sort_values(ascending=false).index[0]
which of these apartment type codes are used most often?,apartments.groupby('apt_type_code').size().sort_values(ascending=false).index[0]
the code that corresponds to the most common apartment type among apartments with more than 1 bathroom.,apartments.loc[lambda x: x['bathroom_count']>1].groupby('apt_type_code').size().sort_values(ascending=false).index[0]
which apartment type code is utilized most frequently by the apartments that have more than one bathroom?,apartments.loc[lambda x: x['bathroom_count']>1].groupby('apt_type_code').size().sort_values(ascending=false).index[0]
"a list of apartment type codes, and the maximum and minimum number of rooms for each type.","apartments.groupby('apt_type_code')['room_count'].agg(['max', 'min'])"
retrieve for each apartment type its code along with the minimum and maximum number of rooms.,"apartments.groupby('apt_type_code')['room_count'].agg(['max', 'min'])"
"present a table that exhibits each gender code, the corresponding count of guests, and the rank of each guest count according to the count in descending order.",guests.groupby('gender_code').size().sort_values(ascending=false)
sort the gender code in descending order of the number of guests each code represents. return both the gender codes and counts.,guests.groupby('gender_code').size().sort_values(ascending=false)
what is the count of apartments that do not provide any facility?,len(apartments[~apartments['apt_id'].isin(apartment_facilities['apt_id'])])
provide the count of apartments that do not have facilities.,len(apartments[~apartments['apt_id'].isin(apartment_facilities['apt_id'])])
"search the apartments that have both ""provisional"" and ""confirmed"" status codes.","apartments.merge(apartment_bookings[apartment_bookings['booking_status_code'] == 'confirmed'], on='apt_id', how='inner')['apt_number'].intersec‌t(apartments.merge(apartment_bookings[apartment_bookings['booking_status_code'] == 'provisional'], on='apt_id', how='inner')['apt_number'])"
"give me the ids of apartments which have received bookings for both the status codes ""provisional"" and ""confirmed"".","pd.merge(apartment_bookings[apartment_bookings['booking_status_code']=='confirmed'], apartments, on='apt_id')['apt_number'].tolist() and pd.merge(apartment_bookings[apartment_bookings['booking_status_code']=='provisional'], apartments, on='apt_id')['apt_number'].tolist()"
provide me with the apartment numbers of apartments with the unit status availability of both 0 and 1.,"set(apartments.merge(view_unit_status.loc[lambda x: x['available_yn']==0], on='apt_id')['apt_number']).intersection(set(apartments.merge(view_unit_status.loc[lambda x: x['available_yn']==1], on='apt_id')['apt_number']))"
which apartments have both unavailable and ready unit statuses? return their apartment numbers.,"set(apartments.merge(view_unit_status.loc[lambda x: x['available_yn']==0], on='apt_id')['apt_number']).intersection(set(apartments.merge(view_unit_status.loc[lambda x: x['available_yn']==1], on='apt_id')['apt_number']))"
how many matches were held after season 2007?,(game['season'] > 2007).sum()
display the dates of the games of the team by the home team name in descending order.,"game.sort_values('home_team', ascending=false)['date']"
"list the season, home team, away team, date of all games.","game[['season', 'home_team', 'away_team']]"
"determine the maximum, minimum and average home games each stadium has.","stadium['home_games'].agg(['max', 'min', 'mean'])"
what is the average of attendance at stadiums with a capacity higher than 100%?,"stadium.loc[lambda x: x['capacity_percentage'] > 100, 'average_attendance']"
"what player name, number matches, and source should be recorded for players who do not suffer from injury of ""knee problem""?","injury_accident.query(""injury != 'knee problem'"")[['player', 'number_of_matches', 'source']]"
what was season of the soccer game that caused the player 'walter samuel' to get injured?,"pd.merge(game, injury_accident, on='id').loc[lambda x: x['player'] == 'walter samuel', 'season']"
"provide me with the id, score, and date of the games that resulted in at least two injury accidents.","(game.merge(injury_accident, on='id').groupby(['id', 'score', 'date']).filter(lambda x: len(x) >= 2)[['id', 'score', 'date']])"
what is the id and name of stadium where the maximum number of injury accidents happened?,"pd.merge(pd.merge(stadium, game, on='id'), injury_accident, on='game_id').groupby('id').size().sort_values(ascending=false).reset_index(name='count').iloc[0][['id', 'name']]"
"obtain the id and name of the stadium where the greatest number of concussion accidents, if any, occurred.","pd.merge(pd.merge(stadium, game, on='id'), injury_accident, on='game_id').groupby('id').size().sort_values(ascending=false).reset_index(name='count').iloc[0][['id', 'name']]"
in which season and which stadium did any player have an injury of foot injury or knee problem?,"pd.merge(pd.merge(game, stadium, left_on='stadium_id', right_on='id'), injury_accident, on='game_id').loc[lambda x: x['injury'].isin(['foot injury', 'knee problem']), ['season', 'name']]"
how many different kinds of information sources exist regarding injury accidents?,injury_accident['source'].nunique()
how many sports games are free from any injuries?,"game.loc[~game['id'].isin(injury_accident['game_id']), :].shape[0]"
who sustained the most distinct kinds of injuries after 2010?,"pd.merge(injury_accident, game, left_on='game_id', right_on='id').loc[lambda x: x['season'] > 2010, 'injury'].nunique()"
provide me with the name and location of stadium where both the player 'walter samuel' and the player 'thiago motta' were hospitalized.,"(pd.merge(pd.merge(game, stadium, left_on='stadium_id', right_on='id'), injury_accident, left_on='id', right_on='game_id').loc[lambda x: x['player'].isin(['walter samuel', 'thiago motta'])].groupby('name').filter(lambda x: x['player'].nunique() == 2))['name']"
"provide the title, average attendance, and total attendance for stadiums that were free of accidents.","stadium[['name', 'average_attendance', 'total_attendance']].merge(game[['stadium_id']], left_index=true, right_on='stadium_id', how='left').merge(injury_accident[['game_id']], left_on='id', right_on='game_id', how='left').loc[lambda x: x['game_id'].isna()].drop('game_id', axis=1)"
what games were played at each stadium?,"game.groupby('stadium_id').size().reset_index(name='count').rename(columns={'stadium_id': 'id'})[['id', 'count']].merge(stadium, on='id', how='right')[['id', 'count']].fillna(0)"
"for each injury accident, find the date of the accident and the name of the player injured, and sort the results in descending order of accident season.","pd.merge(game, injury_accident, on='game_id')[['date', 'player']].sort_values('season', ascending=false)"
what country names and league names are there?,"pd.merge(country, league, left_on='id', right_on='country_id')[['name_x', 'name_y']]"
what is the general weight (in kilograms) of all players?,player['weight'].mean()
what is the maximum and minimum height attained by all players?,"player['weight'].agg(['max', 'min'])"
what are the players whose overall ratings are higher than average?,"player.merge(player_attributes, on='player_api_id').loc[lambda x: x['overall_rating'] > player_attributes['overall_rating'].mean(), 'player_name'].nunique()"
what are the names of players that make the best dribbling?,"pd.merge(player, player_attributes, on='player_api_id').loc[lambda x: x['dribbling'] == player_attributes['overall_rating'].max(), 'player_name'].unique()"
provide me with the list of all players who are fond of using their right foot and have a higher crossing score.,"pd.merge(player, player_attributes, on='player_api_id').loc[(lambda x: x['crossing']>90)&(lambda x: x['preferred_foot']=='right'), 'player_name'].unique()"
return the names of all the players who have overall rating between 85 and 90 and are left footed.,"pd.merge(player, player_attributes, on='player_api_id').loc[(lambda x: x['preferred_foot']=='left') & (x['overall_rating'] >= 85) & (x['overall_rating'] <= 90), 'player_name'].unique()"
what is the weighted average rating for right-footed players and left-footed players?,player_attributes.groupby('preferred_foot')['overall_rating'].mean()
"of all players whose overall rating is 80 or greater, how many are right-footed and left-footed?",player_attributes.loc[player_attributes['overall_rating'] > 80].groupby('preferred_foot').size()
find all of the players that have a height of at least 180cm and an overall rating higher than 85.,"pd.merge(player.loc[lambda x: x['height']>=180, 'player_api_id'], player_attributes.loc[lambda x: x['overall_rating']>85, 'player_api_id']).squeeze()"
return me the list of players and their respective heights who are left footed and fall in between 180cm and 190cm.,"pd.merge(player.loc[(player['height']>=180) & (player['height']<=190), ['player_api_id']], player_attributes.loc[player_attributes['preferred_foot']=='left', ['player_api_id']]).drop_duplicates()['player_api_id']"
please provide me with the list of top three players on the basis of their total rating.,"pd.merge(player, player_attributes, on='player_api_id').sort_values('overall_rating', ascending=false).drop_duplicates('player_name')['player_name'][:3]"
enumerate the titles of the top five players according to their potential.====,"player.merge(player_attributes, on='player_api_id').loc[:, ['player_name', 'birthday']].sort_values('potential', ascending=false).drop_duplicates(subset=['player_name', 'birthday']).head(5)"
what is the total of performances?,performance.shape[0]
please list the hosts of performances in order of number of attendance.,performance.sort_values('attendance')['host']
what was the date and location of each performance?,"performance[['date', 'location']]"
provide me with the attendances of performances that took place in td garden or bell centre.,"performance.loc[performance['location'].isin(['td garden', 'bell centre']), 'attendance']"
what is the value of the average number of attendees for performances?,performance['attendance'].mean()
what is the date at which the performance amassed the highest number of attendees?,"performance.sort_values('attendance', ascending=false)['date'].iloc[0]"
tell me the locations where ariana grande has performed and the number of her performances at every location.,performance.groupby('location').size()
what are the venues of the most frequent performances?,performance.groupby('location').size().sort_values(ascending=false).index[0]
list the sites that host at least two events.,performance.groupby('location').filter(lambda x: len(x) >= 2)['location'].unique()
"provide me with the venues that have both performances with up to 2,000 attendees and performances that have fewer than 1,000 attendees.","pd.merge(performance.loc[lambda x: x['attendance'] > 2000, ['location']], performance.loc[lambda x: x['attendance'] < 1000, ['location']]).drop_duplicates()['location']"
return the names of members and the location where they attended the performance.,"pd.merge(pd.merge(member_attendance, member, on='member_id'), performance, on='performance_id')[['name', 'location']]"
"append the name, location, and date of all membership classes in order by individual member name.","pd.merge(pd.merge(member_attendance, member, on='member_id'), performance, on='performance_id').sort_values('name')[['name', 'location']]"
reveal the dates of concerts where violin roles have been included in the lineup.,"pd.merge(pd.merge(member_attendance, member, on='member_id'), performance, on='performance_id').loc[lambda x: x['role']=='violin', 'date']"
enumerate the performances attended by each member in the descending order of attendance.,"pd.merge(pd.merge(member_attendance, member, on='member_id'), performance, on='performance_id').sort_values('attendance', ascending=false)[['name', 'date']]"
provide the names of the members who did not attend any of the concerts.,"member.loc[~member['member_id'].isin(member_attendance['member_id']), 'name']"
determine the count of buildings having rooms that can accommodate more than 50 people.,"classroom.loc[lambda x: x['capacity'] > 50, 'building'].unique()"
which building capacities are greater than 50?,"classroom.loc[lambda x: x['capacity'] > 50, 'building'].unique()"
what is the number of rooms that are absent from lamberton building?,"classroom.query(""building != 'lamberton'"")['building'].count()"
how many classrooms are in lamberton?,"classroom.query(""building != 'lamberton'"")['building'].count()"
what is the building name and the department code whose budget is more than the average budget?,"department.loc[lambda x: x['budget'] > x['budget'].mean(), ['dept_name', 'building']]"
please produce the name of department and their respective building along with the year in which their respective budget exceeded the average.,"department.loc[lambda x: x['budget'] > x['budget'].mean(), ['dept_name', 'building']]"
retrieve the id of the building and room numbers which can accommodate 50 to 100 students.,"classroom.loc[lambda x: x['capacity'].between(50, 100), ['building', 'room_number']]"
find the room numbers and the related buildings for classrooms which can seat between 50 and 100 students.,"classroom.loc[lambda x: x['capacity'].between(50, 100), ['building', 'room_number']]"
determine the name of the department that has the highest budget.,"department.sort_values('budget', ascending=false).head(1)[['dept_name', 'building']]"
what is the department name and the respective building for the department with the greatest budget?,"department.sort_values('budget', ascending=false).head(1)[['dept_name', 'building']]"
what is the name of the history student with the highest total credits?,"student.loc[lambda x: x['dept_name'] == 'history'].sort_values('tot_cred', ascending=false)['name'].iloc[0]"
print the name of the student who has the most credits in the history department.,"student.loc[lambda x: x['dept_name'] == 'history'].sort_values('tot_cred', ascending=false)['name'].iloc[0]"
how many rooms are in the lamberton building?,(classroom['building'] == 'lamberton').sum()
determine the number of classrooms in lamberton.,(classroom['building'] == 'lamberton').sum()
what is the number of students that are guided by advisors?,advisor['s_id'].nunique()
which departments offer courses as a part of their course curriculum?,course['dept_name'].nunique()
what is the count of departments for which courses are offered?,course['dept_name'].nunique()
how many different courses are taught in the physics department?,"course.loc[lambda x: x['dept_name']=='physics', 'course_id'].nunique()"
please calculate the total number of courses in the physics department.,"course.loc[lambda x: x['dept_name']=='physics', 'course_id'].nunique()"
retrieve the names of courses that have two prerequisites.,"course.merge(prereq, on='course_id').groupby('course_id').filter(lambda x: len(x) == 2)['title']"
list the titles of courses with two prerequisites.,"course.merge(prereq, on='course_id').groupby('course_id').filter(lambda x: len(x) == 2)['title']"
"retrieve the title, course number, and department name for courses having more than one prerequisite.","pd.merge(course, prereq, on='course_id').groupby('course_id').filter(lambda x: len(x) > 1)[['title', 'credits', 'dept_name']].drop_duplicates()"
"what is the title, credit value, and department name for courses with 2 or more prerequisites?","pd.merge(course, prereq, on='course_id').groupby('course_id').filter(lambda x: len(x) > 1)[['title', 'credits', 'dept_name']].drop_duplicates()"
how many courses are there that have no prerequisites?,course['course_id'].isin(prereq['course_id']).value_counts()[false]
what is the total count of courses that do not require prerequisites?,course['course_id'].isin(prereq['course_id']).value_counts()[false]
describe all the courses with no prerequisites.,"course.loc[~course['course_id'].isin(prereq['course_id']), 'title']"
what are the books whose absence in a student's curriculum does not hurt her gpa?,"course.loc[~course['course_id'].isin(prereq['course_id']), 'title']"
how many professors have taught some course?,teaches['id'].nunique()
which id's are distinct instructors that have taught a course?,teaches['id'].nunique()
retrieve the total expenses of the marketing or finance department.,"department.loc[department['dept_name'].isin(['marketing', 'finance']), 'budget'].sum()"
what is the sum of budgets of the marketing and the finance departments?,"department.loc[department['dept_name'].isin(['marketing', 'finance']), 'budget'].sum()"
what is the department name belonging to the instructor whose name contains 'soisalon'?,"instructor.loc[instructor['name'].str.contains('soisalon', case=false), 'dept_name']"
"given the title for an employee in an organizational structure that includes the word ""soisalon"", return the full name of that department.","instructor.loc[instructor['name'].str.contains('soisalon', case=false), 'dept_name']"
what is the count of rooms that have capacities less than 50?,classroom.loc[(classroom['building'] == 'lamberton') & (classroom['capacity'] < 50)].shape[0]
determine the total number of rooms with capacity less than half lamberton's.,classroom.loc[(classroom['building'] == 'lamberton') & (classroom['capacity'] < 50)].shape[0]
retrieve the name and budget of departments whose budgets are more than the average budget.,"department.loc[lambda x: x['budget'] > x['budget'].mean(), ['dept_name', 'budget']]"
what is the list of department ids along with their names and budget?,"department.loc[lambda x: x['budget'] > x['budget'].mean(), ['dept_name', 'budget']]"
determine the name of the instructor who is in the statistics department and whose salary is the lowest.,instructor.loc[lambda x: x['dept_name']=='statistics'].sort_values('salary').iloc[0]['name']
retrieve the name of the instructor who earns the lowest salary in the statistics department.,instructor.loc[lambda x: x['dept_name']=='statistics'].sort_values('salary').iloc[0]['name']
determine the course title that is offered by both statistics and psychology departments.,"pd.merge(course.query(""dept_name == 'statistics'""),course.query(""dept_name == 'psychology'""),on='title')['title']"
please give me the titles of courses provided by statistics but not psychology departments.,"course.loc[lambda x: x['dept_name']=='statistics', 'title'].drop_duplicates().reset_index(drop=true).append(course.loc[lambda x: x['dept_name']=='psychology', 'title']).drop_duplicates(keep=false).reset_index(drop=true)"
determine the id of instructors who taught a class in fall 2009 but not in spring 2010.,"teaches.loc[(teaches['semester']=='fall') & (teaches['year']==2009), 'id'].drop(teaches.loc[(teaches['semester']=='spring') & (teaches['year']==2010), 'id']).reset_index(drop=true)"
find the names of students who took at least one class in the years of 2009 and 2010.,"pd.merge(student, takes, on='id').loc[lambda x: x['year'].isin([2009, 2010]), 'name'].unique()"
what are the names of those students who took classes in 2009 or 2010?,"pd.merge(student, takes, on='id').loc[lambda x: x['year'].isin([2009, 2010]), 'name'].unique()"
retrieve the names of the departments that have provided the highest number of courses.,course.groupby('dept_name').size().sort_values(ascending=false).head(3).reset_index()['dept_name']
which three departments have the largest number of courses?,course.groupby('dept_name').size().sort_values(ascending=false).head(3).reset_index()['dept_name']
obtain the title of department that offers the best sum of credits.,"course.groupby('dept_name').sum().sort_values('credits', ascending=false).reset_index().loc[0, 'dept_name']"
retrieve the name of the department with most credits.,"course.groupby('dept_name').sum().sort_values('credits', ascending=false).reset_index().loc[0, 'dept_name']"
arrange the course titles ordered by credit size.,"course.sort_values(['title', 'credits'])['title']"
provide me with the titles of all subjects ordered by their titles and their credits.,"course.sort_values(['title', 'credits'])['title']"
which department's budget is the lowest?,department.sort_values('budget').iloc[0]['dept_name']
name:              budget:,department.sort_values('budget').iloc[0]['dept_name']
"provide the department names along with the buildings in which they are located, sorted in order of largest to smallest budget.","department[['dept_name', 'building']].sort_values('budget', ascending=false)"
"provide me the names and buildings of the departments, sorted in descending order of budget.","department[['dept_name', 'building']].sort_values('budget', ascending=false)"
which instructor has the highest salary?,"instructor.sort_values('salary', ascending=false).iloc[0]['name']"
fetch the title of the individual who has the highest compensation.,"instructor.sort_values('salary', ascending=false).iloc[0]['name']"
provide me the details of all the professors ordered based on their compensation ranking.,instructor.sort_values('salary')
"provide all information about instructors, in descending salary order.",instructor.sort_values('salary')
retrieve the names of the students and their department names sorted in descending order by their total credits.,"student[['name', 'dept_name']].sort_values('tot_cred')"
"return the names and ids of students and their respective departments, sorted in descending order by credit count.","student[['name', 'dept_name']].sort_values('tot_cred')"
rearrange the list in alphabetical order of names of courses and their instructors in the year 2008.,"pd.merge(pd.merge(course, teaches, on='course_id'), instructor, on='id').loc[lambda x: x['year']==2008].sort_values('title')[['title', 'name']]"
list the courses and their instructors in 2008 in an alphabetical order by course title.,"pd.merge(pd.merge(course, teaches, on='course_id'), instructor, on='id').loc[lambda x: x['year']==2008].sort_values('title')[['title', 'name']]"
retrieve the ids of teachers that are advising more than one student.,"pd.merge(instructor, advisor, left_on='id', right_on='i_id').groupby('i_id').filter(lambda x: len(x) > 1)['name']"
what are the names of the instructors who advise more than one student?,"pd.merge(instructor, advisor, left_on='id', right_on='i_id').groupby('i_id').filter(lambda x: len(x) > 1)['name']"
retrieve the names of those students who are assigned more than one advisor.,"student.merge(advisor, left_on='id', right_on='s_id').groupby('s_id').filter(lambda x: len(x) > 1)['name']"
which students have more than one advisor?,"student.merge(advisor, left_on='id', right_on='s_id').groupby('s_id').filter(lambda x: len(x) > 1)['name']"
please find the number of rooms in each building that can store more than 50 people.,classroom.loc[classroom['capacity'] > 50].groupby('building').size().reset_index(name='count(*)')
how many rooms in each building have more than 50 people capacity?,classroom.loc[classroom['capacity'] > 50].groupby('building').size().reset_index(name='count(*)')
determine the maximum and the average capacity among rooms in each building.,"classroom.groupby('building')['capacity'].agg(['max', 'mean'])"
what are the maximum and average sizes of each building's rooms?,"classroom.groupby('building')['capacity'].agg(['max', 'mean'])"
retrieve the title of a course that is utilized or offered by more than one department.,course.groupby('title').filter(lambda x: len(x) > 1)['title'].unique()
which course titles are offered in more than one department?,course.groupby('title').filter(lambda x: len(x) > 1)['title'].unique()
provide me with the total number of credits provided by different departments.,course.groupby('dept_name')['credits'].sum()
what were the total credits offered by each department?,course.groupby('dept_name')['credits'].sum()
determine the minimum salary of departments whose average salary is above the average payment of all departments.,instructor.groupby('dept_name').filter(lambda x: x['salary'].mean() > instructor['salary'].mean()).groupby('dept_name')['salary'].min()
what is the min salary in departments where average salary is greater than the overall average salary?,instructor.groupby('dept_name').filter(lambda x: x['salary'].mean() > instructor['salary'].mean()).groupby('dept_name')['salary'].min()
fetch the count of courses provided in each semester and year.,"section.groupby(['semester', 'year']).size().reset_index(name='count(*)')"
how many courses are offered in each specified semester and year?,"section.groupby(['semester', 'year']).size().reset_index(name='count(*)')"
provide me with the year which has the maximum number of courses.,section.groupby('year').size().sort_values(ascending=false).index[0]
during which year was the largest number of courses offered?,section.groupby('year').size().sort_values(ascending=false).index[0]
during what semester/year offered the largest number of courses?,"section.groupby(['semester', 'year']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['semester', 'year']]"
during the year and semester when were the most courses taught?,"section.groupby(['semester', 'year']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['semester', 'year']]"
retrieve the department that holds the maximum number of students.,student.groupby('dept_name').size().sort_values(ascending=false).index[0]
what is the title for the department that has the highest enrollment?,student.groupby('dept_name').size().sort_values(ascending=false).index[0]
provide me with the count of students in each and every department.,student.groupby('dept_name').size().reset_index(name='count(*)')
what are the total counts of students registered in each department?,student.groupby('dept_name').size().reset_index(name='count(*)')
retrieve the year and semester in which the fewest students are registered for any class.,"takes.groupby(['semester', 'year']).size().sort_values().head(1).reset_index()[['semester', 'year']]"
what is the id of the instructor who advises all students from history department?,"pd.merge(advisor, student, left_on='s_id', right_on='id').loc[lambda x: x['dept_name']=='history', 'i_id']"
fetch the id of an instructor who offers guidance to students in the history department.,"pd.merge(advisor, student, left_on='s_id', right_on='id').loc[lambda x: x['dept_name']=='history', 'i_id']"
fetch the name and salary of the instructors who are advisors of any student from the history department.,"pd.merge(pd.merge(advisor, instructor, left_on='i_id', right_on='id'), student, left_on='s_id', right_on='id').loc[lambda x: x['dept_name']=='history', ['name', 'salary']]"
retrieve the names and salaries of instructors that advise students in the history department.,"pd.merge(pd.merge(advisor, instructor, left_on='i_id', right_on='id'), student, left_on='s_id', right_on='id').loc[lambda x: x['dept_name']=='history', ['name', 'salary']]"
retrieve the ids for courses that have no prerequisites.,course[~course['course_id'].isin(prereq['course_id'])]['course_id']
which course codes do not have a prerequisite for taking the course?,course[~course['course_id'].isin(prereq['course_id'])]['course_id']
could you provide me with a list of all the courses which don't have a prerequisite?,"course.loc[~course['course_id'].isin(prereq['course_id']), 'title']"
which courses do not have prerequisite courses?,"course.loc[~course['course_id'].isin(prereq['course_id']), 'title']"
what is the name of the prerequisite class of international finance course?,"course.loc[lambda x: x['course_id'].isin(prereq.merge(course, on='course_id').loc[lambda x: x['title']=='international finance', 'prereq_id']), 'title']"
what are the titles of the preparatory courses for the study of international finance?,"course.loc[lambda x: x['course_id'].isin(prereq.merge(course, on='course_id').loc[lambda x: x['title']=='international finance', 'prereq_id']), 'title']"
retrieve the name of the course whose prerequisite is differential geometry.,"course.loc[lambda x: x['course_id'].isin(prereq.merge(course, left_on='prereq_id', right_on='course_id').loc[lambda x: x['title']=='differential geometry', 'course_id']), 'title']"
what is the course title that is a prerequisite for differential geometry?,"course.loc[lambda x: x['course_id'].isin(prereq.merge(course, left_on='prereq_id', right_on='course_id').loc[lambda x: x['title']=='differential geometry', 'course_id']), 'title']"
find the names of students who have taken a course in the fall term of year 2003.,"student.loc[student['id'].isin(takes.loc[(takes['semester']=='fall')&(takes['year']==2003), 'id']), 'name']"
retrieve the names of students who took courses in the fall of 2003.,"student.loc[student['id'].isin(takes.loc[(takes['semester']=='fall')&(takes['year']==2003), 'id']), 'name']"
determine the title of the course that was offered at building chandler during the fall of the year 2010.,"course.merge(section.query(""building=='chandler' and semester=='fall' and year==2010""), on='course_id')['title']"
please provide me with the title of course offered in chandler during the fall 2010.,"course.merge(section.query(""building=='chandler' and semester=='fall' and year==2010""), on='course_id')['title']"
retrieve the names of the instructors who taught c programming course before.,"pd.merge(pd.merge(instructor, teaches, on='id'), course, on='course_id').loc[lambda x: x['title']=='c programming', 'name']"
obtain the names of instructors that have a c programming course.,"pd.merge(pd.merge(instructor, teaches, on='id'), course, on='course_id').loc[lambda x: x['title']=='c programming', 'name']"
provide me with the title and salary of the instructors who are advisors of the students from the math department.,"pd.merge(pd.merge(advisor, instructor, left_on='i_id', right_on='id'), student, left_on='s_id', right_on='id').loc[lambda x: x['dept_name']=='math', ['name', 'salary']]"
retrieve the ids and salaries of instructors who advise students in the math department.,"pd.merge(pd.merge(advisor, instructor, left_on='i_id', right_on='id'), student, left_on='s_id', right_on='id').loc[lambda x: x['dept_name']=='math', ['name', 'salary']]"
retrieve the instructors (advisors) who are math department students and order them by their students' total credits.,"pd.merge(pd.merge(advisor, instructor, left_on='i_id', right_on='id'), student, left_on='s_id', right_on='id').loc[lambda x: x['dept_name']=='math'].sort_values('tot_cred')['name_y']"
obtain the names of all instructors who advise students in the math department sorted in descending order by credits of the student.,"pd.merge(pd.merge(advisor, instructor, left_on='i_id', right_on='id'), student, left_on='s_id', right_on='id').loc[lambda x: x['dept_name']=='math'].sort_values('tot_cred')['name_y']"
what is the course title of a prerequisite of the course mobile computing?,"course.loc[course['course_id'].isin(prereq.merge(course, on='course_id').loc[lambda x: x['title']=='mobile computing', 'prereq_id']), 'title']"
identify the title of the course that is a prerequisite for the mobile computing class.,"course.loc[course['course_id'].isin(prereq.merge(course, on='course_id').loc[lambda x: x['title']=='mobile computing', 'prereq_id']), 'title']"
retrieve the name of the instructor who is the master of the student who has the most credits in total.,"pd.merge(pd.merge(advisor, instructor, left_on='i_id', right_on='id'), student, left_on='s_id', right_on='id').sort_values('tot_cred', ascending=false).iloc[0]['name']"
provide me with the name and department number of the instructor whose advisee had the most total credits.,"pd.merge(pd.merge(advisor, instructor, left_on='i_id', right_on='id'), student, left_on='s_id', right_on='id').sort_values('tot_cred', ascending=false).iloc[0]['name']"
retrieve the names of instructors who did not teach any courses.,"instructor.loc[~instructor['id'].isin(teaches['id']), 'name']"
retrieve the titles of instructors who haven't instructed.,"instructor.loc[~instructor['id'].isin(teaches['id']), 'name']"
please provide me the id of instructors who did not teach any course.,instructor[~instructor['id'].isin(teaches['id'])]['id']
retrieve the ids of instructors who did not teach classes.,instructor[~instructor['id'].isin(teaches['id'])]['id']
retrieve the titles of course instructors who did not teach in any spring semester.,"instructor.loc[~instructor['id'].isin(teaches.loc[teaches['semester']=='spring', 'id']), 'name']"
retrieve the names of teachers that did not teach courses in the spring.,"instructor.loc[~instructor['id'].isin(teaches.loc[teaches['semester']=='spring', 'id']), 'name']"
which department has a relatively high average instructor salary?,instructor.groupby('dept_name')['salary'].mean().sort_values(ascending=false).index[0]
determine the number of salary averages of all instructors who are in the department with the highest budget.,"pd.merge(instructor, department, on='dept_name').groupby('dept_name').agg(avg_salary=('salary', 'mean'), count=('dept_name', 'size')).sort_values('budget', ascending=false).iloc[:1]"
how many instructors are hired by the department with the highest budget? what is their average annual salary?,"pd.merge(instructor, department, on='dept_name').groupby('dept_name').agg(avg_salary=('salary', 'mean'), count=('dept_name', 'size')).sort_values('budget', ascending=false).iloc[:1]"
which course was taught most often in the largest classroom (with the greatest capacity)?,"classroom.merge(section, on=['building', 'room_number']).merge(course, on='course_id').loc[lambda x: x['capacity'] == classroom['capacity'].max(), ['title', 'credits']]"
provide me with the course title taught and the credits for the course taught in the classroom with the greatest capacity.,"classroom.merge(section, on=['building', 'room_number']).merge(course, on='course_id').loc[lambda x: x['capacity'] == classroom['capacity'].max(), ['title', 'credits']]"
retrieve the names belonging to students who did not take any course from biology department.,"student[~student['id'].isin(takes.merge(course.query(""dept_name == 'biology'""), on='course_id')['id'])]['name']"
retrieve the titles of those students who haven't taken biology courses.,"student[~student['id'].isin(takes.merge(course.query(""dept_name == 'biology'""), on='course_id')['id'])]['name']"
provide me with the number of students and the number of instructors for each department.,"pd.merge(pd.merge(student, department, on='dept_name'), instructor, on='dept_name').groupby('dept_name').agg({'id_x':'nunique', 'id_y':'nunique', 'dept_name':'first'}).rename(columns={'id_x':'students_count', 'id_y':'instructors_count', 'dept_name':'dept_name'})[['students_count', 'instructors_count', 'dept_name']]"
"retrieve the titles of students who are taking the course ""international finance"" and have taken the prerequisite course.","pd.merge(student, takes, on='id').loc[lambda x: x['course_id'].isin(pd.merge(course.loc[lambda x: x['title']=='international finance'], prereq, on='course_id')['prereq_id']), 'name']"
obtain the names of students who have already completed the prerequisite course international finance.,"pd.merge(student, takes, on='id').loc[lambda x: x['course_id'].isin(pd.merge(course.loc[lambda x: x['title']=='international finance'], prereq, on='course_id')['prereq_id']), 'name']"
obtain the authors' names and salarys that are lower than the average salary of instructors in the physics department.,"instructor.loc[lambda x: x['salary'] < instructor.loc[lambda x: x['dept_name']=='physics', 'salary'].mean(), ['name', 'salary']]"
what are the names and salaries of the instructors who earn less than the average salary in the physics department?,"instructor.loc[lambda x: x['salary'] < instructor.loc[lambda x: x['dept_name']=='physics', 'salary'].mean(), ['name', 'salary']]"
determine the names of students who have taken a course offered by statistics department.,"pd.merge(pd.merge(course, takes, on='course_id'), student, on='id').loc[lambda x: x['dept_name']=='statistics', 'name']"
which students have taken the statistics course?,"pd.merge(pd.merge(course, takes, on='course_id'), student, on='id').loc[lambda x: x['dept_name']=='statistics', 'name']"
"give all courses, building, room number, semester and year offered by the psychology department sorted by course titles.","pd.merge(course.loc[lambda x: x['dept_name']=='psychology'], section, on='course_id').sort_values('title')[['building', 'room_number', 'semester', 'year']]"
"list the courses in the psychology department, sorted by course title, using building, room number, semester, and year.","pd.merge(course.loc[lambda x: x['dept_name']=='psychology'], section, on='course_id').sort_values('title')[['building', 'room_number', 'semester', 'year']]"
list down names of all teachers in computer science department,"instructor.loc[lambda x: x['dept_name']=='comp. sci.', 'name']"
search the title of all instructors in the computer science department.,"instructor.loc[lambda x: x['dept_name']=='comp. sci.', 'name']"
"find the names of all professors in comp. sci. department who have salaries exceeding $80,000.","instructor.loc[(instructor['dept_name']=='comp. sci.') & (instructor['salary']>80000), 'name']"
retrieve the names of the instructors in the computer science department earning more than 80k.,"instructor.loc[(instructor['dept_name']=='comp. sci.') & (instructor['salary']>80000), 'name']"
get all the names of instructors who taught some course and the course_id.,"pd.merge(instructor, teaches, on='id')[['name', 'course_id']]"
"how many instructors taught courses, and which are the corresponding course ids for each instructor?","pd.merge(instructor, teaches, on='id')[['name', 'course_id']]"
find the names of all professors in the art department who have taught at least one course and the course id of that course.,"pd.merge(instructor, teaches, on='id').loc[lambda x: x['dept_name']=='art', ['name', 'course_id']]"
"retrieve the names of art instructors who have taught a course, along with their course id.","pd.merge(instructor, teaches, on='id').loc[lambda x: x['dept_name']=='art', ['name', 'course_id']]"
list the names of all the instructors whose last name includes the substring “dar”.,"instructor.loc[instructor['name'].str.contains('dar'), 'name']"
"give me the names of all instructors that have names containing ""dar"".","instructor.loc[instructor['name'].str.contains('dar'), 'name']"
return the titles of all distinguishable instructors in alphabetic order.,instructor['name'].sort_values().unique()
"provide the complete list of instructors, ordered alphabetically by name.",instructor['name'].sort_values().unique()
find courses that ran in fall 2009 or in spring 2010.,"pd.concat([section.query(""semester=='fall' and year==2009"")['course_id'], section.query(""semester=='spring' and year==2010"")['course_id']]).unique()"
provide the ids for courses that were offered in the school year 2009-2010.,"pd.concat([section.query(""semester=='fall' and year==2009"")['course_id'], section.query(""semester=='spring' and year==2010"")['course_id']]).unique()"
provide me with the names of courses offered in fall of 2009 and spring of 2010.,"pd.merge(section.query(""semester=='fall' and year==2009"")['course_id'], section.query(""semester=='spring' and year==2010"")['course_id'], how='inner')"
what are the ids for courses that were offered during the fall and spring semesters of 2009 and 2010?,"pd.merge(section.query(""semester=='fall' and year==2009"")['course_id'], section.query(""semester=='spring' and year==2010"")['course_id'], how='inner')"
find courses that were run during the fall 2009 term but were not run during the spring 2010 semester.,"section.loc[(section['semester']=='fall')&(section['year']==2009), 'course_id'].drop(section.loc[(section['semester']=='spring')&(section['year']==2010), 'course_id'].index).unique()"
what is the count of courses that were offered in the fall of 2009 but not in the spring of 2010?,"section.loc[(section['semester']=='fall')&(section['year']==2009), 'course_id'].drop(section.loc[(section['semester']=='spring')&(section['year']==2010), 'course_id'].index).unique()"
provide me the salaries of all distinct instructors that are lesser than the largest salary.,"instructor.loc[lambda x: x['salary'] < instructor['salary'].max(), 'salary'].unique()"
provide me with the count of instructors who taught a course during the spring 2010 semester.,"teaches.loc[(teaches['semester']=='spring') & (teaches['year']==2010), 'id'].nunique()"
what is the count of instructors who teach a course in the spring semester of 2010?,"teaches.loc[(teaches['semester']=='spring') & (teaches['year']==2010), 'id'].nunique()"
retrieve the names of the departments whose average salary is greater than 42000.,instructor.groupby('dept_name').filter(lambda x: x['salary'].mean() > 42000).groupby('dept_name')['salary'].mean()
provide me with the names and salaries of departments whose average salary is higher than 42000.,instructor.groupby('dept_name').filter(lambda x: x['salary'].mean() > 42000).groupby('dept_name')['salary'].mean()
retrieve the names of instructors whose salary exceeds the salary of some (at least one) instructor in the biology department.,"instructor.loc[lambda x: x['salary'] > instructor.loc[lambda y: y['dept_name']=='biology', 'salary'].min(), 'name']"
identify the names of instructors who earn more than at least one instructor from the biology department.,"instructor.loc[lambda x: x['salary'] > instructor.loc[lambda y: y['dept_name']=='biology', 'salary'].min(), 'name']"
list the names of all instructors whose salaries are larger than the salaries of all instructors in the biology department.,"instructor.loc[lambda x: x['salary'] > instructor.loc[instructor['dept_name'] == 'biology', 'salary'].max(), 'name']"
list the names of all instructors who earn a higher salary than any of the instructors at the biology department.,"instructor.loc[lambda x: x['salary'] > instructor.loc[instructor['dept_name'] == 'biology', 'salary'].max(), 'name']"
what is the total count of debates?,debate.shape[0]
sort the venues of debates in ascending order of the number of viewers.,debate.sort_values('num_of_audience')['venue']
give me the date and venue of each debate.,"debate[['date', 'venue']]"
provide me with the list of dates of debates along with the count of audiences bigger than 150.,"debate.loc[lambda x: x['num_of_audience'] > 150, 'date']"
list the names for people aged either 35 or 36.,"people.loc[lambda x: x['age'].isin([35, 36]), 'name']"
provide me the names of different parties of people along with the number of members in each party.,people.groupby('party').size()
display the party which has the maximum people.,people.groupby('party').size().sort_values(ascending=false).index[0]
display the names of distinct venues of debates.,debate['venue'].unique()
"please return names of affirmative debaters, dates, and venues.","pd.merge(pd.merge(debate_people, debate, on='debate_id'), people, left_on='affirmative', right_on='people_id')[['name', 'date', 'venue']]"
"retrieve the names of people, and dates and venues of debates they are on the negative side, ordered in ascending alphabetical order of name.","pd.merge(pd.merge(debate_people, debate, on='debate_id'), people, left_on='negative', right_on='people_id').sort_values('name')[['name', 'date', 'venue']]"
list the names of people on the affirmative side of debates with the total count of audience larger than 200.,"pd.merge(pd.merge(debate_people, debate, on='debate_id'), people, left_on='affirmative', right_on='people_id').loc[lambda x: x['num_of_audience'] > 200, 'name']"
list the affirmative speakers appearing in the debates along with the count.,"debate_people.merge(people, left_on='affirmative', right_on='people_id').groupby('name').size().reset_index(name='count')"
list the names of people who have taken part in more than one debate.,"pd.merge(debate_people, people, left_on='negative', right_on='people_id').groupby('name').filter(lambda x: len(x) >= 2)['name'].unique()"
provide the names of individuals who have not spoken on the positive side of debates.,"people.loc[~people['people_id'].isin(debate_people['affirmative']), 'name']"
retrieve the names of all clients in alphabetical order.,customers['customer_details'].sort_values()
sort the customer names alphabetically.,customers['customer_details'].sort_values()
"retrieve the list of policy type codes that is associated with the customer ""dayana robel"".","policies.merge(customers, on='customer_id').loc[lambda x: x['customer_details']=='dayana robel', 'policy_type_code']"
"how many policies did ""dayana robel"" purchase?","policies.merge(customers, on='customer_id').loc[lambda x: x['customer_details']=='dayana robel', 'policy_type_code']"
which policy type was utilized most? what is the policy type code?,policies.groupby('policy_type_code').size().sort_values(ascending=false).index[0]
provide the most frequently utilized policy type code.,policies.groupby('policy_type_code').size().sort_values(ascending=false).index[0]
list out the policy types that are followed by more than 2 customers.,policies.groupby('policy_type_code').filter(lambda x: len(x) > 2)['policy_type_code'].unique()
retrieve the names of policy types that were chosen by more than 2 customers.,policies.groupby('policy_type_code').filter(lambda x: len(x) > 2)['policy_type_code'].unique()
determine the total and regularized amount of payment made in claim headers.,"claim_headers['amount_piad'].agg(['sum', 'mean'])"
what is the total sum of amount and average amount paid in claim headers?,"claim_headers['amount_piad'].agg(['sum', 'mean'])"
obtain the sum total of amount claimed in the most recently created document.,"claim_headers.merge(claims_documents, left_on='claim_header_id', right_on='claim_id').loc[lambda x: x['created_date']==claims_documents.sort_values('created_date')['created_date'].iloc[0], 'amount_claimed'].sum()"
what is the total sum of amounts claimed in the most recently created document?,"claim_headers.merge(claims_documents, left_on='claim_header_id', right_on='claim_id').loc[lambda x: x['created_date']==claims_documents.sort_values('created_date')['created_date'].iloc[0], 'amount_claimed'].sum()"
what is the name of the customer who has made the largest claim amount in a single claim?,"claim_headers.merge(policies, on='policy_id').merge(customers, on='customer_id').loc[lambda x: x['amount_claimed']==x['amount_claimed'].max(), 'customer_details']"
please provide me with the customer details who has made the largest claim in a single claim.,"claim_headers.merge(policies, on='policy_id').merge(customers, on='customer_id').loc[lambda x: x['amount_claimed']==x['amount_claimed'].max(), 'customer_details']"
please provide me with the customer's full name who has made the least payment in one claim.,"customers.merge(policies.merge(claim_headers.query(""amount_piad==amount_piad.min()""), on='policy_id'), on='customer_id')['customer_details']"
return the customer who has submitted the smallest amount of claims in one claim.,"customers.merge(policies.merge(claim_headers.query(""amount_piad==amount_piad.min()""), on='policy_id'), on='customer_id')['customer_details']"
retrieve the names of clients who have no policies established.,"customers.loc[~customers['customer_details'].isin(pd.merge(policies, customers, on='customer_id')['customer_details'])]"
find the names of the customers who do not have insurance policies.,"customers.loc[~customers['customer_details'].isin(pd.merge(policies, customers, on='customer_id')['customer_details'])]"
describe the number of stages that are involved in claim processing.,claims_processing_stages.shape[0]
determine the count of distinct stages in claim processing.,claims_processing_stages.shape[0]
what are the names of the main claim processing stages that claims are mostly on?,"pd.merge(claims_processing, claims_processing_stages, on='claim_stage_id').groupby('claim_stage_id')['claim_status_name'].count().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['claim_status_name']"
which claim processing stage has the most claims? provide the moniker of the status name.,"pd.merge(claims_processing, claims_processing_stages, on='claim_stage_id').groupby('claim_stage_id')['claim_status_name'].count().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['claim_status_name']"
"obtain the names of customers whose names contain ""diana"".","customers.loc[customers['customer_details'].str.contains('diana'), 'customer_details']"
"provide me with the customers whose name contains the substring ""diana"".","customers.loc[customers['customer_details'].str.contains('diana'), 'customer_details']"
list the names of the customers who have the power of attorney.,"pd.merge(policies, customers, on='customer_id').loc[lambda x: x['policy_type_code']=='deputy', 'customer_details'].unique()"
what are the names of customers that have insurance policy type as deputy? give the customer details.,"pd.merge(policies, customers, on='customer_id').loc[lambda x: x['policy_type_code']=='deputy', 'customer_details'].unique()"
retrieve the titles of customers that either have a deputy policy or uniformed policy.,"pd.merge(policies[policies['policy_type_code'].isin(['deputy', 'uniform'])], customers, on='customer_id')['customer_details'].unique()"
could you provide me the names of customers and staff members?,"pd.concat([customers['customer_details'], staff['staff_details']]).reset_index(drop=true)"
"enumerate the record for each policy type, along with the organization type code and its count.",policies.groupby('policy_type_code').size()
obtain the name of the customer that has been included in the greatest number of policies.,"pd.merge(policies, customers, on='customer_id').groupby('customer_details').size().reset_index(name='counts').sort_values('counts', ascending=false).iloc[0]['customer_details']"
please list out the names of customers that have the most policies.,"pd.merge(policies, customers, on='customer_id').groupby('customer_details').size().reset_index(name='counts').sort_values('counts', ascending=false).iloc[0]['customer_details']"
"what are the descriptions of claim status ""open""?","claims_processing_stages.loc[lambda x: x['claim_status_name']=='open', 'claim_status_description']"
"obtain the description of the claim status ""open"".","claims_processing_stages.loc[lambda x: x['claim_status_name']=='open', 'claim_status_description']"
what is the total number of different claim outcome codes?,claims_processing['claim_outcome_code'].nunique()
determine the total count of distinct claim outcomes.,claims_processing['claim_outcome_code'].nunique()
which customer has the most recent policy?,"policies.merge(customers, on='customer_id').loc[lambda x: x['start_date']==policies['start_date'].max(), 'customer_details']"
retrieve the name of the customer who started his most recent policy.,"policies.merge(customers, on='customer_id').loc[lambda x: x['start_date']==policies['start_date'].max(), 'customer_details']"
characterize the total number of accounts.,accounts.shape[0]
what is the number of accounts?a:use excel or google sheets.https://en.wikipedia.org/wiki/comparison_chart,accounts.shape[0]
what is the total count of customers that have opened an account?,accounts['customer_id'].nunique()
what is the count of customers who possess an account?,accounts['customer_id'].nunique()
"provide me with the id, date opened, name, and other account details for all accounts.","accounts[['account_id', 'date_account_opened', 'account_name', 'other_account_details']]"
"provide me the id, account name and other account details for customer 'meaghan'.","pd.merge(accounts, customers, on='customer_id').loc[lambda x: x['customer_first_name']=='meaghan', ['account_id', 'date_account_opened', 'account_name', 'other_account_details']]"
"provide me with the full details of accounts for a customer with the first name of ""meaghan"". please also include the date of opening for each account.","pd.merge(accounts, customers, on='customer_id').loc[lambda x: x['customer_first_name']=='meaghan', ['account_id', 'date_account_opened', 'account_name', 'other_account_details']]"
retrieve the complete account name and account details for all accounts by the customer with the first name as 'meaghan' and last name as 'keeling'.,"pd.merge(accounts, customers.loc[(customers['customer_first_name']=='meaghan')&(customers['customer_last_name']=='keeling'), ['customer_id']], on='customer_id')[['account_name', 'other_account_details']]"
which accounts correspond to customer named meaghan keeling?,"pd.merge(accounts, customers.loc[(customers['customer_first_name']=='meaghan')&(customers['customer_last_name']=='keeling'), ['customer_id']], on='customer_id')[['account_name', 'other_account_details']]"
provide the name and last name of the customer with account name 900.,"pd.merge(accounts.loc[lambda x : x['account_name'] == '900'], customers, on='customer_id')[['customer_first_name', 'customer_last_name']]"
show me the full names of customers with account id 900.,"pd.merge(accounts.loc[lambda x : x['account_name'] == '900'], customers, on='customer_id')[['customer_first_name', 'customer_last_name']]"
what is the count of customers that do not possess accounts?,customers['customer_id'].isin(accounts['customer_id']).value_counts()[false]
provide me with the total count of customers that do not have accounts.,customers['customer_id'].isin(accounts['customer_id']).value_counts()[false]
"display all unique first names, last names, and phone numbers for all customers with accounts.","pd.merge(customers, accounts, on='customer_id')[['customer_first_name', 'customer_last_name', 'phone_number']].drop_duplicates()"
"which names, last names, and phone numbers are identical for the customers?","pd.merge(customers, accounts, on='customer_id')[['customer_first_name', 'customer_last_name', 'phone_number']].drop_duplicates()"
deliver me the customer ids of customers that don't possess an account.,customers[~customers['customer_id'].isin(accounts['customer_id'])]['customer_id']
what is the count of customer ids that do not correspond to any customer account?,customers[~customers['customer_id'].isin(accounts['customer_id'])]['customer_id']
list the number and id of each customer's accounts.,accounts.groupby('customer_id').size().reset_index(name='count(*)')
enumerate the count of accounts corresponding to each customer id.,accounts.groupby('customer_id').size().reset_index(name='count(*)')
which customer id has the largest number of accounts?,"pd.merge(accounts, customers, on='customer_id').groupby(['customer_id', 'customer_first_name', 'customer_last_name']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[:1, :3]"
please give me the id and full name of customer with the maximum number of accounts.,"pd.merge(accounts, customers, on='customer_id').groupby(['customer_id', 'customer_first_name', 'customer_last_name']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[:1, :3]"
please show me a list of all the customers and the number of accounts held by each of them.,"pd.merge(accounts, customers, on='customer_id').groupby(['customer_id', 'customer_first_name', 'customer_last_name']).size().reset_index(name='count')"
"provide me all the info about the customers, i.e. their complete names, ids, and the count of accounts.","pd.merge(accounts, customers, on='customer_id').groupby(['customer_id', 'customer_first_name', 'customer_last_name']).size().reset_index(name='count')"
provide me with the names of customers that have at least two accounts.,"accounts.merge(customers, on='customer_id').groupby(['customer_id', 'customer_first_name']).size().loc[lambda x: x>=2].reset_index().loc[:, ['customer_first_name', 'customer_id']]"
retrieve the first names and ids of customers who have at least two accounts.,"accounts.merge(customers, on='customer_id').groupby(['customer_id', 'customer_first_name']).size().loc[lambda x: x>=2].reset_index().loc[:, ['customer_first_name', 'customer_id']]"
show me the number of customers.,customers.shape[0]
calculate the total count of customers.,customers.shape[0]
what is the count of customers of each gender?,customers.groupby('gender').size()
how many transactions are there?,financial_transactions.shape[0]
determine the number of transactions,financial_transactions.shape[0]
retrieve the number of transactions associated with each account and their corresponding id.,financial_transactions.groupby('account_id').size().reset_index(name='count')
determine the count of financial transactions associated with each account id.,financial_transactions.groupby('account_id').size().reset_index(name='count')
how many transactions have the account named 337?,"pd.merge(financial_transactions, accounts, on='account_id').loc[lambda x: x['account_name']==""337""].shape[0]"
provide the number of transactions performed by the account whose number was 337.,"pd.merge(financial_transactions, accounts, on='account_id').loc[lambda x: x['account_name']==""337""].shape[0]"
"what is the total, average, minimum, and maximum transaction amount?","financial_transactions.agg({'transaction_amount': ['mean', 'min', 'max', 'sum']})"
provide me with the summary statistics for the transaction amounts for the restaurant dataset.,"financial_transactions.agg({'transaction_amount': ['mean', 'min', 'max', 'sum']})"
retrieve ids for all transactions whose monetary value is greater than the average.,"financial_transactions.loc[lambda x: x['transaction_amount'] > x['transaction_amount'].mean(), 'transaction_id']"
provide the details of payment types in terms of name and amount.,financial_transactions.groupby('transaction_type')['transaction_amount'].sum()
list out the total transaction amounts for transaction types.,financial_transactions.groupby('transaction_type')['transaction_amount'].sum()
"give me the account name, id and number of transactions for each account.","pd.merge(financial_transactions, accounts, on='account_id').groupby(['account_name', 'account_id']).size().reset_index(name='count')"
"please return the names and ids of each account, as well as the count of transactions made.","pd.merge(financial_transactions, accounts, on='account_id').groupby(['account_name', 'account_id']).size().reset_index(name='count')"
provide me with the id of the account that registered the most number of transactions.,financial_transactions.groupby('account_id').size().sort_values(ascending=false).index[0]
what is the id of account associated with the most transactions?,financial_transactions.groupby('account_id').size().sort_values(ascending=false).index[0]
please provide me with the account id and name that had at least four transactions.,"pd.merge(financial_transactions, accounts, on='account_id').groupby(['account_id', 'account_name']).filter(lambda x: len(x) >= 4).loc[:, ['account_id', 'account_name']].drop_duplicates()"
retrieve the ids and names of accounts with 4 or more transactions.,"pd.merge(financial_transactions, accounts, on='account_id').groupby(['account_id', 'account_name']).filter(lambda x: len(x) >= 4).loc[:, ['account_id', 'account_name']].drop_duplicates()"
show me all sizes of products.,products['product_size'].unique()
which product sizes are offered by yahoo?,products['product_size'].unique()
return me all product colors.,products['product_color'].unique()
what is the count of different colors of products?,products['product_color'].unique()
please list the numbers of the invoices along with the tally of the transactions for each invoice.,financial_transactions.groupby('invoice_number').size().reset_index(name='count')
please get me the count of transactions corresponding to every invoice number.,financial_transactions.groupby('invoice_number').size().reset_index(name='count')
"what is the invoice number, and invoice date for the invoice with the maximum number of transactions?","pd.merge(financial_transactions, invoices, on='invoice_number').groupby('invoice_number')[['invoice_number', 'invoice_date']].count().sort_values(ascending=false).iloc[0]"
provide me with the id and date of the invoice containing the largest number of transactions.,"pd.merge(financial_transactions, invoices, on='invoice_number').groupby('invoice_number')[['invoice_number', 'invoice_date']].count().sort_values(ascending=false).iloc[0]"
get me the total count of invoices.,len(invoices)
how many invoices are there?,len(invoices)
"provide me with the dates of invoices, order ids, and order details of each invoice.","pd.merge(invoices, orders, on='order_id')[['invoice_date', 'order_id', 'order_details']]"
"retrieve the date of invoice, order id, and order details for all invoices.","pd.merge(invoices, orders, on='order_id')[['invoice_date', 'order_id', 'order_details']]"
please provide me with a list of order ids and their corresponding number of invoices.,invoices.groupby('order_id').size().reset_index(name='count')
for which order id did there exist multiple invoices?,invoices.groupby('order_id').size().reset_index(name='count')
please provide me with the order id and order details for the order with more than two invoices.,"invoices.merge(orders, on='order_id').groupby(['order_id', 'order_details']).filter(lambda x: len(x) > 2)[['order_id', 'order_details']].drop_duplicates()"
provide me with the ids and information for orders that contain two or more invoices.,"invoices.merge(orders, on='order_id').groupby(['order_id', 'order_details']).filter(lambda x: len(x) > 2)[['order_id', 'order_details']].drop_duplicates()"
"find the customer name, id and phone number with the highest number of orders.","pd.merge(orders, customers, on='customer_id').groupby(['customer_id', 'customer_last_name', 'phone_number']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['customer_last_name', 'customer_id', 'phone_number']]"
"please provide me with the last name, id and phone number of a customer who has made the most purchases.","pd.merge(orders, customers, on='customer_id').groupby(['customer_id', 'customer_last_name', 'phone_number']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['customer_last_name', 'customer_id', 'phone_number']]"
retrieve the names of products that have never been ordered.,"products.loc[lambda x: ~x['product_name'].isin(pd.merge(products, order_items, on='product_id')['product_name'])]['product_name']"
list all product names and display the total quantity of each item ordered.,"pd.merge(order_items, products, on='product_id').groupby('product_name')['product_quantity'].sum()"
"what are the different types of products, and what is the total amount of quantity ordered for all of them?","pd.merge(order_items, products, on='product_id').groupby('product_name')['product_quantity'].sum()"
return me the ids of the orders along with the number of items in each order.,order_items.groupby('order_id').size().reset_index(name='count')
provide me with the count of order items associated with each unique order id.,order_items.groupby('order_id').size().reset_index(name='count')
provide the product ids and the number of times each product was included in orders.,order_items.groupby('product_id')['order_id'].nunique()
what is the number of distinct ids for orders that are linked with each product?,order_items.groupby('product_id')['order_id'].nunique()
provide me with the names and number of customers having at least a single order on each product.,"order_items.merge(products, on='product_id').merge(orders, on='order_id').groupby('product_name').size().reset_index(name='count')"
what is the title and number of the different products that have been ordered by the customers?,"order_items.merge(products, on='product_id').merge(orders, on='order_id').groupby('product_name').size().reset_index(name='count')"
"please list the order id, and the number of products in each order id.",order_items.groupby('order_id')['product_id'].nunique().reset_index(name='count')
what is the count of products that correspond to each order id?,order_items.groupby('order_id')['product_id'].nunique().reset_index(name='count')
provide the ids and the total quantity of each order.,order_items.groupby('order_id')['product_quantity'].sum()
"please return me the order id and product quantity of all orders placed, as well as their total sum.",order_items.groupby('order_id')['product_quantity'].sum()
what is the count of products that were not included in any order?,products['product_id'].isin(order_items['product_id']).value_counts()[false]
how many product orders are there that were not placed?,products['product_id'].isin(order_items['product_id']).value_counts()[false]
how many churches were established before the year 1850?,(church['open_date'] < 1850).sum()
"provide me each church's name, open date, and organizer.","church[['name', 'open_date', 'organized_by']]"
generate a list of all churches in decreasing order of date of opening.,"church.sort_values('open_date', ascending=false)['name']"
list the years in which have at least 2 churches were opened.,church.groupby('open_date').filter(lambda x: len(x) >= 2)['open_date']
return the title and organizer of churches that were set up between 1830 and 1840.,"church.loc[lambda x: x['open_date'].between(1830, 1840), ['organized_by', 'name']]"
show the names of cities and the number of churches that opened in those regions.,church.groupby('open_date').size().reset_index(name='count')
please display the names and opening years for the top three churches that opened most recently.,"church[['name', 'open_date']].sort_values('open_date', ascending=false).head(3)"
what is the count of females that are older than 30 in our dataset?,people.loc[(people['is_male']=='f') & (people['age'] > 30)].shape[0]
sort the countries of people whose ages intersect with the given ranges.,"people.loc[people['age'] < 25, 'country'].unique() & people.loc[people['age'] > 30, 'country'].unique()"
"provide the min, max, and average age for all persons.","people['age'].agg(['min', 'max', 'mean'])"
display the names of all people whose age is smaller than the average.,"people.loc[lambda x: x['age'] < x['age'].mean(), ['name', 'country']]"
show me the wedding couples after year 2014 of which both were male or both female.,"pd.merge(pd.merge(wedding, people.rename(columns={'people_id':'male_id', 'name':'name_1'}), on='male_id'),people.rename(columns={'people_id':'female_id', 'name':'name_2'}), on='female_id').loc[lambda x: x['year']>2014,['name_1', 'name_2']]"
provide me the names and ages of all males who have not yet got married.,"people.loc[(people['is_male']=='t') & (~people['people_id'].isin(wedding['male_id'])), ['name', 'age']]"
list all church names except for those that had a wedding in the year 2015.,"church.loc[~church['church_id'].isin(wedding.loc[wedding['year']==2015, 'church_id']), 'name']"
return the names of churches that have hosted only two weddings.,"pd.merge(church, wedding, on='church_id').groupby('church_id').agg({'name': 'first', 'church_id': 'count'}).loc[lambda x: x['church_id']>=2, 'name']"
please display the names of the females in canada who have a wedding in the year 2016.,"pd.merge(wedding[wedding['year'] == 2016], people[people['is_male']=='f'][people['country']=='canada'], left_on='female_id', right_on='people_id')['name']"
how many weddings occurred in 2016?,(wedding['year'] == 2016).sum()
list out the names of churches where weddings of people who are older than 30 had taken place.,"pd.merge(pd.merge(pd.merge(wedding, people, left_on='male_id', right_on='people_id'), people, left_on='female_id', right_on='people_id'), church, on='church_id').loc[lambda x: (x['age_x']>30) | (x['age_y']>30), 'name']"
recollect the names of all countries along with the count of people from each country.,people.groupby('country').size()
how many churches had weddings in the year 2016?,"wedding.loc[lambda x: x['year']==2016, 'church_id'].nunique()"
what is the count of artists in the database?,artist.shape[0]
retrieve the number of artists.,artist.shape[0]
"list the names of artists, their age, and country of origin, ranked by when they joined.","artist[['name', 'age', 'country']].sort_values('year_join')"
"please sort from the list of artists, coming up with their names, ages, and countries, with each year you joined listed before it.","artist[['name', 'age', 'country']].sort_values('year_join')"
get the names of the distinct countries for all artists.,artist['country'].unique()
provide me the distinct countries of the artists.,artist['country'].unique()
"retrieve the names of all bands and the artists recruited by them along with their year of joining, who are not from united states.","artist.loc[lambda x: x['country']!='united states', ['name', 'year_join']]"
"what are the names and years of joining for artists that do not have the country ""united states""?","artist.loc[lambda x: x['country']!='united states', ['name', 'year_join']]"
how many artists were people above age 46 and joined after 1990?,(artist['age'] > 46 & artist['year_join'] > 1990).sum()
determine how many artists are older than 46 years of age and joined after 1990.,(artist['age'] > 46 & artist['year_join'] > 1990).sum()
please give me the average age and minimum age of all artists from united states.,"artist.loc[lambda x: x['country'] == 'united states', 'age'].agg(['mean', 'min'])"
determine the average age and average age of artists from the united states.,"artist.loc[lambda x: x['country'] == 'united states', 'age'].agg(['mean', 'min'])"
who joined latest?,"artist.sort_values('year_join', ascending=false).iloc[0]['name']"
please provide me the name of the artist with the latest join year.,"artist.sort_values('year_join', ascending=false).iloc[0]['name']"
determine the number of exhibitions that were hosted after year 2005.,(exhibition['year'] >= 2005).sum()
what is the number of exhibitions that occurred after 2005?,(exhibition['year'] >= 2005).sum()
provide me the theme and year for exhibitions with ticket prices less than 15.,"exhibition.loc[lambda x: x['ticket_price'] < 15, ['theme', 'year']]"
provide the titles and themes of all exhibitions that cost less than $15.,"exhibition.loc[lambda x: x['ticket_price'] < 15, ['theme', 'year']]"
display the names of the artists and the number of exhibitions that have been performed by each.,"exhibition.groupby('artist_id').size().rename('count').reset_index().merge(artist[['artist_id', 'name']], on='artist_id')[['name', 'count']]"
how many exhibitions did each artist have?,"exhibition.groupby('artist_id').size().rename('count').reset_index().merge(artist[['artist_id', 'name']], on='artist_id')[['name', 'count']]"
what is the name and country for the artist that has performed the highest number of public exhibitions?,"exhibition.merge(artist, on='artist_id').groupby(['artist_id', 'name', 'country']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'country']]"
"i wish to know the name, country, and number of exhibitions of the artist who had the most.","exhibition.merge(artist, on='artist_id').groupby(['artist_id', 'name', 'country']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'country']]"
provide me with the names of artists that have no exhibitions.,"artist.loc[~artist['artist_id'].isin(exhibition['artist_id']), 'name']"
retrieve the names of artists that have not been presented in any exhibitions.,"artist.loc[~artist['artist_id'].isin(exhibition['artist_id']), 'name']"
what is the name of the exhibition which has the ticket price higher than the average?,"exhibition.loc[lambda x: x['ticket_price'] > exhibition['ticket_price'].mean(), ['theme', 'name']].merge(artist, on='artist_id')"
please return the names of artists and the subject matter of exhibitions they produced that had a ticket price higher than average.,"exhibition.loc[lambda x: x['ticket_price'] > exhibition['ticket_price'].mean(), ['theme', 'name']].merge(artist, on='artist_id')"
"provide me with the average, minimum, and maximum ticket prices of exhibitions for all years before 2009.","exhibition.loc[lambda x: x['year'] < 2009, 'ticket_price'].agg(['mean', 'min', 'max'])"
"what are the average, minimum, and maximum prices for tickets that were bought for exhibitions before the year 2009?","exhibition.loc[lambda x: x['year'] < 2009, 'ticket_price'].agg(['mean', 'min', 'max'])"
return the topics and years that are associated with the exhibitions in descending order of ticket price.,"exhibition[['theme', 'year']].sort_values('ticket_price', ascending=false)"
"what are the themes and years of the exhibitions, sorted in descending order?","exhibition[['theme', 'year']].sort_values('ticket_price', ascending=false)"
find the details regarding the exhibition that was held in year 2004.,"exhibition_record.merge(exhibition.query(""year==2004""), on='exhibition_id')[['theme', 'date', 'attendance']]"
"provide me with the names of themes, dates, and attendance for exhibitions that were completed in 2004.","exhibition_record.merge(exhibition.query(""year==2004""), on='exhibition_id')[['theme', 'date', 'attendance']]"
list the names for artists that did not have an exhibition in 2004.,"artist['name'].loc[~artist['artist_id'].isin(pd.merge(exhibition.loc[exhibition['year'] == 2004], artist)['artist_id'])]"
what are the names of artists that did not have an exhibition in 2004?,"artist['name'].loc[~artist['artist_id'].isin(pd.merge(exhibition.loc[exhibition['year'] == 2004], artist)['artist_id'])]"
list all the exhibitions that have a record of attendance below 100 and above 500.,exhibition_record.merge(exhibition).query('attendance < 100')['theme'].interesect(exhibition_record.merge(exhibition).query('attendance > 500')['theme'])
how many exhibitions had attendance more than a hundred or a ticket price lower than ten?,"pd.merge(exhibition_record, exhibition, on='exhibition_id').loc[lambda x: (x['attendance'] > 100) | (x['ticket_price'] < 10), :].shape[0]"
how many exhibitions had an attendance of more than 100 or ticket prices under 10?,"pd.merge(exhibition_record, exhibition, on='exhibition_id').loc[lambda x: (x['attendance'] > 100) | (x['ticket_price'] < 10), :].shape[0]"
provide a list of artists with an average attendance of over 200.,"pd.merge(pd.merge(exhibition_record, exhibition, on='exhibition_id'), artist, on='artist_id').groupby('artist_id').filter(lambda x: x['attendance'].mean() > 200)['name'].unique()"
list the names of artists whose exhibitions draw over 200 attendees on average.,"pd.merge(pd.merge(exhibition_record, exhibition, on='exhibition_id'), artist, on='artist_id').groupby('artist_id').filter(lambda x: x['attendance'].mean() > 200)['name'].unique()"
"find the id of the item whose title is ""orange""?","item.loc[lambda x: x['title']=='orange', 'i_id']"
return all item details.,item
count the number of reviews.,review.shape[0]
please provide me with the user count.,useracct.shape[0]
provide me with the ratings of all items and the averaged rating.,"review['rating'].agg(['mean', 'max'])"
find out the highest value of all ratings.,review['rank'].min()
how many different users exist who contributed reviews?,review['u_id'].nunique()
how many items were reviewed by each user?,review['i_id'].nunique()
determine the number of products that were never reviewed by others.,len(item[~item['i_id'].isin(review['i_id'])])
retrieve the titles of users that did not leave any review for any item.,useracct[~useracct['u_id'].isin(review['u_id'])]['name']
retrieve the names of the products that receive a rating of 10.,"pd.merge(item, review, on='i_id').loc[lambda x: x['rating']==10, 'title']"
retrieve the titles of goods whose rating is higher than that of all other goods.,"item.loc[lambda x: x['i_id'].isin(review.loc[lambda x: x['rating'] > review['rating'].mean(), 'i_id']), 'title']"
locate the titles of items that received any rating from 1 to 4.,"item.merge(review, on='i_id').loc[lambda x: x['rating'] < 5, 'title']"
retrieve the titles of all products that received both a rating higher than 8 and a rating below 5.,"pd.merge(review.loc[lambda x: x['rating'] > 8], item, on='i_id')['title'].intersect(pd.merge(review.loc[lambda x: x['rating'] < 5], item, on='i_id')['title'])"
retrieve the names of items whose average rating is higher than 5 and their rank is greater than 3.,"pd.merge(item, review.loc[lambda x: x['rank']>3], on=""i_id"").groupby('i_id')['rating'].mean().loc[lambda x: x>5].index.intersection(pd.merge(item, review.loc[lambda x: x['rank']>3], on=""i_id"")['title'])"
find the item with the lowest average rating.,"pd.merge(item, review, on='i_id').groupby('i_id')['rating'].mean().sort_values().index[0]"
sort in the list titles of all items in alphabetic order.,item.sort_values('title')['title']
retrieve the name of the user who publishes the most reviews.,"pd.merge(useracct, review, on='u_id').groupby('u_id')['name'].count().reset_index().sort_values(0, ascending=false).iloc[0]['name']"
provide the title of item with the highest average rating.,"pd.merge(item, review, on='i_id').groupby('i_id').agg({'title': 'first', 'rating': 'mean'}).reset_index().sort_values('rating', ascending=false).iloc[0][['title', 'i_id']]"
provide the name and id of the good having the highest average rank.,"(pd.merge(item, review, on='i_id').groupby('i_id').agg({'title': 'first', 'rank': 'mean'}).reset_index().sort_values('rank', ascending=false).iloc[0][['title', 'i_id']])"
"for each user, return its name and the averaged review rating.","useracct.merge(review, on='u_id').groupby('name')['rating'].mean()"
determine the titles and number of reviews written by each user.,"review.groupby('u_id').size().reset_index(name='count').merge(useracct[['u_id', 'name']], on='u_id')['name', 'count']"
retrieve the titles of the users who received the highest number of ratings.,"useracct.merge(review, on='u_id').sort_values('rating', ascending=false).iloc[0]['name']"
send me the name of the source user with the maximum average trust score.,"useracct.merge(trust, left_on='u_id', right_on='source_u_id').groupby('source_u_id').mean().sort_values('trust', ascending=false).iloc[[0]]['name']"
retrieve the names of every target user and their respective average trust score for each target user.,"pd.merge(useracct, trust, left_on='u_id', right_on='target_u_id').groupby('target_u_id')['name', 'trust'].mean()"
identify the name of the target user with the lowest trust score.,useracct.loc[useracct['u_id'].isin(trust['target_u_id'])].sort_values('trust').iloc[0]['name']
retrieve the names of the items that did not receive any review.,item[~item['i_id'].isin(review['i_id'])]['title']
retrieve the names of users that did not provide reviews for any product.,useracct[~useracct['u_id'].isin(review['u_id'])]['name']
retrieve the number of users who did not write any review.,useracct[~useracct['u_id'].isin(review['u_id'])].shape[0]
retrieve the count of items that do not have any reviews.,len(item[~item['i_id'].isin(review['i_id'])])
number of players,player.shape[0] or len(player)
provide me the list of players sorted according to the number of votes they have received by profession.,player.sort_values('votes')['player_name']
what is the gender and occupation of players?,"player[['gender', 'occupation']]"
return the name and place of residence of players whose career is not researcher.,"player.loc[player['occupation'] != 'researcher', ['player_name', 'residence']]"
"list the names of players whose residence is either ""brandon"" or ""birtle"".","player.loc[player['residence'].isin(['brandon', 'birtle']), 'sponsor_name']"
what is the full names of the players that have received the most votes?,"player.sort_values('votes', ascending=false)['player_name'].iloc[0]"
create a list of occupations along with the number of players in each occupation.,player.groupby('occupation').size().reset_index(name='count')
please present the occupation of players that is most frequently encountered.,player.groupby('occupation').size().sort_values(ascending=false).index[0]
list the domiciles that have at least two residents.,player.groupby('residence').filter(lambda x: len(x) >= 2)['residence'].unique()
retrieve the names of all the players along with their coaches.,"pd.merge(pd.merge(player_coach, coach, on='coach_id'), player, on='player_id')[['player_name', 'coach_name']]"
determine the names of players coached by the top-rated coach.,"pd.merge(pd.merge(player_coach, coach, on='coach_id'), player, on='player_id').loc[lambda x: x['rank']==1, 'player_name']"
retrieve the  name and gender of players with a coach appointed after 2011.,"pd.merge(pd.merge(player_coach, coach, on='coach_id'), player, on='player_id').loc[lambda x: x['starting_year']>2011, ['player_name','gender']]"
list the names of players in descending order of their number of votes from coaches and please include the names of coaches as well.,"pd.merge(pd.merge(player_coach, coach, on='coach_id'), player, on='player_id').sort_values('votes', ascending=false)[['player_name', 'coach_name']]"
extract the isolated names of players who do not have coaches.,"player.loc[~player['player_id'].isin(player_coach['player_id']), 'player_name']"
what is the count of households that contain both a female and a male?,"set(player.loc[player['gender']=='m', 'residence']).intersection(set(player.loc[player['gender']=='f', 'residence']))"
"how many coaches does each club has? provide a list of club id, club name and the number of coaches.","coach.groupby('club_id').size().reset_index(name='count').merge(club, on='club_id')[['club_id', 'club_name', 'count']]"
what is the count of gold medals won by the club that possesses the most coaches?,"match_result.merge(coach, on='club_id').groupby('club_id')['gold'].sum().sort_values(ascending=false).nlargest(1).reset_index()"
what is the ascending order of total points of gymnasts?,"gymnast.sort_values('total_points', ascending=false)['total_points']"
i would like you to provide me with the total score of all gymnasts in order of descending total score.,"gymnast.sort_values('total_points', ascending=false)['total_points']"
determine the count of points held by gymnasts in descending order of floor exercise points.,"gymnast.sort_values('floor_exercise_points', ascending=false)['total_points']"
rank the gymnasts by their floor exercise points in descending order.,"gymnast.sort_values('floor_exercise_points', ascending=false)['total_points']"
what is the mean of horizontal bar points of all gymnasts?,gymnast['horizontal_bar_points'].mean()
provide me with the average horizontal bar points across all gymnasts.,gymnast['horizontal_bar_points'].mean()
enumerate the names of people in ascending alphabetical order.,people.sort_values('name')['name']
please return the list of people with their names sorted alphabetically.,people.sort_values('name')['name']
retrieve the names of gymnasts.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')['name']"
return the names of gymnasts.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')['name']"
what are the names for gymnasts whose hometown is not santo domingo?,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').loc[lambda x: x['hometown']!='santo domingo', 'name']"
please return the names of gymnasts who did not grow up in santo domingo.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').loc[lambda x: x['hometown']!='santo domingo', 'name']"
determine the age of the tallest person.,"people.sort_values('height', ascending=false)['age'].iloc[0]"
provide the age of the person with the greatest stature.,"people.sort_values('height', ascending=false)['age'].iloc[0]"
provide me with the name and age of the top five oldest persons.,"people.sort_values('age', ascending=false).iloc[:5]['name']"
retrieve the names of people who were born before 1940.,"people.sort_values('age', ascending=false).iloc[:5]['name']"
what is the total number of points of the youngest gymnast?,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').sort_values('age').iloc[0]['total_points']"
return the total points scored by a gymnast of the lowest age.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').sort_values('age').iloc[0]['total_points']"
what is the age for an average gymnast?,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')['age'].mean()"
what is the total average age for all the gymnasts?,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')['age'].mean()"
determine the names of gymnasts who are natives of distinct hometowns with total points above 57.5.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').loc[lambda x: x['total_points'] > 57.5, 'hometown'].unique()"
provide the hometowns gymnasts whose total point score exceeds 57.5.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').loc[lambda x: x['total_points'] > 57.5, 'hometown'].unique()"
what is the count of hometowns of gymnasts and what is the count of gymnasts?,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').groupby('hometown').size()"
what are the hometowns to which the gymnasts belong?,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').groupby('hometown').size()"
which is the most common hometown for gymnasts?,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').groupby('hometown').size().sort_values(ascending=false).index[0]"
retrieve the locality that is most frequent among gymnasts.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').groupby('hometown').size().sort_values(ascending=false).index[0]"
list out the hometowns that are shared by at least two gymnast.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').groupby('hometown').filter(lambda x: len(x) >= 2)['hometown'].unique()"
provide the cities from which more than two gymnasts are from.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').groupby('hometown').filter(lambda x: len(x) >= 2)['hometown'].unique()"
give the names in ascending order of the gymnasts based on their heights.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').sort_values('height')['name']"
"provide me the names and height of gymnasts, listed in descending order.","pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').sort_values('height')['name']"
return the ids of locations that are not related to any of the gymnasts.,"people['hometown'].unique().tolist() - pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')['hometown'].unique().tolist()"
which towns did no gymnasts come from?,"people['hometown'].unique().tolist() - pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id')['hometown'].unique().tolist()"
provide me the hometowns of people aged 23 or younger.,"pd.series(list(set(people.loc[people['age']>23, 'hometown']).intersection(set(people.loc[people['age']<20, 'hometown']))))"
which towns were from both the people older than 23 and younger than 20 from?,"pd.series(list(set(people.loc[people['age']>23, 'hometown']).intersection(set(people.loc[people['age']<20, 'hometown']))))"
determine the number of unique hometowns of these people.,people['hometown'].nunique()
display the ages of gymnasts in descending order of points.,"pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').sort_values('total_points', ascending=false)['age']"
"please list the ages in descending order of the gymnasts, based on the number of points they earned.","pd.merge(gymnast, people, left_on='gymnast_id', right_on='people_id').sort_values('total_points', ascending=false)['age']"
"obtain the total savings balance of all accounts except the one that has the name ""brown"".","pd.merge(accounts, savings, on='custid').loc[lambda x: x['name']!='brown', 'balance'].sum()"
what is the total account balance of savings accounts that are not owned by someone named brown?,"pd.merge(accounts, savings, on='custid').loc[lambda x: x['name']!='brown', 'balance'].sum()"
which accounts were utilized more than 500 times?,accounts.shape[0]
provide me with the checking balance in all accounts.,checking['balance'].sum()
calculate the total sum of the balances across checking accounts.,checking['balance'].sum()
provide me with the checked balance average.,checking['balance'].mean()
what is the mean balance of checking accounts?,checking['balance'].mean()
what is the number of accounts whose savings balance is greater than the average balance?,(savings['balance'] > savings['balance'].mean()).sum()
find the count of accounts that have a higher than average savings balance.,(savings['balance'] > savings['balance'].mean()).sum()
honor me with the name of the accounts of customers whose balance is below the checking balance maximum.,"accounts.merge(checking, on='custid').loc[lambda x: x['balance']<checking['balance'].max(), ['custid', 'name']]"
what is the account id and name of the customer with the least checking balance?,"accounts.merge(checking, on='custid').loc[lambda x: x['balance']<checking['balance'].max(), ['custid', 'name']]"
what is the checking balance of the account that ends with the substring ‘ee’?,"accounts.merge(checking, on='custid').loc[lambda x: x['name'].str.contains('ee', case=false), 'balance']"
retrieve the amount in the checking account possessed by the account holder whose name contains 'ee'.,"accounts.merge(checking, on='custid').loc[lambda x: x['name'].str.contains('ee', case=false), 'balance']"
retrieve the balance sheet and the savings balance for the account number 5265063.,"pd.merge(accounts[accounts['name']=='brown'], checking, on='custid').merge(savings, on='custid')[['balance_x', 'balance_y']]"
provide me with the amounts of check and savings balance from the accounts of brown.,"pd.merge(accounts[accounts['name']=='brown'], checking, on='custid').merge(savings, on='custid')[['balance_x', 'balance_y']]"
"retrieve the names of the accounts whose checking balance is above-average, but their savings balance is less-than-average.","pd.merge(accounts.loc[checking['balance'] > checking['balance'].mean(), 'name'], accounts.loc[savings['balance'] < savings['balance'].mean(), 'name'], on='name')"
retrieve the names of accounts with high checking balances and low savings balances.,"pd.merge(accounts.loc[checking['balance'] > checking['balance'].mean(), 'name'], accounts.loc[savings['balance'] < savings['balance'].mean(), 'name'], on='name')"
determine the account balance of accounts whose savings balance is over the average savings balance.,"accounts.merge(checking, on='custid').loc[lambda x: x['name'].isin(accounts.merge(savings, on='custid').loc[lambda y: y['balance'] > savings['balance'].mean(), 'name']), 'balance']"
find the total account balances of customers having savings balances that are higher than the average savings balance.,"accounts.merge(checking, on='custid').loc[lambda x: x['name'].isin(accounts.merge(savings, on='custid').loc[lambda y: y['balance'] > savings['balance'].mean(), 'name']), 'balance']"
arrange the names of the customers in an alphabetical order.,accounts.sort_values('name')['name']
what are the names of all the customers displayed in alphabetical order?,accounts.sort_values('name')['name']
retrieve the account with the least total checking and saving balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').assign(total_balance=lambda x: x['balance_x'] + x['balance_y']).sort_values('total_balance').iloc[0]['name']"
please provide me with the name corresponding to the highest total checking and savings balances.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').assign(total_balance=lambda x: x['balance_x'] + x['balance_y']).sort_values('total_balance').iloc[0]['name']"
provide me with the names and total checking and savings balances of the accounts with savings balances higher than that of the average savings balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').loc[lambda x: x['balance_y'] > savings['balance'].mean(), ['name', 'balance_x', 'balance_y']].assign(balance_sum=lambda x: x['balance_x']+x['balance_y']).loc[:, ['name', 'balance_sum']]"
provide me the information of the names and sum of checking and savings balances of the accounts with savings balance exceeding the average savings balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').loc[lambda x: x['balance_y'] > savings['balance'].mean(), ['name', 'balance_x', 'balance_y']].assign(balance_sum=lambda x: x['balance_x']+x['balance_y']).loc[:, ['name', 'balance_sum']]"
find the title for the account with the least savings balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').sort_values('balance').iloc[0][['name', 'balance']]"
retrieve the names of the checking accounts of the customer with the lowest savings balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').sort_values('balance').iloc[0][['name', 'balance']]"
determine the count of checking accounts for each account name.,"pd.merge(accounts, checking, on='custid').groupby('name').size().reset_index(name='count')"
identify the titles for customers with accounts and determine the count of each checking account.,"pd.merge(accounts, checking, on='custid').groupby('name').size().reset_index(name='count')"
retrieve the count of money for each account name.,"pd.merge(accounts, savings, on='custid').groupby('name')['balance_y'].sum()"
retrieve the details for customers with accounts along with total savings balances for each.,"pd.merge(accounts, savings, on='custid').groupby('name')['balance_y'].sum()"
list the accounts of persons with checking account balances below the average of checking account balances.,"accounts.merge(checking, on='custid').loc[lambda x: x['balance'] < checking['balance'].mean(), 'name']"
retrieve the names of customers with account balances that are below average.,"accounts.merge(checking, on='custid').loc[lambda x: x['balance'] < checking['balance'].mean(), 'name']"
get the checjkng balance of the account with the maximum saving balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').sort_values('balance_x', ascending=false).iloc[0]['balance_y']"
provide me with the current account balance for the customer with the maximum checking balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').sort_values('balance_x', ascending=false).iloc[0]['balance_y']"
calculate the total checking and saving balance of all accounts in ascending order.,"pd.merge(checking, savings, on='custid').assign(total_balance=lambda x: x['balance_x'] + x['balance_y']).sort_values('total_balance')['total_balance']"
"please provide me with the sum of the checking and savings balances for all customers, ordered by the total balance.","pd.merge(checking, savings, on='custid').assign(total_balance=lambda x: x['balance_x'] + x['balance_y']).sort_values('total_balance')['total_balance']"
provide me with the name of the account with the lowest balance in savings.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').sort_values('balance').iloc[0][['balance', 'name']]"
what is the name of the account that has the least funds?,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').sort_values('balance').iloc[0][['balance', 'name']]"
"return the account name, balance, and saving balance of all accounts in a bank.","pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid')[['balance_x', 'balance_y', 'name']]"
"retrieve the name, account checking, and savings balance for all customers.","pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid')[['balance_x', 'balance_y', 'name']]"
"retrieve the rows with the ids and name, checking balance and savings balance of all accounts in the bank, sorted by their total checking and savings balance in descending order.","pd.merge(checking, savings, on='custid').merge(accounts, on='custid')[['balance_x', 'balance_y', 'name']].sort_values(by=['balance_x', 'balance_y'], ascending=false)"
"provide me with the names, checking balances and total savings balances of customers, in descending order, by total savings balances.","pd.merge(checking, savings, on='custid').merge(accounts, on='custid')[['balance_x', 'balance_y', 'name']].sort_values(by=['balance_x', 'balance_y'], ascending=false)"
retrieve the title of accounts whose checking balance is higher than the corresponding saving balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').loc[lambda x: x['balance_x'] > x['balance_y'], 'name']"
examine the ids of customers who have a higher savings account balance than checking account balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').loc[lambda x: x['balance_x'] > x['balance_y'], 'name']"
find the names of accounts whose savings balance is less than their checking balance.,"pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').loc[lambda x: x['balance_x'] > x['balance_y'], ['name', 'balance_x']+['balance_y']]"
"determine the names of customers who have a difference between their checking and savings balances, along with the total of said balances.","pd.merge(pd.merge(accounts, checking, on='custid'), savings, on='custid').loc[lambda x: x['balance_x'] > x['balance_y'], ['name', 'balance_x']+['balance_y']]"
retrieve the top 3 accounts with the highest saving balance along with their corresponding names and saving balance in descending order.,"pd.merge(accounts, savings, on='custid').sort_values('balance', ascending=false)[['name', 'balance']].iloc[:3]"
give me the names of the three accounts with the maximum savings amount.,"pd.merge(accounts, savings, on='custid').sort_values('balance', ascending=false)[['name', 'balance']].iloc[:3]"
what number of mainstream browsers whose market share is at least 5 exist?,(browser['market_share'] >= 5).sum()
return the names of browsers in descending order by percentage.,"browser.sort_values('market_share', ascending=false)['name']"
"provide me with the id, name and market share of all browsers.","browser[['id', 'name', 'market_share']]"
"determine the maximum, minimum and average market share of the listed browsers.","browser['market_share'].agg(['max', 'min', 'mean'])"
what is the id and market share of the browser safari?,"browser.loc[browser['name']=='safari', ['id', 'market_share']]"
which web accelerators are not compatible with a 'broadband' connection type?,"web_client_accelerator.loc[lambda x: x['connection'] != 'broadband', ['name', 'operating_system']]"
what is the name of the browser that implemented 'cproxy' after 1998?,"pd.merge(pd.merge(browser, accelerator_compatible_browser, on='id'), web_client_accelerator, left_on='accelerator_id', right_on='id').loc[(lambda x: (x['name_x']=='cproxy') & (x['compatible_since_year']>1998))(x), 'name_x']"
i would like to have the name of web accelerators that are compatible with two or more browsers.,"pd.merge(web_client_accelerator, accelerator_compatible_browser, on='id').groupby(['id', 'name']).filter(lambda x: len(x) >= 2)[['id', 'name']].drop_duplicates()"
provide me with the browser id and name that are compatible with the largest number of web accelerators.,"pd.merge(browser, accelerator_compatible_browser, on='id').groupby(['id', 'name']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0, [0, 1]]"
determine the year in which cachebox and internet explorer became compatible.,"pd.merge(pd.merge(accelerator_compatible_browser, browser, left_on='browser_id', right_on='id'), web_client_accelerator, left_on='accelerator_id', right_on='id').loc[lambda x: (x['name_x']=='internet explorer') & (x['name_y']=='cachebox'), 'compatible_since_year']"
"what are the kinds of entities supported by web clients accelerators?a:you can use regex,(?<=\d{3})(?=[a-z])(?=\d)in java :string[] str = input.split(""(?<=\d{3})(?=[a-z])(?=\d)"");",web_client_accelerator['client'].nunique()
how many accelerators are incompatible with the browsers listed in the dataset?,web_client_accelerator[~web_client_accelerator['id'].isin(accelerator_compatible_browser['accelerator_id'])].shape[0]
what are the distinct accelerator names that are compatible with the browsers that have sector share higher than 15?,"pd.merge(pd.merge(web_client_accelerator, accelerator_compatible_browser, left_on='id', right_on='accelerator_id'), browser, left_on='browser_id', right_on='id').loc[lambda x: x['market_share']>15, 'name'].unique()"
provide the names of web browsers compatible with both 'cachebox' and 'fasterfox'.,"pd.merge(pd.merge(web_client_accelerator.loc[lambda x: x['name'] == 'cachebox'], accelerator_compatible_browser, on='accelerator_id'), browser, on='id')['name'].loc[lambda x: x.isin(pd.merge(pd.merge(web_client_accelerator.loc[lambda x: x['name'] == 'fasterfox'], accelerator_compatible_browser, on='accelerator_id'), browser, on='id')['name'])]"
"which accelerator name was found to have the string ""opera""?","web_client_accelerator.loc[web_client_accelerator['name'].str.contains('opera'), 'name']"
how many web accelerators are utilized by each os?,web_client_accelerator.groupby('operating_system').size().reset_index(name='count')
"what is the list of titles of the browser and accelerators, arranged in the descending order of their compatibility?","pd.merge(pd.merge(accelerator_compatible_browser, browser, left_on='browser_id', right_on='id'), web_client_accelerator, left_on='accelerator_id', right_on='id')[['name_x', 'name_y']].sort_values('compatible_since_year', ascending=false)"
how many wrestlers should be returned?,wrestler.shape[0]
determine the number of wrestlers.,wrestler.shape[0]
enumerate the titles of wrestlers in ascending order of their number of days held.,"wrestler.sort_values('days_held', ascending=false)['name']"
"retrieve the titles of wrestlers, ordered descending by day provided.","wrestler.sort_values('days_held', ascending=false)['name']"
please provide me with the name of the wrestler who had the shortest tenure in a team.,wrestler.sort_values('days_held').iloc[0]['name']
what is the full name of the wrestler who had the shortest number of days held?,wrestler.sort_values('days_held').iloc[0]['name']
"which wrestlers were located in some place other than tokyo, japan?","wrestler.loc[lambda x: x['location'] != 'tokyo , japan', 'reign'].unique()"
"identify the titles of wrestlers who are not located in tokyo, japan.","wrestler.loc[lambda x: x['location'] != 'tokyo , japan', 'reign'].unique()"
retrieve the names and locations of the wrestlers.,"wrestler[['name', 'location']]"
retrieve the names and locations of all wrestlers.,"wrestler[['name', 'location']]"
"what is the count of elimination moves of wrestlers belonging to the team ""team orton""?","elimination.loc[lambda x: x['team'] == 'team orton', 'elimination_move']"
please return me a list of the elimination wrestling matches of wrestlers on team orton.,"elimination.loc[lambda x: x['team'] == 'team orton', 'elimination_move']"
provide the titles and names of wrestlers and elimination moves.,"pd.merge(elimination, wrestler, on='wrestler_id')[['name', 'elimination_move']]"
provide the full name of each wrestler as well as the move by which he was eliminated.,"pd.merge(elimination, wrestler, on='wrestler_id')[['name', 'elimination_move']]"
"list the titles, surnames, and teams of wrestlers in elimination in descending order of the number of days.","pd.merge(elimination, wrestler, on='wrestler_id').sort_values('days_held', ascending=false)[['name', 'team']]"
"retrieve the names and orders of wrestlers and their elimination teams, ordered in descending order by the number of days each man was in the elimination.","pd.merge(elimination, wrestler, on='wrestler_id').sort_values('days_held', ascending=false)[['name', 'team']]"
give me the list of wrestlers with the longest number of days held.,"pd.merge(elimination, wrestler, on='wrestler_id').sort_values('days_held', ascending=false).iloc[0]['time']"
for which wrestler was the maximum number of days held for elimination?,"pd.merge(elimination, wrestler, on='wrestler_id').sort_values('days_held', ascending=false).iloc[0]['time']"
show how many wrestlers were eliminated on days when they held more than 50 days in a competition.,"pd.merge(elimination, wrestler, on='wrestler_id').loc[lambda x: x['days_held'] > 50, 'time']"
give the names of wrestlers to be eliminated when the total days held are greater than or equal to 50.,"pd.merge(elimination, wrestler, on='wrestler_id').loc[lambda x: x['days_held'] > 50, 'time']"
produce output with different team names in eliminations and the count of eliminations for each.,elimination.groupby('team').size()
obtain the count of eliminations made by each team.,elimination.groupby('team').size()
list the teams that have encountered more than 3 eliminations.,elimination.groupby('team').filter(lambda x: len(x) > 3)['team'].unique()
which teams had the most eliminations?,elimination.groupby('team').filter(lambda x: len(x) > 3)['team'].unique()
show me the reigns and time held by wrestlers.,"wrestler[['reign', 'days_held']]"
retrieve the titles and days of reign of all wrestlers.,"wrestler[['reign', 'days_held']]"
"which wrestlers have had the fewest matches held, less than 100?","wrestler.loc[wrestler['days_held'] < 100, 'name']"
list the wrestlers who have held the championship for less than 100 days.,"wrestler.loc[wrestler['days_held'] < 100, 'name']"
show the most common reigns of wrestlers.,wrestler.groupby('reign').size().sort_values(ascending=false).reset_index(name='count').iloc[0]['reign']
what are the locations that are shared by more than two wrestlers?,wrestler.groupby('location').filter(lambda x: len(x) > 2)['location'].unique()
what are the locations that are used by multiple wrestlers?,wrestler.groupby('location').filter(lambda x: len(x) > 2)['location'].unique()
identify the names of wrestlers that are not eliminated.,wrestler[~wrestler['wrestler_id'].isin(elimination['wrestler_id'])]['name']
retrieve the names of wrestlers who have never been eliminated.,wrestler[~wrestler['wrestler_id'].isin(elimination['wrestler_id'])]['name']
"give the teams of wrestlers who were both eliminated by ""orton"" and by ""benjamin"".","elimination.loc[elimination['eliminated_by']=='orton', 'team'].isin(elimination.loc[elimination['eliminated_by']=='benjamin', 'team'])"
which teams have both wrestlers eliminated by orton and wrestlers eliminated by benjamin?,"elimination.loc[elimination['eliminated_by']=='orton', 'team'].isin(elimination.loc[elimination['eliminated_by']=='benjamin', 'team'])"
what is the count of distinct teams that were eliminated?,elimination['team'].nunique()
what number of teams have had eliminated wrestlers?,elimination['team'].nunique()
"please display the times of elimination for ""punk"" or ""orton"".","elimination.loc[lambda x: x['eliminated_by'].isin(['punk', 'orton']), 'time']"
which contestants were eliminated by punk or orton?,"elimination.loc[lambda x: x['eliminated_by'].isin(['punk', 'orton']), 'time']"
how many schools were observed?,school.shape[0]
provide the count of schools.,school.shape[0]
please arrange all the names of schools in alphabetical order.,school.sort_values('school_name')['school_name']
"retrieve the name of each school, its location, and the mascot assigned to it.","school[['school_name', 'location', 'mascot']]"
"how many students are enrolled in all the schools, and how many courses are they taking on average?","school['enrollment'].agg(['sum', 'mean'])"
which mascots are utilized by schools with enrollments above the average?,"school.loc[school['enrollment'] > school['enrollment'].mean(), 'mascot']"
retrieve the name of the institute that enrolls the smallest number of students.,school.sort_values('enrollment').iloc[0]['school_name']
"what is the mean, maximum, and minimum count of students in all schools?","school['enrollment'].agg(['mean', 'max', 'min'])"
return me each of the county name along with its corresponding count of schools and total enrollment.,"school.groupby('county').agg(count=('enrollment', 'size'), sum_enrollment=('enrollment', 'sum'))"
"what is the count of donors that have endowed a school named ""glenn""?","endowment.merge(school, on='school_id').loc[lambda x: x['school_name']=='glenn', 'donator_name'].nunique()"
topple the list of all donators in descending order of the amount of endowment.,endowment.groupby('donator_name')['amount'].sum().sort_values(ascending=false)
retrieve names of schools without any endowment.,"school.loc[~school['school_id'].isin(endowment['school_id']), 'school_name']"
provide me the names of schools that have an endowment amount less than or equal to 10.,"endowment.merge(school, on='school_id').groupby('school_name').filter(lambda x: x['amount'].sum() <= 10)['school_name'].unique()"
"provide the names of donors who donated to both school ""glenn"" and ""triton.""","pd.merge(endowment.loc[endowment['school_id'].isin(school.loc[school['school_name']=='glenn', 'school_id'])], endowment.loc[endowment['school_id'].isin(school.loc[school['school_name']=='triton', 'school_id'])], on='donator_name')['donator_name']"
retrieve the title of donors whose donation value is less than 9.,"endowment.loc[lambda x: x['amount'] >= 9, 'donator_name'].drop_duplicates()"
what is the total donation amount as well as the name of the donor for the largest amount of donation?,"endowment[['amount', 'donator_name']].sort_values('amount', ascending=false).iloc[:1]"
which budgets in 2001 or earlier were $300k or greater?,budget.loc[(budget['budgeted'] > 3000) & (budget['year'] <= 2001)].shape[0]
what is the count of budgets in year 2001 or before whose budgeted amount is greater than 3000?,budget.loc[(budget['budgeted'] > 3000) & (budget['year'] <= 2001)].shape[0]
"show me the name of the school, the amount budgeted for it, along with the invested amount in that order.","pd.merge(budget.query(""year >= 2002""), school, on='school_id')[['school_name', 'budgeted', 'invested']]"
retrieve the name(s) of donor(s).,endowment['donator_name'].unique()
what is the count of budget records having a budget amount smaller of the invested amount?,(budget['budgeted'] < budget['invested']).sum()
"what is the total amount spent by school ""glenn"" in all years?","pd.merge(budget, school, on='school_id').loc[lambda x: x['school_name']=='glenn', 'budgeted'].sum()"
provide me with all the names of schools having a budget greater than 100 or a total endowment greater than 10.,"pd.merge(pd.merge(budget, school, on='school_id'), endowment, on='school_id').groupby('school_name').agg(total_budget=('budgeted', 'sum'), total_endowment=('amount', 'sum')).loc[lambda x: (x['total_budget'] > 100) | (x['total_endowment'] > 10), :].reset_index()['school_name']"
retrieve the names of schools that have more than one donor with donation amount higher than 8.5.,"pd.merge(endowment.query('amount > 8.5'), school, on='school_id').groupby('school_id').filter(lambda x: len(x) > 1)['school_name']"
please give me the number of schools that have more than one donator whose donation amount is less than 8.5.,endowment.groupby('school_id').filter(lambda x: (x['amount'] > 8.5).sum() > 1).nunique()
"list the names of the schools, football class, and mascot of those institutions that have more than 6000 of budgeted amount or were founded before 2003.","pd.merge(school, budget, on='school_id').query('budgeted > 6000 | year < 2003')[['school_name', 'mascot', 'ihsaa_football_class']].sort_values(['total_budget_percent_invested', 'total_budget_percent_budgeted'])"
"display the name of the building, street address, and number of floors for each building ordered by the number of floors.","building[['name', 'street_address', 'floors']].sort_values('floors')"
what is the building's name that is the highest?,"building.sort_values('height_feet', ascending=false)['name'].iloc[0]"
"provide me with the average, maximum and minimum number of floors for buildings.","building['floors'].agg(['mean', 'max', 'min'])"
provide the count of buildings whose height is above the average or the number of floors above the average.,building[(building['height_feet'] > building['height_feet'].mean()) | (building['floors'] > building['floors'].mean())].shape[0]
determine the names of buildings whose height is greater than 200 feet and whose number of floors is greater than 20.,"building.loc[(building['height_feet'] >= 200) & (building['floors'] >= 20), 'name']"
"show the names of the institutions that are founded after 1990 and have the type of ""private"".","institution.loc[(institution['founded'] > 1990) & (institution['type'] == 'private'), ['institution', 'location']]"
"show institutions types, with the number of institutions and total enrollment for each type.","institution.groupby('type').agg({'type': 'count', 'enrollment': 'sum'}).rename(columns={'type': 'count'})"
what institution type hosts the highest number of institutions?,institution.groupby('type').size().sort_values(ascending=false).index[0]
provide information for two institutions founded after 1990 and an institution with at least 1000 enrollment.,"institution.loc[(institution['founded'] > 1990) & (institution['enrollment'] >= 1000), 'type']"
retrieve the names of buildings that are not owned by any institution.,"building.loc[~building['building_id'].isin(institution['building_id']), 'name']"
retrieve the titles of all buildings except those with an institution founded in 2003.,building[~building['building_id'].isin(institution[institution['founded']==2003]['building_id'])]['name']
"for each building, provide the name of the building and the number of universities in it.","institution.merge(building, on='building_id').groupby('name')['building_id'].count()"
determine the names of buildings with at least two institutions founded after 1880 along with the heights.,"building.merge(institution.loc[lambda x: x['founded'] > 1880], on='building_id').groupby(['building_id', 'name', 'height_feet']).size().reset_index(name='count').loc[lambda x: x['count'] >= 2][['name', 'height_feet']]"
gather the names and descriptions of all institution types.,institution['type'].unique()
are the names  of institutions also quoted alongside the number of proteins?,"protein.merge(institution, on='institution_id').groupby('institution')['institution'].count()"
"what is the count of proteins that are associated with institutions that were founded after 1880, or institutions classified as a private type?","pd.merge(institution, protein, on='institution_id').loc[lambda x: (x['founded'] > 1880) | (x['type'] == 'private'), :].shape[0]"
show me the protein name and the name of the institution.,"pd.merge(institution, protein, on='institution_id')[['protein_name', 'institution']]"
how many proteins are associated by a given institution with a building with at least 20 floors?,"pd.merge(pd.merge(institution, protein, on='institution_id'), building, on='building_id').loc[lambda x: x['floors']>=20].shape[0]"
how many institutions do not have any protein linked to them?,len(institution[~institution['institution_id'].isin(protein['institution_id'])])
display all the locations where no cinema has capacity over 800.,"cinema.loc[lambda x: (~x['location'].isin(cinema.loc[lambda x: x['capacity'] > 800, 'location']))]['location']"
specify the cinemas that are opened at the same location in both the year 2010 and year 2011.,"cinema.loc[cinema['openning_year'] == 2010, 'location'].unique() & cinema.loc[cinema['openning_year'] == 2011, 'location'].unique()"
what is the count of cinemas in existence?,cinema.shape[0]
provide the number of cinemas.,cinema.shape[0]
"show the name, opening date, and seating capacity for each cinema.","cinema[['name', 'openning_year', 'capacity']]"
return the names of cinemas with greater than average capacity.,"cinema.loc[cinema['capacity'] > cinema['capacity'].mean(), ['name', 'location']]"
obtain all the details of locations with cinemas.,cinema['location'].unique()
what are the distinct locations where a cinema is registered?,cinema['location'].unique()
display all the names of cinemas in the order of founding year.,"cinema[['name', 'openning_year']].sort_values('openning_year', ascending=false)"
what is the title of cinema which has the largest seating capacity?,"cinema[['name', 'location']].sort_values('capacity', ascending=false).iloc[0]"
"show the average, minimum, and maximum capacities of all the theatres opened in year 2011 or later.","cinema.loc[cinema['openning_year'] >= 2011, 'capacity'].agg(['mean', 'min', 'max'])"
display the location along with the number of cinemas at each location.,cinema.groupby('location').size()
which location saw the opening of maximum number of movie viewing centers in or after year 2010?,cinema.loc[cinema['openning_year'] >= 2010].groupby('location').size().sort_values(ascending=false).index[0]
list out all the locations where at least two cinemas have capacities over 300.,cinema.loc[cinema['capacity'] > 300].groupby('location').filter(lambda x: len(x) >= 2)['location'].unique()
which locations have two or more cinema halls with capacity exceeding 300?,cinema.loc[cinema['capacity'] > 300].groupby('location').filter(lambda x: len(x) >= 2)['location'].unique()
provide me the title and director of all films.,"film[['title', 'directed_by']]"
what movie titles were made by each director and in what year?,"film[['title', 'directed_by']]"
please show me the names of directors.,film['directed_by'].unique()
give me the names of all the directors.,film['directed_by'].unique()
provide a list of all directors along with the number of films directed by each director.,film.groupby('directed_by').size().reset_index(name='count')
determine the count of show times per dataset for each cinema.,"schedule.groupby('cinema_id').sum('show_times_per_day').reset_index().merge(cinema, on='cinema_id')[['name', 'show_times_per_day']]"
provide me with the title and maximum price of every movie.,"pd.merge(schedule, film, on='film_id').groupby('film_id').agg({'title': 'first', 'price': 'max'}).reset_index()[['title', 'price']]"
fetch the title of each film along with its corresponding value.,"pd.merge(schedule, film, on='film_id').groupby('film_id').agg({'title': 'first', 'price': 'max'}).reset_index()[['title', 'price']]"
"generate the cinema name, film title, date, and price for each record in the schedule.","pd.merge(pd.merge(schedule, film, on='film_id'), cinema, on='cinema_id')[['name', 'title', 'date', 'price']]"
retrieve the names of films and directors with no scheduled dates.,"film.loc[~film['film_id'].isin(schedule['film_id']), ['title', 'directed_by']]"
provide me with the surname of the director who has performed the most shows.,"pd.merge(schedule, film, on='film_id').groupby('directed_by').agg(show_times_per_day_sum=('show_times_per_day', 'sum')).nlargest(1, 'show_times_per_day_sum').index[0]"
retrieve the names of the locations which have more than one movie theater with capacity above 300.,cinema.loc[cinema['capacity'] > 300].groupby('location').filter(lambda x: len(x) > 1)['location'].unique()
what are the city locations which have at least two movie theaters with capacity above 300?,cinema.loc[cinema['capacity'] > 300].groupby('location').filter(lambda x: len(x) > 1)['location'].unique()
determine the number of movies that have the word 'dummy' in their titles.,film['title'].str.contains('dummy').sum()
"what is the count of movies that possess the title ""dummy""?",film['title'].str.contains('dummy').sum()
is the customers who have a coupon of amount 500 good or bad?,"customers.merge(discount_coupons).loc[lambda x: x['coupon_amount']==500, 'good_or_bad_customer']"
"please list the customer id, first name, and number of bookings made by the customer.","bookings.groupby('customer_id').size().reset_index(name='count').merge(customers[['customer_id', 'first_name']], on='customer_id')[['customer_id', 'first_name', 'count']]"
what was the max total amount of payment made by a customer? please provide me with the customer id and the amount of the payment.,"payments.groupby('customer_id')['amount_paid'].sum().reset_index().sort_values('amount_paid', ascending=false).iloc[0]"
"which booking incurred the most number of payment instances, and how many refunds were authorized?","pd.merge(bookings, payments, on='booking_id').groupby('booking_id').agg({'amount_of_refund':'first'}).reset_index().sort_values(by='booking_id', ascending=false)[:1]"
extract the id of the product that is reserved three times.,products_booked.groupby('product_id').filter(lambda x: len(x) == 3)['product_id'].unique()
what is the product name that was set against an amount equal to 102.76?,"pd.merge(products_booked.loc[lambda x: x['booked_amount']==102.76], products_for_hire, on='product_id')['product_description']"
i want to know the start date and end date of booking any product named 'book collection a'.,"pd.merge(pd.merge(products_for_hire.loc[lambda x: x['product_name']=='book collection a'], products_booked, on='product_id'), bookings, on='booking_id')[['booking_start_date', 'booking_end_date']]"
retrieve the titles of products whose availability match the value of 1.,"pd.merge(view_product_availability.loc[lambda x: x['available_yn']==1], products_for_hire, on='product_id')['product_name']"
how many different types of products are there?,products_for_hire['product_type_code'].nunique()
"provide me with the first-name, last-name, and gender for all the good customers. order them by their last name.","customers.loc[lambda x: x['good_or_bad_customer']=='good',['first_name', 'last_name', 'gender_mf']].sort_values('last_name')"
what is the total sum of all the payments?,payments['amount_due'].mean()
"retrieve the maximum, minimum, and average booked count for the products booked.","products_booked['booked_count'].agg(['max', 'min', 'mean'])"
what are the complete list of all payment types?,payments['payment_type_code'].unique()
what is the daily average cost for products that have substring 'book' in their name?,"products_for_hire.loc[products_for_hire['product_name'].str.contains('book'), 'daily_hire_cost']"
which products have never been sold with an amount exceeding 200?,"products_for_hire[~products_for_hire['product_id'].isin(products_booked.loc[lambda x: x['booked_amount']>200, 'product_id'].unique())].shape[0]"
what is the total coupon value of coupons owned by good and bad customers?,"pd.merge(discount_coupons, customers, on='coupon_id').loc[lambda x: x['good_or_bad_customer']=='good', 'coupon_amount'].to_frame().merge(pd.merge(discount_coupons, customers, on='coupon_id').loc[lambda x: x['good_or_bad_customer']=='bad', 'coupon_amount'].to_frame()).rename(columns={'coupon_amount': 'common_coupon_amount'})['common_coupon_amount'].unique()"
"what are the dates of payments made with amount paid higher than 300 or with a payment type of ""check""?","payments.loc[(payments['amount_paid'] > 300) | (payments['payment_type_code'] == 'check'), 'payment_date']"
please list the products under the cutlery category which have a daily hire price below 20. also provide their descriptions.,"products_for_hire.loc[(products_for_hire['product_type_code'] == 'cutlery') & (products_for_hire['daily_hire_cost'] < 20), ['product_name', 'product_description']]"
count the number of mobile phones.,phone.shape[0]
display the names of phones in ascending order of price.,phone.sort_values('price')['name']
"what is the list of memories, carriers, and handsets of phones?","phone[['memory_in_g', 'carrier']]"
retrieve the names of the carriers of phones with memories measuring more than 32.,"phone.loc[lambda x: x['memory_in_g'] > 32, 'carrier'].unique()"
"provide me with the listing of phones with either the carrier ""sprint"" or ""tmobile"".","phone.loc[lambda x: x['carrier'].isin(['sprint', 'tmobile']), 'name']"
for which phone do the most expensive tariffs apply?,"phone.sort_values('price', ascending=false).iloc[0]['carrier']"
display the different carriers that carry phones along with the number of phones with each carrier.,phone.groupby('carrier').size().reset_index(name='count')
retrieve the title of carriers that are mostly used for phones.,phone.groupby('carrier').size().sort_values(ascending=false).index[0]
fetch the names and districts of phones (including name of contacts on channels).,"pd.merge(pd.merge(phone_market, market, on='market_id'), phone, on='phone_id')[['name', 'district']]"
please return the names of phones and districts in ascending rank order.,"pd.merge(pd.merge(phone_market, market, on='market_id'), phone, on='phone_id').sort_values('ranking')[['name', 'district']]"
retrieve the names of phones that are available on the market with at least 50 vendors.,"pd.merge(pd.merge(phone_market, market, on='market_id'), phone, on='phone_id').loc[lambda x: x['num_of_shops']>50, 'name']"
"for each phone, list its name and total number of stock.","phone_market.merge(phone, on='phone_id').groupby('name')['num_of_stock'].sum()"
"provide me with the titles of the first 10 phones that have a total number of stocks higher than 2000, sorted in descending order.","pd.merge(phone_market, phone, on='phone_id').groupby('name').filter(lambda x: x['num_of_stock'].sum() >= 2000).groupby('name').agg('sum').sort_values('num_of_stock', ascending=false).index.tolist()"
retrieve the titles of all phones that are not present on any marketplace.,"phone.loc[~phone['phone_id'].isin(phone_market['phone_id']), 'name']"
"enumerate the company name, rank, and the total sales for all companies in descending order of their total sales.","company[['company', 'rank']].sort_values('sales_billion', ascending=false)"
provide me with the name of every company arranged in descending order by number of sales.,"company[['company', 'rank']].sort_values('sales_billion', ascending=false)"
provide the names of companies whose headquarters are not in the usa and their major industries.,"company.loc[lambda x: x['headquarters'] != 'usa', ['company', 'main_industry']]"
what is the total count of companies and industries of all companies that are headquartered outside usa?,"company.loc[lambda x: x['headquarters'] != 'usa', ['company', 'main_industry']]"
output the names of company headquarters in the descending order of market value.,"company[['company', 'headquarters']].sort_values('market_value', ascending=false)"
provide the names of the companies along with their respective headquarters and market value in descending order.,"company[['company', 'headquarters']].sort_values('market_value', ascending=false)"
"provide me with the minimum and maximum market value for all companies. also, please compute the mean market value for all of them (i.e, average market value).","company['market_value'].agg(['min', 'max', 'mean'])"
"what is the minimum, maximum, and average market value of each company?","company['market_value'].agg(['min', 'max', 'mean'])"
list the names of all industries for all companies.,company['main_industry'].unique()
what are the main industries for all companies?,company['main_industry'].unique()
list all the headquarters and the number of companies in each headquarter.,company.groupby('headquarters').size()
"for each company, which headquarter is the company's headquarters and what is the count of companies centered there?",company.groupby('headquarters').size()
obtain the titles of the main industries and the market value of each industry.,company.groupby('main_industry')['market_value'].sum()
provide a list with the top industry with the highest aggregate market value and the number of companies.,"company.groupby('main_industry').agg({'market_value': 'sum'}).nlargest(1, 'market_value')"
"for each main industry, what is the count of companies which hold the highest market value?","company.groupby('main_industry').agg({'market_value': 'sum'}).nlargest(1, 'market_value')"
list all the headquarters which comprise at least two financial companies.,company.loc[lambda x: x['main_industry']=='banking'].groupby('headquarters').filter(lambda x: len(x)>=2)['headquarters'].unique()
which cities have at least two banks?,company.loc[lambda x: x['main_industry']=='banking'].groupby('headquarters').filter(lambda x: len(x)>=2)['headquarters'].unique()
please list the cities of gas stations ordered by the year of their establishment.,"gas_station.sort_values('open_year')[['station_id', 'location', 'manager_name']]"
"what are the gas station id, location, and manager name for the gas stations ordered by opening year?","gas_station.sort_values('open_year')[['station_id', 'location', 'manager_name']]"
how many gas stations have been opened between 2000 and 2005?,((gas_station['open_year'] >= 2000) & (gas_station['open_year'] <= 2005)).sum()
provide me with the count of gas stations that opened between 2000 and 2005.,((gas_station['open_year'] >= 2000) & (gas_station['open_year'] <= 2005)).sum()
please provide the names of locations and the number of gas stations in each location ordered on the basis of count.,gas_station.groupby('location').size().sort_values()
tell me the number of gas stations that are present at each location.,gas_station.groupby('location').size().sort_values()
show headquarters of companies with both companies in the banking and oil and gas industries.,"pd.merge(company.loc[lambda x: x['main_industry']=='banking', 'headquarters'], company.loc[lambda x: x['main_industry']=='oil and gas', 'headquarters']).squeeze()"
find the offices that are the headquarters of companies that have both oil and gas and banking industries.,"pd.merge(company.loc[lambda x: x['main_industry']=='banking', 'headquarters'], company.loc[lambda x: x['main_industry']=='oil and gas', 'headquarters']).squeeze()"
please retrieve the names of headquarters of corporations that are not found in banking industry.,"company.loc[lambda x: x['main_industry'] != 'banking', 'headquarters']"
which headquarters are not possessed by companies in the banking industry?,"company.loc[lambda x: x['main_industry'] != 'banking', 'headquarters']"
list out the company name with the number of gas stations.,"pd.merge(station_company, company, on='company_id').groupby('company')['company'].count()"
"for each company id, retrieve the list of companies that they own as well as the total number of gas stations that each company owns.","pd.merge(station_company, company, on='company_id').groupby('company')['company'].count()"
list the company name and the industry of which they are not a gas station.,"company.loc[~company['company_id'].isin(station_company['company_id']), ['company', 'main_industry']]"
which industries are related to the companies that do not have gas stations and what companies relate to them?,"company.loc[~company['company_id'].isin(station_company['company_id']), ['company', 'main_industry']]"
provide the titles of gas stations that are managed by the exxonmobil company.,"pd.merge(pd.merge(station_company, company, on='company_id'), gas_station, on='station_id').loc[lambda x: x['company']=='exxonmobil', 'manager_name']"
retrieve the names of the managers for exxon gas stations.,"pd.merge(pd.merge(station_company, company, on='company_id'), gas_station, on='station_id').loc[lambda x: x['company']=='exxonmobil', 'manager_name']"
retrieve all locations of gas stations whose market value exceeds 100 for companies that are scrutinized.,"pd.merge(pd.merge(station_company, company, on='company_id'), gas_station, on='station_id').loc[lambda x: x['market_value'] > 100, 'location']"
please state the manager name that has opened the most number of gas stations after 2000.,gas_station.loc[lambda x: x['open_year'] > 2000].groupby('manager_name').size().sort_values(ascending=false).index[0]
what is the title or designation of the person that opened the maximum number of gas stations after year 2000?,gas_station.loc[lambda x: x['open_year'] > 2000].groupby('manager_name').size().sort_values(ascending=false).index[0]
please arrange all gas station locations in descending order by year of establishment.,gas_station.sort_values('open_year')['location']
provide me the location of the gas stations ordered by chronological order of opening.,gas_station.sort_values('open_year')['location']
"may i please have the rank, company names, market values of the companies in the banking industry in order of sales and profits in billion?","company.loc[lambda x: x['main_industry']=='banking', ['rank', 'company', 'market_value']].sort_values(['sales_billion', 'profits_billion'])"
"return me the rank, company name, and market value for banks in the order of sales and profits.","company.loc[lambda x: x['main_industry']=='banking', ['rank', 'company', 'market_value']].sort_values(['sales_billion', 'profits_billion'])"
give me the location and representative company names of the gas stations owned by the top 3 corporations concerning asset amounts.,"pd.merge(pd.merge(station_company, company, on='company_id'), gas_station, on='station_id').sort_values('assets_billion', ascending=false).iloc[:3][['location', 'representative_name']]"
please provide me with the location and name of the representative that is in charge of each gas station owned by the companies with the most assets.,"pd.merge(pd.merge(station_company, company, on='company_id'), gas_station, on='station_id').sort_values('assets_billion', ascending=false).iloc[:3][['location', 'representative_name']]"
enumerate the number of regions.,region.shape[0]
show all distinct region labels in the ascending order of their region names.,region.sort_values('label')['region_name'].unique()
"what toponyms are found in a region, when ordered by name?",region.sort_values('label')['region_name'].unique()
how many parties exist?,party['party_name'].nunique()
how many different parties are there?,party['party_name'].nunique()
list the names and time in office of the ministers.,"party[['minister', 'took_office', 'left_office']].sort_values('left_office')"
please list the ministers in order by when they left office.,"party[['minister', 'took_office', 'left_office']].sort_values('left_office')"
specify the minister who took office after 1961 or before 1959.,"party.loc[(party['took_office'] > 1961) | (party['took_office'] < 1959), 'minister']"
provide a list of ministers who took office after 1961 or before 1959.,"party.loc[(party['took_office'] > 1961) | (party['took_office'] < 1959), 'minister']"
list out the names of ministers who are not members of the progress party.,"party.loc[lambda x: x['party_name'] != 'progress party', 'minister']"
include the titles of the ministers who are not included in the progress party.,"party.loc[lambda x: x['party_name'] != 'progress party', 'minister']"
list out the names of ministers and parties they belong to in descending order of the time they took office.,"party[['minister', 'party_name']].sort_values('took_office', ascending=false)"
"list the ministers, along with their parties, in the descending order of times they took office.","party[['minister', 'party_name']].sort_values('took_office', ascending=false)"
please get me the name of the minister who vacated office the latest.,"party.sort_values('left_office', ascending=false).iloc[0]['minister']"
identify the minister of cabinet who officially left office the latest.,"party.sort_values('left_office', ascending=false).iloc[0]['minister']"
list the names of the members of the party along with their party name.,"pd.merge(member, party, on='party_id')[['member_name', 'party_name']]"
obtain the titles of its members along with their party affiliations.,"pd.merge(member, party, on='party_id')[['member_name', 'party_name']]"
retrieve the names of political parties along with the number of members in each.,"pd.merge(member, party, on='party_id').groupby('party_name').size()"
what are the counts for members of each party?,"pd.merge(member, party, on='party_id').groupby('party_name').size()"
what is the name of the party with the greatest number of members?,"pd.merge(member, party, on='party_id').groupby('party_name').size().sort_values(ascending=false).index[0]"
see that the party with the most members is retrieved.,"pd.merge(member, party, on='party_id').groupby('party_name').size().sort_values(ascending=false).index[0]"
list the title of all of the political parties along with their region.,"pd.merge(party, region, on='region_id')[['party_name', 'region_name']]"
retrieve the names of the parties and their corresponding regions.,"pd.merge(party, region, on='region_id')[['party_name', 'region_name']]"
present names of parties that do not have the membership.,"party.loc[~party['party_id'].isin(member['party_id']), 'party_name']"
obtain the names of the parties that have no members.,"party.loc[~party['party_id'].isin(member['party_id']), 'party_name']"
retrieve the member ids that belong to both the 3rd party and 1st party.,"pd.merge(member.loc[lambda x: x['party_id']==3, 'member_name'], member.loc[lambda x: x['party_id']==1, 'member_name'])"
which member names are shared by members of parties with the id 3 and the party with the id 1?,"pd.merge(member.loc[lambda x: x['party_id']==3, 'member_name'], member.loc[lambda x: x['party_id']==1, 'member_name'])"
provide the names of members that are not contained in the progress party.,"member.merge(party, on='party_id').query('party_name != ""progress party""')['member_name']"
what is the count of parties?,party_events.shape[0]
what is the number of parties?,party_events.shape[0]
list the names of the parties along with the number of events for each party.,"party_events.merge(party, on='party_id').groupby('party_id')['party_name'].agg(['first', 'count'])['first'].reset_index()"
what counts are listed under each party?,"party_events.merge(party, on='party_id').groupby('party_id')['party_name'].agg(['first', 'count'])['first'].reset_index()"
show the names of members who are not in charge of any event.,"member[~member['member_name'].isin(pd.merge(member, party_events, left_on='member_id', right_on='member_in_charge_id')['member_name'])]['member_name']"
what names of members are non administrators of events?,"member[~member['member_name'].isin(pd.merge(member, party_events, left_on='member_id', right_on='member_in_charge_id')['member_name'])]['member_name']"
give the names of candidates that have a minimum of two events.,"pd.merge(party_events, party, on='party_id').groupby('party_id').filter(lambda x: len(x) >= 2)['party_name']"
list the names and titles of parties that have two or more events.,"pd.merge(party_events, party, on='party_id').groupby('party_id').filter(lambda x: len(x) >= 2)['party_name']"
please provide me with the name of the member who was in charge of the greatest number of events.,"member.merge(party_events, left_on='member_id', right_on='member_in_charge_id').groupby('member_name').size().nlargest(1).index[0]"
please provide me with the title belonging to each member who has presided over the most events.,"member.merge(party_events, left_on='member_id', right_on='member_in_charge_id').groupby('member_name').size().nlargest(1).index[0]"
provide me with the count of events that have at least 2 documents.,party_events.groupby('event_name').filter(lambda x: x['event_name'].count() > 2)['event_name'].unique()
list all the annual meeting events that were organized in the uk region.,"pd.merge(pd.merge(region, party, on='region_id'), party_events, on='party_id').loc[(lambda x: x['region_name']=='united kingdom') & (lambda x: x['event_name']=='annaual meeting'), :].shape[0]"
what was the number of annual meeting events that took place in the united kingdom?,"pd.merge(pd.merge(region, party, on='region_id'), party_events, on='party_id').loc[(lambda x: x['region_name']=='united kingdom') & (lambda x: x['event_name']=='annaual meeting'), :].shape[0]"
what is the count of pilots?,pilot.shape[0]
return the names of pilots in a sorted order based on the ascending order of their ranks.,pilot.sort_values('rank')['pilot_name']
provide the names of the pilots and the positions they fill.,"pilot[['position', 'team']]"
list the distinct positions of pilots who are above 30 years of age.,"pilot.loc[lambda x: x['age'] > 30, 'position'].unique()"
"provide me with the titles of those pilots who are associated with ""bradley"" or ""fordham"".","pilot.loc[pilot['team'].isin(['bradley', 'fordham']), 'pilot_name']"
what was the year when the pilots that had been recruited in 1995 had enjoyed the rank of the highest?,pilot.sort_values('rank').iloc[0]['join_year']
what is the count of nationalities of pilots? show each nationality and the count of pilots of each nationality.,pilot.groupby('nationality').size()
what are the most common nationalities of pilots?,pilot.groupby('nationality').size().sort_values(ascending=false).index[0]
display the positions that joined the airline after year 2005 and before 2000 with both pilots.,"pilot.loc[pilot['join_year'] < 2000, 'position'].interesect(pilot.loc[pilot['join_year'] > 2005, 'position'])"
return the names of the pilots and their aircrafts.,"pd.merge(pd.merge(pilot_record, aircraft, on='aircraft_id'), pilot, on='pilot_id')[['pilot_name', 'model']]"
provide me with the name and rank of each pilot and the fleet series of the planes they have flown with in descending order of the rank of the pilot.,"pd.merge(pd.merge(pilot_record, aircraft, on='aircraft_id'), pilot, on='pilot_id').sort_values('rank')[['pilot_name', 'fleet_series']]"
return the series number of aircrafts flown by pilots younger than 34.,"pd.merge(pd.merge(pilot_record, aircraft, on='aircraft_id'), pilot, on='pilot_id').loc[lambda x: x['age']<34, 'fleet_series']"
list the names of the pilots and the number of records in their hands.,"pd.merge(pilot_record, pilot, on='pilot_id').groupby('pilot_name').size()"
list the pilots who have more than one record for air traffic control.,"pd.merge(pilot_record, pilot, on='pilot_id').groupby('pilot_name').filter(lambda x: len(x) > 1).groupby('pilot_name').size()"
retrieve the names of the pilots without any record.,"pilot.loc[~pilot['pilot_id'].isin(pilot_record['pilot_id']), 'pilot_name']"
what are the document status codes?,ref_document_status['document_status_code']
fetch the document type codes that we have.,ref_document_types['document_type_code']
retrieve the names of shipping agents.,ref_shipping_agents['shipping_agent_name']
what is the ups agency code?,"ref_shipping_agents.loc[lambda x: x['shipping_agent_name']=='ups', 'shipping_agent_code']"
list all the role codes that exist.,roles['role_code']
what is the role of ed?,"roles.loc[lambda x: x['role_code']=='ed', 'role_description']"
how many employees do we have in our department?,employees.shape[0]
who is the employee named koby?,"roles.merge(employees.loc[lambda x: x['employee_name']=='koby'], on='role_code')['role_description']"
provide a list of document ids and receipt dates of documents.,"documents[['document_id', 'receipt_date']]"
"could you list the roles along with their descriptions, id and number of members?","roles.merge(employees, on='role_code').groupby(['role_description', 'role_code']).size().reset_index(name='count')"
list all roles that have more than one employee. include their descriptions and the number of staff members in each role.,"(employees.merge(roles, on='role_code').groupby(['role_description'])['employee_id'].count().loc[lambda x: x > 1])"
what is the document description for document with id 1?,"pd.merge(ref_document_status, documents.loc[lambda x: x['document_id']==1], on='document_status_code')['document_status_description'].squeeze()"
what is the count of the documents having status code done?,(documents['document_status_code'] == 'done').sum()
please provide me with the ``document type code`` for the document with the id ``2``.,"documents.loc[lambda x: x['document_id']==2, 'document_type_code']"
"list document ids for any documents with the status code of ""done"" and ""paper"".","documents.loc[(documents['document_status_code'] == 'done') & (documents['document_type_code'] == 'paper'), 'document_id']"
what is the number of documents sent by usps?,"pd.merge(ref_shipping_agents, documents, on='shipping_agent_code').loc[lambda x: x['shipping_agent_name']=='usps', :].shape[0]"
provide the names of shipping agents that shipped the most documents as well as the count of documents.,"pd.merge(ref_shipping_agents, documents, on='shipping_agent_code').groupby('shipping_agent_name')['document_id'].count().sort_values(ascending=false).nlargest(1)"
please provide me with the receipt date of the paper with id 3.,"documents.loc[lambda x: x['document_id']==3, 'receipt_date']"
find the address of documents that were assigned the id 4.,"addresses.merge(documents_mailed, left_on='address_id', right_on='mailed_to_address_id').loc[lambda x: x['document_id']==4, 'address_details']"
please inform me of the date when the document with id 7 was created.,"documents_mailed.loc[lambda x: x['document_id']==7, 'mailing_date']"
"list the document ids of documents with the status done and of type paper, which not shipped by the shipping agent named usps.","documents.query('document_status_code == ""done"" & document_type_code == ""paper""')['document_id'].values.tolist() - documents[documents['shipping_agent_code'].isin(ref_shipping_agents[ref_shipping_agents['shipping_agent_name']=='usps']['shipping_agent_code'])]['document_id'].values.tolist()"
"provide me the ids of documents that are in the done state, are of the paper type, and were shipped by the usps.","documents.loc[(documents['document_status_code']=='done') & (documents['document_type_code']=='paper') & (documents['shipping_agent_code'].isin(ref_shipping_agents.loc[ref_shipping_agents['shipping_agent_name']=='usps', 'shipping_agent_code'])), 'document_id']"
provide me the draft details of the document with id 7.,"document_drafts.loc[lambda x: x['document_id']==7, 'draft_details']"
how many draft copies of document 2 does the document possess?,(df['document_id'] == 2).sum()
list the document id and the number of draft copies of the document that has the most draft copies.,"(draft_copies.groupby('document_id')['copy_number'].count().reset_index().sort_values('copy_number', ascending=false).iloc[0])[['document_id', 'copy_number']]"
which documents have 2 or more draft copies? list the document id and number of draft copies.,draft_copies.groupby('document_id').filter(lambda x: len(x) > 1).groupby('document_id').size().reset_index(name='count')
please list all employees that participated in the circulation history of the document with id 1 along with their full names.,"pd.merge(employees, circulation_history[circulation_history['document_id']==1], on='employee_id')['employee_name']"
list the names of employees who have not appeared in any circulation history of documents.,"employees[~employees['employee_name'].isin(pd.merge(employees, circulation_history, on='employee_id')['employee_name'])]['employee_name']"
"list the name of an employee who has turned up in most circulation history documents. also, provide the number of drafts and copies.","pd.merge(employees, circulation_history, on='employee_id').groupby(['document_id', 'draft_number', 'copy_number'])['employee_name'].count().reset_index().sort_values(0, ascending=false).iloc[0]['employee_name']"
"for each document, give the number of employees who have reportedly been involved in its circulation, along with the corresponding document id.",circulation_history.groupby('document_id')['employee_id'].nunique().reset_index(name='count')
arrange the department names according to their start date.,department.sort_values('mgr_start_date')['dname']
"retrieve names of dependents that have some relationship with some employee.i already wrote this regex:\b(?:[^\.|(?<=\\)]+\.)+(?:[^\.|(?<=\\)]+)(?:\.[^\.|(?<=\\)]+)*(?:[^\.|(?<=\\)]+\.)+(?:[0-9]{4}(?:\.[0-9]{4})*)?but it's wrong, any help?edit: now i write:\b(?:[^\.|(?<=\\)]+\.)+(?:[^\.|(?<=\\)]+)(?:\.[^\.|(?<=\\)]+)*(?:[^\.|(?<=\\)]+\.)+\s?(?:[0-9]{4}(?:\.[0-9","dependent.loc[lambda x: x['relationship'] == 'spouse', 'dependent_name']"
what is the count of female dependents?,(dependent['sex'] == 'f').sum()
retrieve the titles of departments that are situated in houston.,"department.merge(dept_locations, on='dnumber').loc[lambda x: x['dlocation']=='houston', 'dname']"
find the names of employees who are paid more than 30000 in salary.,"employee.loc[lambda x: x['salary'] > 30000, ['fname', 'lname']]"
determine the number of employees of each sex whose salary is lower than 50000.,employee.loc[lambda x: x['salary'] < 50000].groupby('sex').size()
what is the event information of services that have the type code of 'marriage'?,"pd.merge(events, services.query(""service_type_code == 'marriage'""), on='service_id')['event_details']"
what are the ids and details of events that have two or more participants?,"pd.merge(events, participants_in_events, on='event_id').groupby('event_id').filter(lambda x: x.shape[0] > 1)[['event_id', 'event_details']].drop_duplicates()"
"please provide me with the total number of events attended by each participant, along with their id and type.","participants.merge(participants_in_events, on='participant_id').groupby(['participant_id', 'participant_type_code'])['participant_id'].count().reset_index(name='count')"
"retrieve the full names of participants, their ids and details.","participants[['participant_id', 'participant_type_code', 'participant_details']]"
what is the count of participants that belong to the type 'organizer'?,(participants['participant_type_code']=='organizer').sum()
sort the services by type in alphabetical order.,services['service_type_code'].sort_values()
list the service id along with details for events.,"events[['service_id', 'event_details']]"
count the number of events that had participants whose details had the substring 'dr.',"pd.merge(participants, participants_in_events, on='participant_id').loc[lambda x: x['participant_details'].str.contains('dr.')].shape[0]"
what is the common type of participants?,participants.groupby('participant_type_code').size().sort_values(ascending=false).head(1).index[0]
which type of service had the least number of participants?,"pd.merge(pd.merge(pd.merge(participants, participants_in_events, on='participant_id'), events, on='event_id'), services, on='service_id').groupby('service_id')['service_type_code'].first().sort_values().index[0]"
what is the id of the event with the largest number of participants?,participants_in_events.groupby('event_id').size().sort_values(ascending=false).index[0]
provide the details of events id that do not have participant 'kenyatta kuhn'.,"events[~events['event_id'].isin(participants_in_events.merge(participants.query(""participant_details == 'kenyatta kuhn'""), on='participant_id')['event_id'])]['event_id']"
which service type contained both successful and failure data?,"pd.merge(services.loc[lambda x: x.merge(events.loc[lambda x: x['event_details'].eq('success')], on='service_id').index, 'service_type_code'], services.loc[lambda x: x.merge(events.loc[lambda x: x['event_details'].eq('fail')], on='service_id').index, 'service_type_code']).drop_duplicates()"
what is the count of events that did not involve any participants?,"events.loc[~events['event_id'].isin(participants_in_events['event_id']), 'event_id'].count()"
what is the list of participant ids that were present at any events?,participants_in_events['participant_id'].nunique()
what race was most recently held?,"races.sort_values('date', ascending=false).iloc[0]['name']"
what was the name of the race that most recently occurred?,"races.sort_values('date', ascending=false).iloc[0]['name']"
could you please provide me with the name of the most recent race and the date on which it occurred?,"races[['name', 'date']].sort_values('date', ascending=false).head(1)"
please fetch me the names of all the races held in 2017.,"races.loc[races['year']==2017, 'name']"
determine the complete names of all the races that occurred in the year 2017.,"races.loc[races['year']==2017, 'name']"
find the titles that are distinct for all races held between 2014 and 2017?,races.query('year >= 2014 and year <= 2017')['name'].unique()
retrieve the titles of races held between 2014 and 2017.,races.query('year >= 2014 and year <= 2017')['name'].unique()
provide me the names and surnames of drivers who achieved laptime less than 93000 milliseconds.,"pd.merge(drivers, laptimes, on='driverid').loc[lambda x: x['milliseconds'] < 93000, ['forename', 'surname']].drop_duplicates()"
retrieve the complete names of drivers whose lap time was less than 93 seconds.,"pd.merge(drivers, laptimes, on='driverid').loc[lambda x: x['milliseconds'] < 93000, ['forename', 'surname']].drop_duplicates()"
retrieve the details about all the drivers who have logged lap times exceeding 100000 milliseconds.,"pd.merge(drivers, laptimes.loc[laptimes['milliseconds'] > 100000, :], on='driverid')[['driverid', 'nationality']].drop_duplicates()"
what are the driver ids and nationalities of drivers who surpassed the laptime threshold of 100000 milliseconds?,"pd.merge(drivers, laptimes.loc[laptimes['milliseconds'] > 100000, :], on='driverid')[['driverid', 'nationality']].drop_duplicates()"
what is the first name and last name of the driver of the car that has the lowest laptime?,"drivers.merge(laptimes, on='driverid').sort_values('milliseconds').iloc[0][['forename', 'surname']]"
which driver has the shortest laptime?,"drivers.merge(laptimes, on='driverid').sort_values('milliseconds').iloc[0][['forename', 'surname']]"
what is the driver's id and last name who has the longest laptime?,"pd.merge(drivers, laptimes, on='driverid').sort_values('milliseconds', ascending=false).iloc[0][['driverid', 'surname']]"
what is the driver id and full name who has the longest laptime?,"pd.merge(drivers, laptimes, on='driverid').sort_values('milliseconds', ascending=false).iloc[0][['driverid', 'surname']]"
"retrieve the id, forename and surname of the driver who had the first position in terms of laptime at least twice.","drivers.merge(laptimes.loc[laptimes['position'] == '1'], on='driverid').groupby(['driverid', 'forename', 'surname']).filter(lambda x: x['driverid'].count() >= 2).loc[:, ['driverid', 'forename', 'surname']].drop_duplicates()"
"please provide me with the id, first name, and last name of the driver who was in first place for more than laptimes.","drivers.merge(laptimes.loc[laptimes['position'] == '1'], on='driverid').groupby(['driverid', 'forename', 'surname']).filter(lambda x: x['driverid'].count() >= 2).loc[:, ['driverid', 'forename', 'surname']].drop_duplicates()"
what was the count of drivers who participated in the australian grand prix held in 2009?,"pd.merge(results, races, on='raceid').query('name==""australian grand prix"" and year==2009').shape[0]"
how many drivers were in the competition in 2009?,"pd.merge(results, races, on='raceid').query('name==""australian grand prix"" and year==2009').shape[0]"
in which year did most drivers not participate?,"results.loc[~results['raceid'].isin(races.loc[races['year']!=2009,'raceid']),'driverid'].nunique()"
how many drivers did not participate in a race in 2009?,"results.loc[~results['raceid'].isin(races.loc[races['year']!=2009,'raceid']),'driverid'].nunique()"
please provide me with the names of the races in the years that have any drivers whose forename is lewis.,"results.merge(races, on='raceid').merge(drivers, on='driverid').loc[lambda x: x['forename'] == ""lewis"", ['name', 'year']]"
"retrieve the names of all races in which a driver with the last name lewis was present, and the year of their occurrence.","results.merge(races, on='raceid').merge(drivers, on='driverid').loc[lambda x: x['forename'] == ""lewis"", ['name', 'year']]"
arrange the first and last names of drivers whose nationality is germany.,"drivers.loc[lambda x: x['nationality']=='german', ['forename', 'surname']]"
what is the complete list of firstand last names for all german drivers?,"drivers.loc[lambda x: x['nationality']=='german', ['forename', 'surname']]"
retrieve the id and first names of drivers who participated in both the races with name australian grand prix and the races with name chinese grand prix.,"pd.merge(pd.merge(races[races['name']=='australian grand prix'], results, on='raceid'), drivers, on='driverid')[['driverid', 'forename']].merge(pd.merge(pd.merge(races[races['name']=='chinese grand prix'], results, on='raceid'), drivers, on='driverid')[['driverid', 'forename']]).drop_duplicates()"
provide me with the id and first name of all the drivers who took part in the australian grand prix and the chinese grand prix.,"pd.merge(pd.merge(races[races['name']=='australian grand prix'], results, on='raceid'), drivers, on='driverid')[['driverid', 'forename']].merge(pd.merge(pd.merge(races[races['name']=='chinese grand prix'], results, on='raceid'), drivers, on='driverid')[['driverid', 'forename']]).drop_duplicates()"
"provide a listing of forenames and surnames of drivers who participated in races named australian grand prix, but no races named chinese grand prix.","drivers[drivers['driverid'].isin(pd.merge(pd.merge(races[races['name']=='australian grand prix'], results, on='raceid'), drivers, on='driverid')[['driverid', 'forename', 'surname']].drop_duplicates().reset_index(drop=true)).query('driverid not in @pd.merge(pd.merge(races[races[""name""]==""chinese grand prix""], results, on=""raceid""), drivers, on=""driverid"")[[""driverid"", ""forename"", ""surname""]].drop_duplicates().reset_index(drop=true)[""driverid""].tolist())][['forename', 'surname']]"
retrieve the first and last names of drivers who competed in the australian grand prix but did not participate in the chinese grand prix.,"drivers[drivers['driverid'].isin(pd.merge(pd.merge(races[races['name']=='australian grand prix'], results, on='raceid'), drivers, on='driverid')[['driverid', 'forename', 'surname']].drop_duplicates().reset_index(drop=true)).query('driverid not in @pd.merge(pd.merge(races[races[""name""]==""chinese grand prix""], results, on=""raceid""), drivers, on=""driverid"")[[""driverid"", ""forename"", ""surname""]].drop_duplicates().reset_index(drop=true)[""driverid""].tolist())][['forename', 'surname']]"
"determine the representation of distinct drivers who attained the position 1 in the standing, and won.","pd.merge(drivers, driverstandings.query('position == 1 and wins == 1'), on='driverid')['forename'].unique()"
what is the full list of first names of drivers who are in positions of standing and won?,"pd.merge(drivers, driverstandings.query('position == 1 and wins == 1'), on='driverid')['forename'].unique()"
give me a complete listing of forenames for drivers who won in position 1 as driver standing and had more than 20 points.,"pd.merge(drivers, driverstandings, on='driverid').query('position == 1 and wins == 1 and points > 20')['forename'].unique()"
please provide me with the last name and first name of all the drivers who finished first as driver standing and had a score of more than 20 points.,"pd.merge(drivers, driverstandings, on='driverid').query('position == 1 and wins == 1 and points > 20')['forename'].unique()"
what is the count of constructors from each country?,constructors.groupby('nationality').size().reset_index(name='count')
"for each nationality, what are the constructors?",constructors.groupby('nationality').size().reset_index(name='count')
how many races were conducted by each constructor id?,constructorstandings.groupby('constructorid').size().reset_index(name='count')
"find for each constructor id, the number of races.",constructorstandings.groupby('constructorid').size().reset_index(name='count')
name the races that were organized after 2017 and the venues were in the country of spain.,"pd.merge(races, circuits, on='circuitid').loc[(lambda x: x['country']=='spain') & (lambda x: x['year']>2017), 'name']"
what is the list of race titles held after 2017 in spain?,"pd.merge(races, circuits, on='circuitid').loc[(lambda x: x['country']=='spain') & (lambda x: x['year']>2017), 'name']"
what is the count of unique races that were held after 2000 and the circuits were located in spain?,"pd.merge(races, circuits, on='circuitid').loc[(lambda x: (x['country']=='spain') & (x['year']>2000)), 'name'].unique()"
what are the titles of the races held after 2000 in spain?,"pd.merge(races, circuits, on='circuitid').loc[(lambda x: (x['country']=='spain') & (x['year']>2000)), 'name'].unique()"
provide me with the ids and pit stop duration of drivers that have pit stop durations that are shorter than some drivers in the race with id 841.,"pitstops.loc[lambda x: x['duration'] < pitstops.loc[lambda y: y['raceid'] == 841, 'duration'].max(), ['driverid', 'stop']].drop_duplicates()"
what is the card and pit stop number for each driver that accomplished a shorter pit stop than the driver in the race with card 841?,"pitstops.loc[lambda x: x['duration'] < pitstops.loc[lambda y: y['raceid'] == 841, 'duration'].max(), ['driverid', 'stop']].drop_duplicates()"
what are the distinct driver ids of those drivers whose stop duration exceeded the stop duration of some drivers with id 841?,"pitstops.loc[lambda x: x['duration'] > pitstops.loc[lambda y: y['raceid']==841, 'duration'].min(), ['driverid', 'stop']].drop_duplicates()"
provide me with the surnames of drivers that are not repeated.,drivers['forename'].sort_values().unique()
list the names of all the distinct races in reversed lexicographical order.,races['name'].sort_values(ascending=false).unique()
retrieve the names in the reverse alphabetical order of all race types.,races['name'].sort_values(ascending=false).unique()
what are the running races held between 2009 and 2011?,"races.loc[races['year'].between(2009, 2011), 'name']"
retrieve the subjects of races held after 12:00:00 or before 09:00:00.,"races.loc[races['time'].between('09:00:00', '12:00:00', inclusive=false), 'name']"
list the names of all races that occurred between 12:00:00 and 09:00:00.,"races.loc[races['time'].between('09:00:00', '12:00:00', inclusive=false), 'name']"
"please return me total first name, last name and id of drivers who participated in races or had more than 8 pit stops.","pd.concat([drivers.merge(pitstops, on='driverid').groupby('driverid').filter(lambda x: len(x) > 8),drivers.merge(results, on='driverid').groupby('driverid').filter(lambda x: len(x) > 5)])[['forename', 'surname', 'driverid']].drop_duplicates()"
"for drivers who had 8 or more stops or participated in 5 or more competitive races, please provide me with their first name, last name, and id.","pd.concat([drivers.merge(pitstops, on='driverid').groupby('driverid').filter(lambda x: len(x) > 8),drivers.merge(results, on='driverid').groupby('driverid').filter(lambda x: len(x) > 5)])[['forename', 'surname', 'driverid']].drop_duplicates()"
provide me the names and full ids of the drivers who had 11 pit stops and participated in more than five racing results.,"pd.merge(drivers, pitstops, on='driverid').groupby(['surname_x', 'driverid']).filter(lambda x: len(x)==11).reset_index()[['surname_x', 'driverid']].merge(pd.merge(drivers, results, on='driverid').groupby(['surname_x', 'driverid']).filter(lambda x: len(x)>5).reset_index()[['surname_x', 'driverid']], on=['surname_x', 'driverid'], how='inner')['surname_x', 'driverid']"
provide me with the last name and id of all drivers who had 11 pit stops and participated in more than 5 races.,"pd.merge(drivers, pitstops, on='driverid').groupby(['surname_x', 'driverid']).filter(lambda x: len(x)==11).reset_index()[['surname_x', 'driverid']].merge(pd.merge(drivers, results, on='driverid').groupby(['surname_x', 'driverid']).filter(lambda x: len(x)>5).reset_index()[['surname_x', 'driverid']], on=['surname_x', 'driverid'], how='inner')['surname_x', 'driverid']"
what are the titles and last names of drivers who have competed in the highest number of races after 2010?,"drivers.merge(results, on='driverid').merge(races, on='raceid').loc[lambda x: x['year']>2010].groupby(['driverid', 'surname']).size().idxmax()[1]"
what is the id and last name of the driver who proceeded with the most races after 2010?,"drivers.merge(results, on='driverid').merge(races, on='raceid').loc[lambda x: x['year']>2010].groupby(['driverid', 'surname']).size().idxmax()[1]"
identify the circuits that are situated in either uk or malaysia.,"circuits.loc[circuits['country'].isin(['uk', 'malaysia']), 'name']"
determine the names of all the circuits that are either in the uk or malaysia.,"circuits.loc[circuits['country'].isin(['uk', 'malaysia']), 'name']"
please return the id and location of circuits that belong to france or belgium.,"circuits.loc[circuits['country'].isin(['france', 'belgium']), ['circuitid', 'location']]"
please provide me with the id and location of all circuits in france or belgium.,"circuits.loc[circuits['country'].isin(['france', 'belgium']), ['circuitid', 'location']]"
retrieve the titles of japanese companies that once scored more than 5 points.,"pd.merge(constructors, constructorstandings, on='constructorid').loc[(constructors['nationality']=='japanese') & (constructorstandings['points']>5), 'name']"
retrieve the names of all japanese constructors that have earned 5 or more points.,"pd.merge(constructors, constructorstandings, on='constructorid').loc[(constructors['nationality']=='japanese') & (constructorstandings['points']>5), 'name']"
"determine the average speed of the fastest lap in ""monaco grand prix"" race which took place in 2008.","results.merge(races.loc[(races['year'] == 2008) & (races['name'] == 'monaco grand prix'), ['raceid']], on='raceid')['fastestlapspeed'].mean()"
what was the average fastest lap speed for the monaco grand prix in the year 2008?,"results.merge(races.loc[(races['year'] == 2008) & (races['name'] == 'monaco grand prix'), ['raceid']], on='raceid')['fastestlapspeed'].mean()"
"what is the fastest lap speed in ""monaco grand prix"" race in the year 2008?","races.merge(results, on='raceid').query('year == 2008 and name == ""monaco grand prix""')['fastestlapspeed'].max()"
what was the highest top speed attained by any racer in the monaco grand prix in the year 2008?,"races.merge(results, on='raceid').query('year == 2008 and name == ""monaco grand prix""')['fastestlapspeed'].max()"
what are the maximum average speed of races held after 2004 ordered by year and grouped by race name?,"pd.merge(races[races['year'] > 2014], results, on='raceid').groupby('name').agg({'fastestlapspeed': 'max', 'year': 'first'}).sort_values('year')[['fastestlapspeed', 'year']]"
"for which races name, retrieve the maximum fastest lap speed for races after 2004 ordered by year?","pd.merge(races[races['year'] > 2014], results, on='raceid').groupby('name').agg({'fastestlapspeed': 'max', 'year': 'first'}).sort_values('year')[['fastestlapspeed', 'year']]"
please provide me the average fastest lap speed in races held after 2004 grouped by race name and ordered by year.,"pd.merge(races[races['year'] > 2014], results, on='raceid').groupby('name').agg(avg_fastestlapspeed=('fastestlapspeed', 'mean'), year=('year', 'first')).sort_values('year')"
"provide me with the id, forename and number of races of drivers who have undertaken at least 2 races.","drivers.merge(results, on='driverid').merge(races, on='raceid').groupby(['driverid', 'forename']).size().reset_index(name='count').loc[lambda x: x['count']>=2, ['driverid', 'forename', 'count']]"
"could you return me the id, forename, and number of races for all drivers that have participated in at least 2 races?","drivers.merge(results, on='driverid').merge(races, on='raceid').groupby(['driverid', 'forename']).size().reset_index(name='count').loc[lambda x: x['count']>=2, ['driverid', 'forename', 'count']]"
retrieve the driver id and the number of races for drivers who have participated only 30 times.,"pd.merge(pd.merge(drivers, results, on='driverid'), races, on='raceid').groupby('driverid').filter(lambda x: x.shape[0] <= 30).groupby('driverid').size().reset_index(name='count(*)')[['driverid', 'count(*)']]"
"for each driver id who participated in at most 30 races, please provide me with the number of races they participated in.","pd.merge(pd.merge(drivers, results, on='driverid'), races, on='raceid').groupby('driverid').filter(lambda x: x.shape[0] <= 30).groupby('driverid').size().reset_index(name='count(*)')[['driverid', 'count(*)']]"
find the driver id number and surname that participated in the most number of races.,"pd.merge(pd.merge(drivers, results, on='driverid'), races, on='raceid').groupby(['driverid', 'surname']).size().sort_values(ascending=false).reset_index().iloc[0][['driverid', 'surname']]"
provide me with the ids and last names of all drivers who took part in the largest number of races.,"pd.merge(pd.merge(drivers, results, on='driverid'), races, on='raceid').groupby(['driverid', 'surname']).size().sort_values(ascending=false).reset_index().iloc[0][['driverid', 'surname']]"
provide the names of technicians in order of their age.,technician.sort_values('age')['name']
retrieve the names and ages of the technicians by sorting them in ascending order.,technician.sort_values('age')['name']
what is the number of teams and the starting year of the technicians?,"technician[['team', 'starting_year']]"
what is the team and starting year for each employee?,"technician[['team', 'starting_year']]"
which technicians were not a part of team nyy?,"technician.loc[lambda x: x['team'] != 'nyy', 'name']"
what is the designation of the person whose group is not 'nyy'?,"technician.loc[lambda x: x['team'] != 'nyy', 'name']"
return me the names of technicians who are either 36 or 37 years old.,"technician.loc[technician['age'].isin([36, 37]), 'name']"
provide me with the titles of those technicians who have either 36 or 37 as their date of birth.,"technician.loc[technician['age'].isin([36, 37]), 'name']"
provide me with the starting year of the oldest technicians.,"technician.sort_values('age', ascending=false).iloc[0]['starting_year']"
what is the starting year associated with the oldest technician?,"technician.sort_values('age', ascending=false).iloc[0]['starting_year']"
what is the number of teams and the number of members in each team?,technician.groupby('team').size()
"for each team, what is the number of technical support personnel?",technician.groupby('team').size()
please list the team that has the most number of employees.,technician.groupby('team').size().sort_values(ascending=false).index[0]
who are the teams with the most employees?,technician.groupby('team').size().sort_values(ascending=false).index[0]
show me the team that has at least two technicians.,technician.groupby('team').filter(lambda x: x['team'].count() >= 2)['team'].unique()
which team has more than 2 technicians?,technician.groupby('team').filter(lambda x: x['team'].count() >= 2)['team'].unique()
retrieve the ids of technicians and machines they are assigned to repair.,"pd.merge(pd.merge(repair_assignment, machine, on='machine_id'), technician, on='technician_id')[['name', 'machine_series']]"
determine the titles of technicians and machine series that they repair.,"pd.merge(pd.merge(repair_assignment, machine, on='machine_id'), technician, on='technician_id')[['name', 'machine_series']]"
list out the names in ascending order of the quality rank of the machines they are assigned.,"pd.merge(pd.merge(repair_assignment, machine, on='machine_id'), technician, on='technician_id').sort_values('quality_rank')['name']"
list the names of the technicians by ascending quality rank.,"pd.merge(pd.merge(repair_assignment, machine, on='machine_id'), technician, on='technician_id').sort_values('quality_rank')['name']"
list the names of technicians who were assigned to fix machines with value point more than 70.,"pd.merge(pd.merge(repair_assignment, machine, on='machine_id'), technician, on='technician_id').loc[lambda x: x['value_points']>70, 'name']"
retrieve the names and ids of technicians who were assigned to repair machines with point values greater than 70.,"pd.merge(pd.merge(repair_assignment, machine, on='machine_id'), technician, on='technician_id').loc[lambda x: x['value_points']>70, 'name']"
provide me with the names and number of machines maintained and serviced by each technician.,"repair_assignment.merge(technician, on='technician_id').groupby('name').size().rename_axis('name').reset_index(name='count')"
what are the names for technicians and how many machines do they repair.,"repair_assignment.merge(technician, on='technician_id').groupby('name').size().rename_axis('name').reset_index(name='count')"
provide me with the names of technicians who have not been assigned to repair machines.,"technician.loc[~technician['technician_id'].isin(repair_assignment['technician_id']), 'name']"
what are the names of technicians that have not been assigned to repair machines?,"technician.loc[~technician['technician_id'].isin(repair_assignment['technician_id']), 'name']"
"provide me the names of the starting years shared by technicians from teams ""cle"" and ""cws"".","set(technician.loc[technician['team']=='cle', 'starting_year']).intersection(set(technician.loc[technician['team']=='cws', 'starting_year']))"
"what are the starting years that are found in the technicians from the teams ""cle"" or ""cws""?","set(technician.loc[technician['team']=='cle', 'starting_year']).intersection(set(technician.loc[technician['team']=='cws', 'starting_year']))"
determine the total count of entrepreneurs.,entrepreneur.shape[0]
provide me the names of the companies with shareholders with the highest amount of money requested.,"entrepreneur.sort_values('money_requested', ascending=false)['company']"
"write the names of companies of entrepreneurs, ordered from highest to lowest by amount of money requested.","entrepreneur.sort_values('money_requested', ascending=false)['company']"
allow me to see the names of the investors and the companies of entrepreneurs.,"entrepreneur[['company', 'investor']]"
what is the company and individual that correspond to each business person?,"entrepreneur[['company', 'investor']]"
what is the average amount requested by all entrepreneurs?,entrepreneur['money_requested'].mean()
list the average amount of funds demanded by all the entrepreneurs.,entrepreneur['money_requested'].mean()
what are the names of the people in ascending order of weight?,people.sort_values('weight')['name']
"please return the names of people, ordered by weight ascending.",people.sort_values('weight')['name']
what are the titles of entrepreneurs?,"pd.merge(entrepreneur, people, on='people_id')['name']"
"retrieve the names of entrepreneurs whose investor is not ""rachel elnaugh"".","pd.merge(entrepreneur, people, on='people_id').loc[lambda x: x['investor']!='rachel elnaugh', 'name']"
provide me a list of names of entrepreneurs that do not possess the investment of rachel elnaugh.,"pd.merge(entrepreneur, people, on='people_id').loc[lambda x: x['investor']!='rachel elnaugh', 'name']"
please provide me with the body weight of the shortest person.,people.sort_values('height').iloc[0]['weight']
please name the individual who possesses the greatest weight.,"pd.merge(entrepreneur, people, on='people_id').sort_values('weight', ascending=false).iloc[0]['name']"
please supply the title of the entrepreneur that is the heaviest.,"pd.merge(entrepreneur, people, on='people_id').sort_values('weight', ascending=false).iloc[0]['name']"
what is the sum of money requested for this year by entrepreneurs whose heights are over 1.85?,"pd.merge(entrepreneur, people, on='people_id').loc[lambda x: x['height']>1.85, 'money_requested'].sum()"
please provide me with the total amount of money requested by entrepreneurs who are taller than 1.85 m.,"pd.merge(entrepreneur, people, on='people_id').loc[lambda x: x['height']>1.85, 'money_requested'].sum()"
what is the list of birthdays of entrepreneurs associated with simon woodroffe or peter jones?,"people.merge(entrepreneur, on='people_id').loc[lambda x: x['investor'].isin(['simon woodroffe', 'peter jones']), 'date_of_birth']"
provide me with the dates of birth for entrepreneurs that have either the investors simon woodroffe or peter jones.,"people.merge(entrepreneur, on='people_id').loc[lambda x: x['investor'].isin(['simon woodroffe', 'peter jones']), 'date_of_birth']"
what is the descending rank of money requested in terms of weight of entrepreneur?,"people.merge(entrepreneur, on='people_id').sort_values('money_requested', ascending=false)['weight']"
please provide me with the weights of individual entrepreneurs in descending order of the amount of money they requested.,"people.merge(entrepreneur, on='people_id').sort_values('money_requested', ascending=false)['weight']"
provide me with the names of the investors of entrepreneurs and the corresponding number of entrepreneurs invested by each investor.,entrepreneur.groupby('investor').size()
give the count of investors that correspond to the indicated number of entrepreneurs.,entrepreneur.groupby('investor').size()
which investor has funded the maximum number of entrepreneurs?,entrepreneur.groupby('investor').size().sort_values(ascending=false).index[0]
please return the investor who has invested in the highest number of entrepreneurs.,entrepreneur.groupby('investor').size().sort_values(ascending=false).index[0]
what are the investors that have provided financing to at least two entrepreneurs?,entrepreneur.groupby('investor').filter(lambda x: len(x) >= 2)['investor'].unique()
retrieve the names of the investors who have invested in at least two entrepreneurs.,entrepreneur.groupby('investor').filter(lambda x: len(x) >= 2)['investor'].unique()
return the titles of the top entrepreneurs who were requesting large amounts of funding.,"pd.merge(entrepreneur, people, on='people_id').sort_values('money_requested')[['name', 'company']]"
"name the entrepreneurs and their investors, ordered descending by the amount of money requested.","pd.merge(entrepreneur, people, on='people_id').sort_values('money_requested')[['name', 'company']]"
return a list of names that are ineligible to be entrepreneurs.,"people.loc[~people['people_id'].isin(entrepreneur['people_id']), 'name']"
retrieve the names of the people who are not entrepreneurs.,"people.loc[~people['people_id'].isin(entrepreneur['people_id']), 'name']"
specify the investors that have provided funding to both entrepreneurs with investment requests above 140000 and requests below 120000.,"entrepreneur.loc[entrepreneur['money_requested'] > 140000, 'investor'].to_frame().merge(entrepreneur.loc[entrepreneur['money_requested'] < 120000, 'investor'].to_frame(),on='investor')['investor']"
how many unique businesses are there?,entrepreneur['company'].nunique()
what is the count of different companies?,entrepreneur['company'].nunique()
display the name of the company of the tallest entrepreneur.,"pd.merge(entrepreneur, people, on='people_id').sort_values('height', ascending=false).iloc[0]['company']"
determine the company whose founder has the highest peak.,"pd.merge(entrepreneur, people, on='people_id').sort_values('height', ascending=false).iloc[0]['company']"
what is the count of perpetrators?,perpetrator.shape[0]
which date saw the highest number of people killed?,"perpetrator.sort_values('killed', ascending=false)['date']"
please list the names and number of victims of perpetrators in ascending order.,perpetrator.sort_values('injured')['injured']
"find the average number of people injured, regardless of the perpetrating party.",perpetrator['injured'].mean()
identify the location at which the single perpetrator had the most kills.,"perpetrator.sort_values('killed', ascending=false).iloc[0]['location']"
retrieve the names of people in ascending order of height.,people.sort_values('height')['name']
fetch the names of criminals.,"pd.merge(people, perpetrator, on='people_id')['name']"
find the titles of perpetrators who are not from china.,"pd.merge(people, perpetrator, on='people_id').loc[lambda x: x['country'] != 'china', 'name']"
what is the title of the perpetrator that has the greatest weight?,"people.merge(perpetrator, on='people_id').sort_values('weight', ascending=false).iloc[0]['name']"
what was the total number of kills committed with perpetrators having a height of more than 1.84?,"pd.merge(people, perpetrator, on='people_id').loc[lambda x: x['height'] > 1.84, 'killed'].sum()"
what are the names of persons implicated in the incidents of china or japan?,"pd.merge(people, perpetrator, on='people_id').loc[lambda x: x['country'].isin(['china', 'japan']), 'name']"
provide me with the heights of perpetrators in descending order of the number of people they injured.,"people.merge(perpetrator, on=""people_id"").sort_values('injured', ascending=false)[""height""]"
"display the number of perpetrators in each country, along with the full name of that country.",perpetrator.groupby('country').size().reset_index(name='count')
identify the nation that has the highest number of perpetrators.,perpetrator.groupby('country').size().nlargest(1)
retrieve the names of perpetrators in descending order of the year.,"pd.merge(people, perpetrator, on='people_id').sort_values('year', ascending=false)['name']"
retrieve the names of people that are not included in the list of perpetrators.,"people.loc[~people['people_id'].isin(perpetrator['people_id']), 'name']"
what is the count of distinct locations of perpetrators?,perpetrator['location'].nunique()
provide the date of the tallest criminal.,"perpetrator.merge(people, on='people_id').sort_values('height', ascending=false).iloc[0]['date']"
what is the most recent year in which a crime has been committed?,perpetrator['year'].max()
retrieve the names of all campuses in los angeles county.,"campuses.loc[campuses['county']=='los angeles', 'campus']"
what campuses are located within the county of los angeles?,"campuses.loc[campuses['county']=='los angeles', 'campus']"
what is the list of names of all the campuses located at chico?,"campuses.loc[campuses['location']=='chico', 'campus']"
locate the campuses in chico.,"campuses.loc[campuses['location']=='chico', 'campus']"
list all campuses that were opened in 1958.,"campuses.loc[campuses['year']==1958, 'campus']"
please provide me with the list of universities that opened in 1958.,"campuses.loc[campuses['year']==1958, 'campus']"
provide me the names of the campuses that were established before the year 1800.,"campuses.loc[lambda x: x['year'] < 1800, 'campus']"
examine the count of campus that were established between 1935 and 1939.,"campuses.loc[lambda x: (x['year'] >= 1935) & (x['year'] <= 1939), 'campus']"
what campuses were established between 1935 and 1939?,"campuses.loc[lambda x: (x['year'] >= 1935) & (x['year'] <= 1939), 'campus']"
"retrieve the names of campuses that are located in either northridge, los angeles or in san francisco, san francisco.","pd.concat([campuses.loc[(campuses['location']=='northridge') & (campuses['county']=='los angeles'), 'campus'], campuses.loc[(campuses['location']=='san francisco') & (campuses['county']=='san francisco'), 'campus']]).drop_duplicates()"
"please indicate the campuses located in northridge, los angeles, or san francisco.","pd.concat([campuses.loc[(campuses['location']=='northridge') & (campuses['county']=='los angeles'), 'campus'], campuses.loc[(campuses['location']=='san francisco') & (campuses['county']=='san francisco'), 'campus']]).drop_duplicates()"
how about the fee for the course of san jose state university in the year 1996?,"pd.merge(campuses[campuses['campus'] == 'san jose state university'], csu_fees[csu_fees['year'] == 1996], left_on='id', right_on='campus')['campusfee']"
what is the tuition fee at san jose state university in 1996?,"pd.merge(campuses[campuses['campus'] == 'san jose state university'], csu_fees[csu_fees['year'] == 1996], left_on='id', right_on='campus')['campusfee']"
"what is the monthly fee of california state university, ""s. f."" in 1996?","pd.merge(campuses[campuses['campus'] == 'san francisco state university'], csu_fees[csu_fees['year'] == 1996], left_on='id', right_on='campus')['campusfee'].iloc[0]"
what is the fee that has been charged to the students enrolled in san francisco state university in the year 1996?,"pd.merge(campuses[campuses['campus'] == 'san francisco state university'], csu_fees[csu_fees['year'] == 1996], left_on='id', right_on='campus')['campusfee'].iloc[0]"
determine the count of universities whose campus fees are greater than that of average campus fees.,(csu_fees['campusfee'] > csu_fees['campusfee'].mean()).sum()
which universities have fees higher than the averaged?,(csu_fees['campusfee'] > csu_fees['campusfee'].mean()).sum()
determine the count of universities whose campus fees are greater than the average campus fee.,(csu_fees['campusfee'] > csu_fees['campusfee'].mean()).sum()
how many universities have campus fees higher than the average?,(csu_fees['campusfee'] > csu_fees['campusfee'].mean()).sum()
which university is located in los angeles county and opened after 1950?,"campuses.loc[(campuses['county'] == 'los angeles') & (campuses['year'] > 1950), 'campus']"
which campuses are located los angeles county and opened after 1950?,"campuses.loc[(campuses['county'] == 'los angeles') & (campuses['year'] > 1950), 'campus']"
during which most years degrees were conferred?,degrees.groupby('year').sum().sort_values(ascending=false).head(1).index[0]
which year saw the highest count of degrees conferred?,degrees.groupby('year').sum().sort_values(ascending=false).head(1).index[0]
which campus has conferred the largest number of degrees over all time?,degrees.groupby('campus').sum().sort_values(ascending=false).index[0]
what is the campus that holds the highest number of degrees conferred over its whole existence?,degrees.groupby('campus').sum().sort_values(ascending=false).index[0]
which campus boasted the most of the faculty in 2003?,"pd.merge(campuses, faculty, left_on='id', right_on='campus').loc[lambda x: x['year']==2003].sort_values('faculty', ascending=false).iloc[0]['campus']"
how many faculties are affiliated with the campus in 2003?,"pd.merge(campuses, faculty, left_on='id', right_on='campus').loc[lambda x: x['year']==2003].sort_values('faculty', ascending=false).iloc[0]['campus']"
retrieve the average fee charged on a csu campus in the year 1996,"csu_fees.loc[lambda x: x['year']==1996, 'campusfee'].mean()"
give me the average fee for a csu campus in the year of 1996.,"csu_fees.loc[lambda x: x['year']==1996, 'campusfee'].mean()"
get the average fee charged by a csu campus in the year 2005.,"csu_fees.loc[lambda x: x['year']==2005, 'campusfee'].mean()"
obtain the average fee for a university campus in the year 2005.,"csu_fees.loc[lambda x: x['year']==2005, 'campusfee'].mean()"
provide the total count of degrees awarded between 1998 and 2002.,"degrees.loc[lambda x: (x['year'] >= 1998) & (x['year'] <= 2002)].merge(campuses, left_on='campus', right_on='id').groupby('campus')['degrees'].sum()"
what number of degrees were conferred between 1998 and 2002?,"degrees.loc[lambda x: (x['year'] >= 1998) & (x['year'] <= 2002)].merge(campuses, left_on='campus', right_on='id').groupby('campus')['degrees'].sum()"
"for each orange county campus, determine the count of degrees awarded after 2000.","degrees.loc[lambda x: x['year']>=2000].merge(campuses[campuses['county']=='orange'], left_on='campus', right_on='id').groupby('campus').agg({'degrees':'sum'}).reset_index().rename(columns={'campus':'campus', 'degrees':'sum'})[['campus', 'sum']]"
what are the counts and degree years for all orange county campuses after 2000?,"degrees.loc[lambda x: x['year']>=2000].merge(campuses[campuses['county']=='orange'], left_on='campus', right_on='id').groupby('campus').agg({'degrees':'sum'}).reset_index().rename(columns={'campus':'campus', 'degrees':'sum'})[['campus', 'sum']]"
"find the campus that has the most faculties in the year 2002, and the campus that is most equipped with faculties in orange country.","campuses.merge(faculty[faculty['year']==2002][['campus', 'faculty']]).query('year==2002 and faculty > @campuses.merge(faculty[faculty[""year""]==2002][[""campus"", ""faculty""]]).query(""year==2002 and county=='orange'"")[""faculty""].max()')['campus']"
retrieve the titles of campus that have more faculties in 2002 than the maximum number in orange county.,"campuses.merge(faculty[faculty['year']==2002][['campus', 'faculty']]).query('year==2002 and faculty > @campuses.merge(faculty[faculty[""year""]==2002][[""campus"", ""faculty""]]).query(""year==2002 and county=='orange'"")[""faculty""].max()')['campus']"
which university had more than 400 enrollment in total but also more than 200 full time enrollment in the year 1956?,"pd.merge(campuses, enrollments, left_on='id', right_on='campus').query('year == 1956 and totalenrollment_ay > 400 and fte_ay > 200')['campus']"
"retrieve the details about any campus that commenced operations during 1956, has more than 200 enrolled students, and more than 400 students enrolled.","pd.merge(campuses, enrollments, left_on='id', right_on='campus').query('year == 1956 and totalenrollment_ay > 400 and fte_ay > 200')['campus']"
how many campus sites are there in los angeles county?,(campuses['county'] == 'los angeles').sum()
how many campuses exist in the county of la?,(campuses['county'] == 'los angeles').sum()
please list the cities or cities including los angeles in california.,"campuses.loc[campuses['county']=='los angeles', 'campus']"
which campus is located in los angeles county?,"campuses.loc[campuses['county']=='los angeles', 'campus']"
"how many degrees were awarded by ""san jose state university"" in the year 2000?","pd.merge(campuses.loc[lambda x: x['campus'] == 'san jose state university'], degrees.loc[lambda x: x['year'] == 2000], left_on='id', right_on='campus')['degrees']"
in which year were most of the degrees conferred at san jose state university?,"pd.merge(campuses.loc[lambda x: x['campus'] == 'san jose state university'], degrees.loc[lambda x: x['year'] == 2000], left_on='id', right_on='campus')['degrees']"
"obtain the list of degrees conferred in ""san francisco state university"" in the year 2001.","pd.merge(campuses[campuses['campus'] == 'san francisco state university'], degrees[degrees['year']==2001], left_on='id', right_on='campus')['degrees']"
please list the degrees conferred in the year 2001 in san francisco state university.,"pd.merge(campuses[campuses['campus'] == 'san francisco state university'], degrees[degrees['year']==2001], left_on='id', right_on='campus')['degrees']"
how many faculty members are there in the year 2002?,"faculty.loc[lambda x: x['year']==2002, 'faculty'].sum()"
how many faculty members were working in the year 2002?,"faculty.loc[lambda x: x['year']==2002, 'faculty'].sum()"
"please provide me the count of faculty lines in campus ""long beach state university"" in the year 2002.","pd.merge(faculty, campuses, left_on='campus', right_on='id').loc[(faculty['year']==2002) & (campuses['campus']=='long beach state university'), 'faculty']"
how many faculty members were at long beach state university in the year 2002?,"pd.merge(faculty, campuses, left_on='campus', right_on='id').loc[(faculty['year']==2002) & (campuses['campus']=='long beach state university'), 'faculty']"
"how many faculty lines are there in ""san francisco state university"" in the year 2004?","pd.merge(faculty.loc[faculty['year']==2004], campuses.loc[campuses['campus']==""san francisco state university""], left_on='campus', right_on='id')['faculty']"
how many faculty lines are there in the san francisco state university in 2004?,"pd.merge(faculty.loc[faculty['year']==2004], campuses.loc[campuses['campus']==""san francisco state university""], left_on='campus', right_on='id')['faculty']"
display the names of campus having at least 600 and at most 1000 faculty members in the year 2004.,"pd.merge(campuses, faculty, left_on='id', right_on='campus').loc[lambda x: (x['faculty'] >= 600) & (x['faculty'] <= 1000) & (x['year'] == 2004), 'campus']"
determine the names of campuses that have between 600 and 1000 faculty members in 2004.,"pd.merge(campuses, faculty, left_on='id', right_on='campus').loc[lambda x: (x['faculty'] >= 600) & (x['faculty'] <= 1000) & (x['year'] == 2004), 'campus']"
which college at the institution granted the most of the degrees in the year 2002?,"(pd.merge(pd.merge(campuses, faculty, left_on='id', right_on='campus'),degrees,left_on=['id', 'year'],right_on=['campus', 'year']).loc[lambda x: x['year']==2002].sort_values('degrees', ascending=false).iloc[0]['faculty'])"
which university awarded the largest number of degrees in the year 2002?,"(pd.merge(pd.merge(campuses, faculty, left_on='id', right_on='campus'),degrees,left_on=['id', 'year'],right_on=['campus', 'year']).loc[lambda x: x['year']==2002].sort_values('degrees', ascending=false).iloc[0]['faculty'])"
"among the universities that gave the least number of degrees in 2001, how many faculty members did each university have?","pd.merge(pd.merge(campuses, faculty, left_on='id', right_on='campus'), degrees, left_on=['id', 'year'], right_on=['campus', 'year']).loc[lambda x: x['year']==2001].sort_values('degrees').iloc[0]['faculty']"
how many undergraduate students were part of san jose state university in the year 2004?,"pd.merge(discipline_enrollments, campuses, left_on='campus', right_on='id').loc[(discipline_enrollments['year'] == 2004) & (campuses['campus'] == 'san jose state university'), 'undergraduate'].sum()"
how many undergraduate students are there at san jose state university?,"pd.merge(discipline_enrollments, campuses, left_on='campus', right_on='id').loc[(discipline_enrollments['year'] == 2004) & (campuses['campus'] == 'san jose state university'), 'undergraduate'].sum()"
"how many students were graduated in the ""san francisco state university"" in 2004?","pd.merge(discipline_enrollments, campuses, left_on='campus', right_on='id').loc[(lambda x: (x['year']==2004) & (x['campus']=='san francisco state university')), 'graduate'].sum()"
provide the count of people who graduated from san francisco state university in the year 2004.,"pd.merge(discipline_enrollments, campuses, left_on='campus', right_on='id').loc[(lambda x: (x['year']==2004) & (x['campus']=='san francisco state university')), 'graduate'].sum()"
"what is the campus fee for ""san francisco state university"" in the year 2000?","pd.merge(csu_fees, campuses, left_on='campus', right_on='id').loc[(lambda x: x['campus']=='san francisco state university')(campuses) & (csu_fees['year']==2000)].iloc[0]['campusfee']"
in which year was the campus fee for san francisco state university highest?,"pd.merge(csu_fees, campuses, left_on='campus', right_on='id').loc[(lambda x: x['campus']=='san francisco state university')(campuses) & (csu_fees['year']==2000)].iloc[0]['campusfee']"
provide me the tuition fee collected by the san jose state university in the year 2000.,"pd.merge(csu_fees, campuses, left_on='campus', right_on='id').loc[(lambda x: x['campus']=='san jose state university')(df) & (df['year']==2000), 'campusfee']"
please retrieve the total fee that must be paid as campus fees for san jose state university for the year 2000.,"pd.merge(csu_fees, campuses, left_on='campus', right_on='id').loc[(lambda x: x['campus']=='san jose state university')(df) & (df['year']==2000), 'campusfee']"
how many campuses are there under the california state university system?,campuses.shape[0]
how many campuses are there in total?,campuses.shape[0]
what is the total number of candidates?,candidate.shape[0]
what is the count of candidates?,candidate.shape[0]
which polling resource provided the most information on candidates?,candidate.groupby('poll_source').size().sort_values(ascending=false).index[0]
please find me the poll resource with the greatest number of candidates.,candidate.groupby('poll_source').size().sort_values(ascending=false).index[0]
which support rate ids are the top three highest?,"candidate.sort_values('support_rate', ascending=false)['support_rate'].head(3)"
list the top 3 greatest support rates.,"candidate.sort_values('support_rate', ascending=false)['support_rate'].head(3)"
find the id of the candidate with lowest oppose rate.,candidate.sort_values('oppose_rate').iloc[0]['candidate_id']
please provide me with the candidate id with the lower oppose percentage.,candidate.sort_values('oppose_rate').iloc[0]['candidate_id']
"please list support, consider, and oppose rate in descending order by unsure rate.","candidate[['support_rate', 'consider_rate', 'oppose_rate']].sort_values('unsure_rate')"
"provide me the support, consider, and oppose rates, as ordered by their unsure rate.","candidate[['support_rate', 'consider_rate', 'oppose_rate']].sort_values('unsure_rate')"
which poll source has the highest oppose rate?,"candidate.sort_values('oppose_rate', ascending=false).iloc[0]['poll_source']"
please provide me with the source corresponding to the candidate having the oppose rate.,"candidate.sort_values('oppose_rate', ascending=false).iloc[0]['poll_source']"
"list all people names, in the chronological order of their date of birth, from old to young.",people.sort_values('date_of_birth')['name']
"provide the names of all people, sorted in the order of their birth dates.",people.sort_values('date_of_birth')['name']
calculate the average height and weight of all males (sex is m).,"people.loc[lambda x: x['sex']=='m', ['height', 'weight']].mean()"
calculate the mean height and weight across males (sex is m).,"people.loc[lambda x: x['sex']=='m', ['height', 'weight']].mean()"
retrieve the names of people who are larger than 200 cm or smaller than 190 cm.,"people.loc[(people['height'] > 200) | (people['height'] < 190), 'name']"
retrieve the names of individuals who fall in the height range 200 to 190.,"people.loc[(people['height'] > 200) | (people['height'] < 190), 'name']"
know the average and minimum weight of males and females.,"people.groupby('sex')['weight'].agg(['mean', 'min']).reset_index()"
what is the average and minimum value of weight for males and females?,"people.groupby('sex')['weight'].agg(['mean', 'min']).reset_index()"
obtain the name and gender of the candidate who received the highest support rate.,"people.merge(candidate, on='people_id').sort_values('support_rate', ascending=false)[['name', 'sex']].iloc[:1]"
please provide me with the name and sex of the candidate whose support rate is highest.,"people.merge(candidate, on='people_id').sort_values('support_rate', ascending=false)[['name', 'sex']].iloc[:1]"
find the title of the candidates whose percentage of opposition is the lowest for each sex.,"pd.merge(people, candidate, on='people_id').groupby('sex').agg({'name': 'first', 'sex': 'first', 'oppose_rate': 'min'}).reset_index(drop=true)"
"for each sex, what is the full name and sex of the candidate whose vote is opposite to that sex's?","pd.merge(people, candidate, on='people_id').groupby('sex').agg({'name': 'first', 'sex': 'first', 'oppose_rate': 'min'}).reset_index(drop=true)"
who has the highest uncertain ratio.,"pd.merge(people, candidate, on='people_id').groupby('sex').agg(avg_unsure_rate=('unsure_rate', 'mean')).sort_values('avg_unsure_rate', ascending=false).iloc[[0]].index.reshape(-1)"
what is the percentage of candidates that have the highest rate of being unsure about their sex?,"pd.merge(people, candidate, on='people_id').groupby('sex').agg(avg_unsure_rate=('unsure_rate', 'mean')).sort_values('avg_unsure_rate', ascending=false).iloc[[0]].index.reshape(-1)"
retrieve the names of people who did not participate in the candidates' elections.,"people.loc[~people['people_id'].isin(candidate['people_id']), 'name']"
please provide me with the names of individuals who did not participate in the candidate election.,"people.loc[~people['people_id'].isin(candidate['people_id']), 'name']"
retrieve the names of the candidates whose support rating is below their oppose rating.,"pd.merge(people, candidate, on='people_id').loc[lambda x: x['support_rate'] < x['oppose_rate'], 'name']"
which candidate names have a lower rating for support compared to their rating for opposition?,"pd.merge(people, candidate, on='people_id').loc[lambda x: x['support_rate'] < x['oppose_rate'], 'name']"
how many males and females are overweight?,people[people['weight'] > 85].groupby('sex').size()
provide me the count of male and female people with a weight higher than 85.,people[people['weight'] > 85].groupby('sex').size()
"count the politicians whose support rate is higher than 60%, consider rate is lower than 30%, and oppose rate is lower than 30%.","candidate.agg({'support_rate': 'max', 'consider_rate': 'min', 'oppose_rate': 'min'})"
return a list of female names (whose sex is f) in alphabetically order.,"pd.merge(people, candidate, on='people_id').loc[lambda x: x['sex']=='f'].sort_values('name')['name']"
please list the names of all female candidates in alphabetical order.,"pd.merge(people, candidate, on='people_id').loc[lambda x: x['sex']=='f'].sort_values('name')['name']"
find the names of people whose height is lower than the mean.,"people.loc[lambda x: x['height'] < x['height'].mean(), 'name']"
please return the names of people shorter than average.,"people.loc[lambda x: x['height'] < x['height'].mean(), 'name']"
return me the details about all individuals.,people
"list out the names of all people along with their age, gender and place of residence.",people
return me the list of movies directed and produced by steven spielburg.,"movie.loc[lambda x: x['director']=='steven spielberg', 'title']"
retrieve the titles of all movies directed by steven spielberg.,"movie.loc[lambda x: x['director']=='steven spielberg', 'title']"
what is the movie produced by james cameron and directed by him from 2000 onward?,"movie.loc[(movie['director']=='james cameron') & (movie['year']>2000), 'title']"
what is the title of all movies that james cameron directed after 2000?,"movie.loc[(movie['director']=='james cameron') & (movie['year']>2000), 'title']"
what were the number of movies made before the year 2000?,(movie['year'] < 2000).sum()
what year led to the creation of most movies?,(movie['year'] < 2000).sum()
provide the name of the director of movie avatar.,"movie.loc[lambda x: x['title']=='avatar', 'director']"
who is the director of avatar?,"movie.loc[lambda x: x['title']=='avatar', 'director']"
how many reviewers were there?,reviewer.shape[0]
how many reviewers are involved in the process?,reviewer.shape[0]
what is the id of the reviewer whose name matches substring “mike”?,"reviewer.loc[reviewer['name'].str.contains('mike'), 'rid']"
"retrieve the id of reviewer whose name includes the word ""mike"".","reviewer.loc[reviewer['name'].str.contains('mike'), 'rid']"
please provide me with the reviewer ids of all scientists who have reviewed daniel lewis's paper.,"reviewer.loc[lambda x: x['name']=='daniel lewis', 'rid']"
what is the document id of the reviewer daniel lewis?,"reviewer.loc[lambda x: x['name']=='daniel lewis', 'rid']"
what is the count of ratings that have more than 3 stars?,(rating['stars'] > 3).sum()
how many movies have received ratings between 3 and 4 stars?,(rating['stars'] > 3).sum()
what is the rating range for 1 star and 5 stars?,"rating['stars'].agg(['max', 'min'])"
what is the max and min number of stars a rating can receive?,"rating['stars'].agg(['max', 'min'])"
"provide the year-wise list of movie titles that got a rating of 4 or 5, arranged in increasing order.","pd.merge(movie, rating, on='mid').loc[lambda x: x['stars']>=4, 'year'].sort_values().unique()"
list the years of a movie that received a 4 or 5 star rating from oldest to most recently.,"pd.merge(movie, rating, on='mid').loc[lambda x: x['stars']>=4, 'year'].sort_values().unique()"
"return the names of directors who directed films with a rating of 5, and also return the title of those movies.","pd.merge(movie, rating, on='mid').loc[lambda x: x['stars']==5, ['director', 'title']]"
find the names of directors who created a movie with a rating of 5 stars.,"pd.merge(movie, rating, on='mid').loc[lambda x: x['stars']==5, ['director', 'title']]"
what is the mean rating star for each reviewer?,"pd.merge(rating, reviewer, on='rid').groupby('name')['stars'].mean()"
find the average rating that each reviewer gives to a movie.,"pd.merge(rating, reviewer, on='rid').groupby('name')['stars'].mean()"
retrieve the titles of all movies that have a score of zero.,"movie.loc[~movie['mid'].isin(rating['mid']), 'title']"
what are the titles of all movies that have never been rated?,"movie.loc[~movie['mid'].isin(rating['mid']), 'title']"
return the titles for reviewers whose rating dates for several objects have a null value.,"pd.merge(reviewer, rating, on='rid').loc[lambda x: x['ratingdate']=='null', 'name'].unique()"
what names are listed for all reviewers of papers with no date field on their ratings?,"pd.merge(reviewer, rating, on='rid').loc[lambda x: x['ratingdate']=='null', 'name'].unique()"
what is the title of the most recently produced movie?,"movie.loc[movie['year'] == movie['year'].max(), 'title']"
what is the title for the most recently-released movie?,"movie.loc[movie['year'] == movie['year'].max(), 'title']"
what is the year and maximum stars for the most recent movie?,"rating.merge(movie.query('year == @movie.year.max()'), on='mid').agg({'stars': 'max', 'year': 'first'})"
what was the highest rating for the most recent movie and what was the release date?,"rating.merge(movie.query('year == @movie.year.max()'), on='mid').agg({'stars': 'max', 'year': 'first'})"
fetch the names of the movies that don't have directors after steven spielberg.,"movie.loc[lambda x: x['year'] > movie.loc[lambda y: y['director'] == 'steven spielberg', 'year'].max(), 'title']"
obtain the titles of movies whose stars are greater than the average stars of movies directed by james cameron.,"movie.merge(rating, on='mid').loc[lambda x: x['stars']>x.merge(movie, on='mid').loc[lambda y: y['director']=='james cameron','stars'].mean(), ['title','director']].drop_duplicates().reset_index(drop=true)"
"obtain the title, director, and rating of all movies that surpass james cameron's average rating.","movie.merge(rating, on='mid').loc[lambda x: x['stars']>x.merge(movie, on='mid').loc[lambda y: y['director']=='james cameron','stars'].mean(), ['title','director']].drop_duplicates().reset_index(drop=true)"
"sort the data first by reviewer name, then by movie title, and lastly by number of stars.","pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').sort_values(['name', 'title', 'stars'])[['name', 'title', 'stars', 'ratingdate']]"
"retrieve the reviewer name, movie title, movie rating, movie rating date, and movie rating value for every movie ordered by their reviewer name, title, rating, then rating date.","pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').sort_values(['name', 'title', 'stars'])[['name', 'title', 'stars', 'ratingdate']]"
retrieve the titles of reviewers who have provided three or more ratings.,"pd.merge(rating, reviewer, on='rid').groupby('rid').filter(lambda x: len(x) >= 3)['name']"
retrieve the names of all reviewers that have rated 3 or more movies.,"pd.merge(rating, reviewer, on='rid').groupby('rid').filter(lambda x: len(x) >= 3)['name']"
retrieve the names of all the individuals who rated gone with the wind.,"pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: x['title']=='gone with the wind', 'name'].unique()"
list down the names of all the,"pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: x['title']=='gone with the wind', 'name'].unique()"
retrieve the names of directors whose movies were rated by sarah martinez.,"pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: x['name']=='sarah martinez', 'director'].unique()"
identify the names of directors whose movies were reviewed by sarah martinez.,"pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: x['name']=='sarah martinez', 'director'].unique()"
"for each movie rating that has the same reviewer name as the movie director, return the movie title, number of stars, and reviewer name.","pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: x['director']==x['name'], ['name', 'title', 'stars']].drop_duplicates()"
"for each rating, give me the reviewer name, movie title and star name where the reviewer is the director.","pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: x['director']==x['name'], ['name', 'title', 'stars']].drop_duplicates()"
please return the names of movie reviewers and movies together in a single list.,"pd.concat([reviewer['name'], movie['title']]).reset_index(drop=true)"
retrieve the names of all the reviewers along with the movie names.,"pd.concat([reviewer['name'], movie['title']]).reset_index(drop=true)"
provide me the labels of all movies that are not reviewed by chris jackson.,"movie['title'].unique().tolist() - pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: x['name']=='chris jackson', 'title'].tolist()"
list the titles of movies that chris jackson has not reviewed.,"movie['title'].unique().tolist() - pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: x['name']=='chris jackson', 'title'].tolist()"
"for all directors who have directed two or more movies, list the movies they have directed along with their names.","movie.merge(movie, on='director').loc[lambda x: x['title_x'] != x['title_y'], ['title_x', 'director']].rename(columns={'title_x': 'title'}).sort_values(['director', 'title'])"
"for directors who had more than one movie, please return the title and the year in which each movie was produced.","movie.merge(movie, on='director', suffixes=('_1', '_2')).loc[lambda x: x['title_1'] != x['title_2'], ['title_1', 'year_1']]"
what were all the films directed by a particular person and when were they released?,"movie.merge(movie, on='director', suffixes=('_1', '_2')).loc[lambda x: x['title_1'] != x['title_2'], ['title_1', 'year_1']]"
"given the names of directors who made only one movie, retrieve their names.",movie.groupby('director').filter(lambda x: len(x)==1)['director'].unique()
find the names of the directors who produced one film.,movie.groupby('director').filter(lambda x: len(x)==1)['director'].unique()
retrieve the names and films of directors who made exactly one motion picture excluding directors that do not exist.,movie[movie['director'].notnull()].groupby('director').filter(lambda x: len(x)==1)['director']
retrieve the names of all directors who have made one movie except for the director named null,movie[movie['director'].notnull()].groupby('director').filter(lambda x: len(x)==1)['director']
what is the count of movie reviews that each director receives?,"pd.merge(movie, rating, on='mid').groupby('director').size().reset_index(name='count')"
"for each director, how many reviews has he or she received?","pd.merge(movie, rating, on='mid').groupby('director').size().reset_index(name='count')"
provide me with the titles of movies and their average ratings.,"pd.merge(rating, movie, on='mid').groupby('mid').agg({'title': 'first', 'stars': 'mean'}).sort_values('stars', ascending=false).iloc[0]"
retrieve the names of movies with the highest average rating and their respective ratings.,"pd.merge(rating, movie, on='mid').groupby('mid').agg({'title': 'first', 'stars': 'mean'}).sort_values('stars', ascending=false).iloc[0]"
determine the titles of movies that are rated the lowest as well as the ratings of those movies.,"pd.merge(rating, movie, on='mid').groupby('mid').agg(avg_stars=('stars', 'mean'), title=('title', 'first')).sort_values('avg_stars').head(1)[['title', 'avg_stars']]"
list the names and average ratings for all movies that have the lowest rate.,"pd.merge(rating, movie, on='mid').groupby('mid').agg(avg_stars=('stars', 'mean'), title=('title', 'first')).sort_values('avg_stars').head(1)[['title', 'avg_stars']]"
retrieve the years of movies that are most highly rated.,"rating.merge(movie, on='mid')[['title', 'year', 'stars']].sort_values('stars', ascending=false).head(3)[['title', 'year']]"
fetch the names of the movies and the year of their release that have the three highest ratings.,"rating.merge(movie, on='mid')[['title', 'year', 'stars']].sort_values('stars', ascending=false).head(3)[['title', 'year']]"
"for each director, list the titles and ratings of all the movies they reviewed.","rating.merge(movie[movie['director']!='null'], on='mid').groupby('director').agg({'title':'first', 'stars':'max'}).reset_index()[['title', 'stars', 'director']]"
list the title and rating for each movie that is reviewed by each reviewer.,"rating.merge(movie, on='mid').groupby('rid').agg({'title': 'first', 'stars': ['first', 'min']}).droplevel(level=0, axis=1).rename(columns={'first': 'stars', 'min': 'min_stars'})"
"please provide me with the titles, the ratings and the respective reviewer ids for which a movie with the smallest rating is gotten.","rating.merge(movie, on='mid').groupby('rid').agg({'title': 'first', 'stars': ['first', 'min']}).droplevel(level=0, axis=1).rename(columns={'first': 'stars', 'min': 'min_stars'})"
retrieve the title and ranking of the movie with the lowest total rating among all movies directed by each director.,"pd.merge(rating, movie, on='mid').groupby('director').agg({'title':'first', 'stars':'min'}).reset_index()[['title', 'stars', 'director']]"
"for each director, what are the most poorly-rated movie with their scores?","pd.merge(rating, movie, on='mid').groupby('director').agg({'title':'first', 'stars':'min'}).reset_index()[['title', 'stars', 'director']]"
what is the name of the movie that is rated by most users most frequently?,"movie.merge(rating).groupby(['mid', 'title'])['rating'].count().reset_index().sort_values('rating', ascending=false).iloc[0][['title', 'mid']]"
what is the best-selling film?,"movie.merge(rating).groupby(['mid', 'title'])['rating'].count().reset_index().sort_values('rating', ascending=false).iloc[0][['title', 'mid']]"
how many movies have rating stars between 3 and 5?,"pd.merge(rating, movie, on='mid').loc[lambda x: x['stars'].between(3, 5), 'title']"
how many movies have between 3 and 5 stars?,"pd.merge(rating, movie, on='mid').loc[lambda x: x['stars'].between(3, 5), 'title']"
retrieve the names of reviewers who had given ratings higher than 3 stars.,"pd.merge(rating, reviewer, on='rid').loc[lambda x: x['stars'] > 3, 'name']"
what were the names of the reviewers who rated a movie more than 3 stars in the past?,"pd.merge(rating, reviewer, on='rid').loc[lambda x: x['stars'] > 3, 'name']"
retrieve the ids of movies that are not reviewed by brittany harris.,"rating[~rating['rid'].isin(pd.merge(rating, reviewer.loc[reviewer['name'] == 'brittany harris'], on='rid')['mid'])]['mid']"
what is the count of all the movies that have never been reviewed by britanny harris?,"rating[~rating['rid'].isin(pd.merge(rating, reviewer.loc[reviewer['name'] == 'brittany harris'], on='rid')['mid'])]['mid']"
calculate the average rating of all movies that got at least 2 reviews.,rating.groupby('mid')['stars'].filter(lambda x: len(x)>=2).groupby('mid').mean()
in which movies were more than 3 reviews received and what was the average rating for each movie?,rating.groupby('mid')['stars'].filter(lambda x: len(x)>=2).groupby('mid').mean()
retrieve the ids of reviewers that rated a product with fewer than 4 stars.,"rating.loc[lambda x: x['stars'] != 4, 'rid']"
what are the ids of all the reviewers who gave less than or equal to 4 stars?,"rating.loc[lambda x: x['stars'] != 4, 'rid']"
"what is the number of reviewers who gave a 4-star rating but did not mark ""excellent""?","rating.loc[lambda x: x['stars'] != 4, 'rid']"
i require the list of ids of all reviewers who did not give 4 stars at least once.,"rating.loc[lambda x: x['stars'] != 4, 'rid']"
find the names of movies that either premiered after 2000 or were reviewed by brittany harris.,"pd.merge(pd.merge(rating, movie, on='mid'), reviewer, on='rid').loc[lambda x: (x['name']=='brittany harris') | (x['year']>2000), 'title'].unique()"
find the names of movies produced before 1980 or directed by james cameron.,"movie.loc[(movie['director'] == 'james cameron') | (movie['year'] < 1980), 'title']"
"retrieve the names of the movies that did not become renowned before the year 1980, or had james cameron as their director.","movie.loc[(movie['director'] == 'james cameron') | (movie['year'] < 1980), 'title']"
retrieve the names of the reviewers who rated 3 stars and 4 stars.,"pd.merge(rating.loc[lambda x: x['stars'] == 3, ['rid']], reviewer, on='rid')['name'].intersect(pd.merge(rating.loc[lambda x: x['stars'] == 4, ['rid']], reviewer, on='rid')['name'])"
retrieve the names of all reviewers that have awarded 3 or 4 stars to (at least) one review.,"pd.merge(rating.loc[lambda x: x['stars'] == 3, ['rid']], reviewer, on='rid')['name'].intersect(pd.merge(rating.loc[lambda x: x['stars'] == 4, ['rid']], reviewer, on='rid')['name'])"
provide me the names of movies that received 3-star and 4-star ratings.,"pd.merge(rating.loc[lambda x: x['stars']==3], movie,on='mid', suffixes=['_rating', '_movie'])['title'].pipe(lambda x: x[np.in1d(x, pd.merge(rating.loc[lambda x: x['stars']==4], movie,on='mid', suffixes=['_rating', '_movie'])['title'].unique())])"
please find the names of movies that received 3 or 4 stars.,"pd.merge(rating.loc[lambda x: x['stars']==3], movie,on='mid', suffixes=['_rating', '_movie'])['title'].pipe(lambda x: x[np.in1d(x, pd.merge(rating.loc[lambda x: x['stars']==4], movie,on='mid', suffixes=['_rating', '_movie'])['title'].unique())])"
how many counties are there in the united states?,county_public_safety.shape[0]
count the number of nations.,county_public_safety.shape[0]
list the counties by descending order of population.,"county_public_safety.sort_values('population', ascending=false)['name']"
order the counties of public safety according to descending population.,"county_public_safety.sort_values('population', ascending=false)['name']"
provide me with the names and locations of counties whose police forces are not located on the east.,"county_public_safety.loc[lambda x: x['location'] != 'east', 'police_force'].unique()"
what are the different police departments of counties that are not located in the east?,"county_public_safety.loc[lambda x: x['location'] != 'east', 'police_force'].unique()"
what are the minimum and maximum crime rates,"county_public_safety['crime_rate'].agg(['min', 'max'])"
provide me with the minimum and maximum crime rates across counties.,"county_public_safety['crime_rate'].agg(['min', 'max'])"
arrange the counties in descending order of crime rate and the number of police officers.,county_public_safety.sort_values('police_officers')['crime_rate']
what is the crime rate of counties sorted by number of offices ascending?,county_public_safety.sort_values('police_officers')['crime_rate']
retrieve the title of cities in ascending alphabetical order.,city.sort_values('name')['name']
enumerate the names of cities that are in alphabetical order.,city.sort_values('name')['name']
what percentage of hispanics live in the city where black residents are more than 10%?,"city.loc[lambda x: x['black'] > 10, 'hispanic']"
provide me with the hispanic percentage for the cities in which the black percentage is greater than or equal to 10.,"city.loc[lambda x: x['black'] > 10, 'hispanic']"
provide me with the name of the county with the largest population.,"county_public_safety.sort_values('population', ascending=false).iloc[0]['name']"
what is the title or name of a county that has the greatest population?,"county_public_safety.sort_values('population', ascending=false).iloc[0]['name']"
find out the names of cities with the highest white population percentage.,"city.sort_values('white', ascending=false)['name'].head(5)"
which cities are those that comprise the largest proportion of white people?,"city.sort_values('white', ascending=false)['name'].head(5)"
list the names of cities and name of counties each is in.,"pd.merge(city[['name', 'county_id']], county_public_safety[['name', 'county_id']], on='county_id')"
deliver to me the crime rates of cities along with the white percentages they are in.,"pd.merge(city, county_public_safety, on='county_id')[['white', 'crime_rate']]"
what is the white percentage of each county and the corresponding crime rates?,"pd.merge(city, county_public_safety, on='county_id')[['white', 'crime_rate']]"
please list the names of cities in the county that have more police officers.,"city.loc[lambda x: x['county_id'] == county_public_safety.sort_values('police_officers', ascending=false)['county_id'].iloc[0], 'name']"
provide me the names or titles of cities that are in the largest counties in terms of police officers.,"city.loc[lambda x: x['county_id'] == county_public_safety.sort_values('police_officers', ascending=false)['county_id'].iloc[0], 'name']"
give me the names of cities within counties that have populations exceeding 20000.,"city.loc[city['county_id'].isin(county_public_safety.loc[lambda x: x['population'] > 20000, 'county_id']), :].shape[0]"
"what percentage of counties contain more than 20,000 residents?","city.loc[city['county_id'].isin(county_public_safety.loc[lambda x: x['population'] > 20000, 'county_id']), :].shape[0]"
retrieve every county’s crime rate with a city having white population percentage greater than 90.,"pd.merge(city, county_public_safety, on='county_id').loc[lambda x: x['white'] > 90, 'crime_rate']"
what is the crime rate of counties that house cities which have white percentages higher than 90?,"pd.merge(city, county_public_safety, on='county_id').loc[lambda x: x['white'] > 90, 'crime_rate']"
could you provide the count of police forces and the number of counties per police force?,county_public_safety.groupby('police_force').size()
how many counties are linked with each of our police forces?,county_public_safety.groupby('police_force').size()
what common location is found mostly in the counties?,county_public_safety.groupby('location').size().sort_values(ascending=false).index[0]
which location has the most cities having counties?,county_public_safety.groupby('location').size().sort_values(ascending=false).index[0]
display the names and titles of the counties that have no cities.,"county_public_safety.loc[~county_public_safety['county_id'].isin(city['county_id']), 'name']"
retrieve the titles of all counties that do not possess any cities.,"county_public_safety.loc[~county_public_safety['county_id'].isin(city['county_id']), 'name']"
what is the number of counties that share law enforcement resources?,"set(county_public_safety.loc[lambda x: x['location']=='east', 'police_force']).intersection(set(county_public_safety.loc[lambda x: x['location']=='west', 'police_force']))"
which police forces operate in both the counties that are located in the east and in the west?,"set(county_public_safety.loc[lambda x: x['location']=='east', 'police_force']).intersection(set(county_public_safety.loc[lambda x: x['location']=='west', 'police_force']))"
list out the names of cities that are situated in the counties having a crime rate less than 100.,"city.loc[city['county_id'].isin(county_public_safety.loc[county_public_safety['crime_rate'] < 100, 'county_id']), 'name']"
what are the titles of cities that are in counties that have a crime rate below 100?,"city.loc[city['county_id'].isin(county_public_safety.loc[county_public_safety['crime_rate'] < 100, 'county_id']), 'name']"
show the populations of counties in ascending order.,"county_public_safety.sort_values('population', ascending=false)['case_burden']"
"sort the case burdens of counties, lowest first, with ascending population.","county_public_safety.sort_values('population', ascending=false)['case_burden']"
retrieve the names of all modern rooms that cost less than $160 and are furnished with two beds.,"rooms.loc[(rooms['baseprice'] < 160) & (rooms['beds'] == 2) & (rooms['decor'] == 'modern'), 'roomname']"
give me the names of modern rooms that have a base price lower than $160 and two beds.,"rooms.loc[(rooms['baseprice'] < 160) & (rooms['beds'] == 2) & (rooms['decor'] == 'modern'), 'roomname']"
please show the room ids and names of those rooms that have a high rental cost and can accommodate more than 2 people.,"rooms.loc[(rooms['baseprice'] > 160) & (rooms['maxoccupancy'] > 2), ['roomname', 'roomid']]"
provide me the room names and ids of all rooms that cost over 160 and have more than two people.,"rooms.loc[(rooms['baseprice'] > 160) & (rooms['maxoccupancy'] > 2), ['roomname', 'roomid']]"
what room is most popular among the available rooms in the hotel?,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').groupby('roomname').size().nlargest(1).index[0]"
which room has the highest number of reservations?,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').groupby('roomname').size().nlargest(1).index[0]"
what are the count of kids that stay in rooms reserved by roy swazzy?,"reservations.loc[(reservations['firstname']=='roy') & (reservations['lastname']=='sweazy'), 'kids']"
determine the total number of kids staying in rooms reserved by a person called roy sweez.,"reservations.loc[(reservations['firstname']=='roy') & (reservations['lastname']=='sweazy'), 'kids']"
how many reservations did roy sweazy made?,((reservations['firstname']=='roy') & (reservations['lastname']=='sweazy')).sum()
provide me with the count of times roy sweazy has reserved a room.,((reservations['firstname']=='roy') & (reservations['lastname']=='sweazy')).sum()
determine the rooms that have the highest rates.,"reservations.merge(rooms, left_on='room', right_on='roomid').groupby('room')[['rate', 'checkin', 'checkout', 'roomname']].max().sort_values('rate', ascending=false).iloc[0]"
find the name and dates for the hotel room that possessed the highest rate.,"reservations.merge(rooms, left_on='room', right_on='roomid').groupby('room')[['rate', 'checkin', 'checkout', 'roomname']].max().sort_values('rate', ascending=false).iloc[0]"
"what is the count of adult guests that booked room conrad selbig on oct 23, 2010?","reservations.loc[(reservations['checkin'] == '2010-10-23') & (reservations['firstname'] == 'conrad') & (reservations['lastname'] == 'selbig'), 'adults']"
"provide me the total count of adults for the room that was reserved and checked in on oct 23, 2010 by conrad selbig.","reservations.loc[(reservations['checkin'] == '2010-10-23') & (reservations['firstname'] == 'conrad') & (reservations['lastname'] == 'selbig'), 'adults']"
"how many kids stayed in the room damien trachsel checked in on sep 21, 2010?","reservations.loc[(reservations['checkin']=='2010-09-21')&(reservations['firstname']=='damien')&(reservations['lastname']=='trachsel'), 'kids']"
"provide me with the count of kids for the room reserved and checked in by damien trachsel on  sep 21, 2010.","reservations.loc[(reservations['checkin']=='2010-09-21')&(reservations['firstname']=='damien')&(reservations['lastname']=='trachsel'), 'kids']"
how many king-sized beds are there?,"rooms.loc[lambda x: x['bedtype']=='king', 'beds'].sum()"
how many king sized beds are available for sale?,"rooms.loc[lambda x: x['bedtype']=='king', 'beds'].sum()"
list the title of rooms that have a king size bed as well as their decor and price. sort the records in descending order of price.,"rooms.loc[lambda x: x['bedtype']=='king'].sort_values('baseprice')[['roomname', 'decor']]"
"return the titles, names, and decor of rooms with a king bed whose prices aren't higher than 70 dollars. they must be sorted in order of ascending price.","rooms.loc[lambda x: x['bedtype']=='king'].sort_values('baseprice')[['roomname', 'decor']]"
list the name of the room whose base price is equal to the cheapest.,"rooms[['roomname', 'baseprice']].sort_values('baseprice').iloc[0]"
what is the name and the rates of rooms whose rates are the lowest?,"rooms[['roomname', 'baseprice']].sort_values('baseprice').iloc[0]"
"please provide me with the description of the decor of the room named ""recluse and defiance"".","rooms.loc[lambda x: x['roomname']=='recluse and defiance', 'decor']"
"for each bed type, calculate the average price for that type.",rooms.groupby('bedtype')['baseprice'].mean()
how many guests could reside in the modern rooms in this inn?,"rooms.loc[lambda x: x['decor']=='modern', 'maxoccupancy'].sum()"
how many persons in total can stay in the modern rooms of the inn?,"rooms.loc[lambda x: x['decor']=='modern', 'maxoccupancy'].sum()"
which decor has the least number of reservations?,"reservations.merge(rooms, left_on='room', right_on='roomid').groupby('decor')['decor'].count().sort_values().head(1).index[0]"
what is the decor which has the lowest popularity?,"reservations.merge(rooms, left_on='room', right_on='roomid').groupby('decor')['decor'].count().sort_values().head(1).index[0]"
list the number of times the number of people in the room reaches the maximum occupancy of the room. the number of people include adults and kids.,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').eval(""maxoccupancy == adults + kids"").sum()"
count the number of adults who were staying in a room with kids reaching the maximum capacity of the room first.,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').eval(""maxoccupancy == adults + kids"").sum()"
provide me the first and last names of the guests who paid more than the room's base price.,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').loc[lambda x: x['rate']-x['baseprice']>0, ['firstname', 'lastname']]"
list the first and last names of the individuals who paid more than the rooms' base price.,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').loc[lambda x: x['rate']-x['baseprice']>0, ['firstname', 'lastname']]"
what number of rooms are provided in this hotel?,rooms.shape[0]
please count how many rooms contain a king bed.,sum(rooms['bedtype'] == 'king')
what is the count of rooms having a king bed?,sum(rooms['bedtype'] == 'king')
determine the total number of bedrooms in each bed type.,rooms.groupby('bedtype').size()
how many rooms are there for each bed type?,rooms.groupby('bedtype').size()
retrieve the id of rooms with the maximum occupancy.,"rooms.loc[rooms['maxoccupancy'].idxmax(), 'roomname']"
what is the room that hosts the maximum people called?,"rooms.loc[rooms['maxoccupancy'].idxmax(), 'roomname']"
what room has the highest price?,"rooms[['roomid', 'roomname']].sort_values('baseprice', ascending=false).head(1)"
what is the highest base price of a room?,"rooms[['roomid', 'roomname']].sort_values('baseprice', ascending=false).head(1)"
list the titles of beds and the names of all traditional rooms.,"rooms.loc[lambda x: x['decor']=='traditional', ['roomname', 'bedtype']]"
list the pertinent information about all bed types and rooms that are characterized as traditional decor.,"rooms.loc[lambda x: x['decor']=='traditional', ['roomname', 'bedtype']]"
determine the count of rooms with king bed for each decor type.,rooms[rooms['bedtype']=='king'].groupby('decor').size()
please provide me with the number of rooms with king beds for each decor.,rooms[rooms['bedtype']=='king'].groupby('decor').size()
please provide me with the average and minimum cost of rooms in different decor.,"rooms.groupby('decor')['baseprice'].agg(['mean','min']).reset_index()"
what is the average price and count of rooms for each different decoration?,"rooms.groupby('decor')['baseprice'].agg(['mean','min']).reset_index()"
sort the names of all rooms by their corresponding prices.,rooms.sort_values('baseprice')['roomname']
sort all the rooms with respect to the price. just present the room names.,rooms.sort_values('baseprice')['roomname']
retrieve the count of rooms that are priced higher than 120 for different decor.,rooms.loc[lambda x: x['baseprice'] > 120].groupby('decor').size()
"provide me with the count of rooms that cost more than $120, for each different decor.",rooms.loc[lambda x: x['baseprice'] > 120].groupby('decor').size()
"for each bed type, retrieve the average room price.",rooms.groupby('bedtype')['baseprice'].mean()
"what are the average base prices of rooms, for each bed type?",rooms.groupby('bedtype')['baseprice'].mean()
list the titles of rooms that are provided with king or queen bed.,"rooms.loc[lambda x: x['bedtype'].isin(['king', 'queen']), 'roomname']"
provide the list of rooms that have a king size or queen-sized bed.,"rooms.loc[lambda x: x['bedtype'].isin(['king', 'queen']), 'roomname']"
what is the count of different types of beds?,rooms['bedtype'].nunique()
determine the number of distinct types of beds that are present within this bed and breakfast.,rooms['bedtype'].nunique()
list the names of the 3 most expensive rooms along with their corresponding ids.,"rooms[['roomid', 'roomname']].sort_values('baseprice', ascending=false).head(3)"
what are the names and ids of the three highest priced rooms?,"rooms[['roomid', 'roomname']].sort_values('baseprice', ascending=false).head(3)"
find the names of rooms that are more expensive than the average.,"rooms.loc[lambda x: x['baseprice'] > x['baseprice'].mean(), 'roomname']"
what are the names of the rooms that are more expensive than the average?,"rooms.loc[lambda x: x['baseprice'] > x['baseprice'].mean(), 'roomname']"
what is the number of rooms that have no reservations?,rooms.loc[~rooms['roomid'].isin(reservations['room'].unique())].shape[0]
what is the count of rooms that have had no reservation so far?,rooms.loc[~rooms['roomid'].isin(reservations['room'].unique())].shape[0]
"for each room, i have to find its name and the number of reservations made in its favor.","pd.merge(reservations, rooms, left_on='room', right_on='roomid').groupby('room')[['roomname', 'room']].agg({'roomname': 'first', 'room': 'count'}).reset_index()[['roomname', 'room', 'count']]"
retrieve titles of rooms that are reserved by guests for more than 60 times.,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').groupby('room').filter(lambda x: len(x) > 60)['roomname'].unique()"
retrieve the titles of rooms whose reservation frequency exceeds 60 times.,"pd.merge(reservations, rooms, left_on='room', right_on='roomid').groupby('room').filter(lambda x: len(x) > 60)['roomname'].unique()"
extract the names of rooms whose base price is between 120 and 150.,"rooms.loc[lambda x: (x['baseprice'] >= 120) & (x['baseprice'] <= 150), 'roomname']"
which rooms that are between 120 and 150? give me the room names.,"rooms.loc[lambda x: (x['baseprice'] >= 120) & (x['baseprice'] <= 150), 'roomname']"
retrieve the name of rooms booked by some of the customers who have first name beginning with roy.,rooms[rooms['roomid'].isin(reservations[reservations['firstname'].str.contains('roy')]['room'])]['roomname']
"provide me with the names of rooms that customers whose first name have ""roy"" in part have reserved.",rooms[rooms['roomid'].isin(reservations[reservations['firstname'].str.contains('roy')]['room'])]['roomname']
which cmi masters have the cross reference code 'tax'?,"pd.merge(customer_master_index, cmi_cross_references.loc[lambda x: x['source_system_code']=='tax'], on='master_customer_id')['cmi_details']"
"find the codes that are connected to at least one council tax entry. also, display the source system code associated with those codes.","pd.merge(cmi_cross_references, council_tax, on='cmi_cross_ref_id').groupby('cmi_cross_ref_id').filter(lambda x: len(x) >= 1)[['cmi_cross_ref_id', 'source_system_code']]"
"list the ids for the cross reference, master customer id and the count.","business_rates.merge(cmi_cross_references, on='cmi_cross_ref_id').groupby('cmi_cross_ref_id').agg(count=('cmi_cross_ref_id', 'count'), master_customer_id=('master_customer_id', 'first'))[['master_customer_id', 'count']]"
what are the tax source type numbers as well as the corresponding customer ids for all taxes related to each parking fine id number?,"pd.merge(cmi_cross_references, parking_fines, on='cmi_cross_ref_id')[['source_system_code', 'master_customer_id', 'council_tax_id']]"
"what rental arrears tax ids are related to the customer master index whose details are not 'schmidt, kertzmann and lubowitz'?","rent_arrears.merge(cmi_cross_references, on='cmi_cross_ref_id').merge(customer_master_index, on='master_customer_id').loc[lambda x: x['cmi_details']!=""schmidt ,kertzmann and lubowitz"", 'council_tax_id']"
what is the count of electoral registry ids that have the cross reference source system code 'electoral' or 'tax'?,"pd.merge(electoral_register, cmi_cross_references.loc[cmi_cross_references['source_system_code'].isin(['electoral', 'tax'])], on='cmi_cross_ref_id')['electoral_register_id']"
can you provide me the count of source system codes that are used in the cmi cross references?,cmi_cross_references['source_system_code'].nunique()
"please present me the information about customer master index, sorted by the details in descending order.","customer_master_index.sort_values('cmi_details', ascending=false)"
list the council tax ids and the related cmi cross references to parking fines.,"parking_fines[['council_tax_id', 'cmi_cross_ref_id']]"
please provide me with the number of council taxes that are collected due to renting arrears.,rent_arrears.shape[0]
"which cross reference source system codes can be found in the master customer details 'gottlieb, becker and wyman'?","pd.merge(customer_master_index[['master_customer_id', 'cmi_details']],cmi_cross_references['source_system_code'],on='master_customer_id').loc[lambda x: x['cmi_details']=='gottlieb ,becker and wyman', 'source_system_code'].unique()"
which cmi cross reference id is not related to any parking taxes?,"pd.concat([cmi_cross_references['cmi_cross_ref_id'], parking_fines['cmi_cross_ref_id']]).drop_duplicates(keep=false)"
which source system code includes the substring 'en'?,"cmi_cross_references.loc[lambda x: x['source_system_code'].str.contains('en'), 'source_system_code'].unique()"
determine the number of parties.,party.shape[0]
in which party were most hosts present?,party.sort_values('number_of_hosts')['party_theme']
what are the themes of parties ordered by the number of hosts from highest to lowest?,party.sort_values('number_of_hosts')['party_theme']
what is the theme of parties and the location of these events?,"party[['party_theme', 'location']]"
please provide me with the theme and location of each party.,"party[['party_theme', 'location']]"
retrieve the year in which spring parties or technology parties were organized.,"party.loc[party['party_theme'].isin(['spring', 'technology']), ['first_year', 'last_year']]"
"what is the starting year and ending year of the parties with themes ""spring"" or ""technology""?","party.loc[party['party_theme'].isin(['spring', 'technology']), ['first_year', 'last_year']]"
what is the mean count of hosts for parties?,party['number_of_hosts'].mean()
determine the average of the number of hosts for parties.,party['number_of_hosts'].mean()
which party has the most hosts?,"party.sort_values('number_of_hosts', ascending=false).iloc[0]['location']"
which party had the most event hosts? please give the location of the party.,"party.sort_values('number_of_hosts', ascending=false).iloc[0]['location']"
retrieve the names of each nationality along with the number of hosts.,host.groupby('nationality').size().reset_index(name='count')
list the nationality of hosts and the number of hosts belonging to that nationality.,host.groupby('nationality').size().reset_index(name='count')
give the most common nationality of hosts.,host.groupby('nationality').size().sort_values(ascending=false).head(1).index[0]
which nationality had the highest number of hosts?,host.groupby('nationality').size().sort_values(ascending=false).head(1).index[0]
return the names of nations that have both hosts older than 45 and hosts younger than 35.,"set(host.loc[lambda x: x['age']>45, 'nationality']).intersection(set(host.loc[lambda x: x['age']<35, 'nationality']))"
which nations have both hosts of age 45 and older and hosts of age 35 and younger?,"set(host.loc[lambda x: x['age']>45, 'nationality']).intersection(set(host.loc[lambda x: x['age']<35, 'nationality']))"
present the themes of parties and the names for the hosts of parties.,"pd.merge(pd.merge(party_host, host, on='host_id'), party, on='party_id')[['party_theme', 'name']]"
"for each party, return the themes of its attendees and the name of its host.","pd.merge(pd.merge(party_host, host, on='host_id'), party, on='party_id')[['party_theme', 'name']]"
rearrange the locations of the parties with the corresponding host names in descending order of their ages.,"pd.merge(pd.merge(party_host, host, on='host_id'), party,on='party_id').sort_values('age')[['location', 'name']]"
"for each of the events, retrieve its name, location, and the name of the host. sort the resultant table in descending order for the age of the host.","pd.merge(pd.merge(party_host, host, on='host_id'), party,on='party_id').sort_values('age')[['location', 'name']]"
fetch the party locations of hosts whose ages exceed 50.,"pd.merge(pd.merge(party_host, host, on='host_id'), party, on='party_id').loc[lambda x: x['age'] > 50, 'location']"
what are the parties whose hosts are above the age of 50? please provide me with the city and state location.,"pd.merge(pd.merge(party_host, host, on='host_id'), party, on='party_id').loc[lambda x: x['age'] > 50, 'location']"
provide the host names for parties with a number of hosts greater than 20.,"pd.merge(pd.merge(party_host, host, on='host_id'), party, on='party_id').loc[lambda x: x['number_of_hosts']>20, 'name_y']"
which parties have more than 20 hosts? provide the names of hosts for these organizations.,"pd.merge(pd.merge(party_host, host, on='host_id'), party, on='party_id').loc[lambda x: x['number_of_hosts']>20, 'name_y']"
show me the name and the age of the oldest host.,"host[['name', 'nationality']].sort_values('age', ascending=false).iloc[0]"
what is the name of the host with the highest age and what is his nationality?,"host[['name', 'nationality']].sort_values('age', ascending=false).iloc[0]"
compute the names of hosts that have not served as host of any party in our information.,"host.loc[~host['host_id'].isin(party_host['host_id']), 'name']"
retrieve the titles of those hosts who did not host any party in our document collection.,"host.loc[~host['host_id'].isin(party_host['host_id']), 'name']"
determine the total number of regions.,region.shape[0]
please sort the region codes as well as the corresponding regions.,"region[['region_code', 'region_name']].sort_values('region_code')"
"please list the areas and names for all regions, grouped by region codes","region[['region_code', 'region_name']].sort_values('region_code')"
sort the region names in alphabetical order.,region.sort_values('region_name')['region_name']
what are the titles of the regions when they are listed in alphabetical order?,region.sort_values('region_name')['region_name']
display the names of all regions except for the regions in denmark.,"region.loc[lambda x: x['region_name'] != 'denmark', 'region_name']"
provide me the names of all regions except those belonging to denmark.,"region.loc[lambda x: x['region_name'] != 'denmark', 'region_name']"
count the number of storms which included death records.,(storm['number_deaths'] > 0).sum()
how many storms involved at least 1 death?,(storm['number_deaths'] > 0).sum()
"return the full name of each storm, dates it was active, and the number   of deaths.","storm.loc[lambda x: x['number_deaths'] >= 1, ['name', 'dates_active', 'number_deaths']]"
"identify the dates active, names, and counts for storms that experienced at least one death.","storm.loc[lambda x: x['number_deaths'] >= 1, ['name', 'dates_active', 'number_deaths']]"
display the average annual and maximum damage for all storms whose velocity is greater than 1000.,"storm.loc[lambda x: x['max_speed']>1000, 'damage_millions_usd'].agg(['mean', 'max'])"
what is the mean and maximum damage in millions for storms that had a maximum speed over 1000 km/h?,"storm.loc[lambda x: x['max_speed']>1000, 'damage_millions_usd'].agg(['mean', 'max'])"
what is the total count of deaths and damage for all storms whose speeds are greater than or equal to the average?,"storm.loc[lambda x: x['max_speed'] > x['max_speed'].mean()].agg({'number_deaths': 'sum', 'damage_millions_usd': 'sum'})"
provide me with the 2-digit count of storms whose maximum sustained winds were higher than the mean.,"storm.loc[lambda x: x['max_speed'] > x['max_speed'].mean()].agg({'number_deaths': 'sum', 'damage_millions_usd': 'sum'})"
"provide me a list containing the name, damage, and speed of the storm in a descending order of the highest speed.","storm[['name', 'damage_millions_usd']].sort_values('max_speed', ascending=false)"
"provide me the names and damage in millions for storms, sorted by max speed descending.","storm[['name', 'damage_millions_usd']].sort_values('max_speed', ascending=false)"
what is the count of regions that are affected by the accident?,affected_region['region_id'].nunique()
determine the number of affected regions.,affected_region['region_id'].nunique()
find names of regions not affected by flood.,"region.loc[~region['region_id'].isin(affected_region['region_id']), 'region_name']"
what is the list of names of regions that were not impacted?,"region.loc[~region['region_id'].isin(affected_region['region_id']), 'region_name']"
retrieve the name for each region and the number of storms for each region.,"region.merge(affected_region, on='region_id').groupby('region_name').size()"
determine the number of storms in each region.,"region.merge(affected_region, on='region_id').groupby('region_name').size()"
list the name of storms and the number of affected regions for each storm.,"storm.merge(affected_region, on='storm_id').groupby('name').size().reset_index(name='count')"
how many regions were impacted per storm?,"storm.merge(affected_region, on='storm_id').groupby('name').size().reset_index(name='count')"
what is the name and maximum speed of storm which affected the most number of regions?,"pd.merge(storm, affected_region, on='storm_id').groupby('storm_id').agg({'name': 'first', 'max_speed': 'first',}).reset_index().sort_values(by='storm_id', ascending=false)[:1]"
give me the name and the maximum speed of the severe storm that hit the greatest number of regions.,"pd.merge(storm, affected_region, on='storm_id').groupby('storm_id').agg({'name': 'first', 'max_speed': 'first',}).reset_index().sort_values(by='storm_id', ascending=false)[:1]"
identify the names of storms that didn't affect any region on record.,"storm.loc[~storm['storm_id'].isin(affected_region['storm_id']), 'name']"
what is the title of storms that did not affect any regions?,"storm.loc[~storm['storm_id'].isin(affected_region['storm_id']), 'name']"
show a list of storm names that involve at least 10 cities and 2 states.,"pd.merge(storm, affected_region, on='storm_id').groupby(['storm_id', 'name'], as_index=false).agg({'number_city_affected': 'sum'}).groupby('name').filter(lambda x: x['name'].count()>=2 and x['number_city_affected'].sum()>=10)['name']"
which hurricanes affected at least two regions and affected a total of at least 10 cities?,"pd.merge(storm, affected_region, on='storm_id').groupby(['storm_id', 'name'], as_index=false).agg({'number_city_affected': 'sum'}).groupby('name').filter(lambda x: x['name'].count()>=2 and x['number_city_affected'].sum()>=10)['name']"
indicate the names of storms apart from those having at least two affected regions.,"storm['name'].loc[lambda x: ~x.isin(pd.merge(storm, affected_region, on='storm_id').groupby('storm_id').filter(lambda x: len(x) >= 2)['name'])]"
what are the names of storms that occurred in only one region?,"storm['name'].loc[lambda x: ~x.isin(pd.merge(storm, affected_region, on='storm_id').groupby('storm_id').filter(lambda x: len(x) >= 2)['name'])]"
obtain the region names that are affected by the hurricane with the least number of deaths of 10.,"pd.merge(pd.merge(affected_region, region, on='region_id'), storm, on='storm_id').loc[lambda x: x['number_deaths'] >= 10, 'region_name']"
fetch the names of regions that suffered damages from storms that had at least 10 deaths.,"pd.merge(pd.merge(affected_region, region, on='region_id'), storm, on='storm_id').loc[lambda x: x['number_deaths'] >= 10, 'region_name']"
"please list all storm names that struck the area of ""denmark"".","pd.merge(pd.merge(affected_region, region, on='region_id'), storm, on='storm_id').loc[lambda x: x['region_name']=='denmark', 'name']"
retrieve the names of storms that ravaged denmark.,"pd.merge(pd.merge(affected_region, region, on='region_id'), storm, on='storm_id').loc[lambda x: x['region_name']=='denmark', 'name']"
which regions have at least two storms?,"pd.merge(region, affected_region, on='region_id').groupby('region_id').size().loc[lambda x: x>=2].reset_index().merge(region, on='region_id')['region_name']"
obtain the names of regions that have more than one storm.,"pd.merge(region, affected_region, on='region_id').groupby('region_id').size().loc[lambda x: x>=2].reset_index().merge(region, on='region_id')['region_name']"
retrieve the names of the regions that suffered the most damage due to the storm.,"pd.merge(pd.merge(affected_region, region, on='region_id'), storm, on='storm_id')[['region_name', 'number_deaths']].sort_values('number_deaths', ascending=false).iloc[0,0]"
find the names of the regions that suffered damages during the storm in which the maximum people died.,"pd.merge(pd.merge(affected_region, region, on='region_id'), storm, on='storm_id')[['region_name', 'number_deaths']].sort_values('number_deaths', ascending=false).iloc[0,0]"
obtain the title of the storm that affected both afghanistan and albania regions.,"pd.merge(pd.merge(affected_region, region.loc[lambda x: x['region_name']=='afghanistan'], on='region_id'), storm, on='storm_id')['name'].intersect(pd.merge(pd.merge(affected_region, region.loc[lambda x: x['region_name']=='albania'], on='region_id'), storm, on='storm_id')['name'])"
could you retrieve the names of storms that affected both the regions of afghanistan and albania?,"pd.merge(pd.merge(affected_region, region.loc[lambda x: x['region_name']=='afghanistan'], on='region_id'), storm, on='storm_id')['name'].intersect(pd.merge(pd.merge(affected_region, region.loc[lambda x: x['region_name']=='albania'], on='region_id'), storm, on='storm_id')['name'])"
determine the total number of counties.,county.shape[0]
show the titles and population information for all counties.,"county[['county_name', 'population']]"
please list the name of each county along with its population.,"county[['county_name', 'population']]"
show the average population for all counties.,county['population'].mean()
what is the mean population of the counties?,county['population'].mean()
please determine the two most and least populous counties.,"county['population'].agg(['max', 'min'])"
retrieve the maximum and minimum population of the counties.,"county['population'].agg(['max', 'min'])"
provide me the list of all distinct electoral districts.,election['district'].unique()
how many distinct districts are represented in the elections?,election['district'].unique()
"please use the zip code ""howard"" to retrieve the corresponding county.","county.loc[lambda x: x['county_name']=='howard', 'zip_code']"
"what is the zip code of the county named ""howard"" that resides in?","county.loc[lambda x: x['county_name']=='howard', 'zip_code']"
who is the delegate of district 1 in the 2019 elections?,"election.loc[election['district']==1, 'delegate']"
display the delegate and committee information of elections.,"election[['delegate', 'committee']]"
retrieve the delegate and committee information for each election record.,"election[['delegate', 'committee']]"
what is the total count of governors?,party['governor'].nunique()
determine the count of governors.,party['governor'].nunique()
retrieve the titles of the party's lieutenant governor and comptroller.,"party.loc[lambda x: x['party'] == 'democratic', ['lieutenant_governor', 'comptroller']]"
retrieve the titles of those from the democratic party who are lieutenant governor and comptroller.,"party.loc[lambda x: x['party'] == 'democratic', ['lieutenant_governor', 'comptroller']]"
in what distinct years was the governor of new york state eliot spitzer serving?,"party.loc[lambda x: x['governor']=='eliot spitzer', 'year'].unique()"
"identify the years in which the governor was named ""eliot spitzer"".","party.loc[lambda x: x['governor']=='eliot spitzer', 'year'].unique()"
provide me with the most detailed information about the election.,election
retrieve all the information from the election records.,election
show the list of delegates assigned to each county.,"pd.merge(county, election, left_on='county_id', right_on='district')[['delegate', 'county_name']]"
fetch the county and delegate for each category county.,"pd.merge(county, election, left_on='county_id', right_on='district')[['delegate', 'county_name']]"
"retrieve the names or titles of delegates from counties that have populations fewer than 100,000.","pd.merge(county.loc[lambda x: x['population'] < 100000, ['county_id']], election, left_on='county_id', right_on='district')['delegate']"
"list the delegates that hail from counties with less than 100,000 inhabitants.","pd.merge(county.loc[lambda x: x['population'] < 100000, ['county_id']], election, left_on='county_id', right_on='district')['delegate']"
"what is the number of distinct delegates from counties with population larger than 50,000?","pd.merge(county[county['population'] > 50000], election, left_on='county_id', right_on='district')['delegate'].nunique()"
determine the count of delegates who are from counties with population exceeding 50000.,"pd.merge(county[county['population'] > 50000], election, left_on='county_id', right_on='district')['delegate'].nunique()"
"what are the titles of the delegates on the ""appropriations"" committee belonging to specific counties?","county.merge(election, left_on='county_id', right_on='district').loc[lambda x: x['committee']=='appropriations', 'county_name']"
"who are members of the ""appropriations"" committee? provide their names.","county.merge(election, left_on='county_id', right_on='district').loc[lambda x: x['committee']=='appropriations', 'county_name']"
provide the contents of delegates and the name of the party they respectively represent.,"pd.merge(election, party, left_on='party', right_on='party_id')[['delegate', 'party']]"
identify the names of the parties for each of the delegates.,"pd.merge(election, party, left_on='party', right_on='party_id')[['delegate', 'party']]"
who were the governorship designations of the parties associated with delegates from district 1?,"pd.merge(election.loc[lambda x: x['district'] == 1], party, left_on='party', right_on='party_id')['governor']"
which parties were associated as delegates from district 1?,"pd.merge(election.loc[lambda x: x['district'] == 1], party, left_on='party', right_on='party_id')['governor']"
which comptrollers were associated with republicans from district 1 or with democrats from district 2?,"pd.merge(election.loc[election['district'].isin([1, 2])], party, left_on='party', right_on='party_id')['comptroller']"
provide me the count of committees whose members are all democratic party delegates.,"pd.merge(election, party, left_on='party', right_on='party_id').loc[lambda x: x['party']=='democratic', 'committee']"
determine which committees have delegates from the democratic party.,"pd.merge(election, party, left_on='party', right_on='party_id').loc[lambda x: x['party']=='democratic', 'committee']"
retrieve the names of each county along with the corresponding count of delegates from that county.,"pd.merge(county, election, left_on='county_id', right_on='district').groupby('county_name').size().reset_index(name='count')"
"for each county, retrieve its name, as well as the count of its delegates.","pd.merge(county, election, left_on='county_id', right_on='district').groupby('county_name').size().reset_index(name='count')"
return the names of each party along with the corresponding count of delegates from that party.,"election.merge(party, left_on='party', right_on='party_id').groupby('party')['party'].count().reset_index(name='count')[['party', 'count']]"
provide the names and counts of delegates from the listed parties.,"election.merge(party, left_on='party', right_on='party_id').groupby('party')['party'].count().reset_index(name='count')[['party', 'count']]"
"sort out the names of all counties by population, beginning with the lowest to the highest.",county.sort_values('population')['county_name']
sort the names of all counties according to the population in descending order.,county.sort_values('population')['county_name']
provide the names of all counties sorted in alphabetical order by their title.,"county.sort_values('county_name', ascending=false)['county_name']"
sort the names of all the counties in descending order.,"county.sort_values('county_name', ascending=false)['county_name']"
which is the biggest city with the highest population?,"county.sort_values('population', ascending=false).iloc[0]['county_name']"
which county has the highest population? provide the name of the county.,"county.sort_values('population', ascending=false).iloc[0]['county_name']"
please identify the names of the 3 counties with the least population.,county.sort_values('population').iloc[:3]['county_name']
give me the names of 3 counties that possess the smallest population.,county.sort_values('population').iloc[:3]['county_name']
print the names of the counties in which there are at least two delegates.,"county.merge(election, left_on='county_id', right_on='district').groupby('county_name').filter(lambda x: len(x) >= 2)['county_name']"
what are the counties of usa that have more than one delegate?,"county.merge(election, left_on='county_id', right_on='district').groupby('county_name').filter(lambda x: len(x) >= 2)['county_name']"
display the titles of political parties that have at least two constituents.,party.groupby('party').filter(lambda x: len(x) >= 2)['party']
which has two or more records?,party.groupby('party').filter(lambda x: len(x) >= 2)['party']
depict the party that has the most delegates.,"pd.merge(election, party, left_on='party', right_on='party_id').groupby('party')['party'].count().idxmax()"
what is the count of delegates for the largest party?,"pd.merge(election, party, left_on='party', right_on='party_id').groupby('party')['party'].count().idxmax()"
list the individuals who have been governors most frequently.,party.groupby('governor').size().sort_values(ascending=false).index[0]
identify the names of people who occupied the governor position most frequently.,party.groupby('governor').size().sort_values(ascending=false).index[0]
show the list of people who occupied the position of the comptroller the most number of times and the corresponding number of times.,party.groupby('comptroller').size().sort_values(ascending=false).head(1)
"what are the names and the frequency of comptrollers?a:look for ""official"", ""officials"", ""officials'"", etc. and replace them with ""official"".",party.groupby('comptroller').size().sort_values(ascending=false).head(1)
what are the parties that did not have any delegates in elections?,"party.loc[~party['party_id'].isin(election['party']), 'party']"
"get the names of parties that have both delegates on the ""appropriations"" committee and","set(election.loc[election['committee'] == 'appropriations'].merge(party, left_on='party', right_on='party_id')['party']).intersection(set(election.loc[election['committee'] == 'economic matters'].merge(party, left_on='party', right_on='party_id')['party']))"
"which parties have party delegates in both the ""appropriations"" and ""economic matters"" committees?","set(election.loc[election['committee'] == 'appropriations'].merge(party, left_on='party', right_on='party_id')['party']).intersection(set(election.loc[election['committee'] == 'economic matters'].merge(party, left_on='party', right_on='party_id')['party']))"
which committees include delegates from both the democratic party and the liberal party?,"set(election.merge(party[party['party']=='democratic'], left_on='party', right_on='party_id')['committee']).intersection(set(election.merge(party[party['party']=='liberal'], left_on='party', right_on='party_id')['committee']))"
retrieve the committees that have delegates from both the democratic party and the liberal party.,"set(election.merge(party[party['party']=='democratic'], left_on='party', right_on='party_id')['committee']).intersection(set(election.merge(party[party['party']=='liberal'], left_on='party', right_on='party_id')['committee']))"
list the journalists' names in the ascending order of years they worked.,journalist.sort_values('years_working')['name']
what is the nationality and age of journalists?,"journalist[['nationality', 'age']]"
"provide me the names and surnames of journalists who were born in ""england"" or ""wales"".","journalist.loc[journalist['nationality'].isin(['england', 'wales']), 'name']"
what is the average of years that journalists spent working?,journalist['years_working'].mean()
what nationality is the journalist with the longest career?,"journalist.sort_values('years_working', ascending=false).iloc[0]['nationality']"
return me the names of the nationalities along with the count of journalists belonging to each nationality.,journalist.groupby('nationality').size().reset_index(name='count')
provide me with the nationality associated with the most common journalists.,journalist.groupby('nationality').size().sort_values(ascending=false).index[0]
list the nations that possess both journalists with more than ten years of working and journalists with less than three years of working skill.,"journalist.loc[journalist['years_working'] > 10, 'nationality'].interesect(journalist.loc[journalist['years_working'] < 3, 'nationality'])"
"provide me the sequence of events in descending order, with dates, places, and names of events.","event[['date', 'name', 'venue']].sort_values('event_attendance', ascending=false)"
provide the titles and dates of reports published by journalists.,"pd.merge(pd.merge(news_report, event, on='event_id'), journalist, on='journalist_id')[['name', 'date']]"
display the titles of the journalists who wrote the event titles in descending order.,"pd.merge(pd.merge(news_report, event, on='event_id'), journalist, on='journalist_id').sort_values('event_attendance')['name_x', 'name_y']"
send the names of journalists and the number of events they reported.,"pd.merge(pd.merge(news_report, event, on='event_id'), journalist, on='journalist_id').groupby('name').size().reset_index(name='count')"
list the titles of journalists who have reported more than one event.,"pd.merge(pd.merge(news_report, event, on='event_id'), journalist, on='journalist_id').groupby('name').filter(lambda x: len(x) > 1)['name'].unique()"
retrieve the names of journalists that have not reported any event.,"journalist.loc[~journalist['journalist_id'].isin(news_report['journalist_id']), 'name']"
what are the values for average and maximum attendances of all the events?,"event['event_attendance'].agg(['mean', 'max'])"
provide me with the age and experience details of each journalist across different job types.,"pd.merge(journalist, news_report, on='journalist_id').groupby('work_type').agg({'age': 'mean', 'years_working': 'mean'})"
determine the names of venues and the events where the top 2 most number of attendees were registered.,"event[['venue', 'name']].sort_values('event_attendance', ascending=false).head(2)"
describe all restaurants.,restaurant['resname']
please provide me with the address for restaurant subway.,"restaurant.loc[lambda x: x['resname']=='subway', 'address']"
provide me a list of all restaurant types.,restaurant_type['restypename']
what is the description of restaurant type sandwich?,"restaurant_type.loc[lambda x: x['restypename']=='sandwich', 'restypedescription']"
provide with me the list of restaurants along with their ratings.,"restaurant[['resname', 'rating']].sort_values('rating', ascending=false).iloc[0]"
what is the age at which linda smith studied?,"student.loc[(student['fname']=='linda') & (student['lname']=='smith'), 'age']"
provide me with the first names of students along with their last names and who majored in 600.,"student.loc[lambda x: x['major']==600, ['fname', 'lname']]"
in what city does linda smith live?,"student.loc[(student['fname']=='linda') & (student['lname']=='smith'), 'city_code']"
how many students does advisor 1121 have?,(student['advisor'] == 1121).sum()
what advisor has the largest number of students?,student.groupby('advisor').size().sort_values(ascending=false).reset_index(name='count').iloc[0]
please provide the counts of students enrolled in each major.,"student.groupby('major').size().sort_values().head(1).reset_index(name='count')[['major', 'count']]"
please list majors that have between 2 and 30 students.,"student.groupby('major').filter(lambda x: x['major'].count().between(2, 30)).groupby('major').size()"
find the names of students whose age is more than 18 and are majoring in 600.,"student.loc[(student['age'] > 18) & (student['major'] == 600), ['fname', 'lname']]"
list all of the female students of age older than 18 that are not taking 600. include the student's first name and last name.,"student.loc[(student['age']>18) & (student['major']!=600) & (student['sex']=='f'), ['fname', 'lname']]"
what is the count of restaurants that have the sandwich type?,"restaurant.join(type_of_restaurant.set_index('resid'), on='resid').join(restaurant_type.set_index('restypeid'), on='restypeid').groupby('restypeid').filter(lambda x: x['restypename'].iloc[0] == 'sandwich').shape[0]"
what duration did student linda smith spend in the restaurant?,"student.merge(visits_restaurant, on='stuid').loc[(student['fname']=='linda') & (student['lname']=='smith'), 'spent'].sum()"
please determine the year in which linda smith visited subway.,"pd.merge(pd.merge(student, visits_restaurant, on='stuid'), restaurant, on='resid').loc[(lambda x: (x['fname']=='linda') & (x['lname']=='smith') & (x['resname']=='subway')), 'time']"
"which restaurant, when visited by the students, consumed the least amount of time? provide the restaurant name, as well as the time the students spent there in total.","pd.merge(visits_restaurant, restaurant, on='resid').groupby('resname')['spent'].sum().nsmallest(1)"
list student's first and last name along with the number of times the student visited the restaurant.,"student.merge(visits_restaurant, on='stuid').groupby(['stuid', 'fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['fname', 'lname']]"
"under the condition that status is 'success', provide me the id of orders.","actual_orders.loc[lambda x: x['order_status_code']=='success', 'actual_order_id']"
determine the product title and its cost with the least variation.,"pd.merge(products, regular_order_products, on='product_id').groupby('product_id').agg({'product_name':'first','product_price':'first','product_id':'count'} ).sort_values('product_id', ascending=false).iloc[0][['product_name', 'product_price']]"
provide me with the total number of customers.,customers.shape[0]
how many payment methods are there?,customers['payment_method'].nunique()
display the details of all trucks in the order of their license number.,trucks.sort_values('truck_licence_number')['truck_details']
please provide me with the title of the most expensive product.,"products.sort_values('product_price', ascending=false)['product_name'].iloc[0]"
retrieve the names of clients who do not reside in the state of california.,"customers[~customers['customer_name'].isin(pd.merge(pd.merge(customer_addresses, addresses, on='address_id'), customers, on='customer_id').loc[lambda x: x['state_province_county']=='california', 'customer_name'])]['customer_name']"
retrieve the names and e-mails of customers who paid with visa cards.,"customers.loc[lambda x: x['payment_method']=='visa', ['customer_email', 'customer_name']]"
figure out the titles and phone numbers of customers living in the state of california.,"pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').loc[lambda x: x['state_province_county']=='california', ['customer_name', 'customer_phone']]"
produce a list of the states in which no employee is registered.,"addresses.loc[~addresses['address_id'].isin(employees['employee_address_id']), 'state_province_county']"
"provide the first and last name, phone number, and email address of all customers sorted by the date they became customers.","customers[['customer_name', 'customer_phone', 'customer_email']].sort_values('date_became_customer')"
provide me with the first 5 customers' names.,customers.sort_values('date_became_customer').iloc[:5]['customer_name']
return the payment method that is utilized most frequently.,customers.groupby('payment_method').size().sort_values(ascending=false).index[0]
retrieve the names of all the routes in the form of an alphabetically ordered list.,delivery_routes.sort_values('route_name')['route_name']
provide me with the titles of those routes that have the highest number of deliveries.,"pd.merge(delivery_routes, delivery_route_locations, on='route_id').groupby('route_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['route_name']"
please list all the state names and the number of customers residing in each state.,"pd.merge(customer_addresses, addresses, on='address_id').groupby('state_province_county').size()"
how many authors have contributed to the papers?,authors.shape[0]
how many authors have you listed?,authors.shape[0]
how many distinct institutions are there?,inst.shape[0]
find the total number of institutions.,inst.shape[0]
how many papers were published overall?,papers.shape[0]
obtain the count of total papers.,papers.shape[0]
give the titles of papers published by jeremy gibbons.,"pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[(lambda x: (x['fname']=='jeremy') & (x['lname']=='gibbons'))(authors), 'title']"
"provide me with all papers authored by ""aaron turon"".","authors.loc[(authors['fname']=='aaron') & (authors['lname']=='turon'), :].merge(authorship, on='authid').merge(papers, on='paperid')['title']"
"please provide me with the titles of all the papers written by ""aaron turon"".","authors.loc[(authors['fname']=='aaron') & (authors['lname']=='turon'), :].merge(authorship, on='authid').merge(papers, on='paperid')['title']"
determine the number of papers that have been authored by atsushi ohori.,"pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: (x['fname']=='atsushi') & (x['lname']=='ohori')].shape[0]"
what is the count of papers authored by atsushi ohori?,"pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: (x['fname']=='atsushi') & (x['lname']=='ohori')].shape[0]"
what is the name of the university that matthias blume attends?,"pd.merge(pd.merge(authors, authorship, on='authid'), inst, on='instid').loc[lambda x: (x['fname']=='matthias') & (x['lname']=='blume'), 'name'].unique()"
"what is the name of the institution where the author ""matthias blume"" is employed?","pd.merge(pd.merge(authors, authorship, on='authid'), inst, on='instid').loc[lambda x: (x['fname']=='matthias') & (x['lname']=='blume'), 'name'].unique()"
"what are the affiliations of ""katsuhiro ueno""?","pd.merge(pd.merge(authors, authorship, on='authid'), inst, on='instid').loc[lambda x: (x['fname']=='katsuhiro') & (x['lname']=='ueno'), 'name'].unique()"
"what is the full name of the institution in which the scholar ""katsuhiro ueno"" is registered?","pd.merge(pd.merge(authors, authorship, on='authid'), inst, on='instid').loc[lambda x: (x['fname']=='katsuhiro') & (x['lname']=='ueno'), 'name'].unique()"
"list the names of those belonging to the institution ""university of oxford"".","pd.merge(pd.merge(authors, authorship, on='authid'), inst, on='instid').loc[lambda x: x['name']=='university of oxford', ['fname', 'lname']].drop_duplicates()"
"identify the first name and last name of the authors whose affiliation is ""university of oxford"".","pd.merge(pd.merge(authors, authorship, on='authid'), inst, on='instid').loc[lambda x: x['name']=='university of oxford', ['fname', 'lname']].drop_duplicates()"
what are the names of authors that are employed at google?,"pd.merge(pd.merge(authors, authorship, on='authid'), inst, on='instid').loc[lambda x: x['name']=='google', ['fname', 'lname']].drop_duplicates()"
"retrieve the first names and surnames of authors whose institution is ""google"".","pd.merge(pd.merge(authors, authorship, on='authid'), inst, on='instid').loc[lambda x: x['name']=='google', ['fname', 'lname']].drop_duplicates()"
"retrieve the last name and first name of the author of the article titled ""binders unbound"".","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: x['title']=='binders unbound', 'lname']"
"give me the last name of the author of the paper titled ""binders unbound"".","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: x['title']=='binders unbound', 'lname']"
"retrieve the author names and surname of papers whose titles include ""nameless, painless"".","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: x['title']=='nameless , painless', ['fname', 'lname']]"
"provide me the first and last name of the journal that published the paper titled ""nameless, painless"".","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: x['title']=='nameless , painless', ['fname', 'lname']]"
"which papers were published under ""indiana university""?","pd.merge(pd.merge(papers, authorship, on='paperid'), inst, on='instid').loc[lambda x: x['name']=='indiana university', 'title'].unique()"
"retrieve the titles of the papers authored by authors from the university ""indiana university"".","pd.merge(pd.merge(papers, authorship, on='paperid'), inst, on='instid').loc[lambda x: x['name']=='indiana university', 'title'].unique()"
"retrieve all works published by the institution ""google"".","pd.merge(pd.merge(papers, authorship, on='paperid'), inst, on='instid').loc[lambda x: x['name']=='google', 'title'].unique()"
"retrieve the names of papers authored by authors from ""google"".","pd.merge(pd.merge(papers, authorship, on='paperid'), inst, on='instid').loc[lambda x: x['name']=='google', 'title'].unique()"
"what is the number of papers published by ""tokohu university""?","pd.merge(pd.merge(papers, authorship, on='paperid'), inst, on='instid').loc[lambda x: x['name']=='tokohu university', 'title'].nunique()"
"determine the number of papers published by authors from the institution ""tokohu university"".","pd.merge(pd.merge(papers, authorship, on='paperid'), inst, on='instid').loc[lambda x: x['name']=='tokohu university', 'title'].nunique()"
retrieve the count of papers published by the university of pennsylvania.,"pd.merge(pd.merge(papers, authorship, on='paperid'), inst, on='instid').loc[lambda x: x['name']=='university of pennsylvania', 'title'].nunique()"
what is the count of papers that are written by authors from the university of pennsylvania?,"pd.merge(pd.merge(papers, authorship, on='paperid'), inst, on='instid').loc[lambda x: x['name']=='university of pennsylvania', 'title'].nunique()"
"find the titles that have ""olin shivers"" as author.","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: (x['fname']=='olin') & (x['lname']=='shivers'), 'title']"
list the paper titles authored by olin shivers.,"pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: (x['fname']=='olin') & (x['lname']=='shivers'), 'title']"
list the papers that have stephanie weirich as an author.,"pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: (x['fname']=='stephanie') & (x['lname']=='weirich'), 'title']"
"retrieve the names of papers that were written by the author ""stephanie weirich"".","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: (x['fname']=='stephanie') & (x['lname']=='weirich'), 'title']"
"which paper was published by an institution located in ""usa"" and whose second author's name is ""turon""?","pd.merge(pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid'), inst, on='instid').loc[(lambda x: (x['country'] == 'usa') & (x['authorder'] == 2) & (x['lname'] == 'turon'))(authors), 'title']"
"retrieve the titles of papers whose first author is affiliated with an institution in the country ""japan"" and has last name ""ohori"".","pd.merge(pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid'), inst, on='instid').loc[(lambda x: (x['country']=='japan') & (x['authorder']==1) & (x['lname']=='ohori'))].title"
which author has published the most papers?,"authors.merge(authorship, on='authid').merge(papers, on='paperid').groupby(['fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['lname']"
please provide me with the author name of the person who has written the maximum paper.,"authors.merge(authorship, on='authid').merge(papers, on='paperid').groupby(['fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['lname']"
find the country with the most number of papers published,"inst.merge(authorship, on='instid').merge(papers, on='paperid').groupby('country')['paperid'].count().nlargest(1).index[0]"
retrieve the country in which the highest number of papers were published.,"inst.merge(authorship, on='instid').merge(papers, on='paperid').groupby('country')['paperid'].count().nlargest(1).index[0]"
retrieve the title of the most regular publisher of papers.,"inst.merge(authorship, on='instid').merge(papers, on='paperid').groupby('name').size().sort_values(ascending=false).head(1).index[0]"
find the title of institution with the most documents.,"inst.merge(authorship, on='instid').merge(papers, on='paperid').groupby('name').size().sort_values(ascending=false).head(1).index[0]"
"find the titles that have the word ""ml"".","papers.loc[papers['title'].str.contains('ml'), 'title']"
"please return the title of the papers that possess the substring ""ml"" in their titles.","papers.loc[papers['title'].str.contains('ml'), 'title']"
"please identify the titles that include the word ""database"".","papers.loc[papers['title'].str.contains('database'), 'title']"
"which papers contain the phrase ""database"" in their titles? present the title of the papers.","papers.loc[papers['title'].str.contains('database'), 'title']"
"retrieve the first names of the authors who have written a paper containing the word ""functional"" in their title.","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: x['title'].str.contains('functional'), 'fname']"
"please list the first names of all the authors who have written a paper with the title that contains the word ""functional"".","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: x['title'].str.contains('functional'), 'fname']"
"list down the last names of authors who have published papers with title containing the word ""monadic"".","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: x['title'].str.contains('monadic', case=false), 'lname']"
"please provide me with the last names of the ""monadic"" experts.","pd.merge(pd.merge(authors, authorship, on='authid'), papers, on='paperid').loc[lambda x: x['title'].str.contains('monadic', case=false), 'lname']"
provide the title of paper that has the most number of authors.,"papers.merge(authorship.groupby('paperid')['authorder'].max().reset_index(), on='paperid').loc[lambda x: x['authorder_x']==x['authorder_y'], 'title']"
give me the paper with the most authors.,"papers.merge(authorship.groupby('paperid')['authorder'].max().reset_index(), on='paperid').loc[lambda x: x['authorder_x']==x['authorder_y'], 'title']"
"retrieve the first names of authors with last name ""ueno"".","authors.loc[lambda x: x['lname']=='ueno', 'fname']"
"identify the titles of the author whose first name is ""amal"".","authors.loc[lambda x: x['fname']=='amal', 'lname']"
"list the names of the authors who have first name ""amal"".","authors.loc[lambda x: x['fname']=='amal', 'lname']"
"return the names (first and middle) of all the authors, alphabetically ordered.",authors.sort_values('fname')['fname']
organize the first names of the authors in alphabetical order.,authors.sort_values('fname')['fname']
return the last name of each author in alphabetical order.,authors['lname'].sort_values()
provide me a sorted list of last names of authors.,authors['lname'].sort_values()
generate a list of authors whose last names commence from a to z.,"authors[['fname', 'lname']].sort_values('lname')"
sort the list of all the authors' last names in alphabetical order.,"authors[['fname', 'lname']].sort_values('lname')"
how many separate last names do the actors and actresses have?,actor['last_name'].nunique()
determine the count of distinct last names of the actors.,actor['last_name'].nunique()
what is the most popular first name of actors?,"actor.groupby('first_name').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['first_name']"
provide the most common first name of all actors.,"actor.groupby('first_name').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['first_name']"
what are the most popular full names of the actors?,"actor.groupby(['first_name', 'last_name']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['first_name', 'last_name']]"
please determine the full name with the maximum frequency occurrence among all actors.,"actor.groupby(['first_name', 'last_name']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['first_name', 'last_name']]"
find all the districts that have more than one address.,address.groupby('district').filter(lambda x: len(x) >= 2)['district'].unique()
retrieve the locations which have two or more addresses.,address.groupby('district').filter(lambda x: len(x) >= 2)['district'].unique()
what is the number and postal code of the address 1031 daugavpils parkway?,"address.loc[lambda x: x['address']=='1031 daugavpils parkway', ['phone', 'postal_code']]"
provide me with the information corresponding to the address '1031 daugavpils parkway'.,"address.loc[lambda x: x['address']=='1031 daugavpils parkway', ['phone', 'postal_code']]"
what is the total count of addresses in different locations? list the names of cities and the count of addresses of each.,"address.merge(city, on='city_id').groupby('city_id').size().reset_index(name='count').merge(city, on='city_id').sort_values('count', ascending=false).iloc[0][['city', 'count', 'city_id']]"
"please give me the details of the city that has the largest number of addresses along with the zip code, id, and name of the city.","address.merge(city, on='city_id').groupby('city_id').size().reset_index(name='count').merge(city, on='city_id').sort_values('count', ascending=false).iloc[0][['city', 'count', 'city_id']]"
how many addresses are there in california district?,(address['district'] == 'california').sum()
how many addressees are there in the california district?,(address['district'] == 'california').sum()
please list the film title and its id that is rented at a cost of 0.99 and currently has less than 3 units in stock.,"film.loc[film['rental_rate'] == 0.99, ['title', 'film_id']].merge(inventory, on='film_id').groupby('film_id').filter(lambda x: len(x) < 3)['title', 'film_id']"
please inform me of the titles of films that have a rental rate of 0.99 and an inventory of fewer than three.,"film.loc[film['rental_rate'] == 0.99, ['title', 'film_id']].merge(inventory, on='film_id').groupby('film_id').filter(lambda x: len(x) < 3)['title', 'film_id']"
what is the number of cities in australia?,"pd.merge(city, country, on='country_id').loc[lambda x: x['country']=='australia'].shape[0]"
find the number of cities in australia.,"pd.merge(city, country, on='country_id').loc[lambda x: x['country']=='australia'].shape[0]"
what are the number of countries having at least three cities?,"pd.merge(city, country, on='country_id').groupby('country').filter(lambda x: len(x) >= 3)['country'].unique()"
which countries are those that contain at least 3 cities?,"pd.merge(city, country, on='country_id').groupby('country').filter(lambda x: len(x) >= 3)['country'].unique()"
retrieve the date of all payments that have a value in excess or equal to 10 and the payments handled by a staff person with the first name elsa.,"payment.loc[payment['amount'] > 10, 'payment_date'].append(pd.merge(payment, staff, on='staff_id').loc[lambda x: x['first_name']=='elsa', 'payment_date']).drop_duplicates()"
"retrieve the payment dates for any payments that exceed 10, or payments that are handled from a staff member with the first name elsa.","payment.loc[payment['amount'] > 10, 'payment_date'].append(pd.merge(payment, staff, on='staff_id').loc[lambda x: x['first_name']=='elsa', 'payment_date']).drop_duplicates()"
"what is the count of customers for whom the ""active"" attribute has a value of 1?",(customer['active'] == '1').sum()
what is the count of existing customers?,(customer['active'] == '1').sum()
determine the film that has the highest rental charge.,"film[['title', 'rental_rate']].sort_values('rental_rate', ascending=false).iloc[0]"
provide me with the title and rental rate of the film having the highest rental rate.,"film[['title', 'rental_rate']].sort_values('rental_rate', ascending=false).iloc[0]"
provide the titles of the films that have the most number of actors or actresses.,"film_actor.merge(film, on='film_id').groupby(['film_id', 'title', 'description']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['title', 'film_id', 'description']]"
"what are the title, id, and description of a movie that has the largest number of actors?","film_actor.merge(film, on='film_id').groupby(['film_id', 'title', 'description']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['title', 'film_id', 'description']]"
provide me with the first and last names of the movie actor (actress) who has starred in the most films as well as his or her id number.,"pd.merge(film_actor, actor, on='actor_id').groupby(['first_name', 'last_name', 'actor_id']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['first_name', 'last_name', 'actor_id']]"
which actor or actress has appeared in the greatest number of movies?,"pd.merge(film_actor, actor, on='actor_id').groupby(['first_name', 'last_name', 'actor_id']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['first_name', 'last_name', 'actor_id']]"
list the first and last names of film actors who appeared in more than 30 movies.,"pd.merge(film_actor, actor, on='actor_id').groupby(['actor_id', 'first_name', 'last_name']).filter(lambda x: len(x) > 30)[['first_name', 'last_name']].drop_duplicates()"
retrieve the name lists of actors that featured in more than 30 films.,"pd.merge(film_actor, actor, on='actor_id').groupby(['actor_id', 'first_name', 'last_name']).filter(lambda x: len(x) > 30)[['first_name', 'last_name']].drop_duplicates()"
which store has the most number of items?,inventory.groupby('store_id').size().sort_values(ascending=false).index[0]
provide me the sum of all payment amounts.,payment['amount'].sum()
"please provide me with the id, last name, and first name of the customer who has spent the least.","customer.merge(payment, on='customer_id').groupby(['customer_id', 'first_name', 'last_name']).agg({'amount': 'sum'}).reset_index().sort_values('amount').iloc[0][['first_name', 'last_name', 'customer_id']]"
what is the full name and id of the customer with the least payment received?,"customer.merge(payment, on='customer_id').groupby(['customer_id', 'first_name', 'last_name']).agg({'amount': 'sum'}).reset_index().sort_values('amount').iloc[0][['first_name', 'last_name', 'customer_id']]"
"what is the title of the movie that falls under the genre of ""horror""?","pd.merge(pd.merge(category, film_category, on='category_id'), film, on='film_id').loc[lambda x: x['title']=='hunger roof', 'name']"
provide the title of the category of which the film 'hunger roof' is a part.,"pd.merge(pd.merge(category, film_category, on='category_id'), film, on='film_id').loc[lambda x: x['title']=='hunger roof', 'name']"
"provide the list of movies along with their genre name, genre id, and the number of movies in each category.","pd.merge(film_category, category, on='category_id').groupby('category_id').agg({'name': 'first', 'film_id': 'count'}).reset_index()[['name', 'category_id', 'film_id']]"
what is the id of each category and how many movies does it contain?,"pd.merge(film_category, category, on='category_id').groupby('category_id').agg({'name': 'first', 'film_id': 'count'}).reset_index()[['name', 'category_id', 'film_id']]"
which film has the most copies in the inventory? obtain its title and id.,"pd.merge(film, inventory, on='film_id').groupby('film_id').agg({'title':'first', 'inventory_id':'count'}).sort_values('inventory_id', ascending=false).iloc[0][['title', 'inventory_id']]"
what is the title and id of the film that has the highest quantity of copies in inventory?,"pd.merge(film, inventory, on='film_id').groupby('film_id').agg({'title':'first', 'inventory_id':'count'}).sort_values('inventory_id', ascending=false).iloc[0][['title', 'inventory_id']]"
which film title and item id were rented the most number of times?,"pd.merge(pd.merge(film, inventory, on='film_id'), rental, on='inventory_id').groupby('inventory_id').size().sort_values(ascending=false).reset_index(name='count').iloc[0][['title', 'inventory_id']]"
please provide me with the film title and its inventory id that is most often rented out.,"pd.merge(pd.merge(film, inventory, on='film_id'), rental, on='inventory_id').groupby('inventory_id').size().sort_values(ascending=false).reset_index(name='count').iloc[0][['title', 'inventory_id']]"
what is the total number of languages utilized in these films?,film['language_id'].nunique()
estimate the number of different languages in the films specified.,film['language_id'].nunique()
provide with the titles of all the movies that are rated r,"film.loc[film['rating']=='r', 'title']"
please produce the names of the movies that are r rated.,"film.loc[film['rating']=='r', 'title']"
please return the address of store 1.,"address.loc[lambda x: x['address_id']==store.loc[lambda y: y['store_id']==1, 'address_id'].iloc[0], 'address']"
write down the full name as well as the id of the staff that handled the least number of payments.,"pd.merge(staff, payment, on='staff_id').groupby(['first_name', 'last_name', 'staff_id']).size().reset_index(name='count').sort_values('count').iloc[0]"
provide me the name and id of the staff member that executed the least number of payments.,"pd.merge(staff, payment, on='staff_id').groupby(['first_name', 'last_name', 'staff_id']).size().reset_index(name='count').sort_values('count').iloc[0]"
please indicate the code of language utilized in the creation of the film airport pollock.,"film.merge(language, on='language_id').loc[lambda x: x['title']=='airport pollock', 'name']"
"what is the language in which the film is titled ""port pollock""?","film.merge(language, on='language_id').loc[lambda x: x['title']=='airport pollock', 'name']"
what is the count of stores?,store.shape[0]
what are the categories of ratings listed?,film['rating'].nunique()
is the count of distinct film ratings equal to the number of distinct film ratings?,film['rating'].nunique()
who are the movies containing deleted scenes in special feature?,"film.loc[film['special_features'].str.contains('deleted scenes'), 'title']"
"please return the names of films that include the ""deleted scenes"" on their ""special feature"" section.","film.loc[film['special_features'].str.contains('deleted scenes'), 'title']"
determine the number of items in inventory possessed by store 1.,(inventory['store_id'] == 1).sum()
"what is the number of items in stock at store ""1""?",(inventory['store_id'] == 1).sum()
at what time was the first transaction recorded?,payment.sort_values('payment_date').iloc[0]['payment_date']
what was the date of the earliest payment made?,payment.sort_values('payment_date').iloc[0]['payment_date']
please give me the name of a customer named linda as well as the email address.,"pd.merge(customer.loc[lambda x: x['first_name']=='linda', ['address_id', 'email']], address, on='address_id')['address']"
please provide me with the address and email of the customer with the first name linda.,"pd.merge(customer.loc[lambda x: x['first_name']=='linda', ['address_id', 'email']], address, on='address_id')['address']"
"what are the movie titles that are not longer than 100 minutes, or rated pg, and are not replacing more than 200?","film.loc[((film['length'] > 100) | (film['rating'] == 'pg')) & ~(film['replacement_cost'] > 200), 'title']"
which titles were longer than 100 minutes or were rated pg other than those that were expensive to replace?,"film.loc[((film['length'] > 100) | (film['rating'] == 'pg')) & ~(film['replacement_cost'] > 200), 'title']"
provide me with the first name and last name of the customer that rented the earliest vehicle.,"pd.merge(customer, rental, on='customer_id').sort_values('rental_date').iloc[0][['first_name', 'last_name']]"
please provide me with the full name of the client who made the first order.,"pd.merge(customer, rental, on='customer_id').sort_values('rental_date').iloc[0][['first_name', 'last_name']]"
what is the full name of the staff member that rented a film to a customer with the first name april and the last name burns?,"pd.merge(pd.merge(staff, rental, on='staff_id'), customer, on='customer_id').loc[(lambda x: x['first_name']=='april')&(lambda x: x['last_name']=='burns'), ['first_name', 'last_name']].drop_duplicates()"
"give me the data regarding the person, who provided a customer with the first name april and the last name burns with a film rental.","pd.merge(pd.merge(staff, rental, on='staff_id'), customer, on='customer_id').loc[(lambda x: x['first_name']=='april')&(lambda x: x['last_name']=='burns'), ['first_name', 'last_name']].drop_duplicates()"
which store has the highest count of customers?,customer.groupby('store_id').size().sort_values(ascending=false).index[0]
provide the id of the store that has the most customers.,customer.groupby('store_id').size().sort_values(ascending=false).index[0]
retrieve the highest value of payment.,payment['amount'].nlargest(1)
provide me the  amount  of the largest  payment.,payment['amount'].nlargest(1)
is there a staff member with the first name elsa living in france?,"address.loc[lambda x: x['address_id'].isin(staff.loc[lambda x: x['first_name']=='elsa', 'address_id']), 'address']"
please provide the address for the staff who has the first name elsa.,"address.loc[lambda x: x['address_id'].isin(staff.loc[lambda x: x['first_name']=='elsa', 'address_id']), 'address']"
retrieve the first names of customers who do not own any films after '2005-08-23 02:06:01'.,"customer.loc[~customer['customer_id'].isin(rental.loc[rental['rental_date'] > '2005-08-23 02:06:01', 'customer_id']), 'first_name']"
please list the names of customers who have rented a movie after the date '2005-08-23 02:06:01'.,"customer.loc[~customer['customer_id'].isin(rental.loc[rental['rental_date'] > '2005-08-23 02:06:01', 'customer_id']), 'first_name']"
provide me with the count of bank branches.,bank.shape[0]
provide with me the count of bank branches.,bank.shape[0]
what is the count of customers?,bank['no_of_customers'].sum()
determine the total count of customers associated with various banks.,bank['no_of_customers'].sum()
please determine the number of customers present in the banks of new york city.,"bank.loc[lambda x: x['city']=='new york city', 'no_of_customers'].sum()"
what are the total counts of customers that utilize banks in nyc?,"bank.loc[lambda x: x['city']=='new york city', 'no_of_customers'].sum()"
express the average number of customers in all banks of utah state.,"bank.loc[lambda x: x['state']=='utah', 'no_of_customers'].mean()"
what is the mean number of customers across banks in the state of utah?,"bank.loc[lambda x: x['state']=='utah', 'no_of_customers'].mean()"
provide the average number of customers that cross all banks.,bank['no_of_customers'].mean()
what is the average count of bank customers?,bank['no_of_customers'].mean()
provide the state and the city in which the bank branch named morningside is located.,"bank.loc[lambda x: x['bname'] == 'morningside', ['city', 'state']]"
"determine which city and state is the bank with the name ""morningside"" in.","bank.loc[lambda x: x['bname'] == 'morningside', ['city', 'state']]"
determine the names of branches in new york state.,"bank.loc[lambda x: x['state']=='new york', 'bname']"
provide me the names of the banks located in the u.s. state of new york.,"bank.loc[lambda x: x['state']=='new york', 'bname']"
please sort the names of customers based on their account balance in ascending order.,customer.sort_values('acc_bal')['cust_name']
"obtain the title of each customer, ordered in descending order by account balance.",customer.sort_values('acc_bal')['cust_name']
provide the names of the customers along with the assortment of their total loan amount.,"customer.merge(loan, on='cust_id').groupby('cust_name').agg({'amount': 'sum'}).sort_values('amount', ascending=true).reset_index()['cust_name']"
"provide me the names of customers with largest loans taken out, ordered as the total sum written in the loans.","customer.merge(loan, on='cust_id').groupby('cust_name').agg({'amount': 'sum'}).sort_values('amount', ascending=true).reset_index()['cust_name']"
"provide the state, account type, and credit score of the customer whose number of loans is 0.","customer.loc[lambda x: x['no_of_loans'] == 0, ['state', 'acc_type', 'credit_score']]"
"list the states, account types, and credit scores for customers who have zero loans.","customer.loc[lambda x: x['no_of_loans'] == 0, ['state', 'acc_type', 'credit_score']]"
pass me the number of cities in which banks are located.,bank['city'].nunique()
how many cities host banks?,bank['city'].nunique()
determine the number of different states in which banks are located.,bank['state'].nunique()
how many different states contain banking institutions?,bank['state'].nunique()
how many types of accounts are there?,customer['acc_type'].nunique()
what is the count of account types?,customer['acc_type'].nunique()
provide me the name and account balance of the customer whose name includes the letter 'a'.,"customer.loc[lambda x: x['cust_name'].str.contains('a', case=false), ['cust_name', 'acc_bal']]"
"which customers’ names and account balances possess the letter ""a"" in their names?","customer.loc[lambda x: x['cust_name'].str.contains('a', case=false), ['cust_name', 'acc_bal']]"
retrieve the count of customer who has balance greater than x for utah and texas,"customer.loc[lambda x: x['state'].isin(['utah', 'texas']), 'acc_bal'].sum()"
give me the aggregate account balances for each account held by a customer from utah or texas.,"customer.loc[lambda x: x['state'].isin(['utah', 'texas']), 'acc_bal'].sum()"
retrieve the names of customers that own both saving and checking account types.,"pd.series(list(set(customer.loc[customer['acc_type']=='saving', 'cust_name']).intersection(set(customer.loc[customer['acc_type']=='checking', 'cust_name']))))"
retrieve the names of customers that possess both checking and savings accounts.,"pd.series(list(set(customer.loc[customer['acc_type']=='saving', 'cust_name']).intersection(set(customer.loc[customer['acc_type']=='checking', 'cust_name']))))"
retrieve the names of clients that do not have any savings account.,"customer.loc[lambda x: x['acc_type']!='saving', 'cust_name']"
provide me with the titles of all customers who do not have savings accounts.,"customer.loc[lambda x: x['acc_type']!='saving', 'cust_name']"
determine the titles that belong to customers that are not linked to a mortgage type of mortgages.,"customer.loc[~customer['cust_name'].isin(pd.merge(customer, loan.loc[loan['loan_type']=='mortgages'], on='cust_id', how='inner')['cust_name'])]['cust_name']"
"for each title, return the customer name. if title is ""mrs."" or ""mr."", return the associated name.","customer.loc[~customer['cust_name'].isin(pd.merge(customer, loan.loc[loan['loan_type']=='mortgages'], on='cust_id', how='inner')['cust_name'])]['cust_name']"
"list the names of people having both types of loans, i.e., mortgages and auto.","pd.merge(customer.loc[lambda x: x['loan_type']=='mortgages', ['cust_id', 'cust_name']],loan.loc[lambda x: x['loan_type']=='mortgages', ['cust_id']],on='cust_id')['cust_name'].rename_axis(none).isin(pd.merge(customer.loc[lambda x: x['loan_type']=='auto', ['cust_id', 'cust_name']],loan.loc[lambda x: x['loan_type']=='auto', ['cust_id']],on='cust_id')['cust_name'].values).replace({true: 'yes', false: 'no'}).rename('cust_name')"
retrieve the names of customers who have taken both mortgage and auto loans.,"pd.merge(customer.loc[lambda x: x['loan_type']=='mortgages', ['cust_id', 'cust_name']],loan.loc[lambda x: x['loan_type']=='mortgages', ['cust_id']],on='cust_id')['cust_name'].rename_axis(none).isin(pd.merge(customer.loc[lambda x: x['loan_type']=='auto', ['cust_id', 'cust_name']],loan.loc[lambda x: x['loan_type']=='auto', ['cust_id']],on='cust_id')['cust_name'].values).replace({true: 'yes', false: 'no'}).rename('cust_name')"
name the customers who have a lower credit score than average.,"customer.loc[lambda x: x['credit_score'] < x['credit_score'].mean(), 'cust_name']"
list the names of customers with credit score that is fewer than the average across customers.,"customer.loc[lambda x: x['credit_score'] < x['credit_score'].mean(), 'cust_name']"
which bank branch has the most number of customers?,"bank.sort_values('no_of_customers', ascending=false).iloc[0]['bname']"
what is the total count of customers at a bank branch?,"bank.sort_values('no_of_customers', ascending=false).iloc[0]['bname']"
retrieve the full name and credit score of the lowest customer.,customer.sort_values('credit_score').iloc[0]['cust_name']
what is the customer id with the poor credit rating?,customer.sort_values('credit_score').iloc[0]['cust_name']
"provide me the id of the customer with the maximum credit score, the account type, and the account balance.","customer[['cust_name', 'acc_type', 'acc_bal']].sort_values('credit_score', ascending=false).head(1)"
what is the name of the client who has the greatest total loan allowed?,"pd.merge(customer, loan, on='cust_id').groupby('cust_name').agg(total_loan=('amount', 'sum')).sort_values('total_loan', ascending=false).iloc[0]['cust_name']"
find the state the has the highest number of customers.,bank.groupby('state')['no_of_customers'].sum().sort_values(ascending=false).reset_index().iloc[0]['state']
what is the total sum of bank customers of each state?,bank.groupby('state')['no_of_customers'].sum().sort_values(ascending=false).reset_index().iloc[0]['state']
provide me with the average balance of accounts owned by customers with credit scores below 50.,customer.loc[lambda x: x['credit_score'] < 50].groupby('acc_type')['acc_bal'].mean()
find the average of average account balances of customers with credit score below 50 for the different account types.,customer.loc[lambda x: x['credit_score'] < 50].groupby('acc_type')['acc_bal'].mean()
"for each state, determine the aggregated balance of customers whose credit score is higher than 100.",customer.loc[lambda x: x['credit_score'] > 100].groupby('state')['acc_bal'].sum()
please provide me the total account balance of the customers with a credit score of above 100 for different states.,customer.loc[lambda x: x['credit_score'] > 100].groupby('state')['acc_bal'].sum()
what is the total sum of loans offered by each bank?,"pd.merge(bank, loan, on='branch_id').groupby('bname')['amount'].sum()"
enumerate the names of different bank branches along with the loan amounts associated with each branch.,"pd.merge(bank, loan, on='branch_id').groupby('bname')['amount'].sum()"
produce the names of the customers who have more than one loan.,"customer.merge(loan, on='cust_id').groupby('cust_name').filter(lambda x: len(x) > 1)['cust_name'].unique()"
retrieve the names of customers who have taken out more than one loan.,"customer.merge(loan, on='cust_id').groupby('cust_name').filter(lambda x: len(x) > 1)['cust_name'].unique()"
"what is the total amount of loans held by customers, and what is the account and name of the customer who hold the highest amount of loans?","customer.merge(loan, on='cust_id').groupby(['cust_name', 'acc_type']).filter(lambda x: x['amount'].sum() > 5000).iloc[:, :2].drop_duplicates()"
"please list the id, names, and account balances of customers who have taken more than five thousand dollar loans.","customer.merge(loan, on='cust_id').groupby(['cust_name', 'acc_type']).filter(lambda x: x['amount'].sum() > 5000).iloc[:, :2].drop_duplicates()"
find the name of bank branch that has issued the most loans.,"bank.merge(loan, on='branch_id').groupby('bname').agg({'amount': 'sum'}).sort_values('amount', ascending=false).iloc[:1].index.tolist()[0]"
what is the complete name of the bank that has lent the most amount of money?,"bank.merge(loan, on='branch_id').groupby('bname').agg({'amount': 'sum'}).sort_values('amount', ascending=false).iloc[:1].index.tolist()[0]"
list the names of banks that lent out the most loans to customers whose credit score was less than 100.,"loan.merge(bank, on='branch_id').merge(customer, on='cust_id').loc[lambda x: x['credit_score']<100].groupby('bname')['amount'].sum().sort_values(ascending=false).index[0]"
what are the names of banks providing loans to their customers with credit scores below 100 for the largest corpus?,"loan.merge(bank, on='branch_id').merge(customer, on='cust_id').loc[lambda x: x['credit_score']<100].groupby('bname')['amount'].sum().sort_values(ascending=false).index[0]"
retrieve the names of banks that offered some loans.,"pd.merge(bank, loan, on='branch_id')['bname'].unique()"
provide me with the full names of the different bank corporations that have provided loans.,"pd.merge(bank, loan, on='branch_id')['bname'].unique()"
retrieve the customer names and credit scores of customers that have some loans.,"pd.merge(customer, loan, on='cust_id')[['cust_name', 'credit_score']].drop_duplicates()"
what is the quantity of various name and credit score combinations for customers who have taken out a loan?,"pd.merge(customer, loan, on='cust_id')[['cust_name', 'credit_score']].drop_duplicates()"
retrieve the titles of those customers who have loans amounting to more than $3000.,"pd.merge(customer, loan, on='cust_id').loc[lambda x: x['amount'] > 3000, 'cust_name']"
retreive the names of clients who have a loan of more than 3000.,"pd.merge(customer, loan, on='cust_id').loc[lambda x: x['amount'] > 3000, 'cust_name']"
obtain the list of cities in which banks offer loans to businesses.,"pd.merge(bank, loan, on='branch_id').loc[lambda x: x['loan_type']=='business', ['bname', 'city']]"
which banks offer loans for business development and which cities have those branches?,"pd.merge(bank, loan, on='branch_id').loc[lambda x: x['loan_type']=='business', ['bname', 'city']]"
retrieve the titles of bank branches that have approved any loan to any customer whose credit score is below 100.,"pd.merge(pd.merge(loan, bank, on='branch_id'), customer, on='cust_id').loc[lambda x: x['credit_score'] < 100, 'bname']"
retrieve the names of banks that have lent money to customers who have credit ratings lower than 100.,"pd.merge(pd.merge(loan, bank, on='branch_id'), customer, on='cust_id').loc[lambda x: x['credit_score'] < 100, 'bname']"
determine the total sum of loans that were provided by bank branches in the state of new york.,"pd.merge(bank, loan, on='branch_id').loc[lambda x: x['state']=='new york', 'amount'].sum()"
identify the total amount of cash lent by banks in the state of new york.,"pd.merge(bank, loan, on='branch_id').loc[lambda x: x['state']=='new york', 'amount'].sum()"
determine the average credit score of the customers who have some loans.,"customer.loc[lambda x: x['cust_id'].isin(loan['cust_id']), 'credit_score'].mean()"
what is the average of credit scores of customers who have availed loan?,"customer.loc[lambda x: x['cust_id'].isin(loan['cust_id']), 'credit_score'].mean()"
determine the average credit rating of the customers who do not have loans.,"customer.loc[~customer['cust_id'].isin(loan['cust_id']), 'credit_score'].mean()"
what is the credit score for individuals who have never taken a loan?,"customer.loc[~customer['cust_id'].isin(loan['cust_id']), 'credit_score'].mean()"
what is the count of assessment notes that are present?,assessment_notes.shape[0]
on which dates were the assessment notes created?,assessment_notes['date_of_notes']
please provide me with the count of unique zip codes beginning with 197.,(addresses['zip_postcode'] == '197').sum()
what is the distinct count of incident type codes?,behavior_incident['incident_type_code'].nunique()
please provide the names of all detention types present in dataset.,detention['detention_type_code'].unique()
"give me the start and end timestamps for incidents with incident type code ""noise"".","behavior_incident.loc[lambda x: x['incident_type_code']=='noise', ['date_incident_start', 'date_incident_end']]"
please provide me with a list of all detention summaries..................................................,detention['detention_summary']
please provide me with the cell phone numbers and email addresses for all students.,"students[['cell_mobile_number', 'email_address']]"
"whose email is ""emmarohan0@gmail.com""?","students.loc[(students['first_name'] == ""emma"") & (students['last_name'] == ""rohan""), 'email_address']"
how many unique students have spent time in detention?,students_in_detention['student_id'].nunique()
"what is the description code for the incident type with code ""violence""?","ref_incident_type.loc[lambda x: x['incident_type_code']=='violence', 'incident_type_description']"
provide me with the minimum and maximum monthly rental for all student addresses.,"student_addresses['monthly_rental'].agg(['max', 'min'])"
"query the email address of teachers whose first names contain the word ""man"".","teachers.loc[teachers['email_address'].str.contains('man'), 'first_name']"
retrieve all assessment information sorted by date in ascending order.,assessment_notes.sort_values('date_of_notes')
justify a list of cities in the order of their addresses.,addresses['city'].sort_values()
provide me with the names of the teachers arranged in alphabetical order by last name.,"teachers[['first_name', 'last_name']].sort_values('last_name')"
"extract all data related to student addresses, and sort by monthly rent in descending order.","student_addresses.sort_values('monthly_rental', ascending=false)"
return the id and first name of the student with the most number of assessment notes.,"pd.merge(assessment_notes, students, on='student_id').groupby('student_id').size().sort_values(ascending=false).head(1).reset_index()[['student_id', 'first_name']]"
determine the ids and first names of the 3 teachers that have the largest count of assessment notes.,"pd.merge(assessment_notes, teachers, on='teacher_id').groupby('teacher_id')['first_name'].count().sort_values(ascending=false)[:3].reset_index()"
identify the student with the maximum behavior incidents.,"behavior_incident.merge(students, on='student_id').groupby(['student_id', 'last_name']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['student_id', 'last_name']]"
please provide me with id and last name of the teacher that is most frequently assigned detentions with detention type after.,"pd.merge(detention.loc[detention['detention_type_code']=='after'].groupby('teacher_id').size().reset_index(name='count'), teachers, on='teacher_id').sort_values('count', ascending=false).iloc[0][['teacher_id', 'last_name']]"
get the name of the student whose addresses have the maximum average monthly rental and their respective id and full name.,"pd.merge(student_addresses, students, on='student_id').groupby('student_id').agg({'first_name':'first', 'monthly_rental':'mean'}).sort_values('monthly_rental', ascending=false).iloc[0][['first_name', 'student_id']]"
provide the name and city of the student with the maximum average monthly rental.,"addresses.merge(student_addresses, on='address_id').groupby('address_id').agg({'city':'first', 'monthly_rental':'mean'}).sort_values('monthly_rental', ascending=false).iloc[0]"
please provide me with the code and description of the most frequent behavior incident type.,"pd.merge(behavior_incident, ref_incident_type, on='incident_type_code').groupby('incident_type_code')['incident_type_description'].count().sort_values(ascending=false).iloc[0:1]"
what is the least frequent detention code and its description?,"pd.merge(detention, ref_detention_type, on='detention_type_code').groupby('detention_type_code').size().sort_values().head(1).reset_index()[['detention_type_code', 'detention_type_description']]"
"obtain the dates for the assessment notes for students with first name ""fanny"".","pd.merge(assessment_notes, students, on='student_id').loc[lambda x: x['first_name']=='fanny', 'date_of_notes']"
"retrieve the texts associated with assessment notes for teachers whose last name is ""schuster"".","pd.merge(assessment_notes, teachers.loc[lambda x: x['last_name'] == 'schuster', ['teacher_id']], on='teacher_id')['text_of_notes']"
retrieve the dates and time of behavior incidents for fahey's last name.,"pd.merge(behavior_incident, students, on='student_id').loc[lambda x: x['last_name']=='fahey', ['date_incident_start', 'date_incident_end']]"
"what is the start and end dates of the detentions of teachers with last name ""schultz""?","pd.merge(detention, teachers, on='teacher_id').query('last_name==""schultz""')[['datetime_detention_start', 'datetime_detention_end']]"
please give me the id and zip code of the address whose monthly rental is the highest.,"pd.merge(addresses, student_addresses, on='address_id').sort_values('monthly_rental', ascending=false).iloc[0][['address_id', 'zip_postcode']]"
please provide me with the cell phone number of the student whose rent is the lowest.,"pd.merge(student_addresses, students, on='student_id').sort_values('monthly_rental').iloc[0]['cell_mobile_number']"
how many monthly rentals were specified by students in the state of texas?,"pd.merge(addresses, student_addresses, on='address_id').loc[lambda x: x['state_province_county'] == 'texas', 'monthly_rental']"
"provide the full name, first name and last name, of each student with address in the wisconsin area.","pd.merge(addresses, students, on='address_id').loc[lambda x: x['state_province_county']=='wisconsin', ['first_name', 'last_name']]"
determine the line 1 and average monthly rentals of student addresses.,"pd.merge(addresses, student_addresses, on='address_id').groupby('address_id').agg({'line_1': 'first', 'monthly_rental': 'mean'})['line_1']"
which zip code corresponds to the address where the teacher named lyla lives?,"addresses.merge(teachers.loc[lambda x: x['first_name']=='lyla'], on='address_id')['zip_postcode']"
"retrieve the titles of teachers whose address is in the zip code ""918"".","pd.merge(addresses, teachers, on='address_id').loc[lambda x: x['zip_postcode']=='918', 'email_address']"
what is the count of students that are not involved in any reported behavior incidents?,students[~students['student_id'].isin(behavior_incident['student_id'])].shape[0]
retrieve the names of teachers who are not associated with any detention.,teachers['last_name'].loc[~teachers['teacher_id'].isin(detention['teacher_id'])]
what are the shared lines (lines 1) of addresses among some students and their teachers?,"pd.merge(addresses, students, on='address_id')['line_1'].interesect(pd.merge(addresses, teachers, on='address_id')['line_1'])"
which assets have 2 parts and have had 2 or fewer fault logs? list the asset id and detail.,"pd.merge(assets, asset_parts, on='asset_id').groupby(['asset_id', 'asset_details']).filter(lambda x: len(x) == 2).merge(pd.merge(assets, fault_log, on='asset_id').groupby(['asset_id', 'asset_details']).filter(lambda x: len(x) < 2), on=['asset_id', 'asset_details'])['asset_id']"
what is the number of assets each maintenance contract contains? list the number and the contract id.,"assets.merge(maintenance_contracts, on='maintenance_contract_id').groupby('maintenance_contract_id').size().reset_index(name='count')"
provide a total of the assets that are provided by each of the third party companies along with their respective company identifier.,"assets.merge(third_party_companies, left_on='supplier_company_id', right_on='company_id').groupby('company_id').size().reset_index(name='count')"
provide me with the details of third party companies that have at least 2 maintenance engineers or have at least 2 maintenance contracts.,"pd.concat([third_party_companies.merge(maintenance_engineers, on='company_id').groupby(['company_id', 'company_name']).filter(lambda x: len(x)>=2), third_party_companies.merge(maintenance_contracts, left_on='company_id', right_on='maintenance_contract_company_id').groupby(['company_id', 'company_name']).filter(lambda x: len(x)>=2)] ).drop_duplicates(subset=['company_id', 'company_name'])[['company_id', 'company_name']]"
please provide me with the name of the staff member who recorded the fault logs but has not contacted any visiting engineers.,"pd.merge(staff, fault_log, left_on='staff_id', right_on='recorded_by_staff_id')[['staff_name', 'staff_id']].drop_duplicates().merge(pd.merge(staff, engineer_visits, left_on='staff_id', right_on='contact_staff_id')[['staff_name', 'staff_id']].drop_duplicates(), how='left', on=['staff_name', 'staff_id'], indicator=true).loc[lambda x: x['_merge']=='left_only', ['staff_name', 'staff_id']].reset_index(drop=true)"
how many visits did the relevant engineer make?,"pd.merge(maintenance_engineers, engineer_visits).groupby(['engineer_id', 'first_name', 'last_name']).size().sort_values(ascending=false).reset_index().iloc[0, :3]"
which parts have more than 2 faults? show the part name and its id.,"parts.merge(part_faults, on='part_id').groupby(['part_name', 'part_id']).filter(lambda x: len(x) > 2)[['part_name', 'part_id']].drop_duplicates()"
"provide with a full list of each engineer’s first name, last name, details, and corresponding skill description.","pd.merge(pd.merge(maintenance_engineers, engineer_skills, on='engineer_id'), skills, on='skill_id')[['first_name', 'last_name', 'other_details', 'skill_description']]"
provide a list of faults and the corresponding skills required to fix them.,"pd.merge(pd.merge(part_faults, skills_required_to_fix, on='part_fault_id'), skills, on='skill_id')[['fault_short_name', 'skill_description']]"
what is the maximum number of assets that each parts can be utilized in?,"asset_parts.merge(parts, on='part_id').groupby('part_name').size().reset_index(name='count')[['part_name', 'count']]"
please provide me with the descriptions of faults along with their status that were recorded in the logs.,"pd.merge(fault_log, fault_log_parts, on='fault_log_entry_id')[['fault_description', 'fault_status']]"
how many engineer visits does it take at most to fix one fault? also show me the id of the logged fault.,"pd.merge(fault_log, engineer_visits, on='fault_log_entry_id').groupby('fault_log_entry_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
which surnames are the distinct of all engineers?,maintenance_engineers['last_name'].unique()
list the names of engineers who did not perform maintenance of assets.,"maintenance_engineers[~maintenance_engineers['engineer_id'].isin(engineer_visits['engineer_id'])][['first_name', 'last_name']]"
retrieve the year in which the first asset was acquired.,assets.sort_values('asset_acquired_date').iloc[0]['asset_acquired_date']
what is the number of part faults that require a maximum number of skills to fix?,"(parts.merge(part_faults, on='part_id').merge(skills_required_to_fix, on='part_fault_id').groupby(['part_id', 'part_name'])['part_fault_id'].count().reset_index().sort_values(['part_fault_id', 'part_id'], ascending=[false, true]).iloc[:1, :2])"
which part has the least number of faults? what is the part name?,"(pd.merge(parts, part_faults, on='part_id').groupby('part_name').size().sort_values().index[0])"
"provide the engineer id, first name and last name of the engineer who has made the least number of visitations.","pd.merge(maintenance_engineers, engineer_visits, on='engineer_id').groupby(['engineer_id', 'first_name', 'last_name']).size().sort_values().reset_index().iloc[0][['engineer_id', 'first_name', 'last_name']]"
retrieve names of staff members who have contacted engineers.,"pd.merge(pd.merge(staff, engineer_visits, left_on='staff_id', right_on='contact_staff_id'), maintenance_engineers, on='engineer_id')[['staff_name', 'first_name', 'last_name']]"
determine the skill used to fix the highest number of faults.,"skills.merge(skills_required_to_fix, on='skill_id').groupby(['skill_id','skill_description']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['skill_id','skill_description']]"
retrieve the distinct asset models.,assets['asset_model'].unique()
"please list the make, model and details of assets disposed by date in ascending order.","assets.sort_values('asset_disposed_date')[['asset_make', 'asset_model', 'asset_details']]"
please list the part id and the amount of the least chargeable part.,"parts[['part_id', 'chargeable_amount']].sort_values('chargeable_amount').iloc[0]"
which company started the earliest the maintenance contract and show me the company name?,"pd.merge(third_party_companies, maintenance_contracts.rename(columns={'maintenance_contract_company_id': 'company_id'}), on='company_id').sort_values('contract_start_date').iloc[0]['company_name']"
what is the designation of the company who signed a contract most recently?,"pd.merge(pd.merge(third_party_companies, maintenance_contracts, left_on='company_id', right_on='maintenance_contract_company_id'), ref_company_types, on='company_type_code').sort_values('contract_end_date', ascending=false).iloc[0]['company_name']"
what percentage of staff is comprised of males?,staff.groupby('gender').size().sort_values(ascending=false).index[0]
provide both the staff name and number of engineers contacted.,"engineer_visits.merge(staff, left_on='contact_staff_id', right_on='staff_id').groupby('staff_name').size().reset_index(name='count')"
what assets did not incur any fault log? please list the asset model.,"assets.loc[~assets['asset_id'].isin(fault_log['asset_id']), 'asset_model']"
list the local authorities and services provided by all train stations.,"station[['local_authority', 'services']]"
"what are the train numbers and their corresponding names, ordered from early to late?","train.sort_values('time')[['train_number', 'name']]"
select the trains that are headed to chennai by their time.,"train.loc[train['destination']=='chennai'].sort_values('time')[['time', 'train_number']]"
provide the count of trains with the word 'express' in their names.,train['name'].str.contains('express').sum()
what is the train number of the train that goes from chennai to guruvayur?,"train.loc[(train['origin']=='chennai') & (train['destination']=='guruvayur'), ['train_number', 'time']]"
provide me with the total number of trains that departed on each origination point.,train.groupby('origin').size()
please give me the name of the train whose route passes through the greatest number of stations.,"pd.merge(train, route, on='id').groupby('train_id')['name'].count().idxmax()"
please list all the trains at each station along with the integrated station network name and the services that are provided.,"station.merge(route, on='id').groupby('station_id').agg({'network_name':'first', 'services':'first', 'id':'count'})"
provide me with the average temperature for each day of the week.,weekly_weather.groupby('day_of_week')['high_temperature'].mean()
provide me with the maximum low temperature and average precipitation recorded at the amersham station.,"pd.merge(weekly_weather, station, left_on='station_id', right_on='id').loc[lambda x: x['network_name']=='amersham'].agg({'low_temperature': 'max', 'precipitation': 'mean'})"
retrieve the names of trains that stop at chiltern stations for the local authority.,"pd.merge(pd.merge(station, route, on='id'), train, on='train_id').loc[lambda x: x['local_authority']=='chiltern', ['name', 'time']]"
what is the count of all services supplied by every station?,station['services'].nunique()
please provide me with the id and local authority of the station that has the highest average daily high temperature.,"pd.merge(weekly_weather, station, left_on='station_id', right_on='id').groupby('station_id').agg({'id': 'first', 'local_authority': 'first', 'high_temperature': 'mean'}).sort_values('high_temperature', ascending=false).iloc[0, ['id', 'local_authority']]"
retrieve the id and local authority of the station that experienced the highest recorded precipitation.,"weekly_weather.merge(station, left_on='station_id', right_on='id').groupby('station_id').filter(lambda x: x['precipitation'].max() > 50)[['id', 'local_authority']]"
report the lowest low temperature and highest wind speed in miles per hour.,"weekly_weather.agg({'low_temperature': 'min', 'wind_speed_mph': 'max'})"
find the origins from which 2 or more trains start.,train.groupby('origin').filter(lambda x: len(x) > 1)['origin'].unique()
please provide me with the count of professors in accounting department.,"pd.merge(professor, department, on='dept_code').loc[lambda x: x['dept_name']=='accounting'].shape[0]"
what is the count of accounting professors?,"pd.merge(professor, department, on='dept_code').loc[lambda x: x['dept_name']=='accounting'].shape[0]"
what is the count of professors who are teaching class with code acct-211?,"class.loc[lambda x: x['crs_code']=='acct-211', 'prof_num'].nunique()"
what is the count of professors teaching a class with the code acct-211?,"class.loc[lambda x: x['crs_code']=='acct-211', 'prof_num'].nunique()"
what is the name of the professor from the biology department?,"pd.merge(pd.merge(professor, department, on='dept_code'), employee, on='emp_num').loc[lambda x: x['dept_name']=='biology', ['emp_fname', 'emp_lname']]"
please obtain the names of the professors in the biology department.,"pd.merge(pd.merge(professor, department, on='dept_code'), employee, on='emp_num').loc[lambda x: x['dept_name']=='biology', ['emp_fname', 'emp_lname']]"
retrieve the first and last names of the professors teaching the course acct-211 along with the date of birth.,"pd.merge(employee, class_, left_on='emp_num', right_on='prof_num').loc[lambda x: x['crs_code']=='acct-211', ['emp_fname', 'emp_dob']].drop_duplicates()"
retrieve names of professors as well as specific birthdates involved in teaching acct-211.,"pd.merge(employee, class_, left_on='emp_num', right_on='prof_num').loc[lambda x: x['crs_code']=='acct-211', ['emp_fname', 'emp_dob']].drop_duplicates()"
what is the count of classes taught by professor whose last name is graztevski?,"pd.merge(employee, class, left_on='emp_num', right_on='prof_num').loc[lambda x: x['emp_lname']=='graztevski'].shape[0]"
what is the count of classes that professor graztevski teaches?,"pd.merge(employee, class, left_on='emp_num', right_on='prof_num').loc[lambda x: x['emp_lname']=='graztevski'].shape[0]"
provide me the school code for accounting department.,"department.loc[lambda x: x['dept_name']=='accounting', 'school_code']"
what is the identifier for the school code of the accounting department?,"department.loc[lambda x: x['dept_name']=='accounting', 'school_code']"
what is the number of credits for course cis-220? and what is its description?,"course.loc[course['crs_code'] == 'cis-220', ['crs_credit', 'crs_description']]"
what is the overview of cis-220 and how many credits does it include?,"course.loc[course['crs_code'] == 'cis-220', ['crs_credit', 'crs_description']]"
what is the address history of department?,"department.loc[lambda x: x['dept_name']=='history', 'dept_address']"
please identify the location of the history department.,"department.loc[lambda x: x['dept_name']=='history', 'dept_address']"
what is the count of the different locations of the school with the id bus?,"department.loc[lambda x: x['school_code']=='bus', 'dept_address'].nunique()"
which locations are school with the code bus?,"department.loc[lambda x: x['school_code']=='bus', 'dept_address'].nunique()"
what is the count of schools with multiple locations?,department.groupby('school_code')['dept_address'].nunique()
determine the number of distinct addresses for each school.,department.groupby('school_code')['dept_address'].nunique()
retrieve the description and credit for the course qm-261?,"course.loc[lambda x: x['crs_code']=='qm-261', ['crs_credit', 'crs_description']]"
"provide me the title, course description, and number of credits for qm-261.","course.loc[lambda x: x['crs_code']=='qm-261', ['crs_credit', 'crs_description']]"
determine the count of departments in each school.,department.groupby('school_code')['dept_name'].nunique().reset_index().rename(columns={'dept_name': 'count'})
how many departments are in each university?,department.groupby('school_code')['dept_name'].nunique().reset_index().rename(columns={'dept_name': 'count'})
determine the count of departments in each school that have fewer than 5 different departments.,"department.groupby('school_code').agg({'dept_name': 'nunique'}).reset_index().rename(columns={'dept_name': 'unique_dept_count'}).loc[lambda x: x['unique_dept_count'] < 5].agg({'unique_dept_count': 'count', 'school_code': 'first'})"
which department exists in each school that has less than 5 apartments?,"department.groupby('school_code').agg({'dept_name': 'nunique'}).reset_index().rename(columns={'dept_name': 'unique_dept_count'}).loc[lambda x: x['unique_dept_count'] < 5].agg({'unique_dept_count': 'count', 'school_code': 'first'})"
what is the count for the number of sections in each of the courses?,class.groupby('crs_code').size().reset_index(name='count')
how many categories does each chapter have?,class.groupby('crs_code').size().reset_index(name='count')
what is the total number of credits offered by each department?,course.groupby('dept_code')['crs_credit'].sum()
what is the total count of credits offered by the department?,course.groupby('dept_code')['crs_credit'].sum()
list the number of classes offered for all classrooms that held at least 2 classes.a:the quill and word2vec have similar functionality.,class.groupby('class_room').filter(lambda x: len(x) >=2).groupby('class_room').size().reset_index(name='count(*)')
"for each classroom containing at least two classes, provide the total number of classes.",class.groupby('class_room').filter(lambda x: len(x) >=2).groupby('class_room').size().reset_index(name='count(*)')
list the total number of classes in each department.,"pd.merge(class, course, on='crs_code').groupby('dept_code').size().reset_index(name='count')"
count the number of classes in each institution.,"pd.merge(pd.merge(class, course, on='crs_code'), department, on='dept_code').groupby('school_code').size().reset_index(name='count')"
list the names of schools that exist for different classes.,"pd.merge(pd.merge(class, course, on='crs_code'), department, on='dept_code').groupby('school_code').size().reset_index(name='count')"
what are the count for professors for different school?,"pd.merge(department, professor, on='dept_code').groupby('school_code').size().reset_index(name='count')"
what are the total number of professors from each school?,"pd.merge(department, professor, on='dept_code').groupby('school_code').size().reset_index(name='count')"
give me the count of jobs that have the maximum number of employees.,employee.groupby('emp_jobcode').size().sort_values(ascending=false).head(1)
what is the total number and classification of the job with the greatest number of employees?,employee.groupby('emp_jobcode').size().sort_values(ascending=false).head(1)
what is the count of faculty members of the school that has the fewest number of professors?,"pd.merge(department, professor, on='dept_code').groupby('school_code')['dept_code'].count().sort_values().index[0]"
which institution has the fewest number of professors?,"pd.merge(department, professor, on='dept_code').groupby('school_code')['dept_code'].count().sort_values().index[0]"
provide the count of professors who possess phd degrees in each department.,professor.loc[lambda x: x['prof_high_degree']=='ph.d.'].groupby('dept_code').size().reset_index(name='count')
what is the count of faculty members with ph.d.s in each department?,professor.loc[lambda x: x['prof_high_degree']=='ph.d.'].groupby('dept_code').size().reset_index(name='count')
provide me the count of students for each category.,student.groupby('dept_code').size().reset_index(name='count')
what is the count of students in each class?the example shown above is for only the 1st paragraph. the subsequent paragraphs contain as follows:,student.groupby('dept_code').size().reset_index(name='count')
desired the total of hours spent by students in each department.,student.groupby('dept_code')['stu_hrs'].sum()
what is the total time spent studying in each department?,student.groupby('dept_code')['stu_hrs'].sum()
"what is the max, average, and min gpa for students in each department?","student.groupby('dept_code')['stu_gpa'].agg(['max', 'mean', 'min']).reset_index()"
"what is the gpa of the highest, lowest, and average student in every department?","student.groupby('dept_code')['stu_gpa'].agg(['max', 'mean', 'min']).reset_index()"
provide me the titles of departments whose students have the highest average gpa.,"student.merge(department, on='dept_code').groupby('dept_name')['stu_gpa'].mean().sort_values(ascending=false).head(1).reset_index()"
"which department has the highest average student gpa, and what is the average gpa?","student.merge(department, on='dept_code').groupby('dept_name')['stu_gpa'].mean().sort_values(ascending=false).head(1).reset_index()"
what is the total number of schools that are in place?,department['school_code'].nunique()
how many different classes exist?,class['class_code'].nunique()
how many unique courses are taught?,class['class_code'].nunique()
which courses are being offered?,class['crs_code'].nunique()
what is the number of unique course codes?,class['crs_code'].nunique()
how many departments does the college have?,department['dept_name'].nunique()
how many different departments are present?,department['dept_name'].nunique()
how many courses are provided by the computer informational systems department?,"pd.merge(department.loc[lambda x: x['dept_name'] == ""computer info. systems""], course, on='dept_code').shape[0]"
how many courses are provided by the department of computer information systems?,"pd.merge(department.loc[lambda x: x['dept_name'] == ""computer info. systems""], course, on='dept_code').shape[0]"
how many sections does the course acct-211 possess?,"class.loc[lambda x: x['crs_code']=='acct-211', 'class_section'].nunique()"
what number of different class sections are offered in acct-211?,"class.loc[lambda x: x['crs_code']=='acct-211', 'class_section'].nunique()"
provide me with the credits for all courses taught by each department.,"pd.merge(course, class, on='crs_code').groupby('dept_code')['crs_credit'].sum()"
what is the department that provides the highest number of credits of all of the courses?,"pd.merge(pd.merge(course, class_, on='crs_code'), department, on='dept_code').groupby('dept_name').agg(total_credit=('crs_credit','sum')).sort_values('total_credit', ascending=false).head(1).index.values[0]"
which department offers the most credits in total?,"pd.merge(pd.merge(course, class_, on='crs_code'), department, on='dept_code').groupby('dept_name').agg(total_credit=('crs_credit','sum')).sort_values('total_credit', ascending=false).head(1).index.values[0]"
determine the total number of students enrolled in class acct-211.,"pd.merge(class, enroll, on='class_code').loc[lambda x: x['crs_code']=='acct-211'].shape[0]"
list the number of students enrolled in acct-211 program.,"pd.merge(class, enroll, on='class_code').loc[lambda x: x['crs_code']=='acct-211'].shape[0]"
does each student enrolled in class acct-211 have a first name?,"pd.merge(pd.merge(class.loc[lambda x: x['crs_code']=='acct-211'], enroll, on='class_code'), student, on='stu_num')['stu_fname']"
provide me with the first name of every student enrolled in course acct-211.,"pd.merge(pd.merge(class.loc[lambda x: x['crs_code']=='acct-211'], enroll, on='class_code'), student, on='stu_num')['stu_fname']"
provide me with the first name of students enrolled in class acct-211 and received grade c in the exam.,"pd.merge(pd.merge(students, enroll, on='stu_num'), classes, on='class_code').loc[(lambda x: (x['enroll_grade'] == 'c') & (x['crs_code'] == 'acct-211')), 'stu_fname']"
determine the first names of all students who took acct-211 and earned a c.,"pd.merge(pd.merge(students, enroll, on='stu_num'), classes, on='class_code').loc[(lambda x: (x['enroll_grade'] == 'c') & (x['crs_code'] == 'acct-211')), 'stu_fname']"
how many employees are there in total?,employee.shape[0]
what is the total number of employees present?,employee.shape[0]
what is the count of professors who have ph.d. degrees?,(professor['prof_high_degree']=='ph.d.').sum()
what is the number of professors that possess a ph.d.?,(professor['prof_high_degree']=='ph.d.').sum()
what is the count of students that are registered for classes taught by an accounting professor?,"(pd.merge(pd.merge(pd.merge(class, enroll, on='class_code'), course, on='crs_code'), department, on='dept_code').loc[lambda x: x['dept_name']=='accounting'].shape[0])"
what is the name of the department that has the highest number of students enrolled?,"(pd.merge(pd.merge(pd.merge(class, enroll, on='class_code'), course, on='crs_code'), department, on='dept_code').groupby('dept_name').size().sort_values(ascending=false).reset_index().loc[0,'dept_name'])"
what is the department code that contains the highest number of students?,"(pd.merge(pd.merge(pd.merge(class, enroll, on='class_code'), course, on='crs_code'), department, on='dept_code').groupby('dept_name').size().sort_values(ascending=false).reset_index().loc[0,'dept_name'])"
print the names of departments sorted by their names.,department.sort_values('dept_name')['dept_name']
please return to me the names of all departments in alphabetical order.,department.sort_values('dept_name')['dept_name']
please provide me with the lists of codes of all courses that take place in room klr209.,"class.loc[lambda x: x['class_room']=='klr209', 'class_code']"
fetch the codes of all the courses that are located in room klr209.,"class.loc[lambda x: x['class_room']=='klr209', 'class_code']"
"list the first and last names of all employees that are professors, arranged from oldest to youngest.",employee.loc[employee['emp_jobcode']=='prof'].sort_values('emp_dob')['emp_fname']
"return the first and last name of all professors, sorted in alphabetical order.","pd.merge(professor, employee, on='emp_num').sort_values('emp_fname')[['emp_fname', 'prof_office']]"
retrieve the names and office locations for all professors. sort them alphabetically by first name.,"pd.merge(professor, employee, on='emp_num').sort_values('emp_fname')[['emp_fname', 'prof_office']]"
provide me the first name and surname of the oldest employee.,"employee[['emp_fname', 'emp_lname']].sort_values('emp_dob').head(1)"
kindly provide me with the first and last name of the employee with the earliest date of employment.,"employee[['emp_fname', 'emp_lname']].sort_values('emp_dob').head(1)"
please provide me with the details of the youngest student among those whose gpa is above 3.,"student.loc[lambda x: x['stu_gpa'] > 3, ['stu_fname', 'stu_lname', 'stu_gpa', 'stu_dob']].sort_values('stu_dob', ascending=false).head(1)[['stu_fname', 'stu_lname', 'stu_gpa']]"
please provide me with the full name and gpa of the youngest student with a gpa above 3.,"student.loc[lambda x: x['stu_gpa'] > 3, ['stu_fname', 'stu_lname', 'stu_gpa', 'stu_dob']].sort_values('stu_dob', ascending=false).head(1)[['stu_fname', 'stu_lname', 'stu_gpa']]"
what are the first names of all students who obtained grades c in a course?,"pd.merge(student, enroll, on='stu_num').loc[lambda x: x['enroll_grade']=='c', 'stu_fname'].unique()"
which department has the fewest number of professors?,"pd.merge(professor, department, on='dept_code').groupby('dept_code')['dept_name'].count().sort_values().head(1)"
what are the department names which have the fewest professors?,"pd.merge(professor, department, on='dept_code').groupby('dept_code')['dept_name'].count().sort_values().head(1)"
what is the name of the department where has the maximum count of professors with a ph.d. degree?,"professor.merge(department, on='dept_code').loc[lambda x: x['prof_high_degree']=='ph.d.'].groupby('dept_code')['dept_name'].count().reset_index().rename(columns={'dept_name': 'count'}).sort_values('count', ascending=false).iloc[0][['dept_name', 'dept_code']]"
which department has the most professors who have earned a ph.d.?,"professor.merge(department, on='dept_code').loc[lambda x: x['prof_high_degree']=='ph.d.'].groupby('dept_code')['dept_name'].count().reset_index().rename(columns={'dept_name': 'count'}).sort_values('count', ascending=false).iloc[0][['dept_name', 'dept_code']]"
please return me the names of professors who are not teaching any class.,"employee.loc[lambda x: (x['emp_jobcode']=='prof') & (~x['emp_num'].isin(class['prof_num'])), 'emp_fname']"
retrieve the title of all professors not teaching any classes.,"employee.loc[lambda x: (x['emp_jobcode']=='prof') & (~x['emp_num'].isin(class['prof_num'])), 'emp_fname']"
retrieve the names of professors from the history department that do not teach classes.,"employee.merge(professor, on='emp_num').merge(department, on='dept_code').query('dept_name==""history""')['emp_fname'].unique().difference(employee.merge(class, left_on='emp_num', right_on='prof_num')['emp_fname'])"
what are the first names of all the history professors who do not teach?,"employee.merge(professor, on='emp_num').merge(department, on='dept_code').query('dept_name==""history""')['emp_fname'].unique().difference(employee.merge(class, left_on='emp_num', right_on='prof_num')['emp_fname'])"
which name is the last name and official title of the professor from the history department?,"pd.merge(pd.merge(employee, professor, on='emp_num'), department, on='dept_code').loc[lambda x: x['dept_name']=='history', ['emp_lname', 'prof_office']]"
what is the complete list of last names and offices of all history professors?,"pd.merge(pd.merge(employee, professor, on='emp_num'), department, on='dept_code').loc[lambda x: x['dept_name']=='history', ['emp_lname', 'prof_office']]"
what is the name and office id of the professor whose last name is heffington?,"pd.merge(pd.merge(employee, professor, on='emp_num'), department, on='dept_code').loc[lambda x: x['emp_lname']=='heffington', ['dept_name', 'prof_office']]"
please identify the name of the department and office location of a professor with the last name of heffington.,"pd.merge(pd.merge(employee, professor, on='emp_num'), department, on='dept_code').loc[lambda x: x['emp_lname']=='heffington', ['dept_name', 'prof_office']]"
retrieve the last name and date of employment of the professor of the office at dre 102.,"pd.merge(employee, professor, on='emp_num').loc[lambda x: x['prof_office']=='dre 102', ['emp_lname', 'emp_hiredate']]"
what is the code for the course the student whose surname is smithson took?,"pd.merge(pd.merge(class, enroll, on='class_code'), student, on='stu_num').loc[lambda x: x['stu_lname']=='smithson', 'crs_code']"
"please describe the course which the student whose last name was smithson took, and provide their instructor's name.","pd.merge(pd.merge(pd.merge(student.loc[lambda x: x['stu_lname']=='smithson'], enroll, on='stu_num'), class, on='class_code'), course, on='crs_code')[['crs_description', 'crs_credit']]"
"what is the credits of the class that the student with the last name smithson took, and describe its description?","pd.merge(pd.merge(pd.merge(student.loc[lambda x: x['stu_lname']=='smithson'], enroll, on='stu_num'), class, on='class_code'), course, on='crs_code')[['crs_description', 'crs_credit']]"
what are the count of professors with either ph.d. degree or ma degree?,"professor.loc[lambda x: x['prof_high_degree'].isin(['ph.d.', 'ma'])].shape[0]"
how many faculty members have attained either a ph.d. or masters degree?,"professor.loc[lambda x: x['prof_high_degree'].isin(['ph.d.', 'ma'])].shape[0]"
what is the count of professors who belong to either accounting or biology areas?,"pd.merge(professor, department, on='dept_code').loc[lambda x: x['dept_name'].isin(['accounting', 'biology'])].shape[0]"
what is the number of professors who are in the accounting or the biology departments?,"pd.merge(professor, department, on='dept_code').loc[lambda x: x['dept_name'].isin(['accounting', 'biology'])].shape[0]"
provide the last name of the first professor who teaches two courses with the codes cis-220 and qm-261.,"pd.merge(employee[employee['emp_num'].isin(classroom[classroom['crs_code']=='cis-220']['prof_num'].unique())]['emp_fname'], employee[employee['emp_num'].isin(classroom[classroom['crs_code']=='qm-261']['prof_num'].unique())]['emp_fname'])"
what is the first name of the professor who teaches cis-220 and qm-261?,"pd.merge(employee[employee['emp_num'].isin(classroom[classroom['crs_code']=='cis-220']['prof_num'].unique())]['emp_fname'], employee[employee['emp_num'].isin(classroom[classroom['crs_code']=='qm-261']['prof_num'].unique())]['emp_fname'])"
obtain the first name of students who are taking classes from the departments of accounting and computer information systems.,"pd.merge(pd.merge(pd.merge(pd.merge(student, enroll, on='stu_num'), class, on='class_code'), course, on='crs_code'), department, on='dept_code').loc[lambda x: x['dept_name']=='accounting', 'stu_fname'].unique() & pd.merge(pd.merge(pd.merge(pd.merge(student, enroll, on='stu_num'), class, on='class_code'), course, on='crs_code'), department, on='dept_code').loc[lambda x: x['dept_name']=='computer info. systems', 'stu_fname'].unique()"
retrieve the first names of all students taking accounting and computer information systems classes.,"pd.merge(pd.merge(pd.merge(pd.merge(student, enroll, on='stu_num'), class, on='class_code'), course, on='crs_code'), department, on='dept_code').loc[lambda x: x['dept_name']=='accounting', 'stu_fname'].unique() & pd.merge(pd.merge(pd.merge(pd.merge(student, enroll, on='stu_num'), class, on='class_code'), course, on='crs_code'), department, on='dept_code').loc[lambda x: x['dept_name']=='computer info. systems', 'stu_fname'].unique()"
what is the gpa of students who were enrolled in acct-211?,"enroll.merge(student, on='stu_num').merge(class, on='class_code').loc[lambda x: x['crs_code']=='acct-211', 'stu_gpa'].mean()"
please provide me with the 5 students with the highest gpa.,"student[['stu_gpa', 'stu_phone', 'stu_fname']].sort_values('stu_gpa', ascending=false).head(5)"
"provide me with the first name, gpa, and phone number of the students with the top five gpas.","student[['stu_gpa', 'stu_phone', 'stu_fname']].sort_values('stu_gpa', ascending=false).head(5)"
what are the department names in which the students who had the lowest gpas belong?,"pd.merge(student, department, on='dept_code').sort_values('stu_gpa').iloc[0]['dept_name']"
what is the name of the department that has a student with the lowest gpa?,"pd.merge(student, department, on='dept_code').sort_values('stu_gpa').iloc[0]['dept_name']"
identify the names of the students whose gpa is lower than the average gpa of all.,"student.loc[lambda x: x['stu_gpa'] < student['stu_gpa'].mean(), ['stu_fname', 'stu_gpa']]"
find the names of all students whose gpa is lower than the average gpa.,"student.loc[lambda x: x['stu_gpa'] < student['stu_gpa'].mean(), ['stu_fname', 'stu_gpa']]"
list out the departments that have the highest number of students.,"student.merge(department, on='dept_code').groupby('dept_code')[['dept_name', 'dept_address']].first().nlargest(1, 'dept_code').reset_index(drop=true)"
please supply me with the name and address of the department that has the highest number of students.,"student.merge(department, on='dept_code').groupby('dept_code')[['dept_name', 'dept_address']].first().nlargest(1, 'dept_code').reset_index(drop=true)"
"retrieve the name, address, and number of students of the departments with the highest count of students.","student.merge(department, on='dept_code').groupby(['dept_name', 'dept_address'])['dept_code'].count().sort_values(ascending=false).head(3).reset_index()"
"list the names of departments having the most students, along with their address and the number of students in them.","student.merge(department, on='dept_code').groupby(['dept_name', 'dept_address'])['dept_code'].count().sort_values(ascending=false).head(3).reset_index()"
give me a professor who has a ph.d. degree in the history department and whose first name is liz.,"employee.merge(professor, on='emp_num').merge(department, on='dept_code').loc[lambda x: (x['dept_name']=='history') & (x['prof_high_degree']=='ph.d.'), ['emp_fname', 'prof_office']]"
which professors have a ph.d. degree and are a part of the history department?,"employee.merge(professor, on='emp_num').merge(department, on='dept_code').loc[lambda x: (x['dept_name']=='history') & (x['prof_high_degree']=='ph.d.'), ['emp_fname', 'prof_office']]"
find the first names of all the instructors who have taught some course and the course code.,"pd.merge(class, employee, left_on='prof_num', right_on='emp_num')[['emp_fname', 'crs_code']]"
list the first names of all teachers that have taught a specific course and their corresponding course codes.,"pd.merge(class, employee, left_on='prof_num', right_on='emp_num')[['emp_fname', 'crs_code']]"
retrieve the first names of instructors who have taught some course and the course description.,"pd.merge(pd.merge(class, employee, left_on='prof_num', right_on='emp_num'), course, on='crs_code')[['emp_fname', 'crs_description']]"
retrieve the first and last names of professors teaching a particular course along with complete descriptions of the courses.,"pd.merge(pd.merge(class, employee, left_on='prof_num', right_on='emp_num'), course, on='crs_code')[['emp_fname', 'crs_description']]"
"provide me with the names, positions, and details of the instructors who have taught some subject along with their corresponding course and course description.","pd.merge(pd.merge(pd.merge(class, employee, left_on='prof_num', right_on='emp_num'), course, on='crs_code'), professor, on='emp_num')[['emp_fname', 'prof_office', 'crs_description']]"
retrieve the ids and locations of all lecturers who have taught some course.,"pd.merge(pd.merge(pd.merge(class, employee, left_on='prof_num', right_on='emp_num'), course, on='crs_code'), professor, on='emp_num')[['emp_fname', 'prof_office', 'crs_description']]"
list the instructors along with the course description and the department name who have taught some course.,"pd.merge(pd.merge(pd.merge(pd.merge(class, employee, left_on='prof_num', right_on='emp_num'), course, on='crs_code'), professor, left_on='emp_num_y', right_on='emp_num'), department, on='dept_code')[['emp_fname', 'prof_office', 'crs_description', 'dept_name']]"
"retrieve the name, office location, and department of all instructors, and list their descriptions and courses that they teach.","pd.merge(pd.merge(pd.merge(pd.merge(class, employee, left_on='prof_num', right_on='emp_num'), course, on='crs_code'), professor, left_on='emp_num_y', right_on='emp_num'), department, on='dept_code')[['emp_fname', 'prof_office', 'crs_description', 'dept_name']]"
provide the names of all students who took some course along with the course description.,"pd.merge(pd.merge(pd.merge(student, enroll, on='stu_num'), class, on='class_code'), course, on='crs_code')[['stu_fname', 'stu_lname', 'crs_description']]"
retrieve the names of all students that enrolled in a particular class and the course description for each.,"pd.merge(pd.merge(pd.merge(student, enroll, on='stu_num'), class, on='class_code'), course, on='crs_code')[['stu_fname', 'stu_lname', 'crs_description']]"
retrieve the names of all students who took a course and got an a or a c in the course.,"student.merge(enroll, on='stu_num').loc[lambda x: x['enroll_grade'].isin(['c', 'a']), ['stu_fname', 'stu_lname']]"
list the names of the students who are taking the course with an a or c.,"student.merge(enroll, on='stu_num').loc[lambda x: x['enroll_grade'].isin(['c', 'a']), ['stu_fname', 'stu_lname']]"
list all professors in the accounting department who are teaching some course and the class room.,"pd.merge(pd.merge(pd.merge(class_room, employee, left_on='prof_num', right_on='emp_num'), professor, on='emp_num'), department, left_on='dept_code', right_on='dept_code').loc[lambda x: x['dept_name']=='accounting', ['emp_fname', 'class_room']]"
retrieve the complete names of professors of accounting department and the classroom in which each professor teaches.,"pd.merge(pd.merge(pd.merge(class_room, employee, left_on='prof_num', right_on='emp_num'), professor, on='emp_num'), department, left_on='dept_code', right_on='dept_code').loc[lambda x: x['dept_name']=='accounting', ['emp_fname', 'class_room']]"
retrieve the first and last names and degree of all professors who are teaching some class in the computer information systems department.,"pd.merge(pd.merge(pd.merge(class, employee, left_on='prof_num', right_on='emp_num'), professor, on='emp_num'), department, on='dept_code').loc[lambda x: x['dept_name']=='computer info. systems', ['emp_fname', 'prof_high_degree']].drop_duplicates()"
list the first and last names of professors in the computer information systems department along with the department in which they work and their degree.,"pd.merge(pd.merge(pd.merge(class, employee, left_on='prof_num', right_on='emp_num'), professor, on='emp_num'), department, on='dept_code').loc[lambda x: x['dept_name']=='computer info. systems', ['emp_fname', 'prof_high_degree']].drop_duplicates()"
obtain the last name of the first student who obtained a grade a in the class numbered 10018.,"pd.merge(student, enroll.loc[(enroll['enroll_grade']=='a') & (enroll['class_code']==10018), 'stu_num'], on='stu_num')['stu_lname']"
which history professor does not have a ph.d.?,"pd.merge(pd.merge(professor, employee, on='emp_num'), department, on='dept_code').loc[(lambda x: x['dept_name']=='history') & ~(lambda x: x['prof_high_degree']==""ph.d.""), ['emp_fname', 'prof_office']]"
can you provide me with the names of history professors who do not have ph.d. degrees along with their office location?,"pd.merge(pd.merge(professor, employee, on='emp_num'), department, on='dept_code').loc[(lambda x: x['dept_name']=='history') & ~(lambda x: x['prof_high_degree']==""ph.d.""), ['emp_fname', 'prof_office']]"
"have the names and classes of all professors who are teaching more than one class, as well as the number of classes they are teaching in the same order.","pd.merge(class, employee, left_on='prof_num', right_on='emp_num').groupby('prof_num').filter(lambda x: x['emp_num'].count() > 1)['emp_fname']"
what are the first names of professors who teach more than one class?,"pd.merge(class, employee, left_on='prof_num', right_on='emp_num').groupby('prof_num').filter(lambda x: x['emp_num'].count() > 1)['emp_fname']"
retrieve the first names of students who took exactly one class.,"student.merge(enroll, on='stu_num').groupby('stu_num').filter(lambda x: len(x) == 1)['stu_fname']"
please provide me the names of students who only took a single course.,"student.merge(enroll, on='stu_num').groupby('stu_num').filter(lambda x: len(x) == 1)['stu_fname']"
"fetch the title of the department offering the class whose description has the word ""statistics"".","pd.merge(course, department, on='dept_code').loc[lambda x: x['crs_description'].str.contains('statistics'), 'dept_name']"
identify the department that offers a course that is tagged as a statistics course.,"pd.merge(course, department, on='dept_code').loc[lambda x: x['crs_description'].str.contains('statistics'), 'dept_name']"
what is the count of clubs?,club.shape[0] or len(club)
please list the string of regions in ascending alphabetical order.,club['region'].sort_values().unique()
provide the names of the regions in which clubs are listed alphabetically.,club['region'].sort_values().unique()
what is the average number of golds for clubs?,club_rank['gold'].mean()
determine the average number of gold medals won by each club.,club_rank['gold'].mean()
list out the types of competitions and the countries involved.,"competition[['competition_type', 'country']]"
provide me the types of every competition according to the countries they are conducted.,"competition[['competition_type', 'country']]"
"what are the distinct years in which the type of competition is not ""tournament""?","competition.loc[lambda x: x['competition_type'] != 'tournament', 'year'].unique()"
what are the years for competitions that are not of type equal to tournament?,"competition.loc[lambda x: x['competition_type'] != 'tournament', 'year'].unique()"
what are the maximum and minimum number of silver medals for clubs?,"club_rank['silver'].agg(['max', 'min'])"
determine the maximum and minimum count of silvers medals earned by all the clubs in fifa.,"club_rank['silver'].agg(['max', 'min'])"
what are the clubs with least total medals?,(club_rank['total'] < 10).sum()
retrieve the total count of clubs that hold less than 10 medals in total.,(club_rank['total'] < 10).sum()
please list all the clubs in ascending order of start year.,club.sort_values('start_year')['name']
retrieve the names of all clubs starting with the oldest.,club.sort_values('start_year')['name']
produce a descending list of the titles of clubs.,"club.sort_values('name', ascending=false)['name']"
what is the list of all clubs ordered in descending alphabetical order?,"club.sort_values('name', ascending=false)['name']"
display the names of clubs and the players of the clubs.,"pd.merge(club, player, on='club_id')[['name', 'player_id']]"
retrieve the lists of players and clubs.,"pd.merge(club, player, on='club_id')[['name', 'player_id']]"
"provide me with the name of all clubs that possess players with a position of ""right wing"".","pd.merge(club, player.query(""position == 'right wing'""), on='club_id')['name']"
"list the names of the clubs whose players have the position of ""right wing"".","pd.merge(club, player.query(""position == 'right wing'""), on='club_id')['name']"
"what is the mean score of players belonging to the ""aib"" club?","player.loc[player['club_id'].isin(club.loc[club['name']=='aib', 'club_id']), 'points'].mean()"
list the names of players along with their corresponding positions and average number of points.,player.groupby('position')['points'].mean()
"for each position, provide the average number of points scored by players in that position.",player.groupby('position')['points'].mean()
show me the names of players that have an average of points scored by players of their position larger than 20.,player.groupby('name').filter(lambda x: x['points'].mean() >= 20)['position']
count the total number of players whose average score by position is larger than 20.,player.groupby('name').filter(lambda x: x['points'].mean() >= 20)['position']
"provide me the details of competitions, including their names, and categorize them based on their types.",competition.groupby('competition_type').size().reset_index(name='count')
what are the types of competitions and count the number of competitions of that type?,competition.groupby('competition_type').size().reset_index(name='count')
which is the most frequently utilized competition type?,competition.groupby('competition_type').size().sort_values(ascending=false).index[0]
determine the count of competitions that have at most five competitions of that type.,competition.groupby('competition_type').filter(lambda x: len(x) <= 5).drop_duplicates('competition_type')['competition_type']
what type of competition exhibits the highest number of 5 performances?,competition.groupby('competition_type').filter(lambda x: len(x) <= 5).drop_duplicates('competition_type')['competition_type']
please inform me about the names of the clubs that do not feature any members.,"club.loc[~club['club_id'].isin(player['club_id']), 'name']"
fetch the names of all clubs that do not have players.,"club.loc[~club['club_id'].isin(player['club_id']), 'name']"
what is the count of positions in which the players have more than 20 points but less than 10 points?,"set(player.loc[player['points'] > 20, 'position']).intersection(set(player.loc[player['points'] < 10, 'position']))"
provide me with the scores of players that have more than 20 and less than 10 points.,"set(player.loc[player['points'] > 20, 'position']).intersection(set(player.loc[player['points'] < 10, 'position']))"
provide me with the total points of all players.,player['points'].sum()
what is the number of points awarded all athletes?,player['points'].sum()
how many different positions are there?,player['position'].nunique()
how many different positions for players are specified?,player['position'].nunique()
provide the names of players that exceed the average points earned.,"player.loc[player['points'] > player['points'].mean(), 'name']"
retrieve the names of players that acquired more than the aggregate amount of points.,"player.loc[player['points'] > player['points'].mean(), 'name']"
find the total number of players whose points are lesser than 30.,player.loc[player['points'] < 30].groupby('position').size().reset_index(name='count')
generate the number of players with scores less than 30 for each position.,player.loc[player['points'] < 30].groupby('position').size().reset_index(name='count')
what is the country that participated in the largest number of tournaments?,"competition.loc[lambda x: x['competition_type']=='tournament', 'country'].value_counts().index[0]"
what is the nationality of the team that took part the most often in competitions?,"competition.loc[lambda x: x['competition_type']=='tournament', 'country'].value_counts().index[0]"
which countries participated in both friendly and tournament type competitions.,"pd.merge(competition.loc[lambda x: x['competition_type']=='friendly', 'country'], competition.loc[lambda x: x['competition_type']=='tournament', 'country']).drop_duplicates()"
which countries participated in both friendly competitions and tournament type events?,"pd.merge(competition.loc[lambda x: x['competition_type']=='friendly', 'country'], competition.loc[lambda x: x['competition_type']=='tournament', 'country']).drop_duplicates()"
make a list of the countries which have never taken part in any friendly competition.,"competition['country'].drop(competition.loc[competition['competition_type']=='friendly', 'country'].index).unique()"
which countries have never participated in friendly competitions?,"competition['country'].drop(competition.loc[competition['competition_type']=='friendly', 'country'].index).unique()"
what is the total number of furniture components?,furniture['num_of_component'].sum()
please return the name and id of the highest priced furniture.,"furniture[['name', 'furniture_id']].sort_values('market_rate', ascending=false).iloc[[0]]"
find the rates at which furnitures having the top two market shares.,"furniture.sort_values('market_rate', ascending=false).head(2)['market_rate'].sum()"
retrieve the names and component quantities of all furnitures that have more than 10 units.,"furniture.loc[lambda x: x['num_of_component'] > 10, ['num_of_component', 'name']]"
provide the name and quantity of the least popular furniture.,"furniture[['name', 'num_of_component']].sort_values('market_rate').iloc[0]"
retrieve the names of furnitures whose prices are less than the highest.,"furniture.loc[lambda x: x['furniture_id'].isin(furniture_manufacte.loc[lambda y: y['price_in_dollar'] < furniture_manufacte['price_in_dollar'].max(), 'furniture_id']), 'name']"
which manufacturer has the highest number of stores? provide the name and year of establishment.,"manufacturer[['open_year', 'name']].sort_values('num_of_shops', ascending=false).iloc[0]"
what is the average count of factories for those manufacturers that have more than 20 shops?,"manufacturer.loc[lambda x: x['num_of_shops'] > 20, 'num_of_factories'].mean()"
list all manufacturer ids and full names ordered by opening year.,"manufacturer[['name', 'manufacturer_id']].sort_values('open_year')"
give me the id and complete name of manufacturers that have either less than 10 factories or more than 10 shops.,"manufacturer.loc[(manufacturer['num_of_shops']>10) | (manufacturer['num_of_factories']<10), ['name', 'open_year']]"
what is the mean number of factories and maximum quantity of shops for manufacturers that opened prior to 1990?,"manufacturer.loc[manufacturer['open_year'] < 1990, ['num_of_shops', 'num_of_factories']].agg({'num_of_shops': 'max', 'num_of_factories': 'mean'})"
provide the id and number of the company that manufactures the most expensive furniture.,"pd.merge(manufacturer, furniture_manufacte, on='manufacturer_id').sort_values('price_in_dollar', ascending=false).iloc[0][['manufacturer_id', 'num_of_shops']]"
provide me with the total number of furniture types manufactured by each company along with their corresponding names.,"pd.merge(manufacturer, furniture_manufacte, on='manufacturer_id').groupby('manufacturer_id')['name'].count().reset_index(name='count')"
query the name of the manufacturers and the prices of furnitures that they are producing.,"pd.merge(furniture, furniture_manufacte, on='furniture_id')[['name', 'price_in_dollar']]"
determine the shares and titles of furnitures that none of the companies in our records produced.,"furniture[~furniture['furniture_id'].isin(furniture_manufacte['furniture_id'])][['market_rate', 'name']]"
retrieve the names of the companies that are known to produce both furnitures with less than 6 components and furnitures with more than 10 components.,"pd.merge(pd.merge(furniture, furniture_manufacte, on='furniture_id'), manufacturer, on='manufacturer_id').loc[lambda x: x['num_of_component'] < 6, 'name'].unique() & pd.merge(pd.merge(furniture, furniture_manufacte, on='furniture_id'), manufacturer, on='manufacturer_id').loc[lambda x: x['num_of_component'] > 10, 'name'].unique()"
list the first names and departments corresponding to each employee.,"pd.merge(employees, departments, on='department_id')[['first_name', 'department_name']]"
what are the names of all employees and their departments?,"pd.merge(employees, departments, on='department_id')[['first_name', 'department_name']]"
"provide me the full name, salary, and department name for the employees who earn less than 6000.","employees.loc[lambda x: x['salary'] < 6000, ['first_name', 'last_name', 'salary']]"
obtain the name and salary of employees earning less than 6000.,"employees.loc[lambda x: x['salary'] < 6000, ['first_name', 'last_name', 'salary']]"
"provide me a list of employees whose last name is ""mcewen"" along with their first name and department number.","employees.loc[lambda x: x['last_name']=='mcewen', ['first_name', 'department_id']]"
what are the first names and department numbers for employees whose last name is mcewen?,"employees.loc[lambda x: x['last_name']=='mcewen', ['first_name', 'department_id']]"
please return the details of all employees without any department number.,employees.loc[employees['department_id'].isnull()]
provide the names of the employees who have no department number assigned to them.,employees.loc[employees['department_id'].isnull()]
please provide me all the information on marketing department.,departments.loc[lambda x: x['department_name']=='marketing']
what is the hire date for employees whose first names not containing the letter m?,"employees.loc[~employees['first_name'].str.contains('m'), 'hire_date']"
on what dates were employees without a name beginning with the letter m hired?,"employees.loc[~employees['first_name'].str.contains('m'), 'hire_date']"
provide me with the list of employees whose first names do not begin with the letter m.,"employees.loc[~employees['first_name'].str.contains('m'), ['first_name', 'last_name', 'hire_date', 'salary', 'department_id']]"
"please provide the names, hire date, salary, and department id for personnel who don't have the letter m in their first name.","employees.loc[~employees['first_name'].str.contains('m'), ['first_name', 'last_name', 'hire_date', 'salary', 'department_id']]"
please provide a count of employees whose salary is between 8000 and 12000.,"employees.loc[lambda x: x['salary'].between(8000, 12000), 'phone_number']"
please provide me with the phone numbers of the employees with salaries between $8000 and $12000.,"employees.loc[lambda x: x['salary'].between(8000, 12000), 'phone_number']"
provide me the details of employees whose salary is between 8000 and 12000 and whose commission is not null and whose department number is not equal to 40.,"employees.loc[(employees['salary'].between(8000, 12000)) & (employees['commission_pct'] != ""null"") | (employees['department_id'] != 40)]"
give me all the information about employees whose salary is between 8000 and 12000 and whose commission is not null or whose department id is not 40.,"employees.loc[(employees['salary'].between(8000, 12000)) & (employees['commission_pct'] != ""null"") | (employees['department_id'] != 40)]"
retrieve the names of employees and their salary that do not contain commission.,"employees.loc[employees['commission_pct'].isnull(), ['first_name', 'last_name', 'salary']]"
retrieve the full name and salary of employees with null commission.,"employees.loc[employees['commission_pct'].isnull(), ['first_name', 'last_name', 'salary']]"
"please display the title, last name, and salary of those employees whose first name ends with the letter m.","employees.loc[employees['first_name'].str.contains('m'), ['first_name', 'last_name', 'salary']]"
provide me with the full name and salary of the employees whose first names end with the letter m.,"employees.loc[employees['first_name'].str.contains('m'), ['first_name', 'last_name', 'salary']]"
"deduce the job id and date of hire for those employees who were hired by date between 5th november, 2007 and 5th july, 2009.","employees.loc[(employees['hire_date'] >= '2007-11-05') & (employees['hire_date'] <= '2009-07-05'), ['job_id', 'hire_date']]"
"what are the ids and dates of hire for employees hired after november 5, 2007 and before july 5, 2009?","employees.loc[(employees['hire_date'] >= '2007-11-05') & (employees['hire_date'] <= '2009-07-05'), ['job_id', 'hire_date']]"
retrieve the first and last names of employees affiliated with either department 70 or department 90.,"employees.loc[lambda x: x['department_id'].isin([70, 90]), ['first_name', 'last_name']]"
which employees are employed within either department 70 or 90?,"employees.loc[lambda x: x['department_id'].isin([70, 90]), ['first_name', 'last_name']]"
retrieve the salaries of employees who are managed by a manager.,"employees[employees['manager_id'].notnull()][['salary', 'manager_id']]"
what is the salary and manager id for employees that have managers?,"employees[employees['manager_id'].notnull()][['salary', 'manager_id']]"
"how many employees are hired before june 21, 2002?",employees[employees['hire_date'] < '2002-06-21']
please list the names of employees that have 'd' or 's' in their first names and also provide me their salaries in descending order.,"employees.loc[employees['first_name'].str.contains('d|s', regex=true)].sort_values('salary', ascending=false)"
"provide me with the names and salaries of employees with letters d and s in their first name, in ascending order.","employees.loc[employees['first_name'].str.contains('d|s', regex=true)].sort_values('salary', ascending=false)"
"return the names of employees who joined the organization after september 7th, 1987.",employees.loc[lambda x: x['hire_date'] > '1987-09-07']
"please provide me with the names of employees who were added to their companies after september 7th, 1987.",employees.loc[lambda x: x['hire_date'] > '1987-09-07']
display the job titles of the jobs that pay more than 9000 usd.,"jobs.loc[jobs['min_salary'] > 9000, 'job_title']"
list the titles of jobs that correspond to the salaries exceeding 9000.,"jobs.loc[jobs['min_salary'] > 9000, 'job_title']"
"provide me with the job title, the difference between the minimum and maximum salaries for those jobs that fall within the range of 12000 to 18000.","jobs.loc[jobs['max_salary'].between(12000, 18000), ['job_title', 'max_salary', 'min_salary']].assign(diff=lambda x: x['max_salary'] - x['min_salary'])[['job_title', 'diff']]"
"what are the job titles, and salaries for jobs whose salary is between 12,000 and 18,000?","jobs.loc[jobs['max_salary'].between(12000, 18000), ['job_title', 'max_salary', 'min_salary']].assign(diff=lambda x: x['max_salary'] - x['min_salary'])[['job_title', 'diff']]"
"please provide me with the names of employees with null commission, salary between 7000 and 12000, and who work in department 50 along with their email addresses.","employees.loc[(employees['commission_pct'].isnull()) & (employees['salary'].between(7000, 12000)) & (employees['department_id'] == 50), 'email']"
show the employee id and the date on which the employee left his previous job.,job_history.groupby('employee_id')['end_date'].max().reset_index()
provide me with a list of employee ids and dates of employment for each employee at their last job.,job_history.groupby('employee_id')['end_date'].max().reset_index()
please display those departments where more than ten employees work who got a commission percentage.,employees.groupby('department_id').filter(lambda x: x['commission_pct'].count() > 10)['department_id'].unique()
provide me with the department ids that have more than 10 employees with commission.,employees.groupby('department_id').filter(lambda x: x['commission_pct'].count() > 10)['department_id'].unique()
provide the ids of departments in which at least one manager supervises 4 or more employees.,"employees.groupby(['department_id', 'manager_id']).filter(lambda x: len(x) >= 4)['department_id'].unique()"
what is the department id associated with departments headed by managers managing more than three employees?,"employees.groupby(['department_id', 'manager_id']).filter(lambda x: len(x) >= 4)['department_id'].unique()"
calculate the average commission percentage received by employees of each department.,employees.loc[employees['commission_pct'].notnull()].groupby('department_id')['salary'].mean()
determine the average earnings of employees whose commission percentage is not none.,employees.loc[employees['commission_pct'].notnull()].groupby('department_id')['salary'].mean()
show the country id and number of cities for every country.,locations.groupby('country_id').size().reset_index(name='count')
provide the country id and corresponding number of cities in that country.,locations.groupby('country_id').size().reset_index(name='count')
show the job ids for those jobs that were performed for more than 300 times.,job_history.loc[(job_history['end_date'] - job_history['start_date']).dt.days > 300].groupby('job_id').filter(lambda x: len(x)>=2)['job_id'].unique()
retrieve the job ids for jobs that have been repeated more than 300 times.,job_history.loc[(job_history['end_date'] - job_history['start_date']).dt.days > 300].groupby('job_id').filter(lambda x: len(x)>=2)['job_id'].unique()
provide to me the ids for those employees who fulfilled two or more positions in the past.,job_history.groupby('employee_id').filter(lambda x: len(x) >= 2)['employee_id'].unique()
kindly provide me with the id of employees who have worked on two or more jobs.,job_history.groupby('employee_id').filter(lambda x: len(x) >= 2)['employee_id'].unique()
retrieve the id and full name of the country wherein the employee is currently working.,"pd.merge(pd.merge(pd.merge(employees, departments, on='department_id'), locations, on='location_id'), countries, on='country_id')[['employee_id', 'country_name']]"
"return me the id and name of each employee, along with the country in which they work.","pd.merge(pd.merge(pd.merge(employees, departments, on='department_id'), locations, on='location_id'), countries, on='country_id')[['employee_id', 'country_name']]"
provide the department names and employee counts in each of the departments.,"employees.merge(departments, on='department_id').groupby('department_name').size().reset_index(name='count')"
list the name of the departments and the number of employees in each department.,"employees.merge(departments, on='department_id').groupby('department_name').size().reset_index(name='count')"
please provide me with the detail of jobs which were carried out by employees earning salaries on and above 12000.,"pd.merge(job_history, employees.loc[lambda x: x['salary'] >= 12000], on='employee_id')"
"how many employees have earned a salary greater than or equal to $12,000?","pd.merge(job_history, employees.loc[lambda x: x['salary'] >= 12000], on='employee_id')"
display job title and average salary of employees.,"pd.merge(employees, jobs, on='job_id').groupby('job_title')['salary'].mean()"
determine the average salary for each job title.,"pd.merge(employees, jobs, on='job_id').groupby('job_title')['salary'].mean()"
what is the full name ( first name and last name ) for those employees whose salaries are higher than john doe whose id is 163?,"employees.loc[lambda x: x['salary'] > employees.loc[lambda y: y['employee_id']==163, 'salary'].values[0], ['first_name', 'last_name']]"
please provide me with the full names of employees whose total earning is greater than the total earning of the employee with id 163.,"employees.loc[lambda x: x['salary'] > employees.loc[lambda y: y['employee_id']==163, 'salary'].values[0], ['first_name', 'last_name']]"
please provide me with the average salary of departments.,employees.groupby('department_id')['salary'].min().reset_index()
what is the salary minimum in each department?,employees.groupby('department_id')['salary'].min().reset_index()
return me the first and last name and department id for those employees earning the smallest salary of any of the departments.,"employees.loc[employees['salary'].isin(employees.groupby('department_id')['salary'].min()), ['first_name', 'last_name', 'department_id']]"
retrieve the names of employees along with their department ids and minimum salary.,"employees.loc[employees['salary'].isin(employees.groupby('department_id')['salary'].min()), ['first_name', 'last_name', 'department_id']]"
give me the employee ids of all employees who earn more than the average salary.,"employees.loc[lambda x: x['salary'] > x['salary'].mean(), 'employee_id']"
i wish to determine the count of employee ids for employees who earn more than the mean salary.,"employees.loc[lambda x: x['salary'] > x['salary'].mean(), 'employee_id']"
"what are all the employee ids of employees who report to payam, and what is their salary?","employees.loc[lambda x: x['manager_id'] == employees.loc[lambda y: y['first_name']=='payam', 'employee_id'].iloc[0], ['employee_id', 'salary']]"
find the names of the departments which have employees at-least one.,"pd.merge(employees, departments, on='department_id')['department_name'].unique()"
provide me with the profile of employees who manage a department.,"pd.merge(employees, departments, on='department_id', suffixes=('_emp', '_dept')).loc[lambda x: x['employee_id_emp']==x['manager_id'], :].drop(columns=['department_id_dept', 'manager_id'])"
please provide me with all the information about employees who are managers.,"pd.merge(employees, departments, on='department_id', suffixes=('_emp', '_dept')).loc[lambda x: x['employee_id_emp']==x['manager_id'], :].drop(columns=['department_id_dept', 'manager_id'])"
show me all info about the department of marketing.,departments.loc[lambda x: x['department_name']=='marketing']
provide me with the details about the marketing department.,departments.loc[lambda x: x['department_name']=='marketing']
fetch the titles of employees who did two or more jobs in the past.,job_history.groupby('employee_id').filter(lambda x: len(x) >= 2)['employee_id'].unique()
which employee ids had more than 1 position?,job_history.groupby('employee_id').filter(lambda x: len(x) >= 2)['employee_id'].unique()
which department(s) have managers who are responsible for overseeing more than four employees?,"employees.groupby(['department_id', 'manager_id']).filter(lambda x: len(x) >= 4)['department_id'].unique()"
how many departments have a manager in charge of four or more employees?,"employees.groupby(['department_id', 'manager_id']).filter(lambda x: len(x) >= 4)['department_id'].unique()"
provide the job ids of those jobs with average salary more than 8000.,employees.groupby('job_id').filter(lambda x: x['salary'].mean()>8000)['job_id'].unique()
what is the job id which correspond to jobs with salary above 8000?,employees.groupby('job_id').filter(lambda x: x['salary'].mean()>8000)['job_id'].unique()
display the id and name of every employee working in department 80.,"pd.merge(employees.loc[lambda x: x['department_id']==80, ['employee_id', 'job_id']], jobs, on='job_id')[['employee_id', 'job_title']]"
provide me with the ids and job titles for employees in department 80.,"pd.merge(employees.loc[lambda x: x['department_id']==80, ['employee_id', 'job_id']], jobs, on='job_id')[['employee_id', 'job_title']]"
find the first name and job id of all employees in the finance department.,"employees.merge(departments, on='department_id').loc[lambda x: x['department_name']=='finance', ['first_name', 'job_id']]"
please present the first name and id of all employees belonging to the finance department.,"employees.merge(departments, on='department_id').loc[lambda x: x['department_name']=='finance', ['first_name', 'job_id']]"
present the names of all individuals who earn salaries within the range of smallest and 2500.,employees.loc[lambda x: (x['salary'] >= employees['salary'].min()) & (x['salary'] <= 2500)]
provide a list of all employees who earn over the minimum and under $2500.,employees.loc[lambda x: (x['salary'] >= employees['salary'].min()) & (x['salary'] <= 2500)]
retrieve the ids of employees whose managers work in those departments where employees work whose manager ids are within the range 100 and 200.,"employees[~employees['department_id'].isin(departments.loc[lambda x: x['manager_id'].between(100, 200), 'department_id'])]"
could you provide me with the ids for employees who do not work in departments whose managers have ids between 100 and 200?,"employees[~employees['department_id'].isin(departments.loc[lambda x: x['manager_id'].between(100, 200), 'department_id'])]"
please provide me the names and hire dates of all employees belonging to the same department as clara.,"employees.loc[employees['department_id']==employees.loc[employees['first_name']=='clara', 'department_id'].iloc[0], ['first_name', 'last_name', 'hire_date']]"
provide me with the list of full names and hire dates for employees in the same department as someone with the first name clara.,"employees.loc[employees['department_id']==employees.loc[employees['first_name']=='clara', 'department_id'].iloc[0], ['first_name', 'last_name', 'hire_date']]"
display the complete names of all employees who are in the same department as clara excluding clara.,"employees[employees['department_id'] == employees[employees['first_name'] == 'clara']['department_id'].iloc[0]].loc[lambda x: x['first_name'] != 'clara', ['first_name', 'last_name', 'hire_date']]"
"what is the first and last name of an employee from the same department as someone with the first name clara, neither including nor starting with clara?","employees[employees['department_id'] == employees[employees['first_name'] == 'clara']['department_id'].iloc[0]].loc[lambda x: x['first_name'] != 'clara', ['first_name', 'last_name', 'hire_date']]"
"display the first name and last name, along with the employee number for all employees who work in a department with any such employee whose name contains an ""t"".","employees[employees['department_id'].isin(employees[employees['first_name'].str.contains('t')]['department_id'])][['employee_id', 'first_name', 'last_name']]"
what are the ids and full names of employees who work for a department that has an employee with the first name of t.,"employees[employees['department_id'].isin(employees[employees['first_name'].str.contains('t')]['department_id'])][['employee_id', 'first_name', 'last_name']]"
display the ids of employees whose salary is less than any salary of employees with mk_man as their job title.,"employees.loc[employees['salary'] < employees.loc[employees['job_id']=='mk_man', 'salary'].min(), ['employee_id', 'job_id']]"
provide me the ids and corresponding titles of the employees who make less than the lowest earning employee with title mk_man.,"employees.loc[employees['salary'] < employees.loc[employees['job_id']=='mk_man', 'salary'].min(), ['employee_id', 'job_id']]"
display the number of employees whose salaries are higher than any employee in the pu_man department.,"employees.loc[lambda x: x['salary'] > employees.loc[lambda y: y['job_id'] == 'pu_man', 'salary'].max(), ['employee_id', 'first_name', 'last_name', 'job_id']]"
"provide the ids, full names, and job ids of the employees making more than the highest earning employee with job pu_man.","employees.loc[lambda x: x['salary'] > employees.loc[lambda y: y['job_id'] == 'pu_man', 'salary'].max(), ['employee_id', 'first_name', 'last_name', 'job_id']]"
display the department id and the total salary for those departments having at least two employees.,employees.groupby('department_id').filter(lambda x: len(x) >= 2).groupby('department_id')['salary'].sum()
what is the total number of salaries in each department that has greater than 2 employees?,employees.groupby('department_id').filter(lambda x: len(x) >= 2).groupby('department_id')['salary'].sum()
display the names of employees who did not have any job in the past.,employees[~employees['employee_id'].isin(job_history['employee_id'])]
provide the names of the employees that have never held a job in the past.,employees[~employees['employee_id'].isin(job_history['employee_id'])]
"display the department id, full name (first and last name), salary for those employees whose salary is the highest in every department.","employees.groupby('department_id').agg({'first_name': 'first', 'last_name': 'first', 'salary': 'sum'}).reset_index()"
"what are the department ids, full names, and salaries of employees who earn the most in their departments?","employees.groupby('department_id').agg({'first_name': 'first', 'last_name': 'first', 'salary': 'sum'}).reset_index()"
"display the full name, department, city, and state province for each employee.","pd.merge(pd.merge(employees, departments, on='department_id'), locations, on='location_id')[['first_name', 'last_name', 'department_name', 'city', 'state_province']]"
"provide me with all of the employee details like full name, department, city, state and province. (hint: group_by)","pd.merge(pd.merge(employees, departments, on='department_id'), locations, on='location_id')[['first_name', 'last_name', 'department_name', 'city', 'state_province']]"
display the names of employees that contain a z in their names along with the locations that they reside.,"employees.merge(departments, on='department_id').merge(locations, on='location_id')[lambda x: x['first_name'].str.contains('z')][['first_name', 'last_name','city']]"
retrieve the names and complete cities of employees that start with the letter z.,"employees.merge(departments, on='department_id').merge(locations, on='location_id')[lambda x: x['first_name'].str.contains('z')][['first_name', 'last_name','city']]"
"display the department name, city, and state province for each department.","pd.merge(departments, locations, on='location_id')[['department_name', 'city', 'state_province']]"
"fetch the title, city, and state province for each of the departments.","pd.merge(departments, locations, on='location_id')[['department_name', 'city', 'state_province']]"
display the complete names of employees along with their corresponding ids and the country where they presently work.,"pd.merge(pd.merge(pd.merge(employees, departments, on='department_id'), locations, on='location_id'), countries, on='country_id')[['first_name', 'last_name', 'employee_id', 'country_name']]"
"provide me the full name, id and country of origin of each employee.","pd.merge(pd.merge(pd.merge(employees, departments, on='department_id'), locations, on='location_id'), countries, on='country_id')[['first_name', 'last_name', 'employee_id', 'country_name']]"
display the department name and count of employees in each one.,"pd.merge(employees, departments, on='department_id').groupby('department_name').size()"
what are the department names and how many employees are employed in each?,"pd.merge(employees, departments, on='department_id').groupby('department_name').size()"
list the full names and salaries of employees working in any department located in london.,"pd.merge(pd.merge(employees, departments, on='department_id'), locations, on='location_id').loc[lambda x: x['city']=='london', ['first_name', 'last_name', 'salary']]"
provide me with the names and salaries of workers employed in the city of london.,"pd.merge(pd.merge(employees, departments, on='department_id'), locations, on='location_id').loc[lambda x: x['city']=='london', ['first_name', 'last_name', 'salary']]"
what are the names of songs that were released in the most recent year?,"song.sort_values('releasedate', ascending=false).iloc[0][['song_name', 'releasedate']]"
tell me the title of the song that was released the latest.,"song.sort_values('releasedate', ascending=false).iloc[0][['song_name', 'releasedate']]"
what is the id of the longest song composed by michel ?,"files.sort_values('duration', ascending=false).iloc[0]['f_id']"
determine the id of the song that lasts the longest.,"files.sort_values('duration', ascending=false).iloc[0]['f_id']"
retrieve the names of all english songs.,"song.loc[song['languages']=='english', 'song_name']"
please fetch me the names of the songs in english.,"song.loc[song['languages']=='english', 'song_name']"
what is the id of songs whose format is mp3?,"files.loc[lambda x: x['formats'] == 'mp3', 'f_id']"
provide a list of all filenames that match to the mp3 extension.,"files.loc[lambda x: x['formats'] == 'mp3', 'f_id']"
tell me the artists and countries of residence for all singers who produced songs with rating higher than 9.,"pd.merge(artist, song[song['rating'] > 9], on='artist_name')[['artist_name', 'country']].drop_duplicates()"
list all artists and countries of origin whose song ratings are greater than or equal to 9.,"pd.merge(artist, song[song['rating'] > 9], on='artist_name')[['artist_name', 'country']].drop_duplicates()"
provide me the metadata for all songs that have resolution less than 800.,"pd.merge(files, song, on='f_id').loc[lambda x: x['resolution']<800, ['file_size', 'formats']].drop_duplicates()"
determine the total file sizes and formats of songs with a resolution lower than 800.,"pd.merge(files, song, on='f_id').loc[lambda x: x['resolution']<800, ['file_size', 'formats']].drop_duplicates()"
what is the title of the song that was produced by a tune with the shortest duration?,"pd.merge(song, files, on='f_id').sort_values('duration').iloc[0]['artist_name']"
find the titles that are sung in the shortest duration.,"pd.merge(song, files, on='f_id').sort_values('duration').iloc[0]['artist_name']"
"retrieve the name of the artists and the country of their origin for the artists who scored 1st, 2nd and 3rd on the most popular song lists.","pd.merge(artist, song, on='artist_name').sort_values('rating', ascending=false).iloc[:3][['artist_name', 'country']]"
which artists sang the top-ranked songs worldwide and what countries do they represent?,"pd.merge(artist, song, on='artist_name').sort_values('rating', ascending=false).iloc[:3][['artist_name', 'country']]"
what is the total count of songs that have precisely 4 minutes duration?,files.loc[lambda x: x['duration'].str.startswith('4:')].shape[0]
how many songs last approximately 4 minutes?,files.loc[lambda x: x['duration'].str.startswith('4:')].shape[0]
what is the count of bangladeshi artists?,(artist['country'] == 'bangladesh').sum()
what number of bangladeshi artists are listed?,(artist['country'] == 'bangladesh').sum()
obtain the average rating of songs created by female artists.,"song.merge(artist, on='artist_name').loc[lambda x: x['gender']=='female', 'rating'].mean()"
what is the mean number of songs sung by female artists?,"song.merge(artist, on='artist_name').loc[lambda x: x['gender']=='female', 'rating'].mean()"
what are the most widely used file format?,files.groupby('formats').size().sort_values(ascending=false).index[0]
find the code of the file formatting that is utilized by the most number of files.,files.groupby('formats').size().sort_values(ascending=false).index[0]
retrieve the names and titles of artists from the united kingdom who produced english songs.,artist[artist['country']=='uk']['artist_name'].interesect(song[song['languages']=='english']['artist_name'])
what artists are from the uk and sang songs in english?,artist[artist['country']=='uk']['artist_name'].interesect(song[song['languages']=='english']['artist_name'])
please provide me with the id of songs whose resolution is lower than 1000 and are available in mp4 format.,"files.loc[files['formats']=='mp4', 'f_id'].interesect(song.loc[song['resolution']<1000, 'f_id'])"
which files have the id equal to mp4 and a resolution with less than or equal to 1000?,"files.loc[files['formats']=='mp4', 'f_id'].interesect(song.loc[song['resolution']<1000, 'f_id'])"
what is the country of origin of the female artist that produced a bangla song?,"pd.merge(artist.loc[lambda x: x['gender']=='female'], song.loc[lambda x: x['languages']=='bangla'], on='artist_name')['country']"
obtain the nationalities of female artists that sang in bangla language.,"pd.merge(artist.loc[lambda x: x['gender']=='female'], song.loc[lambda x: x['languages']=='bangla'], on='artist_name')['country']"
what is the average duration of songs with mp3 format and resolution below 800?,"pd.merge(files.loc[lambda x: x['formats']=='mp3'], song.loc[lambda x: x['resolution']<800], on='f_id')['duration'].mean()"
please provide me with the count of artists for each gender.,artist.groupby('gender').size().reset_index(name='count')
what is the count of male artists and female artists?,artist.groupby('gender').size().reset_index(name='count')
calculate the average rating of songs for each language.,"song.groupby('languages').agg(avg_rating=('rating', 'mean'), languages=('languages', 'first'))[['avg_rating', 'languages']]"
what are the average song ratings for each language?,"song.groupby('languages').agg(avg_rating=('rating', 'mean'), languages=('languages', 'first'))[['avg_rating', 'languages']]"
please provide me with the name and gender of the artist who produced the song with the lowest resolution.,"pd.merge(artist, song, on='artist_name').sort_values('resolution').head(1)[['gender', 'artist_name']]"
what is the gender of the artist and title of the song that was sung with the smallest resolution?,"pd.merge(artist, song, on='artist_name').sort_values('resolution').head(1)[['gender', 'artist_name']]"
"for each file format, return the number of artists who released their songs in that format.",files.groupby('formats').size().reset_index(name='count')
what are the number of songs that were released for each format?,files.groupby('formats').size().reset_index(name='count')
what are the names of songs that have a higher resolution than the english songs?,"song.loc[lambda x: x['resolution'] > song.loc[lambda y: y['languages']=='english', 'resolution'].min(), 'song_name'].unique()"
which title names are used for all songs that have higher resolution than english songs?,"song.loc[lambda x: x['resolution'] > song.loc[lambda y: y['languages']=='english', 'resolution'].min(), 'song_name'].unique()"
list the names of all songs that have a lower score than some blues song.,"song.loc[song['rating'] < song.loc[song['genre_is'] == 'blues', 'rating'].max(), 'song_name']"
what is the name of the song that has a rating lower than at least one blues song?,"song.loc[song['rating'] < song.loc[song['genre_is'] == 'blues', 'rating'].max(), 'song_name']"
"determine the name and country of origin of the artist who released a song with ""love"" in its title.","pd.merge(artist, song, on='artist_name').loc[lambda x: x['song_name'].str.contains('love', case=false), ['artist_name', 'country']]"
"which song titles include the word love, and where are the artists from?","pd.merge(artist, song, on='artist_name').loc[lambda x: x['song_name'].str.contains('love', case=false), ['artist_name', 'country']]"
please list the names of all artists who released songs in march along with their gender and age.,"pd.merge(artist, song, on='artist_name').loc[lambda x: x['releasedate'].str.contains('mar'), ['artist_name', 'gender']]"
which artists released songs in the month of march?,"pd.merge(artist, song, on='artist_name').loc[lambda x: x['releasedate'].str.contains('mar'), ['artist_name', 'gender']]"
"list the names of all genres in alphabetical order, along with their ratings.","genre.sort_values('g_name')[['g_name', 'rating']]"
"enumerate all genres in the order of ascending rating, along with their complete names.","genre.sort_values('g_name')[['g_name', 'rating']]"
please give me a list of the names of all songs ordered in ascending by resolution.,song.sort_values('resolution')['song_name']
retrieve the titles of songs ordered by their resolution numbers.,song.sort_values('resolution')['song_name']
which songs are available in mp4 format or have higher resolution?,"pd.concat([files.loc[lambda x: x['formats']=='mp4', 'f_id'], song.loc[lambda x: x['resolution']>720, 'f_id']]).drop_duplicates()"
provide me with the id of all songs that are saved in mp4 format or with a higher resolution than 720.,"pd.concat([files.loc[lambda x: x['formats']=='mp4', 'f_id'], song.loc[lambda x: x['resolution']>720, 'f_id']]).drop_duplicates()"
list down all of the titles of songs that are 4 minutes long or are in english.,"pd.concat([pd.merge(files, song, on='f_id').loc[lambda x: x['duration'].str.startswith('4:'), 'song_name'], song.loc[lambda x: x['languages']=='english', 'song_name']]).drop_duplicates()"
"list the names of all songs that are at least 4 minutes in length or in english.'''`) // 2. 设置输入数组 testinput := []string{"""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""","""",""","pd.concat([pd.merge(files, song, on='f_id').loc[lambda x: x['duration'].str.startswith('4:'), 'song_name'], song.loc[lambda x: x['languages']=='english', 'song_name']]).drop_duplicates()"
what languages are most commonly utilized in the songs?,song.groupby('languages').size().sort_values(ascending=false).index[0]
what language was used the most frequently in songs with resolution above 500?,song.loc[song['resolution'] > 500].groupby('languages')['artist_name'].agg(lambda x: x.value_counts().index[0]).sort_values(ascending=false).iloc[0]
"for which artist is the title each language, which has the highest count of songs with resolution higher than 500?",song.loc[song['resolution'] > 500].groupby('languages')['artist_name'].agg(lambda x: x.value_counts().index[0]).sort_values(ascending=false).iloc[0]
"provide the names of the musicians who are ""male"" and belong to britain.","artist.loc[(artist['country']=='uk') & (artist['gender']=='male'), 'artist_name']"
tell me the names of all male artists from england.,"artist.loc[(artist['country']=='uk') & (artist['gender']=='male'), 'artist_name']"
retrieve the songs whose genre is modern or language belongs to english.,"song.loc[(song['genre_is']=='modern') | (song['languages']=='english'), 'song_name']"
what are the titles of the songs that are sung in modern english?,"song.loc[(song['genre_is']=='modern') | (song['languages']=='english'), 'song_name']"
provide me with the names of songs that are in .mp3 format and have a resolution below 1000.,"files.merge(song, on='f_id').query('formats == ""mp3""')['song_name'].loc[lambda x: x.isin(song.loc[lambda x: x['resolution'] < 1000, 'song_name'])]"
find the title names of songs that are in mp3 format and have a resolution of less than 1000.,"files.merge(song, on='f_id').query('formats == ""mp3""')['song_name'].loc[lambda x: x.isin(song.loc[lambda x: x['resolution'] < 1000, 'song_name'])]"
what is the count of singers who are from the united kingdom and released an english song?,"set(artist.query('country == ""uk""')['artist_name']).intersection(song.query('languages == ""english""')['artist_name'])"
please provide me with a list of all the singers from the uk and based in the uk that released a song in english.,"set(artist.query('country == ""uk""')['artist_name']).intersection(song.query('languages == ""english""')['artist_name'])"
provide me with the average rating and resolution of all the songs that are in bangla.,"song.loc[song['languages'] == 'bangla', ['rating', 'resolution']].mean()"
which songs have the maximum average rating and resolution?,"song.loc[song['languages'] == 'bangla', ['rating', 'resolution']].mean()"
what is the range of resolution for songs that are of approximately 3 minutes in duration?,"pd.merge(files.loc[lambda x: x['duration'].str.startswith('3:'), ['f_id']], song, on='f_id').agg({'resolution': ['max', 'min']})"
what are the maximum duration and resolution values of songs grouped by language?,"pd.merge(files, song, on='f_id').groupby('languages').agg({'duration': 'max', 'resolution': 'max'})"
"provide me with the duration and resolution range for every song along with the language details. also, sort the songs alphabetically by language.","pd.merge(files, song, on='f_id').groupby('languages').agg({'duration': 'max', 'resolution': 'max'})"
determine the shortest duration and lowest rating of songs from any genre.,"pd.merge(files, song, on='f_id').groupby('genre_is').agg({'duration':'min', 'rating':'min'})"
what are the title and rating for the shortest and worst song in their respective genres?,"pd.merge(files, song, on='f_id').groupby('genre_is').agg({'duration':'min', 'rating':'min'})"
retrieve the titles of all artists who have at least one work in english.,"song.loc[song['languages']=='english'].merge(artist, on='artist_name').groupby('artist_name').filter(lambda x: len(x)>=1).groupby('artist_name').size().reset_index(name='count')[['artist_name', 'count']]"
retrieve all the names of singers along with the count of their works in the english language.,"song.loc[song['languages']=='english'].merge(artist, on='artist_name').groupby('artist_name').filter(lambda x: len(x)>=1).groupby('artist_name').size().reset_index(name='count')[['artist_name', 'count']]"
precisely identify the authors of all songs whose resolution exceeds 900.,"artist.merge(song[song['resolution'] > 900], on='artist_name').groupby('artist_name').filter(lambda group: len(group) >= 1)[['artist_name', 'country']]"
could you provide me with the complete name and country of origin of each artist who released a song with a resolution higher than 900?,"artist.merge(song[song['resolution'] > 900], on='artist_name').groupby('artist_name').filter(lambda group: len(group) >= 1)[['artist_name', 'country']]"
fetch the authors and number of works composed by the three artists producing the most songs.,"song.groupby('artist_name').size().nlargest(3).reset_index(name='count').merge(artist, on='artist_name', how='left')[['artist_name', 'count']]"
"list the three names of the artists who have composed the most songs, and calculate the total number of their compositions.","song.groupby('artist_name').size().nlargest(3).reset_index(name='count').merge(artist, on='artist_name', how='left')[['artist_name', 'count']]"
determine the country of origin for the artist that made the least number of songs.,"pd.merge(artist, song, on='artist_name').groupby('artist_name')['country'].count().sort_values().index.values[0]"
the artist that made the fewest songs was from the country,"pd.merge(artist, song, on='artist_name').groupby('artist_name')['country'].count().sort_values().index.values[0]"
which songs in english have an average rating of below 100?,"song.loc[song['rating'] < song.loc[song['languages']=='english', 'rating'].min(), 'song_name']"
find the names of songs whose ratings are less than the minimum rating for english songs.,"song.loc[song['rating'] < song.loc[song['languages']=='english', 'rating'].min(), 'song_name']"
provide the ids of the songs that have higher resolution than the resolution of any songs with lower ratings.,"song.loc[song['resolution'] > song.loc[song['rating'] < 8, 'resolution'].max(), 'f_id']"
how many songs have a rating higher than 8? and please provide their id.,"song.loc[song['resolution'] > song.loc[song['rating'] < 8, 'resolution'].max(), 'f_id']"
what are the ids of the songs whose resolution is not less than the average resolution for all songs in modern genre?,"song.loc[song['resolution'] > song.loc[song['genre_is'] == 'modern', 'resolution'].mean(), 'f_id']"
provide me the ids for all songs with lower average resolution than their peers in the modern genre.,"song.loc[song['resolution'] > song.loc[song['genre_is'] == 'modern', 'resolution'].mean(), 'f_id']"
please retrieve the list of top 3 artists who have the largest number for songs written in bangla.,"song.loc[song['languages']=='bangla'].merge(artist, on='artist_name').groupby('artist_name').size().nlargest(3).reset_index(name='count').loc[:, 'artist_name']"
which 3 artists have the largest number of bangla-language songs?,"song.loc[song['languages']=='bangla'].merge(artist, on='artist_name').groupby('artist_name').size().nlargest(3).reset_index(name='count').loc[:, 'artist_name']"
"provide me the title, genre and artist details for the top-rated english songs.","song.loc[song['languages'] == 'english', ['f_id', 'genre_is', 'artist_name']].sort_values('rating')"
"list the id, genre, and artist for every song in english ordered by ascending rating.","song.loc[song['languages'] == 'english', ['f_id', 'genre_is', 'artist_name']].sort_values('rating')"
deliver the following details: - number of songs - song duration - song file size - song format - song title,"files.merge(song[song['genre_is']=='pop'], on='f_id').sort_values('song_name')[['duration', 'file_size', 'formats']]"
"provide me with the duration, file size, and song format data for every pop song, ordered by title alphabetically.","files.merge(song[song['genre_is']=='pop'], on='f_id').sort_values('song_name')[['duration', 'file_size', 'formats']]"
return the names of the artists who have composed english songs but have not received a rating of 8 or more.,"song.loc[song['languages']=='english', 'artist_name'].drop_duplicates().append(song.loc[song['rating']>8, 'artist_name']).drop_duplicates(keep=false)"
retrieve the names of artists who have composed a song in english and have never received a rating higher than 8.,"song.loc[song['languages']=='english', 'artist_name'].drop_duplicates().append(song.loc[song['rating']>8, 'artist_name']).drop_duplicates(keep=false)"
retrieve the names of musicians from bangladesh who have received ratings equal to or less than 7.,"set(artist.loc[artist['country']=='bangladesh', 'artist_name']) - set(song.loc[song['rating']>7, 'artist_name'])"
which are the names of pakistani singers who have never received a rating higher than a 7?,"set(artist.loc[artist['country']=='bangladesh', 'artist_name']) - set(song.loc[song['rating']>7, 'artist_name'])"
what is the complete name and id of the college with the most baseball players?,"pd.merge(college, player_college, on='college_id').groupby('college_id').apply(lambda x: x['name_full'].nunique()).idxmax()"
obtain the full name and id of the college that has the highest number of baseball players.,"pd.merge(college, player_college, on='college_id').groupby('college_id').apply(lambda x: x['name_full'].nunique()).idxmax()"
what is the average salary of the players in the team named 'boston red stockings'?,"salary.merge(team, left_on='team_id', right_on='team_id_br').loc[lambda x: x['name']=='boston red stockings', 'salary'].mean()"
calculate the average earning of the players in the team called 'boston red stockings'.,"salary.merge(team, left_on='team_id', right_on='team_id_br').loc[lambda x: x['name']=='boston red stockings', 'salary'].mean()"
retrieve the first and last names of the players who took part in the all-star game in 1998.,"pd.merge(player, all_star, on='player_id').loc[lambda x: x['year']==1998, ['name_first', 'name_last']]"
provide me with the first and last names of all players who participated in the all star game in the year 1998.,"pd.merge(player, all_star, on='player_id').loc[lambda x: x['year']==1998, ['name_first', 'name_last']]"
which players enter the hall of fame each year?,hall_of_fame.groupby('yearid').size()
determine the number of players who enter the hall of fame for each year.,hall_of_fame.groupby('yearid').size()
what is the average count of attendance at home games for each year?,home_game.groupby('year')['attendance'].mean()
what are the id and rank of teams that showed the most attendance in 2014?,"home_game.query(""year == 2014"").merge(team, on=""team_id"").groupby([""team_id"", ""rank""]).mean()[""attendance""].reset_index().sort_values(""attendance"", ascending=false).iloc[0][[""team_id"", ""rank""]]"
determine the team that attained the highest average attendance rate in the year 2014.,"home_game.query(""year == 2014"").merge(team, on=""team_id"").groupby([""team_id"", ""rank""]).mean()[""attendance""].reset_index().sort_values(""attendance"", ascending=false).iloc[0][[""team_id"", ""rank""]]"
"provide me with the full name, id, and first name and last name of the manager who won the most manager award.","player.merge(manager_award, on='player_id').groupby('player_id').apply(lambda x: x.iloc[0][['name_first', 'name_last', 'player_id']]).reset_index(drop=true).sort_values(by=manager_award.groupby('player_id').size().sort_values(ascending=false).index[0], ascending=false).head(1)"
"who won the most manager award? i would like to obtain their full names, id, and the year in which they won the award.","player.merge(manager_award, on='player_id').groupby('player_id').apply(lambda x: x.iloc[0][['name_first', 'name_last', 'player_id']]).reset_index(drop=true).sort_values(by=manager_award.groupby('player_id').size().sort_values(ascending=false).index[0], ascending=false).head(1)"
what is the count of parks in the state of new york?,(park['state'] == 'ny').sum()
provide me with the count of parks possessed by the state of new york.,(park['state'] == 'ny').sum()
"draw the names of those players who won the highest number of player awards. also, provide their full names and their ids.","pd.merge(player, player_award, on='player_id').groupby(['name_first', 'name_last', 'player_id']).size().reset_index(name='count').nlargest(3, 'count')[['name_first', 'name_last', 'player_id']]"
"list the first name, last name and id for players who earned the most awards.","pd.merge(player, player_award, on='player_id').groupby(['name_first', 'name_last', 'player_id']).size().reset_index(name='count').nlargest(3, 'count')[['name_first', 'name_last', 'player_id']]"
identify the countries of origin for the least players.,player.groupby('birth_country')['birth_country'].agg(['count']).sort_values('count').head(3).reset_index()['birth_country']
which three countries are the country of origin of the fewest players?,player.groupby('birth_country')['birth_country'].agg(['count']).sort_values('count').head(3).reset_index()['birth_country']
please list all the players whose complete names contain no death information.,"player.loc[player['death_year'].isnull(), ['name_first', 'name_last']]"
please provide me with the title and first name and last name of the players whose death records contain no information.,"player.loc[player['death_year'].isnull(), ['name_first', 'name_last']]"
how many players born in the united states are right-handed batters?,"player.loc[(player['birth_country'] == 'usa') & (player['bats'] == 'r'),:].shape[0]"
what is the count of players that have 'r' as their bat type and also were born in the united states?,"player.loc[(player['birth_country'] == 'usa') & (player['bats'] == 'r'),:].shape[0]"
what is the average of heights of players from the yale university?,"pd.merge(pd.merge(player, player_college, on='player_id'), college, on='college_id').loc[lambda x: x['name_full']=='yale university', 'height'].mean()"
determine the average height of the players belonging to the college called 'yale university'.,"pd.merge(pd.merge(player, player_college, on='player_id'), college, on='college_id').loc[lambda x: x['name_full']=='yale university', 'height'].mean()"
provide me with the names of teams that have the maximum salary along with the corresponding team ids and salary amounts.,"pd.merge(team, salary, on='team_id').groupby(['name', 'team_id']).agg({'salary': 'max'})"
fetch the name and the id of the team offering the least average salary.,"team.merge(salary, on='team_id').groupby('team_id').mean().sort_values('salary').head(1).reset_index()[['name', 'team_id']]"
which team offers the lowest average as salary? provide me with the name of the team and id.,"team.merge(salary, on='team_id').groupby('team_id').mean().sort_values('salary').head(1).reset_index()[['name', 'team_id']]"
return the players' first name and last name who won an award in 1960 as well as 1961.,"pd.merge(player.loc[player_award.loc[player_award['year'] == 1960, 'player_id'], ['name_first', 'name_last']], player.loc[player_award.loc[player_award['year'] == 1961, 'player_id'], ['name_first', 'name_last']]).drop_duplicates().reset_index(drop=true)"
give the first and last names of the players who received awards in 1960 and 1961.,"pd.merge(player.loc[player_award.loc[player_award['year'] == 1960, 'player_id'], ['name_first', 'name_last']], player.loc[player_award.loc[player_award['year'] == 1961, 'player_id'], ['name_first', 'name_last']]).drop_duplicates().reset_index(drop=true)"
list the first and last names of players whose weight and height are greater than or equal to 220 or are less than or equal to 75.,"player.loc[(player['weight'] > 220) | (player['height'] < 75), ['name_first', 'name_last']]"
determine the correct first name and last name of the players who have weight above 220 or height below 75.,"player.loc[(player['weight'] > 220) | (player['height'] < 75), ['name_first', 'name_last']]"
give the names of the teams who won the maximum points during their matches in postseason.,"postseason.merge(team, left_on='team_id_winner', right_on='team_id_br').loc[lambda x: x['name']=='boston red stockings', 'wins'].max()"
identify the team with the highest total score when the team won in the postseason.,"postseason.merge(team, left_on='team_id_winner', right_on='team_id_br').loc[lambda x: x['name']=='boston red stockings', 'wins'].max()"
how many times did boston red stockings lose in the 2009 postseason?,"pd.merge(postseason, team, left_on='team_id_loser', right_on='team_id_br').loc[(lambda x: x['name']=='boston red stockings')(team) & (postseason['year'] == 2009), :].shape[0]"
"determine the number of losses suffered by the team ""boston red stockings"" in the 2009 postseason.","pd.merge(postseason, team, left_on='team_id_loser', right_on='team_id_br').loc[(lambda x: x['name']=='boston red stockings')(team) & (postseason['year'] == 2009), :].shape[0]"
could you please provide me with the names of teams with the most wins in the 2008 playoffs?,"postseason[postseason['year']==2008].merge(team, left_on='team_id_winner', right_on='team_id_br').groupby(['team_id_winner', 'name']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'team_id_winner']]"
identify the team that won the most games in the 2008 postseason.,"postseason[postseason['year']==2008].merge(team, left_on='team_id_winner', right_on='team_id_br').groupby(['team_id_winner', 'name']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'team_id_winner']]"
what was the number of wins obtained by the team boston red stockings in each postseason?,"postseason.merge(team, left_on='team_id_winner', right_on='team_id_br').loc[lambda x: x['name']=='boston red stockings'].groupby('year').size().reset_index(name='count')"
provide the year and the total number of postseasons won for each year by the team boston red stockings.,"postseason.merge(team, left_on='team_id_winner', right_on='team_id_br').loc[lambda x: x['name']=='boston red stockings'].groupby('year').size().reset_index(name='count')"
what was the count of postseason games that team boston red stockings played in?,"pd.concat([postseason.merge(team, left_on='team_id_winner', right_on='team_id_br'),postseason.merge(team, left_on='team_id_loser', right_on='team_id_br')]).loc[lambda x: x['name']=='boston red stockings'].nunique()[0]"
for how many games in the 1885 postseason did the score end as a tie?,postseason.loc[(postseason['year']==1885) & (postseason['ties']==1)].shape[0]
what is the sum of salaries of team members of boston red stockings in 2010?,"salary.merge(team, left_on='team_id', right_on='team_id_br').query(""name=='boston red stockings' and year==2010"")['salary'].sum()"
please provide me with the count of players who were in team boston red stockings in 2000.,"pd.merge(salary, team, left_on='team_id', right_on='team_id_br').loc[lambda x: (x['name']=='boston red stockings') & (x['year']==2000)].shape[0]"
what is the number of players that boston red stockings possessed in 2000?,"pd.merge(salary, team, left_on='team_id', right_on='team_id_br').loc[lambda x: (x['name']=='boston red stockings') & (x['year']==2000)].shape[0]"
please list the 3 highest salaries of the players in 2001.,"salary.loc[salary['year']==2001, 'salary'].sort_values(ascending=false).head(3)"
what is the mean salary of the top three paid players in the year 2001?,"salary.loc[salary['year']==2001, 'salary'].sort_values(ascending=false).head(3)"
please make a list of all salaries players received in 2010 and 2001.,"pd.concat([salary[salary['year']==2010]['salary'], salary[salary['year']==2001]['salary']]).drop_duplicates()"
during which year were the fewest people awarded with hall of fame?,hall_of_fame.groupby('yearid').size().sort_values().index[0]
identify the year in which the least number of people were inducted in the hall of fame.,hall_of_fame.groupby('yearid').size().sort_values().index[0]
what is the count of parks in atlanta?,(park['city'] == 'atlanta').sum()
what is the number of parks in atlanta city?,(park['city'] == 'atlanta').sum()
"how many games were played in the year 1907 at park ""columbia park""?","pd.merge(home_game.loc[home_game['year'] == 1907], park.loc[park['park_name'] == 'columbia park'], on='park_id')['year'].count()"
"calculate the number of games played in park ""columbia park"" in 1907.","pd.merge(home_game.loc[home_game['year'] == 1907], park.loc[park['park_name'] == 'columbia park'], on='park_id')['year'].count()"
what number of games were played in the atlanta city in the year 2000?,"home_game.merge(park, on='park_id').query(""year == 2000 and city == 'atlanta'"").shape[0]"
how many games took place in the city of atlanta in the year 2000?,"home_game.merge(park, on='park_id').query(""year == 2000 and city == 'atlanta'"").shape[0]"
what is the average number of home game attendees of team boston red stockings from 2000 to 2010?,"home_game.merge(team, left_on='team_id', right_on='team_id_br').loc[lambda x: (x['name'] == 'boston red stockings') & (x['year'].between(2000, 2010)), 'attendance'].sum()"
determine the total number of games attended by the team boston red stockings from 2000 to 2010.,"home_game.merge(team, left_on='team_id', right_on='team_id_br').loc[lambda x: (x['name'] == 'boston red stockings') & (x['year'].between(2000, 2010)), 'attendance'].sum()"
apprise me of the total sum of earnings by the basketball player named len barker between the years 1985 and 1990.,"salary.merge(player).query(""name_first == 'len' and name_last == 'barker' and 1985 <= year <= 1990"")['salary'].sum()"
determine the total salary received by the player named len barker between 1985 and 1990.,"salary.merge(player).query(""name_first == 'len' and name_last == 'barker' and 1985 <= year <= 1990"")['salary'].sum()"
provide me with the first- and last names of players who received salary from team washington nationals for both years 2005 and 2007.,"pd.merge(pd.merge(salary[salary['year']==2005], player, on='player_id'), team[team['name']=='washington nationals'], left_on='team_id', right_on='team_id_br')[['name_first', 'name_last']].merge(pd.merge(pd.merge(salary[salary['year']==2007], player, on='player_id'), team[team['name']=='washington nationals'], left_on='team_id', right_on='team_id_br')[['name_first', 'name_last']]).drop_duplicates()"
retrieve the first names of the players who were paid salary by the washington nationals in both 2005 and 2007.,"pd.merge(pd.merge(salary[salary['year']==2005], player, on='player_id'), team[team['name']=='washington nationals'], left_on='team_id', right_on='team_id_br')[['name_first', 'name_last']].merge(pd.merge(pd.merge(salary[salary['year']==2007], player, on='player_id'), team[team['name']=='washington nationals'], left_on='team_id', right_on='team_id_br')[['name_first', 'name_last']]).drop_duplicates()"
how many home games did the team boston red stockings play from 1990 to 2000?,"pd.merge(home_game, team, left_on='team_id', right_on='team_id_br').loc[lambda x: (x['name']=='boston red stockings') & (x['year'].between(1990, 2000)), 'games'].sum()"
determine the count of games attended from 1990 to 2000 by the team boston red stockings.,"pd.merge(home_game, team, left_on='team_id', right_on='team_id_br').loc[lambda x: (x['name']=='boston red stockings') & (x['year'].between(1990, 2000)), 'games'].sum()"
determine the number of attendances in a specific team's home games in the year 1980.,"pd.merge(home_game.loc[lambda x: x['year'] == 1980], team, how='inner', left_on='team_id', right_on='team_id_br').sort_values('attendance').iloc[0]['name']"
retrieve the names of the teams that attended the least number of home games in 1980.,"pd.merge(home_game.loc[lambda x: x['year'] == 1980], team, how='inner', left_on='team_id', right_on='team_id_br').sort_values('attendance').iloc[0]['name']"
identify the states which have more than 2 parks.,park.groupby('state').filter(lambda x: len(x) > 2)['state'].unique()
"how many teams are active, with active value 'y'?",(team_franchise['active'] == 'y').sum()
identify the cities having 2 to 4 parks.,park.groupby('city').filter(lambda x: (2 <= len(x) <= 4))['city'].unique()
find those cities that have 2 or 3 parks and the city that has four parks.,park.groupby('city').filter(lambda x: (2 <= len(x) <= 4))['city'].unique()
"during 2008, which park had the highest attendance?","pd.merge(home_game.loc[lambda x: x['year']==2008], park, on='park_id').sort_values('attendance', ascending=false).iloc[0]['park_name']"
what is the park in which most visitors attended in 2008?,"pd.merge(home_game.loc[lambda x: x['year']==2008], park, on='park_id').sort_values('attendance', ascending=false).iloc[0]['park_name']"
how many camera lenses have a focal length greater than 15 mm?,(camera_lens['focal_length_mm'] > 15).sum()
"retrieve the brand and name for each camera lens, and sort in ascending order of maximum aperture.","camera_lens[['brand', 'name']].sort_values('max_aperture', ascending=false)"
"list the id, color scheme, and name for all photos.","photos[['id', 'color', 'name']]"
please provide me with the maximum and average height of mountains.,"mountain['height'].agg(['max', 'mean'])"
discover the value of the prominence of the mountains in each county.,"mountain.loc[mountain['country']=='morocco', 'prominence'].mean()"
"retrieve the id, height, and prominence of mountains which do not belong to the range 'aberdare range'.","mountain.loc[lambda x: x['range']!='aberdare range', ['name', 'height', 'prominence']]"
please provide me with the first and last names of the photos for mountains.,"pd.merge(mountain, photos, on='mountain_id').loc[lambda x: x['height'] > 4000, ['id', 'name']]"
provide me the id and full name of mountains that have more than one photograph.,"mountain.merge(photos, on='mountain_id').groupby(['id', 'name']).filter(lambda x: len(x) >= 2)[['id', 'name']].drop_duplicates()"
what are the names of cameras that have taken pictures of the most mountains?,"pd.merge(photos, camera_lens, left_on='camera_lens_id', right_on='id').groupby('name').size().sort_values(ascending=false).index[0]"
obtain the title of digital camera photos shot with lenses belonging to the brands 'sigma' or 'olympus'.,"photos.merge(camera_lens, left_on='camera_lens_id', right_on='id', how='inner').query(""brand in ['sigma', 'olympus']"")['name']"
how many types of lens brands are there?,camera_lens['brand'].nunique()
what is the count of camera lenses that are never utilized to take any photos?,camera_lens[~camera_lens['id'].isin(photos['camera_lens_id'])].shape[0]
what is the count of different camera lenses that are utilized in taking photos of mountains in the country 'ethiopia'?,"photos.merge(mountain, left_on='mountain_id', right_on='id').loc[lambda x: x['country']=='ethiopia', 'camera_lens_id'].nunique()"
list the brands of lenses that possess the capability to capture images of mountains with ranges 'toubkal atlas' and 'lasta massif'.,"pd.merge(pd.merge(mountain.loc[lambda x: x['range']=='toubkal atlas'], photos, on='id'), camera_lens, on='camera_lens_id')['brand'].drop_duplicates().reset_index(drop=true).merge(pd.merge(pd.merge(mountain.loc[lambda x: x['range']=='lasta massif'], photos, on='id'), camera_lens, on='camera_lens_id')['brand'].drop_duplicates().reset_index(drop=true), how='inner')"
provide the title and prominence of the mountains whose image is not taken with a lens of brand 'sigma'.,"mountain[['name', 'prominence']].merge(photos.merge(camera_lens[camera_lens['brand']!='sigma'], on='camera_lens_id'), on='id', how='left').loc[lambda x: x['camera_lens_id'].isna(), ['name', 'prominence']]"
"which camera lens names contain the character ""digital""?","camera_lens.loc[camera_lens['name'].str.contains('digital'), 'name']"
provide me with the title of each camera lens along with the count of photos taken by it. sort the result alphabetically by the count of photos.,"pd.merge(camera_lens, photos, on='camera_lens_id').groupby('id')['name'].agg([('count', 'count')]).sort_values('count')"
retrieve the titles of channels that are not possessed by cctv.,"channel.loc[lambda x: x['owner'] != 'cctv', 'name']"
list the titles of channels that are not possessed by cctv.,"channel.loc[lambda x: x['owner'] != 'cctv', 'name']"
list the channel names ordered by the percentile they represent of the total number of channels.,"channel.sort_values('rating_in_percent', ascending=false)['name']"
please provide titles for all channels sorted by their rating in descending order.,"channel.sort_values('rating_in_percent', ascending=false)['name']"
which channel bears the highest rating?,"channel.sort_values('rating_in_percent', ascending=false).iloc[0]['owner']"
please provide me with the name of the owner of a channel possessing the highest rating.,"channel.sort_values('rating_in_percent', ascending=false).iloc[0]['owner']"
what is the count of programs?,program.shape[0]
what is the total count of programs?,program.shape[0]
"list the names of programs, ordering by launch date.",program.sort_values('launch')['name']
"provide me the list of program titles, sorted by chronological sequence.",program.sort_values('launch')['name']
"please list the name, origin and owner of each program.","program[['name', 'origin', 'owner']]"
"which program titles, origins and owners should be included in the response document?","program[['name', 'origin', 'owner']]"
identify the program that was broadcast most recently.,"program.sort_values('launch', ascending=false).iloc[0]['name']"
which program was launched most recently? retrieve the program's title.,"program.sort_values('launch', ascending=false).iloc[0]['name']"
determine the share of all channels possessed by cctv.,"channel.loc[channel['owner']=='cctv', 'share_in_percent'].sum()"
what is the percentage share (in percent) of all the channels possessed by cctv?,"channel.loc[channel['owner']=='cctv', 'share_in_percent'].sum()"
retrieve the names of the channels that are being broadcast in the morning.,"channel.merge(broadcast[broadcast['time_of_day']=='morning'], on='channel_id')['name']"
display the codes of channels that broadcast in the morning.,"channel.merge(broadcast[broadcast['time_of_day']=='morning'], on='channel_id')['name']"
retrieve the titles of the channels that broadcast both in the morning and at night.,"pd.merge(broadcast.query(""time_of_day == 'morning'"")[['channel_id']], channel, on='channel_id')['name'].intersect(pd.merge(broadcast.query(""time_of_day == 'night'"")[['channel_id']], channel, on='channel_id')['name'])"
what are the channels that have broadcast both in the morning and at night?,"pd.merge(broadcast.query(""time_of_day == 'morning'"")[['channel_id']], channel, on='channel_id')['name'].intersect(pd.merge(broadcast.query(""time_of_day == 'night'"")[['channel_id']], channel, on='channel_id')['name'])"
what is the count of programs broadcasted in each hour of each day?,broadcast.groupby('time_of_day').size().reset_index(name='count')
what is the total count of programs broadcast during each time period in a day?,broadcast.groupby('time_of_day').size().reset_index(name='count')
retrieve the number of programs that belong to different broadcast genres that are displayed during night time.,broadcast[broadcast['time_of_day']=='night']['program_id'].nunique()
"what is the number of unique programs broadcast at ""night"" time slot?",broadcast[broadcast['time_of_day']=='night']['program_id'].nunique()
provide me with the names for programs never broadcasted in the morning.,"program.loc[~program['name'].isin(pd.merge(program, broadcast, on='program_id').loc[lambda x: x['time_of_day']=='morning', 'name'])]['name']"
list the names of the programs that are never broadcast in the morning.,"program.loc[~program['name'].isin(pd.merge(program, broadcast, on='program_id').loc[lambda x: x['time_of_day']=='morning', 'name'])]['name']"
find the name of program owners that have programs in both morning and evening sessions.,"pd.merge(program.loc[lambda x: x.merge(broadcast).time_of_day == 'morning', 'owner'], program.loc[lambda x: x.merge(broadcast).time_of_day == 'night', 'owner']).drop_duplicates()"
who are the owners of the programs that air both in the morning and at night?,"pd.merge(program.loc[lambda x: x.merge(broadcast).time_of_day == 'morning', 'owner'], program.loc[lambda x: x.merge(broadcast).time_of_day == 'night', 'owner']).drop_duplicates()"
arrange the origination of programs in the alphabetical order.,program.sort_values('origin')['origin']
which titles are ordered alphabetically for listing programs?,program.sort_values('origin')['origin']
what is the count of different categories of channel owners?,channel['owner'].nunique()
how many channels are owned by distinct publishers?,channel['owner'].nunique()
retrieve the names of programs that don't have their origin in beijing.,"program.loc[lambda x: x['origin']!='beijing', 'name']"
"what are the titles of programs whose origins are not ""beijing""?","program.loc[lambda x: x['origin']!='beijing', 'name']"
obtain the names of channels owned by cctv or hbs.,"channel.loc[channel['owner'].isin(['cctv', 'hbs']), 'name']"
list all of the channel titles which are either owned by cctv or hbs.,"channel.loc[channel['owner'].isin(['cctv', 'hbs']), 'name']"
retrieve the total rating ratio for each channel owner.,channel.groupby('owner')['rating_in_percent'].sum()
what is the total rating of channels for each channel owner?,channel.groupby('owner')['rating_in_percent'].sum()
identify the program title that is broadcasted the highest number of times.,"pd.merge(program, broadcast, on='program_id').groupby('program_id')['name'].first().value_counts().index[0]"
return the name of the program that is broadcast most frequently.,"pd.merge(program, broadcast, on='program_id').groupby('program_id')['name'].first().value_counts().index[0]"
how many courses exist?,courses.shape[0]
what is the total number of courses offered?,courses.shape[0]
"what courses are found under the name ""database""?","courses.loc[courses['course_name'] == 'database', 'course_description']"
"please provide me with the description for courses with the key words ""database"".","courses.loc[courses['course_name'] == 'database', 'course_description']"
"provide the names or aliases of the course authors or tutors whose first name is ""cathrine"".","course_authors_and_tutors.loc[lambda x: x['personal_name']=='cathrine', 'address_line_1']"
provide me with the addresses of all the course tutors or authors.,course_authors_and_tutors['address_line_1']
provide me the postal addresses of the course authored or tutored by each teacher.,course_authors_and_tutors['address_line_1']
provide the ids of tutees and tutors along with the names of course author and tutees.,"course_authors_and_tutors.loc[:, ['login_name', 'family_name']]"
provide me with the names of the authors of courses and their tutors.,"course_authors_and_tutors.loc[:, ['login_name', 'family_name']]"
list all dates of enrollment and completion of students.,"student_course_enrolment[['date_of_enrolment', 'date_of_completion']]"
find all the dates of enrollments and completions of records.,"student_course_enrolment[['date_of_enrolment', 'date_of_completion']]"
please return me the total number of students enrolled in a given course.,student_course_enrollment['student_id'].nunique()
find out the number of distinct students taking courses.,student_course_enrollment['student_id'].nunique()
what are the total number of distinct courses that students enroll into?,student_course_enrolment['course_id'].count()
what is your query for the count of distinct courses who have enrolled students?,student_course_enrolment['course_id'].count()
"find the date on which most exams were taken and the results were ""pass"".","student_tests_taken.loc[lambda x: x['test_result']=='pass', 'date_test_taken']"
"which tests had ""pass"" results? retrieve the dates of the tests.","student_tests_taken.loc[lambda x: x['test_result']=='pass', 'date_test_taken']"
"obtain the data set of tests that returned a result of ""fail.""",(student_tests_taken['test_result'] == 'fail').sum()
"how many tests resulted in ""fail""?",(student_tests_taken['test_result'] == 'fail').sum()
"list the login names of the students with family name ""ward"".","students.loc[lambda x: x['family_name']=='ward', 'login_name']"
provide me with the login names of the students whose family name is ward.,"students.loc[lambda x: x['family_name']=='ward', 'login_name']"
"retrieve the dates of the latest logon of the students with surnames ""jaskolski"" or ""langosh"".","students.loc[students['family_name'].isin(['jaskolski', 'langosh']), 'date_of_latest_logon']"
determine the date of the latest login among students who are related to jaskolski or langosh.,"students.loc[students['family_name'].isin(['jaskolski', 'langosh']), 'date_of_latest_logon']"
"what is the count of students with personal names containing the word ""son""?",students['personal_name'].str.contains('son').sum()
"retrieve the count of students that have the word ""son"" in their personal names.",students['personal_name'].str.contains('son').sum()
list all the titles of the subject names.,subjects['subject_name']
provide me with the titles of all the subjects.,subjects['subject_name']
specify the names of course authors and tutors in alphabetical order of their first name.,course_authors_and_tutors.sort_values('personal_name')
arrange the details about course authors and tutors in alphabetical order of the personal name.,course_authors_and_tutors.sort_values('personal_name')
"list the names of the students, in alphabetical order of family names.","students[['personal_name', 'family_name']].sort_values('family_name')"
sort the names of all the students in alphabetical order.,"students[['personal_name', 'family_name']].sort_values('family_name')"
enumerate all test results and order them in descending order by count.,"student_tests_taken.groupby('test_result').size().sort_values(ascending=false).reset_index(name='count')[['test_result', 'count']]"
"for each distinct test result, count the number of students who got the result.","student_tests_taken.groupby('test_result').size().sort_values(ascending=false).reset_index(name='count')[['test_result', 'count']]"
"retrieve the username of the professor who authored the course with name ""advanced database"".","pd.merge(course_authors_and_tutors, courses, on='author_id').loc[lambda x: x['course_name'] == 'advanced database', 'login_name']"
"give me the names of professors who teach the ""advanced database"" course.","pd.merge(course_authors_and_tutors, courses, on='author_id').loc[lambda x: x['course_name'] == 'advanced database', 'login_name']"
"find the course authors with the names ""operating system"" or ""data structure"" that are responsible for courses.","pd.merge(course_authors_and_tutors, courses, on='author_id').loc[lambda x: x['course_name'].isin(['operating system', 'data structure']), 'address_line_1']"
"list the ids of authors who teach either ""operating system"" or ""data structure"" class.","pd.merge(course_authors_and_tutors, courses, on='author_id').loc[lambda x: x['course_name'].isin(['operating system', 'data structure']), 'address_line_1']"
"which course writer has the most courses? what is his/her name, family name, and author id?","pd.merge(course_authors_and_tutors, courses, on='author_id').groupby(['personal_name', 'family_name', 'author_id']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['personal_name', 'family_name', 'author_id']]"
"provide me the title, family name, and id of the highest teaching faculty member based on course count.","pd.merge(course_authors_and_tutors, courses, on='author_id').groupby(['personal_name', 'family_name', 'author_id']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['personal_name', 'family_name', 'author_id']]"
what is the list of course authors that teach at least two courses along with their respective ids and addresses?,"pd.merge(course_authors_and_tutors, courses, on='author_id').groupby('author_id').filter(lambda x: len(x) >= 2)[['address_line_1', 'author_id']]"
give the addresses of authors who instruct two or more courses as well as their ids.,"pd.merge(course_authors_and_tutors, courses, on='author_id').groupby('author_id').filter(lambda x: len(x) >= 2)[['address_line_1', 'author_id']]"
"retrieve the title of courses taught by the tutor who has personal name ""julio"".","pd.merge(course_authors_and_tutors.loc[lambda x: x['personal_name']=='julio'], courses, on='author_id')['course_name']"
"retrieve the names of the courses offered by the trainer whose personal name is ""julio"".","pd.merge(course_authors_and_tutors.loc[lambda x: x['personal_name']=='julio'], courses, on='author_id')['course_name']"
"return the names of courses that belong to the subject named ""computer science"" along with the corresponding descriptions.","pd.merge(courses, subjects, on='subject_id').loc[lambda x: x['subject_name']=='computer science', ['course_name', 'course_description']]"
"fetch the titles and descriptions of the all the courses offered under the subject ""computer science"".","pd.merge(courses, subjects, on='subject_id').loc[lambda x: x['subject_name']=='computer science', ['course_name', 'course_description']]"
"retrieve the subject id, subject name, and the total number of courses for each subject.","pd.merge(courses, subjects, on='subject_id').groupby(['subject_id', 'subject_name']).size().reset_index(name='count')"
"what is the id, name, and the number of courses for each subject?","pd.merge(courses, subjects, on='subject_id').groupby(['subject_id', 'subject_name']).size().reset_index(name='count')"
"determine the subject id, course code, subject name, and course count for each subject, and sort by the course count in ascending order.","pd.merge(courses, subjects, on='subject_id').groupby(['subject_id', 'subject_name']).size().reset_index(name='count').sort_values(""count"")[['subject_id', 'subject_name', 'count']]"
"provide me the id, name and course count for each subject in ascending order.","pd.merge(courses, subjects, on='subject_id').groupby(['subject_id', 'subject_name']).size().reset_index(name='count').sort_values(""count"")[['subject_id', 'subject_name', 'count']]"
"what is the enrollment date of the english course named ""spanish""?","pd.merge(courses.loc[lambda x: x['course_name']=='spanish'], student_course_enrolment, on='course_id')['date_of_enrolment']"
"find the date when the ""spanish"" course was started.","pd.merge(courses.loc[lambda x: x['course_name']=='spanish'], student_course_enrolment, on='course_id')['date_of_enrolment']"
what course has the most students enrolling in it?,"courses.loc[pd.merge(courses, enrollment)['course_id'].value_counts().idxmax(), 'course_name']"
which course was taken up by the most students?,"courses.loc[pd.merge(courses, enrollment)['course_id'].value_counts().idxmax(), 'course_name']"
retrieve the courses that host exactly one student.,"pd.merge(courses, student_course_enrolment, on='course_id').groupby('course_name').filter(lambda x: len(x) == 1)['course_name']"
retrieve the titles of courses that were obtained from single student enrollments.,"pd.merge(courses, student_course_enrolment, on='course_id').groupby('course_name').filter(lambda x: len(x) == 1)['course_name']"
provide me with the names of courses that contain a minimum of 2 students.,"courses.merge(student_course_enrolment, on='course_id').groupby('course_name').filter(lambda x: len(x) > 2)[['course_description', 'course_name']].drop_duplicates()"
provide me with each course and its respective number of student enrollment.,"pd.merge(courses, student_course_enrolment, on='course_id').groupby('course_name').size().reset_index(name='count')"
please list the names of enrolled students and their corresponding course titles.,"pd.merge(courses, student_course_enrolment, on='course_id').groupby('course_name').size().reset_index(name='count')"
"retrieve the enrollment dates of all the tests whose results are ""pass.""","pd.merge(student_course_enrolment, student_tests_taken.loc[lambda x: x['test_result']=='pass'], on='registration_id')['date_of_enrolment']"
"obtain the enrollment dates for all tests that are marked as ""pass"".","pd.merge(student_course_enrolment, student_tests_taken.loc[lambda x: x['test_result']=='pass'], on='registration_id')['date_of_enrolment']"
"what is the completion date of tests whose status is ""fail""?","pd.merge(student_course_enrolment, student_tests_taken, on='registration_id').loc[lambda x: x['test_result']=='fail', 'date_of_completion']"
"please return me the list of tests that have ""fail"" result along with the completion dates.","pd.merge(student_course_enrolment, student_tests_taken, on='registration_id').loc[lambda x: x['test_result']=='fail', 'date_of_completion']"
"list the enrollment and completion dates of the student with personal name ""karson"".","pd.merge(student_course_enrolment, students.loc[lambda x: x['personal_name']=='karson', ['student_id']], on='student_id')[['date_of_enrolment', 'date_of_completion']]"
"find and return the dates on which the user ""karson"" enrolled in and completed the courses.","pd.merge(student_course_enrolment, students.loc[lambda x: x['personal_name']=='karson', ['student_id']], on='student_id')[['date_of_enrolment', 'date_of_completion']]"
"please list the enrollment and completion dates of the student with family name ""zieme"" and personal name ""bernie"".","pd.merge(student_course_enrolment, students, on='student_id').loc[lambda x: (x['family_name']=='zieme') & (x['personal_name']=='bernie'), ['date_of_enrolment', 'date_of_completion']]"
"on what dates did the student with family name ""zieme"" and personal name ""bernie"" enroll in and complete the two courses?","pd.merge(student_course_enrolment, students, on='student_id').loc[lambda x: (x['family_name']=='zieme') & (x['personal_name']=='bernie'), ['date_of_enrolment', 'date_of_completion']]"
please provide me with the student id and login name of the student with the highest count of course enrollments.,"pd.merge(student_course_enrolment, students, on='student_id').groupby('student_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['student_id', 'login_name']]"
please provide me the student id and login name of students who are enrolled in the most courses.,"pd.merge(student_course_enrolment, students, on='student_id').groupby('student_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['student_id', 'login_name']]"
provide me the student id and personal name of a student that has more than two enrollments.,"pd.merge(student_course_enrolment, students, on='student_id').groupby(['student_id', 'personal_name']).filter(lambda x: len(x) >= 2)[['student_id', 'personal_name']].drop_duplicates()"
give me the ids and names of all students who are enrolled in at least 2 courses.,"pd.merge(student_course_enrolment, students, on='student_id').groupby(['student_id', 'personal_name']).filter(lambda x: len(x) >= 2)[['student_id', 'personal_name']].drop_duplicates()"
retrieve the ids and middle names of the students having at most two enrollments.,"pd.merge(student_course_enrolment, students[['student_id', 'middle_name']], on='student_id').groupby('student_id').filter(lambda x: x.shape[0] <= 2)[['student_id', 'middle_name']]"
retrieve the student ids and middle names of students enrolled in at most two classes.,"pd.merge(student_course_enrolment, students[['student_id', 'middle_name']], on='student_id').groupby('student_id').filter(lambda x: x.shape[0] <= 2)[['student_id', 'middle_name']]"
obtain names assigned to students not enrolled in any course.,"students.loc[~students['personal_name'].isin(pd.merge(students, student_course_enrolment, on='student_id')['personal_name'])]['personal_name']"
retrieve names of students who are not enrolled in any course.,"students.loc[~students['personal_name'].isin(pd.merge(students, student_course_enrolment, on='student_id')['personal_name'])]['personal_name']"
how many students had no course enrollment?,students[~students['student_id'].isin(student_course_enrolment['student_id'])].shape[0]
determine the count of students who did not enroll in any of the courses.,students[~students['student_id'].isin(student_course_enrolment['student_id'])].shape[0]
return the names of courses and students who share the same login name.,pd.series(list(set(course_authors_and_tutors['login_name']).intersection(set(students['login_name']))))
"retrieve the list of login names, some of which belong to both some course authors and some students.",pd.series(list(set(course_authors_and_tutors['login_name']).intersection(set(students['login_name']))))
find the common names of authors of courses as well as their corresponding students.,pd.series(list(set(course_authors_and_tutors['personal_name']) & set(students['personal_name'])))
retrieve the names of both course authors and students.,pd.series(list(set(course_authors_and_tutors['personal_name']) & set(students['personal_name'])))
list all claims that have caused more than two settlements or have the maximum claim value. please include the date of the claim and the id of the claim.,"(pd.merge(claims, settlements, on='claim_id').groupby('claim_id').filter(lambda x: len(x) > 2)[['date_claim_made', 'claim_id']]).append(claims.loc[claims['amount_claimed']==claims['amount_claimed'].max(), ['date_claim_made', 'claim_id']].merge(settlements, on='claim_id'))"
"for claimants who settled more than two claims or had the maximum claim value, return the dates of the claims and the ids of the claims.","(pd.merge(claims, settlements, on='claim_id').groupby('claim_id').filter(lambda x: len(x) > 2)[['date_claim_made', 'claim_id']]).append(claims.loc[claims['amount_claimed']==claims['amount_claimed'].max(), ['date_claim_made', 'claim_id']].merge(settlements, on='claim_id'))"
provide the customer details as well as the customer id.,"pd.merge(customers, customer_policies, on='customer_id').groupby('customer_id').filter(lambda x: len(x)>=2).merge(claims, on='policy_id', how='left').dropna().drop_duplicates(subset=['customer_details', 'customer_id'])[['customer_details', 'customer_id']]"
identify those customers who had at least two policies but did not file any claims.,"pd.merge(customers, customer_policies, on='customer_id').groupby('customer_id').filter(lambda x: len(x)>=2).merge(claims, on='policy_id', how='left').dropna().drop_duplicates(subset=['customer_details', 'customer_id'])[['customer_details', 'customer_id']]"
"list all the payments, in ascending order of date, and with the name of the method and the amount.","payments[['payment_method_code', 'date_payment_made', 'amount_payment']].sort_values('date_payment_made')"
"provide the methods, dates, and amounts of each payment. sort the results by date in ascending order.","payments[['payment_method_code', 'date_payment_made', 'amount_payment']].sort_values('date_payment_made')"
what is the claim of the claim with the largest settlement amount? list both the settlement amount and claim amount.,"claims[['amount_settled', 'amount_claimed']].sort_values('amount_claimed', ascending=false).head(1)"
determine the settlement amount and the original amount of the largest claim.,"claims[['amount_settled', 'amount_claimed']].sort_values('amount_claimed', ascending=false).head(1)"
"provide me with the total amount of claims that have been settled and have the least settlement amount. also, please provide me the amounts of each claim.","claims[['amount_settled', 'amount_claimed']].sort_values('amount_settled').head(1)"
determine the amount of claim settled in the claim with the least amount settled; show both the settlement amount and the claim amount.,"claims[['amount_settled', 'amount_claimed']].sort_values('amount_settled').head(1)"
return me all claims that had a claimed amount larger than the average. list the date the claim was made and the date it was settled.,"claims.loc[lambda x: x['amount_claimed']>claims['amount_claimed'].mean(), ['date_claim_made', 'date_claim_settled']]"
"please provide me with the claim date, settlement date for all claims that exceeded the average claim amount.","claims.loc[lambda x: x['amount_claimed']>claims['amount_claimed'].mean(), ['date_claim_made', 'date_claim_settled']]"
"among all the settlements, which claims have a settlement that is no more than the average? list the settlement date.","claims.loc[lambda x: x['amount_settled'] <= x['amount_settled'].mean(), 'date_claim_made']"
provide the date of claim start for the claims that have a claimed amount not greater than the average.,"claims.loc[lambda x: x['amount_settled'] <= x['amount_settled'].mean(), 'date_claim_made']"
which claim code corresponds to which settlement number? list the claim id and the settlement number.,"pd.merge(claims, settlements, on='claim_id').groupby('claim_id').size().reset_index(name='count')"
"provide me the number of settlements each claim corresponds to. also, present the count along with the claim id.","pd.merge(claims, settlements, on='claim_id').groupby('claim_id').size().reset_index(name='count')"
"what claim received the greatest number of settlements? provide the claim id, the date the filing was made, and the total number of settlements.","claims.merge(settlements, on='claim_id').groupby(['claim_id', 'date_claim_made']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
provide me the claim id and claim date of the claim with the maximum number of settlement. also give me the count of settlement.,"claims.merge(settlements, on='claim_id').groupby(['claim_id', 'date_claim_made']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
list the count of settlements made on the claim with the most recent claim settlement date. please also list the number and the claim id of the claim.,"pd.merge(claims, settlements, on='claim_id').groupby('claim_id').size().reset_index(name='count').sort_values(by='date_claim_settled', ascending=false).iloc[0]"
provide me the id of the claim and the number of settlements made for the claim with the most recent settlement date.,"pd.merge(claims, settlements, on='claim_id').groupby('claim_id').size().reset_index(name='count').sort_values(by='date_claim_settled', ascending=false).iloc[0]"
return me the date on which the earliest claim was made.,claims.sort_values('date_claim_made').iloc[0]['date_claim_made']
when was the claim made for the first time?,claims.sort_values('date_claim_made').iloc[0]['date_claim_made']
what is the total amount paid for all the settlements?,settlements['amount_settled'].sum()
determine the sum of all settlement sums.,settlements['amount_settled'].sum()
list the ids and the names or customer who had more than one policy.,"pd.merge(customers, customer_policies, on='customer_id').groupby('customer_id').filter(lambda x: len(x)>1)[['customer_details', 'customer_id']]"
fetch the customer's name and id for those customers who had more than one policy.,"pd.merge(customers, customer_policies, on='customer_id').groupby('customer_id').filter(lambda x: len(x)>1)[['customer_details', 'customer_id']]"
could you return me the dates when the claims were settled?,"settlements[['date_claim_made', 'date_claim_settled']]"
provide me with the dates of the filing of a claim and the date of its settlement for each settlement case.,"settlements[['date_claim_made', 'date_claim_settled']]"
which payment model is the most popular?,payments.groupby('payment_method_code').size().sort_values(ascending=false).index[0]
what is the payment method that is most popular?,payments.groupby('payment_method_code').size().sort_values(ascending=false).index[0]
"out of all the payment methods, by which method had the least number of payments processed?",payments.groupby('payment_method_code').size().sort_values().index[0]
what is the count of payment types that were employed the least number of times?,payments.groupby('payment_method_code').size().sort_values().index[0]
what are the total payments?,payments['amount_payment'].sum()
what is the total amount (in dollars) of payment processed?,payments['amount_payment'].sum()
retrieve the lists of all the distinct customers' details.,customers['customer_details'].unique()
provide me with the distinct customer details.,customers['customer_details'].unique()
what are the policy types that were chosen most frequently by customers?,customer_policies.groupby('policy_type_code').size().sort_values(ascending=false).index[0]
determine the policy type which has been chosen by the largest number of customers.,customer_policies.groupby('policy_type_code').size().sort_values(ascending=false).index[0]
count the number of settlements.,settlements.shape[0]
determine the total number of settlements.,settlements.shape[0]
"what is the payment id, date, and amount for payments paid with visa?","payments.loc[payments['payment_method_code']=='visa', ['payment_id', 'date_payment_made', 'amount_payment']]"
"provide me with payment ids, dates and amounts of payments processed with visa.","payments.loc[payments['payment_method_code']=='visa', ['payment_id', 'date_payment_made', 'amount_payment']]"
retrieve the ids and names of customers who are not having policies.,"customers.loc[~customers['customer_id'].isin(customer_policies['customer_id']), 'customer_details']"
list the details for the customers who do not have policies.,"customers.loc[~customers['customer_id'].isin(customer_policies['customer_id']), 'customer_details']"
"provide me the date the claim was made, the date it was settled and the settlement amount for all the claims which had exactly one settlement.","pd.merge(claims, settlements, on='claim_id').groupby('claim_id').filter(lambda g: g.shape[0] == 1)[['claim_id', 'date_claim_made', 'date_claim_settled']]"
"for each claim, provide me the date that it was made, the date that it was settled and the settlement amount.","pd.merge(claims, settlements, on='claim_id').groupby('claim_id').filter(lambda g: g.shape[0] == 1)[['claim_id', 'date_claim_made', 'date_claim_settled']]"
retrieve the total claimed to be paid by all the individuals.,claims['amount_claimed'].sum()
what is the total amount of claims?,claims['amount_claimed'].sum()
what is the department that has the most number of employees?,department.groupby('departmentid')['name'].count().sort_values(ascending=false).index[0]
what is the top department by the number of its subordinates?,department.groupby('departmentid')['name'].count().sort_values(ascending=false).index[0]
please provide me with the employee id of the head of that department that has the smallest number of employees.,"department.groupby('departmentid').agg(head=pd.namedagg(column='head', aggfunc='first')).reset_index().sort_values(by='departmentid').groupby('head').agg(department_count=pd.namedagg(column='departmentid', aggfunc='count')).reset_index().sort_values(by='department_count').reset_index(drop=true).head(1)['head']"
please provide me with the employee id of the head of the department with the least number of employees.,"department.groupby('departmentid').agg(head=pd.namedagg(column='head', aggfunc='first')).reset_index().sort_values(by='departmentid').groupby('head').agg(department_count=pd.namedagg(column='departmentid', aggfunc='count')).reset_index().sort_values(by='department_count').reset_index(drop=true).head(1)['head']"
"retrieve the name (first name, last name) and position of the department head who has the smallest number of subordinates.","department.merge(physician, left_on='head', right_on='employeeid').groupby('departmentid').apply(lambda x: x[['name', 'position']].iloc[0]).sort_values('departmentid', ascending=true).iloc[[0]]"
list the departments with the fewest employees and their associated head.,"department.merge(physician, left_on='head', right_on='employeeid').groupby('departmentid').apply(lambda x: x[['name', 'position']].iloc[0]).sort_values('departmentid', ascending=true).iloc[[0]]"
retrieve the names of patients that made appointments.,"pd.merge(appointment, patient, left_on='patient', right_on='ssn')['name']"
provide me with the names of patients who have made appointments.,"pd.merge(appointment, patient, left_on='patient', right_on='ssn')['name']"
record the names of the patients who had more than one appointments and their phone numbers.,"pd.merge(appointment, patient, left_on='patient', right_on='ssn').groupby('patient').filter(lambda x: len(x) > 1).loc[:, ['name', 'phone']]"
which patients made more than one appointment? provide me with the names of the patients and the phone numbers they were registered under.,"pd.merge(appointment, patient, left_on='patient', right_on='ssn').groupby('patient').filter(lambda x: len(x) > 1).loc[:, ['name', 'phone']]"
determine the appointment id with the most recently scheduled start date.,"appointment.sort_values('start', ascending=false).iloc[0]['appointmentid']"
what are the ids of appointments that started most recently?,"appointment.sort_values('start', ascending=false).iloc[0]['appointmentid']"
please provide the names of physicians who were taken appointments.,"pd.merge(appointment, physician, left_on='physician', right_on='employeeid')['name']"
fetch the names of all the physicians who have taken appointments.,"pd.merge(appointment, physician, left_on='physician', right_on='employeeid')['name']"
please show me the list of medical practitioners who are never booked.,"physician[~physician['name'].isin(appointment.merge(physician, left_on='physician', right_on='employeeid')['name_y'])]['name']"
list the names of the physicians who have not accepted any appointment.,"physician[~physician['name'].isin(appointment.merge(physician, left_on='physician', right_on='employeeid')['name_y'])]['name']"
retrieve the titles of physicians and departments that they belong to.,"pd.merge(pd.merge(physician, affiliated_with, left_on='employeeid', right_on='physician'), department, left_on='department', right_on='departmentid').loc[lambda x: x['primaryaffiliation']==1, ['name_x', 'name_y']]"
"which title, department name, and physician name combinations are applicable?","pd.merge(pd.merge(physician, affiliated_with, left_on='employeeid', right_on='physician'), department, left_on='department', right_on='departmentid').loc[lambda x: x['primaryaffiliation']==1, ['name_x', 'name_y']]"
please provide me with the name of the patient who makes the most recent appointment.,"pd.merge(patient, appointment, left_on='ssn', right_on='patient').sort_values('start', ascending=false).iloc[0]['name']"
determine the name of patient whose appointment started most recently.,"pd.merge(patient, appointment, left_on='ssn', right_on='patient').sort_values('start', ascending=false).iloc[0]['name']"
kindly count the number of patients that stay in room 112.,(stay['room'] == 112)['patient'].sum()
how many patients stayed in room 112?,(stay['room'] == 112)['patient'].sum()
what is the count of patients who received prescriptions from john dorian?,"pd.merge(pd.merge(patient, prescribes, left_on='ssn', right_on='patient'), physician, left_on='physician', right_on='employeeid').loc[lambda x: x['name']=='john dorian', 'ssn'].count()"
please provide me with the count of prescriptions made by john dorian to patients.,"pd.merge(pd.merge(patient, prescribes, left_on='ssn', right_on='patient'), physician, left_on='physician', right_on='employeeid').loc[lambda x: x['name']=='john dorian', 'ssn'].count()"
identify the name of the medicine that was given to a patient staying in room 111.,"pd.merge(pd.merge(pd.merge(stay, patient, left_on='patient', right_on='ssn'), prescribes, left_on='ssn', right_on='patient'), medication, left_on='medication', right_on='code').loc[lambda x: x['room']==111, 'name']"
determine the name and type of medication that is administered to the patient staying in room 111.,"pd.merge(pd.merge(pd.merge(stay, patient, left_on='patient', right_on='ssn'), prescribes, left_on='ssn', right_on='patient'), medication, left_on='medication', right_on='code').loc[lambda x: x['room']==111, 'name']"
find the patient with the most recent visit in room 111.,"stay.loc[lambda x: x['room']==111].sort_values('staystart', ascending=false).iloc[0]['patient']"
please provide me with the id of the patient who stayed in room 111 most recently.,"stay.loc[lambda x: x['room']==111].sort_values('staystart', ascending=false).iloc[0]['patient']"
what is the full name of the nurse who has made the most appointments?,"pd.merge(nurse, appointment, left_on='employeeid', right_on='prepnurse').groupby('employeeid').size().sort_values(ascending=false).reset_index(drop=true).iloc[0]"
retrieve the title of the nurse who has the greatest number of appointments.,"pd.merge(nurse, appointment, left_on='employeeid', right_on='prepnurse').groupby('employeeid').size().sort_values(ascending=false).reset_index(drop=true).iloc[0]"
"provide me with the id, name, and count of patients that each doctor is responsible for.","patient.groupby('pcp').size().reset_index(name='count').merge(physician[['employeeid', 'name']], left_on='pcp', right_on='employeeid', how='left').drop('employeeid', axis=1)"
please give me the name and count of patients treated by each physician.,"patient.groupby('pcp').size().reset_index(name='count').merge(physician[['employeeid', 'name']], left_on='pcp', right_on='employeeid', how='left').drop('employeeid', axis=1)"
list the names of physicians who are in charge of more than one patient.,"pd.merge(physician, patient, left_on='employeeid', right_on='pcp').groupby('employeeid').filter(lambda x: len(x) > 1)['name']"
please provide the names of physicians who are in charge of more than one patient.,"pd.merge(physician, patient, left_on='employeeid', right_on='pcp').groupby('employeeid').filter(lambda x: len(x) > 1)['name']"
provide me the count of rooms on each block floor.,"pd.merge(block, room, on=['blockfloor', 'blockcode']).groupby('blockfloor').size().reset_index(name='count')"
how many rooms does each floor have in each block?,"pd.merge(block, room, on=['blockfloor', 'blockcode']).groupby('blockfloor').size().reset_index(name='count')"
how many rooms there are for different block codes?,"pd.merge(block, room, on=['blockfloor', 'blockcode']).groupby('blockcode').size().reset_index(name='count')"
what is the count of rooms for each apartment type?,"pd.merge(block, room, on=['blockfloor', 'blockcode']).groupby('blockcode').size().reset_index(name='count')"
what are the unique block codes that have rooms available?,"room.loc[lambda x: x['unavailable']==0, 'blockcode'].unique()"
a count of rooms that belong to a block code where the rooms are not available.,"room.loc[lambda x: x['unavailable']==0, 'blockcode'].unique()"
what is the number of different types of rooms?,room['roomtype'].nunique()
determine the total count of available room types.,room['roomtype'].nunique()
"which physicians prescribed medication ""thesisin"" for their patients?","pd.merge(pd.merge(physician, prescribes, left_on='employeeid', right_on='physician'), medication, left_on='medication', right_on='code').loc[lambda x: x['name']=='thesisin', 'name_x'].unique()"
provide me with the full name of physicians who prescribe thesisin as medication.,"pd.merge(pd.merge(physician, prescribes, left_on='employeeid', right_on='physician'), medication, left_on='medication', right_on='code').loc[lambda x: x['name']=='thesisin', 'name_x'].unique()"
reveal the names and positions of physicians who prescribe some medication whose brand is x.,"pd.merge(pd.merge(physician, prescribes, left_on='employeeid', right_on='physician'), medication, on='code').loc[lambda x: x['brand']=='x', ['name', 'position']].drop_duplicates()"
which physicians prescribe a specific brand of medication? please provide me the names and positions of the doctors.,"pd.merge(pd.merge(physician, prescribes, left_on='employeeid', right_on='physician'), medication, on='code').loc[lambda x: x['brand']=='x', ['name', 'position']].drop_duplicates()"
compute the count of medications prescribed for each brand.,"medication.merge(prescribes, left_on='code', right_on='medication').groupby('brand')['name'].agg(['count', lambda x: x.iloc[0]])"
how many medications are prescribed by each brand?,"medication.merge(prescribes, left_on='code', right_on='medication').groupby('brand')['name'].agg(['count', lambda x: x.iloc[0]])"
list the titles of physicians that possess the term 'senior'.,"physician.loc[physician['position'].str.contains('senior', case=false), 'name']"
retrieve the titles of physicians who have 'senior' in their titles.,"physician.loc[physician['position'].str.contains('senior', case=false), 'name']"
please provide me with the patient who is undergoing the most recent treatment.,undergoes.sort_values('dateundergoes')['patient'].iloc[0]
what patient is undergoing the most recent treatment?,undergoes.sort_values('dateundergoes')['patient'].iloc[0]
find the titles of all patients that are accompanying their treatments and have rooms 111.,"pd.merge(pd.merge(undergoes, patient, left_on='patient', right_on='ssn'), stay, left_on='stay', right_on='stayid').loc[lambda x: x['room']==111, 'name'].unique()"
what is the list of patients staying in room 111 and who are diagnosed with a disease?,"pd.merge(pd.merge(undergoes, patient, left_on='patient', right_on='ssn'), stay, left_on='stay', right_on='stayid').loc[lambda x: x['room']==111, 'name'].unique()"
please sort the names of all distinct nurses alphabetically.,nurse['name'].sort_values().unique()
what is the ordered list of the distinct names of nurses?,nurse['name'].sort_values().unique()
find the names of nurses that are taking care of patients.,"pd.merge(undergoes, nurse, left_on='assistingnurse', right_on='employeeid')['name'].unique()"
which nurses are primarily responsible for patients under treatment?,"pd.merge(undergoes, nurse, left_on='assistingnurse', right_on='employeeid')['name'].unique()"
"retrieve the names of the distinct medications, ordered alphabetically.",medication['name'].sort_values().unique()
what is an alphabetically ordered list of all distinct medications?,medication['name'].sort_values().unique()
give me the names of physicians who prescribed the highest dose.,"pd.merge(physician, prescribes, left_on='employeeid', right_on='physician').nlargest(1, 'dose')['name']"
please provide me with the name of the doctor and the dosage he or she is prescribing.,"pd.merge(physician, prescribes, left_on='employeeid', right_on='physician').nlargest(1, 'dose')['name']"
provide the ids of the employees that work in departments that are their affiliated departments' ids.,"affiliated_with.loc[lambda x: x['primaryaffiliation']==1, ['physician', 'department']]"
retrieve the employee id and department id for each physician primarily affiliated.,"affiliated_with.loc[lambda x: x['primaryaffiliation']==1, ['physician', 'department']]"
list the titles of departments that include physicians who are typically affiliated with.,"pd.merge(affiliated_with, department, left_on='department', right_on='departmentid').loc[lambda x: x['primaryaffiliation']==1, 'name'].unique()"
which departments have physicians affiliated primarily?,"pd.merge(affiliated_with, department, left_on='department', right_on='departmentid').loc[lambda x: x['primaryaffiliation']==1, 'name'].unique()"
please provide me with the names of nurses who are on call with block floor 1 and block code 1.,"on_call.loc[(on_call['blockfloor'] == 1) & (on_call['blockcode'] == 1), 'nurse']"
what are the ids of the nurses who are on call in block floor 1 and block code 1?,"on_call.loc[(on_call['blockfloor'] == 1) & (on_call['blockcode'] == 1), 'nurse']"
"what is the maximum amount, minimum amount and average amount spent on medical procedures?","procedures['cost'].agg(['max', 'min', 'mean'])"
"please provide me with the highest, lowest, and average cost of procedures.","procedures['cost'].agg(['max', 'min', 'mean'])"
provide me with the name and cost of all procedures in ascending order from the highest cost to the lowest cost.,"procedures[['name', 'cost']].sort_values('cost', ascending=false)"
sort the list of names and costs of all procedures in descending order of their cost.,"procedures[['name', 'cost']].sort_values('cost', ascending=false)"
get the details of the top three most expensive procedures.,procedures.sort_values('cost').reset_index()['name'][:3]
what is the highest number of expensive procedures?,procedures.sort_values('cost').reset_index()['name'][:3]
retrieve the names of physicians trained in a procedure that costs more than 5000.,"pd.merge(pd.merge(physician, trained_in, left_on='employeeid', right_on='physician'), procedures, left_on='treatment', right_on='code').loc[lambda x: x['cost'] > 5000, 'name']"
which physicians are trained in procedures that cost greater than 5000?,"pd.merge(pd.merge(physician, trained_in, left_on='employeeid', right_on='physician'), procedures, left_on='treatment', right_on='code').loc[lambda x: x['cost'] > 5000, 'name']"
determine the physician who underwent the most expensive procedure.,"pd.merge(pd.merge(physician, trained_in, left_on='employeeid', right_on='physician'), procedures, left_on='treatment', right_on='code')['name'].loc[lambda x: x['cost']==x['cost'].max()]"
which physician was trained in the procedure that incurs the highest cost?,"pd.merge(pd.merge(physician, trained_in, left_on='employeeid', right_on='physician'), procedures, left_on='treatment', right_on='code')['name'].loc[lambda x: x['cost']==x['cost'].max()]"
calculate the average cost of procedures that physician john wen was trained in.,"pd.merge(pd.merge(physician.loc[lambda x: x['name']=='john wen'], trained_in, left_on='employeeid', right_on='physician'), procedures, left_on='treatment', right_on='code')['cost'].mean()"
calculate the average value of prices physician john wen was trained in.,"pd.merge(pd.merge(physician.loc[lambda x: x['name']=='john wen'], trained_in, left_on='employeeid', right_on='physician'), procedures, left_on='treatment', right_on='code')['cost'].mean()"
retrieve the names of procedures that physician john wen was trained in.,"procedures.merge(trained_in.merge(physician[physician['name']=='john wen'], left_on='physician', right_on='employeeid'), left_on='code', right_on='treatment')['name']"
what is the list of procedures taught by dr. john wen?,"procedures.merge(trained_in.merge(physician[physician['name']=='john wen'], left_on='physician', right_on='employeeid'), left_on='code', right_on='treatment')['name']"
list all procedures that cost more than 1000 or procedures in which john wen was involved.,"pd.concat([procedures.loc[lambda x: x['cost'] > 1000, 'name'], pd.merge(pd.merge(physician.loc[lambda x: x['name'] == 'john wen'], trained_in, left_on='employeeid', right_on='physician'), procedures, on='code')['name']]).drop_duplicates()"
which procedures cost over $1000 or are being performed by physician john wen?,"pd.concat([procedures.loc[lambda x: x['cost'] > 1000, 'name'], pd.merge(pd.merge(physician.loc[lambda x: x['name'] == 'john wen'], trained_in, left_on='employeeid', right_on='physician'), procedures, on='code')['name']]).drop_duplicates()"
retrieve the names of all procedures whose cost is more than 1000 but were not trained in by physician john wen.,"procedures.loc[lambda x: x['cost']>1000, 'name'].tolist() - procedures.loc[procedures.merge(trained_in.merge(physician.loc[lambda x: x['name']=='john wen'], on='employeeid'), on='code')]['name'].tolist()"
give me the procedures that cost at least $1k which john wen is not specialized in.,"procedures.loc[lambda x: x['cost']>1000, 'name'].tolist() - procedures.loc[procedures.merge(trained_in.merge(physician.loc[lambda x: x['name']=='john wen'], on='employeeid'), on='code')]['name'].tolist()"
please provide me with the names of procedures that cost less than $5000 and were instructed by john wen.,"procedures[procedures['cost'] < 5000]['name'].intersec‌t(procedures.merge(trained_in.merge(physician[physician['name'] == 'john wen'], on='employeeid', how='inner'), left_on='code', right_on='treatment', how='inner')['name'])"
which procedures have an average cost of less than 5000 dollars and john wen as a trained physician?,"procedures.loc[lambda x: x['cost']<5000, 'name'].intersects(procedures.merge(trained_in.merge(physician.loc[lambda x: x['name']=='john wen'], on='employeeid'), on='code')['name'])"
figure out the authors who are affiliated with both the psychiatry and surgery departments.,"pd.merge(pd.merge(physician.merge(affiliated_with, left_on='employeeid', right_on='physician'), department, left_on='department', right_on='departmentid').loc[lambda x: x['name']=='surgery', 'name'], pd.merge(physician.merge(affiliated_with, left_on='employeeid', right_on='physician'), department, left_on='department', right_on='departmentid').loc[lambda x: x['name']=='psychiatry', 'name'], on='name')['name']"
which physicians are affiliated with both surgery and psychiatry departments?  tell me about them.,"pd.merge(pd.merge(physician.merge(affiliated_with, left_on='employeeid', right_on='physician'), department, left_on='department', right_on='departmentid').loc[lambda x: x['name']=='surgery', 'name'], pd.merge(physician.merge(affiliated_with, left_on='employeeid', right_on='physician'), department, left_on='department', right_on='departmentid').loc[lambda x: x['name']=='psychiatry', 'name'], on='name')['name']"
return the names of physicians who are associated with surgery or psychiatry department.,"pd.merge(pd.merge(physician, affiliated_with, left_on='employeeid', right_on='physician'), department, left_on='department', right_on='departmentid').loc[lambda x: x['name'].isin(['surgery', 'psychiatry']), 'name_x']"
"is there a department of surgery and psychiatry that have physicians affiliated to them? if so, then provide me with their names.","pd.merge(pd.merge(physician, affiliated_with, left_on='employeeid', right_on='physician'), department, left_on='department', right_on='departmentid').loc[lambda x: x['name'].isin(['surgery', 'psychiatry']), 'name_x']"
find the title s of patients that are not utilizing the medicine of procrastin-x.,"patient.loc[~patient['name'].isin(pd.merge(pd.merge(prescribes, medication, left_on='medication', right_on='code'), patient, left_on='patient', right_on='ssn').loc[lambda x: x['name']=='procrastin-x', 'name'])]['name']"
retrieve the names of patients who are not taking the medicine of procrastin-x.,"patient.loc[~patient['name'].isin(pd.merge(pd.merge(prescribes, medication, left_on='medication', right_on='code'), patient, left_on='patient', right_on='ssn').loc[lambda x: x['name']=='procrastin-x', 'name'])]['name']"
provide the count of patients who are not recommended to take procrastin-x.,"patient.loc[~patient['ssn'].isin(pd.merge(prescribes, medication, left_on='medication', right_on='code').loc[lambda x: x['name']=='procrastin-x', 'patient']), :].shape[0]"
determine the number of patients that are not using procrastin-x as their medication.,"patient.loc[~patient['ssn'].isin(pd.merge(prescribes, medication, left_on='medication', right_on='code').loc[lambda x: x['name']=='procrastin-x', 'patient']), :].shape[0]"
how many appointments are scheduled?,appointment.shape[0]
determine the total count of appointments that are done.,appointment.shape[0]
retrieve the names of nurses that are on-duty.,"pd.merge(nurse, on_call, left_on='employeeid', right_on='nurse')['name'].unique()"
what are the unique names of nurses who are on-call?,"pd.merge(nurse, on_call, left_on='employeeid', right_on='nurse')['name'].unique()"
how many ships are present in the data?,ship.shape[0]
how many times do ships appear?,ship.shape[0]
provide the names of the ships in ascending order of tonnage.,ship.sort_values('tonnage')['name']
retrieve the names of ships ordered by ascending mass.,ship.sort_values('tonnage')['name']
what are the attributes of ships?,"ship[['type', 'nationality']]"
"retrieve the names of vessels whose nationality is not ""united states"".","ship.loc[ship['nationality'] != 'united states', 'name']"
retrieve the names of the ships that are not from the united states.,"ship.loc[ship['nationality'] != 'united states', 'name']"
display the title of ships whose nationality is either the united states or the united kingdom.,"ship.loc[lambda x: x['nationality'].isin(['united states', 'united kingdom']), 'name']"
identify the titles of all ships that are either from the united kingdom or the united states.,"ship.loc[lambda x: x['nationality'].isin(['united states', 'united kingdom']), 'name']"
kindly provide the name of the ship possessing the largest tonnage.,"ship.sort_values('tonnage', ascending=false).iloc[0]['name']"
what is the title given to the ship with the largest tonnage?,"ship.sort_values('tonnage', ascending=false).iloc[0]['name']"
which types of ships exist and how many ships of each type exist?,ship.groupby('type').size().reset_index(name='count')
how many ships are there for each type?,ship.groupby('type').size().reset_index(name='count')
please return me the top five types of ships.,ship.groupby('type').size().sort_values(ascending=false).index[0]
what is the most commonly built ship type?,ship.groupby('type').size().sort_values(ascending=false).index[0]
enumerate the nations that possess more than two ships.,ship.groupby('nationality').filter(lambda x: len(x) > 2)['nationality'].unique()
provide the names of nations that have more than one ship.,ship.groupby('nationality').filter(lambda x: len(x) > 2)['nationality'].unique()
"return me the titles of ships, their tonnage and displacement.",ship.groupby('type')['tonnage'].mean()
"for each cargo type, what is the average tonnage?",ship.groupby('type')['tonnage'].mean()
display the id and fates of the missions and names of the ships involved in each.,"pd.merge(mission, ship, on='ship_id')[['code', 'fate', 'name']]"
"please provide me with the mission codes, fate codes, and names of ships involved in the incident.","pd.merge(mission, ship, on='ship_id')[['code', 'fate', 'name']]"
can you give me the titles of ships engaged in missions launched after 1928?,"pd.merge(mission, ship, on='ship_id').loc[lambda x: x['launched_year'] > 1928, 'name']"
provide me the names of ships that were involved in missions launched after 1928.,"pd.merge(mission, ship, on='ship_id').loc[lambda x: x['launched_year'] > 1928, 'name']"
"reveal the fate of each mission that involves a ship with nationality ""united states"".","pd.merge(mission, ship, on='ship_id').loc[lambda x: x['nationality']=='united states', 'fate'].unique()"
which of the missions that involved ships from the united states had different outcomes?,"pd.merge(mission, ship, on='ship_id').loc[lambda x: x['nationality']=='united states', 'fate'].unique()"
list the titles of all ships that are not engaged in any mission.,"ship.loc[~ship['ship_id'].isin(mission['ship_id']), 'name']"
provide me the names of ships that are not involved in any mission.,"ship.loc[~ship['ship_id'].isin(mission['ship_id']), 'name']"
create an array of types of ships that have both ships with tonnage larger than 6000 and ships with tonnage smaller than 4000.,"ship.loc[ship['tonnage'] > 6000, 'type'].intersect(ship.loc[ship['tonnage'] < 4000, 'type'])"
what kinds of ships have both ships with tonnage greater than 6000 and ships with tonnage less than 4000?,"ship.loc[ship['tonnage'] > 6000, 'type'].intersect(ship.loc[ship['tonnage'] < 4000, 'type'])"
retrieve the last names of students associated with room 111.,"list.loc[list['classroom']==111, 'lastname']"
what names are there for the students in room 111?,"list.loc[list['classroom']==111, 'lastname']"
return the names of students engrossed in classroom 108.,"list.loc[list['classroom']==108, 'firstname']"
please provide me with the names of the students in room 108.,"list.loc[list['classroom']==108, 'firstname']"
return me the first names of students studying in room 107.,"list.loc[list['classroom']==107, 'firstname'].unique()"
return the names of all students who occupy room 107.,"list.loc[list['classroom']==107, 'firstname'].unique()"
for each classroom return the grade that is taught in it.,"list[['classroom', 'grade']].drop_duplicates()"
provide the grade number and the assigned classroom number for each class in the list.,"list[['classroom', 'grade']].drop_duplicates()"
what is the grade that is studying in classroom 103?,"list.loc[list['classroom']==103, 'grade'].unique()"
find the classroom number 103 in which grade x is taught.,"list.loc[list['classroom']==103, 'grade'].unique()"
what is the number of students who study in room 105?,"list.loc[list['classroom']==105, 'grade'].unique()"
what classrooms are used by grade 4?,"list.loc[lambda x: x['grade'] == 4, 'classroom'].unique()"
retrieve the classrooms that are being used for grade 4.,"list.loc[lambda x: x['grade'] == 4, 'classroom'].unique()"
what is the count of classrooms utilized by grade 5 students?,"list.loc[lambda x: x['grade']==5, 'classroom'].unique()"
obtain the names of classrooms of grade 5.,"list.loc[lambda x: x['grade']==5, 'classroom'].unique()"
provide me with the surnames of the teachers that teach fifth grade.,"pd.merge(list, teachers, on='classroom').loc[lambda x: x['grade']==5, 'lastname'].unique()"
find the names of teachers who teach 5th grade.,"pd.merge(list, teachers, on='classroom').loc[lambda x: x['grade']==5, 'lastname'].unique()"
retrieve the first names for the teachers that teach first grade.,"pd.merge(list, teachers, on='classroom').loc[lambda x: x['grade']==1, 'firstname'].unique()"
list the first names of the teachers who teach grade 1.,"pd.merge(list, teachers, on='classroom').loc[lambda x: x['grade']==1, 'firstname'].unique()"
retrieve the names of all the teachers that are located in classroom 110.,"teachers.loc[lambda x: x['classroom']==110, 'firstname']"
give me the names of teachers that teach in classroom 110.,"teachers.loc[lambda x: x['classroom']==110, 'firstname']"
retrieve the last names that are linked with classroom number 109.,"teachers.loc[lambda x: x['classroom'] == 109, 'lastname']"
which teachers teach in classroom 109? sentence: how many employees are 80 years old or older?output: how many employees are 80 years old or older?,"teachers.loc[lambda x: x['classroom'] == 109, 'lastname']"
please provide me with the first name and last name of all the teachers.,"teachers[['firstname', 'lastname']].drop_duplicates()"
please return me the first and last name of all the teachers.,"teachers[['firstname', 'lastname']].drop_duplicates()"
provide the titles of all students.,"list[['firstname', 'lastname']].drop_duplicates()"
please list the first and last name of students in decreasing order.,"list[['firstname', 'lastname']].drop_duplicates()"
return the first and last names of the students taught by otha moyer.,"list.loc[list['classroom'].isin(teachers.loc[(teachers['firstname']=='otha') & (teachers['lastname']=='moyer'), 'classroom']), ['firstname', 'lastname']]"
provide me with the first and last names of students studying under the teacher named otha moyer.,"list.loc[list['classroom'].isin(teachers.loc[(teachers['firstname']=='otha') & (teachers['lastname']=='moyer'), 'classroom']), ['firstname', 'lastname']]"
provide me with the first and last names of students taught by marotte kirk.,"list.merge(teachers.loc[(teachers['firstname']=='marrotte') & (teachers['lastname']=='kirk'), 'classroom'], on='classroom')[['firstname', 'lastname']]"
what are the first and last names of the students taught by marrotte kirk?,"list.merge(teachers.loc[(teachers['firstname']=='marrotte') & (teachers['lastname']=='kirk'), 'classroom'], on='classroom')[['firstname', 'lastname']]"
retrieve the first and last name of all the faculty that teaches velina bromley.,"teachers.loc[lambda x: x['classroom'].isin(list.loc[lambda y: (y['firstname']=='evelina')&(y['lastname']=='bromley'), 'classroom']), ['firstname', 'lastname']]"
which teaches teach the student named evelina bromley? give me the full names of the teachers.,"teachers.loc[lambda x: x['classroom'].isin(list.loc[lambda y: (y['firstname']=='evelina')&(y['lastname']=='bromley'), 'classroom']), ['firstname', 'lastname']]"
determine the complete names of all the teachers that are teaching the gell tami.,"pd.merge(list[list['firstname']=='gell'][list['lastname']=='tami'], teachers, on='classroom')['lastname']"
what are the last names of teachers in the student called gell tami?,"pd.merge(list[list['firstname']=='gell'][list['lastname']=='tami'], teachers, on='classroom')['lastname']"
what are the members of the department of loria ondersma?,"pd.merge(list, teachers, on='classroom').loc[lambda x: (x['firstname']=='loria') & (x['lastname']=='ondersma'), :].shape[0]"
what is the count of students taught by the teacher loria ondersma?,"pd.merge(list, teachers, on='classroom').loc[lambda x: (x['firstname']=='loria') & (x['lastname']=='ondersma'), :].shape[0]"
how many students are taught by kawa gordon?,"pd.merge(list, teachers, on='classroom').loc[lambda x: (x['firstname']=='kawa')&(x['lastname']=='gordon'), :].shape[0]"
please count the number of students taught by the teacher kawa gordon.,"pd.merge(list, teachers, on='classroom').loc[lambda x: (x['firstname']=='kawa')&(x['lastname']=='gordon'), :].shape[0]"
count the number of students taught by tarring leia.,"pd.merge(list, teachers, on='classroom').loc[lambda x: (x['firstname']=='tarring')&(x['lastname']=='leia'), :].shape[0]"
what is the count of students who are taught by teacher tarring leia?,"pd.merge(list, teachers, on='classroom').loc[lambda x: (x['firstname']=='tarring')&(x['lastname']=='leia'), :].shape[0]"
what is the count of teachers that the student named chrissy nabozny has?,"len(pd.merge(list, teachers, on='classroom').loc[(list['firstname']=='chrissy') & (list['lastname']=='nabozny')])"
find the total number of teachers who teach the student named chrissy nabozny.,"len(pd.merge(list, teachers, on='classroom').loc[(list['firstname']=='chrissy') & (list['lastname']=='nabozny')])"
what is the count of teachers that the student named madlock ray has?,"pd.merge(list, teachers, on='classroom').loc[(lambda x: (x['firstname']=='madlock') & (x['lastname']=='ray')), :].shape[0]"
determine the count of teachers instructing the student called madlock ray.,"pd.merge(list, teachers, on='classroom').loc[(lambda x: (x['firstname']=='madlock') & (x['lastname']=='ray')), :].shape[0]"
determine the names of students of first-grade who are not taught by otha moyer. report their first names and surnames.,"list.merge(teachers, on='classroom').loc[lambda x: x['grade']==1].loc[lambda x: ~((x['firstname']=='otha') & (x['lastname']=='moyer'))][['firstname', 'lastname']].drop_duplicates()"
what is the last name and first name of the student who is taught by teacher otha moyer?,"list.merge(teachers, on='classroom').loc[lambda x: x['grade']==1].loc[lambda x: ~((x['firstname']=='otha') & (x['lastname']=='moyer'))][['firstname', 'lastname']].drop_duplicates()"
extract the last names that are not taught by covin jerome for the third grade.,"pd.merge(list.loc[lambda x: x['grade']==3], teachers.loc[(teachers['firstname']!='covin') & (teachers['lastname']!='jerome')], left_on='classroom', right_on='classroom')['lastname'].unique()"
give me the last names of the students who are not taught by teacher covin jerome.,"pd.merge(list.loc[lambda x: x['grade']==3], teachers.loc[(teachers['firstname']!='covin') & (teachers['lastname']!='jerome')], left_on='classroom', right_on='classroom')['lastname'].unique()"
"for each grade, report the grade, the number of classrooms in which it’s taught, and the total number of students in that grade.","list.groupby('grade').agg(num_classrooms=('classroom', 'nunique'),num_students=('grade', 'count')).reset_index()[['grade', 'num_classrooms', 'num_students']]"
"obtain the grade number, number of classrooms, and number of students in each grade.","list.groupby('grade').agg(num_classrooms=('classroom', 'nunique'),num_students=('grade', 'count')).reset_index()[['grade', 'num_classrooms', 'num_students']]"
"for each classroom, please report the classroom number and the number of grades using it.",list.groupby('classroom')['grade'].nunique()
"for each classroom, display the room number along with the number of distinct grades that use the room.",list.groupby('classroom')['grade'].nunique()
which classroom has the highest number of students?,list.groupby('classroom').size().sort_values(ascending=false).index[0]
determine the classroom that is the oldest.,list.groupby('classroom').size().sort_values(ascending=false).index[0]
provide the count of students in each class.,list.groupby('classroom').size()
"for each classroom, print the classroom number and indicate the number of students utilizing it.",list.groupby('classroom').size()
"for each grade of 0 classroom, could you please provide the total number of students?",list.loc[lambda x: x['grade'] == '0'].groupby('classroom').size()
"for every grade 0 classroom, provide the classroom number and student count.",list.loc[lambda x: x['grade'] == '0'].groupby('classroom').size()
please give me the total count of students in each fourth-grade classroom.,list.loc[lambda x: x['grade']=='4'].groupby('classroom').size()
"for each fourth-grade classroom, list the classroom number and total count of students using it.",list.loc[lambda x: x['grade']=='4'].groupby('classroom').size()
should retrieve the teacher's name who teaches the most students.,"list.merge(teachers, on='classroom').groupby(['firstname', 'lastname']).size().sort_values(ascending=false).reset_index().iloc[0, :2]"
which teacher teaches the highest number of students? give me the first name and last name of the teacher.,"list.merge(teachers, on='classroom').groupby(['firstname', 'lastname']).size().sort_values(ascending=false).reset_index().iloc[0, :2]"
how many students are present in the classroom?,list.groupby('classroom').size().reset_index(name='count')
how many students are there in one classroom?,list.groupby('classroom').size().reset_index(name='count')
how many companies are headquartered within the unites states?,(company['headquarters'] == 'usa').sum()
show the names of companies in ascending order according to the total number of sales.,company.sort_values('sales_in_billion')['name']
what is the headquarter and industry of all companies?,"company[['headquarters', 'industry']]"
what is the name of the companies in the banking and retailing domain?,"company.loc[company['industry'].isin(['banking', 'retailing']), 'name']"
what is the maximum and minimum market value of the companies?,"company['market_value_in_billion'].agg(['max', 'min'])"
provide me with the name of the company (name of the ceo) with the maximum annual revenues.,"company.sort_values('sales_in_billion', ascending=false).iloc[0]['headquarters']"
return me the names of the head office with their corresponding count of companies at each location.,company.groupby('headquarters').size()
please display the most common address for companies.,company.groupby('headquarters').size().sort_values(ascending=false).index[0]
list the headquarters that have at least two companies.,company.groupby('headquarters').filter(lambda x: len(x) >= 2)['headquarters'].unique()
obtain the headquarters in which the two companies in banking industry and the companies in oil and gas industry exist.,"pd.series(list(set(company.loc[company['industry']=='banking', 'headquarters']).intersection(set(company.loc[company['industry']=='oil and gas', 'headquarters']))))"
retrieve the names of companies and of employees.,"pd.merge(pd.merge(employment, people, on='people_id'), company, on='company_id')[['name_x', 'name_y']]"
please provide me the names of companies and the name of employees in decreasing order of the number of years they have worked for that company.,"pd.merge(pd.merge(employment, people, on='people_id'), company, on='company_id').sort_values('year_working')[['name_x', 'name_y']]"
reveal the names of employees that work for companies with sales greater than 200.,"pd.merge(pd.merge(employment, people, on='people_id'), company, on='company_id').loc[lambda x: x['sales_in_billion'] > 200, 'name']"
identify the companies and the number of workers they employ,"employment.merge(people, on='people_id').merge(company, on='company_id').groupby('name')['name'].count()"
retrieve the names of people who are not working for a company.,"people.loc[~people['people_id'].isin(employment['people_id']), 'name']"
enumerate the company names in descending order of the profits and sales.,"company.loc[lambda x: x['sales_in_billion'] > 200].sort_values(['sales_in_billion', 'profits_in_billion'], ascending=[true, false])['name']"
how many films are there?,film.shape[0]
find the number of films.,film.shape[0]
enumerate the directors of all movies.,film['director'].unique()
what are the different film directors?,film['director'].unique()
what is the total gross of average ticket sales for films?,film['gross_in_dollar'].mean()
provide the total gross sales in dollars across each film.,film['gross_in_dollar'].mean()
what are the high and low estimates of film markets?,"film_market_estimation[['low_estimate', 'high_estimate']]"
please provide me with the low and high estimates for all markets.,"film_market_estimation[['low_estimate', 'high_estimate']]"
"(for those unfamiliar with machine learning, the ""year 1995"" is a placeholder and the ""type"" of film market estimation is the output.)","film_market_estimation.loc[film_market_estimation['year'] == 1995, 'type']"
obtain the varieties of film market estimations in 1995.,"film_market_estimation.loc[film_market_estimation['year'] == 1995, 'type']"
i would like to obtain the maximum and minimum numbers of cities in each of the market groups.,"market['number_cities'].agg(['max', 'min'])"
please return me the maximum and minimum number of cities across all markets.,"market['number_cities'].agg(['max', 'min'])"
for how many markets do the cities number less than 300?,(market['number_cities'] < 300).sum()
what is the count of markets that have lower than 300 cities?,(market['number_cities'] < 300).sum()
provide me the names of countries that are for markets in ascending order.,market.sort_values('country')['country']
"please furnish me the list of countries for each market, arranged in alphabetical order.",market.sort_values('country')['country']
list all countries in descending order of the number of cities each has.,"market.sort_values('number_cities', ascending=false)['country']"
sort countries for each market in descending order based on the number of cities present.,"market.sort_values('number_cities', ascending=false)['country']"
please display the titles of films as well as the types of their market.,"pd.merge(film, film_market_estimation, on='film_id')[['title', 'type']]"
determine the titles of films along with their corresponding types of market estimations.,"pd.merge(film, film_market_estimation, on='film_id')[['title', 'type']]"
"provide the titles, year, and estimated market valuations of movies that went to public auction in the year of 1995.","pd.merge(film, film_market_estimation, on='film_id').loc[lambda x: x['year']==1995, 'director'].unique()"
provide me with the titles of various directors of movies that were produced in 1995 along with their corresponding market estimation.,"pd.merge(film, film_market_estimation, on='film_id').loc[lambda x: x['year']==1995, 'director'].unique()"
what is the average number of cities of markets which are big for more than 10000?,"pd.merge(film_market_estimation.loc[lambda x: x['low_estimate'] > 10000], market, on='market_id')['number_cities'].mean()"
what is the average number of cities within markets that possessed a low market estimation greater than 10000?,"pd.merge(film_market_estimation.loc[lambda x: x['low_estimate'] > 10000], market, on='market_id')['number_cities'].mean()"
please list the countries and years for which film market estimations have been provided.,"pd.merge(film_market_estimation, market, on='market_id')[['country', 'year']]"
what are the countries of markets and the years for which market estimation was conducted?,"pd.merge(film_market_estimation, market, on='market_id')[['country', 'year']]"
"please give me the films market estimation years when the market was in japan, in descending manner.","film_market_estimation.merge(market, on='market_id').query('country == ""japan""').sort_values('year', ascending=false)['year']"
"list the years of the japanese film market estimation, ordered by year descending.","film_market_estimation.merge(market, on='market_id').query('country == ""japan""').sort_values('year', ascending=false)['year']"
provide the studios (production companies) of each film and the number films produced by that company.,film.groupby('studio').size().reset_index(name='count')
what are the production methods of films by each studio?,film.groupby('studio').size().reset_index(name='count')
provide the names of the film studios that have the most number of films.,film.groupby('studio').size().sort_values(ascending=false).index[0]
what is the name of the studio that produced the most movies?,film.groupby('studio').size().sort_values(ascending=false).index[0]
return the names of studios that have more than one movie.,film.groupby('studio').filter(lambda x: len(x) >= 2)['studio'].unique()
retrieve the titles of studios that have produced more than two films.,film.groupby('studio').filter(lambda x: len(x) >= 2)['studio'].unique()
determine the titles of any films that do not have market estimations.,"film.loc[~film['film_id'].isin(film_market_estimation['film_id']), 'title']"
give me the list of movie titles that do not have a film market estimation.,"film.loc[~film['film_id'].isin(film_market_estimation['film_id']), 'title']"
provide the production company names for movies directed by nicholas meyer and walter hill.,"set(film.loc[film['director']=='nicholas meyer', 'studio']).intersection(set(film.loc[film['director']=='walter hill', 'studio']))"
which studios produced films with nicholas meyer and walter hill?,"set(film.loc[film['director']=='nicholas meyer', 'studio']).intersection(set(film.loc[film['director']=='walter hill', 'studio']))"
"retrieve the names of the films and studios that are owned by some studios that consist the word ""universal"".","film.loc[film['studio'].str.contains('universal'), ['title', 'studio']]"
"return the title of a movie produced by a studio whose name contains ""universal"".","film.loc[film['studio'].str.contains('universal'), ['title', 'studio']]"
show the studios that have not worked with director walter hill.,"film.loc[lambda x: x['director'] != 'walter hill', 'studio'].drop_duplicates()"
which studios have never collaborated with the director walter hill?,"film.loc[lambda x: x['director'] != 'walter hill', 'studio'].drop_duplicates()"
"list all studios whose average gross is greater than £4,500,000.",film.groupby('studio').filter(lambda x: x['gross_in_dollar'].mean() >= 4500000)['studio'].unique()
which studios have an average gross over 4500000?,film.groupby('studio').filter(lambda x: x['gross_in_dollar'].mean() >= 4500000)['studio'].unique()
what is the title of the film that has the highest market value?,"film.merge(film_market_estimation, on='film_id').sort_values('high_estimate', ascending=false).iloc[0]['title']"
please provide me with the name of the film with the highest estimated revenue.,"film.merge(film_market_estimation, on='film_id').sort_values('high_estimate', ascending=false).iloc[0]['title']"
which films and directors were never screened in china?,"film.loc[~film['film_id'].isin(film_market_estimation.merge(market.loc[lambda x: x['country']=='china'], left_on='market_id', right_on='market_id', how='inner')['film_id_x']), ['title', 'director']]"
retrieve the names of the directors and titles of films that were not released in china.,"film.loc[~film['film_id'].isin(film_market_estimation.merge(market.loc[lambda x: x['country']=='china'], left_on='market_id', right_on='market_id', how='inner')['film_id_x']), ['title', 'director']]"
what is the count of calendar items?,ref_calendar.shape[0]
return the total number of all calendar items.,ref_calendar.shape[0]
list the calendar dates along with their corresponding day numbers.,"ref_calendar[['calendar_date', 'day_number']]"
what is the number of calendar dates and day numbers?,"ref_calendar[['calendar_date', 'day_number']]"
how many types of documents are there?,ref_document_types.shape[0]
list the titles of document type codes and document type names.,"ref_document_types[['document_type_code', 'document_type_name']]"
retrieve all the document type codes and document type names.,"ref_document_types[['document_type_code', 'document_type_name']]"
what is the title and description of document type code rv?,"ref_document_types.loc[lambda x: x['document_type_code']=='rv', ['document_type_name', 'document_type_description']]"
fetch the name and description of the document type code rv.,"ref_document_types.loc[lambda x: x['document_type_code']=='rv', ['document_type_name', 'document_type_description']]"
what is the document type code for paper?,"ref_document_types.loc[lambda x: x['document_type_name']=='paper', 'document_type_code']"
please provide me with the code of the document type 'paper'.,"ref_document_types.loc[lambda x: x['document_type_name']=='paper', 'document_type_code']"
provide me with the count represented by document type codes cv or bk.,"all_documents.loc[lambda x: (x['document_type_code']=='cv') | (x['document_type_code']=='bk'), :].shape[0]"
how many documents are of the types cv and bk?,"all_documents.loc[lambda x: (x['document_type_code']=='cv') | (x['document_type_code']=='bk'), :].shape[0]"
"when was the document ""marry cv"" stored?","all_documents.loc[lambda x: x['document_name']=='marry cv', 'date_stored']"
"please provide me with the date when document ""marry cv"" was saved.","all_documents.loc[lambda x: x['document_name']=='marry cv', 'date_stored']"
what is the day number and date of every document?,"pd.merge(all_documents, ref_calendar, left_on='date_stored', right_on='calendar_date')[['day_number', 'date_stored']]"
retrieve the day number and a time stamp for all the data.,"pd.merge(all_documents, ref_calendar, left_on='date_stored', right_on='calendar_date')[['day_number', 'date_stored']]"
"what is the document type name for document with name ""how to read a book""?","pd.merge(all_documents, ref_document_types, on='document_type_code').loc[lambda x: x['document_name']=='how to read a book', 'document_type_name']"
"retrieve the document type of the document named by ""how to read a book"".","pd.merge(all_documents, ref_document_types, on='document_type_code').loc[lambda x: x['document_name']=='how to read a book', 'document_type_name']"
state the number of locations.,ref_locations.shape[0]
determine the count of locations listed in the database.,ref_locations.shape[0]
provide a list of all location and location name codes.,"ref_locations[['location_code', 'location_name']]"
what types of locations and location names are present?,"ref_locations[['location_code', 'location_name']]"
"return the name and description for location code ""x"".","ref_locations.loc[lambda x: x['location_code']=='x', ['location_name', 'location_description']]"
please provide me with the name and description of locations with code x.,"ref_locations.loc[lambda x: x['location_code']=='x', ['location_name', 'location_description']]"
what are the codes of the countries of the united states?,"ref_locations.loc[lambda x: x['location_name']=='canada', 'location_code']"
display the code of the country canada.,"ref_locations.loc[lambda x: x['location_name']=='canada', 'location_code']"
what is the count of total roles identified?,roles.shape[0]
"please list all roles, names of roles, and descriptions of roles.","roles[['role_code', 'role_name', 'role_description']]"
"what are all the role codes, names, and descriptions?","roles[['role_code', 'role_name', 'role_description']]"
what is the title and description of role code mg?,"roles.loc[lambda x: x['role_code']=='mg', ['role_name', 'role_description']]"
determine the name of the role with code mg.,"roles.loc[lambda x: x['role_code']=='mg', ['role_name', 'role_description']]"
"provide me the description for the role of ""proof reader"".","roles.loc[lambda x: x['role_name']=='proof reader', 'role_description']"
"what is the description of a role of a title name of ""proof reader""?","roles.loc[lambda x: x['role_name']=='proof reader', 'role_description']"
get the information of the number of employees we have.,employees.shape[0]
"look up the job title, role code, and date of birth for the employee with the last name armani.","employees.loc[lambda x: x['employee_name']=='armani', ['employee_name', 'role_code', 'date_of_birth']]"
"list the name, role code, and birth date of the employee named 'armani'","employees.loc[lambda x: x['employee_name']=='armani', ['employee_name', 'role_code', 'date_of_birth']]"
what's the id for the employee called ebba?,"employees.loc[lambda x: x['employee_name']=='ebba', 'employee_id']"
what is the employee id named ebba?,"employees.loc[lambda x: x['employee_name']=='ebba', 'employee_id']"
"retrieve the names of employees with the role code ""hr"".","employees.loc[lambda x: x['role_code']=='hr', 'employee_name']"
"what titles were possessed by each role, and what was their count of employees?",employees.groupby('role_code').size()
"please list the code for each role, along with the number of employees in each role.",employees.groupby('role_code').size()
which role code has the largest number of employees?,employees.groupby('role_code').size().sort_values(ascending=false).index[0]
determine the role played by the most employees.,employees.groupby('role_code').size().sort_values(ascending=false).index[0]
retrieve the titles of roles having more than 3 employees.,employees.groupby('role_code').filter(lambda x: len(x) >= 3)['role_code'].unique()
find the titles that are held by three or more individuals.,employees.groupby('role_code').filter(lambda x: len(x) >= 3)['role_code'].unique()
find the roles that are employed the least.,employees.groupby('role_code').size().sort_values().index[0]
what are the titles of roles with the lowest count of employees?,employees.groupby('role_code').size().sort_values().index[0]
what name and description is for the role ebba?,"pd.merge(employees, roles, on='role_code').loc[lambda x: x['employee_name']=='ebba', ['role_name', 'role_description']]"
provide me with the id and name of the role played my one of the employees named ebba.,"pd.merge(employees, roles, on='role_code').loc[lambda x: x['employee_name']=='ebba', ['role_name', 'role_description']]"
provide me the names of the employees with role editor.,"pd.merge(employees, roles, on='role_code').loc[lambda x: x['role_name']=='editor', 'employee_name']"
"obtain all the titles of employees whose job role name is ""editor"".","pd.merge(employees, roles, on='role_code').loc[lambda x: x['role_name']=='editor', 'employee_name']"
"please give me a list of employees whose job title is ""human resource"" or ""manager"".","pd.merge(employees, roles, on='role_code').loc[lambda x: x['role_name'].isin(['human resource', 'manager']), 'employee_id']"
what is the list of distinct location codes for documents?,document_locations['location_code'].unique()
"return the location name corresponding to the document ""robin cv"".","pd.merge(pd.merge(all_documents.loc[lambda x: x['document_name']=='robin cv'], document_locations, on='document_id'), ref_locations, on='location_code')['location_name']"
"what is the name of the location in which the document ""robin cv"" was located?","pd.merge(pd.merge(all_documents.loc[lambda x: x['document_name']=='robin cv'], document_locations, on='document_id'), ref_locations, on='location_code')['location_name']"
"return me location ids, starting and ending dates, and data for all documents.","document_locations[['location_code', 'date_in_location_from', 'date_in_locaton_to']]"
"what is the title of the document, and the beginning and ending dates and time of its usage?","document_locations[['location_code', 'date_in_location_from', 'date_in_locaton_to']]"
kindly provide me with starting and ending date of robin's employment.,"pd.merge(document_locations, all_documents.loc[lambda x: x['document_name']=='robin cv'], on='document_id', how='inner')[['date_in_location_from','date_in_location_to']]"
give me the location codes and the number of documents in each location.,document_locations.groupby('location_code').size().reset_index(name='count')
what is the id and code of each location and the number of documents in that location?,document_locations.groupby('location_code').size().reset_index(name='count')
which location code have the most documents?,document_locations.groupby('location_code').size().sort_values(ascending=false).index[0]
identify the locations with the highest number of documents.,document_locations.groupby('location_code').size().sort_values(ascending=false).index[0]
"provide me with the location codes having at least three documents, respectively.",document_locations.groupby('location_code').filter(lambda x: len(x) >= 3)['location_code'].unique()
what is the count of locations having at least three documents?,document_locations.groupby('location_code').filter(lambda x: len(x) >= 3)['location_code'].unique()
what is the name and code of the location with the least number of documents?,"pd.merge(document_locations, ref_locations, on='location_code').groupby('location_code').size().sort_values().reset_index(name='count').iloc[0][['location_name', 'location_code']]"
what is the name and code of the location with the smallest number of documents?,"pd.merge(document_locations, ref_locations, on='location_code').groupby('location_code').size().sort_values().reset_index(name='count').iloc[0][['location_name', 'location_code']]"
what are the names of those who approved the destruction and the names of those who destroyed the documents related to the destruction?,"pd.merge(pd.merge(documents_to_be_destroyed, employees, left_on='destruction_authorised_by_employee_id', right_on='employee_id')[['employee_name', 'document_id']], employees, left_on='destroyed_by_employee_id', right_on='employee_id')[['employee_name_x', 'employee_name_y']]"
display the names of the employees who authorized the destruction of documents and the names of employees who destroyed the corresponding documents.,"pd.merge(pd.merge(documents_to_be_destroyed, employees, left_on='destruction_authorised_by_employee_id', right_on='employee_id')[['employee_name', 'document_id']], employees, left_on='destroyed_by_employee_id', right_on='employee_id')[['employee_name_x', 'employee_name_y']]"
display the ids of each employee and the count of documents destroyed authorized by that employee.,documents_to_be_destroyed.groupby('destruction_authorised_by_employee_id').size().reset_index(name='count')
please give me the list of employee ids and the number of documents that each is authorized to destroy.,documents_to_be_destroyed.groupby('destruction_authorised_by_employee_id').size().reset_index(name='count')
i would ask you to provide me with the id and number of documents that were destroyed by each of your employees.,documents_to_be_destroyed['destroyed_by_employee_id'].value_counts()
obtain the identifier and document count for each employee who was responsible for the destruction of documents.,documents_to_be_destroyed['destroyed_by_employee_id'].value_counts()
provide me with the names of employees who haven't authorized the deletion of any document.,"pd.concat([employees['employee_id'], documents_to_be_destroyed['destruction_authorised_by_employee_id']]).drop_duplicates(keep=false)"
list down the names of employees who don't have the authority to destroy any document.,"pd.concat([employees['employee_id'], documents_to_be_destroyed['destruction_authorised_by_employee_id']]).drop_duplicates(keep=false)"
provide me with the id of all employees who authorize destruction.,documents_to_be_destroyed['destruction_authorised_by_employee_id'].unique()
how may all persons authorize document destruction?,documents_to_be_destroyed['destruction_authorised_by_employee_id'].unique()
provide me with the integer ids of all the employees that have destroyed the documents.,documents_to_be_destroyed['destroyed_by_employee_id'].unique()
whom should we approach for the list of employees who have destroyed documents?,documents_to_be_destroyed['destroyed_by_employee_id'].unique()
please provide me with the ids of all employees who did not destroy any documents.,employees[~employees['employee_id'].isin(documents_to_be_destroyed['destroyed_by_employee_id'])]['employee_id']
please find me the names of employees who did not destroy any document along with their id.,employees[~employees['employee_id'].isin(documents_to_be_destroyed['destroyed_by_employee_id'])]['employee_id']
provide the id of any employee who had either destroyed a document or authorized someone else to do so.,"pd.concat([documents_to_be_destroyed['destroyed_by_employee_id'], documents_to_be_destroyed['destruction_authorised_by_employee_id']]).reset_index(drop=true)"
which employees have trashed a document or granted authorizations to do so? please supply their employee ids.,"pd.concat([documents_to_be_destroyed['destroyed_by_employee_id'], documents_to_be_destroyed['destruction_authorised_by_employee_id']]).reset_index(drop=true)"
how many clubs exist?,club.shape[0] or len(club)
determine the names for all clubs.,club['clubname']
retrieve the names of each club.,club['clubname']
please count the number of students.,student.shape[0]
determine the total number of students enrolled.,student.shape[0]
return the first names of all students.,student['fname'].unique()
retrieve the first names of all students.,student['fname'].unique()
"retrieve the names of members by their last name of the club ""bootup baltimore"".","club.merge(member_of_club, on='clubid').merge(student, on='stuid').loc[lambda x: x['clubname']=='bootup baltimore', 'lname']"
"return the last name, first name and email address of each member of the club named ""bootup baltimore"".","club.merge(member_of_club, on='clubid').merge(student, on='stuid').loc[lambda x: x['clubname']=='bootup baltimore', 'lname']"
"display the names of the members of the club named ""hopkins student enterprises"".","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['clubname']=='hopkins student enterprises', 'lname']"
"fetch the last names of the members of the club ""hopkins student enterprises"".","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['clubname']=='hopkins student enterprises', 'lname']"
"what is the count of club members belonging to the club ""tennis club""?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['clubname']=='tennis club'].shape[0]"
"please determine the number of club members of the ""tennis club"".","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['clubname']=='tennis club'].shape[0]"
"determine the count of members of club ""pen and paper gaming"".","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['clubname']=='pen and paper gaming'].shape[0]"
"what is the number of people who have membership in the club ""pen and paper gaming""?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['clubname']=='pen and paper gaming'].shape[0]"
how many clubs does linda smith belong to?,"pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: (x['fname']=='linda') & (x['lname']=='smith')].shape[0]"
please provide me with the count of clubs that linda smith is a member of.,"pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: (x['fname']=='linda') & (x['lname']=='smith')].shape[0]"
"enumerate the count of clubs where ""tracy kim"" is an individual.","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: (x['fname']=='tracy') & (x['lname']=='kim')].shape[0]"
"give me the names of all female members of club ""bootup baltimore"".","pd.merge(pd.merge(club[club['clubname']=='bootup baltimore'], member_of_club, on='clubid'), student[student['sex']=='f'], left_on='stuid', right_on='stuid')[['fname', 'lname']]"
"please provide me with the first names and surnames of all the female members of the club ""bootup baltimore"".a:use regular expressions; see below.","pd.merge(pd.merge(club[club['clubname']=='bootup baltimore'], member_of_club, on='clubid'), student[student['sex']=='f'], left_on='stuid', right_on='stuid')[['fname', 'lname']]"
"obtain the titles of the male members of the club ""hopkins student enterprises"" along with their first name and last name.","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[(lambda x: (x['clubname']=='hopkins student enterprises') & (x['sex']=='m')) , ['fname', 'lname']]"
retrieve the first and last name of each male member of the club hopkins student enterprises.,"pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[(lambda x: (x['clubname']=='hopkins student enterprises') & (x['sex']=='m')) , ['fname', 'lname']]"
"please provide me with a list of all members of ""bootup baltimore"" whose major is ""600"".","pd.merge(pd.merge(club[club['clubname']=='bootup baltimore'], member_of_club, on='clubid'), student[student['major']=='600'], left_on='stuid', right_on='stuid')[['fname', 'lname']]"
"give me the names of the members majoring in ""600"" from ""bootup baltimore"".","pd.merge(pd.merge(club[club['clubname']=='bootup baltimore'], member_of_club, on='clubid'), student[student['major']=='600'], left_on='stuid', right_on='stuid')[['fname', 'lname']]"
"how many members of the club that are majoring in ""600""?","club.merge(member_of_club, on='clubid').merge(student.loc[lambda x: x['major']=='600'], left_on='stuid', right_on='stuid')['clubname'].value_counts().index[0]"
"retrieve the club which has the greatest number of members majoring in ""600"".","club.merge(member_of_club, on='clubid').merge(student.loc[lambda x: x['major']=='600'], left_on='stuid', right_on='stuid')['clubname'].value_counts().index[0]"
retrieve the title of the club that has the most female members.,"pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: x['sex']=='f'].groupby('clubname').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['clubname']"
what is the name of clubs with the most female students as their members?,"pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: x['sex']=='f'].groupby('clubname').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['clubname']"
"retrieve the description of the club called ""tennis club"".","club.loc[lambda x: x['clubname']=='tennis club', 'clubdesc']"
"what is the wording of the club ""pen and paper gaming""?","club.loc[lambda x: x['clubname']=='pen and paper gaming', 'clubdesc']"
"where lies the tennis club named ""tennis club""?","club.loc[lambda x: x['clubname']=='tennis club', 'clublocation']"
"which club is named ""tennis club""?","club.loc[lambda x: x['clubname']=='tennis club', 'clublocation']"
"please address me with the location of the club ""pen and paper gaming"".","club.loc[lambda x: x['clubname']==""pen and paper gaming"", 'clublocation']"
"provide the details of the address of the club ""pen and paper gaming"".","club.loc[lambda x: x['clubname']==""pen and paper gaming"", 'clublocation']"
please indicate where the hopkins student enterprises club is located.,"club.loc[club['clubname'] == 'hopkins student enterprises', 'clublocation']"
"please give me the address for the club ""hopkins student enterprises"".","club.loc[club['clubname'] == 'hopkins student enterprises', 'clublocation']"
"retrieve the names of all the clubs belonging to ""akw"".","club.loc[lambda x: x['clublocation']=='akw', 'clubname']"
"return the names of clubs located at ""akw"".","club.loc[lambda x: x['clublocation']=='akw', 'clubname']"
"please inform me of the total count of clubs located at ""hhh"".",(club['clublocation'] == 'hhh').sum()
"determine the number of clubs that are located ""hhh"".",(club['clublocation'] == 'hhh').sum()
"retrieve the first and last name of the president of the club ""bootup baltimore"".","student.loc[lambda x: x['stuid'].isin(member_of_club.loc[lambda y: (y['position']=='president') & (y['clubid'].isin(club.loc[lambda z: z['clubname']=='bootup baltimore', 'clubid'])),'stuid']),['fname','lname']]"
"what is the full name of the president for ""bootup baltimore""?","student.loc[lambda x: x['stuid'].isin(member_of_club.loc[lambda y: (y['position']=='president') & (y['clubid'].isin(club.loc[lambda z: z['clubname']=='bootup baltimore', 'clubid'])),'stuid']),['fname','lname']]"
"display the first and the last name of ""cto"" of club ""hopkins student enterprises"".","student.merge(member_of_club.merge(club.loc[lambda x: x['clubname']=='hopkins student enterprises'], on='clubid').loc[lambda x: x['position']=='cto'], on='stuid')[['fname', 'lname']]"
"retrieve the first and last name for the ""chief technical officer"" of ""hopkins student enterprises""","student.merge(member_of_club.merge(club.loc[lambda x: x['clubname']=='hopkins student enterprises'], on='clubid').loc[lambda x: x['position']=='cto'], on='stuid')[['fname', 'lname']]"
"what number of new roles exist in the club ""bootup baltimore""?","pd.merge(club[club['clubname']=='bootup baltimore'], member_of_club, on='clubid')['position'].nunique()"
"what is the count of different team positions in ""bootup baltimore"" club?","pd.merge(club[club['clubname']=='bootup baltimore'], member_of_club, on='clubid')['position'].nunique()"
"what is the count of members in the group ""bootup baltimore"" who are older than 18?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: (x['clubname']=='bootup baltimore') & (x['age']>18)].shape[0]"
"what is the count of members in club ""bootup baltimore"" who are above the age of 18?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: (x['clubname']=='bootup baltimore') & (x['age']>18)].shape[0]"
"how many members are part of the club ""bootup baltimore"" whose age is under 18?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[(lambda x: x['clubname'] == 'bootup baltimore') & (lambda x: x['age'] < 18), :].shape[0]"
give me the names of all clubs whose members are members who reside and are originally from the city of bali.,"pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['city_code']=='bal', 'clubname'].unique()"
"list the names of clubs whose members are either from the city of ""bal"", or in the city ""bal"", or both.","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['city_code']=='bal', 'clubname'].unique()"
"select the names of the clubs that have at least one member belonging to the city with city code ""hou"".","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['city_code']=='hou', 'clubname'].unique()"
"retrieve the names of clubs with at least one member from the city with code ""hou"".","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['city_code']=='hou', 'clubname'].unique()"
what is the total count of clubs that eric tai belongs to?,"pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: (x['fname']=='eric') & (x['lname']=='tai'), 'clubname'].nunique()"
what is the number of clubs in which eric tai is a member?,"pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: (x['fname']=='eric') & (x['lname']=='tai'), 'clubname'].nunique()"
"fetch the clubs having ""davis steven"" as a member.","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: (x['fname']=='davis') & (x['lname']=='steven'), 'clubname'].unique()"
retrieve the names of clubs in which davis steven is enrolled as a member.,"pd.merge(pd.merge(club, member_of_club, on='clubid'), student, left_on='stuid', right_on='stuid').loc[lambda x: (x['fname']=='davis') & (x['lname']=='steven'), 'clubname'].unique()"
list the names of clubs that have at least one member who has an advisor equal to 1121.,"pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['advisor']==1121, 'clubname'].unique()"
"find the names of clubs which have one or more members whose advisor is ""1121"".","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['advisor']==1121, 'clubname'].unique()"
"determine the average age of club members ""bootup baltimore"".","student.loc[lambda x: x['stuid'].isin(member_of_club.loc[lambda x: x['clubid'].isin(club.loc[lambda x: x['clubname']=='bootup baltimore']['clubid']), 'stuid'])]['age'].mean()"
"determine the average age of the members of the club ""bootup baltimore"".","student.loc[lambda x: x['stuid'].isin(member_of_club.loc[lambda x: x['clubid'].isin(club.loc[lambda x: x['clubname']=='bootup baltimore']['clubid']), 'stuid'])]['age'].mean()"
"provide the count of average ages of the members of the club ""hopkins student enterprises"".","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['clubname']=='hopkins student enterprises', 'age'].mean()"
"how old is the club ""hopkins student enterprises"" on average, in terms of its members?","pd.merge(pd.merge(club, member_of_club, on='clubid'), student, on='stuid').loc[lambda x: x['clubname']=='hopkins student enterprises', 'age'].mean()"
"determine the average value of age of members of the club ""tennis club"".","student.merge(member_of_club.merge(club.query('clubname == ""tennis club""'), on='clubid'), on='stuid')['age'].mean()"
"find the average age of the members of the club ""tennis club"".","student.merge(member_of_club.merge(club.query('clubname == ""tennis club""'), on='clubid'), on='stuid')['age'].mean()"
"for grants that ended after '1989-03-16 18:27:16' and where documents were sent before '1986-08-26 20:49:27', retrieve the list of distinct grant amounts.","pd.merge(grants.loc[grants['grant_end_date'] > '1989-03-16 18:27:16', ['grant_id', 'grant_amount']], documents.loc[documents['sent_date'] < '1986-08-26 20:49:27', ['grant_id']], on='grant_id')['grant_amount'].unique()"
what were the grant amounts for different documents sent before 1986-08-26 20:49:27 and after the grant ended on 1989-03-16 18:27:16?,"pd.merge(grants.loc[grants['grant_end_date'] > '1989-03-16 18:27:16', ['grant_id', 'grant_amount']], documents.loc[documents['sent_date'] < '1986-08-26 20:49:27', ['grant_id']], on='grant_id')['grant_amount'].unique()"
return me the project details including publication and patent for each project.,"pd.merge(projects[projects['project_id'].isin(project_outcomes[project_outcomes['outcome_code']=='paper']['project_id'])], projects[projects['project_id'].isin(project_outcomes[project_outcomes['outcome_code']=='patent']['project_id'])])['project_details'].tolist()"
provide me the data set of all projects that produced both patents and papers as outcomes.,"pd.merge(projects[projects['project_id'].isin(project_outcomes[project_outcomes['outcome_code']=='paper']['project_id'])], projects[projects['project_id'].isin(project_outcomes[project_outcomes['outcome_code']=='patent']['project_id'])])['project_details'].tolist()"
what is the sum of grants awarded to organizations described as research?,"pd.merge(pd.merge(grants, organisations, on='organisation_id'), organisation_types, on='organisation_type').loc[lambda x: x['organisation_type_description']=='research', 'grant_amount'].sum()"
what is the total sum of money that is allocated for research?,"pd.merge(pd.merge(grants, organisations, on='organisation_id'), organisation_types, on='organisation_type').loc[lambda x: x['organisation_type_description']=='research', 'grant_amount'].sum()"
provide the names of the staffs and the dates along which they work: the staffs hired for the project that hires the most staffs.,"project_staff.loc[lambda df: df['project_id'].isin(project_staff.groupby('project_id').size().sort_values().tail(1).index), ['date_from', 'date_to']].append(project_staff.loc[lambda df: df['role_code']=='leader', ['date_from', 'date_to']])"
from when and until when do the staff work on a project that has the greatest number of employees and which employs them in a leader role?,"project_staff.loc[lambda df: df['project_id'].isin(project_staff.groupby('project_id').size().sort_values().tail(1).index), ['date_from', 'date_to']].append(project_staff.loc[lambda df: df['role_code']=='leader', ['date_from', 'date_to']])"
find out the titles of organisations and their information which are associated with,"grants.merge(organisations, on='organisation_id').groupby(['organisation_id', 'organisation_details']).filter(lambda x: x['grant_amount'].sum() > 6000)[['organisation_id', 'organisation_details']].drop_duplicates()"
which agencies and the complete details of all organizations having grants in excess of $6000?,"grants.merge(organisations, on='organisation_id').groupby(['organisation_id', 'organisation_details']).filter(lambda x: x['grant_amount'].sum() > 6000)[['organisation_id', 'organisation_details']].drop_duplicates()"
what is the organisation type and id of organizations that have the most number of research staff?,"pd.merge(organisations, research_staff, left_on='organisation_id', right_on='employer_organisation_id').groupby(['organisation_type', 'organisation_id']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['organisation_type', 'organisation_id']]"
for which organization has the maximum research staff?,"pd.merge(organisations, research_staff, left_on='organisation_id', right_on='employer_organisation_id').groupby(['organisation_type', 'organisation_id']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['organisation_type', 'organisation_id']]"
which type of organisation hires the most research staff?,"pd.merge(organisations, research_staff, left_on='organisation_id', right_on='employer_organisation_id').groupby('organisation_type').size().idxmax()"
what is the count of organization types that contain the most researchers?,"pd.merge(organisations, research_staff, left_on='organisation_id', right_on='employer_organisation_id').groupby('organisation_type').size().idxmax()"
retrieve the documents with the grant amount of more than 5000 that were granted by organization type described.,"pd.merge(pd.merge(pd.merge(documents, grants, on='grant_id'), organisations, on='organisation_id'), organisation_types, on='organisation_type').loc[lambda x: (x['grant_amount'] > 5000) & (x['organisation_type_description'] == 'research'), 'sent_date']"
what were send dates for all grant documents with a grant amount of greater than 5000 and dedicated to research?,"pd.merge(pd.merge(pd.merge(documents, grants, on='grant_id'), organisations, on='organisation_id'), organisation_types, on='organisation_type').loc[lambda x: (x['grant_amount'] > 5000) & (x['organisation_type_description'] == 'research'), 'sent_date']"
what are the received dates of responses for documents described as 'regular' or issued with more than 100?,"pd.merge(pd.merge(documents, document_types, on='document_type_code'), grants, on='grant_id').loc[lambda x: (x['document_description']=='regular') | (x['grant_amount']>100), 'response_received_date']"
provide me the details of projects without a researcher role that hired no staff members.,"projects.loc[~projects['project_id'].isin(project_staff.loc[project_staff['role_code']=='researcher', 'project_id']), 'project_details']"
supply me with the details of projects that did not utilize any staff in a research role.,"projects.loc[~projects['project_id'].isin(project_staff.loc[project_staff['role_code']=='researcher', 'project_id']), 'project_details']"
return the total number of projects which describe themselves as 'omni' or have more than one outcome.,"pd.concat([pd.merge(tasks, projects, on='project_id').query(""project_details=='omnis'""), pd.merge(pd.merge(tasks, projects, on='project_id'), project_outcomes, on='project_id').groupby('project_id').filter(lambda x: len(x) > 2)], sort=false) [['task_details', 'task_id', 'project_id']].drop_duplicates()"
"when do all researcher staff start to work, and when do they stop working?","project_staff.loc[lambda x: x['role_code']=='researcher', ['date_from', 'date_to']]"
which year saw the maximum number of researchers starting and stopping their work?,"project_staff.loc[lambda x: x['role_code']=='researcher', ['date_from', 'date_to']]"
how many roles do staff have?,project_staff['role_code'].nunique()
what is the count of the different roles on the project staff?,project_staff['role_code'].nunique()
provide me with the count of grants given by each organization along with the id of each organization.,grants.groupby('organisation_id')['grant_amount'].sum()
what is the sum of the total financial grant given to each organization and what is the id of each organization?,grants.groupby('organisation_id')['grant_amount'].sum()
list all the titles of the projects that have the research outcome described with the substring 'published'.,"pd.merge(pd.merge(projects, project_outcomes, on='project_id'), research_outcomes, on='outcome_code').loc[lambda x: x['outcome_description'].str.contains('published'), 'project_details']"
obtain details of any research whose paper has been published in a specific project.,"pd.merge(pd.merge(projects, project_outcomes, on='project_id'), research_outcomes, on='outcome_code').loc[lambda x: x['outcome_description'].str.contains('published'), 'project_details']"
provide me with the count of staff for each project along with their respective ids in an ascending manner.,"pd.merge(project_staff, projects, on='project_id').groupby('project_id').size().sort_values().reset_index(name='count')"
retrieve the complete description of profession.,"staff_roles.loc[lambda x: x['role_code']=='researcher', 'role_description']"
describe in full a researcher's job.,"staff_roles.loc[lambda x: x['role_code']=='researcher', 'role_description']"
since when was the first project team set up?,project_staff.sort_values('date_from').iloc[0]['date_from']
when did the first employee begin to work?,project_staff.sort_values('date_from').iloc[0]['date_from']
list the project identifier and project that created the greatest number of outcomes.,"pd.merge(projects, project_outcomes, on='project_id').groupby('project_id').size().idxmax()"
what are the details of the project with the most outcomes and its corresponding id?,"pd.merge(projects, project_outcomes, on='project_id').groupby('project_id').size().idxmax()"
what project has no outcome? list the project details.,"projects.loc[~projects['project_id'].isin(project_outcomes['project_id']), 'project_details']"
which project details are accounted for by no outcomes?,"projects.loc[~projects['project_id'].isin(project_outcomes['project_id']), 'project_details']"
which organisation hired the most number of research staff? provide the id and type of organisation.,"pd.merge(organisations, research_staff, left_on='organisation_id', right_on='employer_organisation_id').groupby(['organisation_id', 'organisation_type', 'organisation_details']).size().sort_values(ascending=false).reset_index().iloc[0]"
"what is the id, type, and name of the organization with the most research staff?","pd.merge(organisations, research_staff, left_on='organisation_id', right_on='employer_organisation_id').groupby(['organisation_id', 'organisation_type', 'organisation_details']).size().sort_values(ascending=false).reset_index().iloc[0]"
show me the role description of those staff members who are associated with the highest number of project outcomes.,"pd.merge(pd.merge(staff_roles, project_staff, on='role_code'), project_outcomes, on='project_id').groupby('staff_id').size().sort_values(ascending=false).reset_index(name='count').iloc[0][['role_description', 'staff_id']]"
"for each staff member id, please provide me with the description of the role that is involved with the highest number of projects.","pd.merge(pd.merge(staff_roles, project_staff, on='role_code'), project_outcomes, on='project_id').groupby('staff_id').size().sort_values(ascending=false).reset_index(name='count').iloc[0][['role_description', 'staff_id']]"
which document type has the prefix 'initial'?,"document_types.loc[lambda x: x['document_description'].str.startswith('initial'), 'document_type_code']"
"what is the type description of the documents whose description starts with the word ""initials""?","document_types.loc[lambda x: x['document_description'].str.startswith('initial'), 'document_type_code']"
"for grants with both documents described as 'regular' and documents described as 'initial application', list the date of its start date.","pd.merge(pd.merge(grants, documents, on='grant_id'), document_types, on='document_type_code').loc[lambda x: x['document_description']=='regular', 'grant_start_date'].unique() & pd.merge(pd.merge(grants, documents, on='grant_id'), document_types, on='document_type_code').loc[lambda x: x['document_description']=='initial application', 'grant_start_date'].unique()"
provide me with the start year of each grant that has a description of regular and initial applications.,"pd.merge(pd.merge(grants, documents, on='grant_id'), document_types, on='document_type_code').loc[lambda x: x['document_description']=='regular', 'grant_start_date'].unique() & pd.merge(pd.merge(grants, documents, on='grant_id'), document_types, on='document_type_code').loc[lambda x: x['document_description']=='initial application', 'grant_start_date'].unique()"
determine the total number of grants that a single user can possess.,"documents.groupby('grant_id').size().nlargest(1).reset_index(name='count')[['grant_id', 'count']]"
"for every grant id, provide the number of documents it contains. please also list the grant id that has the most documents.","documents.groupby('grant_id').size().nlargest(1).reset_index(name='count')[['grant_id', 'count']]"
retrieve the description for the organisation type classified under 'quo',"pd.merge(organisation_types, organisations, on='organisation_type').loc[lambda x: x['organisation_details']=='quo', 'organisation_type_description']"
what is the organization type for the entity whose detail is listed as 'quo'?,"pd.merge(organisation_types, organisations, on='organisation_type').loc[lambda x: x['organisation_details']=='quo', 'organisation_type_description']"
provide the names of organisations named as 'sponsor' in an ascending order.,"pd.merge(organisations, organisation_types, on='organisation_type').loc[lambda x: x['organisation_type_description']=='sponsor'].sort_values('organisation_details')['organisation_details']"
list all organizations that are referred to as sponsors and categorize them in ascending order.,"pd.merge(organisations, organisation_types, on='organisation_type').loc[lambda x: x['organisation_type_description']=='sponsor'].sort_values('organisation_details')['organisation_details']"
provide me with a count of patent outcomes generated from all projects.,(project_outcomes['outcome_code'] == 'patent').sum()
how many patent outcomes were listed for all the projects?,(project_outcomes['outcome_code'] == 'patent').sum()
determine the number of staff that worked as managers or started their job before 1989-04-24 23:51:54.,((project_staff['role_code']=='leader')|(project_staff['date_from']<'1989-04-24 23:51:54')).sum()
"at the moment, how many project members were leaders or started working before the given date?",((project_staff['role_code']=='leader')|(project_staff['date_from']<'1989-04-24 23:51:54')).sum()
how long does the staff stay in the projects?,"project_staff.sort_values('date_to', ascending=false).iloc[0]['date_to']"
what is the end date of the tenure of a staff member in a particular project?,"project_staff.sort_values('date_to', ascending=false).iloc[0]['date_to']"
return me the details of projects whose detail is 'sint'.,"pd.merge(pd.merge(research_outcomes, project_outcomes, on='outcome_code'), projects, on='project_id').loc[lambda x: x['project_details']=='sint', 'outcome_description']"
what is the description of results that have the project detail 'sint'?,"pd.merge(pd.merge(research_outcomes, project_outcomes, on='outcome_code'), projects, on='project_id').loc[lambda x: x['project_details']=='sint', 'outcome_description']"
"list the organisation id with the greatest number of outcomes, along with the total number.","projects.merge(project_outcomes, on='project_id').groupby('organisation_id').size().sort_values(ascending=false).iloc[[0]]"
what is the id of the firm having the maximum number of outcomes and what number of outcomes does it have?,"projects.merge(project_outcomes, on='project_id').groupby('organisation_id').size().sort_values(ascending=false).iloc[[0]]"
tell me the details of the projects launched by the organisation.,"projects.loc[lambda x: x['organisation_id'].isin(projects.groupby('organisation_id').size().sort_values(ascending=false).index[0:1]), 'project_details']"
provide me with the projects launched by an organization with the highest number of projects.,"projects.loc[lambda x: x['organisation_id'].isin(projects.groupby('organisation_id').size().sort_values(ascending=false).index[0:1]), 'project_details']"
"order the titles, names, and contact details of research staff in ascending order.",research_staff.sort_values('staff_details')['staff_details']
list the names of the research staff in a ascending alphabetical order.,research_staff.sort_values('staff_details')['staff_details']
what is the count of total tasks?,tasks.shape[0]
what is the count of tasks?,tasks.shape[0]
how many tasks are there in the project? list the task count and the project detail.,"pd.merge(projects, tasks, on='project_id').groupby('project_id').agg({'project_details': 'first', '*': 'count'})"
what is the count of tasks for each project?,"pd.merge(projects, tasks, on='project_id').groupby('project_id').agg({'project_details': 'first', '*': 'count'})"
list the staff roles of all the staff who,"project_staff.loc[(project_staff['date_from'] > '2003-04-19 15:06:20') & (project_staff['date_to'] < '2016-03-15 00:33:18'), 'role_code']"
what roles did staff members play between the specified dates?,"project_staff.loc[(project_staff['date_from'] > '2003-04-19 15:06:20') & (project_staff['date_to'] < '2016-03-15 00:33:18'), 'role_code']"
what is the complete list of project outcomes?,"pd.merge(research_outcomes, project_outcomes, on='outcome_code')['outcome_description']"
list the descriptions of all outcomes for all projects.,"pd.merge(research_outcomes, project_outcomes, on='outcome_code')['outcome_description']"
which title is employed in the majority of staff members?,project_staff.groupby('role_code').size().sort_values(ascending=false).index[0]
what is the prevalent designation for most staff members?,project_staff.groupby('role_code').size().sort_values(ascending=false).index[0]
how many females are present in the network?,(person['gender'] == 'female').sum()
what is the average of/for all person?,person['age'].mean()
what is the average age for all of the people in the table?,person['age'].mean()
how many cities do they belong to?,person['city'].nunique()
calculate the total number of different cities from which people originate.,person['city'].nunique()
determine the number of types of jobs available.,person['job'].nunique()
how many different jobs are there?,person['job'].nunique()
kindly provide the name of the person who is the eldest.,"person.loc[person['age'] == person['age'].max(), 'name']"
which individual is the oldest in whose occupation is the student?,"person.loc[lambda x: (x['job']=='student') & (x['age']==x.loc[x['job']=='student', 'age'].max()), 'name']"
list the names of the oldest students.,"person.loc[lambda x: (x['job']=='student') & (x['age']==x.loc[x['job']=='student', 'age'].max()), 'name']"
provide the gender of the youngest person.,"person.loc[lambda x: (x['gender']=='male') & (x['age']==person.loc[lambda y: y['gender']=='male', 'age'].min()), 'name']"
please provide me with the names of the youngest male.,"person.loc[lambda x: (x['gender']=='male') & (x['age']==person.loc[lambda y: y['gender']=='male', 'age'].min()), 'name']"
what is the age at which zach became a doctor?,"person.loc[(person['job']=='doctor') & (person['name']=='zach'), 'age']"
identify the 30 year old person.,"person.loc[lambda x: x['age'] < 30, 'name']"
get the name of the person whose age is lower than that of 30.,"person.loc[lambda x: x['age'] < 30, 'name']"
how many engineers are there whose age is greater than 30?,"person.loc[(person['age'] > 30) & (person['job'] == 'engineer'), :].shape[0]"
determine the total count of engineers who are older than 30.,"person.loc[(person['age'] > 30) & (person['job'] == 'engineer'), :].shape[0]"
what is the average age of each student by gender?,person.groupby('gender')['age'].mean()
what is the age distribution of each gender?,person.groupby('gender')['age'].mean()
what is the average age of employees with each job title?,person.groupby('job')['age'].mean()
what is the age for the majority of people for each occupation?,person.groupby('job')['age'].mean()
provide me the average ages of male for given job title.,person[person['gender']=='male'].groupby('job')['age'].mean()
what is the age distribution of males in each job?,person[person['gender']=='male'].groupby('job')['age'].mean()
what is the age that each youngest person in a respective job?,person.groupby('job')['age'].min()
provide me with the gender-wise distribution of individuals falling under 40 years of age.,person.loc[person['age']<40].groupby(['gender']).size().reset_index(name='count')
how many members of a given age group are there for each gender?,person.loc[person['age']<40].groupby(['gender']).size().reset_index(name='count')
identify the titles of persons whose age exceeds any engineer sorted by their age.,"person.loc[lambda x: x['age'] > person.loc[person['job'] == 'engineer', 'age'].min()].sort_values('age')['name']"
"list the names of all people older than at least one engineer, and order them by age.","person.loc[lambda x: x['age'] > person.loc[person['job'] == 'engineer', 'age'].min()].sort_values('age')['name']"
determine the total count of employees who are older than all engineers.,"person.loc[lambda x: x['age'] > person.loc[lambda y: y['job']=='engineer', 'age'].max()].shape[0]"
please list all the names of people working in the human resources department ordered by their names.,"person[['name', 'job']].sort_values('name')"
what is the list of all names and job titles ordered alphabetically?,"person[['name', 'job']].sort_values('name')"
retrieve the names of all people in an order based on age.,"person.sort_values('age', ascending=false)['name']"
sort the names by descending age and determine the list of names.,"person.sort_values('age', ascending=false)['name']"
give me the names and ages of all males in the order of their age.,person.loc[lambda x: x['gender']=='male'].sort_values('age')['name']
return the names of all the males along with their ages. sort the results by age.,person.loc[lambda x: x['gender']=='male'].sort_values('age')['name']
return the name and the age of the person who is a mutual friend of dan and alice.,"person.merge(person_friend.loc[lambda x: x['friend']=='dan'], on='name')[['name', 'age']].merge(person_friend.loc[lambda x: x['friend']=='alice'], on='name')[['name', 'age']]"
retrieve the name and age of every person who is a friend of both dan and alice.,"person.merge(person_friend.loc[lambda x: x['friend']=='dan'], on='name')[['name', 'age']].merge(person_friend.loc[lambda x: x['friend']=='alice'], on='name')[['name', 'age']]"
identify the title and age of the person who is a friend of dan or alice.,"pd.merge(person, personfriend, on='name').loc[lambda x: x['friend'].isin(['dan', 'alice']), ['name', 'age']].drop_duplicates()"
what are the names of age and friendship pairs of either dan or alice?,"pd.merge(person, personfriend, on='name').loc[lambda x: x['friend'].isin(['dan', 'alice']), ['name', 'age']].drop_duplicates()"
enumerate the names of friends whose ages lie between 40 and 30.,"person_friend.merge(person.loc[person['age'] > 40][['name']], on='friend').merge(person.loc[person['age'] < 30][['name']], on=['name']).drop_duplicates()['name']"
provide a list of the names of persons who have a friend aged 40 or more and 30 or less.,"person_friend.merge(person.loc[person['age'] > 40][['name']], on='friend').merge(person.loc[person['age'] < 30][['name']], on=['name']).drop_duplicates()['name']"
please display the name of the person having friends who has a minimum age of 40 and a maximum of 30.,"set(pd.merge(person, personfriend, on='name').loc[lambda x: x['friend'].isin(person.loc[lambda y: y['age'] > 40, 'name']), 'name']) - set(pd.merge(person, personfriend, on='name').loc[lambda x: x['friend'].isin(person.loc[lambda y: y['age'] < 30, 'name']), 'name'])"
what people are older 40 years but have no friends that are younger than 30?,"set(pd.merge(person, personfriend, on='name').loc[lambda x: x['friend'].isin(person.loc[lambda y: y['age'] > 40, 'name']), 'name']) - set(pd.merge(person, personfriend, on='name').loc[lambda x: x['friend'].isin(person.loc[lambda y: y['age'] < 30, 'name']), 'name'])"
fetch the title of the person who doesn't own any student friends.,"person[~person['name'].isin(person.merge(person_friend, left_on='name', right_on='friend').loc[lambda x: x['job']=='student', 'name_x'])]['name']"
retrieve the names for individuals who have no friends who are students.,"person[~person['name'].isin(person.merge(person_friend, left_on='name', right_on='friend').loc[lambda x: x['job']=='student', 'name_x'])]['name']"
what is the title of a person who has exactly one friend?,personfriend.groupby('name').filter(lambda x: len(x) == 1)['name']
which people have no friends at all?,personfriend.groupby('name').filter(lambda x: len(x) == 1)['name']
what are the friends of bob?,"personfriend.merge(person.loc[lambda x: x['name']=='bob'], on='name')['friend']"
list the names of the contacts who are friends with bob.,"personfriend.merge(person.loc[lambda x: x['name']=='bob'], on='name')['friend']"
list the names of people who are friends with bob.,"pd.merge(df_person, df_personfriend, on='name').loc[lambda x: x['friend']=='bob', 'name']"
show me the names of all of bobs' friends.,"pd.merge(df_person, df_personfriend, on='name').loc[lambda x: x['friend']=='bob', 'name']"
retrieve the names of females who are friends with zach.,"pd.merge(person, person_friend, on='name').loc[lambda x: (x['friend']=='zach') & (x['gender']=='female'), 'name']"
retrieve the names of females who are friends of zach.,"pd.merge(person, person_friend, on='name').loc[lambda x: (x['friend']=='zach') & (x['gender']=='female'), 'name']"
find the names of female friends of alice.,"pd.merge(personfriend.loc[lambda x: x['name']=='alice'], person.loc[lambda x: (x['gender']=='female') & (x['name']==personfriend.loc[lambda x: x['name']=='alice', 'friend'].iloc[0])], left_on='friend', right_on='name')['friend']"
what are the names of female friends of alice?,"pd.merge(personfriend.loc[lambda x: x['name']=='alice'], person.loc[lambda x: (x['gender']=='female') & (x['name']==personfriend.loc[lambda x: x['name']=='alice', 'friend'].iloc[0])], left_on='friend', right_on='name')['friend']"
retrieve the names of male friends of alice who are doctors.,"pd.merge(personfriend.loc[lambda x: x['name']=='alice'], person.loc[(person['gender']=='male') & (person['job']=='doctor')], left_on='friend', right_on='name')['friend']"
retrieve the names of friends of alice that are doctors.,"pd.merge(personfriend.loc[lambda x: x['name']=='alice'], person.loc[(person['gender']=='male') & (person['job']=='doctor')], left_on='friend', right_on='name')['friend']"
who has a buddy that is from nyc?,"person.merge(person_friend, left_on='name', right_on='friend').loc[lambda x: x['city']=='new york city', 'name_y']"
find the names of the friends (users) who are from new york.,"person.merge(person_friend, left_on='name', right_on='friend').loc[lambda x: x['city']=='new york city', 'name_y']"
determine the names of people that have friends that are younger than the overall average age.,"person_friend.loc[person_friend['friend'].isin(person.loc[person['age'] < person['age'].mean(), 'name'].values), 'name'].unique()"
which names are utilized by friends that are younger than the average age for a facebook friend?,"person_friend.loc[person_friend['friend'].isin(person.loc[person['age'] < person['age'].mean(), 'name'].values), 'name'].unique()"
who are friends with people who are older than the average age? print those people and their ages as well.,"person.merge(person_friend, left_on='name', right_on='friend').loc[lambda x: x['age_x'] > person['age'].mean(), ['name_y', 'friend', 'age_x']].rename(columns={'name_y':'name'}).drop_duplicates()"
"retrieve the names, friends, and ages of all individuals who are older than the average age of an individual.","person.merge(person_friend, left_on='name', right_on='friend').loc[lambda x: x['age_x'] > person['age'].mean(), ['name_y', 'friend', 'age_x']].rename(columns={'name_y':'name'}).drop_duplicates()"
who has been zach's friend for the longest time?,"personfriend.loc[lambda x: (x['name']=='zach')&(x['year']==personfriend.loc[lambda y: y['name']=='zach', 'year'].max()), 'friend']"
what is the total number of friends that zach holds?,"personfriend.loc[lambda x: (x['name']=='zach')&(x['year']==personfriend.loc[lambda y: y['name']=='zach', 'year'].max()), 'friend']"
what is the year at which the friendship between zach and his friend with longest year duration began?,"person.loc[lambda x: x['name'].isin(person_friend.loc[(person_friend['name'] == 'zach') & (person_friend['year'] == person_friend.loc[lambda y: y['name'] == 'zach', 'year'].max()), 'friend']), 'age']"
return me the ages of all zach's friends who have been in a relationship longer than that of zach and eva.,"person.loc[lambda x: x['name'].isin(person_friend.loc[(person_friend['name'] == 'zach') & (person_friend['year'] == person_friend.loc[lambda y: y['name'] == 'zach', 'year'].max()), 'friend']), 'age']"
retrieve the names of persons whose friendship duration is shortest with alice.,"personfriend.loc[lambda x: (x['friend'] == 'alice') & (x['year'] == personfriend.loc[lambda y: y['friend'] == 'alice', 'year'].min()), 'name']"
find the names of people who are friends to alice for the shortest time.,"personfriend.loc[lambda x: (x['friend'] == 'alice') & (x['year'] == personfriend.loc[lambda y: y['friend'] == 'alice', 'year'].min()), 'name']"
"return the full name, age, and job title of persons who were present at functions with alice for the longest duration.","person.merge(personfriend.query(""friend == 'alice' and year == (select max(year) from personfriend where friend == 'alice')""), on='name')[['name', 'age', 'job']]"
"find the names of all people befriended by alice for the longest time, along with their ages and occupation.","person.merge(personfriend.query(""friend == 'alice' and year == (select max(year) from personfriend where friend == 'alice')""), on='name')[['name', 'age', 'job']]"
locate the person who has no friend.,person[~person['name'].isin(personfriend['name'])]['name']
determine the names of individuals who have no friends.,person[~person['name'].isin(personfriend['name'])]['name']
who is the person whose friends have the oldest average age?,"person.merge(personfriend, left_on='name', right_on='friend').groupby('name_y').agg({'age': 'mean'}).sort_values('age', ascending=false).iloc[0]"
"obtain the name of the person with the oldest average age for her friends, and calculate that average age.","person.merge(personfriend, left_on='name', right_on='friend').groupby('name_y').agg({'age': 'mean'}).sort_values('age', ascending=false).iloc[0]"
how many residents in austin have no friends living in the city of austin?,"personfriend.loc[~personfriend['friend'].isin(person.loc[person['city']=='austin', 'name']), 'name'].nunique()"
what number of people have no friends living in austin?,"personfriend.loc[~personfriend['friend'].isin(person.loc[person['city']=='austin', 'name']), 'name'].nunique()"
"find alice's second-""level-of-friends"".","(pd.merge(pd.merge(pd.merge(person_friend, person, left_on='name', right_on='name'), person_friend, left_on='friend', right_on='name'), person_friend, left_on='friend_y', right_on='name').loc[lambda x: (x['name_x']=='alice')&(x['name_y']!='alice'), 'name'])"
retrieve the names of all of alice's friends of friends.,"(pd.merge(pd.merge(pd.merge(person_friend, person, left_on='name', right_on='name'), person_friend, left_on='friend', right_on='name'), person_friend, left_on='friend_y', right_on='name').loc[lambda x: (x['name_x']=='alice')&(x['name_y']!='alice'), 'name'])"
what is the count of the number of members?,member.shape[0]
provide me with the titles of all members in ascending alphabetical order.,member.sort_values('name')['name']
retrieve the titles of names and countries of members.,"member[['name', 'country']]"
"provide me with the titles of those members whose country is ""united states"" or ""canada"".","member.loc[lambda x: x['country'].isin(['united states', 'canada']), 'name']"
please make a list of the different countries and the number of members from each.,member.groupby('country').size().reset_index(name='count')
provide a sorted list of the most common countries across the members.,member.groupby('country').size().sort_values(ascending=false).index[0]
retrieve the names of college leaders and their corresponding locations.,"college[['leader_name', 'college_location']]"
provide me with the names of members and their respective college.,"pd.merge(college, member, on='college_id')[['name_x', 'name_y']]"
please show the members grouped by location and organized by name in alphabetical order.,"pd.merge(college, member, on='college_id').sort_values('name')[['name', 'college_location']]"
give me the names of members and the decoration categories they have.,"pd.merge(member, round, on='member_id')[['name', 'decoration_theme']]"
list the names of members that have a high rank in round.,"pd.merge(member, round, on='member_id').loc[lambda x: x['rank_in_round'] > 3, 'name']"
produce a list in ascending order of the counts of members participating in each round.,"pd.merge(member, round, on='member_id').sort_values('rank_in_round')['name']"
retrieve the titles of people who did not partake in any round.,"member.loc[~member['member_id'].isin(round['member_id']), 'name']"
"retrieve the name and access counts of all documents, in the order of their title.","documents[['document_name', 'access_count']].sort_values('document_name')"
"please list the names of all the documents, as well as the access counts of each, in alphabetical order.","documents[['document_name', 'access_count']].sort_values('document_name')"
"provide me with the title of the most accessed document, as well as the count of the number of times it has been accessed.","documents[['document_name', 'access_count']].sort_values('access_count', ascending=false).iloc[0]"
"please list the documents that have been accessed the largest number of occasions, along with the number of times each has been accessed.","documents[['document_name', 'access_count']].sort_values('access_count', ascending=false).iloc[0]"
identify the templates for which there are more than four copies.,documents.groupby('document_type_code').filter(lambda x: len(x) > 4)['document_type_code'].unique()
which document type codes are used more than or equal to 1 instances?,documents.groupby('document_type_code').filter(lambda x: len(x) > 4)['document_type_code'].unique()
how could one count and access the total count of all documents of the most popular document type?,documents.groupby('document_type_code')['access_count'].sum().nlargest(1)
what is the highest number of accesses achieved for documents of the most common document type?,documents.groupby('document_type_code')['access_count'].sum().nlargest(1)
what is the average count of accesses made to documents?,documents['access_count'].mean()
how many documents had accessed most?,documents['access_count'].mean()
which document has the least number of accesses?,"pd.merge(documents, document_structures, on='document_structure_code').groupby('document_structure_description').size().sort_values(ascending=false).index[0]"
please compute the number of accesses to documents having the structure description seen the fewest number of times.,"pd.merge(documents, document_structures, on='document_structure_code').groupby('document_structure_description').size().sort_values(ascending=false).index[0]"
"what is the format of a document named ""david cv""?","documents.loc[lambda x: x['document_name']=='david cv', 'document_type_code']"
"please provide me with the doctype of the document named ""david cv""","documents.loc[lambda x: x['document_name']=='david cv', 'document_type_code']"
find the list of documents that are in both of three most widely used types and three most widely used structures.,"documents.groupby('document_type_code').count().sort_values(by='document_name', ascending=false).iloc[:3].reset_index()['document_name'].to_frame().merge(documents.groupby('document_structure_code').count().sort_values(by='document_name', ascending=false).iloc[:3].reset_index()['document_name'].to_frame()).drop_duplicates()['document_name']"
"which document types have more than 10,000 total access numbers?",documents.groupby('document_type_code').filter(lambda x: x['access_count'].sum() > 10000)['document_type_code'].unique()
determine the document type codes that are utilized by fewer than 10000 documents in total.,documents.groupby('document_type_code').filter(lambda x: x['access_count'].sum() > 10000)['document_type_code'].unique()
"retrieve the section titles of the document named ""david cv"".","document_sections.merge(documents[documents['document_name']=='david cv'], on='document_code')['section_title']"
"provide the section titles of the document whose name is ""david cv"".","document_sections.merge(documents[documents['document_name']=='david cv'], on='document_code')['section_title']"
provide the list of titles of documents that have no sections.,"documents.loc[~documents['document_code'].isin(document_sections['document_code']), 'document_name']"
give me the titles of these username/passwords along with their respective role.,"users.groupby('role_code').agg({'user_name': 'first', 'password': 'first'}).reset_index().sort_values(by='role_code', ascending=false).nlargest(1, columns='role_code')[['user_name', 'password']]"
which user accounts are the most common and what type of role do they have?,"users.groupby('role_code').agg({'user_name': 'first', 'password': 'first'}).reset_index().sort_values(by='role_code', ascending=false).nlargest(1, columns='role_code')[['user_name', 'password']]"
"determine the average access count of documents with functional area ""acknowledgement"".","pd.merge(pd.merge(documents, document_functional_areas, on='document_code'), functional_areas, on='functional_area_code').loc[lambda x: x['functional_area_description']=='acknowledgement', 'access_count'].mean()"
"find the average access counts for documents that have the ""acknowledgement"" functional area description.","pd.merge(pd.merge(documents, document_functional_areas, on='document_code'), functional_areas, on='functional_area_code').loc[lambda x: x['functional_area_description']=='acknowledgement', 'access_count'].mean()"
retrieve the titles of documents that are not accompanied with images.,"documents['document_name'].loc[~documents['document_code'].isin(document_sections.merge(document_sections_images, on='section_id')['document_code'].unique())]"
what is the title/title name of a document with the most number of sections?,"documents.merge(document_sections, on='document_code').groupby('document_code')['document_name'].first().value_counts().index[0]"
give me the document title that contains the most sections.,"documents.merge(document_sections, on='document_code').groupby('document_code')['document_name'].first().value_counts().index[0]"
"list all the document titles which contain the words ""cv"".","documents.loc[documents['document_name'].str.contains('cv'), 'document_name']"
"return the names of files that contain the string ""cv"".","documents.loc[documents['document_name'].str.contains('cv'), 'document_name']"
what is the number of logged in users?,(users['user_login'] == 1).sum()
determine the total number of users that are logged on.,(users['user_login'] == 1).sum()
retrieve the description of the most popular role among the users that have logged in.,"roles.loc[lambda x: x['role_code']==users.loc[lambda y: y['user_login']==1, 'role_code'].value_counts().idxmax(), 'role_description']"
what is the description of the role that is the most popular among users that have logged in?,"roles.loc[lambda x: x['role_code']==users.loc[lambda y: y['user_login']==1, 'role_code'].value_counts().idxmax(), 'role_description']"
determine the average access count of documents with the least popular structure.,documents.groupby('document_structure_code')['access_count'].mean().sort_values().head(1)
what is the mean of the document access counts in papers that have the least common structure?,documents.groupby('document_structure_code')['access_count'].mean().sort_values().head(1)
arrange the names of images and urls in the order of their names.,"images[['image_name', 'image_url']].sort_values('image_name')"
list the urls along with the titles of images sorted in alphabetical order.,"images[['image_name', 'image_url']].sort_values('image_name')"
report the number of users in each role.,users.groupby('role_code').size().reset_index(name='count')
provide me with the job title codes of users and their corresponding count of users.,users.groupby('role_code').size().reset_index(name='count')
what document types have at least 2 documents belonging to the category?,documents.groupby('document_type_code').filter(lambda x: len(x) > 2)['document_type_code'].unique()
provide the codes of document types that have more than two corresponding documents.,documents.groupby('document_type_code').filter(lambda x: len(x) > 2)['document_type_code'].unique()
the number of companies that are present?,companies.shape[0]
what is the count of companies?,companies.shape[0]
provide me the list of company names in descending order of market value.,"companies.sort_values('market_value_billion', ascending=false)['name']"
categorize the names of the companies in descending order of their market values.,"companies.sort_values('market_value_billion', ascending=false)['name']"
provide the names of the companies whose headquarters are not located in the united states of america.,"companies.loc[lambda x: x['headquarters']!='usa', 'name']"
"list the companies whose headquarters are not located in ""usa"".","companies.loc[lambda x: x['headquarters']!='usa', 'name']"
please sort and list companies based on their names and assets.,"companies[['name', 'assets_billion']].sort_values('name')"
list the title and assets of the companies in ascending order of company name.,"companies[['name', 'assets_billion']].sort_values('name')"
which companies made the most profit in 2017?,companies['profits_billion'].mean()
return the average profits accrued by companies.,companies['profits_billion'].mean()
"provide me with the maximum and minimum sales of the companies whose industries are not ""banking"".","companies.loc[lambda x: x['industry']!='banking', 'sales_billion'].agg(['max', 'min'])"
"determine the maximum and minimum sales of the companies that are not included in ""banking"" industry.","companies.loc[lambda x: x['industry']!='banking', 'sales_billion'].agg(['max', 'min'])"
what is the count of industries where these companies operate?,companies['industry'].nunique()
find the total number of distinct company industries.,companies['industry'].nunique()
show me the buildings exhibited in a descending order of building height.,"buildings.sort_values('height', ascending=false)['name']"
what are the titles of buildings sorted in descending order of building height?,"buildings.sort_values('height', ascending=false)['name']"
i would like you to return me the names of buildings with the tallest heights.,"buildings.sort_values('height', ascending=false).iloc[0]['stories']"
what are the accounts of tallest structures?,"buildings.sort_values('height', ascending=false).iloc[0]['stories']"
return the titles of buildings along with the name of companies whose offices are located in those particular buildings.,"pd.merge(pd.merge(office_locations, buildings, left_on='building_id', right_on='id'), companies, left_on='company_id', right_on='id')[['name_x', 'name_y']]"
"for each company, provide its company name and the name of the building where its office is located.","pd.merge(pd.merge(office_locations, buildings, left_on='building_id', right_on='id'), companies, left_on='company_id', right_on='id')[['name_x', 'name_y']]"
please find the names of buildings that contain more than one company office.,"pd.merge(pd.merge(office_locations, buildings, left_on='building_id', right_on='id'), companies, left_on='company_id', right_on='id').groupby('building_id').filter(lambda x: len(x) > 1)['name_y']"
provide me with the names of buildings with more than one company office.,"pd.merge(pd.merge(office_locations, buildings, left_on='building_id', right_on='id'), companies, left_on='company_id', right_on='id').groupby('building_id').filter(lambda x: len(x) > 1)['name_y']"
tell me the name of building that has the most offices.,"pd.merge(pd.merge(office_locations, buildings, left_on='building_id', right_on='id'), companies, left_on='company_id', right_on='id').groupby('building_id')['name'].count().idxmax()"
give the building name with the largest number of offices occupied by companies.,"pd.merge(pd.merge(office_locations, buildings, left_on='building_id', right_on='id'), companies, left_on='company_id', right_on='id').groupby('building_id')['name'].count().idxmax()"
"please display the names of buildings whose status is ""on-hold"", in ascending order of total stories.",buildings.loc[lambda x: x['status']=='on-hold'].sort_values('stories')['name']
"return the names of buildings that were classified as ""on-hold"", and sort them in ascending order of building stories.",buildings.loc[lambda x: x['status']=='on-hold'].sort_values('stories')['name']
please display the name of each industry along with the number of companies in each respective industry.,companies.groupby('industry').size().reset_index(name='count')
provide the titles of each industry along with the corresponding count of companies in each industry.,companies.groupby('industry').size().reset_index(name='count')
provide me with the names of industries in descending order of the number of companies.,companies.groupby('industry').size().sort_values(ascending=false).index
provide the count of industries shared by the most companies.,companies.groupby('industry').size().sort_values(ascending=false).index[0]
list the names of the buildings that have no company offices.,"buildings.loc[~buildings['id'].isin(office_locations['building_id']), 'name']"
please list the names of buildings that do not have company offices.,"buildings.loc[~buildings['id'].isin(office_locations['building_id']), 'name']"
"display the industry names that are common to the companies whose headquarters are ""usa"" and companies whose headquarters are ""china"".","set(companies.query('headquarters==""usa""')['industry']).intersection(set(companies.query('headquarters==""china""')['industry']))"
"which industries have both companies with headquarters in ""usa"" and companies with headquarters in ""china""?","set(companies.query('headquarters==""usa""')['industry']).intersection(set(companies.query('headquarters==""china""')['industry']))"
"determine the number of companies that are either ""banking"" or ""conglomerate"".","companies.loc[lambda x: x['industry'].isin(['banking', 'conglomerate'])].shape[0]"
how many firms appear in both banking and conglomerate industries?,"companies.loc[lambda x: x['industry'].isin(['banking', 'conglomerate'])].shape[0]"
list the headquarters that are used by two or more companies.,companies.groupby('headquarters').filter(lambda x: len(x) > 2).groupby('headquarters').first()
fetch the titles in ascending order of price of the products.,products.sort_values('product_price')['product_name']
what are the names of products and type codes?,"products[['product_name', 'product_type_code']]"
"return me the prices of the products named ""dining"" or ""trading policy"".","products.loc[lambda x: x['product_name'].isin(['dining', 'trading policy']), 'product_price']"
what is the average price for each product?,products['product_price'].mean()
retrieve a name for the product that has the highest sale price.,"products.sort_values('product_price', ascending=false).iloc[0]['product_name']"
display the codes of product types along with the number of products with each type code.,products.groupby('product_type_code').size().rename_axis('product_type_code').reset_index(name='count')
provide the titles of template types that are most widely used across various products.,products.groupby('product_type_code').size().sort_values(ascending=false).index[0]
provide the list of product type codes having at least two products.,products.groupby('product_type_code').filter(lambda x: len(x) >= 2)['product_type_code'].unique()
determine the titles of product type codes that contain products priced higher and lower than 4500.,set(products.query('product_price > 4500')['product_type_code']).intersection(set(products.query('product_price < 3000')['product_type_code']))
display the names of products along with the number of events they are in.,"pd.merge(products, products_in_events, on='product_id').groupby('product_name').size().reset_index(name='count')"
list all products and sort the results by descending order of the number of events.,"pd.merge(products, products_in_events, on='product_id').groupby('product_name').size().sort_values(ascending=false)"
display the titles of all products cited in at least two events.,"pd.merge(products, products_in_events, on='product_id').groupby('product_name').filter(lambda x: len(x) >= 2)['product_name'].unique()"
show the names of products that are used in more than two events in ascending alphabetical order of product name.,"pd.merge(products, products_in_events, on='product_id').groupby('product_name').filter(lambda x: len(x) >= 2).sort_values('product_name')['product_name']"
retrieve the names of products that are not in any events.,"products.loc[~products['product_id'].isin(products_in_events['product_id']), 'product_name']"
which artworks are there?,artwork.shape[0]
please list the names of artworks in ascending alphabetical order.,artwork.sort_values('name')['name']
"retrieve the titles of artworks that do not have ""program talent show"" as type.","artwork.loc[lambda x: x['type']!='program talent show', 'name']"
retrieve the title of each festival and its location.,"festival_detail[['festival_name', 'location']]"
which festivals were held by their respective chair?,festival_detail.sort_values('year')['chair_name']
what festival had the largest audience?,"festival_detail.sort_values('num_of_audience', ascending=false)['location'].iloc[0]"
obtain the names of festivals held in the year 2007.,"festival_detail.loc[lambda x: x['year']==2007, 'festival_name']"
what is the average number of audiences attending festivals?,festival_detail['num_of_audience'].mean()
list the names of the three most recent festivals.,"festival_detail.sort_values('year', ascending=false).iloc[:3]['festival_name']"
display the name of the artwork and the name of the festival it was nominated with.,"pd.merge(pd.merge(nomination, artwork, on='artwork_id'), festival_detail, on='festival_id')[['name', 'festival_name']]"
retrieve the distinct types of media that are nominated for awards in 2007.,"pd.merge(pd.merge(nomination, artwork, on='artwork_id'), festival_detail, on='festival_id').loc[lambda x: x['year']==2007, 'type'].unique()"
place the titles of art works in order of the year of nomination.,"pd.merge(pd.merge(nomination, artwork, on='artwork_id'), festival_detail, on='festival_id').sort_values('year')['name']"
"retrieve the titles of the festivals that have nominated artworks of type ""program talent show"".","pd.merge(pd.merge(nomination, artwork, on='artwork_id'), festival_detail, on='festival_id').loc[lambda x: x['type'] == 'program talent show', 'festival_name']"
list the nominates of all the festivals that have received at least two nominations for artworks.,"pd.merge(pd.merge(nomination, artwork, on='artwork_id'), festival_detail, on='festival_id').groupby(['festival_id', 'festival_name']).filter(lambda x: len(x) >= 2)[['festival_id', 'festival_name']].drop_duplicates()"
"show the id, title, and number of nominated artworks for each festival.","pd.merge(pd.merge(nomination, artwork, on='artwork_id'), festival_detail, on='festival_id').groupby(['festival_id', 'festival_name']).size().reset_index(name='count')[['festival_id', 'festival_name', 'count']]"
provide me with all the types of artwork and their corresponding number.,artwork.groupby('type').size().reset_index(name='count')
please send me the list of most common types of artworks.,artwork.groupby('type').size().sort_values(ascending=false).index[0]
provide the year in which there is more than one festival.,"festival_detail.groupby('year').filter(lambda x: len(x) > 1).groupby('year').size().reset_index(name='count').loc[:, 'year']"
for which artworks were no nominations made?,"artwork.loc[~artwork['artwork_id'].isin(nomination['artwork_id']), 'name']"
please provide me with the total number of people in the specified year.,"festival_detail.loc[festival_detail['year'].isin([2008, 2010]), 'num_of_audience']"
what is the total count of audiences who have visited any of the festivals?,festival_detail['num_of_audience'].sum()
which year did both united states and non-united states countries celebrate festivals?,"festival_detail.loc[festival_detail['location'] == 'united states', 'year'].drop_duplicates().reset_index(drop=true).intersect(festival_detail.loc[festival_detail['location'] != 'united states', 'year'].drop_duplicates().reset_index(drop=true))"
what is the count of premises?,premises.shape[0]
return the names of all distinct premise types.,premises['premises_type'].unique()
find all the premises and order them by their premises type.,"premises[['premises_type', 'premise_details']].sort_values('premises_type')"
present each premise type with the corresponding count.,premises.groupby('premises_type').size()
list all product categories along with the number of mailshots in each category.,mailshot_campaigns.groupby('product_category').size()
give the full name and phone number of customers without any mailshots.,"customers.loc[~customers['customer_id'].isin(mailshot_customers['customer_id']), ['customer_name', 'customer_phone']]"
provide the name of customers for whom the mailshot has been sent with the outcome code 'no response'.,"pd.merge(customers, mailshot_customers, on='customer_id').loc[lambda x: x['outcome_code']=='no response', ['customer_name', 'customer_phone']]"
obtain the outcomes code for the mailshots along with their corresponding count.,mailshot_customers['outcome_code'].value_counts()
"list the name of customers who have received at least 2 mailshots with the outcome code ""order"".","pd.merge(mailshot_customers, customers, on='customer_id').loc[lambda x: x['outcome_code']=='order'].groupby('customer_id')['customer_name'].filter(lambda x: len(x)>=2).unique()"
reveal the names of customers that receive the most e-mail campaigns.,"pd.merge(mailshot_customers, customers, on='customer_id').groupby('customer_name').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0, 0]"
"what is the name of customers with both mailshots in 'order' outcome and mailshots in 'no response' outcome? also, what is their payment method?","pd.merge(mailshot_customers.loc[lambda x:x['outcome_code']=='order', ['customer_id']], customers, on='customer_id')[['customer_name', 'payment_method']].merge(pd.merge(mailshot_customers.loc[lambda x:x['outcome_code']=='no response', ['customer_id']],customers, on='customer_id')[['customer_name', 'payment_method']]).drop_duplicates()"
provide me with the premise type and address type code for all customer addresses.,"pd.merge(customer_addresses, premises, on='premise_id')[['premises_type', 'address_type_code']]"
provide me with the unique address type codes for all customers.,customer_addresses['address_type_code'].unique()
provide me the shipping charge and customer id for customer orders with order status cancelled or paid.,"customer_orders.loc[lambda x: x['order_status_code'].isin(['cancelled', 'paid']), ['order_shipping_charges', 'customer_id']]"
how many total courses are there?,course.shape[0]
how many courses does the web have?,course.shape[0]
determine the count of courses with more than two credits.,(course['credits'] > 2).sum()
list all names of courses with 1 credit.,"course.loc[lambda x: x['credits'] == 1, 'cname']"
what courses are credited for one credit?,"course.loc[lambda x: x['credits'] == 1, 'cname']"
what is the course name for courses taught on mtw?,"course.loc[course['days'] == 'mtw', 'cname']"
"how many departments exist in division ""as""?",(department['division'] == 'as').sum()
how many departments are contained in the division as?,(department['division'] == 'as').sum()
what is the first phone number of departments in room 268?===  **solutions**===[https://discuss.leetcode.com/topic/1881/all-sentence-sol...](https://discuss.leetcode.com/topic/1881/all-sentence-solutions/)[https://discuss.leetcode.com/topic/1881/all-sentence-sol...](https://discuss.leetcode.com/topic/1881/all-sentence-solutions/)[https://discuss.leetcode.com/topic/1881/all-sentence-sol...](https://discuss.leetcode.com/topic/1881/all-sentence-solutions/)[https://discuss.leetcode.com/topic/1881/all-sentence-sol...](https://discuss.leetcode.com/topic/1881/all-sentence-solutions/)[,"department.loc[lambda x: x['room']==268, 'dphone']"
give me the phones corresponding to departments in room 268.,"department.loc[lambda x: x['room']==268, 'dphone']"
"return me the count of students having at least one grade of ""b"".","enrolled_in.loc[enrolled_in['grade'] == 'b', 'stuid'].nunique()"
"what is the number of students that have at least one ""b"" grade?","enrolled_in.loc[enrolled_in['grade'] == 'b', 'stuid'].nunique()"
provide me with the minimum and maximum grade points for letter grade.,"gradeconversion.agg({'gradepoint': ['max', 'min']})"
what is the maximum of grade points and what is the minimum of grade points?,"gradeconversion.agg({'gradepoint': ['max', 'min']})"
"return me the names of students whose first names contain the letter ""a"".","student.loc[lambda x: x['fname'].str.contains('a'), 'fname'].unique()"
"write the first names of students that have an ""a"" in their first names.","student.loc[lambda x: x['fname'].str.contains('a'), 'fname'].unique()"
give me the first and last name of male faculty that resides in building neb.,"faculty.loc[(faculty['sex'] == 'm') & (faculty['building'] == 'neb'), ['fname', 'lname']]"
identify the full names of faculty members with sex m and who live in building neb,"faculty.loc[(faculty['sex'] == 'm') & (faculty['building'] == 'neb'), ['fname', 'lname']]"
list the names of rooms that belong to faculties with professor rank and live in building neb.,"faculty.loc[(faculty['rank'] == 'professor') & (faculty['building'] == 'neb'), 'room']"
list the departments of professors in the faculty who live in neb building.,"faculty.loc[(faculty['rank'] == 'professor') & (faculty['building'] == 'neb'), 'room']"
"what could you give me the department that is situated in ""mergenthaler""?","department.loc[lambda x: x['building']=='mergenthaler', 'dname']"
what is the title for the department in the building mergenthaler?,"department.loc[lambda x: x['building']=='mergenthaler', 'dname']"
produce a report of courses sorted by credits in the ascending order.,course.sort_values('credits')
please arrange the information of all courses in order of their credits ascending.,course.sort_values('credits')
list the course titles of programs sorted by credits.,course.sort_values('credits')['cname']
what is the order by credits of course names that were taught?,course.sort_values('credits')['cname']
list the names of students who are in the descending order of age.,"student.sort_values('age', ascending=false)['fname']"
"derive the names of students, arranged by age from greatest to least.","student.sort_values('age', ascending=false)['fname']"
retrieve the surnames of female students in descending order of age.,"student.loc[lambda x: x['sex']=='f'].sort_values('age', ascending=false)['lname']"
"provide me with a list of last names of female students, ordered from youngest to oldest.","student.loc[lambda x: x['sex']=='f'].sort_values('age', ascending=false)['lname']"
please sort the surnames of the faculty members in building barton in alphabetical order.,faculty.loc[lambda x: x['building']=='barton'].sort_values('lname')['lname']
"please sort the last name of all the faculty members residing in building barton, based on their last names.",faculty.loc[lambda x: x['building']=='barton'].sort_values('lname')['lname']
return the names corresponding to the first founders of the professorial ranks in alphabetical order.,faculty.loc[faculty['rank']=='professor'].sort_values('fname')['fname']
return the names of departments that has the largest number of students that declared minoring in these fields.,"department.merge(minor_in, on='dno').groupby('dname').size().sort_values(ascending=false).index[0]"
what is the name of the department in which most students minor?,"department.merge(minor_in, on='dno').groupby('dname').size().sort_values(ascending=false).index[0]"
list out the departments that have no students minored in.,department['dname'].loc[~department['dno'].isin(minor_in['dno'])]
what is the name of the department that does not have at least one student majoring in it?,department['dname'].loc[~department['dno'].isin(minor_in['dno'])]
"respectively, retrieve the name of the department that has the fewest members.","pd.merge(department, member_of, on='dno').groupby('dname').size().sort_values().index[0]"
what is the name of the department that has the fewest number of members?,"pd.merge(department, member_of, on='dno').groupby('dname').size().sort_values().index[0]"
determine the rank of the faculty that the fewest faculties belong to.,faculty.groupby('rank').size().sort_values().index[0]
what is the least common faculty position rank?,faculty.groupby('rank').size().sort_values().index[0]
gather the names and first and last initials of the top 3 instructors who teach the highest number of courses.,"course.merge(faculty, left_on='instructor', right_on='facid').groupby(['instructor', 'fname', 'lname'], as_index=false).size().rename(columns={'size': 'num_courses'}).sort_values('num_courses', ascending=false).iloc[:3, [1, 2]]"
what is the list of three instructors that teach the most courses?,"course.merge(faculty, left_on='instructor', right_on='facid').groupby(['instructor', 'fname', 'lname'], as_index=false).size().rename(columns={'size': 'num_courses'}).sort_values('num_courses', ascending=false).iloc[:3, [1, 2]]"
which building does the instructor who teaches the largest number of courses reside in?,"course.merge(faculty, left_on='instructor', right_on='facid').groupby('instructor')['building'].first().value_counts().index[0]"
return the building of the teacher who conducts the greatest number of lessons.,"course.merge(faculty, left_on='instructor', right_on='facid').groupby('instructor')['building'].first().value_counts().index[0]"
what is the number of courses having at least five enrollments?,"pd.merge(course, enrolled_in, on='cid').groupby('cid').filter(lambda x: len(x) >= 5)['cname']"
provide me the titles of courses with at least five enrollments.,"pd.merge(course, enrolled_in, on='cid').groupby('cid').filter(lambda x: len(x) >= 5)['cname']"
retrieve the top row and first column of the dataset containing the course name and instructor name.,"pd.merge(course, faculty, left_on='instructor', right_on='facid').loc[lambda x: x['cname']=='computer literacy', ['fname', 'lname']]"
what is the moniker of the instructor who has the course named computer literacy?,"pd.merge(course, faculty, left_on='instructor', right_on='facid').loc[lambda x: x['cname']=='computer literacy', ['fname', 'lname']]"
retrieve the name of the course and the name of the department and the room in which the course has commenced.,"pd.merge(course.loc[course['cname'] == ""introduction to computer science""], department, left_on='dno', right_on='dno')[['dname', 'room']]"
please find the department name and room number for introduction to computer science.,"pd.merge(course.loc[course['cname'] == ""introduction to computer science""], department, left_on='dno', right_on='dno')[['dname', 'room']]"
"retrieve the names of students, along with their corresponding grades.","enrolled_in.merge(gradeconversion, left_on='grade', right_on='lettergrade').merge(student, on='stuid')[['fname', 'lname', 'gradepoint']]"
calculate the number of distinct first names of all students who have obtained grade point at least 3.8 in at least one course.,"pd.merge(pd.merge(enrolled_in, gradeconversion, on='lettergrade'), student, on='stuid').loc[lambda x: x['gradepoint'] >= 3.8, 'fname'].unique()"
what distinct first names are possessed by students who attained a gpa of 3.8 or above in at least one course?,"pd.merge(pd.merge(enrolled_in, gradeconversion, on='lettergrade'), student, on='stuid').loc[lambda x: x['gradepoint'] >= 3.8, 'fname'].unique()"
retrieve the complete names of faculty that are a part of the department of pharmacy with department number 520.,"pd.merge(faculty, member_of, on='facid').loc[lambda x: x['dno']==520, ['fname', 'lname']]"
what are the full names of faculty members who are part of department 520?,"pd.merge(faculty, member_of, on='facid').loc[lambda x: x['dno']==520, ['fname', 'lname']]"
list the first names and last names of the students that are majoring in the department of dno 140.,"pd.merge(minor_in.loc[minor_in['dno']==140, ['stuid']], student, on='stuid')[['fname', 'lname']]"
provide me the roster of students majoring in department 140 with a minor into.,"pd.merge(minor_in.loc[minor_in['dno']==140, ['stuid']], student, on='stuid')[['fname', 'lname']]"
retrieve the last names of professors who are members of computer science department.,"pd.merge(pd.merge(department.loc[lambda x: x['dname']=='computer science'], member_of, on='dno'), faculty, on='facid')['lname']"
retrieve the last names of faculty in the computer science department.,"pd.merge(pd.merge(department.loc[lambda x: x['dname']=='computer science'], member_of, on='dno'), faculty, on='facid')['lname']"
fetch the gpa of pupils whose last name is smith.,"enrolled_in.merge(gradeconversion, left_on='grade', right_on='lettergrade').merge(student, on='stuid').loc[lambda x: x['lname']=='smith', 'gradepoint'].mean()"
determine the average grade-point for subjects having the last name smith.,"enrolled_in.merge(gradeconversion, left_on='grade', right_on='lettergrade').merge(student, on='stuid').loc[lambda x: x['lname']=='smith', 'gradepoint'].mean()"
what is the highest and lowest grade point earned by students who reside in new york city?,"pd.merge(pd.merge(enrolled_in, gradeconversion, left_on='grade', right_on='lettergrade'), student, on='stuid').loc[lambda x: x['city_code']=='nyc', 'gradepoint'].agg(['max', 'min'])"
give the maximum and minimum gradepoints for students living in new york city.,"pd.merge(pd.merge(enrolled_in, gradeconversion, left_on='grade', right_on='lettergrade'), student, on='stuid').loc[lambda x: x['city_code']=='nyc', 'gradepoint'].agg(['max', 'min'])"
"convert the courses in which either 3 credits or 1 credit is earned but 4 hours are studied, to title.","pd.concat([course.loc[lambda x: x['credits']==3, 'cname'] , course.loc[lambda x: (x['credits']==1) & (x['hours']==4), 'cname'] ]).drop_duplicates()"
"which courses provide either 3 credits, or 1 credit and 4 hours?","pd.concat([course.loc[lambda x: x['credits']==3, 'cname'] , course.loc[lambda x: (x['credits']==1) & (x['hours']==4), 'cname'] ]).drop_duplicates()"
retrieve the titles of departments that belong to either division as or division en and building neb.,"pd.concat([department.loc[lambda x: x['division'] == 'as', 'dname'], department.loc[lambda x: (x['division'] == 'en') & (x['building'] == 'neb'), 'dname']]).drop_duplicates()"
"determine the names of departments that are located in division as, division en, and in building neb.","pd.concat([department.loc[lambda x: x['division'] == 'as', 'dname'], department.loc[lambda x: (x['division'] == 'en') & (x['building'] == 'neb'), 'dname']]).drop_duplicates()"
provide me the names of students who are not enrolled in any course.,"student.loc[~student['stuid'].isin(enrolled_in['stuid']), 'fname']"
which names are the first names of students that are not included in any courses?,"student.loc[~student['stuid'].isin(enrolled_in['stuid']), 'fname']"
list the ids of the top three products that were bought by the largest number of people.,"product_suppliers.sort_values('total_amount_purchased', ascending=false)['product_id'].iloc[:3]"
provide me with the ids of products that have been bought in the largest quantities.,"product_suppliers.sort_values('total_amount_purchased', ascending=false)['product_id'].iloc[:3]"
determine the product id and product type of the cheapest product.,"products[['product_id', 'product_type_code']].sort_values('product_price').head(1)"
give the id and product type of the product that has the lowest price.,"products[['product_id', 'product_type_code']].sort_values('product_price').head(1)"
please return the total number of different product types.,products['product_type_code'].nunique()
determine the total number of distinct product categories.,products['product_type_code'].nunique()
please provide me with the postal address of customer id 10.,"addresses.merge(customer_addresses.query('customer_id==10'), on='address_id')['address_details']"
please provide me with the complete address for the customer with id 10.,"addresses.merge(customer_addresses.query('customer_id==10'), on='address_id')['address_details']"
display all staffs with the department manager job title and their ids and genders,"staff_department_assignments[staff_department_assignments['job_title_code']=='department manager'].merge(staff[['staff_id', 'staff_gender']], on='staff_id')[['staff_id', 'staff_gender']]"
provide me with the staff members' ids and genders that have the title department manager.,"staff_department_assignments[staff_department_assignments['job_title_code']=='department manager'].merge(staff[['staff_id', 'staff_gender']], on='staff_id')[['staff_id', 'staff_gender']]"
show the count of customers who use each different payment method.,customers.groupby('payment_method_code').size().reset_index(name='count')
which payment methods are availed by customers?,customers.groupby('payment_method_code').size().reset_index(name='count')
what is the name of the item that was ordered by customers most often?,order_items['product_id'].value_counts().index[0]
please provide the product id for the item that was ordered most often.,order_items['product_id'].value_counts().index[0]
"fetch the id, phone number and email address of the customer who made the highest number of purchases.","pd.merge(customers, customer_orders, on='customer_id').groupby('customer_id').agg({'customer_name':'first', 'customer_phone':'first', 'customer_email':'first'}).sort_values(by='count', ascending=false).iloc[0][['customer_name','customer_phone','customer_email']]"
"please provide me with the name, phone number and email address of a customer who placed the maximum number of orders.","pd.merge(customers, customer_orders, on='customer_id').groupby('customer_id').agg({'customer_name':'first', 'customer_phone':'first', 'customer_email':'first'}).sort_values(by='count', ascending=false).iloc[0][['customer_name','customer_phone','customer_email']]"
what are the prices for each type of product?,products.groupby('product_type_code')['product_price'].mean()
please provide me with the average sale price of each product type.,products.groupby('product_type_code')['product_price'].mean()
how many department stores does the south mall have?,"pd.merge(department_stores, department_store_chain, on='dept_store_chain_id').loc[lambda x: x['dept_store_chain_name']=='south'].shape[0]"
determine the count of stores operated by south.,"pd.merge(department_stores, department_store_chain, on='dept_store_chain_id').loc[lambda x: x['dept_store_chain_name']=='south'].shape[0]"
retrieve the name and job title of the staff who was allocated the latest.,"pd.merge(staff, staff_department_assignments, on='staff_id').sort_values('date_assigned_to', ascending=false).iloc[0][['staff_name', 'job_title_code']]"
please provide me with the name and job title of the staffer assigned to the project the latest.,"pd.merge(staff, staff_department_assignments, on='staff_id').sort_values('date_assigned_to', ascending=false).iloc[0][['staff_name', 'job_title_code']]"
"obtain the title, type and price for all products supplied by supplier identification number 3.","pd.merge(product_suppliers[product_suppliers['supplier_id']==3], products, on='product_id')[['product_type_code', 'product_name', 'product_price']]"
"please provide me with a customer id ordered product list, where the order status contains the word ""pending"".","pd.merge(customers, customer_orders.loc[lambda x: x['order_status_code']=='pending'], on='customer_id')['customer_name'].sort_values().unique()"
"please provide me with an account of customer with the order status of ""pending"".","pd.merge(customers, customer_orders.loc[lambda x: x['order_status_code']=='pending'], on='customer_id')['customer_name'].sort_values().unique()"
list the names of customer who have both new and pending orders.,"pd.merge(customers.loc[lambda x: x['customer_id'].isin(customer_orders.loc[lambda x: x['order_status_code']=='new', 'customer_id'])][['customer_name', 'customer_address']], customers.loc[lambda x: x['customer_id'].isin(customer_orders.loc[lambda x: x['order_status_code']=='pending', 'customer_id'])][['customer_name', 'customer_address']]).drop_duplicates()"
give me the names and addresses of customers having both new and pending orders.,"pd.merge(customers.loc[lambda x: x['customer_id'].isin(customer_orders.loc[lambda x: x['order_status_code']=='new', 'customer_id'])][['customer_name', 'customer_address']], customers.loc[lambda x: x['customer_id'].isin(customer_orders.loc[lambda x: x['order_status_code']=='pending', 'customer_id'])][['customer_name', 'customer_address']]).drop_duplicates()"
give me the ids of products that are supplied by supplier id 2 and are more expensive than the average price of all the products.,products.merge(product_suppliers[product_suppliers['supplier_id'] == 2])[lambda x: x['product_price'] > x['product_price'].mean()]['product_id']
for which supplier's products is their product more expensive than the average price of all products?,products.merge(product_suppliers[product_suppliers['supplier_id'] == 2])[lambda x: x['product_price'] > x['product_price'].mean()]['product_id']
what was the name of department store that possessed both marketing and management departments?,"pd.merge(departments.loc[lambda x: x['department_name']=='marketing'], department_stores, on='dept_store_id')[['dept_store_id', 'store_name']].merge(departments.loc[lambda x: x['department_name']=='managing'], on='dept_store_id', how='inner')[['dept_store_id', 'store_name']]"
what is the total number of department stores that have both marketing and management departments?,"pd.merge(departments.loc[lambda x: x['department_name']=='marketing'], department_stores, on='dept_store_id')[['dept_store_id', 'store_name']].merge(departments.loc[lambda x: x['department_name']=='managing'], on='dept_store_id', how='inner')[['dept_store_id', 'store_name']]"
provide me with the website ids of the two department store chains with the highest number of locations.,department_stores.groupby('dept_store_chain_id').size().sort_values(ascending=false).head(2).index.tolist()
provide the ids of the two department stores chains that have the most number of branches.,department_stores.groupby('dept_store_chain_id').size().sort_values(ascending=false).head(2).index.tolist()
what is the id of the department with the least number of staff members?,staff_department_assignments['department_id'].value_counts().sort_values().index[0]
provide me with the id of the department that possesses the fewest staff.,staff_department_assignments['department_id'].value_counts().sort_values().index[0]
"for each product type, provide the information related to the maximum and minimum price.","products.groupby('product_type_code')['product_price'].agg(['max', 'min'])"
what is the minimum and maximum product price for each distinct product type?,"products.groupby('product_type_code')['product_price'].agg(['max', 'min'])"
identify the product type whose average unit price is higher than the average price of all products.,products.groupby('product_type_code').filter(lambda x: x['product_price'].mean() > products['product_price'].mean())['product_type_code'].unique()
what are the product types with a pricing higher than the average pricing of all the products?,products.groupby('product_type_code').filter(lambda x: x['product_price'].mean() > products['product_price'].mean())['product_type_code'].unique()
please find the id and name of the employee who has been assigned for the shortest duration.,"pd.merge(staff, staff_department_assignments, on='staff_id').assign(difference=lambda x: x['date_assigned_to'] - x['date_assigned_from']).sort_values('difference').iloc[0][['staff_id', 'staff_name']]"
what is the id and full-name of the staff who has been assigned for the least amount of time?,"pd.merge(staff, staff_department_assignments, on='staff_id').assign(difference=lambda x: x['date_assigned_to'] - x['date_assigned_from']).sort_values('difference').iloc[0][['staff_id', 'staff_name']]"
please return the names and corresponding ids of all items whose price ranges between 600 and 700.,"products.loc[lambda x: (x['product_price'] >= 600) & (x['product_price'] <= 700), ['product_name', 'product_id']]"
return me the ids and names of the products whose price range is between 600 and 700.,"products.loc[lambda x: (x['product_price'] >= 600) & (x['product_price'] <= 700), ['product_name', 'product_id']]"
please list all distinct customers whose orders were canceled after certain previous canceled orders.,"customer_orders.loc[lambda x: x['order_date'] > customer_orders.loc[lambda x: x['order_status_code'] == 'cancelled', 'order_date'].min(), 'customer_id'].unique()"
determine the distinct ids of customers whose order after any order that was cancelled.,"customer_orders.loc[lambda x: x['order_date'] > customer_orders.loc[lambda x: x['order_status_code'] == 'cancelled', 'order_date'].min(), 'customer_id'].unique()"
what is id of the employee who had been assigned as the staff department earlier than any clerical staff?,staff_department_assignments[staff_department_assignments['date_assigned_to'] < staff_department_assignments[staff_department_assignments['job_title_code']=='clerical staff']['date_assigned_to'].max()]['staff_id']
please provide me with the id of an employee whose staff department assignment was earlier than that of any clerical staff.,staff_department_assignments[staff_department_assignments['date_assigned_to'] < staff_department_assignments[staff_department_assignments['job_title_code']=='clerical staff']['date_assigned_to'].max()]['staff_id']
"what is the number of customers who have an address which contains the letter ""t""?","customers.loc[lambda x: x['customer_address'].str.contains('tn'), ['customer_name', 'customer_id']]"
provide me with the names and ids of customers who have tn in their addresses.,"customers.loc[lambda x: x['customer_address'].str.contains('tn'), ['customer_name', 'customer_id']]"
please provide me with the first and last name and gender of the employees that were assigned to duty in 2016.,"pd.merge(staff, staff_department_assignments, on='staff_id').loc[lambda x: x['date_assigned_from'].str.startswith('2016'), ['staff_name', 'staff_gender']]"
retrieve the name and gender of staff assigned in 2016.,"pd.merge(staff, staff_department_assignments, on='staff_id').loc[lambda x: x['date_assigned_from'].str.startswith('2016'), ['staff_name', 'staff_gender']]"
what are the names for those members who have been assigned multiple tasks?,"pd.merge(staff, staff_department_assignments, on='staff_id').groupby('staff_id').filter(lambda x: len(x) > 1)['staff_name']"
provide me with the name list of all staff assigned multiple tasks.,"pd.merge(staff, staff_department_assignments, on='staff_id').groupby('staff_id').filter(lambda x: len(x) > 1)['staff_name']"
please provide me with an alphabetical list of suppliers along with their respective name and phone numbers.,"pd.merge(pd.merge(suppliers, supplier_addresses, on='supplier_id'), addresses, on='address_id').sort_values('address_details')[['supplier_name', 'supplier_phone']]"
"could you provide the names and phone numbers for all suppliers, sorted in alphabetical order of their addresses?","pd.merge(pd.merge(suppliers, supplier_addresses, on='supplier_id'), addresses, on='address_id').sort_values('address_details')[['supplier_name', 'supplier_phone']]"
please provide me with the phone numbers of all customers and suppliers.,"pd.concat([customers['customer_phone'], suppliers['supplier_phone']]).unique()"
please provide me with the phone numbers for all customers and suppliers.,"pd.concat([customers['customer_phone'], suppliers['supplier_phone']]).unique()"
please expose to me the ranks of products whose orders exceeded three or whose supply exceeded eighty thousand.,"pd.concat([order_items.groupby('product_id').filter(lambda x: len(x) > 3)['product_id'].drop_duplicates(),product_suppliers.groupby('product_id').filter(lambda x: x['total_amount_purchased'].sum() > 80000)['product_id'].drop_duplicates()]).drop_duplicates()"
please provide me with the ids of products that have an overall purchase amount exceeding 80000 or its orders placed more than 3.,"pd.concat([order_items.groupby('product_id').filter(lambda x: len(x) > 3)['product_id'].drop_duplicates(),product_suppliers.groupby('product_id').filter(lambda x: x['total_amount_purchased'].sum() > 80000)['product_id'].drop_duplicates()]).drop_duplicates()"
"provide me with the id and name of the products that cost less than $600, or if the cost is more than $900.","products.loc[(products['product_price'] < 600) | (products['product_price'] > 900), ['product_id', 'product_name']]"
provide the ids as well as names of products whose prices are less than or equal to 600 and/or greater than or equal to 900.,"products.loc[(products['product_price'] < 600) | (products['product_price'] > 900), ['product_id', 'product_name']]"
retrieve the ids of suppliers whose average amount purchased for each product exceeds 50000 or falls below 30000.,product_suppliers.groupby('supplier_id')['total_amount_purchased'].mean().loc[lambda x: (x>50000) | (x<30000)].index.tolist()
which suppliers have an average purchase amount that is either higher than 50000 or lower than 30000?,product_suppliers.groupby('supplier_id')['total_amount_purchased'].mean().loc[lambda x: (x>50000) | (x<30000)].index.tolist()
in which supplier did most products get provided and how much are the average purchase price and purchase price?,"product_suppliers[product_suppliers['supplier_id'] == product_suppliers.groupby('supplier_id').size().sort_values(ascending=false).index[0]][['total_amount_purchased', 'total_value_purchased']].mean()"
provide me the average salary and average amount paid for suppliers who supply the maximum number of products.,"product_suppliers[product_suppliers['supplier_id'] == product_suppliers.groupby('supplier_id').size().sort_values(ascending=false).index[0]][['total_amount_purchased', 'total_value_purchased']].mean()"
"determine the id that is shared by the largest number of customers, and the id shared by the smallest number of customers.","customers['customer_code'].agg(['max', 'min'])"
provide me with the customer ids that are assigned to either the maximum or minimum of customer codes.,"customers['customer_code'].agg(['max', 'min'])"
enumerate the names of all the distinct customers that purchased a keyboard.,"pd.merge(pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').loc[lambda x: x['product_name'] == 'keyboard', 'customer_name'].unique()"
find the names of customers that have purchased a keyboard.,"pd.merge(pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').loc[lambda x: x['product_name'] == 'keyboard', 'customer_name'].unique()"
list the names of suppliers that provide red jeans as well as the corresponding phone numbers.,"pd.merge(pd.merge(suppliers, product_suppliers, on='supplier_id'), products, on='product_id').loc[lambda x: x['product_name']=='red jeans', ['supplier_name', 'supplier_phone']].drop_duplicates()"
provide me with the names and phone numbers for suppliers that have red jeans.,"pd.merge(pd.merge(suppliers, product_suppliers, on='supplier_id'), products, on='product_id').loc[lambda x: x['product_name']=='red jeans', ['supplier_name', 'supplier_phone']].drop_duplicates()"
"what are the highest and lowest prices of products, grouped by product type, and in alphabetical order?","products.groupby('product_type_code')['product_price'].agg(['max', 'min']).reset_index()"
"provide me with the maximum and minimum prices for each product type, grouped by product type.","products.groupby('product_type_code')['product_price'].agg(['max', 'min']).reset_index()"
"please provide me with the id and customer number for orders whose status is cancelled, ordered chronologically.","customer_orders.loc[lambda x: x['order_status_code']=='cancelled', ['order_id', 'customer_id']].sort_values('order_date')"
"please sort the cancelled orders by their order dates, and then provide me with the order id and customer id.","customer_orders.loc[lambda x: x['order_status_code']=='cancelled', ['order_id', 'customer_id']].sort_values('order_date')"
return a list that contains the names of products that were acquired by at least two different consumers.,"pd.merge(pd.merge(customer_orders, order_items, on='order_id'), products, on='product_id').groupby('product_id').filter(lambda x: x['customer_id'].nunique() >= 2)['product_name'].unique()"
list the distinct names of products purchased by at least two different customers.,"pd.merge(pd.merge(customer_orders, order_items, on='order_id'), products, on='product_id').groupby('product_id').filter(lambda x: x['customer_id'].nunique() >= 2)['product_name'].unique()"
retrieve the names of customers that have bought at least three different products from the company.,"pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id').groupby('customer_name').apply(lambda x: x['product_id'].nunique() >= 3).loc[lambda x: x].index"
retrieve the distinct names of customers who have purchased at least three different products.,"pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id').groupby('customer_name').apply(lambda x: x['product_id'].nunique() >= 3).loc[lambda x: x].index"
obtain the ids of employees who have been assigned the job of sales person but never clerical staff along with their gender.,"pd.merge(staff.loc[lambda x: x['job_title_code']=='sales person', ['staff_id', 'staff_name', 'staff_gender']],staff_department_assignments.loc[lambda x: x['job_title_code']=='sales person', 'staff_id']).drop_duplicates().merge(staff.loc[lambda x: x['job_title_code']=='clerical staff'].drop(columns='job_title_code'), how='left', on='staff_id').drop_duplicates().loc[lambda x: x['job_title_code'].isna()].loc[:, ['staff_name', 'staff_gender']]"
"which titles owned by sales person have been held by staff with the present or previous status ""clerical staff""?","pd.merge(staff.loc[lambda x: x['job_title_code']=='sales person', ['staff_id', 'staff_name', 'staff_gender']],staff_department_assignments.loc[lambda x: x['job_title_code']=='sales person', 'staff_id']).drop_duplicates().merge(staff.loc[lambda x: x['job_title_code']=='clerical staff'].drop(columns='job_title_code'), how='left', on='staff_id').drop_duplicates().loc[lambda x: x['job_title_code'].isna()].loc[:, ['staff_name', 'staff_gender']]"
find the ids and names of customers whose address contains the state of wyoming and do not use credit cards for making payments.,"customers.loc[(customers['customer_address'].str.contains('wy')) & (customers['payment_method_code'] != 'credit card'), ['customer_id', 'customer_name']]"
"retrieve the titles of customers with names containing wy, who do not use a credit card, and address.","customers.loc[(customers['customer_address'].str.contains('wy')) & (customers['payment_method_code'] != 'credit card'), ['customer_id', 'customer_name']]"
obtain the weighted average price of all the clothes sold by products.,"products.loc[lambda x: x['product_type_code']=='clothes', 'product_price'].mean()"
what is the average price of clothing?,"products.loc[lambda x: x['product_type_code']=='clothes', 'product_price'].mean()"
identify the name of the most expensive computer hardware product.,"products.loc[lambda x: x['product_type_code']=='hardware'].sort_values('product_price', ascending=false)['product_name'].iloc[0]"
please provide me with the name of the hardware product with the highest price tag.,"products.loc[lambda x: x['product_type_code']=='hardware'].sort_values('product_price', ascending=false)['product_name'].iloc[0]"
what was the total number of aircrafts?,aircraft.shape[0]
what is the count of aircraft?,aircraft.shape[0]
provide the metadata about all aircrafts.,aircraft['description']
retrieve the descriptions of aircrafts.,aircraft['description']
how many international passengers found at all airports?,airport['international_passengers'].mean()
what is the average of international passengers for an airport?,airport['international_passengers'].mean()
"how many domestic and international passengers have passed through the airport named london ""heathrow""?","airport.loc[lambda x: x['airport_name']=='london heathrow', ['international_passengers', 'domestic_passengers']]"
what is the count of passengers arriving at and departing from the airport london heathrow?,"airport.loc[lambda x: x['airport_name']=='london heathrow', ['international_passengers', 'domestic_passengers']]"
"how many domestic passengers in total are boarded at airports that contain the word ""london"" in them?","airport.loc[airport['airport_name'].str.contains('london', case=false), 'domestic_passengers'].sum()"
determine the total number of domestic passengers at all london airports.,"airport.loc[airport['airport_name'].str.contains('london', case=false), 'domestic_passengers'].sum()"
how many transit passengers did the maximum and minimum number in all airports?,"airport['transit_passengers'].agg(['max', 'min'])"
please provide me with the maximum and minimum count of total passengers for all airports.,"airport['transit_passengers'].agg(['max', 'min'])"
what titles of pilots whose ages are 25 or over do i have?,"pilot.loc[pilot['age'] >= 25, 'name']"
list the names of the pilots who are at least 25 years old.,"pilot.loc[pilot['age'] >= 25, 'name']"
in which order are the names of pilots arranged?,pilot.sort_values('name')['name']
order the names of pilots alphabetically.,pilot.sort_values('name')['name']
are there any pilots younger than 30 in descending alphabetical order?,"pilot.loc[lambda x: x['age']<=30].sort_values('name', ascending=false)['name']"
what are the names of pilots 30 years of age or under down in their order of names?,"pilot.loc[lambda x: x['age']<=30].sort_values('name', ascending=false)['name']"
please show the title of airplanes associated with london gatwick international airport.,"pd.merge(pd.merge(aircraft, airport_aircraft, on='aircraft_id'), airport, on='airport_id').loc[lambda x: x['airport_name']=='london gatwick', 'aircraft']"
retrieve the names of the aircrafts related to london gatwick airport.,"pd.merge(pd.merge(aircraft, airport_aircraft, on='aircraft_id'), airport, on='airport_id').loc[lambda x: x['airport_name']=='london gatwick', 'aircraft']"
please list the names of aircrafts associated with airports that accommodate more than 10 million passengers.,"pd.merge(pd.merge(aircraft, airport_aircraft, on='aircraft_id'), airport, on='airport_id').query('total_passengers > 10000000')[['aircraft', 'description']]"
"please find the titles of aircrafts associated with an airport that has a greater number of total passengers than 10,000,000.","pd.merge(pd.merge(aircraft, airport_aircraft, on='aircraft_id'), airport, on='airport_id').query('total_passengers > 10000000')[['aircraft', 'description']]"
"what is the average of the total number of passengers of airports that are associated with aircraft ""robinson r-22""?","pd.merge(pd.merge(aircraft, airport_aircraft, on='aircraft_id'), airport, on='airport_id').loc[lambda x: x['aircraft']=='robinson r-22', 'total_passengers'].mean()"
"what is the mean total number of passengers for all airports visited by the aircraft  ""robinson r-22""?","pd.merge(pd.merge(aircraft, airport_aircraft, on='aircraft_id'), airport, on='airport_id').loc[lambda x: x['aircraft']=='robinson r-22', 'total_passengers'].mean()"
please provide me with the location and aircraft name that won.,"pd.merge(aircraft, match, left_on='aircraft_id', right_on='winning_aircraft')[['location', 'aircraft']]"
what is the location of the winning aircraft as well as its name?,"pd.merge(aircraft, match, left_on='aircraft_id', right_on='winning_aircraft')[['location', 'aircraft']]"
which aircraft has been named winning aircraft the most number of times?,"pd.merge(aircraft, match, left_on='aircraft_id', right_on='winning_aircraft').groupby('winning_aircraft')['aircraft'].count().sort_values(ascending=false).index[0]"
what is the name of the aircraft which has won the maximum awards?,"pd.merge(aircraft, match, left_on='aircraft_id', right_on='winning_aircraft').groupby('winning_aircraft')['aircraft'].count().sort_values(ascending=false).index[0]"
provide me with the titles of all aircraft along with their corresponding win count.,"pd.merge(aircraft, match, left_on='aircraft_id', right_on='winning_aircraft').groupby('winning_aircraft').agg({'aircraft':'first', '*':'count'}).rename(columns={'*':'count'}).reset_index()[['aircraft', 'count']]"
find the names of all pilots in descending order of age.,"pilot.sort_values('age', ascending=false)['name']"
provide to me a list of pilots by name and age.,"pilot.sort_values('age', ascending=false)['name']"
please list the names of aircrafts that won at least twice.,"aircraft.loc[aircraft['aircraft_id'].isin(match['winning_aircraft'].value_counts()[match['winning_aircraft'].value_counts()>=2].index), 'aircraft'].unique()"
what is the list of names of airplanes that have won a competition at least twice?,"aircraft.loc[aircraft['aircraft_id'].isin(match['winning_aircraft'].value_counts()[match['winning_aircraft'].value_counts()>=2].index), 'aircraft'].unique()"
list the names of the aircrafts that failed to win any match.,"aircraft.loc[~aircraft['aircraft_id'].isin(match['winning_aircraft']), 'aircraft']"
reveal the names for all aircrafts that have never won a match.,"aircraft.loc[~aircraft['aircraft_id'].isin(match['winning_aircraft']), 'aircraft']"
"enumerate the names of aircrafts that are associated with both an airfield named ""london heathrow"" and an airfield named ""london gatwick""","pd.merge(pd.merge(airport_aircraft.loc[airport_aircraft['airport_id'].isin(airport.query('airport_name == ""london heathrow""').index), 'aircraft_id'], aircraft, on='aircraft_id'), airport_aircraft.loc[airport_aircraft['airport_id'].isin(airport.query('airport_name == ""london gatwick""').index), 'aircraft_id'], on='aircraft_id')['aircraft']"
retrieve the titles of the aircrafts associated with both london heathrow and gatwick airports.,"pd.merge(pd.merge(airport_aircraft.loc[airport_aircraft['airport_id'].isin(airport.query('airport_name == ""london heathrow""').index), 'aircraft_id'], aircraft, on='aircraft_id'), airport_aircraft.loc[airport_aircraft['airport_id'].isin(airport.query('airport_name == ""london gatwick""').index), 'aircraft_id'], on='aircraft_id')['aircraft']"
provide me with the information on airports that possess the largest international passenger count.,"airport.sort_values('international_passengers', ascending=false).iloc[:1]"
retrieve the data associated with the airport with the largest number of international passengers.,"airport.sort_values('international_passengers', ascending=false).iloc[:1]"
determine the name and age of the pilots who won the highest number of times among the pilots who are younger than 30.,"pilot[pilot['age'] < 30].merge(match, left_on='pilot_id', right_on='winning_pilot').groupby(['winning_pilot', 'name', 'age']).size().nlargest(1).reset_index()[['name', 'age']]"
what are the name and age of the pilots younger than 30 who have won the most times?,"pilot[pilot['age'] < 30].merge(match, left_on='pilot_id', right_on='winning_pilot').groupby(['winning_pilot', 'name', 'age']).size().nlargest(1).reset_index()[['name', 'age']]"
"please provide me the name and age of the youngest winner of ""top gun"" contest.","pd.merge(pilot, match, left_on='pilot_id', right_on='winning_pilot').sort_values('age').iloc[0][['name', 'age']]"
please specify the age of the youngest pilot who ever won a race.,"pd.merge(pilot, match, left_on='pilot_id', right_on='winning_pilot').sort_values('age').iloc[0][['name', 'age']]"
search the names of the pilots who did not win any matches held in australia.,"pilot.loc[~pilot['pilot_id'].isin(match.loc[match['country']=='australia', 'winning_pilot']),'name']"
provide me with the titles of those pilots who have not won any matches in australia.,"pilot.loc[~pilot['pilot_id'].isin(match.loc[match['country']=='australia', 'winning_pilot']),'name']"
how many residents belong to each property? list property id and number of residents.,"residents.groupby('property_id').size().reset_index(name='count').merge(properties, on='property_id')[['property_id', 'count']]"
which service types are provided by the organization of which the name is 'denesik and sons party'?,"services.merge(organizations, on='organization_id').loc[lambda x: x['organization_details']=='denesik and sons party', 'service_type_code'].unique()"
"list for each resident, their id, details, and total count of the services requested in descending order.","pd.merge(residents, residents_services, on='resident_id').groupby(['resident_id', 'other_details']).size().reset_index(name='count').sort_values(by='count', ascending=false)[['resident_id', 'other_details', 'count']]"
"what is the maximum number of times that a certain service is provided? provide the service id, details and count.","services.merge(residents_services, on='service_id').groupby(['service_id', 'service_details']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
"provide me with the id and type of each entity, along with the description of the organization that owns it.","pd.merge(things, organizations, on='organization_id')[['thing_id', 'type_of_thing_code', 'organization_details']]"
could you provide me with the id and the details about the customers who have had at least 3 events?,"customers.merge(customer_events, on='customer_id').groupby(['customer_id', 'customer_details']).filter(lambda x: len(x) >= 3)[['customer_id', 'customer_details']].drop_duplicates()"
retrieve each customer's moving-in date along with the associated customer id and details.,"pd.merge(customers, customer_events, on='customer_id')[['date_moved_in', 'customer_id', 'customer_details']]"
what are the events that contain the number of notes between one and three? list the event id and the property id.,"pd.merge(customer_events, customer_event_notes, on='customer_event_id').groupby('customer_event_id').filter(lambda x: 1<=len(x)<=3)[['customer_event_id', 'property_id']]"
give the distinct id and type of things having the status 'close' or having a status record ahead of the date '2017-06-19 02:59:21'.,"pd.merge(timed_status_of_things, things, on='thing_id').loc[(timed_status_of_things['status_of_thing_code']=='close') | (timed_status_of_things['date_and_date'] < '2017-06-19 02:59:21'), ['thing_id', 'type_of_thing_code']].drop_duplicates()"
what locations did things with service detail 'unsatisfied' have been uncovered in?,"pd.merge(things, timed_locations_of_things, on='thing_id').loc[lambda x: x['service_details']=='unsatisfied', 'location_code'].nunique()"
provide with me the number of status codes of objects that exist.,timed_status_of_things['status_of_thing_code'].nunique()
which organization is not a parent organization of others? list the organization id.,organizations['organization_id'][~organizations['organization_id'].isin(organizations['parent_organization_id'])]
when was the last date of any resident's moving in?,residents['date_moved_in'].max()
"give me the count of residents whose address contains the substring ""miss"".","residents.loc[residents['other_details'].str.contains('miss'), 'other_details']"
what is the count of customers that did not have any event?,customers['customer_id'].isin(customer_events['customer_id']).value_counts()[false]
which move dates of residents are distinct?,residents['date_moved_in'].unique()
how may schools exist?,school.shape[0]
reorder the locations of schools based on the enrollment count.,school.sort_values('enrollment')['location']
"please list the names of school locations in ascending alphabetical order, based on the total enrollment of pupils.",school.sort_values('enrollment')['location']
display the list of schools sorted by founded year in ascending order.,"school.sort_values('founded', ascending=false)['location']"
please rank the school locations in decreasing order of their foundation years.,"school.sort_values('founded', ascending=false)['location']"
"what is the number of enrollments in schools that do not have a denomination of ""catholic""?","school.loc[lambda x: x['denomination']!='catholic', 'enrollment']"
"provide me with the list of enrollment counts for each school that does not include ""catholic"" as part of its denomination.","school.loc[lambda x: x['denomination']!='catholic', 'enrollment']"
please provide me with the average enrollment of the schools.,school['enrollment'].mean()
weigh the mean of the varsity enrollment.,school['enrollment'].mean()
"which are the teams of the players, sorted in ascending alphabetical order?",player.sort_values('team')['team']
identify the teams of every player and classify them in ascending alphabetical order.,player.sort_values('team')['team']
how many different positions are there in a soccer team?,player['position'].nunique()
how many distinct positions were hold by players?,player['position'].nunique()
provide me the listing of players whose age is the maximum.,"player.sort_values('age', ascending=false).iloc[0]['team']"
provide me with the titles of the teams that have the oldest players.,"player.sort_values('age', ascending=false).iloc[0]['team']"
perform a count of players with top five maximum ages.,"player.sort_values('age', ascending=false).head(5)['team']"
what is the count of teams having the oldest players?,"player.sort_values('age', ascending=false).head(5)['team']"
"for each player, show his team and the location of his school.","pd.merge(player, school, on='school_id')[['team', 'location']]"
what is the team and location of the school each player belongs to?,"pd.merge(player, school, on='school_id')[['team', 'location']]"
provide the schools having a large number of students with their names.,"player.merge(school, on='school_id').groupby('school_id').filter(lambda x: len(x) > 1)['location']"
which schools have more than one player? please provide me with the school's locations.,"player.merge(school, on='school_id').groupby('school_id').filter(lambda x: len(x) > 1)['location']"
return the denomination of the school that has the most students.,"pd.merge(player, school, on='school_id').groupby('denomination').size().sort_values(ascending=false).index[0]"
what is the denomination of school the most players belong to?,"pd.merge(player, school, on='school_id').groupby('denomination').size().sort_values(ascending=false).index[0]"
present the location and nickname of schools.,"pd.merge(school, school_details, on='school_id')[['location', 'nickname']]"
please provide me with the ids and complete location of each school.,"pd.merge(school, school_details, on='school_id')[['location', 'nickname']]"
please display the distinct denominations and the number associated with each denomination.,school.groupby('denomination').size().reset_index(name='count')
"for each row, return the column header name(denomination) and the count of rows with the same name in column denomination.",school.groupby('denomination').size().reset_index(name='count')
display the names of different denominations and the name of each school in the descending order.,"school.groupby('denomination').size().reset_index(name='count').sort_values('count', ascending=false)"
"provide the denominations in descending order of their number of usages, along with the corresponding count.","school.groupby('denomination').size().reset_index(name='count').sort_values('count', ascending=false)"
determine the school color that is most prevalent among the schools with the largest student enrollment.,"school.sort_values('enrollment', ascending=false).iloc[0]['school_colors']"
identify the colors of the school with largest enrollment.,"school.sort_values('enrollment', ascending=false).iloc[0]['school_colors']"
list the locations of schools that do not feature any student player.,"school.loc[~school['school_id'].isin(player['school_id']), 'location']"
"what is the count of schools that do not have players? also, send me the addresses of these schools.","school.loc[~school['school_id'].isin(player['school_id']), 'location']"
what is shared by schools founded before 1890 and schools founded after 1900?,"school.loc[school['founded'] < 1890, 'denomination'].interesect(school.loc[school['founded'] > 1900, 'denomination'])"
list down all the denominations that are used by both schools founded before 1890 and schools founded after 1900.,"school.loc[school['founded'] < 1890, 'denomination'].interesect(school.loc[school['founded'] > 1900, 'denomination'])"
obtain the titles of schools that are not in division i.,"school_details.loc[lambda x: x['division'] != 'division 1', 'nickname']"
populate the names of the schools whose division is not equal to 1.,"school_details.loc[lambda x: x['division'] != 'division 1', 'nickname']"
find denominations shared by more than one school.,school.groupby('denomination').filter(lambda x: len(x) > 1)['denomination'].unique()
what is the count of denominations that more than one school have?,school.groupby('denomination').filter(lambda x: len(x) > 1)['denomination'].unique()
return the city district names in alphabetical order of city district area descending,"district.sort_values('city_area', ascending=false)['district_name'].unique()"
"wherein order are the names of the districts of pakistan, beginning with the most extensive city area?","district.sort_values('city_area', ascending=false)['district_name'].unique()"
provide me the count of page sizes in which more than three products are listed on the page.,product.groupby('max_page_size').filter(lambda x: len(x)>3)['max_page_size'].unique()
"provide me with the name and population of the district whose population lies within the range of 200,000 and 2,000,000.","district.loc[(district['city_population'] >= 200000) & (district['city_population'] <= 2000000), ['district_name', 'city_population']]"
"find the district name and total population for districts between 200,000 and 2,000,000.","district.loc[(district['city_population'] >= 200000) & (district['city_population'] <= 2000000), ['district_name', 'city_population']]"
retrieve the names of all districts with city area greater than 10 or population larger than 100000.,"district.loc[(district['city_area'] > 10) | (district['city_population'] > 100000), 'district_name']"
what are the names of all the districts with city areas greater than 10 or have more than 100000 people living there?,"district.loc[(district['city_area'] > 10) | (district['city_population'] > 100000), 'district_name']"
what is the population of the largest district in the given dataset?,"district.sort_values('city_population', ascending=false).iloc[0]['district_name']"
which district has the most residents?,"district.sort_values('city_population', ascending=false).iloc[0]['district_name']"
what is the smallest district area?,district.sort_values('city_area').iloc[0]['district_name']
what is the district with the smallest area?,district.sort_values('city_area').iloc[0]['district_name']
retrieve the total population of the districts that have the largest area.,"district.sort_values('city_area', ascending=false).head(3)['city_population'].sum()"
what is the total number of residents for the districts with the larger area?,"district.sort_values('city_area', ascending=false).head(3)['city_population'].sum()"
what are the types of stores and how many of each are there?,store.groupby('type').size()
how many types of stores are there?,store.groupby('type').size()
retrieve the names of all of stores in khanewal district.,"pd.merge(pd.merge(store, store_district, on='store_id'), district, on='district_id').loc[lambda x: x['district_name']=='khanewal district', 'store_name']"
retrieve the names of all the retail outlets located in khanewal district.,"pd.merge(pd.merge(store, store_district, on='store_id'), district, on='district_id').loc[lambda x: x['district_name']=='khanewal district', 'store_name']"
fetch the stores in the district whose populations are the highest.,"store.merge(store_district).loc[lambda x: x['district_id']==district.sort_values('city_population', ascending=false).iloc[0]['district_id'], 'store_name']"
please list the names of all the stores in the largest district by population.,"store.merge(store_district).loc[lambda x: x['district_id']==district.sort_values('city_population', ascending=false).iloc[0]['district_id'], 'store_name']"
"find the city that is the headquarter of the store named ""blackville"".","pd.merge(pd.merge(store, store_district, on='store_id'), district, on='district_id').loc[lambda x: x['store_name']=='blackville', 'headquartered_city']"
which city is the headquarter of the store blackville?,"pd.merge(pd.merge(store, store_district, on='store_id'), district, on='district_id').loc[lambda x: x['store_name']=='blackville', 'headquartered_city']"
how many stores are there in each city?,"store.merge(store_district, on='store_id').merge(district, on='district_id').groupby('headquartered_city').size()"
what is the count of stores being headquartered in each city?,"store.merge(store_district, on='store_id').merge(district, on='district_id').groupby('headquartered_city').size()"
obtain the name of the city with the most number of stores.,"store_district.merge(district, on='district_id').merge(store, on='store_id').groupby('headquartered_city').size().idxmax()"
which city has the highest number of flagship stores?,"store_district.merge(district, on='district_id').merge(store, on='store_id').groupby('headquartered_city').size().idxmax()"
what is the average number of pages printed per minute using the color option?,product['pages_per_minute_color'].mean()
what is the count of pages colored per minute?,product['pages_per_minute_color'].mean()
"determine the products available at stores bearing the name ""miramichi"".","pd.merge(pd.merge(product, store_product, on='product_id'), store, on='store_id').loc[lambda x: x['store_name']=='miramichi', 'product']"
list out the products that are sold at the store named miramichi.,"pd.merge(pd.merge(product, store_product, on='product_id'), store, on='store_id').loc[lambda x: x['store_name']=='miramichi', 'product']"
obtain the maximum page size of a product type a4 that has a ppm color less than 5.,"product.loc[(product['max_page_size']=='a4') & (product['pages_per_minute_color']<5), 'product']"
"list the products with the maximum page size as ""a4"" or pages per minute color less than equal to 5.","product.loc[(product['max_page_size']=='a4') | (product['pages_per_minute_color']<5), 'product']"
determine the count of products that have the page size equal to a4 or a ppm color value less than 5.,"product.loc[(product['max_page_size']=='a4') | (product['pages_per_minute_color']<5), 'product']"
"retrieve the names of all products which include the word ""scanner"".","product.loc[product['product'].str.contains('scanner'), 'product']"
"what are all of the products whose names include the substring ""scanner""?","product.loc[product['product'].str.contains('scanner'), 'product']"
what are the sizes for the largest pages among all of the products?,product.groupby('max_page_size').size().sort_values(ascending=false).index[0]
which page size is the most common?,product.groupby('max_page_size').size().sort_values(ascending=false).index[0]
retrieve the names of the products that are not using the most frequently-used max page size.,"product.loc[product['product'] != product.loc[product.groupby('max_page_size')['max_page_size'].transform('size').nlargest(1).index[0], 'max_page_size'], 'product']"
fetch the names and page sizes of all products that are not the most frequently-used maximum page size.,"product.loc[product['product'] != product.loc[product.groupby('max_page_size')['max_page_size'].transform('size').nlargest(1).index[0], 'max_page_size'], 'product']"
count the total population of the districts where the area is greater than the average city area.,"district.loc[district['city_area'] > district['city_area'].mean(), 'city_population'].sum()"
what is the total population for all the districts that have a geographic area greater than that of an average city?,"district.loc[district['city_area'] > district['city_area'].mean(), 'city_population'].sum()"
find the names of districts where have both the city mall and village store types.,"district.loc[pd.merge(store[store['type']=='city mall'], store_district, on='store_id').merge(district, on='district_id')['district_name'].isin(pd.merge(store[store['type']=='village store'], store_district, on='store_id').merge(district, on='district_id')['district_name'])]['district_name']"
what district names have both mall and village stores?,"district.loc[pd.merge(store[store['type']=='city mall'], store_district, on='store_id').merge(district, on='district_id')['district_name'].isin(pd.merge(store[store['type']=='village store'], store_district, on='store_id').merge(district, on='district_id')['district_name'])]['district_name']"
provide me the total count of students enrolled in all colleges.,college['enr'].sum()
how many students are in college?,college['enr'].sum()
what is the enrollment average?,college['enr'].mean()
how many colleges did exist altogether?,college.shape[0]
how many players had more than 1000 hours of training?,(player['hs'] > 1000).sum()
how many players trained for more than 1000 hours?,(player['hs'] > 1000).sum()
"find the number of colleges with more than 15,000 students.",(college['enr'] > 15000).sum()
how many colleges have a student population greater than 15000?,(college['enr'] > 15000).sum()
what is the average training hours that players invest?,player['hs'].mean()
how many hours do the athletes train on average?,player['hs'].mean()
retrieve the names of players whose training hours are less or equal than 1500.,"player.loc[lambda x: x['hs'] < 1500, ['pname', 'hs']]"
which players did not train for 1500 hours?,"player.loc[lambda x: x['hs'] < 1500, ['pname', 'hs']]"
how many different colleges are present at the tryouts test?,tryout['cname'].nunique()
during which year were the maximum numbers of colleges represented at tryouts?,tryout['cname'].nunique()
list the various unique classifications of player positions in the tryout.,tryout['ppos'].nunique()
what is the total number of player positions?,tryout['ppos'].nunique()
determine the total count of students who received approval from the tryouts.,(tryout['decision'] == 'yes').sum()
how many students played the role of goalie?,(tryout['ppos'] == 'goalie').sum()
what is the number of students playing the role of a goalie?,(tryout['ppos'] == 'goalie').sum()
"provide me with the max, average and min training hours of all players.","player['hs'].agg(['mean', 'max', 'min'])"
"please provide me with the average, maximum, and minimum for the number of hours spent training.","player['hs'].agg(['mean', 'max', 'min'])"
what is the annual enrollment in schools in the state florida?,"college.loc[lambda x: x['state']=='fl', 'enr'].mean()"
what is the average count of students enrolled in florida colleges?,"college.loc[lambda x: x['state']=='fl', 'enr'].mean()"
obtain the names of players whose number of training hours is between 500 and 1500.,"player.loc[lambda x: x['hs'].between(500, 1500), 'pname']"
what is a list of players who spend between 500 and 1500 training hours?,"player.loc[lambda x: x['hs'].between(500, 1500), 'pname']"
retrieve the ids of players whose names contain the letter 'a'.,"player.loc[lambda x: x['pname'].str.contains('a'), 'pname'].unique()"
"retrieve the player names that begin with the letter ""a"".","player.loc[lambda x: x['pname'].str.contains('a'), 'pname'].unique()"
"retrieve the name of the colleges whose size is exceeding 10,000 and are in the state of la.","college.loc[(college['enr'] > 10000) & (college['state'] == 'la'), ['cname', 'enr']]"
retrieve the names of colleges that have more than 10000 enrolled students and are located at louisiana.,"college.loc[(college['enr'] > 10000) & (college['state'] == 'la'), ['cname', 'enr']]"
list college details sorted by enrollment number in ascending order.,college.sort_values('enr')
please list out the colleges sorted by increasing enrollment numbers.,college.sort_values('enr')
provide a list of all the colleges that have a student count of greater than 18000 within the descending order of their colleges' names.,college.loc[lambda x: x['enr']>18000].sort_values('cname')['cname']
please list the names of colleges in alphabetical order that have more than 18000 enrolled students.,college.loc[lambda x: x['enr']>18000].sort_values('cname')['cname']
get the names of players who have yes as the value of training hours in the descending order.,"player.loc[lambda x: x['ycard']=='yes'].sort_values('hs', ascending=false)['pname']"
name the players who received a card in descending order according to the hours of training.,"player.loc[lambda x: x['ycard']=='yes'].sort_values('hs', ascending=false)['pname']"
resolve the names of colleges that took part in the tryout in alphabetical order.,tryout['cname'].sort_values().unique()
order the colleges in alphabetical order based on the different names of the colleges involved in the tryout.,tryout['cname'].sort_values().unique()
find the position in which most players take part in the tryout.,tryout.groupby('ppos').size().sort_values(ascending=false).index[0]
"how many players were selected to play the position of ""forward"" during tryouts?",tryout.groupby('ppos').size().sort_values(ascending=false).index[0]
what is the descending order of students who participate in tryouts for colleges?,"tryout.groupby('cname').size().reset_index(name='count(*)').sort_values('count(*)', ascending=false)"
how many students took part in tryouts for each college by decreasing count?,"tryout.groupby('cname').size().reset_index(name='count(*)').sort_values('count(*)', ascending=false)"
what is the maximum number of hours needed to learn by a student to play a different position?,"pd.merge(tryout, player, on='pid').groupby('ppos').agg({'hs': 'min', 'ppos': 'first'})['hs']"
"for each position, what is the minimum amount of time students spent practicing?","pd.merge(tryout, player, on='pid').groupby('ppos').agg({'hs': 'min', 'ppos': 'first'})['hs']"
retrieve the names of schools with the top 3 largest sizes.,"college.sort_values('enr', ascending=false).iloc[:3]['cname']"
what is the count of schools with the largest class sizes?,"college.sort_values('enr', ascending=false).iloc[:3]['cname']"
what is the school name that has the smallest enrollment in each respective state?,"college.groupby('state').agg({'cname': 'first', 'enr': 'min'})"
what is the school with the smallest enrollment size per state?,"college.groupby('state').agg({'cname': 'first', 'enr': 'min'})"
"what are the states, in which some college students are found trying out?","pd.merge(college, tryout, on='cname')['state'].unique()"
identify the states in which students are trying out.,"pd.merge(college, tryout, on='cname')['state'].unique()"
list the states in which some college students participated in a tryout and the outcome of the tryout was yes.,"pd.merge(college, tryout, on='cname').loc[lambda x: x['decision']=='yes', 'state'].unique()"
which states had students successfully try out for football?,"pd.merge(college, tryout, on='cname').loc[lambda x: x['decision']=='yes', 'state'].unique()"
determine the ids and names of students who are approved for the tryout.,"pd.merge(player, tryout[tryout['decision']=='yes'], on='pid')[['pname', 'cname']]"
"find the titles of all the players that got accepted to the staff, as well as the name of their college.","pd.merge(player, tryout[tryout['decision']=='yes'], on='pid')[['pname', 'cname']]"
list titles of the students that were in the tryouts.,"pd.merge(player, tryout, on='pid').sort_values('pname')['pname']"
list the names of all students in alphabetical order who auditioned for the program.,"pd.merge(player, tryout, on='pid').sort_values('pname')['pname']"
please provide me with the name and schedule for students who are cleared for tryouts.,"pd.merge(player, tryout.loc[lambda x: x['decision']=='yes'], on='pid')[['pname', 'hs']]"
determine the titles and times of practice that different students who received a positive reply during tryouts.,"pd.merge(player, tryout.loc[lambda x: x['decision']=='yes'], on='pid')[['pname', 'hs']]"
provide me the names of the colleges having students participating in the tryout exercise specialized in striker position.,"pd.merge(college, tryout, on='cname').loc[lambda x: x['ppos']=='striker', 'state']"
retrieve the list of states of the community colleges where students who tried out for the striker position attend.,"pd.merge(college, tryout, on='cname').loc[lambda x: x['ppos']=='striker', 'state']"
retrieve the titles of students who have tried out for the position of striker.,"pd.merge(player, tryout.loc[lambda x: (x['decision']=='yes') & (x['ppos']=='striker')], on='pid')['pname']"
return the name of the college that charles is attending.,"pd.merge(pd.merge(college, tryout, on='cname'), player, on='pid').loc[lambda x: x['pname']=='charles', 'state']"
in which state is the college attended by charles?,"pd.merge(pd.merge(college, tryout, on='cname'), player, on='pid').loc[lambda x: x['pname']=='charles', 'state']"
determine the average and maximum hours of the students whose tryout decision is yes.,"pd.merge(player, tryout.loc[lambda x: x['decision']=='yes'], on='pid')['hs'].agg(['mean', 'max'])"
how many hours on average did students who made the team practice?,"pd.merge(player, tryout.loc[lambda x: x['decision']=='yes'], on='pid')['hs'].agg(['mean', 'max'])"
calculate the average hours of students who are not selected.,"pd.merge(player, tryout.loc[lambda x: x['decision']=='no'], on='pid')['hs'].mean()"
compute the average hours of practice that students that are rejected had.,"pd.merge(player, tryout.loc[lambda x: x['decision']=='no'], on='pid')['hs'].mean()"
what is the total training hours for students who are in different positions and whose training hours is more than 1000 hours?,"pd.merge(player, tryout, on='pid').loc[lambda x: x['hs'] > 1000].groupby('ppos')['hs'].max()"
"for each job, what is the count of students who spent more than 1000 hours training?","pd.merge(player, tryout, on='pid').loc[lambda x: x['hs'] > 1000].groupby('ppos')['hs'].max()"
provide me the names of the colleges where tryout players whose first name start with the letter 'd' are enrolled.,"pd.merge(tryout, player, on='pid').loc[lambda x: x['pname'].str.startswith('d'), 'cname']"
"which colleges does a player whose name starts with the letter d, who tried out, attend?","pd.merge(tryout, player, on='pid').loc[lambda x: x['pname'].str.startswith('d'), 'cname']"
what college has a student playing as a goalie and who was selected for the team?,"tryout.loc[(tryout['decision']=='yes')&(tryout['ppos']=='goalie'), 'cname']"
which college has a student-athlete who was successful at making the team as a goalie?,"tryout.loc[(tryout['decision']=='yes')&(tryout['ppos']=='goalie'), 'cname']"
find the names of players who were from the college with the largest population.,"player.merge(tryout, on='pid').loc[lambda x: x['cname']==college.sort_values('enr', ascending=false)['cname'].iloc[0], 'pname']"
please provide me with the names of all participants from the largest college.,"player.merge(tryout, on='pid').loc[lambda x: x['cname']==college.sort_values('enr', ascending=false)['cname'].iloc[0], 'pname']"
provide me the state and enrollment of the colleges in which any student was accepted in the tryout decision.,"pd.merge(college, tryout.loc[lambda x: x['decision']=='yes'], on='cname')[['state', 'enr']].drop_duplicates()"
"how many colleges grant enrollment to students who pass their tryouts, and in which states do those colleges reside?","pd.merge(college, tryout.loc[lambda x: x['decision']=='yes'], on='cname')[['state', 'enr']].drop_duplicates()"
"list down the names of colleges in la that have more than 15,000 students and of colleges in az with less than 13,000 students.","pd.concat([college.loc[(college['enr'] < 13000) & (college['state'] == 'az'), 'cname'],college.loc[(college['enr'] > 15000) & (college['state'] == 'la'), 'cname']]).drop_duplicates()"
retrieve the titles of schools whose students have played in goalie and mid-field positions.,"set(tryout.loc[tryout['ppos'] == 'goalie', 'cname']).intersection(set(tryout.loc[tryout['ppos'] == 'mid', 'cname']))"
retrieve the names of all the schools having students try out for the positions of goal and midfield.,"set(tryout.loc[tryout['ppos'] == 'goalie', 'cname']).intersection(set(tryout.loc[tryout['ppos'] == 'mid', 'cname']))"
retrieve the titles of all states that have at least one college student playing in goalie and mid positions.,"pd.merge(college.loc[college.merge(tryout.loc[tryout['ppos']=='goalie', ['cname']])['cname']], college.loc[college.merge(tryout.loc[tryout['ppos']=='mid', ['cname']])['cname']], how='inner')['state']"
what are the names of states that have college students playing at the positions of goalie and mid-field?,"pd.merge(college.loc[college.merge(tryout.loc[tryout['ppos']=='goalie', ['cname']])['cname']], college.loc[college.merge(tryout.loc[tryout['ppos']=='mid', ['cname']])['cname']], how='inner')['state']"
what percentage of schools have students playing in both goalie and midfield positions?,"len(pd.merge(tryout.loc[tryout['ppos']=='goalie', ['cname']], tryout.loc[tryout['ppos']=='mid', ['cname']], on='cname'))"
what is the number of schools where students are playing in goalie positions as well as midfield?,"len(pd.merge(tryout.loc[tryout['ppos']=='goalie', ['cname']], tryout.loc[tryout['ppos']=='mid', ['cname']], on='cname'))"
"retrieve the names of schools whose players occupy the mid positions, but not in the goalie position.",tryout[tryout['ppos']=='mid']['cname'].isin(tryout[tryout['ppos']=='goalie']['cname']).pipe(lambda x:x[~x]).index
what school names have some players who play in the middle but not goalie?,tryout[tryout['ppos']=='mid']['cname'].isin(tryout[tryout['ppos']=='goalie']['cname']).pipe(lambda x:x[~x]).index
provide the names of states that have some students playing in the position of mid-fielder but not the position of goalkeeper.,"college.merge(tryout.loc[lambda x: x['ppos']=='mid'], on='cname')['state'].drop_duplicates().append(college.merge(tryout.loc[lambda x: x['ppos']=='goalie'], on='cname')['state']).drop_duplicates(keep=false)"
retrieve the names of all the states where college students play in the mid position but no goalies.,"college.merge(tryout.loc[lambda x: x['ppos']=='mid'], on='cname')['state'].drop_duplicates().append(college.merge(tryout.loc[lambda x: x['ppos']=='goalie'], on='cname')['state']).drop_duplicates(keep=false)"
how many states have some college students playing in the mid position but not in the goalie position?,"((college.merge(tryout[tryout.ppos=='mid'], on='cname')).loc[~(college.merge(tryout[tryout.ppos=='goalie'], on='cname'))['state'].isin((college.merge(tryout[tryout.ppos=='mid'], on='cname'))['state'])])['state'].nunique()"
what is the count of states in which college students play the mid position but not as goalies?,"((college.merge(tryout[tryout.ppos=='mid'], on='cname')).loc[~(college.merge(tryout[tryout.ppos=='goalie'], on='cname'))['state'].isin((college.merge(tryout[tryout.ppos=='mid'], on='cname'))['state'])])['state'].nunique()"
which states have colleges whose enrollments are fewer than the largest size?,"college.loc[lambda x: x['enr'] < x['enr'].max(), 'state'].unique()"
provide the names of colleges whose enrollment is greater than that of the colleges in the state of florida.,"college.loc[lambda x: x['enr'] > college.loc[lambda y: y['state']=='fl', 'enr'].min(), 'cname'].unique()"
retrieve the title of colleges that are larger than at least one college of florida.,"college.loc[lambda x: x['enr'] > college.loc[lambda y: y['state']=='fl', 'enr'].min(), 'cname'].unique()"
fetch names of all colleges whose enrollment exceeds that of all colleges in the florida state.,"college.loc[college['enr'] > college.loc[college['state'] == 'fl', 'enr'].max(), 'cname']"
which colleges in the country have a larger student enrollment than the largest college in florida?,"college.loc[college['enr'] > college.loc[college['state'] == 'fl', 'enr'].max(), 'cname']"
what is the count of schools that enrolled no goalies in the hockey division?,"college.loc[~college['cname'].isin(tryout.loc[tryout['ppos']=='goalie', 'cname']), 'enr'].sum()"
what is the count of students enrolled in schools without any goalies?,"college.loc[~college['cname'].isin(tryout.loc[tryout['ppos']=='goalie', 'cname']), 'enr'].sum()"
which states have colleges whose enrollment is greater than the average enrollment?,"college.loc[lambda x: x['enr'] > x['enr'].mean(), 'state'].nunique()"
which states possess colleges with much higher number of students than average?,"college.loc[lambda x: x['enr'] > x['enr'].mean(), 'state'].nunique()"
find the number of states that have colleges whose enrollment is smaller than the average enrollment.,"college.loc[lambda x: x['enr'] < x['enr'].mean(), 'state'].nunique()"
what states have colleges that have a lower student count than the average?,"college.loc[lambda x: x['enr'] < x['enr'].mean(), 'state'].nunique()"
what are the total number of devices that were present?,device.shape[0]
what are the total number of devices?,device.shape[0]
order the names of the carriers of the devices in ascending order.,device.sort_values('carrier')['carrier']
"name the different carriers for devices, listed in alphabetical order.",device.sort_values('carrier')['carrier']
what are the names of carriers whose platforms are not android?,"device.loc[lambda x: x['software_platform']!='android', 'carrier']"
provide the names for the device carriers that do not have android as the software platform.,"device.loc[lambda x: x['software_platform']!='android', 'carrier']"
return the names of shops in descending order of open year.,shop.sort_values('open_year')['shop_name']
"please list the names of shops, in the order of year of opening ascending.",shop.sort_values('open_year')['shop_name']
what are the average quantities of stocks?,stock['quantity'].mean()
give me the average count of stocks.,stock['quantity'].mean()
provide with the name and location details of the shops in ascending alphabetic order of name.,"shop[['shop_name', 'location']].sort_values('shop_name')"
"please provide me with the names and locations of the shops, which are ordered alphabetically.","shop[['shop_name', 'location']].sort_values('shop_name')"
how many platforms are there for devices?,device['software_platform'].nunique()
please count the number of different software platforms.,device['software_platform'].nunique()
provide me the open date information for all shops with the name of apple.,"shop.loc[shop['shop_name'] == 'apple', ['open_date', 'open_year']]"
what is the year and date that apple store opened?,"shop.loc[shop['shop_name'] == 'apple', ['open_date', 'open_year']]"
retrieve the title of the store with the latest open year.,"shop.sort_values('open_year', ascending=false).iloc[0]['shop_name']"
what is the shop title corresponding to the shop that opened in the most recent year?,"shop.sort_values('open_year', ascending=false).iloc[0]['shop_name']"
return the names of shops and the kinds of devices they have in stock.,"pd.merge(pd.merge(stock, device, on='device_id'), shop, on='shop_id')[['shop_name', 'carrier']]"
provide me with the titles of all device shops and the types of carriers that they stock devices for.,"pd.merge(pd.merge(stock, device, on='device_id'), shop, on='shop_id')[['shop_name', 'carrier']]"
show the titles of retailers that have at least two types of devices in stock.,"pd.merge(stock, shop, on='shop_id').groupby('shop_name').filter(lambda x: len(x)>1)['shop_name'].unique()"
retrieve the names of stores that carry multiple types of devices in stock.,"pd.merge(stock, shop, on='shop_id').groupby('shop_name').filter(lambda x: len(x)>1)['shop_name'].unique()"
which shop has the maximum number of devices in stock?,"stock.merge(shop, on='shop_id').groupby('shop_name').size().sort_values(ascending=false).index[0]"
provide the name of the shop that has the greatest number of merchandise categories.,"stock.merge(shop, on='shop_id').groupby('shop_name').size().sort_values(ascending=false).index[0]"
list out the names of the shops that possess the largest quantity of devices.,"pd.merge(stock, shop, on='shop_id').groupby('shop_id')['quantity'].sum().sort_values(ascending=false).head(1).index.get_level_values('shop_name')"
please provide me the name of the shop that has the greatest count of devices in stock.,"pd.merge(stock, shop, on='shop_id').groupby('shop_id')['quantity'].sum().sort_values(ascending=false).head(1).index.get_level_values('shop_name')"
fetch me the programs utilized and the number of devices utilizing each.,device.groupby('software_platform').size().reset_index(name='count')
"how many platforms are used for devices, and what devices have each?",device.groupby('software_platform').size().reset_index(name='count')
rank the software platforms of devices with respect to their count.,device.groupby('software_platform').size().sort_values(ascending=false).index
could you order the platforms used for devices by descending frequency?,device.groupby('software_platform').size().sort_values(ascending=false).index
which software platform is shared by the greatest number of devices?,device.groupby('software_platform').size().sort_values(ascending=false).head(1).index[0]
which operating system is primarily used across all devices?,device.groupby('software_platform').size().sort_values(ascending=false).head(1).index[0]
return the names of shops that do not have available items.,"shop.loc[~shop['shop_id'].isin(stock['shop_id']), 'shop_name']"
retrieve the names of shops that have no devices in stock.,"shop.loc[~shop['shop_id'].isin(stock['shop_id']), 'shop_name']"
find the shops having open year after 2012 and before 2008 and list their common locations.,"shop.loc[shop['open_year'] > 2012, 'location'].interesect(shop.loc[shop['open_year'] < 2008, 'location'])"
which locations are both shops that opened after the year 2012 and shops that opened before 2008?,"shop.loc[shop['open_year'] > 2012, 'location'].interesect(shop.loc[shop['open_year'] < 2008, 'location'])"
list the suppliers of devices that do not have any devices in stock.,"device.loc[~device['device_id'].isin(stock['device_id']), 'carrier']"
what are the carriers of devices that are not available in any of the stock locations?,"device.loc[~device['device_id'].isin(stock['device_id']), 'carrier']"
retrieve the carriers of devices in stock at more than one shop.,"pd.merge(stock, device, on='device_id').groupby('device_id').filter(lambda x: len(x) > 1)['carrier']"
which carrier codes are replicated more than a single retailer?,"pd.merge(stock, device, on='device_id').groupby('device_id').filter(lambda x: len(x) > 1)['carrier']"
count the number of bookings we have.,bookings.shape[0] or len(bookings)
provide me the total number of bookings held in reservations.,bookings.shape[0] or len(bookings)
determine the dates of arrival for all the bookings.,bookings['order_date']
what is the due-date of each booking?,bookings['order_date']
show me all the planned delivery dates and actual delivery dates of bookings.,"bookings[['planned_delivery_date', 'actual_delivery_date']]"
list the planned delivery date and actual delivery date for each booking.,"bookings[['planned_delivery_date', 'actual_delivery_date']]"
how may customers do we have?,customers.shape[0]
calculate the number of customers that were recorded.,customers.shape[0]
please furnish me with the phone numbers and email id of customer harold.,"customers.loc[lambda x: x['customer_name']=='harold', ['customer_phone', 'customer_email_address']]"
"please find the details of the customer ""harold"".","customers.loc[lambda x: x['customer_name']=='harold', ['customer_phone', 'customer_email_address']]"
display all the names of the drama workshop groups.,drama_workshop_groups['store_name']
what are the titles of drama workshop groups?,drama_workshop_groups['store_name']
"calculate the average, maximum, minimum order quantity of all documents.","invoices['order_quantity'].agg(['min', 'mean', 'max'])"
"which invoices had the minimum, average, and maximum quantities ordered? re-check all the invoices.","invoices['order_quantity'].agg(['min', 'mean', 'max'])"
how many distinct payment method codes are present in all the invoices?,invoices['payment_method_code'].unique()
do bring forward the distinct payment methods from the invoice record.,invoices['payment_method_code'].unique()
what region description is china?,"marketing_regions.loc[lambda x: x['marketing_region_name']=='china', 'marketing_region_descriptrion']"
retrieve the marketing description of china.,"marketing_regions.loc[lambda x: x['marketing_region_name']=='china', 'marketing_region_descriptrion']"
identify the products with titles that are more expensive than the average.,"products.loc[lambda x: x['product_price'] > x['product_price'].mean(), 'product_name'].unique()"
please provide me with the distinct unique products whose price is greater than the average.,"products.loc[lambda x: x['product_price'] > x['product_price'].mean(), 'product_name'].unique()"
retrieve the title of the most expensive product.,"products.sort_values('product_price', ascending=false)['product_name'].iloc[0]"
please provide me with a list of product names in order of decreasing price.,products.sort_values('product_price')['product_name']
sort the names of products in the order of their price.,products.sort_values('product_price')['product_name']
find the complete phone number of the singer ashley.,"performers.loc[performers['customer_name']=='ashley', 'customer_phone']"
"retrieve the phone number of the performer ""ashley"".","performers.loc[performers['customer_name']=='ashley', 'customer_phone']"
show me all payment type and numbers of orders that were processed by each payment method.,invoices.groupby('payment_method_code').size()
"provide the list, title and number of payment methods used by the company.",invoices.groupby('payment_method_code').size()
what payment method code is used by the most orders?,invoices.groupby('payment_method_code').size().sort_values(ascending=false).index[0]
collect the most frequently used payment method from all invoices. provide its code.,invoices.groupby('payment_method_code').size().sort_values(ascending=false).index[0]
"what is the address of the city in which the store named ""fja filming"" is located?","addresses.merge(stores, on='address_id').loc[lambda x: x['store_name']=='fja filming', 'city_town']"
"please return me the city in which the store named ""fja filming"" is located.","addresses.merge(stores, on='address_id').loc[lambda x: x['store_name']=='fja filming', 'city_town']"
"obtain the list of states or counties that contained the address of the stores with marketing region code ""ca"".","addresses.merge(stores.loc[lambda x: x['marketing_region_code']=='ca'], on='address_id')['state_county']"
"find the state names or the county names where the stores with the marketing region code ""ca"" are located.","addresses.merge(stores.loc[lambda x: x['marketing_region_code']=='ca'], on='address_id')['state_county']"
name the marketing region that rob dinning's store belongs to.,"marketing_regions.loc[marketing_regions['marketing_region_code'].isin(stores.loc[stores['store_name']=='rob dinning', 'marketing_region_code']), 'marketing_region_name']"
please return the name of the region in which rob dinning's store is located.,"marketing_regions.loc[marketing_regions['marketing_region_code'].isin(stores.loc[stores['store_name']=='rob dinning', 'marketing_region_code']), 'marketing_region_name']"
list out the service types that are marked with product price above 100.,"pd.merge(ref_service_types, services.loc[lambda x: x['product_price'] > 100], on='service_type_code')['service_type_description']"
provide me with the description for all of the service types that cost more than 100.,"pd.merge(ref_service_types, services.loc[lambda x: x['product_price'] > 100], on='service_type_code')['service_type_description']"
"fetch the description, code and count of each service type.","pd.merge(ref_service_types, services, on='service_type_code').groupby(['service_type_code', 'service_type_description']).size().reset_index(name='count')[['service_type_description', 'service_type_code', 'count']]"
"please list the description, code and number of services for all service types.","pd.merge(ref_service_types, services, on='service_type_code').groupby(['service_type_code', 'service_type_description']).size().reset_index(name='count')[['service_type_description', 'service_type_code', 'count']]"
which description and code fit the type of service that is most frequently performed?,"pd.merge(ref_service_types, services, on='service_type_code').groupby(['service_type_code', 'service_type_description']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['service_type_description', 'service_type_code']]"
what is the name of service type that is most frequently performed?,"pd.merge(ref_service_types, services, on='service_type_code').groupby(['service_type_code', 'service_type_description']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['service_type_description', 'service_type_code']]"
exactly what is the contact information of workshop groups in which services are provided?,"pd.merge(drama_workshop_groups, services, on='workshop_group_id')[['store_phone', 'store_email_address']]"
find me all the phone numbers and email addresses of workshops where services are performed.,"pd.merge(drama_workshop_groups, services, on='workshop_group_id')[['store_phone', 'store_email_address']]"
"give the name of the groups in which services are performed with the product name ""film"".","pd.merge(drama_workshop_groups, services[lambda x: x['product_name']=='film'], on='workshop_group_id')[['store_phone', 'store_email_address']]"
"retrieve the titles of workshops that provide services about products named ""film"".","pd.merge(drama_workshop_groups, services[lambda x: x['product_name']=='film'], on='workshop_group_id')[['store_phone', 'store_email_address']]"
"provide me with the titles of products that are available, and their corresponding average price.",products.groupby('product_name')['product_price'].mean()
"for each product name, show its price.",products.groupby('product_name')['product_price'].mean()
"give me the names of products whose prices are smaller than $1,000,000.",products.groupby('product_name').filter(lambda x: x['product_price'].mean() < 1000000)['product_name'].unique()
pick out the product names whose average price is less than or equal to one million.,products.groupby('product_name').filter(lambda x: x['product_price'].mean() < 1000000)['product_name'].unique()
retrieve the total count of photo products.,"order_items.merge(products, on='product_id').query('product_name == ""photo""')['order_quantity'].sum()"
"please determine the total quantity of ""photo"" products.","order_items.merge(products, on='product_id').query('product_name == ""photo""')['order_quantity'].sum()"
give out the details of products whose price is more than $2000.,"pd.merge(order_items, products, on='product_id').loc[lambda x: x['product_price'] > 2000, 'other_item_details']"
search the orders for the year 2010 priced above 2000.,"pd.merge(order_items, products, on='product_id').loc[lambda x: x['product_price'] > 2000, 'other_item_details']"
what is the count of orders for quantity 1 that were received on the given date?,"pd.merge(customer_orders, order_items.loc[lambda x: x['order_quantity']==1], on='order_id')['actual_delivery_date']"
provide the count of actual delivery dates for all orders placed with quantity equal to 1.,"pd.merge(customer_orders, order_items.loc[lambda x: x['order_quantity']==1], on='order_id')['actual_delivery_date']"
provide me with the dates on which orders with price higher than 1000 were placed in the past.,"pd.merge(pd.merge(customer_orders, order_items, on='order_id'), products, on='product_id').loc[lambda x: x['product_price'] > 1000, 'order_date']"
should i provide you with the order dates of the orders with the price greater than $1000?,"pd.merge(pd.merge(customer_orders, order_items, on='order_id'), products, on='product_id').loc[lambda x: x['product_price'] > 1000, 'order_date']"
how many unique currency codes are utilized by all members of the drama workshop group?,drama_workshop_groups['currency_code'].nunique()
obtain the number of distinct currency codes utilized for drama workshop groups.,drama_workshop_groups['currency_code'].nunique()
conduct a query to retrieve the names of the drama workshop groups having an address in feliciaberg city.,"pd.merge(addresses, drama_workshop_groups, on='address_id').loc[lambda x: x['city_town']=='feliciaberg', 'store_name']"
please list the names of the drama workshop groups that are situated in feliciaberg city.,"pd.merge(addresses, drama_workshop_groups, on='address_id').loc[lambda x: x['city_town']=='feliciaberg', 'store_name']"
identify the email addresses of the drama workshop groups that are in alaska state.,"pd.merge(addresses, drama_workshop_groups, on='address_id').loc[lambda x: x['state_county']=='alaska', 'store_email_address']"
list the lists of email addresses of drama workshop groups situated in alaska state.,"pd.merge(addresses, drama_workshop_groups, on='address_id').loc[lambda x: x['state_county']=='alaska', 'store_email_address']"
display a list of all cities along with the number of drama workshops in each city.,"pd.merge(addresses, drama_workshop_groups, on='address_id').groupby('city_town').size().reset_index(name='count(*)')[['city_town', 'count(*)']]"
for which city is each drama workshop group listed?,"pd.merge(addresses, drama_workshop_groups, on='address_id').groupby('city_town').size().reset_index(name='count(*)')[['city_town', 'count(*)']]"
which region code has the most number of drama workshop groups?,"drama_workshop_groups.groupby('marketing_region_code').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['marketing_region_code']"
"of all possible regions, what is the region that has the most workshop groups for drama?","drama_workshop_groups.groupby('marketing_region_code').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['marketing_region_code']"
show me the locations of cities in which at least one customer resides but where no performer resides.,"pd.merge(addresses, customers, on='address_id')['city_town'].drop_duplicates().append(pd.merge(addresses, performers, on='address_id')['city_town']).drop_duplicates(keep=false)"
"how many cities do not have a performer, but have a customer?","pd.merge(addresses, customers, on='address_id')['city_town'].drop_duplicates().append(pd.merge(addresses, performers, on='address_id')['city_town']).drop_duplicates(keep=false)"
what is the most common status of bookings?,bookings.groupby('status_code').size().sort_values(ascending=false).index[0]
"taken all the bookings that were coded, what is the most used status code?",bookings.groupby('status_code').size().sort_values(ascending=false).index[0]
"search in the lists of workshop groups that have bookings with status code ""stop"".","pd.merge(bookings, drama_workshop_groups, on='workshop_group_id').loc[lambda x: x['status_code']=='stop', 'store_name']"
"give me the names of workshop groups which bookings contain the status code ""stop"".a:enumerate the fields:select 'count seconds'||string_agg(fieldname,' ')from tblgroup by fieldnameorder by 2 desc;","pd.merge(bookings, drama_workshop_groups, on='workshop_group_id').loc[lambda x: x['status_code']=='stop', 'store_name']"
show the names of all clients who have never booked.,"clients['customer_name'].loc[~clients['customer_name'].isin(bookings.merge(clients, left_on='customer_id', right_on='client_id')['customer_name'].unique())]"
what titles are the clients that have no booking?,"clients['customer_name'].loc[~clients['customer_name'].isin(bookings.merge(clients, left_on='customer_id', right_on='client_id')['customer_name'].unique())]"
"what is the average of the quantity of orders made with payment method code ""mastercard"" on invoices?","invoices.loc[invoices['payment_method_code']=='mastercard', 'order_quantity'].mean()"
"download the total record of the orders placed by payment method ""mastercard"" and calculate their average.","invoices.loc[invoices['payment_method_code']=='mastercard', 'order_quantity'].mean()"
retrieve the product id of the item that is most frequently ordered on invoices.,invoices.groupby('product_id').size().sort_values(ascending=false).index[0]
what is the id of the product that was ordered by customers most often on invoices?,invoices.groupby('product_id').size().sort_values(ascending=false).index[0]
what is the description of service types that offer both photo products as well as film products?,"pd.merge(ref_service_types.loc[lambda x: x['service_type_code'].isin(services.loc[lambda x: x['product_name'] == 'photo', 'service_type_code'])],services.loc[lambda x: x['product_name'] == 'film'],on='service_type_code',)['service_type_description']"
please provide me with the description of the services that offers both the photo and film products.,"pd.merge(ref_service_types.loc[lambda x: x['service_type_code'].isin(services.loc[lambda x: x['product_name'] == 'photo', 'service_type_code'])],services.loc[lambda x: x['product_name'] == 'film'],on='service_type_code',)['service_type_description']"
return me the count of bands.,band.shape[0]
which are the labels?,albums['label'].unique()
provide me with the titles of different record labels listed.,albums['label'].unique()
which albums were composed in the year 2012?,albums.loc[lambda x: x['year']==2012]
retrieve all columns of albums created in the year of 2012.,albums.loc[lambda x: x['year']==2012]
"find all the stage positions of musicians with first name ""solveig""","pd.merge(performance, band, left_on='bandmate', right_on='id').loc[lambda x: x['firstname']=='solveig', 'stageposition'].unique()"
"provide me the count of different stage positions for musicians whose first name is ""solveig"".","pd.merge(performance, band, left_on='bandmate', right_on='id').loc[lambda x: x['firstname']=='solveig', 'stageposition'].unique()"
how many songs have been composed?,songs.shape[0]
determine the count of songs.,songs.shape[0]
"retrieve the titles of songs performed by artists with last name ""heilo""","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['lastname'] == 'heilo', 'title']"
"what is the full name of each of the songs by the artist whose last name is ""heilo""?","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['lastname'] == 'heilo', 'title']"
"how many performers were involved in the recording of ""flash""?","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['title']=='flash'].shape[0]"
"how many musicians were utilized in the composition of the song ""flash""?","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['title']=='flash'].shape[0]"
"list down all the songs produced by artists having first name ""marianne"".","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['firstname']=='marianne', 'title']"
"retrieve the title of all songs composed and performed by an artist with the first name ""marianne"".","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['firstname']=='marianne', 'title']"
"show the first name and last name of performers of the song named ""badlands"".","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['title']=='badlands', ['firstname', 'lastname']]"
"find the first and last names of the artist that performed the song ""badlands"".","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['title']=='badlands', ['firstname', 'lastname']]"
"what is the first and last name of the performer performing in the background for the track ""badlands""?","pd.merge(pd.merge(performance.loc[lambda x: x['stageposition']=='back'], band, left_on='bandmate', right_on='id'), songs.loc[lambda x: x['title']=='badlands'], left_on='songid', right_on='songid')[['firstname', 'lastname']]"
"please provide me with the names and ranks of the performer who was in the back stage for the song ""badlands"".","pd.merge(pd.merge(performance.loc[lambda x: x['stageposition']=='back'], band, left_on='bandmate', right_on='id'), songs.loc[lambda x: x['title']=='badlands'], left_on='songid', right_on='songid')[['firstname', 'lastname']]"
how many unique labels have been used for albums?,albums['label'].nunique()
provide me with the titles of albums that have been labeled uniquely.,albums['label'].nunique()
what is the title of the album that has received the maximum number of albums?,albums.groupby('label').size().sort_values(ascending=false).index[0]
what is the last name of the musician that is found in the most songs?,"pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').groupby('lastname').size().sort_values(ascending=false).index[0]"
what is the last name of the musician that has played the back most?,"performance.merge(band, left_on='bandmate', right_on='id').loc[lambda x: x['stageposition']=='back'].groupby('lastname').size().sort_values(ascending=false).index[0]"
find the names of the musicians who have played back position the most.,"performance.merge(band, left_on='bandmate', right_on='id').loc[lambda x: x['stageposition']=='back'].groupby('lastname').size().sort_values(ascending=false).index[0]"
"find the names of songs in which the title contains the word ""the"".","songs.loc[songs['title'].str.contains(' the '), 'title']"
please provide me with the names of all the instruments used in this song.,instruments['instrument'].unique()
retrieve the titles of all instruments stored in the database.,instruments['instrument'].unique()
"determine the instrument used by musician heilo in the song ""le pop.""","pd.merge(pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid'), instruments, left_on=['songid', 'id'], right_on=['songid', 'bandmateid']).loc[(lambda x: (x['lastname'] == ""heilo"") & (x['title'] == ""le pop"")), 'instrument']"
"what are the instruments used by a musician in the song ""le pop"" who has the last name of heilo?","pd.merge(pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid'), instruments, left_on=['songid', 'id'], right_on=['songid', 'bandmateid']).loc[(lambda x: (x['lastname'] == ""heilo"") & (x['title'] == ""le pop"")), 'instrument']"
what is the most utilized instrument?,instruments.groupby('instrument').size().sort_values(ascending=false).index[0]
which instrument did the singers use the most?,instruments.groupby('instrument').size().sort_values(ascending=false).index[0]
what is the count of songs that employed the drums as an instrument?,(instruments['instrument'] == 'drums').sum()
how many songs use the drums as an instrument?,(instruments['instrument'] == 'drums').sum()
"which musical instruments are incorporated in the song ""le pop""?","pd.merge(instruments, songs, on='songid').loc[lambda x: x['title']=='le pop', 'instrument']"
"which instruments were utilized in the composition of the song ""le pop""?","pd.merge(instruments, songs, on='songid').loc[lambda x: x['title']=='le pop', 'instrument']"
"how many musical instruments were used in composing the song ""le pop""?","pd.merge(instruments, songs, on='songid').loc[lambda x: x['title']=='le pop', 'instrument'].nunique()"
"how many instruments were used in the composition of the song ""le pop""?","pd.merge(instruments, songs, on='songid').loc[lambda x: x['title']=='le pop', 'instrument'].nunique()"
"how many instruments are used by the musician with last name ""heilo""?","instruments.merge(band, left_on='bandmateid', right_on='id').loc[lambda x: x['lastname']=='heilo', 'instrument'].nunique()"
how many different instruments are used in the compositions authored by the musician with the last name heilo?,"instruments.merge(band, left_on='bandmateid', right_on='id').loc[lambda x: x['lastname']=='heilo', 'instrument'].nunique()"
"retrieve the names of instruments ever utilized by the musician whose last name is ""heilo"".","pd.merge(instruments, band, left_on='bandmateid', right_on='id').loc[lambda x: x['lastname']=='heilo', 'instrument']"
what is the range of instruments utilized throughout the entire musical career of the musician with the last name heilo?,"pd.merge(instruments, band, left_on='bandmateid', right_on='id').loc[lambda x: x['lastname']=='heilo', 'instrument']"
which song did the most vocals?,"pd.merge(vocals, songs, on='songid').groupby('songid')['title'].count().nlargest(1).index.values[0]"
which song has the maximum number of vocals?,"pd.merge(vocals, songs, on='songid').groupby('songid')['title'].count().nlargest(1).index.values[0]"
what vocal type is most frequently present in all songs?,vocals.groupby('type').size().sort_values(ascending=false).index[0]
what is the term that has appeared most frequently?,vocals.groupby('type').size().sort_values(ascending=false).index[0]
determine the band mates that played the same vocal type most often.,"pd.merge(vocals, band, left_on='bandmate', right_on='id').loc[lambda x: x['lastname']=='heilo'].groupby('type').size().sort_values(ascending=false).index[0]"
"which type of vocals did the band member with the last name ""heilo"" play the most?","pd.merge(vocals, band, left_on='bandmate', right_on='id').loc[lambda x: x['lastname']=='heilo'].groupby('type').size().sort_values(ascending=false).index[0]"
"which vocal types were utilized in the composition of the song ""le pop""?","pd.merge(vocals, songs, on='songid').loc[lambda x: x['title']=='le pop', 'type']"
"what types of vocals were used in the song ""le pop""?","pd.merge(vocals, songs, on='songid').loc[lambda x: x['title']=='le pop', 'type']"
"produce the sum of vocal types utilized in the song ""demon kitty rag"".","pd.merge(vocals, songs, on='songid').loc[lambda x: x['title'] == 'demon kitty rag'].shape[0]"
"what are the vocal types utilized in the composition of ""demon kitty rag""?","pd.merge(vocals, songs, on='songid').loc[lambda x: x['title'] == 'demon kitty rag'].shape[0]"
what is the count of songs whose vocal type is lead?,"vocals.merge(songs, on='songid').loc[lambda x: x['type']=='lead', 'title'].nunique()"
"which vocal type was used by the musician with first name ""solveig"" in the song with title ""a bar in amsterdam""?","pd.merge(pd.merge(vocals, songs, on='songid'), band, left_on='bandmate', right_on='id').loc[(lambda x: x['firstname']=='solveig') & (lambda x: x['title']=='a bar in amsterdam'), 'type']"
for which songs did solveig perform which types of vocals?,"pd.merge(pd.merge(vocals, songs, on='songid'), band, left_on='bandmate', right_on='id').loc[(lambda x: x['firstname']=='solveig') & (lambda x: x['title']=='a bar in amsterdam'), 'type']"
list all the songs without lead vocals.,"pd.merge(vocals, songs, on='songid')['title'].drop_duplicates().subtract(pd.merge(vocals[vocals['type']=='lead'], songs, on='songid')['title']).dropna()"
identify the names of songs that do not have a lead vocal part.,"pd.merge(vocals, songs, on='songid')['title'].drop_duplicates().subtract(pd.merge(vocals[vocals['type']=='lead'], songs, on='songid')['title']).dropna()"
collect the vocal types details.,vocals['type'].unique()
distinguish between vocal types in the given dataset.,vocals['type'].unique()
the year 2010 saw the creation of which albums?,"albums.loc[lambda x: x['year']==2010, :]"
retrieve the titles of albums released in the year 2010.,"albums.loc[lambda x: x['year']==2010, :]"
"who wrote the song named ""le pop""?","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['title']=='le pop', ['firstname', 'lastname']]"
"retrieve the first and last name of artists who participated in the composition of ""le pop"".","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[lambda x: x['title']=='le pop', ['firstname', 'lastname']]"
which musician's last name appeared the most often in the titles of his compositions?,"pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').groupby('lastname').size().sort_values(ascending=false).index[0]"
"what is the instrument used by the musician with the last name ""heilo"" in the song ""badlands""?","pd.merge(pd.merge(pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'),songs,left_on='songid',right_on='songid'),instruments,on=['songid', 'bandmateid']).loc[(lambda x: x['lastname']=='heilo')(band) & (lambda x: x['title']=='badlands')(songs)],on='instrument')['instrument']"
"find the instruments utilized by the musician with the last-name ""heilo"" in the song ""badlands"".","pd.merge(pd.merge(pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'),songs,left_on='songid',right_on='songid'),instruments,on=['songid', 'bandmateid']).loc[(lambda x: x['lastname']=='heilo')(band) & (lambda x: x['title']=='badlands')(songs)],on='instrument')['instrument']"
"how many instruments were utilized in the song ""badlands""?","pd.merge(instruments, songs, on='songid').loc[lambda x: x['title']=='badlands', 'instrument'].nunique()"
"how many musical instruments were used in the song ""badlands""?","pd.merge(instruments, songs, on='songid').loc[lambda x: x['title']=='badlands', 'instrument'].nunique()"
"which vocal types were utilized in the song ""badlands""?","pd.merge(vocals, songs, on='songid').loc[lambda x: x['title']=='badlands', 'type']"
"what type of vocals were utilized in the composition of the song ""badlands""?","pd.merge(vocals, songs, on='songid').loc[lambda x: x['title']=='badlands', 'type']"
"provide me with the total number of vocal types used in song ""le pop"".","pd.merge(vocals, songs, on='songid').loc[lambda x: x['title']=='le pop'].shape[0]"
"what is the count of vocal types that were utilized in the song ""le pop""?","pd.merge(vocals, songs, on='songid').loc[lambda x: x['title']=='le pop'].shape[0]"
how many songs are there wherein the vocals have been shared?,"pd.merge(vocals, songs, on='songid').loc[lambda x: x['type']=='shared', 'title'].nunique()"
what is the count of songs which have shared vocals?,"pd.merge(vocals, songs, on='songid').loc[lambda x: x['type']=='shared', 'title'].nunique()"
retrieve the names of songs that do not have a back vocal.,"pd.merge(vocals, songs, on='songid', how='inner').loc[lambda x: x['type']!='back', 'title'].drop_duplicates()"
return me the names of all songs without back vocals.,"pd.merge(vocals, songs, on='songid', how='inner').loc[lambda x: x['type']!='back', 'title'].drop_duplicates()"
"which vocal type was played most often by the band mates called ""solveig""?","pd.merge(vocals, band, left_on='bandmate', right_on='id').query('firstname == ""solveig""').groupby('type').size().sort_values(ascending=false).head(1).index[0]"
what are the names of the types of vocals that were played by the band member named solveig the most?,"pd.merge(vocals, band, left_on='bandmate', right_on='id').query('firstname == ""solveig""').groupby('type').size().sort_values(ascending=false).head(1).index[0]"
"which vocal type does the musician with last name ""heilo"" play in ""der kapitan""?","pd.merge(pd.merge(vocals, songs, on='songid'), band, left_on='bandmate', right_on='id').loc[lambda x: (x['lastname'] == 'heilo') & (x['title'] == 'der kapitan'), 'type']"
"what types of vocals were employed by a musician with the last name heilö in the creation of ""der kapitan""?","pd.merge(pd.merge(vocals, songs, on='songid'), band, left_on='bandmate', right_on='id').loc[lambda x: (x['lastname'] == 'heilo') & (x['title'] == 'der kapitan'), 'type']"
identify the first name of a singer who has performed in most songs.,"pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, left_on='songid', right_on='songid').groupby('firstname').size().sort_values(ascending=false).index[0]"
what is the first name of the artist who participated in the most songs?,"pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, left_on='songid', right_on='songid').groupby('firstname').size().sort_values(ascending=false).index[0]"
which vocal type has the guitarist with first name marianne played the most?,"vocals.merge(band, left_on='bandmate', right_on='id').query('firstname==""marianne""').groupby('type').size().sort_values(ascending=false).index[0]"
"determine the vocal type of the band mate who bears the first name of ""marianne"" played most frequently.","vocals.merge(band, left_on='bandmate', right_on='id').query('firstname==""marianne""').groupby('type').size().sort_values(ascending=false).index[0]"
"provide the first and last name of the performers in the back stage for the song ""der kapitan"".","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[(lambda x: x['title']=='der kapitan') & (lambda x: x['stageposition']=='back'), ['firstname', 'lastname']]"
"retrieve the first and last name of the artist who performed the back stage for the song ""der kapitan"".","pd.merge(pd.merge(performance, band, left_on='bandmate', right_on='id'), songs, on='songid').loc[(lambda x: x['title']=='der kapitan') & (lambda x: x['stageposition']=='back'), ['firstname', 'lastname']]"
retrieve the titles of songs that do not have backing vocals.,"pd.merge(vocals, songs, on='songid', how='inner').loc[lambda x: x['type']!='back', 'title'].drop_duplicates()"
retrieve the names of songs that do not have backing vocals.,"pd.merge(vocals, songs, on='songid', how='inner').loc[lambda x: x['type']!='back', 'title'].drop_duplicates()"
"determine the titles of songs in album ""a kiss before you go: live in hamburg"".","pd.merge(pd.merge(albums, tracklists, left_on='aid', right_on='albumid'), songs, on='songid').loc[lambda x: x['title_x'] == 'a kiss before you go: live in hamburg', 'title_y']"
"list down the titles that are present in the album ""a kiss before you go: live in hamburg"".","pd.merge(pd.merge(albums, tracklists, left_on='aid', right_on='albumid'), songs, on='songid').loc[lambda x: x['title_x'] == 'a kiss before you go: live in hamburg', 'title_y']"
provide the details of all the songs present in various albums of the label universal music group.,"albums.merge(tracklists, left_on='aid', right_on='albumid').merge(songs, on='songid').loc[lambda x: x['label']=='universal music group', 'title']"
"get the complete titles of all the songs of albums that are under the label of ""universal music group"".","albums.merge(tracklists, left_on='aid', right_on='albumid').merge(songs, on='songid').loc[lambda x: x['label']=='universal music group', 'title']"
determine the total number of songs in all of the album releases.,"pd.merge(pd.merge(albums.loc[lambda x: x['type']=='studio'], tracklists, left_on='aid', right_on='albumid'), songs, on='songid')['title'].nunique()"
how many songs are present in studio albums?,"pd.merge(pd.merge(albums.loc[lambda x: x['type']=='studio'], tracklists, left_on='aid', right_on='albumid'), songs, on='songid')['title'].nunique()"
who is the founder/inventor of sony?,"manufacturers.loc[lambda x: x['name']=='sony', 'founder']"
please find out the name of the founder of sony.,"manufacturers.loc[lambda x: x['name']=='sony', 'founder']"
what is the complete address of the company whose founder is james?,"manufacturers.loc[lambda x: x['founder']=='james', 'headquarter']"
list down all the manufacturers and their headquarters in descending order based on annual revenue.,"manufacturers[['name', 'headquarter']].sort_values('revenue', ascending=false)"
"arrange the names of all manufacturers, ascending or descending, according to their revenue.","manufacturers[['name', 'headquarter']].sort_values('revenue', ascending=false)"
"compute the average, maximum and total revenue of all companies.","manufacturers['revenue'].agg(['mean', 'max', 'sum'])"
provide me the total revenues earned across all manufacturers.,"manufacturers['revenue'].agg(['mean', 'max', 'sum'])"
what companies were created by andy?,(manufacturers['founder'] == 'andy').sum()
please provide me with the number of companies founded by andy.,(manufacturers['founder'] == 'andy').sum()
obtain the revenue figures of the companies whose headquarters are located at austin.,"manufacturers.loc[manufacturers['headquarter']=='austin', 'revenue'].sum()"
what is the full listing of cities?,manufacturers['headquarter'].unique()
provide me with the distinct headquarters of manufacturers.,manufacturers['headquarter'].unique()
compare the number of manufacturers based in beijing or tokyo.,"manufacturer.loc[lambda x: x['headquarter'].isin(['tokyo', 'beijing'])].shape[0]"
how many companies have their headquarters in tokyo or beijing?,"manufacturer.loc[lambda x: x['headquarter'].isin(['tokyo', 'beijing'])].shape[0]"
return the name(s) of the founder of the company that begins with the letter 's'.,"manufacturers.loc[manufacturers['name'].str.startswith('s'), 'founder']"
list out the founders whose first letter is 's' in the companies.,"manufacturers.loc[manufacturers['name'].str.startswith('s'), 'founder']"
retrieve the titles of companies that are between 100 and 150 million in revenue.,"manufacturers.loc[(manufacturers['revenue'] >= 100) & (manufacturers['revenue'] <= 150), 'name']"
provide me with the titles of all companies with annual revenues between $100 and $150.,"manufacturers.loc[(manufacturers['revenue'] >= 100) & (manufacturers['revenue'] <= 150), 'name']"
determine the total revenue of companies that operate from tokyo or taiwan.,"manufacturers.loc[manufacturers['headquarter'].isin(['tokyo','taiwan']), 'revenue'].sum()"
provide me with the revenue generated by companies with their headquarters in tokyo or taiwan.,"manufacturers.loc[manufacturers['headquarter'].isin(['tokyo','taiwan']), 'revenue'].sum()"
retrieve the title of products that are manufactured by both creative labs and sony.,"products.loc[lambda x: x['manufacturer'].isin(manufacturers.loc[manufacturers['name']=='creative labs', 'code'])]['name'].intersect(products.loc[lambda x: x['manufacturer'].isin(manufacturers.loc[manufacturers['name']=='sony', 'code'])]['name'])"
return the names of products manufactured by both creative labs and sony.,"products.loc[lambda x: x['manufacturer'].isin(manufacturers.loc[manufacturers['name']=='creative labs', 'code'])]['name'].intersect(products.loc[lambda x: x['manufacturer'].isin(manufacturers.loc[manufacturers['name']=='sony', 'code'])]['name'])"
"search the title, headquarters and founder of the manufacturer that has the highest sales.","manufacturers.sort_values('revenue', ascending=false).iloc[0][['name', 'headquarter', 'founder']]"
"retrieve the name of company that has the highest revenue, headquarters and founders.","manufacturers.sort_values('revenue', ascending=false).iloc[0][['name', 'headquarter', 'founder']]"
"provide me with the name, headquarter and revenue of manufacturers sorted in descending order of their revenue.","manufacturers[['name', 'headquarter', 'revenue']].sort_values('revenue', ascending=false)"
"retrieve the names of manufacturers, their headquarters and the revenues for each company, sorted in descending order.","manufacturers[['name', 'headquarter', 'revenue']].sort_values('revenue', ascending=false)"
retrieve the names of the companies whose revenue was higher than the average revenue of all companies.,"manufacturers.loc[manufacturers['revenue'] > manufacturers['revenue'].mean(), 'name']"
what are the names of manufacturers whose revenues are higher than the average of all manufacturers?,"manufacturers.loc[manufacturers['revenue'] > manufacturers['revenue'].mean(), 'name']"
find the names of enterprises whose income is smaller than the sum of incomes of all companies located in austin.,"manufacturers.loc[lambda x: x['revenue']<manufacturers.loc[lambda x: x['headquarter']=='austin', 'revenue'].min(), 'name']"
what are the names of businesses that have the lowest revenue among any manufacturer in austin?,"manufacturers.loc[lambda x: x['revenue']<manufacturers.loc[lambda x: x['headquarter']=='austin', 'revenue'].min(), 'name']"
what is the total revenue of austin companies whose revenue is greater than that of any manufacturer in austin?,"manufacturers.loc[lambda x: x['revenue'] > manufacturers.loc[lambda y: y['headquarter']=='austin', 'revenue'].min(), 'revenue'].sum()"
determine the revenues of directors of companies of each founder.,manufacturers.groupby('founder')['revenue'].sum()
what is the total revenue of companies created by founder?,manufacturers.groupby('founder')['revenue'].sum()
obtain the title and revenue of the firm that earns the highest revenue in each city.,"manufacturers.groupby('headquarter').agg({'name': 'first', 'revenue': 'max', 'headquarter': 'first'})[['name', 'revenue', 'headquarter']]"
list the names of the companies with the highest revenues in each headquarter city and their corresponding revenues.,"manufacturers.groupby('headquarter').agg({'name': 'first', 'revenue': 'max', 'headquarter': 'first'})[['name', 'revenue', 'headquarter']]"
determine the total revenue for each manufacturer.,manufacturers.groupby('name')['revenue'].sum()
what is the total revenue earned by each manufacturer?,manufacturers.groupby('name')['revenue'].sum()
"send to me the average prices of products from each company. also, send me the names of each company.","pd.merge(products, manufacturers, left_on='manufacturer', right_on='code').groupby('name').agg({'price': 'mean'})"
what are the average product prices for each manufacturer?,"pd.merge(products, manufacturers, left_on='manufacturer', right_on='code').groupby('name').agg({'price': 'mean'})"
retrieve the number of products that are produced by different outlets at different headquarters.,"pd.merge(products, manufacturers, left_on='manufacturer', right_on='code').groupby('headquarter')['name'].nunique()"
what is the count of products that are manufactured in each headquarter city?,"pd.merge(products, manufacturers, left_on='manufacturer', right_on='code').groupby('headquarter')['name'].nunique()"
determine the number of items not manufactured by sony.,"products.loc[~products['name'].isin(products.merge(manufacturers.loc[manufacturers['name']=='sony', 'code'], how='inner', left_on='manufacturer', right_on='code', suffixes=['', '_sony'])['name']), 'name'].nunique()"
what is the number of products that are not made by sony?,"products.loc[~products['name'].isin(products.merge(manufacturers.loc[manufacturers['name']=='sony', 'code'], how='inner', left_on='manufacturer', right_on='code', suffixes=['', '_sony'])['name']), 'name'].nunique()"
retrieve the names of entities that do not possess dvd drives.,"manufacturers.loc[~manufacturers['name'].isin(pd.merge(products.loc[products['name']=='dvd drive', 'manufacturer'], manufacturers, left_on='manufacturer', right_on='code')['name_y'])]['name']"
what are the titles of companies that do not manufacture dvd drives?,"manufacturers.loc[~manufacturers['name'].isin(pd.merge(products.loc[products['name']=='dvd drive', 'manufacturer'], manufacturers, left_on='manufacturer', right_on='code')['name_y'])]['name']"
"how many products, showing the name of the company, does each manufacturer produce?","pd.merge(products, manufacturers, left_on='manufacturer', right_on='code').groupby('name').size().reset_index(name='count')"
what is the number of products manufactured by each manufacturer?,"pd.merge(products, manufacturers, left_on='manufacturer', right_on='code').groupby('name').size().reset_index(name='count')"
retrieve the names of all the products in the store.,products['name']
returned a list of all products.,products['name']
provide me with the names and the prices of all the products in the store.,"products[['name', 'price']]"
please provide me with the titles of all products along with the prices.,"products[['name', 'price']]"
what are the titles of products that have prices ranging from 0-199?,"products.loc[lambda x: x['price']<=200, 'name']"
return all product information with respect to their price range from $60 to $120.,products[(products['price'] >= 60) & (products['price'] <= 120)]
what information is associated with all the products that have a price between 60 and 120?,products[(products['price'] >= 60) & (products['price'] <= 120)]
give the average price of all products.,products['price'].mean()
provide me with the average price for all the products.,products['price'].mean()
could you provide me with the average price of all products with the manufacturer code equal to 2?,"products.loc[lambda x: x['manufacturer']==2, 'price'].mean()"
retrieve the average price of products where manufacturer code equals 2.,"products.loc[lambda x: x['manufacturer']==2, 'price'].mean()"
provide the count of products whose prices are greater than or equal to $180.,(products['price'] >= 180).sum()
what are the total number of products whose price exceeds $180?,(products['price'] >= 180).sum()
select the title and price of all the products with a price higher than or equal to $180. sort the outputs alphabetically by product name and then by price.,"products.loc[lambda x: x['price'] >= 180].sort_values(['price', 'name'], ascending=[false, true])[['name', 'price']]"
how many products were ordered that had a price tag of at least 180? sort them in terms of decreasing price and increasing product name.,"products.loc[lambda x: x['price'] >= 180].sort_values(['price', 'name'], ascending=[false, true])[['name', 'price']]"
retrieve all the product data along with their manufacturer data.,"pd.merge(products, manufacturers, left_on='manufacturer', right_on='code')"
"please provide me with complete data about all products, along with information about their manufacturer.","pd.merge(products, manufacturers, left_on='manufacturer', right_on='code')"
provide me with the average price for all the products manufactured by a specified manufacturer.,products.groupby('manufacturer')['price'].mean()
what is the average price for each manufacturer code? grouped by product,products.groupby('manufacturer')['price'].mean()
"list the average price of all manufacturers' products, displaying the manufacturer's name.","products.merge(manufacturers, left_on='manufacturer', right_on='code').groupby('name')['price'].mean()"
what is the average price range for products grouped by manufacturer name?,"products.merge(manufacturers, left_on='manufacturer', right_on='code').groupby('name')['price'].mean()"
select the titles of manufacturers whose products cost no less than $150.,"products.merge(manufacturers, left_on='manufacturer', right_on='code').groupby('name').filter(lambda x: x['price'].mean() >= 150).groupby('name').agg(avg_price=('price', 'mean'))"
return only the title and price of the cheapest product.,"products[['name', 'price']].sort_values('price').head(1)"
what is the product name and its cost?,"products[['name', 'price']].sort_values('price').head(1)"
list down the name of each manufacturer along with the price of its most expensive product.,"products.merge(manufacturers, left_on='manufacturer', right_on='code').groupby('name_y').agg({'name': 'max', 'price': 'max'})"
what are the manufacturer names and prices of the most expensive product of each?,"products.merge(manufacturers, left_on='manufacturer', right_on='code').groupby('name_y').agg({'name': 'max', 'price': 'max'})"
please specify the code of the cheapest product in each respective product category.,"products.groupby('name').agg({'code':'first', 'price':'min'}).reset_index()[['code','name','price']]"
provide me with the titles of the least expensive products in each category along with their respective codes.,"products.groupby('name').agg({'code':'first', 'price':'min'}).reset_index()[['code','name','price']]"
please provide me with the details of the problem log generated most recently.,"problem_log.sort_values('log_entry_date', ascending=false).iloc[0]['problem_log_id']"
give me the latest log entry.,"problem_log.sort_values('log_entry_date', ascending=false).iloc[0]['problem_log_id']"
please provide me with the ids of the oldest log and the problem for which it was generated.,"problem_log[['problem_log_id', 'problem_id']].sort_values('log_entry_date').head(1)"
retrieve the oldest log id and its corresponding problem id.,"problem_log[['problem_log_id', 'problem_id']].sort_values('log_entry_date').head(1)"
determine the id and the date of the log for the instance whose id is 10.,"problem_log.loc[problem_log['problem_id'] == 10, ['problem_log_id', 'log_entry_date']]"
provide me the ids and descriptions of the problems from the problem logs.,"problem_log[['problem_log_id', 'log_entry_description']]"
what ids and descriptions are associated with log entries?,"problem_log[['problem_log_id', 'log_entry_description']]"
"what is the list of title, first and last names of staff members who were assigned to the problem whose id is 1?","pd.merge(staff, problem_log[problem_log['problem_id']==1], left_on='staff_id', right_on='assigned_to_staff_id')[['staff_first_name', 'staff_last_name']].drop_duplicates()"
could you please provide me with the first and last names of the staff members assigned to the problem issue id 1?,"pd.merge(staff, problem_log[problem_log['problem_id']==1], left_on='staff_id', right_on='assigned_to_staff_id')[['staff_first_name', 'staff_last_name']].drop_duplicates()"
provide me with the id of problems assigned to rylan homenick along with the id of logs that have been maintained for the same.,"pd.merge(staff.loc[(staff['staff_first_name']=='rylan')&(staff['staff_last_name']=='homenick'), ['staff_id']], problem_log, left_on='staff_id', right_on='assigned_to_staff_id')[['problem_id', 'problem_log_id']].drop_duplicates()"
what is the id problem and log assigned to rylan homenick?,"pd.merge(staff.loc[(staff['staff_first_name']=='rylan')&(staff['staff_last_name']=='homenick'), ['staff_id']], problem_log, left_on='staff_id', right_on='assigned_to_staff_id')[['problem_id', 'problem_log_id']].drop_duplicates()"
how many problems are there regarding product satisfaction?,"pd.merge(product.loc[lambda x: x['product_name']=='voluptatem'], problems, on='product_id').shape[0]"
"how many complaints were made for ""voluptatem"" to date?","pd.merge(product.loc[lambda x: x['product_name']=='voluptatem'], problems, on='product_id').shape[0]"
"provide me with the number of problems faced by the product with the highest number of problems. also, send me the name of the product.","pd.merge(product, problems, on='product_id').groupby('product_name').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
what product has the most complaints? provide me the count and title.,"pd.merge(product, problems, on='product_id').groupby('product_name').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
please provide me with a list of descriptions of the problems that were reported by the staff whose first name is christop.,"problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id').loc[lambda x: x['staff_first_name']=='christop', 'problem_description']"
"which problems were mentioned in the complaints of the employees with first name ""christop""? show the descriptions of the complaints.","problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id').loc[lambda x: x['staff_first_name']=='christop', 'problem_description']"
do return the first names of the staff whose last name is bosco and the id numbers of the problems reported by these individuals.,"pd.merge(problems, staff, left_on='reported_by_staff_id', right_on='staff_id').loc[lambda x: x['staff_last_name']=='bosco', 'problem_id']"
"what are the issues that were marked by staff members with last name ""bosco""? provide me with their ids.","pd.merge(problems, staff, left_on='reported_by_staff_id', right_on='staff_id').loc[lambda x: x['staff_last_name']=='bosco', 'problem_id']"
determine the identifiers of the problems that were reported after 1978-06-26.,"problems.loc[lambda x: x['date_problem_reported'] > '1978-06-26', 'problem_id']"
what is the id of problems reported after 1978-06-26?,"problems.loc[lambda x: x['date_problem_reported'] > '1978-06-26', 'problem_id']"
please determine the ids of the problems that were reported before 1978-06-26.,"problems.loc[lambda x: x['date_problem_reported'] < ""1978-06-26"", 'problem_id']"
which problems were reported before 1978-06-26? provide me with the ids of the problems.,"problems.loc[lambda x: x['date_problem_reported'] < ""1978-06-26"", 'problem_id']"
"for each product that has problems, what is the count of problems and the primary key of the product?","problems.merge(product, on='product_id').groupby('product_id').size().reset_index(name='count')"
"for each product having some issue, list the count of problems along with the product id.","problems.merge(product, on='product_id').groupby('product_id').size().reset_index(name='count')"
"for each product that had problems, find the count of the problems that were reported after 1986-11-13 and the product id.","(pd.merge(problems, product, on='product_id').loc[lambda x: x['date_problem_reported'] > ""1986-11-13""].groupby('product_id').size().reset_index(name='count(*)'))"
please provide me with the product id and the count of problems that were reported after 1986-11-13.,"(pd.merge(problems, product, on='product_id').loc[lambda x: x['date_problem_reported'] > ""1986-11-13""].groupby('product_id').size().reset_index(name='count(*)'))"
provide me with the list of all distinct product names in alphabetical order.,product['product_name'].sort_values().unique()
sort all of the distinctive product names in alphabetical order.,product['product_name'].sort_values().unique()
retrieve the names of products in ascending order of product id.,product.sort_values('product_id')['product_name'].unique()
could you provide me the id of problems reported either by jolie weber or dameon frami?,"pd.concat([problems.merge(staff.loc[(staff['staff_first_name']=='dameon')&(staff['staff_last_name']=='frami')], left_on='reported_by_staff_id', right_on='staff_id')['product_id'],problems.merge(staff.loc[(staff['staff_first_name']=='jolie')&(staff['staff_last_name']=='weber')], left_on='reported_by_staff_id', right_on='staff_id')['product_id']]).drop_duplicates()"
what problems were reported by the staff named dameon frami or jolie weber? provide me with their ids.,"pd.concat([problems.merge(staff.loc[(staff['staff_first_name']=='dameon')&(staff['staff_last_name']=='frami')], left_on='reported_by_staff_id', right_on='staff_id')['product_id'],problems.merge(staff.loc[(staff['staff_first_name']=='jolie')&(staff['staff_last_name']=='weber')], left_on='reported_by_staff_id', right_on='staff_id')['product_id']]).drop_duplicates()"
"for which product was there a problem reported by christop berge, with closure authorized by ashley medhurst?","pd.merge(problems.loc[lambda x: x['reported_by_staff_id'].isin(staff.loc[(staff['staff_first_name']=='christop') & (staff['staff_last_name']=='berge'), 'staff_id'])],problems.loc[lambda x: x['closure_authorised_by_staff_id'].isin(staff.loc[(staff['staff_first_name']=='ashley') & (staff['staff_last_name']=='medhurst'), 'staff_id'])])['product_id']"
what is the id of the problems reported by lysanne turcotte prior to the date of any problem reported by her?,"problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id').loc[lambda x: x['date_problem_reported'] < problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id').loc[lambda y: (y['staff_first_name']=='lysanne')&(y['staff_last_name']=='turcotte'), 'date_problem_reported'].min(), 'problem_id']"
from which day did the total count of problems reported prior to any issue reported by the staff member lysanne turcotte increase? provide the ids of the different problems.,"problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id').loc[lambda x: x['date_problem_reported'] < problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id').loc[lambda y: (y['staff_first_name']=='lysanne')&(y['staff_last_name']=='turcotte'), 'date_problem_reported'].min(), 'problem_id']"
please list down the names of problems that were repaired by rylan homenick after any of the problems reported by rylan homenick.,"problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id')[lambda x: x['date_problem_reported'] > problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id')[lambda y: (y['staff_first_name'] == 'rylan') & (y['staff_last_name'] == 'homenick')]['date_problem_reported'].max()]['problem_id']"
provide the ids of the problems reported after the date of any problems reported by rylan homenick.,"problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id')[lambda x: x['date_problem_reported'] > problems.merge(staff, left_on='reported_by_staff_id', right_on='staff_id')[lambda y: (y['staff_first_name'] == 'rylan') & (y['staff_last_name'] == 'homenick')]['date_problem_reported'].max()]['problem_id']"
provide me a list containing the three products that have the maximum number of problems.,"(pd.merge(problems, product, on='product_id').groupby('product_name').size().sort_values(ascending=false).head(3).reset_index())['product_name']"
"which problems were reported after 1995 for product ""voluptatem""?","problems.merge(product, on='product_id').loc[lambda x: (x['product_name']=='voluptatem') & (x['date_problem_reported'] > '1995'), 'problem_id']"
"what issues were reported from the product ""voluptatem"" and were posted after 1995?","problems.merge(product, on='product_id').loc[lambda x: (x['product_name']=='voluptatem') & (x['date_problem_reported'] > '1995'), 'problem_id']"
"please list the staff members who reported problems from the product ""rem"" but not ""aut.""","pd.merge(pd.merge(problems, product, on='product_id'), staff, on='staff_id').loc[lambda x: x['product_name']=='rem', ['staff_first_name', 'staff_last_name']].merge(pd.merge(problems, product, on='product_id'), staff, on='staff_id').loc[lambda x: x['product_name']=='aut', ['staff_first_name', 'staff_last_name']].drop_duplicates(subset=['staff_first_name', 'staff_last_name'], keep=false)"
"retrieve the first and last names of the staff that reported issues from the product ""rem"" but not ""aut"".","pd.merge(pd.merge(problems, product, on='product_id'), staff, on='staff_id').loc[lambda x: x['product_name']=='rem', ['staff_first_name', 'staff_last_name']].merge(pd.merge(problems, product, on='product_id'), staff, on='staff_id').loc[lambda x: x['product_name']=='aut', ['staff_first_name', 'staff_last_name']].drop_duplicates(subset=['staff_first_name', 'staff_last_name'], keep=false)"
find the products that have been complained about by lacey bosco and kenton champlin.,"pd.merge(pd.merge(problems, product, on='product_id'), staff, left_on='reported_by_staff_id', right_on='staff_id').loc[(lambda x: x['staff_first_name']=='lacey') & (lambda x: x['staff_last_name']=='bosco'), 'product_name'].intersect(pd.merge(pd.merge(problems, product, on='product_id'), staff, left_on='reported_by_staff_id', right_on='staff_id').loc[(lambda x: x['staff_first_name']=='kenton') & (lambda x: x['staff_last_name']=='champlin'), 'product_name']).tolist()"
find the names of products that are reported by both the staff named lacey bosco and the staff named kenton champlin.,"pd.merge(pd.merge(problems, product, on='product_id'), staff, left_on='reported_by_staff_id', right_on='staff_id').loc[(lambda x: x['staff_first_name']=='lacey') & (lambda x: x['staff_last_name']=='bosco'), 'product_name'].intersect(pd.merge(pd.merge(problems, product, on='product_id'), staff, left_on='reported_by_staff_id', right_on='staff_id').loc[(lambda x: x['staff_first_name']=='kenton') & (lambda x: x['staff_last_name']=='champlin'), 'product_name']).tolist()"
how many branches have memberships higher than average?,(branch['membership_amount'] > branch['membership_amount'].mean()).sum()
what is the number of branches that have more than the average of the number of members?,(branch['membership_amount'] > branch['membership_amount'].mean()).sum()
"please list the titles, addresses, and cities of branches in alphabetical order on the basis of their opening years.","branch[['name', 'address_road', 'city']].sort_values('open_year')"
"retrieve the titles of branches, their addresses, roads, and cities ordered by their opening year.","branch[['name', 'address_road', 'city']].sort_values('open_year')"
which three branches of the company have the most number of membership?,"branch.nlargest(3, 'membership_amount')['name']"
what companies has the most number of members under each branch?,"branch.nlargest(3, 'membership_amount')['name']"
provide the names of the cities in which there are branches with 100 or more members.,"branch.loc[lambda x: x['membership_amount'] >= 100, 'city'].unique()"
which cities have more than 100 members?,"branch.loc[lambda x: x['membership_amount'] >= 100, 'city'].unique()"
which years saw the opening of at least two shops?,branch.groupby('open_year').filter(lambda x: len(x) >= 2)['open_year'].unique()
provide me with the minimum and maximum amounts in total number of memberships for all branches opened in 2011 or located at london.,"branch.loc[(branch['open_year']==2011) | (branch['city']=='london'), 'membership_amount'].agg(['min','max'])"
provide the minimum and maximum membership amounts for all branches that opened in either 2011 or are located in london.,"branch.loc[(branch['open_year']==2011) | (branch['city']=='london'), 'membership_amount'].agg(['min','max'])"
display the state and the number of branches opened before 2010 for each city.,branch.loc[lambda x: x['open_year'] < 2010].groupby('city').size()
for which cities were most branches closed before 2010?,branch.loc[lambda x: x['open_year'] < 2010].groupby('city').size()
how many different member levels exist?,member['level'].nunique()
"return the names, hometowns, and levels of all members in an ascending order.","member[['card_number', 'name', 'hometown']].sort_values('level', ascending=false)"
"produce a list of the card numbers, names, and hometowns of each member of the club in descending order of membership level.","member[['card_number', 'name', 'hometown']].sort_values('level', ascending=false)"
what is the membership level with the highest membership?,member.groupby('level').size().sort_values(ascending=false).index[0]
how many members have the highest membership level?,member.groupby('level').size().sort_values(ascending=false).index[0]
present the names and registered branches of members sorted chronologically by registration year.,"pd.merge(pd.merge(membership_register_branch, branch, on='branch_id'), member, on='member_id').sort_values('register_year')[['name_x', 'name_y']]"
please arrange the members and branches of lanyanya bank by their year of registration.,"pd.merge(pd.merge(membership_register_branch, branch, on='branch_id'), member, on='member_id').sort_values('register_year')[['name_x', 'name_y']]"
retrieve the names of branches along with the count of members in each branch that have been registered since 2015.,"membership_register_branch.merge(branch, on='branch_id').loc[lambda x: x['register_year'] > 2015].groupby('name').size()"
"for each branch id, please retrieve the name of branch that were registered after 2015.","membership_register_branch.merge(branch, on='branch_id').loc[lambda x: x['register_year'] > 2015].groupby('name').size()"
retrieve the names of members that have no registered branches.,"member.loc[~member['member_id'].isin(membership_register_branch['member_id']), 'name']"
provide me with the full names of the members that have subscribed to no branches.,"member.loc[~member['member_id'].isin(membership_register_branch['member_id']), 'name']"
list the names of cities that have no registered members.,"branch.loc[~branch['branch_id'].isin(membership_register_branch['branch_id']), ['name', 'city']]"
what are the names of the branches that do not comprise any registered members?,"branch.loc[~branch['branch_id'].isin(membership_register_branch['branch_id']), ['name', 'city']]"
retrieve the name and opening year of the branch with most number of membership registration in 2016.,"pd.merge(membership_register_branch[membership_register_branch['register_year']==2016], branch, on='branch_id').groupby(['branch_id', 'name', 'open_year']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'open_year']]"
"what is the branch name, and when it opened, that registered the highest number of members in 2016?","pd.merge(membership_register_branch[membership_register_branch['register_year']==2016], branch, on='branch_id').groupby(['branch_id', 'name', 'open_year']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'open_year']]"
provide me the full name and home town of the members who registered a branch in 2016.,"pd.merge(membership_register_branch.loc[lambda x: x['register_year']==2016], member, on='member_id')[['name', 'hometown']]"
"what are the full names, locations, and year of registration of members who attended a branch in 2016?","pd.merge(membership_register_branch.loc[lambda x: x['register_year']==2016], member, on='member_id')[['name', 'hometown']]"
find the names of cities with more than one branch opened in the year 2001 and names of cities with a branch having more than 100 members.,"branch.loc[(branch['open_year'] == 2001) & (branch['membership_amount'] > 100), 'city']"
enumerate the citys that have a department that opened in 2001 and also have departments with more than 100 members.,"branch.loc[(branch['open_year'] == 2001) & (branch['membership_amount'] > 100), 'city']"
provide the list of cities with no branch having more than 100 members.,"branch.loc[lambda x: x['membership_amount'] > 100, 'city'].drop_duplicates(keep=false)"
return the names of cities that do not have branches of more than 100 members.,"branch.loc[lambda x: x['membership_amount'] > 100, 'city'].drop_duplicates(keep=false)"
what is the total sum of pounds of purchases in all branches of london in 2018?,"pd.merge(purchase, branch, on='branch_id').loc[lambda x: (x['city']=='london') & (x['year']==2018), 'total_pounds'].sum()"
determine the total weight of pounds purchased in the year 2018 at all london branches?,"pd.merge(purchase, branch, on='branch_id').loc[lambda x: (x['city']=='london') & (x['year']==2018), 'total_pounds'].sum()"
what are the total number of purchases made by members having the level 6 status?,"pd.merge(purchase, member, on='member_id').loc[lambda x: x['level']==6, :].shape[0]"
what is the total sum of purchases for members rated at level 6?,"pd.merge(purchase, member, on='member_id').loc[lambda x: x['level']==6, :].shape[0]"
"retrieve the name of branches in which some individuals whose hometown is in louisville, kentucky and some others whose hometown is hiram, georgia.","branch.loc[pd.merge(pd.merge(membership_register_branch, member.loc[member['hometown']=='louisville ,kentucky'], on='member_id'), branch, on='branch_id')['name'].intersect(pd.merge(pd.merge(membership_register_branch, member.loc[member['hometown']=='hiram ,georgia'], on='member_id'), branch, on='branch_id')['name']).index, 'name']"
what are the names of branches that have at least some members from louisville and hiram?,"branch.loc[pd.merge(pd.merge(membership_register_branch, member.loc[member['hometown']=='louisville ,kentucky'], on='member_id'), branch, on='branch_id')['name'].intersect(pd.merge(pd.merge(membership_register_branch, member.loc[member['hometown']=='hiram ,georgia'], on='member_id'), branch, on='branch_id')['name']).index, 'name']"
"determine the card number of all the members whose hometown addresses include the word ""kentucky"".","member.loc[lambda x: x['hometown'].str.contains('kentucky'), 'card_number']"
give me the ids of members from the state of kentucky.,"member.loc[lambda x: x['hometown'].str.contains('kentucky'), 'card_number']"
determine the count of students in entirety.,student.shape[0]
what is the total count of students?,student.shape[0]
how many records are there in total?,voting_record.shape[0]
how many voting records are in our database?,voting_record.shape[0]
determine the total number of president votes.,voting_record['president_vote'].nunique()
what is the count of distinct president votes?,voting_record['president_vote'].nunique()
what is the maximal age among all the students?,student['age'].max()
what is the oldest age among all the students?,student['age'].max()
return me a list of last names of students who are majoring in major 50.,"student.loc[lambda x: x['major'] == 50, 'lname']"
retrieve the first names of students whose ages are above 22.,"student.loc[lambda x: x['age']>22, 'fname']"
retrieve the surnames of all the students whose age exceeds 22.,"student.loc[lambda x: x['age']>22, 'fname']"
which majors are pursued by male students?,"student.loc[lambda x: x['sex']=='m', 'major']"
retrieve titles of the major of all male students.,"student.loc[lambda x: x['sex']=='m', 'major']"
what is the median age of female students?,"student.loc[lambda x: x['sex']=='f', 'age'].mean()"
determine the average age of female students.,"student.loc[lambda x: x['sex']=='f', 'age'].mean()"
what is the maximum and minimum age of students with a major code of 600?,"student.loc[lambda x: x['major']==600, 'age'].agg(['max', 'min'])"
please provide me with the age of the oldest and youngest students majoring in subject 600.,"student.loc[lambda x: x['major']==600, 'age'].agg(['max', 'min'])"
"retrieve the names of advisors for students that live in a city with city code ""bal"".","student.loc[lambda x: x['city_code']=='bal', 'advisor']"
"provide the names of the advisors for students who are from the city of ""bal"".","student.loc[lambda x: x['city_code']=='bal', 'advisor']"
what is the count of distinct voting averages for secretaries during fall election cycles?,"voting_record.loc[lambda x: x['election_cycle']=='fall', 'secretary_vote'].unique()"
please list all the distinct votes made by secretaries during the fall election cycle.,"voting_record.loc[lambda x: x['election_cycle']=='fall', 'secretary_vote'].unique()"
"determine the number of distinct president votes on august 30, 2015.","voting_record.loc[lambda x: x['registration_date'] == '08/30/2015', 'president_vote'].unique()"
display the number of distinct votes made by the president on 08/30/2015.,"voting_record.loc[lambda x: x['registration_date'] == '08/30/2015', 'president_vote'].unique()"
retrieve the distinct registration dates and the election cycles.,"voting_record[['registration_date', 'election_cycle']].drop_duplicates()"
provide me with the count of the votes of the president and the vice president.,"voting_record[['president_vote', 'vice_president_vote']].drop_duplicates()"
retrieve the president votes and vice president votes.,"voting_record[['president_vote', 'vice_president_vote']].drop_duplicates()"
find all of the distinct last names for the students that voted for a class president.,"pd.merge(student, voting_record, left_on='stuid', right_on='class_president_vote')['lname'].unique()"
what is the count of distinct last names of students who have voted in class elections?,"pd.merge(student, voting_record, left_on='stuid', right_on='class_president_vote')['lname'].unique()"
retrieve the names of distinct students that possess class senator votes.,"pd.merge(student, voting_record, left_on='stuid', right_on='class_senator_vote')['fname'].unique()"
find the names of students who have class president votes.,"pd.merge(student, voting_record, left_on='stuid', right_on='class_senator_vote')['fname'].unique()"
find the unique ages of the students who have cast their vote to elect a secretary in the fall election cycle.,"pd.merge(student, voting_record, left_on='stuid', right_on='secretary_vote').loc[lambda x: x['election_cycle']=='fall', 'age'].unique()"
which distinct ages of students have votes for the secretary in the fall election cycle?,"pd.merge(student, voting_record, left_on='stuid', right_on='secretary_vote').loc[lambda x: x['election_cycle']=='fall', 'age'].unique()"
determine the advisors for students who have treasury votes in the spring election cycle.,"pd.merge(student, voting_record, left_on='stuid', right_on='treasurer_vote').loc[lambda x: x['election_cycle']=='spring', 'advisor'].unique()"
obtain the names of distinct majors for which students have the treasurer vote.,"pd.merge(student, voting_record, left_on='stuid', right_on='treasurer_vote')['major'].unique()"
find the majors of distinct students that received treasury votes.,"pd.merge(student, voting_record, left_on='stuid', right_on='treasurer_vote')['major'].unique()"
retrieve the first and last names of the female students (the sex is f) who have voted president.,"pd.merge(student, voting_record.loc[:, ['president_vote']], left_on='stuid', right_on='president_vote').loc[lambda x: x['sex']=='f', ['fname', 'lname']].drop_duplicates()"
retrieve the names of all the female students who have voted for the president.,"pd.merge(student, voting_record.loc[:, ['president_vote']], left_on='stuid', right_on='president_vote').loc[lambda x: x['sex']=='f', ['fname', 'lname']].drop_duplicates()"
list the full name and id of all the students of age 18 that have vice president votes.,"pd.merge(student, voting_record, left_on='stuid', right_on='vice_president_vote').loc[lambda x: x['age']==18, ['fname', 'lname']].drop_duplicates()"
"list the full name, age, and status of all students who are 18 years old and hold the position of vice president.","pd.merge(student, voting_record, left_on='stuid', right_on='vice_president_vote').loc[lambda x: x['age']==18, ['fname', 'lname']].drop_duplicates()"
what is the number of male (sex is m) students who cast votes for senators in the winter election?,"pd.merge(student, voting_record, left_on='stuid', right_on='class_senator_vote').loc[lambda x: (x['sex']=='m') & (x['election_cycle']=='fall'), :].shape[0]"
how many male students voted in the democratic election for student senators in the fall?,"pd.merge(student, voting_record, left_on='stuid', right_on='class_senator_vote').loc[lambda x: (x['sex']=='m') & (x['election_cycle']=='fall'), :].shape[0]"
determine the count of students with the city of new york as their location as well as those that have voted in spring elections for class senators.,"pd.merge(student.loc[lambda x: x['city_code']=='nyc'], voting_record.loc[lambda x: x['election_cycle']=='spring'], left_on='stuid', right_on='class_senator_vote').shape[0]"
please provide me the names of students that live in the city with code nyc and have class senator votes in the spring election cycle.,"pd.merge(student.loc[lambda x: x['city_code']=='nyc'], voting_record.loc[lambda x: x['election_cycle']=='spring'], left_on='stuid', right_on='class_senator_vote').shape[0]"
determine the average age of students who live in the city of new york and have a secretary's vote in the spring election cycle.,"pd.merge(student, voting_record, left_on='stuid', right_on='secretary_vote').loc[(lambda x: x['city_code'] == 'nyc') & (lambda x: x['election_cycle'] == 'spring'), 'age'].mean()"
"what is the average age of students who have the city code ""nyc"" and have voted in the spring election cycle?","pd.merge(student, voting_record, left_on='stuid', right_on='secretary_vote').loc[(lambda x: x['city_code'] == 'nyc') & (lambda x: x['election_cycle'] == 'spring'), 'age'].mean()"
determine the average age of female students (sex is f) that possess secretary votes during the spring election cycle.,"pd.merge(student[student['sex']=='f'], voting_record[voting_record['election_cycle']=='spring'], left_on='stuid', right_on='secretary_vote')['age'].mean()"
what is the mean of the age of females who had voted in the spring election cycle as secretary?,"pd.merge(student[student['sex']=='f'], voting_record[voting_record['election_cycle']=='spring'], left_on='stuid', right_on='secretary_vote')['age'].mean()"
"retrieve the names of all the students who voted for a vice president, whose city code is not pit, and who have a distinct first names.","student.merge(voting_record, left_on='stuid', right_on='vice_president_vote')['fname'].drop_duplicates().loc[lambda x: x != 'pit']"
"retrieve the lists of first names corresponding to the students who have vice president votes, and who live in cities whose city codes are not pit.","student.merge(voting_record, left_on='stuid', right_on='vice_president_vote')['fname'].drop_duplicates().loc[lambda x: x != 'pit']"
retrieve names of students with president votes and whose advisor is not 2192.,"student.merge(voting_record, left_on='stuid', right_on='president_vote')['lname'].drop_duplicates().except_(student[student['advisor']=='2192']['lname'])"
count the number of students with president votes that do not have 2192 as their advisor.,"student.merge(voting_record, left_on='stuid', right_on='president_vote')['lname'].drop_duplicates().except_(student[student['advisor']=='2192']['lname'])"
retrieve the distinct last names of the students that have president votes and whose advisor has id 8741.,"student.merge(voting_record, left_on='stuid', right_on='president_vote')['lname'].unique().tolist() & student.loc[lambda x: x['advisor']=='8741', 'lname'].unique().tolist()"
what is the list of last names of the students who are students and have vote of president and have 8741 as advisor?,"student.merge(voting_record, left_on='stuid', right_on='president_vote')['lname'].unique().tolist() & student.loc[lambda x: x['advisor']=='8741', 'lname'].unique().tolist()"
please provide me the number of students each advisor counsels.,student.groupby('advisor').size().reset_index(name='count')
which advisor has most students?,student.groupby('advisor').size().reset_index(name='count')
please produce a list of advisors who advise at least 2 students.,student.groupby('advisor').filter(lambda x: len(x) > 2)['advisor'].unique()
provide the names of all majors that do not have more than 3 students.,student.groupby('major').filter(lambda x: len(x) < 3)['major'].unique()
which majors are chosen by less than three students?,student.groupby('major').filter(lambda x: len(x) < 3)['major'].unique()
"for each election cycle, report the total number of voting records.",voting_record.groupby('election_cycle').size().reset_index(name='count(*)')
calculate the count of voting records for each election cycle.,voting_record.groupby('election_cycle').size().reset_index(name='count(*)')
how many students major in ?,student['major'].value_counts().index[0]
find the major that is studied by the greatest number of students.,student['major'].value_counts().index[0]
what is the most prominent major among female (sex is f) students?,student.loc[lambda x: x['sex'] == 'f'].groupby('major').size().sort_values(ascending=false).index[0]
what is the major that is taken by the most female students?,student.loc[lambda x: x['sex'] == 'f'].groupby('major').size().sort_values(ascending=false).index[0]
determine the id of the city with the greatest student population.,student.groupby('city_code').size().sort_values(ascending=false).index[0]
please return the code of a city in which there are the highest number of students.,student.groupby('city_code').size().sort_values(ascending=false).index[0]
what is the division of advisors who have more than 2 students?,students.groupby('advisor').filter(lambda x: len(x) > 2)['advisor'].unique()
which advisors advise at least 2 students?,students.groupby('advisor').filter(lambda x: len(x) > 2)['advisor'].unique()
determine the number of products.,products.shape[0]
what is the count of colors?,ref_colors.shape[0]
how many characters are there in the entity?,characteristics.shape[0]
what is the count of characteristics?,characteristics.shape[0]
provide me with the names and buying prices of all the products.,"products[['product_name', 'typical_buying_price']]"
"provide me with the titles, prices, and product images of all products available.","products[['product_name', 'typical_buying_price']]"
enumerate all the color descriptions.,ref_colors['color_description']
list the colors along with their respective description.,ref_colors['color_description']
retrieve all product characteristic titles.,characteristics['characteristic_name'].unique()
what are the different titles of product characteristics?,characteristics['characteristic_name'].unique()
"what are the titles of products with the category of ""spices""?","products.loc[lambda x: x['product_category_code']=='spices', 'product_name']"
please send the names of the products in the category 'spices'.,"products.loc[lambda x: x['product_category_code']=='spices', 'product_name']"
"provide me with the titles, descriptions and images of products that fall under the category ""herbs"".","pd.merge(products.loc[lambda x: x['product_category_code']=='herbs'], ref_colors, on='color_code')[['product_name', 'color_description', 'product_description']]"
"retrieve the title, color, and product description of the products sold in the 'herbs' category.","pd.merge(products.loc[lambda x: x['product_category_code']=='herbs'], ref_colors, on='color_code')[['product_name', 'color_description', 'product_description']]"
"what is the count of products that are categorized as ""seeds""?",(products['product_category_code'] == 'seeds').sum()
determine the number of products in the 'seeds' category.,(products['product_category_code'] == 'seeds').sum()
"what is the count of products categorized as ""spices"" that are usually sold above 1000?",(products['product_category_code']=='spices') & (products['typical_buying_price'] > 1000).sum()
how many products are in the 'spices' category and have a typical price exceeding 1000?,(products['product_category_code']=='spices') & (products['typical_buying_price'] > 1000).sum()
what are category and typical selling price of cumin?,"products.loc[lambda x: x['product_name']=='cumin', ['product_category_code', 'typical_buying_price']]"
what is the category of 'cumin' and its price?,"products.loc[lambda x: x['product_name']=='cumin', ['product_category_code', 'typical_buying_price']]"
"which category does the given name ""flax"" belong to?","products.loc[lambda x: x['product_name']=='flax', 'product_category_code']"
please provide me with the code of 'flax' category that the product belongs to.,"products.loc[lambda x: x['product_name']=='flax', 'product_category_code']"
"retrieve the title of the product with the color description ""yellow"".","products.merge(ref_colors, on='color_code').loc[lambda x: x['color_description']=='yellow', 'product_name']"
return the product titles that have the color description 'yellow'.,"products.merge(ref_colors, on='color_code').loc[lambda x: x['color_description']=='yellow', 'product_name']"
retrieve the category descriptions of products whose descriptions contain the letter 't'.,"ref_product_categories.merge(products[products['product_description'].str.contains('t')], on='product_category_code', how='inner')['product_category_description']"
what are the descriptive titles of categories that contain products that have a product description containing the letters t?,"ref_product_categories.merge(products[products['product_description'].str.contains('t')], on='product_category_code', how='inner')['product_category_description']"
"describe the color of the product ""catnip"".","pd.merge(products.loc[lambda x: x['product_name'] == 'catnip'], ref_colors, on='color_code')['color_description']"
"retrieve the color code and description of a product named ""chervil""","pd.merge(products, ref_colors, on='color_code').loc[lambda x: x['product_name']=='chervil', ['color_code', 'color_description']]"
please provide me with the color code and description of product with name 'chervil',"pd.merge(products, ref_colors, on='color_code').loc[lambda x: x['product_name']=='chervil', ['color_code', 'color_description']]"
find the product ids and colors of the objects with at least two features.,"(pd.merge(pd.merge(products, ref_colors, on='color_code'), product_characteristics, on='product_id').groupby('product_id').filter(lambda x: len(x) >= 2).loc[:, ['product_id', 'color_description']].drop_duplicates('product_id'))"
what are the product ids and color descriptions of products with two or more characteristics?,"(pd.merge(pd.merge(products, ref_colors, on='color_code'), product_characteristics, on='product_id').groupby('product_id').filter(lambda x: len(x) >= 2).loc[:, ['product_id', 'color_description']].drop_duplicates('product_id'))"
"generate a list of product names with the color ""white"".","products.merge(ref_colors, on='color_code').loc[lambda x: x['color_description']=='white', 'product_name']"
"retrieve the title and price of products that are described as ""yellow"" in color.","pd.merge(products, ref_colors.loc[lambda x: x['color_description']=='yellow'], on='color_code')[['product_name', 'typical_buying_price', 'typical_selling_price']]"
please provide me with the names and asking prices for the products with regards to their color code.,"pd.merge(products, ref_colors.loc[lambda x: x['color_description']=='yellow'], on='color_code')[['product_name', 'typical_buying_price', 'typical_selling_price']]"
retrieve the count of characteristics that the product 'sesame' has.,"pd.merge(products.loc[lambda x: x['product_name']=='sesame'], product_characteristics, on='product_id').shape[0]"
"what is the count of distinct product names that belong to the product ""cumin""?","(products.merge(product_characteristics).merge(characteristics, on='characteristic_id').pipe(lambda x: x[x['product_name'] == 'sesame']).nunique()['characteristic_name'])"
determine the number of different characteristic names the product 'cumin' has.,"(products.merge(product_characteristics).merge(characteristics, on='characteristic_id').pipe(lambda x: x[x['product_name'] == 'sesame']).nunique()['characteristic_name'])"
"list all the characteristic names of product ""sesame"".","pd.merge(pd.merge(products.loc[lambda x: x['product_name']=='sesame'], product_characteristics, on='product_id'), characteristics, on='characteristic_id')['characteristic_name']"
please return the characteristic names of the 'sesame' product.,"pd.merge(pd.merge(products.loc[lambda x: x['product_name']=='sesame'], product_characteristics, on='product_id'), characteristics, on='characteristic_id')['characteristic_name']"
"provide a list of names of product ""cumin"" along with their data types.","pd.merge(pd.merge(products.loc[lambda x: x['product_name']=='cumin'], product_characteristics, on='product_id'), characteristics, on='characteristic_id')[['characteristic_name', 'characteristic_data_type']]"
which product data attributes are 'cumin'?,"pd.merge(pd.merge(products.loc[lambda x: x['product_name']=='cumin'], product_characteristics, on='product_id'), characteristics, on='characteristic_id')[['characteristic_name', 'characteristic_data_type']]"
"retrieve the names and types of the characteristics that pertain to ""sesame"" and that have the attribute type code ""grade"".","pd.merge(pd.merge(products.loc[lambda x: x['product_name']=='sesame'], product_characteristics, on='product_id'), characteristics.loc[lambda x: x['characteristic_type_code']=='grade'], on='characteristic_id')['characteristic_name']"
"how many features does the product named ""laurel"" have?","pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').loc[lambda x: x['product_name']=='laurel'].shape[0]"
how many characteristics of the product named 'laurel' are there?,"pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').loc[lambda x: x['product_name']=='laurel'].shape[0]"
"determine the number of characteristics that are possessed by the product ""flax"".","pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').loc[lambda x: x['product_name']=='flax'].shape[0]"
determine the count of attributes of the 'flax' product.,"pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').loc[lambda x: x['product_name']=='flax'].shape[0]"
what are the product names that possess the color description of 'red' and the 'fast' characteristic?,"pd.merge(pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id'), ref_colors, on='color_code').loc[(lambda x: x['color_description']=='red') & (lambda x: x['characteristic_name']=='fast'), 'product_name']"
"what is the count of products that have the characteristic named ""hot""?","pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').loc[lambda x: x['characteristic_name']=='hot'].shape[0]"
find the total number of products that are scrutinized as 'hot',"pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').loc[lambda x: x['characteristic_name']=='hot'].shape[0]"
what is the list of all distinct product names that possess the term  'warm'?,"pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').loc[lambda x: x['characteristic_name']=='warm', 'product_name'].unique()"
please specify the name of the products that are characterized as 'warm'.,"pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').loc[lambda x: x['characteristic_name']=='warm', 'product_name'].unique()"
"determine the number of products, whose color is ""red"" and whose characteristic is ""slow"".","pd.merge(pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id'), ref_colors, on='color_code').loc[lambda x: (x['color_description']=='red')&(x['characteristic_name']=='slow')].shape[0]"
what are the products that have the color description 'red' and the characteristic name 'slow'?,"pd.merge(pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id'), ref_colors, on='color_code').loc[lambda x: (x['color_description']=='red')&(x['characteristic_name']=='slow')].shape[0]"
"retrieve the count of products that have the keywords ""white"" or ""hot"".","pd.merge(pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id'), ref_colors, on='color_code').loc[lambda x: (x['color_description']=='white') | (x['characteristic_name']=='hot'),:].shape[0]"
what is the count of products that have the color white or a characteristic with the name 'hot'?,"pd.merge(pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id'), ref_colors, on='color_code').loc[lambda x: (x['color_description']=='white') | (x['characteristic_name']=='hot'),:].shape[0]"
"what is the unit of measurement of the product category code ""herbs""?","ref_product_categories.loc[lambda x: x['product_category_code'] == 'herbs', 'unit_of_measure']"
please ask for the unit of measure for 'herb' products.,"ref_product_categories.loc[lambda x: x['product_category_code'] == 'herbs', 'unit_of_measure']"
"identify the product category description of the product category with code ""spices"".","ref_product_categories.loc[lambda x: x['product_category_code'] == 'spices', 'product_category_description']"
what is the description of product category having the sku code 'spices'?,"ref_product_categories.loc[lambda x: x['product_category_code'] == 'spices', 'product_category_description']"
"retrieve the category name as well as the unit of measurement of the product category ""herbs"".","ref_product_categories.loc[ref_product_categories['product_category_code'] == 'herbs', ['product_category_description', 'unit_of_measure']]"
"could you please provide me with the description and units of measurement used for products in the ""herbs"" category?","ref_product_categories.loc[ref_product_categories['product_category_code'] == 'herbs', ['product_category_description', 'unit_of_measure']]"
"what is the unit of measurement of a product named ""cumin""?","pd.merge(products.loc[lambda x: x['product_name']=='cumin'], ref_product_categories, on='product_category_code')['unit_of_measure']"
please specify the unit of measure for cumin.,"pd.merge(products.loc[lambda x: x['product_name']=='cumin'], ref_product_categories, on='product_category_code')['unit_of_measure']"
what is the unit of measurement and product category code for pickled chervil?,"pd.merge(products.loc[lambda x: x['product_name']=='chervil'], ref_product_categories, on='product_category_code')[['unit_of_measure', 'product_category_code']]"
what is the unit of measure and category code for the product 'chervil'?,"pd.merge(products.loc[lambda x: x['product_name']=='chervil'], ref_product_categories, on='product_category_code')[['unit_of_measure', 'product_category_code']]"
"find the product names that are both colored white and do not have a unit of measurement ""handful"".","pd.merge(pd.merge(products, ref_product_categories, on='product_category_code'), ref_colors, on='color_code').loc[lambda x: (x['color_description'] == 'white') & (x['unit_of_measure'] != 'handful'), 'product_name']"
retrieve the names of products that are neither 'white' in color nor measured by the unit 'handful'.,"pd.merge(pd.merge(products, ref_product_categories, on='product_category_code'), ref_colors, on='color_code').loc[lambda x: (x['color_description'] == 'white') & (x['unit_of_measure'] != 'handful'), 'product_name']"
what is the description of the color used for the majority of the products?,"pd.merge(products, ref_colors, on='color_code').groupby('color_description').size().sort_values(ascending=false).index[0]"
provide me with the most frequently occurring color description across products.,"pd.merge(products, ref_colors, on='color_code').groupby('color_description').size().sort_values(ascending=false).index[0]"
what are the common colors of products?,"pd.merge(products, ref_colors, on='color_code').groupby('color_description').size().sort_values().index[0]"
find the name assigned to the color that is the least common amongst all products.,"pd.merge(products, ref_colors, on='color_code').groupby('color_description').size().sort_values().index[0]"
what are the name of the characteristics utilized by maximum number of the commodities?,"pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').groupby('characteristic_name').size().nlargest(1).index[0]"
please provide me with the characteristic that was higher in frequency than all others.,"pd.merge(pd.merge(products, product_characteristics, on='product_id'), characteristics, on='characteristic_id').groupby('characteristic_name').size().nlargest(1).index[0]"
"what are the titles, details, and data types of characteristics that are not used by the products?","characteristics[['characteristic_name', 'other_characteristic_details', 'characteristic_data_type']].loc[~characteristics['characteristic_id'].isin(product_characteristics['characteristic_id'])]"
list the names of characteristics that do not occur in any product.,"characteristics[['characteristic_name', 'other_characteristic_details', 'characteristic_data_type']].loc[~characteristics['characteristic_id'].isin(product_characteristics['characteristic_id'])]"
what is the list of names that are utilized at least twice in the creation of products?,"products.merge(product_characteristics, on='product_id').merge(characteristics, on='characteristic_id').groupby('characteristic_name').filter(lambda x: len(x) >= 2)['characteristic_name'].unique()"
"retrieve the names of characteristics that are featured, singly or multiply, in two or more products.","products.merge(product_characteristics, on='product_id').merge(characteristics, on='characteristic_id').groupby('characteristic_name').filter(lambda x: len(x) >= 2)['characteristic_name'].unique()"
determine the total count of colors that do not occur in any products.,ref_colors[~ref_colors['color_code'].isin(products['color_code'])].shape[0]
determine the total number of colors that are not utilized in any of the products.,ref_colors[~ref_colors['color_code'].isin(products['color_code'])].shape[0]
return me the total count of events.,event.shape[0]
retrieve the names of events by year in chronological sequence.,"event.sort_values('year', ascending=false)['name']"
give me the name of the event that happened most recently.,"event.sort_values('year', ascending=false).iloc[0]['name']"
how many stadiums are in existence?,stadium.shape[0]
retrieve the names of stadiums that can accommodate the maximum number of people.,"stadium.sort_values('capacity', ascending=false).iloc[0]['name']"
retrieve the names of stadiums whose capacity is smaller  than the average capacity.,"stadium.loc[lambda x: x['capacity'] < stadium['capacity'].mean(), 'name']"
identify the country that has the most sports stadiums.,stadium.groupby('country').size().sort_values(ascending=false).index[0]
which country has at most 3 stadiums?,stadium.groupby('country').filter(lambda x: len(x) <= 3)['country'].unique()
which countries possess both stadiums with capacity greater than 60000 and stadiums with capacity less than 50000?,"pd.merge(stadium.loc[stadium['capacity'] > 60000, ['country']], stadium.loc[stadium['capacity'] < 50000, ['country']]).drop_duplicates()"
what is the count of cities that possess a stadium that was opened before the year 2006?,"stadium.loc[lambda x: x['opening_year'] < 2006, 'city'].nunique()"
how many stadiums does each country own?,stadium.groupby('country').size()
list the names of countries that are not equipped with stadiums constructed after 2006.,"stadium['country'].drop_duplicates().reset_index(drop=true).drop(stadium.loc[stadium['opening_year'] > 2006, 'country'].sort_values().index)"
how many stadiums are not located in the country of russia?,(stadium['country'] != 'russia').sum()
"retrieve the names of all swimmers, ranked by their 100 meter scores in ascending order.",swimmer.sort_values('meter_100')['name']
how many different countries did all the swimmers originate from?,swimmer['nationality'].nunique()
list all countries that have more than one swimmer.,swimmer.groupby('nationality').filter(lambda x: len(x) > 1).groupby('nationality').size()
"give me the 200 and 300 meter results of all swimmers that have nationality ""australia"".","swimmer.loc[lambda x: x['nationality']=='australia', ['meter_200', 'meter_300']]"
retrieve the names of swimmers who have won.,"swimmer.merge(record, on='swimmer_id').loc[lambda x: x['result']=='win', 'name']"
what is the name of the stadium that hosted the greatest number of events?,"pd.merge(stadium, event, on='id').groupby('stadium_id')['name'].count().idxmax()"
"retrieve the title and capacity of the stadium where the event named ""world junior"" took place.","stadium.merge(event.loc[lambda x: x['name']=='world junior'], left_on='id', right_on='stadium_id')[['name', 'capacity']]"
retrieve the titles of all stadiums that have never hosted any events.,stadium[~stadium['id'].isin(event['stadium_id'])]['name']
retrieve the name of the swimmer who has the highest number of records.,"swimmer.merge(record, on='id').groupby('swimmer_id')['name'].count().idxmax()"
determine the person who won at least two swimming competitions.,"swimmer.merge(record, on='swimmer_id').groupby('swimmer_id').filter(lambda x: len(x) >= 2)['name']"
"retrieve the name and nationality of the winner of an event who has (i.e., has a result of) won more than once.","swimmer.merge(record[record['result'] == 'win'], on='id').groupby(['swimmer_id', 'name', 'nationality']).filter(lambda x: len(x) > 1).drop_duplicates(subset=['swimmer_id'])[['name', 'nationality']]"
which swimmers have no recorded games?,"swimmer.loc[~swimmer['id'].isin(record['swimmer_id']), 'name']"
"recover the names of swimmers who possess both ""win"" and ""loss"" results in the record.","swimmer.merge(record).loc[lambda x: x['result']=='win', 'name'].to_frame().merge(swimmer.merge(record).loc[lambda x: x['result']=='loss', 'name'].to_frame(), on='name')['name']"
retrieve the names of stadiums in which some australian swimmers have been to.,"pd.merge(pd.merge(pd.merge(swimmer, record, on='id'), event, left_on='event_id', right_on='id'), stadium, left_on='stadium_id', right_on='id').loc[lambda x: x['nationality']=='australia', 'name']"
retrieve the names to stadiums that the most swimmers have visited.,"pd.merge(pd.merge(record, event, left_on='event_id', right_on='id'), stadium, left_on='stadium_id', right_on='id').groupby('stadium_id')['name'].count().idxmax()"
record the details for each swimmer.,swimmer
what is the average capacity of the stadiums that were opened in the year 2005?,"stadium.loc[lambda x: x['opening_year']==2005, 'capacity'].mean()"
how many railway tracks are there?,railway.shape[0]
sort the list of builders of railways in ascending alphabetical order.,railway.sort_values('builder')['builder']
please list the wheels and the locations for the railways.,"railway[['wheels', 'location']]"
"please identify the count of managers in countries that are not ""australia"".","manager.loc[lambda x: x['country'] != 'australia', 'level'].max()"
provide the average age of all managers.,manager['age'].mean()
retrieve the titles of managers in a descending order of level.,manager.sort_values('level')['name']
give me the names of the trains with their corresponding arrival times.,"train[['name', 'arrival']]"
provide me the name of the senior manager.,"manager.sort_values('age', ascending=false).iloc[0]['name']"
retrieve the titles of trains and stations they are in.,"pd.merge(railway, train, on='railway_id')[['name', 'location']]"
"show the builders of the railway tracks that are associated with the trains named ""andaman exp"".","railway.merge(train[train['name'] == 'andaman exp'], on='railway_id')['builder']"
fetch the id and location of railways that are associated with more than one train.,"pd.merge(railway, train, on='railway_id').groupby('railway_id').filter(lambda x: x.shape[0] > 1).loc[:, ['railway_id', 'location']]"
find the trains that were operated by railway companies and builders from an entity with the greatest number of entries.,"pd.merge(railway, train, on='railway_id').groupby('railway_id')['builder'].count().idxmax()"
provide the complete list of major builders of railroads along with the number of railways that were constructed by each builder.,railway.groupby('builder').size().reset_index(name='count')
list the name of builders of railways whose popularity is highest.,railway.groupby('builder').size().sort_values(ascending=false).index[0]
please list the locations of railways and the corresponding number of railways at each location.,railway.groupby('location').size()
list the locations in which more than one railway is present.,railway.groupby('location').filter(lambda x: len(x) > 1)['location'].unique()
what is the number of railways that do not have trains?,"railway.loc[~railway['railway_id'].isin(train['railway_id']), 'objectnumber']"
find the countries whose management teams have both managers of age above 50 and managers of age below 46.,"set(manager.loc[lambda x: x['age'] > 50, 'country']) & set(manager.loc[lambda x: x['age'] < 46, 'country'])"
list out the distinct countries of managers.,manager['country'].unique()
rank the list of working years in descending order by the level.,"manager.sort_values('level', ascending=false)['working_year_starts']"
check the names of the countries that have managers of age 50 or older or younger than 46.,"manager.loc[(manager['age'] > 50) | (manager['age'] < 46), 'country']"
how many unique addresses are there in the united states?,(addresses['country'] == 'usa').sum()
list all the distinct cities in the address record.,addresses['city'].unique()
"display the full name of the state, along with the count of addresses in the state.",addresses.groupby('state_province_county').size().reset_index(name='count')
"please list out the names of customers along with their respective phone numbers, who do not have address information.","customers.loc[~customers['customer_id'].isin(customer_address_history['customer_id']), ['customer_name', 'customer_phone']]"
display the name of the customer who has the most orders.,"pd.merge(customers, customer_orders, on='customer_id').groupby('customer_name').size().sort_values(ascending=false).index[0]"
retrieve the id and full names of product types with at least two products.,products.groupby('product_type_code').filter(lambda x: len(x) >= 2)['product_type_code'].unique()
retrieve the titles of those customers who have both an order in completed status and an order in part status.,"customers.merge(customer_orders).loc[lambda x: x['order_status_code']=='completed', 'customer_name'].intersec(customers.merge(customer_orders).loc[lambda x: x['order_status_code']=='part', 'customer_name'])"
compose a paragraph that summarizes the names and order quantities of the products.,"pd.merge(products, order_items, on='product_id').groupby('product_id')['order_quantity'].sum().reset_index().merge(products, on='product_id')[['product_name', 'order_quantity']]"
"what is the range of the minimum, maximum, and average prices of the products?","products['product_price'].agg(['min', 'max', 'mean'])"
what number of products have a price higher than the average?,(products['product_price'] > products['product_price'].mean()).sum()
"retrieve the customer name, customer address city, and date from and date to for each customer address history.","pd.merge(pd.merge(customer_address_history, customers, on='customer_id'), addresses, on='address_id')[['customer_name', 'city', 'date_from', 'date_to']]"
provide me with the names of customers who use credit card payment method and have more than two orders.,"customers.merge(customer_orders, on='customer_id').loc[lambda x: x['payment_method_code']=='credit card'].groupby('customer_name').filter(lambda x: len(x) > 2)['customer_name']"
retrieve the name and phone number of the customer who ordered the most quantity of a product.,"customers.merge(customer_orders, on='customer_id').merge(order_items, on='order_id').groupby(['customer_id', 'customer_name', 'customer_phone'])[['order_quantity']].sum().sort_values('order_quantity', ascending=false).reset_index()[['customer_name', 'customer_phone']].iloc[0]"
what is the product type and name for those products which have price greater than 1000 or lower than 500?,"products.loc[(products['product_price']>1000) | (products['product_price']<500), ['product_type_code', 'product_name']]"
only return the names of dorms for female.,"dorm.loc[dorm['gender']=='f', 'dorm_name']"
find the titles of dorms that can accommodate more than 300 students.,"dorm.loc[dorm['student_capacity'] > 300, 'dorm_name']"
find the names of all the available dormitories that can house more than 300 students.,"dorm.loc[dorm['student_capacity'] > 300, 'dorm_name']"
what is the number of female students (sex is f) who have an age less than 25?,"student.loc[(student['sex'] == ""f"") & (student['age'] < 25), :].shape[0]"
determine the number of girl students who are younger than 25.,"student.loc[(student['sex'] == ""f"") & (student['age'] < 25), :].shape[0]"
determine the first names of students who are older than 20.,"student.loc[lambda x: x['age'] > 20, 'fname']"
retrieve the first and last names of all students whose ages exceed 20.,"student.loc[lambda x: x['age'] > 20, 'fname']"
recognize the titles for students living in city phl whose age is between 20 and 25.,"student.loc[(student['city_code']=='phl') & (student['age'].between(20, 25)), 'fname']"
please provide me the first names of the students who are between the ages of 20 and 25 and living in philadelphia.,"student.loc[(student['city_code']=='phl') & (student['age'].between(20, 25)), 'fname']"
how many dorms are on campus?,dorm.shape[0]
what number of dormitories are in this database?,dorm.shape[0]
return the number of unique amenities.,dorm_amenity.shape[0]
how many different types of dorm amenities are present?,dorm_amenity.shape[0]
what is the total capacity for all dorms?,dorm['student_capacity'].sum()
how many students exist in the world?,student.shape[0]
determine the average age of each student living in cities.,student.groupby('city_code')['age'].mean()
what is the mean for the average age for each city and what are those cities?,student.groupby('city_code')['age'].mean()
what is the average and maximum capacity of dorm rooms for the students of gender x?,"dorm.loc[dorm['gender']=='x', 'student_capacity'].agg(['mean', 'sum'])"
what is the mean and average capacity for all dorms of specified gender?,"dorm.loc[dorm['gender']=='x', 'student_capacity'].agg(['mean', 'sum'])"
determine the count of dorms that have some amenity.,has_amenity['dormid'].nunique()
what is the count of dorms with amenities?,has_amenity['dormid'].nunique()
return the names of dorms that do not have any amenities.,dorm[~dorm['dormid'].isin(has_amenity['dormid'])]['dorm_name']
determine which dormitories do not have any amenities.,dorm[~dorm['dormid'].isin(has_amenity['dormid'])]['dorm_name']
how many types of genders are represented in the dorms?,dorm['gender'].nunique()
find the capacity and gender type of the dorm whose name contains substring ‘donor’.,"dorm.loc[dorm['dorm_name'].str.contains('donor'), ['student_capacity', 'gender']]"
what's the student capacity and gender type of the dorm whose name begins with the text donor?,"dorm.loc[dorm['dorm_name'].str.contains('donor'), ['student_capacity', 'gender']]"
retrieve the title and gender type of dorms whose capacity is more than 300 or less than 100.,"dorm.loc[(dorm['student_capacity'] > 300) | (dorm['student_capacity'] < 100), ['dorm_name', 'gender']]"
provide the names of dorms that have a maximum occupancy greater than 300 or less than 100.,"dorm.loc[(dorm['student_capacity'] > 300) | (dorm['student_capacity'] < 100), ['dorm_name', 'gender']]"
provide me with the count of different majors and their corresponding cities.,"(student['major'].nunique(), student['city_code'].nunique())"
what is the count of unique majors and the number of unique city codes?,"(student['major'].nunique(), student['city_code'].nunique())"
fetch the names of the dorms which have tv lounge and study room as amenities.,"set(dorm.loc[dorm['dormid'].isin(has_amenity.loc[has_amenity['amenid'].isin(dorm_amenity.loc[dorm_amenity['amenity_name'] == 'tv lounge', 'amenid']), 'dormid']), 'dorm_name']).intersection(set(dorm.loc[dorm['dormid'].isin(has_amenity.loc[has_amenity['amenid'].isin(dorm_amenity.loc[dorm_amenity['amenity_name'] == 'study room', 'amenid']), 'dormid']), 'dorm_name']))"
what is the dorm that is accompanied by a tv lounge and study room?,"set(dorm.loc[dorm['dormid'].isin(has_amenity.loc[has_amenity['amenid'].isin(dorm_amenity.loc[dorm_amenity['amenity_name'] == 'tv lounge', 'amenid']), 'dormid']), 'dorm_name']).intersection(set(dorm.loc[dorm['dormid'].isin(has_amenity.loc[has_amenity['amenid'].isin(dorm_amenity.loc[dorm_amenity['amenity_name'] == 'study room', 'amenid']), 'dormid']), 'dorm_name']))"
retrieve the names of dorms that do not have study room as an amenity but have tv lounge.,"pd.merge(pd.merge(dorm, has_amenity, on='dormid'), dorm_amenity, on='amenid').query('amenity_name == ""tv lounge""')['dorm_name'].drop_duplicates().drop(pd.merge(pd.merge(dorm, has_amenity, on='dormid'), dorm_amenity, on='amenid').query('amenity_name == ""study room""')['dorm_name']).tolist()"
please supply us with the full name and id of dorms that lack a study room.,"pd.merge(pd.merge(dorm, has_amenity, on='dormid'), dorm_amenity, on='amenid').query('amenity_name == ""tv lounge""')['dorm_name'].drop_duplicates().drop(pd.merge(pd.merge(dorm, has_amenity, on='dormid'), dorm_amenity, on='amenid').query('amenity_name == ""study room""')['dorm_name']).tolist()"
"next, provide the last names of all students who fit either condition: female or living in bal or male and under 20.","student.loc[(student['sex']=='f')&(student['city_code']=='bal'), 'lname'].append(student.loc[(student['sex']=='m')&(student['age']<20), 'lname']).drop_duplicates()"
identify the dormitory with the largest capacity.,"dorm.sort_values('student_capacity', ascending=false).iloc[0]['dorm_name']"
retrieve the titles of the dormitory with the greatest capacity.,"dorm.sort_values('student_capacity', ascending=false).iloc[0]['dorm_name']"
enumerate the amenities in alphabetical order.,dorm_amenity['amenity_name'].sort_values()
list the names of dorm amenities that are sorted in alphabetical order.,dorm_amenity['amenity_name'].sort_values()
retrieve the code of the city where the most of students are living.,student.groupby('city_code').size().sort_values(ascending=false).index[0]
what is the code for the city with the highest number of students?,student.groupby('city_code').size().sort_values(ascending=false).index[0]
provide me with the first name and last name of the students who are younger than the average student age.,"student.loc[lambda x: x['age'] < x['age'].mean(), ['fname', 'lname']]"
please give me the names of all students that are younger than average.,"student.loc[lambda x: x['age'] < x['age'].mean(), ['fname', 'lname']]"
".list the first and last names of students who are not living in the city with code hkg, and sort the results by their ages.","student.loc[lambda x: x['city_code']!='hkg'][['fname', 'lname']].sort_values('age')"
retrieve the names and ages of all students who are not residing in the city hkg.,"student.loc[lambda x: x['city_code']!='hkg'][['fname', 'lname']].sort_values('age')"
provide me the names of all amenities in the anonymous donor hall and sort them in alphabetically.,"pd.merge(pd.merge(dorm_amenity, has_amenity, on='amenid'), dorm, on='dormid').loc[lambda x: x['dorm_name']=='anonymous donor hall', 'amenity_name'].sort_values()"
"in alphabetical order, which amenities does anonymous donor hall have?","pd.merge(pd.merge(dorm_amenity, has_amenity, on='amenid'), dorm, on='dormid').loc[lambda x: x['dorm_name']=='anonymous donor hall', 'amenity_name'].sort_values()"
fetch the count of dorms and capacity separated by gender.,"dorm.groupby('gender').agg(count=('gender', 'count'),sum=('student_capacity', 'sum'))['count', 'sum']"
how many dorms are there and what capacity do they accommodate?,"dorm.groupby('gender').agg(count=('gender', 'count'),sum=('student_capacity', 'sum'))['count', 'sum']"
determine the average and oldest age for students of different gender.,"student.groupby('sex')['age'].agg(['mean', 'max']).reset_index()"
how many students have the average and the oldest age for each gender?,"student.groupby('sex')['age'].agg(['mean', 'max']).reset_index()"
list the counts of students in each major.,student.groupby('major').size().reset_index(name='count')
what is the count of students in major x?,student.groupby('major').size().reset_index(name='count')
please provide me with the count of students and the average age of students living in each city.,"student.groupby('city_code').agg(count=('age', 'count'), average=('age', 'mean'), city_code=('city_code', 'max'))"
how many students reside in each city and what are their average ages?,"student.groupby('city_code').agg(count=('age', 'count'), average=('age', 'mean'), city_code=('city_code', 'max'))"
"collect the variables, age, and sex (code: m) from each student from each city.","student.loc[lambda x: x['sex']=='m'].groupby('city_code').agg({'age': 'mean', 'sex': 'count'})"
what is the average age of all students in each city?,"student.loc[lambda x: x['sex']=='m'].groupby('city_code').agg({'age': 'mean', 'sex': 'count'})"
produce the number of students for cities which have more than 1 student.,student.groupby('city_code').filter(lambda x: len(x) > 1).groupby('city_code').size().reset_index(name='count')
what is the count of students from each city and what cities have more than one cities?,student.groupby('city_code').filter(lambda x: len(x) > 1).groupby('city_code').size().reset_index(name='count')
fetch the names and initials of students who are not members of the largest major.,"student.loc[lambda x: x['major'] != student.groupby('major').size().idxmax(), ['fname', 'lname']]"
retrieve the first and last names of the students that are not in the largest major.,"student.loc[lambda x: x['major'] != student.groupby('major').size().idxmax(), ['fname', 'lname']]"
what is the count of students whose age is older than the average age for both genders?,student.loc[lambda x: x['age'] > x['age'].mean()].groupby('sex')['age'].count()
what are the average ages of students of each gender?,student.loc[lambda x: x['age'] > x['age'].mean()].groupby('sex')['age'].count()
please provide me with the name of the dormitory and the average age of its residents.,"pd.merge(pd.merge(student, lives_in, on='stuid'), dorm, on='dormid').groupby('dorm_name')['age'].mean()"
what is the mean average age of residents for each dorm and the dormitory names?,"pd.merge(pd.merge(student, lives_in, on='stuid'), dorm, on='dormid').groupby('dorm_name')['age'].mean()"
provide the names of the dorms that can accommodate more than 100 students along with the count of amenities provided.,dorm.merge(has_amenity).loc[lambda x: x['student_capacity']>100].groupby('dormid').size().reset_index(name='count(*)')
for which dorm are the maximum amenities available?,dorm.merge(has_amenity).loc[lambda x: x['student_capacity']>100].groupby('dormid').size().reset_index(name='count(*)')
give me the count of students who are older than 20 in each dorm.,student.merge(lives_in).merge(dorm).loc[lambda x: x['age']>20].groupby('dorm_name').size().reset_index(name='count')
what is the number of students who are aged more than 20 in each dorm?,student.merge(lives_in).merge(dorm).loc[lambda x: x['age']>20].groupby('dorm_name').size().reset_index(name='count')
provide me the first name of students who live in the smith hall.,"pd.merge(pd.merge(student, lives_in, on='stuid'), dorm, on='dormid').loc[lambda x: x['dorm_name']=='smith hall', 'fname']"
provide me the list of first names for all students in smith hall.,"pd.merge(pd.merge(student, lives_in, on='stuid'), dorm, on='dormid').loc[lambda x: x['dorm_name']=='smith hall', 'fname']"
what is the overall population of students who live in the dorm with the largest capacity?,"student.merge(lives_in).merge(dorm).loc[lambda x: x['student_capacity']==dorm['student_capacity'].max(), 'age'].mean()"
what is the mean age of students that live in the largest dorm?,"student.merge(lives_in).merge(dorm).loc[lambda x: x['student_capacity']==dorm['student_capacity'].max(), 'age'].mean()"
determine the number of male students that are residing in the male dormitory.,"pd.merge(pd.merge(student, lives_in, on='stuid'), dorm, on='dormid').loc[lambda x: x['gender']=='m'].shape[0]"
give the count of students who are living in male dormitories.,"pd.merge(pd.merge(student, lives_in, on='stuid'), dorm, on='dormid').loc[lambda x: x['gender']=='m'].shape[0]"
retrieve the number of female students with f sex living in smith hall.,"pd.merge(pd.merge(student, lives_in, on='stuid'), dorm, on='dormid').loc[lambda x: (x['dorm_name']=='smith hall') & (x['sex']=='f'), :].shape[0]"
how many females live in smith hall?,"pd.merge(pd.merge(student, lives_in, on='stuid'), dorm, on='dormid').loc[lambda x: (x['dorm_name']=='smith hall') & (x['sex']=='f'), :].shape[0]"
fetch a list of all amenities of the smith hall dormitory.,"pd.merge(pd.merge(dorm[dorm['dorm_name']=='smith hall'], has_amenity, on='dormid'), dorm_amenity, on='amenid')['amenity_name']"
list the titles of the amenities that smith hall has.,"pd.merge(pd.merge(dorm[dorm['dorm_name']=='smith hall'], has_amenity, on='dormid'), dorm_amenity, on='amenid')['amenity_name']"
provide me the names of amenities offered in smith hall dorm.,"pd.merge(pd.merge(dorm[dorm['dorm_name']=='smith hall'], has_amenity, on='dormid'), dorm_amenity, on='amenid').sort_values('amenity_name')['amenity_name']"
provide me with a list of amenities that are in alphabetical order in smith hall.,"pd.merge(pd.merge(dorm[dorm['dorm_name']=='smith hall'], has_amenity, on='dormid'), dorm_amenity, on='amenid').sort_values('amenity_name')['amenity_name']"
determine the amenity that is most commonly available in all dormitories.,"has_amenity.merge(dorm_amenity, on='amenid').groupby('amenid')['amenity_name'].count().reset_index().sort_values(by='amenity_name', ascending=false).iloc[0, 1]"
"which common amenity (e.g., television, internet) is most frequently present in the dorms?","has_amenity.merge(dorm_amenity, on='amenid').groupby('amenid')['amenity_name'].count().reset_index().sort_values(by='amenity_name', ascending=false).iloc[0, 1]"
determine the first name of students who live in the dorm with the most number of amenities.,"student.merge(lives_in).loc[lambda x: x['dormid'].isin(dorm.merge(has_amenity).merge(dorm_amenity).groupby('dormid').size().sort_values().tail(1).index), 'fname']"
return the names of the students who live in the dormitory with the most amenities.,"student.merge(lives_in).loc[lambda x: x['dormid'].isin(dorm.merge(has_amenity).merge(dorm_amenity).groupby('dormid').size().sort_values().tail(1).index), 'fname']"
fetch the name of dorms that have the smallest number of amenities.,"(pd.merge(pd.merge(dorm, has_amenity, on='dormid'), dorm_amenity, on='amenid').groupby('dorm_name').agg({'student_capacity': 'first', 'amenity': 'count'}).sort_values('amenity').head(1))"
what is the title and capacity of the least-equipped dorm room?,"(pd.merge(pd.merge(dorm, has_amenity, on='dormid'), dorm_amenity, on='amenid').groupby('dorm_name').agg({'student_capacity': 'first', 'amenity': 'count'}).sort_values('amenity').head(1))"
retrieve the titles of dormitories that do not possess amenity tv lounge.,"dorm['dorm_name'].iloc[~dorm['dormid'].isin(pd.merge(pd.merge(has_amenity, dorm_amenity, on='amenid'), dorm, on='dormid').loc[lambda x: x['amenity_name']=='tv lounge', 'dormid'])]"
retrieve the names of dorms that were not equipped with a tv lounge.,"dorm['dorm_name'].iloc[~dorm['dormid'].isin(pd.merge(pd.merge(has_amenity, dorm_amenity, on='amenid'), dorm, on='dormid').loc[lambda x: x['amenity_name']=='tv lounge', 'dormid'])]"
determine the full name and id of student who live in the dorms which have amenities tv lounge.,"student.merge(lives_in).loc[lambda x: x['dormid'].isin(has_amenity.merge(dorm_amenity.loc[lambda x: x['amenity_name']=='tv lounge']).dormid), ['fname', 'lname']]"
provide the first and last names of all students living in a dorm room that has a tv lounge.,"student.merge(lives_in).loc[lambda x: x['dormid'].isin(has_amenity.merge(dorm_amenity.loc[lambda x: x['amenity_name']=='tv lounge']).dormid), ['fname', 'lname']]"
retrieve the names and ages of students who live in the dorms that do not have amenity tv lounge.,"student.merge(lives_in).loc[~lives_in['dormid'].isin(has_amenity.merge(dorm_amenity.loc[lambda x: x['amenity_name'] == 'tv lounge'], on='amenid')['dormid']), ['fname', 'age']]"
"kindly provide me the first and last name, along with their respective age, of all students who reside in dorms with a tv lounge.","student.merge(lives_in).loc[~lives_in['dormid'].isin(has_amenity.merge(dorm_amenity.loc[lambda x: x['amenity_name'] == 'tv lounge'], on='amenid')['dormid']), ['fname', 'age']]"
"reveal the amenities of the dorm where the student with surname ""smith"" resides.","pd.merge(pd.merge(pd.merge(pd.merge(dorm, has_amenity, on='dormid'), dorm_amenity, on='amenid'), lives_in, on='dormid'), student, on='stuid').loc[lambda x: x['lname']=='smith', 'amenity_name']"
provide the amenities that are possessed by the dormitory room of a student whose last name is smith.,"pd.merge(pd.merge(pd.merge(pd.merge(dorm, has_amenity, on='dormid'), dorm_amenity, on='amenid'), lives_in, on='dormid'), student, on='stuid').loc[lambda x: x['lname']=='smith', 'amenity_name']"
how many customers exist?,customers.shape[0]
determine the total number of customers.,customers.shape[0]
"retrieve the emails and phone numbers of all customers, ordered according to emails and phone numbers.","customers[['email_address', 'phone_number']].sort_values(by=['email_address', 'phone_number'])"
"please list all the email addresses and phone numbers of the customers, sorted alphabetically by email address and phone number.","customers[['email_address', 'phone_number']].sort_values(by=['email_address', 'phone_number'])"
"please list the codes for the city type ""good credit rating"" with the least number of customers.",customers.loc[lambda x: x['customer_type_code']=='good credit rating'].groupby('town_city').size().sort_values().head(1).index[0]
provide to me the names of the products along with the count of complaints that they have been subjected to.,"pd.merge(products, complaints, on='product_id').groupby('product_name').size().reset_index(name='count')"
retrieve the names of products along with the complaint count for each.,"pd.merge(products, complaints, on='product_id').groupby('product_name').size().reset_index(name='count')"
which customers have made the most complaints against the product?,"pd.merge(customers, complaints, on='customer_id').groupby('customer_id')['email_address'].count().sort_values().head(1)"
please provide me with a list of emails of customers who have filed complaints on the product which has had the largest count of complaints.,"pd.merge(customers, complaints, on='customer_id').groupby('customer_id')['email_address'].count().sort_values().head(1)"
find the details of customer who has raised the least number of complaints.,"pd.merge(pd.merge(products, complaints, on='product_id'), customers, on='customer_id').groupby('customer_id')['product_name'].nunique().sort_values().head(1).index[0]"
retrieve the names of products whose owners have filed the fewest complaints.,"pd.merge(pd.merge(products, complaints, on='product_id'), customers, on='customer_id').groupby('customer_id')['product_name'].nunique().sort_values().head(1).index[0]"
"please supply me with the phone number of the last-filed complaint, if it exists.","customers.merge(complaints, on='customer_id').sort_values('date_complaint_raised', ascending=false).iloc[0]['phone_number']"
provide me the contact number for the most recent customer who filed a complaint.,"customers.merge(complaints, on='customer_id').sort_values('date_complaint_raised', ascending=false).iloc[0]['phone_number']"
find the title and phone number of the customers who have never filed a complaint with any of the branches of your company.,"customers.loc[~customers['customer_id'].isin(complaints['customer_id']), ['email_address', 'phone_number']]"
provide me the emails and mobile numbers of customers who have never filed a complaint.,"customers.loc[~customers['customer_id'].isin(complaints['customer_id']), ['email_address', 'phone_number']]"
retrieve the phone numbers of all the customers and staff.,"pd.concat([customers['phone_number'], staff['phone_number']]).drop_duplicates()"
could you provide me with the phone numbers of all the customers and all the staff members?,"pd.concat([customers['phone_number'], staff['phone_number']]).drop_duplicates()"
"what is the parameter of the item named ""chocolate""?","products.loc[lambda x: x['product_name']=='chocolate', 'product_description']"
"can you provide me with a description of a product called ""chocolate""?","products.loc[lambda x: x['product_name']=='chocolate', 'product_description']"
retrieve the item name and category for the most expensive product.,"products[['product_name', 'product_category_code']].nlargest(1, 'product_price')"
which product name corresponds to code that categorizes the product as the highest priced one?,"products[['product_name', 'product_category_code']].nlargest(1, 'product_price')"
give me the prices for products which have never incurred any complaints.,"products.loc[~products['product_id'].isin(complaints['product_id']), 'product_price']"
what is the count of products that never received any complaint?,"products.loc[~products['product_id'].isin(complaints['product_id']), 'product_price']"
what is the average price per unit of each product type in each category?,products.groupby('product_category_code')['product_price'].mean()
what is the average selling price of products that belong to each category?,products.groupby('product_category_code')['product_price'].mean()
retrieve the last name of a staff member who handled the complaint of the cheapest product.,"pd.merge(pd.merge(staff, complaints, on='staff_id'), products, on='product_id').sort_values('product_price').iloc[0]['last_name']"
what is the last name of the staff member who handled the complaint on the product with the lowest cost?,"pd.merge(pd.merge(staff, complaints, on='staff_id'), products, on='product_id').sort_values('product_price').iloc[0]['last_name']"
what complaint status has more than three records on file?,complaints.groupby('complaint_status_code').filter(lambda x: len(x) > 3)['complaint_status_code'].unique()
what are the status codes for complaints that have more than 3 corresponding complaints?,complaints.groupby('complaint_status_code').filter(lambda x: len(x) > 3)['complaint_status_code'].unique()
"retrieve the name of staff whose email address contains ""wrau"".","staff.loc[lambda x: x['email_address'].str.contains('wrau', case=false), 'last_name']"
"identify the last names that appear in the email addresses containing the substring ""wrau"".","staff.loc[lambda x: x['email_address'].str.contains('wrau', case=false), 'last_name']"
what is the count of customers that are associated with the customer type that is most extensive?,customers.groupby('customer_type_code').size().sort_values(ascending=false).iloc[[0]].reset_index(drop=true)
determine the count of customers that contain the most frequently occurring customer type.,customers.groupby('customer_type_code').size().sort_values(ascending=false).iloc[[0]].reset_index(drop=true)
retrieve the titles of the staff who have had the first complaint.,"pd.merge(staff, complaints, on='staff_id').sort_values('date_complaint_raised').iloc[0]['last_name']"
please return the last name and id of a staff member who handled a complaint the earliest date raised.,"pd.merge(staff, complaints, on='staff_id').sort_values('date_complaint_raised').iloc[0]['last_name']"
what is the total count of complaint type codes?,complaints['complaint_type_code'].nunique()
how many different types of complaint codes are there?,complaints['complaint_type_code'].nunique()
"provide me with the address line 1 and 2 of the customer with email ""vbogisich@example.org"".","customers.loc[customers['email_address'] == ""vbogisich@example.org"", ['address_line_1', 'address_line_2']]"
"please show me the first 2 lines of the address of the customer with the email address ""vbogisich@example.org"".","customers.loc[customers['email_address'] == ""vbogisich@example.org"", ['address_line_1', 'address_line_2']]"
give the values for each of the complaint statuses for the number of complaints with product failure type.,complaints.loc[lambda x: x['complaint_type_code']=='product failure'].groupby('complaint_status_code').size().reset_index(name='count')
"provide the amount of complaints with the type code ""product failure"", with each different status code.",complaints.loc[lambda x: x['complaint_type_code']=='product failure'].groupby('complaint_status_code').size().reset_index(name='count')
give me the first and last name of the top 5 staff members who have handled the maximum number of complaints.,staff.merge(complaints).groupby('staff_id')['first_name'].agg(['count']).sort_values('count').head(5)
please provide me with the first name of the first 5 staff members that have received the most complaints.,staff.merge(complaints).groupby('staff_id')['first_name'].agg(['count']).sort_values('count').head(5)
identify the state with the most customers.,customers.groupby('state').size().sort_values().index[0]
please provide me with the name of the state that has the most customers.,customers.groupby('state').size().sort_values().index[0]
what is the total count of submissions?,len(submission)
determine the number of submissions.,len(submission)
"how many submissions were submitted by jitendra malik, and in what order were they submitted?",submission.sort_values('scores')['author']
"retrieve the authors of submissions, arrange them in ascending order of their submission scores, and return their titles.",submission.sort_values('scores')['author']
list the authors of submissions along with their institutes.,"submission[['author', 'college']]"
"for each submission, list its author along with their affiliated colleges","submission[['author', 'college']]"
"provide me the names of authors from whichever college is ""florida"" or ""temple"".","submission.loc[lambda x: x['college'].isin(['florida', 'temple']), 'author']"
"list the authors who submitted papers to college ""florida"" or ""temple"".","submission.loc[lambda x: x['college'].isin(['florida', 'temple']), 'author']"
what is the mean score of submissions?,submission['scores'].mean()
return the average score of submissions.,submission['scores'].mean()
which author has achieved the highest score in a submission?,"submission.sort_values('scores', ascending=false).iloc[0]['author']"
return the names of colleges along with the number of students from that college who have submitted papers.,submission.groupby('college').size().reset_index(name='count')
"for each college, return the college name and the count of submissions by authors from that college.",submission.groupby('college').size().reset_index(name='count')
please return me the names of colleges that are most regularly employed by the authors of submissions.,submission.groupby('college').size().nlargest(1).index[0]
what is the number of authors who have submitted papers to universities?,submission.groupby('college').size().nlargest(1).index[0]
realize the names of the colleges whose authors have both submission scores larger than 90 and scores lower than 80.,"submission.loc[lambda x: x['scores'] > 90, 'college'].intersect(submission.loc[lambda x: x['scores'] < 80, 'college'])"
identify all the authors and specify their submissions and their acceptance/rejection results.,"pd.merge(acceptance, submission, on='submission_id')[['author', 'result']]"
"for each submission, find out the author and acceptance result.","pd.merge(acceptance, submission, on='submission_id')[['author', 'result']]"
fetch the title of the result of the submission that was scored highest.,"acceptance.merge(submission, on='submission_id').sort_values('scores', ascending=false).iloc[0]['result']"
which submission received the highest acceptance rating; please display the result?,"acceptance.merge(submission, on='submission_id').sort_values('scores', ascending=false).iloc[0]['result']"
display the count of submissions by each author along with their name.,"pd.merge(acceptance, submission, on='submission_id').groupby('author')['workshop_id'].nunique()"
retrieve the titles of authors who submitted workshops.,"pd.merge(acceptance, submission, on='submission_id').groupby('author')['workshop_id'].nunique()"
provide me with the names and affiliations of authors that have work cited in more than one workshop.,"pd.merge(acceptance, submission, on='submission_id').groupby('author').filter(lambda x: x['workshop_id'].nunique() > 1)['author'].unique()"
retrieve the names of authors who submitted more than one paper to a workshop.,"pd.merge(acceptance, submission, on='submission_id').groupby('author').filter(lambda x: x['workshop_id'].nunique() > 1)['author'].unique()"
display the date and venue of each workshop in the ascending order of the venue.sentence: which companies were the lowest ranked?  output: what were the lowest ranked companies?,"workshop[['date', 'venue']].sort_values('venue')"
"sort each workshop alphabetically in the order of venue. return the dates, venues, and the workshop names.","workshop[['date', 'venue']].sort_values('venue')"
present the names of authors who have not had a single submission in any of the workshops.,"submission.loc[~submission['submission_id'].isin(acceptance['submission_id']), 'author']"
which authors did not submit their papers to any workshop?,"submission.loc[~submission['submission_id'].isin(acceptance['submission_id']), 'author']"
provide me with the count of investors.,investors['investor_id'].count()
fetch the details of investors.,investors['investor_details']
please show me all distinct lot details.,lots['lot_details'].unique()
"given the maximum transaction amount, return the corresponding id and full name.",transactions['amount_of_transaction'].max()
display all date and volume shares of transactions.,"transactions[['date_of_transaction', 'share_count']]"
what is the aggregate value of transactions?,transactions['share_count'].sum()
list all transaction records with the code 'pur'.,"transactions.loc[lambda x: x['transaction_type_code']=='pur', 'transaction_id']"
"list all the dates of transactions that are of the type ""sale"".","transactions.loc[lambda x: x['transaction_type_code']=='sale', 'date_of_transaction']"
"determine the average sum value of transactions with type code ""sale"".","transactions.loc[lambda x: x['transaction_type_code']=='sale', 'amount_of_transaction'].mean()"
"please provide me with the description of transaction type with the code ""pur"".","ref_transaction_types.loc[lambda x: x['transaction_type_code']=='pur', 'transaction_type_description']"
"provide me with a list of the transaction type code ""pur"" where the share count is greater than or equal to 50.","transactions.loc[(transactions['transaction_type_code']=='pur') & (transactions['share_count']>50), 'amount_of_transaction'].min()"
what date did the transaction take place if the share count was above 100 or the amount was more than 1000?,"transactions.loc[(transactions['share_count'] > 100) | (transactions['amount_of_transaction'] > 1000), 'date_of_transaction']"
obtain the description and date of transactions for share counts lower than 10.,"pd.merge(ref_transaction_types, transactions, on='transaction_type_code').loc[lambda x: x['share_count'] < 10, ['transaction_type_description','date_of_transaction']]"
show me the investors whose transactions consist of purchase of more than 100 shares.,"pd.merge(investors, transactions, on='investor_id').loc[lambda x: x['share_count']>100, 'investor_details']"
what are the codes for all transaction types?,transactions['transaction_type_code'].nunique()
please provide details of lots and investor ids.,"lots[['lot_details', 'investor_id']]"
please list the profile of investors with l in their details.,"pd.merge(investors, lots, on='investor_id').loc[lambda x: x['investor_details']=='l', 'lot_details']"
"return the aggregate details about transactions purchased for amount being more than $10,000.","purchases.merge(transactions, left_on='purchase_transaction_id', right_on='transaction_id').query('amount_of_transaction > 10000')['purchase_details']"
"please provide me with the names of customers and the date, time and amount of funds in transactions for which they paid less than $3,000.","pd.merge(sales, transactions, left_on='sales_transaction_id', right_on='transaction_id').loc[lambda x: x['amount_of_transaction']<3000, ['sales_details', 'date_of_transaction']]"
what is the number of lots associated with a share count that is smaller than 50?,"pd.merge(pd.merge(lots, transactions_lots, on='lot_id'), transactions, on='transaction_id').loc[lambda x: x['share_count']<50, 'lot_details']"
"retrieve the details of the lots associated with transactions whose share count is bigger than 100 and the type code is ""pur"".","pd.merge(pd.merge(lots, transactions_lots, on='lot_id'), transactions, on='transaction_id').loc[lambda x: (x['share_count']>100) & (x['transaction_type_code']=='pur'), 'lot_details']"
compute the average transaction amount for different transaction types.,transactions.groupby('transaction_type_code')['amount_of_transaction'].mean()
report the data on the maximum and minimum share count of transaction types.,"transactions.groupby('transaction_type_code').agg({'share_count': ['max', 'min']}).reset_index()"
what is the average of share counts for transactions by different investors?,transactions.groupby('investor_id')['share_count'].mean()
kindly provide me a list of investors in descending order by the average share count.,transactions.groupby('investor_id')['share_count'].mean().sort_values()
show the average amount of transactions for a variety of investors.,transactions.groupby('investor_id')['amount_of_transaction'].mean()
provide the average number of transactions for different lots.,"pd.merge(transactions, transactions_lots, on='transaction_id').groupby('lot_id').agg(avg_amount_of_transaction=('amount_of_transaction', 'mean'))"
"provide a count of the number of transactions with transaction type code ""sale"" for specified investors if it exceeds 0.",transactions.loc[transactions['transaction_type_code']=='sale'].groupby('investor_id').size().reset_index(name='count')
what number of transactions have been recorded for the different investors?,transactions.groupby('investor_id').size().reset_index(name='count')
fetch the transaction type code that is utilized the most infrequently.,transactions.groupby('transaction_type_code').size().reset_index(name='counts').sort_values('counts').iloc[0]['transaction_type_code']
which transaction type code was utilized the most frequently?,transactions.groupby('transaction_type_code').size().sort_values(ascending=false).index[0]
present the description of the most used type.,"pd.merge(ref_transaction_types, transactions, on='transaction_type_code').groupby('transaction_type_code')['transaction_type_description'].count().nlargest(1).index.item()"
display the name and details of the investor that has the most number of transactions.,"pd.merge(investors, transactions, on='investor_id').groupby('investor_id')['investor_details'].first().reset_index().sort_values(by=pd.merge(investors, transactions, on='investor_id').groupby('investor_id').size(), ascending=false).iloc[0]"
display the ids and details for investors who have the 3 highest number of transactions.,"pd.merge(investors, transactions, on='investor_id').groupby(['investor_id', 'investor_details']).size().reset_index(name='count').sort_values('count', ascending=false).head(3)[['investor_id', 'investor_details']]"
retrieve the ids of the investors who have at least two transactions.,"transactions.merge(investors, on='investor_id').groupby('investor_id').filter(lambda x: len(x)>=2)['investor_id'].unique()"
provide the ids and details of investors who have at least two transaction with type code sale.,"investors.merge(transactions[transactions['transaction_type_code'] == 'sale'], on='investor_id').groupby('investor_id')['investor_details'].first().loc[lambda x: x.groupby('investor_id').transform('count').ge(2)]"
what are the dates of transactions with share counts or amounts bigger than or equal to 100?,"transactions.loc[(transactions['share_count']>=100) | (transactions['amount_of_transaction']>=100), 'date_of_transaction']"
provide me with the details of all sales and purchases.,"pd.concat([sales['sales_details'], purchases['purchase_details']])"
retrieve the names of lots that were not involved in any transaction.,lots['lot_details'].loc[~lots['lot_id'].isin(transactions_lots['lot_id'])]
how many hotels are available overall?,hotels.shape[0]
determine the total count of available hotels.,hotels.shape[0]
provide me all the price ranges for hotels in this region.,hotels['price_range']
please provide me with the prices of all the hotels.,hotels['price_range']
present the names of the locations.,locations['location_name'].unique()
provide me with the names and details of all the staff members.,"staff[['name', 'other_details']]"
list the names of staff members along with their details of employment.,"staff[['name', 'other_details']]"
show me the details of all the visitors.,visitors['tourist_details']
what are the details of the visitors?,visitors['tourist_details']
provide the price range details for hotels rated 5 stars.,"hotels.loc[lambda x: x['star_rating_code'] == '5', 'price_range']"
calculate the average price range of hotels that possess a 5 star rating and permit pets.,"hotels.loc[(hotels['star_rating_code'] == '5') & (hotels['pets_allowed_yn'] == 1), 'price_range'].mean()"
"how many five star hotels charge in the range of $250-$500 per night, allowing pets?","hotels.loc[(hotels['star_rating_code'] == '5') & (hotels['pets_allowed_yn'] == 1), 'price_range'].mean()"
"please provide me with the address for the location ""uk gallery"".","locations.loc[lambda x: x['location_name']=='uk gallery', 'address']"
"please indicate the address for location named ""uk gallery"".","locations.loc[lambda x: x['location_name']=='uk gallery', 'address']"
"please provide me with the detail of the ""uk gallery"" location.","locations.loc[lambda x: x['location_name']=='uk gallery', 'other_details']"
"return the address detail of the location named ""uk gallery"".","locations.loc[lambda x: x['location_name']=='uk gallery', 'other_details']"
"which locations have the title ""film""?","locations.loc[locations['location_name'].str.contains('film', case=false), 'location_name']"
"retrieve all the locations whose names contain the word ""film"".","locations.loc[locations['location_name'].str.contains('film', case=false), 'location_name']"
determine the total count of names that comprise all the photos.,photos['name'].nunique()
please specify the count of distinct names associated with each photo.,photos['name'].nunique()
fetch all the distinct visit dates.,visits['visit_date'].unique()
fetch the subject names of tourist attractions that can be accessed by bus.,"tourist_attractions.loc[lambda x: x['how_to_get_there']=='bus', 'name']"
which tourist attractions can we access by bus? what are the names of these places?,"tourist_attractions.loc[lambda x: x['how_to_get_there']=='bus', 'name']"
enumerate the names of the tourist attractions that can be visited either by walking or bus.,"tourist_attractions.loc[tourist_attractions['how_to_get_there'].isin(['bus', 'walk']), ['name', 'opening_hours']]"
list the titles and opening hours of the tourist attractions that we get to by bus or walking.,"tourist_attractions.loc[tourist_attractions['how_to_get_there'].isin(['bus', 'walk']), ['name', 'opening_hours']]"
what are the descriptions of the hotels with prices above 10000?,"pd.merge(hotels, ref_hotel_star_ratings, on='star_rating_code').loc[lambda x: x['price_range']>10000, 'star_rating_description']"
which star rating descriptors are associated with hotels that cost more than 10000?,"pd.merge(hotels, ref_hotel_star_ratings, on='star_rating_code').loc[lambda x: x['price_range']>10000, 'star_rating_description']"
fetch the details of opening hours and timings of the museums.,"pd.merge(museums, tourist_attractions, left_on='museum_id', right_on='tourist_attraction_id')[['museum_details', 'opening_hours']]"
"tell me the detail, opening hour, and location of each museum.","pd.merge(museums, tourist_attractions, left_on='museum_id', right_on='tourist_attraction_id')[['museum_details', 'opening_hours']]"
"which tourist attraction is associated with the photo ""game1""?","pd.merge(photos, tourist_attractions, on='tourist_attraction_id').loc[lambda x: x['name_x']=='game1', 'name_y']"
"what is the name associated with the tourist attraction using the photo ""game1""?","pd.merge(photos, tourist_attractions, on='tourist_attraction_id').loc[lambda x: x['name_x']=='game1', 'name_y']"
"provide the names and descriptions of the photos snapped at the tourist attraction ""film festival"".","pd.merge(photos, tourist_attractions, on='tourist_attraction_id').loc[lambda x: x['name']=='film festival', ['name', 'description']]"
"obtain the titles and descriptions of photos that were taken at the place named ""film festival"".","pd.merge(photos, tourist_attractions, on='tourist_attraction_id').loc[lambda x: x['name']=='film festival', ['name', 'description']]"
what are the details and ways to get to tourist attractions related to royal family?,"pd.merge(royal_family, tourist_attractions, left_on='royal_family_id', right_on='tourist_attraction_id')[['royal_family_details', 'how_to_get_there']]"
"give me the list of tourist attractions related to the royal family and their information (how to get there, entrance fees, etc.)","pd.merge(royal_family, tourist_attractions, left_on='royal_family_id', right_on='tourist_attraction_id')[['royal_family_details', 'how_to_get_there']]"
please provide me with the count of shops that can be reached by walking.,"pd.merge(shops, tourist_attractions, left_on='shop_id', right_on='tourist_attraction_id').query('how_to_get_there == ""walk""')['shop_details']"
provide me with the details describing the shops that can be accessed on foot.,"pd.merge(shops, tourist_attractions, left_on='shop_id', right_on='tourist_attraction_id').query('how_to_get_there == ""walk""')['shop_details']"
"who's the head of the attraction known as ""us museum""?","staff.merge(tourist_attractions.loc[lambda x: x['name']=='us museum'], on='tourist_attraction_id')['name_x']"
please provide me with the name of the person in charge of the us museum.,"staff.merge(tourist_attractions.loc[lambda x: x['name']=='us museum'], on='tourist_attraction_id')['name_x']"
provide me the details of the markets that can be accessed by walking or riding a bus.,"street_markets.merge(tourist_attractions.loc[lambda x: x['how_to_get_there'].isin(['walk','bus'])], left_on='market_id', right_on='tourist_attraction_id')['market_details']"
i would like to know the locations and details of all the markets that are reachable by walk or bus.,"street_markets.merge(tourist_attractions.loc[lambda x: x['how_to_get_there'].isin(['walk','bus'])], left_on='market_id', right_on='tourist_attraction_id')['market_details']"
what details and date belong to the visitor whose full name is 'vincent'?,"visitors.merge(visits, on='tourist_id').loc[lambda x: x['tourist_details']=='vincent', ['visit_date', 'visit_details']]"
return me the visit date and details of the tourist whose details are 'vincent'.,"visitors.merge(visits, on='tourist_id').loc[lambda x: x['tourist_details']=='vincent', ['visit_date', 'visit_details']]"
what is the number of tourist attractions visited by the visitor with id 1234567?,"pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='vincent', 'name']"
retrieve all the tourist attractions visited by the tourist whose detail is vincent.,"pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='vincent', 'name']"
"what are the names of the tourist attractions at which vincent or vivian visited, and when?","tourist_attractions.merge(visits.merge(visitors[visitors['tourist_details'].isin(['vincent', 'vivian'])], on='tourist_id').drop('tourist_id', axis=1), on='tourist_attraction_id')[['name', 'visit_date']]"
"with for each tourist attraction, return its name and its date of visitation by tourists named vincent or vivian.","tourist_attractions.merge(visits.merge(visitors[visitors['tourist_details'].isin(['vincent', 'vivian'])], on='tourist_id').drop('tourist_id', axis=1), on='tourist_attraction_id')[['name', 'visit_date']]"
please show me the average price of hotels for each star rating code.,hotels.groupby('star_rating_code')['price_range'].mean()
"what is the average range of prices for hotels, by star rating code?",hotels.groupby('star_rating_code')['price_range'].mean()
obtain the average prices of hotels for different policies regarding pets.,hotels.groupby('pets_allowed_yn')['price_range'].mean().reset_index()
"what is the average price charged by hotels, grouped by their policy for pets?",hotels.groupby('pets_allowed_yn')['price_range'].mean().reset_index()
"find the title, id and rating for each hotel, starting with the cheapest, and list them in the order from lowest to highest.","hotels[['hotel_id', 'star_rating_code']].sort_values('price_range')"
retrieve the titles of the top 3 costliest hotels.,"hotels.sort_values('price_range', ascending=false)['other_hotel_details'][:3]"
provide me the details regarding the three hotels that have the highest cost.,"hotels.sort_values('price_range', ascending=false)['other_hotel_details'][:3]"
return me the 3 hotels with the lowest prices ratings.,"hotels[['other_hotel_details', 'star_rating_code', 'price_range']].sort_values('price_range').head(3)[['other_hotel_details', 'star_rating_code']]"
which hotels have the lowest price range and what are the stars and details?,"hotels[['other_hotel_details', 'star_rating_code', 'price_range']].sort_values('price_range').head(3)[['other_hotel_details', 'star_rating_code']]"
what were the most popular methods of transport used by tourists?,tourist_attractions.groupby('how_to_get_there')['how_to_get_there'].count().sort_values(ascending=false).head(1).index.values[0]
which transportation method was the most often used to get to tourist attractions?,tourist_attractions.groupby('how_to_get_there')['how_to_get_there'].count().sort_values(ascending=false).head(1).index.values[0]
indicate the title of the attraction that adheres to the attraction type that is most popular.,"pd.merge(ref_attraction_types, tourist_attractions, on='attraction_type_code').groupby('attraction_type_code')['attraction_type_description'].agg(lambda x: x.iloc[0]).sort_values(ascending=false).head(1).reset_index().drop(columns=['attraction_type_code'])"
which type of tourist attractions is the most famous? give me its attraction type and description.,"pd.merge(ref_attraction_types, tourist_attractions, on='attraction_type_code').groupby('attraction_type_code')['attraction_type_description'].agg(lambda x: x.iloc[0]).sort_values(ascending=false).head(1).reset_index().drop(columns=['attraction_type_code'])"
provide me with the count of attractions that can be accessed using each respective transportation method.,tourist_attractions.groupby('how_to_get_there').size().reset_index(name='count')
"list all the ways in which one can reach attractions, together with the count of attractions accessible from each method.",tourist_attractions.groupby('how_to_get_there').size().reset_index(name='count')
"find the title of different tourist attractions, their ids, and count of visits.","pd.merge(tourist_attractions, visits, on='tourist_attraction_id').groupby(['name', 'tourist_attraction_id']).size().reset_index(name='count')"
"provide me with the titles, ids and number of visits of each tourist attraction.","pd.merge(tourist_attractions, visits, on='tourist_attraction_id').groupby(['name', 'tourist_attraction_id']).size().reset_index(name='count')"
return me the names of tourist attractions that are visited by at least two people.,"pd.merge(tourist_attractions, visits, on='tourist_attraction_id').groupby('tourist_attraction_id').filter(lambda x: len(x) >= 2)[['name', 'tourist_attraction_id']]"
which tourist attractions are visited by people at least twice? give me their names and ids.,"pd.merge(tourist_attractions, visits, on='tourist_attraction_id').groupby('tourist_attraction_id').filter(lambda x: len(x) >= 2)[['name', 'tourist_attraction_id']]"
provide me the names and ids of the tourist attractions that are used only once.,"pd.merge(tourist_attractions, visits, on='tourist_attraction_id').groupby('tourist_attraction_id').filter(lambda x: x['tourist_attraction_id'].count()<=1)[['name', 'tourist_attraction_id']]"
who are the names and ids of tourist attractions that are deemed to have been visited only once?,"pd.merge(tourist_attractions, visits, on='tourist_attraction_id').groupby('tourist_attraction_id').filter(lambda x: x['tourist_attraction_id'].count()<=1)[['name', 'tourist_attraction_id']]"
which attractions can be reached on foot or are located at 660 shea crescent?,"pd.merge(locations, tourist_attractions, on='location_id').loc[(locations['address']=='660 shea crescent') | (tourist_attractions['how_to_get_there']=='walk'), 'name']"
please provide me with the names of popular attractions that are both accessible by walk and at address 660 shea crescent.,"pd.merge(locations, tourist_attractions, on='location_id').loc[(locations['address']=='660 shea crescent') | (tourist_attractions['how_to_get_there']=='walk'), 'name']"
retrieve the titles of all tourist attractions that feature parking or shopping as part of their descriptions.,"(pd.merge(pd.merge(tourist_attractions, tourist_attraction_features, on='tourist_attraction_id'), features, on='feature_id').loc[lambda x: x['feature_details']=='park', 'name'].append(pd.merge(pd.merge(tourist_attractions, tourist_attraction_features, on='tourist_attraction_id'), features, on='feature_id').loc[lambda x: x['feature_details']=='shopping', 'name'])).unique()"
identify the tourist attractions which have parking or shopping as their feature details. assign titles to these attractions.,"(pd.merge(pd.merge(tourist_attractions, tourist_attraction_features, on='tourist_attraction_id'), features, on='feature_id').loc[lambda x: x['feature_details']=='park', 'name'].append(pd.merge(pd.merge(tourist_attractions, tourist_attraction_features, on='tourist_attraction_id'), features, on='feature_id').loc[lambda x: x['feature_details']=='shopping', 'name'])).unique()"
retrieve details of tourist attractions that can be reached by bus or are located at the address 254 ottilie junction.,"pd.merge(locations, tourist_attractions, on='location_id').loc[lambda x: (x['address'] == '254 ottilie junction') | (x['how_to_get_there'] == 'bus'), 'name']"
obtain the list of tourist attractions that can be arrived at by bus or located at 254 ottilie junction.,"pd.merge(locations, tourist_attractions, on='location_id').loc[lambda x: (x['address'] == '254 ottilie junction') | (x['how_to_get_there'] == 'bus'), 'name']"
retrieve the names of attractions that vincent and marcelle visited.,"pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='vincent', 'name'].unique() & pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='marcelle', 'name'].unique()"
what tourist attractions did vincent and marcelle visit? retrieve the names of the attractions.,"pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='vincent', 'name'].unique() & pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='marcelle', 'name'].unique()"
retrieve the titles (names) of tourist attractions that alison visited but rosalind did not visit.,"pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='alison', 'name'].unique().difference(pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='rosalind', 'name'].unique())"
give me the list of tourist attractions visited by the tourist named alison but not by rosalind.,"pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='alison', 'name'].unique().difference(pd.merge(pd.merge(tourist_attractions, visits, on='tourist_attraction_id'), visitors, on='tourist_id').loc[lambda x: x['tourist_details']=='rosalind', 'name'].unique())"
how many tourists did not visit any place?,"visitors.loc[~visitors['tourist_id'].isin(visits['tourist_id']), :].shape[0]"
what is the count of tourists who did not visit any place?,"visitors.loc[~visitors['tourist_id'].isin(visits['tourist_id']), :].shape[0]"
what is the total number of video games?,video_games.shape[0]
count the total number of video games you have.,video_games.shape[0]
how many types of video games exist?,video_games['gtype'].nunique()
how many game types are there?,video_games['gtype'].nunique()
list all video game types.,video_games['gtype'].unique()
which types of video games exist?,video_games['gtype'].unique()
return the list of video games and their types in the order of their names.,"video_games[['gname', 'gtype']].sort_values('gname')"
retrieve the names of all video games and their types in alphabetical order.,"video_games[['gname', 'gtype']].sort_values('gname')"
please show me the video games with type collectible card game.,"video_games.loc[lambda x: x['gtype']==""collectible card game"", 'gname']"
how would i retrieve the full range of video games that are classified as collectible cards?,"video_games.loc[lambda x: x['gtype']==""collectible card game"", 'gname']"
what is the category of the video game call of destiny?,"video_games.loc[lambda x: x['gname']=='call of destiny', 'gtype']"
what is the genre of game call of destiny?,"video_games.loc[lambda x: x['gname']=='call of destiny', 'gtype']"
how many video games are classified as massively multiplayer online games?,(video_games['gtype'] == 'massively multiplayer online game').sum()
determine the count of video games that belong to massively multiplayer online game category.,(video_games['gtype'] == 'massively multiplayer online game').sum()
show me the titles of video game types and the number of video games of each type.,video_games.groupby('gtype').size()
what are the categories of video games that are in use and how many of them are present in each category?,video_games.groupby('gtype').size()
which game type has the most number of games?,video_games.groupby('gtype').size().sort_values(ascending=false).index[0]
what type of product has the most games?,video_games.groupby('gtype').size().sort_values(ascending=false).index[0]
which game type has the least number of games?,video_games.groupby('gtype').size().sort_values().index[0]
which type has the fewest boardgames?,video_games.groupby('gtype').size().sort_values().index[0]
display the ids of all students who reside in chi.,"student.loc[lambda x: x['city_code']=='chi', 'stuid']"
please provide me with the id of all the students who live in chi.,"student.loc[lambda x: x['city_code']=='chi', 'stuid']"
show the ids for all students who have an advisor named 1121.,"student.loc[lambda x: x['advisor'] == 1121, 'stuid']"
what student id numbers do all students who possess advisor number 1121 possess?,"student.loc[lambda x: x['advisor'] == 1121, 'stuid']"
list the first names of all students who majored at the 600 level.,"student.loc[lambda x: x['major']==600, 'fname']"
return the titles of all students who are studying in the major numbered 600.,"student.loc[lambda x: x['major']==600, 'fname']"
"show the statistics for the average, minimum, and maximum ages of students who belong to different majors.","student.groupby('major')['age'].agg(['mean', 'min', 'max'])"
"return me the average, minimum, and maximum age of students enrolled in each of the majors.","student.groupby('major')['age'].agg(['mean', 'min', 'max'])"
please list the names of advisors who have at least one student.,student.groupby('advisor').filter(lambda x: len(x)>=2)['advisor'].unique()
return the names of persons who serve as advisors,student.groupby('advisor').filter(lambda x: len(x)>=2)['advisor'].unique()
how many sports do we offer?,sportsinfo['sportname'].nunique()
how many students are engaged in sports?,sportsinfo['stuid'].nunique()
what is the count of students who are engaged in sports?,sportsinfo['stuid'].nunique()
return the ids for all students on scholarship.,"sportsinfo.loc[lambda x: x['onscholarship']=='y', 'stuid']"
provide me the ids for all students that are actively taking part in sports while being on scholarship.,"sportsinfo.loc[lambda x: x['onscholarship']=='y', 'stuid']"
provide the full names of all students who are on scholarship.,"pd.merge(sportsinfo[sportsinfo['onscholarship']=='y'], student, on='stuid')['lname']"
list all surnames of scholarship students.,"pd.merge(sportsinfo[sportsinfo['onscholarship']=='y'], student, on='stuid')['lname']"
how many games are played by all students?,sportsinfo['gamesplayed'].sum()
determine the total number of games played in all matches.,sportsinfo['gamesplayed'].sum()
what is the count of games played by students on scholarship across all football games?,"sportsinfo.loc[(sportsinfo['sportname'] == 'football') & (sportsinfo['onscholarship'] == 'y'), 'gamesplayed'].sum()"
how may football were played by scholarship students?,"sportsinfo.loc[(sportsinfo['sportname'] == 'football') & (sportsinfo['onscholarship'] == 'y'), 'gamesplayed'].sum()"
display the names of sports and the number of students who play them.,sportsinfo.groupby('sportname').size().reset_index(name='count(*)')
what is the count of students that play each sport?,sportsinfo.groupby('sportname').size().reset_index(name='count(*)')
"given an array of student ids, print the total number of sports and games these students played in.","sportsinfo.groupby('stuid').agg(num_entries=('stuid', 'count'), total_gamesplayed=('gamesplayed', 'sum'))"
please provide me with the id and the count of sports played by each student.,"sportsinfo.groupby('stuid').agg(num_entries=('stuid', 'count'), total_gamesplayed=('gamesplayed', 'sum'))"
please list all student ids that have a sportsation of more than 10 hours per week.,sportsinfo.groupby('stuid').filter(lambda x: x['hoursperweek'].sum() > 10)['stuid'].unique()
please provide me with the ids of all students who worked for more than 10 hours per week for all sports.,sportsinfo.groupby('stuid').filter(lambda x: x['hoursperweek'].sum() > 10)['stuid'].unique()
could you provide me the first name and the last name of the student who has the maximum count of sports?,"sportsinfo.merge(student, on='stuid').groupby(['fname', 'lname']).size().reset_index(name='count').sort_values(by='count', ascending=false).head(1)[['fname', 'lname']]"
what is the first name and last name of the student who plays the most sports?,"sportsinfo.merge(student, on='stuid').groupby(['fname', 'lname']).size().reset_index(name='count').sort_values(by='count', ascending=false).head(1)[['fname', 'lname']]"
identify the sport that has the highest number of students who are on scholarship.,"sportsinfo.query(""onscholarship == 'y'"").groupby('sportname').size().sort_values(ascending=false).index[0]"
what is the name of the sport that has the most scholarship students?,"sportsinfo.query(""onscholarship == 'y'"").groupby('sportname').size().sort_values(ascending=false).index[0]"
give me the names of the students who are not involved in sports.,"student.loc[~student['stuid'].isin(sportsinfo['stuid']), 'stuid']"
which students are not involved in sports?,"student.loc[~student['stuid'].isin(sportsinfo['stuid']), 'stuid']"
present the ids of students who possess scholarship and have a major of 600.,"student.loc[lambda x: x['major']==600, 'stuid'].isin(sportsinfo.loc[lambda x: x['onscholarship']=='y', 'stuid']).astype(int).loc[lambda x: x==1].index.values"
provide the ids of students on scholarship in 600 major.,"student.loc[lambda x: x['major']==600, 'stuid'].isin(sportsinfo.loc[lambda x: x['onscholarship']=='y', 'stuid']).astype(int).loc[lambda x: x==1].index.values"
provide the list of student ids who are female and play football.,"pd.merge(student.loc[lambda x: x['sex']=='f', ['stuid']], sportsinfo.loc[lambda x: x['sportname']=='football', ['stuid']])['stuid']"
provide me the ids of all the female students that play football.,"pd.merge(student.loc[lambda x: x['sex']=='f', ['stuid']], sportsinfo.loc[lambda x: x['sportname']=='football', ['stuid']])['stuid']"
fetch the ids of male students who don't play football.,"student.loc[lambda x: x['sex']=='m'].loc[lambda x: ~x['stuid'].isin(sportsinfo.query('sportname==""football""')['stuid'])]['stuid']"
list the percent of hours per week spent on games and the total games played by student david shieber.,"pd.merge(sportsinfo, student, on='stuid').loc[(lambda x: x['fname']=='david')&(lambda x: x['lname']=='shieber'), ['hoursperweek', 'gamesplayed']].sum()"
what is the total number of hours per work and the number of games played by david shieber?,"pd.merge(sportsinfo, student, on='stuid').loc[(lambda x: x['fname']=='david')&(lambda x: x['lname']=='shieber'), ['hoursperweek', 'gamesplayed']].sum()"
list the total hours that students are pursuing per week and the number of games that they are playing.,"pd.merge(sportsinfo, student, on='stuid').loc[lambda x: x['age']<20, ['hoursperweek', 'gamesplayed']].agg('sum')"
what is the count of hours of week and games played by students under 20?,"pd.merge(sportsinfo, student, on='stuid').loc[lambda x: x['age']<20, ['hoursperweek', 'gamesplayed']].agg('sum')"
what is the number of students that play games?,plays_games['stuid'].nunique()
return the names of students who don't play video games.,"student.loc[~student['stuid'].isin(plays_games['stuid']), 'stuid']"
what is the list of ids of all the students who are not video game players?,"student.loc[~student['stuid'].isin(plays_games['stuid']), 'stuid']"
provide me with the ids of students that play video games and play sports.,pd.series(list(set(sportsinfo['stuid']) & set(plays_games['stuid'])))
what ids of students are associated to playing of video games as well as sports activities?,pd.series(list(set(sportsinfo['stuid']) & set(plays_games['stuid'])))
return me the list of game ids and their respective number of hours played.,plays_games.groupby('gameid')['hours_played'].sum()
what are the id and the total duration of each game?,plays_games.groupby('gameid')['hours_played'].sum()
provide a count of student ids and their corresponding number of hours played.,plays_games.groupby('stuid')['hours_played'].sum()
provide me with the count of students and hours played by each student.,plays_games.groupby('stuid')['hours_played'].sum()
provide me the name of the game that was played for the longest time.,"pd.merge(plays_games, video_games, on='gameid').groupby('gameid').agg(hours_played=('hours_played', 'sum'), gname=('gname', 'first')).sort_values('hours_played', ascending=false).iloc[[0], ['gname']]"
list the titles of the games that have been played the most.,"pd.merge(plays_games, video_games, on='gameid').groupby('gameid').agg(hours_played=('hours_played', 'sum'), gname=('gname', 'first')).sort_values('hours_played', ascending=false).iloc[[0], ['gname']]"
retrieve the names of games that surpassed 1000 hours of play.,"pd.merge(plays_games, video_games, on='gameid').groupby('gname').filter(lambda x: x['hours_played'].sum() >= 1000)['gname']"
which games are played for more than 1000 hours?,"pd.merge(plays_games, video_games, on='gameid').groupby('gname').filter(lambda x: x['hours_played'].sum() >= 1000)['gname']"
list the names for all games that were played by linda smith.,"pd.merge(pd.merge(plays_games, video_games, on='gameid'), student, on='stuid').loc[(student['lname']=='smith')&(student['fname']=='linda'), 'gname']"
retrieve the titles of games played by linda smith.,"pd.merge(pd.merge(plays_games, video_games, on='gameid'), student, on='stuid').loc[(student['lname']=='smith')&(student['fname']=='linda'), 'gname']"
find the last and first name of students who are playing football or lacrosse.,"pd.merge(sportsinfo.query('sportname in [""football"", ""lacrosse""]'), student, on='stuid')[['lname', 'fname']]"
what are the first and last names of all students involving in lacrosse or football?,"pd.merge(sportsinfo.query('sportname in [""football"", ""lacrosse""]'), student, on='stuid')[['lname', 'fname']]"
retrieve the first names and ages of students who are playing both football and lacrosse.,"student.loc[student['stuid'].isin(sportsinfo.loc[sportsinfo['sportname'] == 'football', 'stuid'].values.tolist() & sportsinfo.loc[sportsinfo['sportname'] == 'lacrosse', 'stuid'].values.tolist()), ['fname', 'age']]"
provide me with the first and last names and ages of all students who are participating in both the football and lacrosse sports.,"student.loc[student['stuid'].isin(sportsinfo.loc[sportsinfo['sportname'] == 'football', 'stuid'].values.tolist() & sportsinfo.loc[sportsinfo['sportname'] == 'lacrosse', 'stuid'].values.tolist()), ['fname', 'age']]"
retrieve the last name and gender of those students who play both call of destiny and works of widenius games.,"plays_games.merge(video_games, on='gameid').query('gname == ""call of destiny""').merge(plays_games.merge(video_games, on='gameid').query('gname == ""works of widenius"")', on='stuid')[['lname', 'sex']]"
give me the last name and gender of all students who played both call of destiny and works of widenius.,"plays_games.merge(video_games, on='gameid').query('gname == ""call of destiny""').merge(plays_games.merge(video_games, on='gameid').query('gname == ""works of widenius"")', on='stuid')[['lname', 'sex']]"
provide me with the names of all users.,customers['customer_name']
retrieve the names of customers.,customers['customer_name']
please provide me with the total number of unique customers.,customers.shape[0]
what is the mean of the number of items that were ordered in each order?,order_items['order_quantity'].mean()
find the average number of items per order.,order_items['order_quantity'].mean()
"what is the list of names of customers who opted for the payment method ""cash""?","customers.loc[lambda x: x['payment_method']=='cash', 'customer_name']"
"what are customers that utilize ""cash"" as their payment method? return the customer names.","customers.loc[lambda x: x['payment_method']=='cash', 'customer_name']"
provide me with the date that customers whose id is 10 to 20 became customers.,"customers.loc[lambda x: (x['customer_id'] >= 10) & (x['customer_id'] <= 20), 'date_became_customer']"
provide me with the dates during which customers with ids between 10 and 20 became customers.,"customers.loc[lambda x: (x['customer_id'] >= 10) & (x['customer_id'] <= 20), 'date_became_customer']"
which payment method was used by customers most frequently?,customers.groupby('payment_method').size().sort_values(ascending=false).index[0]
determine the payment method that is most frequently used.,customers.groupby('payment_method').size().sort_values(ascending=false).index[0]
which titles are brought to the attention of the most customers using the most popular payment method?,customers.loc[lambda x: x['payment_method'] == customers['payment_method'].value_counts().index[0]]['customer_name']
retrieve the ids of customers who utilize the most widely used payment method.,customers.loc[lambda x: x['payment_method'] == customers['payment_method'].value_counts().index[0]]['customer_name']
list all of the payment methods.,customers['payment_method'].unique()
retrieve all of the distinct payment methods used by customers.,customers['payment_method'].unique()
get the details of all products.,products['product_details'].unique()
provide the details about all products.,products['product_details'].unique()
"retrieve the name of all customers whose last name contains ""alex"".","customers.loc[customers['customer_name'].str.contains('alex'), 'customer_name']"
"which customers' names contain ""alex""? obtain their full name.","customers.loc[customers['customer_name'].str.contains('alex'), 'customer_name']"
"provide me a detail of products whose description contains the words ""latte"" and ""americano"".","products.loc[lambda x: x['product_details'].str.contains('latte|americano'), 'product_details']"
"provide me with the full description of products that either contain the word ""latte"" or ""americano"".","products.loc[lambda x: x['product_details'].str.contains('latte|americano'), 'product_details']"
"what is the content of the address for the customer named ""maudie kertzmann""?","pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').loc[lambda x: x['customer_name']=='maudie kertzmann', 'address_content']"
"please return the address of the client whose name is ""maudie kertzmann"".","pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').loc[lambda x: x['customer_name']=='maudie kertzmann', 'address_content']"
determine the count of customers residing in the area of lake geovannyton.,"pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').loc[lambda x: x['city']=='lake geovannyton'].shape[0]"
provide the count of customers that reside in the city named lake geovannyton.,"pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').loc[lambda x: x['city']=='lake geovannyton'].shape[0]"
retrieve the names of customers who reside in colorado.,"pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').loc[lambda x: x['state_province_county']=='colorado', 'customer_name']"
retrieve the names of customers living in colorado.,"pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').loc[lambda x: x['state_province_county']=='colorado', 'customer_name']"
retrieve the name of cities that do not have any customers.,"addresses.loc[~addresses['city'].isin(pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id')['city'].unique()), 'city']"
which cities do not have any customers?,"addresses.loc[~addresses['city'].isin(pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id')['city'].unique()), 'city']"
which city has the highest number of customers living there?,"pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').groupby('city').size().sort_values(ascending=false).reset_index(name='count').iloc[0]['city']"
fetch the city from which the most customers hail.,"pd.merge(pd.merge(customers, customer_addresses, on='customer_id'), addresses, on='address_id').groupby('city').size().sort_values(ascending=false).reset_index(name='count').iloc[0]['city']"
provide a list of the names of all cities.,addresses['city'].unique()
retrieve the names of the distinct cities.,addresses['city'].unique()
retrieve the city that has post code 255.,"addresses.loc[lambda x: x['zip_postcode']==255, 'city']"
which postal code is 255 located in?,"addresses.loc[lambda x: x['zip_postcode']==255, 'city']"
retrieve the state and country of all cities with postal codes starting with 4.,"addresses.loc[lambda x: x['zip_postcode'].str.startswith('4'), ['state_province_county', 'country']]"
determine the state and country of all the cities that have postal codes starting with 4.,"addresses.loc[lambda x: x['zip_postcode'].str.startswith('4'), ['state_province_county', 'country']]"
fetch the countries having more than 4 addresses listed.,addresses.groupby('country').filter(lambda x: len(x) > 4)['country'].unique()
which countries possess more than four distinct addresses?,addresses.groupby('country').filter(lambda x: len(x) > 4)['country'].unique()
provide the names of the contact channel codes that were used fewer than 5 times.,customer_contact_channels.groupby('channel_code').filter(lambda x: x['customer_id'].nunique() < 5)['channel_code'].unique()
what are the codes for contact channels that were utilized fewer than 5 instances?,customer_contact_channels.groupby('channel_code').filter(lambda x: x['customer_id'].nunique() < 5)['channel_code'].unique()
"provide to me the id of the contact channel utilized by the customer with the first and last name of ""tillman ernser"".","pd.merge(customers[customers['customer_name']=='tillman ernser'], customer_contact_channels, on='customer_id')['channel_code'].unique()"
"provide the contact channel code that was utilized by the customer called ""tillman ernser"".","pd.merge(customers[customers['customer_name']=='tillman ernser'], customer_contact_channels, on='customer_id')['channel_code'].unique()"
"what is the ""active to date"" of the most recent contact channel employed by ""tillman ernser""?","customer_contact_channels.merge(customers.query('customer_name == ""tillman ernser""'), on='customer_id')['active_to_date'].max()"
"please provide me with the date of the latest contact channel used by the customer named ""tillman ernser"".","customer_contact_channels.merge(customers.query('customer_name == ""tillman ernser""'), on='customer_id')['active_to_date'].max()"
what is the time span of contact channels in the database?,(customer_contact_channels['active_to_date'] - customer_contact_channels['active_from_date']).mean()
what is the average active time of contact channels?,(customer_contact_channels['active_to_date'] - customer_contact_channels['active_from_date']).mean()
retrieve the channel code and contact number of a customer contact channel that was active in the longest duration.,"customer_contact_channels.loc[lambda x: x['active_to_date'] - x['active_from_date'] == customer_contact_channels['active_to_date'] - customer_contact_channels['active_from_date'].max(), ['channel_code', 'contact_number']]"
provide me with the channel id and the contact number of the customer contact channel whose active duration was the longest.,"customer_contact_channels.loc[lambda x: x['active_to_date'] - x['active_from_date'] == customer_contact_channels['active_to_date'] - customer_contact_channels['active_from_date'].max(), ['channel_code', 'contact_number']]"
find the name of the customer that uses email as the contact channel and their home address.,"pd.merge(customers, customer_contact_channels.loc[lambda x: x['channel_code']=='email'], on='customer_id')[['customer_name', 'active_from_date']]"
give me the identities of the customers whose contact channel code is e-mail as well as their contact date.,"pd.merge(customers, customer_contact_channels.loc[lambda x: x['channel_code']=='email'], on='customer_id')[['customer_name', 'active_from_date']]"
provide the name of the customer that made the longest order.,"customer_orders.merge(customers, on='customer_id').merge(order_items, on='order_id').loc[lambda x: x['order_quantity'] == order_items['order_quantity'].max(), 'customer_name']"
retrieve the name of customer who purchased the largest amount of goods.,"customer_orders.merge(customers, on='customer_id').merge(order_items, on='order_id').loc[lambda x: x['order_quantity'] == order_items['order_quantity'].max(), 'customer_name']"
what is the first name of the customer who has purchased the most items?,"(pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id').groupby('customer_name').agg({'order_quantity': 'sum'}).sort_values('order_quantity', ascending=false).head(1).index[0])"
please provide me with the name of customers ordering the most merchandise in total.,"(pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id').groupby('customer_name').agg({'order_quantity': 'sum'}).sort_values('order_quantity', ascending=false).head(1).index[0])"
what is the least number of items purchased by the customer making usage of a particular payment method?,"customers.merge(customer_orders, on='customer_id').merge(order_items, on='order_id').groupby('customer_name').agg({'payment_method': 'first', 'order_quantity': 'sum'}).sort_values(by='order_quantity').head(1)['payment_method']"
please provide me with the payment method used by the buyer who purchased the least amount of goods in total.,"customers.merge(customer_orders, on='customer_id').merge(order_items, on='order_id').groupby('customer_name').agg({'payment_method': 'first', 'order_quantity': 'sum'}).sort_values(by='order_quantity').head(1)['payment_method']"
determine the total number of types of products that rodrick heaney has bought till date.,"pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id').loc[lambda x: x['customer_name']=='rodrick heaney', 'product_id'].nunique()"
retrieve the total count of distinct products rodrick heaney has purchased so far.,"pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id').loc[lambda x: x['customer_name']=='rodrick heaney', 'product_id'].nunique()"
"what is the quantity of goods purchased by ""rodrick heaney""?","pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id').loc[lambda x: x['customer_name']=='rodrick heaney', 'order_quantity'].sum()"
"please provide the total quantity of products bought by the customer called ""rodrick heaney"".","pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id').loc[lambda x: x['customer_name']=='rodrick heaney', 'order_quantity'].sum()"
"how many customers have at least an order with status ""cancelled""?","customer_orders.loc[lambda x: x['order_status']=='cancelled', 'customer_id'].nunique()"
"please provide me with the total number of customers who have had at least one order with ""cancelled"" status.","customer_orders.loc[lambda x: x['order_status']=='cancelled', 'customer_id'].nunique()"
"what is the number of orders having both detail and ""second time""?",(customer_orders['order_details'] == 'second time').sum()
"provide me with the count of orders that have ""second time"" as order info.",(customer_orders['order_details'] == 'second time').sum()
"identify the customer name and date of orders with the status ""delivered"".","pd.merge(customers, customer_orders, on='customer_id').loc[lambda x: x['order_status']=='delivered', ['customer_name', 'order_date']]"
"retrieve the customer name and the date of the orders whose status is ""delivered"".","pd.merge(customers, customer_orders, on='customer_id').loc[lambda x: x['order_status']=='delivered', ['customer_name', 'order_date']]"
"what is the count of products present in orders that have status ""cancelled""?","pd.merge(customer_orders.loc[lambda x: x['order_status']=='cancelled'], order_items, on='order_id')['order_quantity'].sum()"
what are the total quantities of products under consideration for orders that were cancelled?,"pd.merge(customer_orders.loc[lambda x: x['order_status']=='cancelled'], order_items, on='order_id')['order_quantity'].sum()"
provide me with the total count of orders placed before 2018-03-17 07:13:53.,"pd.merge(customer_orders, order_items, on='order_id').loc[lambda x: x['order_date'] < '2018-03-17 07:13:53', 'order_quantity'].sum()"
what is the total sum of purchases made before 2018-03-17 07:13:53?,"pd.merge(customer_orders, order_items, on='order_id').loc[lambda x: x['order_date'] < '2018-03-17 07:13:53', 'order_quantity'].sum()"
what is the person that has made the latest order?,"pd.merge(customers, customer_orders, on='customer_id').sort_values(by='order_date', ascending=false).iloc[0]['customer_name']"
return the name of the customer who placed the most recent order.,"pd.merge(customers, customer_orders, on='customer_id').sort_values(by='order_date', ascending=false).iloc[0]['customer_name']"
what is the count of products that were ordered the greatest number of times?,"pd.merge(order_items, products, on='product_id').groupby('product_id')['product_details'].first().sort_values(ascending=false).head(1)"
which product has been ordered most frequently? please provide me the details of the product.,"pd.merge(order_items, products, on='product_id').groupby('product_id')['product_details'].first().sort_values(ascending=false).head(1)"
what is the product id and name?,"pd.merge(order_items, products, on='product_id').groupby('product_id').agg({'order_quantity': 'sum', 'product_details': 'first'}).sort_values('order_quantity', ascending=true).head(1)[['product_details', 'product_id']]"
identify the product that was purchased the most.,"pd.merge(order_items, products, on='product_id').groupby('product_id').agg({'order_quantity': 'sum', 'product_details': 'first'}).sort_values('order_quantity', ascending=true).head(1)[['product_details', 'product_id']]"
"retrieve the address of all residences in east julianaside, texas, or in gleasonmouth, arizona.","pd.concat([addresses.loc[(addresses['city'] == 'east julianaside') & (addresses['state_province_county'] == 'texas'), 'address_content'],addresses.loc[(addresses['city'] == 'gleasonmouth') & (addresses['state_province_county'] == 'arizona'), 'address_content']]).drop_duplicates()"
"retrieve a list containing the street addresses in east julianaside, texas or gleasonmouth, arizona.","pd.concat([addresses.loc[(addresses['city'] == 'east julianaside') & (addresses['state_province_county'] == 'texas'), 'address_content'],addresses.loc[(addresses['city'] == 'gleasonmouth') & (addresses['state_province_county'] == 'arizona'), 'address_content']]).drop_duplicates()"
retrieve the names of consumers who do not make payments in cash.,"customers.loc[lambda x: x['payment_method'] != 'cash', 'customer_name']"
fetch the names of customers who do not use cash as payment method.,"customers.loc[lambda x: x['payment_method'] != 'cash', 'customer_name']"
obtain the names of customers that did not order product latte.,"customers[~customers['customer_name'].isin(pd.merge(pd.merge(pd.merge(customer_orders, order_items, on='order_id'), products, on='product_id'), customers, on='customer_id').loc[lambda x: x['product_details']=='latte', 'customer_name'])]['customer_name']"
retrieve the names of customers that never ordered product latte.,"customers[~customers['customer_name'].isin(pd.merge(pd.merge(pd.merge(customer_orders, order_items, on='order_id'), products, on='product_id'), customers, on='customer_id').loc[lambda x: x['product_details']=='latte', 'customer_name'])]['customer_name']"
retrieve the names of customers who did not make any order.,"customers.loc[~customers['customer_id'].isin(customer_orders['customer_id']), 'customer_name']"
retrieve the names of customers that have never purchased any merchandise.,"customers.loc[~customers['customer_id'].isin(customer_orders['customer_id']), 'customer_name']"
retrieve the names of customers who ordered both products latte and americano.,"pd.merge(pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').loc[lambda x: x['product_details']=='latte', 'customer_name'].unique() & pd.merge(pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').loc[lambda x: x['product_details']=='americano', 'customer_name'].unique()"
give me the names of customers who purchased both products latte and americano.,"pd.merge(pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').loc[lambda x: x['product_details']=='latte', 'customer_name'].unique() & pd.merge(pd.merge(pd.merge(customers, customer_orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').loc[lambda x: x['product_details']=='americano', 'customer_name'].unique()"
determine the total count of artists.,artist.shape[0]
identify the age of all music artists.,artist['age']
provide the counts of all artists' ages.,artist['age']
calculate the average age of all artists.,artist['age'].mean()
provide me the average age across all the artists.,artist['age'].mean()
"what were some of the famous songs composed by the artist ""triumfall""?","artist.loc[lambda x: x['artist'] == 'triumfall', 'famous_title']"
"give me the given name of the singer known as ""triumfall"".","artist.loc[lambda x: x['artist'] == 'triumfall', 'famous_title']"
what distinct famous release dates are recorded?,artist['famous_release_date'].unique()
find all distinct famous release dates for all artists.,artist['famous_release_date'].unique()
give me the complete date and results of all the music ceremonies and festivals.,"music_festival[['date_of_ceremony', 'result']]"
provide me with the dates of festivals and results for each music festival.,"music_festival[['date_of_ceremony', 'result']]"
"what are the categories of music festivals with the award ""awarded""?","music_festival.loc[music_festival['result'] == 'awarded', 'category']"
please provide me with the categories for music festivals that were the recipients of the award.,"music_festival.loc[music_festival['result'] == 'awarded', 'category']"
what are the maximum and minimum weeks on top of all volumes?,"volume['weeks_on_top'].agg(['max', 'min'])"
provide me with the minimum and maximum weeks on the top of all volumes.,"volume['weeks_on_top'].agg(['max', 'min'])"
find the songs that were at no. 1 position for more than 1 week.,"volume.loc[volume['weeks_on_top'] > 1, 'song']"
provide the title of any song included in music albums that continue to be the best for more than a week.,"volume.loc[volume['weeks_on_top'] > 1, 'song']"
provide me with the names of songs in volumes starting in ascending alphabetical order.,volume['song'].sort_values()
"what are the songs in a given volume, listed in ascending order?",volume['song'].sort_values()
what is the number of artists that are associated with each of the volumes?,volume['artist_id'].nunique()
provide me the count of distinct artists who have volumes.,volume['artist_id'].nunique()
what dates correspond to festivals that lasted more than 2 weeks?,"pd.merge(music_festival, volume, left_on='volume', right_on='volume_id').loc[lambda x: x['weeks_on_top'] > 2, 'date_of_ceremony']"
"return me the title of songs that have been ""nominated"" at music festivals.","music_festival.merge(volume, left_on='volume', right_on='volume_id').loc[lambda x: x['result']=='nominated', 'song']"
what are the songs that made appearances in those soundtracks that received nominations at music awards?,"music_festival.merge(volume, left_on='volume', right_on='volume_id').loc[lambda x: x['result']=='nominated', 'song']"
"(note: the volumes are associated with the artist and have an assigned issue date.) determine the issue dates of volumes associated with the artist ""gorgoroth"".","volume.loc[volume['artist_id'].isin(artist.loc[artist['artist']=='gorgoroth', 'artist_id']), 'issue_date']"
what is the issue date of volumes that were created by the artist named gorgoroth.,"volume.loc[volume['artist_id'].isin(artist.loc[artist['artist']=='gorgoroth', 'artist_id']), 'issue_date']"
determine the number of songs in volumes that were written by artists who are 32 years old or more.,"pd.merge(artist, volume, on='artist_id').loc[lambda x: x['age'] >= 32, 'song']"
please return me the list of songs composed by artists that are at least 32 years old.,"pd.merge(artist, volume, on='artist_id').loc[lambda x: x['age'] >= 32, 'song']"
what is the average tenure for the artists aged 25 or younger?,"pd.merge(artist.loc[lambda x: x['age']<=25], volume, on='artist_id')['weeks_on_top'].mean()"
provide me with the average number of weeks on top for volumes by artists that are at most 25 years old.,"pd.merge(artist.loc[lambda x: x['age']<=25], volume, on='artist_id')['weeks_on_top'].mean()"
what are the artists associated with the albums that sat on the top for more than 2 weeks?,"pd.merge(artist, volume, on='artist_id').loc[lambda x: x['weeks_on_top']>2, 'famous_title']"
return the most famous titles of artists whose cds were released for more than 2 weeks on the bestseller list.,"pd.merge(artist, volume, on='artist_id').loc[lambda x: x['weeks_on_top']>2, 'famous_title']"
please list the ages and famous titles of artists in descending order of age.,"artist[['famous_title', 'age']].sort_values('age', ascending=false)"
"please provide me the list of the most eminent artists and titles of their works, arranged in descending order by age.","artist[['famous_title', 'age']].sort_values('age', ascending=false)"
what is the year in which the artist with the oldest age released his/her first album?,"artist.sort_values('age', ascending=false)['famous_release_date'].iloc[0]"
provide me with the title for the earliest date on which an artist became a famous person.,"artist.sort_values('age', ascending=false)['famous_release_date'].iloc[0]"
provide me with the categories of the music festival and the count.,music_festival.groupby('category').size().reset_index(name='count')
provide me with the total count of music festivals of each type.,music_festival.groupby('category').size().reset_index(name='count')
what is the most frequently occurring result of the festival?,music_festival.groupby('result').size().sort_values(ascending=false).index[0]
display the categories of music festivals that have more than one instance.,music_festival.groupby('category').filter(lambda x: len(x) > 1)['category'].unique()
which categories of music festivals have had more than one music festival?,music_festival.groupby('category').filter(lambda x: len(x) > 1)['category'].unique()
find the song in the volume with the maximum weeks listed at the top.,"volume.sort_values('weeks_on_top', ascending=false).iloc[0]['song']"
provide me with the name of the song in the volume that has spent the most weeks at first place.,"volume.sort_values('weeks_on_top', ascending=false).iloc[0]['song']"
find the title of artists that do not have any data regarding their music album volumes.,"artist.loc[~artist['artist_id'].isin(volume['artist_id']), 'famous_title']"
retrieve the names of artists who do not contain any volumes.,"artist.loc[~artist['artist_id'].isin(volume['artist_id']), 'famous_title']"
provide me the titles of the famous artists with volumes that exceeded 2 weeks ranked on top and volumes that fell short 2 weeks ranked on top.,"pd.merge(artist.loc[lambda x: pd.merge(x, volume, on='artist_id').eval('weeks_on_top > 2'), 'famous_title'], artist.loc[lambda x: pd.merge(x, volume, on='artist_id').eval('weeks_on_top < 2'), 'famous_title']).drop_duplicates()"
"provide me the dates of ceremony of events categorized as ""best song"" and with the outcome ""awarded.""","music_festival.query('category == ""best song"" and result == ""awarded""')['date_of_ceremony']"
"provide me with the date of the ceremony for the music festival that was awarded ""best song"".","music_festival.query('category == ""best song"" and result == ""awarded""')['date_of_ceremony']"
which volume's issue date was the minimum among the volumes indicated?,volume.sort_values('weeks_on_top').iloc[0]['issue_date']
what is the issue date of the publishing volume that had spent the fewest weeks on peak?,volume.sort_values('weeks_on_top').iloc[0]['issue_date']
determine the count of distinct artists that have records.,volume['artist_id'].nunique()
determine the number of artists who have had phonographs.,volume['artist_id'].nunique()
"please present the results for music festivals and the number of music festivals that have had each, ordered by this count.",music_festival.groupby('result').size().sort_values(ascending=false)
"what were the results of most festivals, listed in descending order?",music_festival.groupby('result').size().sort_values(ascending=false)
provide me with the dates of issues for the volumes associated with the artist that is younger than 23.,"pd.merge(artist.loc[lambda x: x['age']<=23], volume, on='artist_id')['issue_date']"
please provide me with the issue dates of volumes authored by artists who are at most 23 years old.,"pd.merge(artist.loc[lambda x: x['age']<=23], volume, on='artist_id')['issue_date']"
what is the count of roller coasters?,roller_coaster.shape[0]
enumerate the titles of roller coasters by ascending order of length.,roller_coaster.sort_values('length')['name']
what is the length and height of the most roller coasters,"roller_coaster[['length', 'height']]"
retrieve the names of countries whose language is not german.,"country.loc[lambda x: x['languages']!='german', 'name']"
provide me with the tallies of roller coasters whose height or length is larger than 3300 or 100.,"roller_coaster.loc[(roller_coaster['length'] > 3300) | (roller_coaster['height'] > 100), 'status']"
retrieve the roller coaster classifications and their respective counts for each classification.,roller_coaster.groupby('status').size().reset_index(name='count')
list the most frequently occurring status of roller coasters.,roller_coaster.groupby('status').size().sort_values(ascending=false).index[0]
list the status shared by more than two roller coasters.,roller_coaster.groupby('status').filter(lambda x: len(x) > 2)['status'].unique()
give the id of the park of the roller coaster with the highest speed.,"roller_coaster.sort_values('speed', ascending=false).iloc[0]['park']"
provide me the list of names of roller coasters and countries where they are located.,"pd.merge(country, roller_coaster, on='country_id')[['name_x', 'name_y']]"
find out the titles of those countries that have more than one roller coaster.,"pd.merge(country, roller_coaster, on='country_id').groupby('name').filter(lambda x: len(x) > 1)['name']"
what is the name of the country that possesses the highest roller coaster?,"pd.merge(country, roller_coaster, on='country_id').sort_values('height', ascending=false).iloc[0][['name', 'population']]"
list the names of the countries and the average speed of roller coasters present in each country.,"pd.merge(country, roller_coaster, on='country_id').groupby('name')['speed'].mean()"
what is the count of countries in which there are no roller coasters longer than 3000 feet?,"country.loc[~country['country_id'].isin(roller_coaster.loc[roller_coaster['length'] > 3000, 'country_id']), :].shape[0]"
"retrieve the names of countries, their areas, and populations that have both roller coasters with speed higher than 40 km/h.","country.merge(roller_coaster.query('speed > 60')[['country_id']], on='country_id')[['name', 'area', 'population']].merge(country.merge(roller_coaster.query('speed < 55')[['country_id']], on='country_id')[['name', 'area', 'population']]).drop_duplicates()"
what is the number of captain positions?,captain['rank'].nunique()
determine the total number of different ranks of captain.,captain['rank'].nunique()
how many captains are there in each rank?,captain.groupby('rank').size().reset_index(name='count')
which are the ranks assigned to the maximum number of captains?,captain.groupby('rank').size().reset_index(name='count')
how many captains have younger than fifty years of age?,captain.loc[captain['age'] < 50].groupby('rank').size().reset_index(name='count')
how many captains are younger than 50 years of age of each category?,captain.loc[captain['age'] < 50].groupby('rank').size().reset_index(name='count')
please sort all captain names from old to young.,"captain.sort_values('age', ascending=false)['name']"
print the names of captains by their age.,"captain.sort_values('age', ascending=false)['name']"
"retrieve the id, class and rank of captains.","captain[['name', 'class', 'rank']]"
"retrieve the names, classes, and ranks of all captains.","captain[['name', 'class', 'rank']]"
which rank is the most common among ship captains?,captain.groupby('rank').size().sort_values(ascending=false).index[0]
obtain the rank of which there are the fewest captains.,captain.groupby('rank').size().sort_values(ascending=false).index[0]
what is the count of classes with more than 2 captains?,captain.groupby('class').filter(lambda x: len(x) > 2)['class'].unique()
which class has more than two captains?,captain.groupby('class').filter(lambda x: len(x) > 2)['class'].unique()
retrieve the names of the ship captains with ranks of either midshipman or lieutenant.,"captain.loc[captain['rank'].isin(['midshipman', 'lieutenant']), 'name']"
obtain the names of the captains that have the rank of midshipman or lieutenant.,"captain.loc[captain['rank'].isin(['midshipman', 'lieutenant']), 'name']"
provide me with the count of captains having the respective minimum age and average age.,"captain.groupby('class')['age'].agg(['mean', 'min'])"
please provide me with the average and minimum age of captains in class.,"captain.groupby('class')['age'].agg(['mean', 'min'])"
determine the rank for captainship that has people in both cutter and armed schooner classes.a:here's my solution. it is using mysql-specific sql features.,"pd.merge(captain.loc[captain['class']=='cutter', 'rank'], captain.loc[captain['class']=='armed schooner', 'rank'], on='rank', how='inner')"
provide me with the ranks for captains that are both in the cutter and armed schooner classes.,"pd.merge(captain.loc[captain['class']=='cutter', 'rank'], captain.loc[captain['class']=='armed schooner', 'rank'], on='rank', how='inner')"
find the name of rank that does not have captains in third-rate ship-of-the-line class.,"captain.loc[~(captain['class']=='third-rate ship of the line'), 'rank']"
rank the ships of the third-rate ship of the line class whose commanders have no captain.,"captain.loc[~(captain['class']=='third-rate ship of the line'), 'rank']"
retrieve the title of the youngest captain.,captain.sort_values('age').iloc[0]['name']
give me the count of ships,ship.shape[0]
"retrieve the title, type, and flag of the ship that was manufactured in the most recent year.","ship[['name', 'type', 'flag', 'built_year']].sort_values('built_year', ascending=false).head(1)[['name', 'type', 'flag']]"
"please provide me with the name, type, and flag of the ship that was manufactured in the most recent year.","ship[['name', 'type', 'flag', 'built_year']].sort_values('built_year', ascending=false).head(1)[['name', 'type', 'flag']]"
"group the ships by flag, and return a count of ships that have each flag.",ship.groupby('flag').size().reset_index(name='count')
tell me the flags for different ships and how many ships have each.,ship.groupby('flag').size().reset_index(name='count')
which flag is most prevalent among ships?,ship.groupby('flag').size().sort_values(ascending=false).index[0]
retrieve the flag that is most common among all ships.,ship.groupby('flag').size().sort_values(ascending=false).index[0]
create a list of names of ships arranged by class and year constructed.,"ship.sort_values(['built_year', 'class'])['name']"
"provide me with the titles of all the ships, ordered in terms of year they were constructed and their class.","ship.sort_values(['built_year', 'class'])['name']"
determine the ship flags that are used by both ships with flags of panama and malta.,"set(ship.loc[ship['flag']=='panama', 'type']).intersection(set(ship.loc[ship['flag']=='malta', 'type']))"
which ships have both panama flags and malta flags?,"set(ship.loc[ship['flag']=='panama', 'type']).intersection(set(ship.loc[ship['flag']=='malta', 'type']))"
what year was the maximum number of ships constructed in?,"ship.groupby('built_year').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['built_year']"
which year saw the maximum number of ships constructed?,"ship.groupby('built_year').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['built_year']"
retrieve the names of ships that have more than one captain.,"ship.merge(captain, on='ship_id').groupby('ship_id').filter(lambda x: len(x) > 1)['name']"
find the names of ships that have more than one captain.,"ship.merge(captain, on='ship_id').groupby('ship_id').filter(lambda x: len(x) > 1)['name']"
what are the names and classes of ships that do not have a permanent captain yet?,"ship.loc[~ship['ship_id'].isin(captain['ship_id']), ['name', 'class']]"
allow me to fetch the names of the ships that do not have a captain along with their corresponding class.,"ship.loc[~ship['ship_id'].isin(captain['ship_id']), ['name', 'class']]"
retrieve the name of the ship that is captained by the youngest captain.,"pd.merge(ship, captain, on='ship_id').sort_values('age').iloc[0]['name']"
retrieve the title of ship that is commanded by the youngest captain.,"pd.merge(ship, captain, on='ship_id').sort_values('age').iloc[0]['name']"
"list the title, name and flag of ships that do not belong to any ship commanded by any midshipman.","ship[~ship['ship_id'].isin(captain.loc[captain['rank']=='midshipman', 'ship_id'])][['name', 'flag']]"
find the name and flag of ships that do not possess a captain with the rank of midshipman.,"ship[~ship['ship_id'].isin(captain.loc[captain['rank']=='midshipman', 'ship_id'])][['name', 'flag']]"
find the names of ships that are steered by both a captain with midshipman rank and a captain with lieutenant rank.,"pd.merge(ship.loc[ship['captain_id'].isin(captain.query('rank==""midshipman""')['captain_id']), ['name', 'ship_id']], captain.query('rank==""lieutenant""')[['captain_id', 'ship_id']], on='ship_id')['name']"
find the names of the sailing vessels that are under the command of both midshipmen and lieutenants.,"pd.merge(ship.loc[ship['captain_id'].isin(captain.query('rank==""midshipman""')['captain_id']), ['name', 'ship_id']], captain.query('rank==""lieutenant""')[['captain_id', 'ship_id']], on='ship_id')['name']"
provide me the id of the city that hosted events in the year 2013.,"hosting_city.sort_values('year', ascending=false).iloc[0]['host_city']"
"get the name of the city that hosted some events in 2010. also, provide the id of this city.","hosting_city.sort_values('year', ascending=false).iloc[0]['host_city']"
find the title ids of the cities that hosted the world cup 1994 qualification.,"match.loc[lambda x: x['competition']==""1994 fifa world cup qualification"", 'match_id']"
"what is the competition known as ""1994 fifa world cup qualification""?","match.loc[lambda x: x['competition']==""1994 fifa world cup qualification"", 'match_id']"
who are the cities that served as a host city after 2010?,"pd.merge(city, hosting_city.loc[lambda x: x['year'] > 2010], left_on='city_id', right_on='host_city')['city']"
which cities served as the host city after 2010?,"pd.merge(city, hosting_city.loc[lambda x: x['year'] > 2010], left_on='city_id', right_on='host_city')['city']"
reveal the city that has hosted the most events.,"pd.merge(city, hosting_city, left_on='city_id', right_on='host_city').groupby('host_city').size().idxmax()"
determine the city that hosted the most events.,"pd.merge(city, hosting_city, left_on='city_id', right_on='host_city').groupby('host_city').size().idxmax()"
"which were the cities that hosted the competition ""1994 fifa world cup qualification""?","(pd.merge(pd.merge(city, hosting_city, on='city_id'), match, on='match_id').loc[lambda x: (x['city'] == 'nanjing ( jiangsu )') & (x['competition'] == '1994 fifa world cup qualification'), 'venue'])"
"retrieve the title of the competition ""1994 fifa world cup qualification"" which was hosted by ""nanjing ( jiangsu )"".","(pd.merge(pd.merge(city, hosting_city, on='city_id'), match, on='match_id').loc[lambda x: (x['city'] == 'nanjing ( jiangsu )') & (x['competition'] == '1994 fifa world cup qualification'), 'venue'])"
please provide me with the temperature of shanghai in the month of january.,"pd.merge(city.loc[lambda x: x['city']=='shanghai', 'city_id'], temperature, on='city_id')['jan']"
list the temperatures of various cities in the month of january.,"pd.merge(city.loc[lambda x: x['city']=='shanghai', 'city_id'], temperature, on='city_id')['jan']"
"what was the city host year of ""taizhou ( zhejiang )""?","hosting_city.merge(city.query(""city == 'taizhou ( zhejiang )'""), on='host_city')['year']"
"in what year did the city of ""taizhou (zhejiang)"" serve as a host city?","hosting_city.merge(city.query(""city == 'taizhou ( zhejiang )'""), on='host_city')['year']"
the cities with the largest regional populations are:[1]  beijing[2]  shanghai[3]  wuhan,"city.sort_values('regional_population', ascending=false).iloc[:3]['city']"
what are the three cities with the highest population of their regions?,"city.sort_values('regional_population', ascending=false).iloc[:3]['city']"
list the city with the smallest gdp. also provide the city's gdp.,"city[['city', 'gdp']].sort_values('gdp').iloc[0]"
what is the city that has the greatest average temperature in february?,"pd.merge(city, temperature, on='city_id').sort_values('feb', ascending=false).iloc[0]['city']"
in which month did a city record the highest temperature?,"pd.merge(city, temperature, on='city_id').sort_values('feb', ascending=false).iloc[0]['city']"
please return me a list of cities whose temperature in march is lower than that of july or higher than that in october.,"pd.merge(city, temperature, on='city_id').query('mar < jul or mar > oct')['city']"
which cities' temperature in april differs from that in june?,"pd.merge(city, temperature, on='city_id').query('mar < jul or mar > oct')['city']"
identify the cities that have a lower temperature in mar than in july and that have also served as host cities.,"pd.merge(city.loc[lambda x: temperature['mar']<temperature['jul']], hosting_city, on='city_id')['city']"
which cities have the lowest temperature in march than in july and have hosted the olympic games once?,"pd.merge(city.loc[lambda x: temperature['mar']<temperature['jul']], hosting_city, on='city_id')['city']"
"please provide me with the names of cities whose temperatures in march are lower than those in december, and cities that have never been hosts.","city.loc[city['city_id'].isin(temperature.loc[temperature['mar'] < temperature['dec'], 'city_id']).tolist()].loc[~city['city_id'].isin(hosting_city['host_city'].tolist()), 'city']"
what is the count of cities that have the temperature lowest in march than in dec and have never hosted the olympic games?,"city.loc[city['city_id'].isin(temperature.loc[temperature['mar'] < temperature['dec'], 'city_id']).tolist()].loc[~city['city_id'].isin(hosting_city['host_city'].tolist()), 'city']"
"provide me the cities whose temperature in february is higher than that of in june, or cities that once served as host cities.","pd.merge(city.loc[lambda x: x.merge(temperature, on='city_id').eval('feb > jun')], hosting_city, on='city_id')['city'].unique()"
what is the count of cities that have warmer temperatures in february than in june or were hosts of international events?,"pd.merge(city.loc[lambda x: x.merge(temperature, on='city_id').eval('feb > jun')], hosting_city, on='city_id')['city'].unique()"
provide the names of cities in which the population of the region is above 10 million.,"city.loc[lambda x: x['regional_population'] > 10000000, 'city']"
which cities have population above 10 million?,"city.loc[lambda x: x['regional_population'] > 10000000, 'city']"
fetch me the names of cities whose regional population is greater than 8 million or less than 5 million.,"pd.concat([city.loc[lambda x: x['regional_population'] > 10000000, 'city'], city.loc[lambda x: x['regional_population'] < 5000000, 'city']]).drop_duplicates()"
which cities have regional population levels exceeding 8 million or falling below 5 million?,"pd.concat([city.loc[lambda x: x['regional_population'] > 10000000, 'city'], city.loc[lambda x: x['regional_population'] < 5000000, 'city']]).drop_duplicates()"
calculate the count of matches that were played in multiple competitions.,match.groupby('competition').size().reset_index(name='count(*)')
enumerate the total number of matches for each competition.,match.groupby('competition').size().reset_index(name='count(*)')
list the venues of the matches arranged in the order of their dates starting from the most recent one.,"match.sort_values('date', ascending=false)['venue']"
the list of matches should be in the following format: venue name and match date. sort them in descending order of the match date.,"match.sort_values('date', ascending=false)['venue']"
what is the gross domestic product (gdp) for the city with the main population.,"city.sort_values('regional_population', ascending=false).iloc[0]['gdp']"
determine the gdp of the city with the largest regional population.,"city.sort_values('regional_population', ascending=false).iloc[0]['gdp']"
what is the gdp and population of a city that has already served as host more than once?,"city.merge(hosting_city, left_on='city_id', right_on='host_city').groupby('host_city').filter(lambda x: len(x) > 1)[['gdp', 'regional_population']]"
which cities were designated host cities more than once? please provide me with their gdp and population.,"city.merge(hosting_city, left_on='city_id', right_on='host_city').groupby('host_city').filter(lambda x: len(x) > 1)[['gdp', 'regional_population']]"
retrieve the first and last name of every individual in alphabetical order.,"individuals[['individual_first_name', 'individual_middle_name', 'individual_last_name']].sort_values('individual_last_name')"
arrange the full names of individuals by last name.,"individuals[['individual_first_name', 'individual_middle_name', 'individual_last_name']].sort_values('individual_last_name')"
please list all the types of forms.,forms['form_type_code'].unique()
provide me a list of different types of forms.,forms['form_type_code'].unique()
retrieve the title of the most popular party form.,forms.merge(party_forms).groupby('form_id')['form_name'].first().value_counts().index[0]
how many instances of party forms were returned?,forms.merge(party_forms).groupby('form_id')['form_name'].first().value_counts().index[0]
"list the exact payment methods and phone numbers of the contacts whose email addresses are ""enrico09@example.com"".","parties.loc[lambda x: x['party_email']=='enrico09@example.com', ['payment_method_code', 'party_phone']]"
please provide me with the payment method code and the party's phone number for the email message 'enrico09@example.com' party.,"parties.loc[lambda x: x['party_email']=='enrico09@example.com', ['payment_method_code', 'party_phone']]"
retrieve the list of emails of the contacts that have the most popular contact form.,"parties.merge(party_forms[party_forms['form_id'] == party_forms['form_id'].value_counts().index[0]], on='party_id')['party_email']"
which parties utilized the party form that received the highest frequency of utilization?,"parties.merge(party_forms[party_forms['form_id'] == party_forms['form_id'].value_counts().index[0]], on='party_id')['party_email']"
list the names of organizations in chronological order.,organizations.sort_values('date_formed')['organization_name']
"return the names of the organizations, ordered ascending by the date of their formation.",organizations.sort_values('date_formed')['organization_name']
retrieve the title of the youngest organization.,"organizations.sort_values('date_formed', ascending=false).iloc[0]['organization_name']"
retrieve the name for an organization that was created most recently.,"organizations.sort_values('date_formed', ascending=false).iloc[0]['organization_name']"
"please present me the surname of the contact individual who is latest in the organization ""labour party"".","individuals.loc[individuals['individual_id'].isin(organization_contact_individuals.loc[organization_contact_individuals['organization_id'].isin(organizations.loc[organizations['organization_name'] == 'labour party', 'organization_id']) & (organization_contact_individuals['date_contact_to'] == organization_contact_individuals['date_contact_to'].max()), 'individual_id'].values), 'individual_last_name']"
retrieve the last name of the individual from the labour party organization that was contacted most recently.,"individuals.loc[individuals['individual_id'].isin(organization_contact_individuals.loc[organization_contact_individuals['organization_id'].isin(organizations.loc[organizations['organization_name'] == 'labour party', 'organization_id']) & (organization_contact_individuals['date_contact_to'] == organization_contact_individuals['date_contact_to'].max()), 'individual_id'].values), 'individual_last_name']"
what is the name of the first person contacted in an organization with the highest uk vat number?,"(pd.merge(pd.merge(organizations,organization_contact_individuals,on='organization_id'),individuals,on='individual_id').loc[lambda x: x['uk_vat_number']==organizations['uk_vat_number'].max()].sort_values('date_contact_to').iloc[0]['individual_last_name'])"
what is the first name of the employee associated with the organization with the maximum uk vat number across the organizations?,"(pd.merge(pd.merge(organizations,organization_contact_individuals,on='organization_id'),individuals,on='individual_id').loc[lambda x: x['uk_vat_number']==organizations['uk_vat_number'].max()].sort_values('date_contact_to').iloc[0]['individual_last_name'])"
find the count of services.,services.shape[0]
find the names of services that have not been utilized.,"services.loc[~services['service_name'].isin(pd.merge(services, party_services, on='service_id')['service_name_y'])]['service_name']"
please state the names of the services that have never used.,"services.loc[~services['service_name'].isin(pd.merge(services, party_services, on='service_id')['service_name_y'])]['service_name']"
retrieve the names of all the cities and states.,addresses['town_city'].append(addresses['state_province_county']).drop_duplicates()
retrieve the names of all cities and states.,addresses['town_city'].append(addresses['state_province_county']).drop_duplicates()
which city is the largest city in colorado?,"(addresses['state_province_county'] == ""colorado"").sum()"
retrieve the payment method code that was utilized by more than three parties.,parties.groupby('payment_method_code').filter(lambda x: len(x) > 3)['payment_method_code'].unique()
what is the count of unique codes of payment methods that have been used more than three instances?,parties.groupby('payment_method_code').filter(lambda x: len(x) > 3)['payment_method_code'].unique()
"fetch the titles of organizations that consist of words ""party"".","organizations.loc[organizations['organization_name'].str.contains('party'), 'organization_name']"
"return the names of the companies or organizations that contain the word ""party"".","organizations.loc[organizations['organization_name'].str.contains('party'), 'organization_name']"
how many unique payment methods are employed by parties?,parties['payment_method_code'].nunique()
what's the total count of payment codes used by customers.,parties['payment_method_code'].nunique()
who among the following has utilized the it services the most number of times?,"pd.merge(parties, party_services, left_on='party_id', right_on='customer_id').groupby('party_email').size().sort_values(ascending=false).head(1).index[0]"
please return the party email that has used party services the most frequently.,"pd.merge(parties, party_services, left_on='party_id', right_on='customer_id').groupby('party_email').size().sort_values(ascending=false).head(1).index[0]"
"may ""6862 kaitlyn knolls"" be a resident of which state?","addresses.loc[lambda x: x['line_1_number_building'].str.contains('6862 kaitlyn knolls'), 'state_province_county']"
"provide the name of the state corresponding to the line number, ""6862 kaitlyn knolls"".","addresses.loc[lambda x: x['line_1_number_building'].str.contains('6862 kaitlyn knolls'), 'state_province_county']"
which organization has the most contact individuals?,"organizations.merge(organization_contact_individuals, on='organization_id').groupby('organization_name').size().sort_values(ascending=false).index[0]"
produce the name of the organization with the highest count for contact persons.,"organizations.merge(organization_contact_individuals, on='organization_id').groupby('organization_name').size().sort_values(ascending=false).index[0]"
provide me with the names of people who have contacted an organization.,"pd.merge(individuals, organization_contact_individuals, on='individual_id')['individual_last_name'].unique()"
provide the last names of individuals who are contact persons for an organization.,"pd.merge(individuals, organization_contact_individuals, on='individual_id')['individual_last_name'].unique()"
"return the names, home cities, and ages of drivers.","driver.loc[:, ['name', 'home_city', 'age']]"
summarize the number of drivers in the different parties.,driver.groupby('party').size()
what should i do to retrieve the names of drivers in descending order of age?,"driver.sort_values('age', ascending=false)['name']"
determine the names of home cities that are not included.,driver['home_city'].unique()
provide me the names of the cities that have the highest number of drivers.,driver.groupby('home_city').size().sort_values(ascending=false).index[0]
"provide me with the party affiliation, names, and ages of all drivers from hartford.","driver.loc[(driver['home_city'] == 'hartford') & (driver['age'] > 40), 'party']"
list the cities in which at least two drivers are older than 40.,driver.loc[lambda x: x['age'] > 40].groupby('home_city').filter(lambda x: len(x) >= 2)['home_city'].unique()
"show the home cities of all users, except for those having a driver older than 40.","driver.loc[lambda x: x['age'] <= 40, 'home_city'].drop_duplicates()"
retrieve the names of drivers who do not operate a school bus.,"driver.loc[~driver['driver_id'].isin(school_bus['driver_id']), 'name']"
show me the names of schools that have two branches.,school.groupby('type').filter(lambda x: len(x)==2)['type'].unique()
return the names of school busses and their drivers.,"pd.merge(pd.merge(school_bus, school, on='school_id'), driver, on='driver_id')[['school', 'name']]"
"how do i calculate the total number of weeks spent working on a school bus by agent a, the minimum, the maximum and average number of weeks?","school_bus['years_working'].agg(['max', 'min', 'mean'])"
give me the name of the school and the type of school for schools without school buses.,"school.loc[~school['school_id'].isin(school_bus['school_id']),['school', 'type']]"
provide the school type and the number of buses for each type.,"school_bus.merge(school, on='school_id').groupby('type').size().reset_index(name='count')"
how many drivers from the city of hartford are under 40 years old?,((driver['home_city'] == 'hartford') | (driver['age'] < 40)).sum()
provide a list of drivers from the city hartford who are younger than 40.,"driver.loc[(driver['home_city'] == 'hartford') & (driver['age'] < 40), 'name']"
fetch the name of school bus drivers who have been working for the longest durations.,"pd.merge(driver, school_bus, on='driver_id').sort_values('years_working', ascending=false).iloc[0]['name']"
how many flights have velocities that exceed 200?,(flight['velocity'] > 200).sum()
"provide the flights ordered by ascending altitude, along with their flight number, date, and pilot.","flight.sort_values('altitude')[['vehicle_flight_number', 'date', 'pilot']]"
"please arrange the airports by their names in alphabetical order and list them along with their id, country, and city.","airport[['id', 'country', 'city', 'name']].sort_values('name')"
what is the total group equity shareholding of the companies?,operate_company['group_equity_shareholding'].max()
what is the velocity of the pilot named thompson?,"flight.loc[lambda x: x['pilot']=='thompson', 'velocity'].mean()"
provide the names and types of the companies that have ever operated an airplane.,"pd.merge(operate_company, flight, on='company_id')[['name', 'type']]"
list the titles of airports that are not located in iceland.,"airport.loc[lambda x: x['country']!='iceland', 'name']"
list the distinct types of companies that have flown any flight with a velocity value less than 200.,"pd.merge(operate_company, flight, on='company_id').loc[lambda x: x['velocity']<200,'type'].unique()"
obtain the identities and names of the companies that owned more than one aircraft.,"pd.merge(operate_company, flight, on='company_id').groupby(['id', 'name']).filter(lambda x: len(x) > 1)[['id', 'name']].drop_duplicates()"
"please provide me with the id, name, and iata code of the airport that had the highest number of flights.","airport.merge(flight, on='id').groupby('id')[['name', 'iata']].first().reset_index().sort_values(by=flight.groupby('id').size().name, ascending=false).iloc[[0]]"
obtain the names of pilots who have piloted a flight in the country 'united states' or in the airport named 'billund airport'.,"flight.merge(airport, on='airport_id').loc[lambda x: (x['country']=='united states') | (x['name']=='billund airport'), 'pilot'].unique()"
"what is the common company type, and how many are there?",operate_company.groupby('type').size().sort_values(ascending=false).head(1)
how many airports do not have thompson as a pilot?,"airport[~airport['id'].isin(flight.loc[flight['pilot']=='thompson', 'airport_id'])].shape[0]"
name the pilots that flew for companies that mainly provide 'cargo' services and companies that provide 'catering services' activities.,"set(pd.merge(flight.merge(operate_company.query(""principal_activities=='cargo'""), on='company_id')['pilot'], flight.merge(operate_company.query(""principal_activities=='catering services'""), on='company_id')['pilot']).values)"
"which of the airport names contains the word ""international""?","airport.loc[airport['name'].str.contains('international'), 'name']"
please provide me with the count of airlines that are operated by each company in each airport.,"flight.merge(operate_company, on='id').merge(airport, on='airport_id').groupby('id').size().reset_index(name='count')"
how many airports are there in each country?,airport.groupby('country').size().rename('count').reset_index()
how many countries have at least 2 airports?,airport.groupby('country').filter(lambda x: len(x)>2)['country'].unique()
who pilots the majority of the flights?,flight.groupby('pilot').size().sort_values(ascending=false).index[0]
count the number of accounts we have.,accounts.shape[0]
please count the number of accounts.,accounts.shape[0]
retrieve the account ids and account details.,"accounts[['account_id', 'account_details']]"
please provide me with the id and details of all the bank accounts.,"accounts[['account_id', 'account_details']]"
how many statements are there?,statements.shape[0]
how many sentences exist in the document?,statements.shape[0]
provide me a list of all statement ids and statement details.,"statements[['statement_id', 'statement_details']]"
please determine the details of all the comments.,"statements[['statement_id', 'statement_details']]"
"provide me with the id, detail, and account details for statements.","pd.merge(accounts, statements, on='statement_id')[['statement_id', 'statement_details', 'account_details']]"
"determine the ids for the statements, statement details, and account details for all of the accounts.","pd.merge(accounts, statements, on='statement_id')[['statement_id', 'statement_details', 'account_details']]"
list all the statement ids and the number of associated accounts for each statement.,accounts.groupby('statement_id').size().reset_index(name='count(*)')
"what are the different statement ids on accounts, and the count of accounts for each id?",accounts.groupby('statement_id').size().reset_index(name='count(*)')
provide the statement id and the statement detail for the statement that has the most accounts.,"pd.merge(accounts, statements, on='statement_id').groupby('statement_id').size().nlargest(1).reset_index(name='count').merge(statements, on='statement_id')[['statement_id', 'statement_details']]"
on which statement did it have the most accounts?,"pd.merge(accounts, statements, on='statement_id').groupby('statement_id').size().nlargest(1).reset_index(name='count').merge(statements, on='statement_id')[['statement_id', 'statement_details']]"
return the number of documents.,documents.shape[0]
determine the number of documents.,documents.shape[0]
"what document type, document name, and document description are associated with the document with name 'noel cv' or name 'king book'?","documents.loc[lambda x: x['document_name'].isin(['noel cv', 'king book']), ['document_type_code', 'document_name', 'document_description']]"
"determine the id, title, and description of the document that are either named 'noel cv' or 'king book'.","documents.loc[lambda x: x['document_name'].isin(['noel cv', 'king book']), ['document_type_code', 'document_name', 'document_description']]"
please show the ids and names of all the documents.,"documents[['document_id', 'document_name']]"
retrieve the records for ids and names for each of the documents.,"documents[['document_id', 'document_name']]"
retrieve the titles of documents with document type code bk.,"documents.loc[lambda x: x['document_type_code']=='bk', ['document_name', 'document_id']]"
list out the names of the documents along with the ids that have the type code bk.,"documents.loc[lambda x: x['document_type_code']=='bk', ['document_name', 'document_id']]"
what are the document type codes bk used for each product id?,documents.loc[lambda x: x['document_type_code']=='bk'].groupby('project_id').size().reset_index(name='count(*)')
determine the total number of documents with the type code bk whose corresponding ids indicate each product.,documents.loc[lambda x: x['document_type_code']=='bk'].groupby('project_id').size().reset_index(name='count(*)')
provide the document name and document date for all documents on project whose details are 'graph database project'.,"pd.merge(documents, projects.query('project_details==""graph database project""'), on='project_id')[['document_name', 'document_date']]"
what are the titles and creation dates for documents related to the project that has the title 'graph database project'?,"pd.merge(documents, projects.query('project_details==""graph database project""'), on='project_id')[['document_name', 'document_date']]"
display the project ids along with the document count for each project.,documents.groupby('project_id').size().reset_index(name='count')
what is the count of documents that correspond with each corresponding project id?,documents.groupby('project_id').size().reset_index(name='count')
what is the lowest id of the project that has the least number of documents?,documents.groupby('project_id').size().sort_values().index[0]
determine the id of the project that has the fewest associated documents.,documents.groupby('project_id').size().sort_values().index[0]
show me the ids for projects with at least 2 documents.,documents.groupby('project_id').filter(lambda x: len(x) >= 2)['project_id'].unique()
obtain the project ids of projects that have more than one corresponding document.,documents.groupby('project_id').filter(lambda x: len(x) >= 2)['project_id'].unique()
provide the document type codes and number of documents in each code.,documents.groupby('document_type_code').size().reset_index(name='count')
how many documents exist of each type?,documents.groupby('document_type_code').size().reset_index(name='count')
which document code possesses the most documents?,documents.groupby('document_type_code').size().sort_values(ascending=false).index[0]
what is the document type that occurs most frequently?,documents.groupby('document_type_code').size().sort_values(ascending=false).index[0]
provide me with the document type code with the smallest number of documents.,documents.groupby('document_type_code').filter(lambda x: len(x) < 3)['document_type_code'].unique()
could you return me the codes for the documents of document type where the number of documents is less than 3?,documents.groupby('document_type_code').filter(lambda x: len(x) < 3)['document_type_code'].unique()
provide me the statement title and the document title for the statement with the detail 'private project'.,"pd.merge(statements, documents, left_on='statement_id', right_on='document_id').loc[lambda x: x['statement_details']=='private project', ['statement_details', 'document_name']]"
provide me the details of statements containing the detail 'private project' as well as the titles of the corresponding documents.,"pd.merge(statements, documents, left_on='statement_id', right_on='document_id').loc[lambda x: x['statement_details']=='private project', ['statement_details', 'document_name']]"
"display the titles of document types, their definitions, and their descriptions.","ref_document_types[['document_type_code', 'document_type_name', 'document_type_description']]"
what is the document type description for the movie document type?,"ref_document_types.loc[lambda x: x['document_type_name']=='film', 'document_type_description']"
provide a description of the document type name 'film'.,"ref_document_types.loc[lambda x: x['document_type_name']=='film', 'document_type_description']"
"provide the data type, description, and creation time for each type of document.","pd.merge(ref_document_types, documents, on='document_type_code')[['document_type_name', 'document_type_description', 'document_date']]"
display the number of projects.,projects.shape[0]
how numerous projects are there?,projects.shape[0]
return the list of project ids and details.,"projects[['project_id', 'project_details']]"
obtain the codes and details for each project.,"projects[['project_id', 'project_details']]"
what are the project id and information for the project with at least two associated documents?,"pd.merge(projects, documents, on='project_id').groupby(['project_id', 'project_details']).filter(lambda x: len(x) > 2)[['project_id', 'project_details']].drop_duplicates()"
provide the ids and details of projects in which more than two documents exist.,"pd.merge(projects, documents, on='project_id').groupby(['project_id', 'project_details']).filter(lambda x: len(x) > 2)[['project_id', 'project_details']].drop_duplicates()"
"describe to me the project detail for the project with the document ""king book"".","projects.merge(documents.loc[lambda x: x['document_name']=='king book'], on='project_id')['project_details']"
"provide the details of a project with the title of ""king book"".","projects.merge(documents.loc[lambda x: x['document_name']=='king book'], on='project_id')['project_details']"
how many different types of budgets are in practice?,ref_budget_codes.shape[0]
what is the count of budget codes?,ref_budget_codes.shape[0]
please provide me with a list of budget types and their descriptions.,"ref_budget_codes[['budget_type_code', 'budget_type_description']]"
which type codes and descriptions are used for budget levels?,"ref_budget_codes[['budget_type_code', 'budget_type_description']]"
what is the description of the budget type with the code org?,"ref_budget_codes.loc[lambda x: x['budget_type_code']=='org', 'budget_type_description']"
please provide me with the description of budget type that has the code organizations.,"ref_budget_codes.loc[lambda x: x['budget_type_code']=='org', 'budget_type_description']"
determine how many documents contain expenses.,documents_with_expenses.shape[0]
determine the total number of documents with expenses.,documents_with_expenses.shape[0]
provide the list of document id for the budget type code sf.,"documents_with_expenses.loc[lambda x: x['budget_type_code']=='sf', 'document_id']"
concretize the ids of documents that have expenses with the budget code 'sf'.,"documents_with_expenses.loc[lambda x: x['budget_type_code']=='sf', 'document_id']"
please provide the info of the budget type code and description and the related document id.,"pd.merge(documents_with_expenses, ref_budget_codes, on='budget_type_code')[['budget_type_code', 'budget_type_description', 'document_id']]"
"fetch all budget type codes, descriptions and document ids for documents with expenses.","pd.merge(documents_with_expenses, ref_budget_codes, on='budget_type_code')[['budget_type_code', 'budget_type_description', 'document_id']]"
provide the list of document ids that have the 'government' budget type.,"pd.merge(documents_with_expenses, ref_budget_codes, on='budget_type_code').loc[lambda x: x['budget_type_description'] == 'government', 'document_id']"
"provide me the codes and descriptions of budget types, and the count of documents in each category.",documents_with_expenses.groupby('budget_type_code').size()
"determine the distinct resolution value types, and list the number of documents for each.",documents_with_expenses.groupby('budget_type_code').size()
which budget type has the most number of documents?,documents_with_expenses.groupby('budget_type_code').size().sort_values(ascending=false).index[0]
provide the budget type code that is frequent in documents with expenses.,documents_with_expenses.groupby('budget_type_code').size().sort_values(ascending=false).index[0]
provide the id of documents which do not have expense budgets.,documents[~documents['document_id'].isin(documents_with_expenses['document_id'])]['document_id']
please return the ids of documents that do not posses any expenses.,documents[~documents['document_id'].isin(documents_with_expenses['document_id'])]['document_id']
"provide the ids of all documents of the type ""cv"" that do not have expense budgets.","documents.query('document_type_code == ""cv""')['document_id'].drop_duplicates().reset_index(drop=true).loc[~documents_with_expenses['document_id'].isin(documents.query('document_type_code == ""cv""')['document_id'])]"
"what are the document id’s of type cv, which do not have expenses?","documents.query('document_type_code == ""cv""')['document_id'].drop_duplicates().reset_index(drop=true).loc[~documents_with_expenses['document_id'].isin(documents.query('document_type_code == ""cv""')['document_id'])]"
find the titles of document ids starting with s and having expense budgets attached.,"pd.merge(documents, documents_with_expenses, on='document_id').loc[lambda x: x['document_name'].str.contains('s', regex=false), 'document_id']"
give the ids of documents that have expenditures and contain the letter s in their names.,"pd.merge(documents, documents_with_expenses, on='document_id').loc[lambda x: x['document_name'].str.contains('s', regex=false), 'document_id']"
what is the number of documents that do not have expenses?,"documents.loc[~documents['document_id'].isin(documents_with_expenses['document_id']), :].shape[0]"
provide me with the count of documents without expenses.,"documents.loc[~documents['document_id'].isin(documents_with_expenses['document_id']), :].shape[0]"
determine the dates of the documents having both 'gv' type and 'sf' type expenses.,"pd.merge(documents, documents_with_expenses.loc[lambda x: x['budget_type_code'] == 'gv'], on='document_id')['document_date'].interesect(pd.merge(documents, documents_with_expenses.loc[lambda x: x['budget_type_code'] == 'sf'], on='document_id')['document_date'])"
provide the year and month in which documents both have budget type codes gv and sf.,"pd.merge(documents, documents_with_expenses.loc[lambda x: x['budget_type_code'] == 'gv'], on='document_id')['document_date'].interesect(pd.merge(documents, documents_with_expenses.loc[lambda x: x['budget_type_code'] == 'sf'], on='document_id')['document_date'])"
extract the account numbers with the maximum or with value ending with the character '5'.,"pd.concat([accounts['account_details'].max(),accounts.loc[accounts['account_details'].str.contains('5'), 'account_details']])"
give me the account details with the higher value and the ones containing the character '5'.,"pd.concat([accounts['account_details'].max(),accounts.loc[accounts['account_details'].str.contains('5'), 'account_details']])"
determine the total number of scientists.,scientists.shape[0]
what is the count of scientists?,scientists.shape[0]
provide me the total amount of time spent on projects.,projects['hours'].sum()
how many hours in total are utilized for all projects?,projects['hours'].sum()
how many scientists are assigned to any project?,assignedto['scientist'].nunique()
what is the count of scientists assigned to any project?,assignedto['scientist'].nunique()
find the number of unique projects.,projects['name'].nunique()
how many distinct projects are there?,projects['name'].nunique()
calculate the average hours of all projects.,projects['hours'].mean()
what is the average working hours across all projects?,projects['hours'].mean()
retrieve the title of project that continues for the longest time.,"projects.sort_values('hours', ascending=false).iloc[0]['name']"
what is the name of the project that has the longest lifetime?,"projects.sort_values('hours', ascending=false).iloc[0]['name']"
find the names of all projects whose working hours are greater than the average working hours of all projects.,"projects.loc[lambda x: x['hours'] > x['hours'].mean(), 'name']"
retrieve the names of projects that took longer than the average time for all projects.,"projects.loc[lambda x: x['hours'] > x['hours'].mean(), 'name']"
describe the number of scientists who are working on which project.,"pd.merge(projects, assignedto, left_on='code', right_on='project').groupby('project')[['name', 'hours']].sum().reset_index().nlargest(1, 'name')[['name', 'hours']]"
provide the name of the project and the count of scientists assigned to it.,"pd.merge(projects, assignedto, left_on='code', right_on='project').groupby('project')[['name', 'hours']].sum().reset_index().nlargest(1, 'name')[['name', 'hours']]"
retrieve the project in which a scientist with the last name of smith has been assigned.,"pd.merge(pd.merge(assignedto, projects, left_on='project', right_on='code'), scientists.loc[lambda x: x['name'].str.contains('smith'), :], left_on='scientist', right_on='ssn')['name']"
what is the project name in which the scientist is smith?,"pd.merge(pd.merge(assignedto, projects, left_on='project', right_on='code'), scientists.loc[lambda x: x['name'].str.contains('smith'), :], left_on='scientist', right_on='ssn')['name']"
get the total hours that are assigned to projects of which scientists michael rogers or carol smith were the members.,"pd.merge(pd.merge(assignedto, projects, left_on='project', right_on='code'), scientists, left_on='scientist', right_on='ssn').loc[lambda x: x['name'].isin(['michael rogers', 'carol smith']), 'hours'].sum()"
what is the total amount of hours that are assigned to projects where scientists with the name michael rogers or carol smith are involved?,"pd.merge(pd.merge(assignedto, projects, left_on='project', right_on='code'), scientists, left_on='scientist', right_on='ssn').loc[lambda x: x['name'].isin(['michael rogers', 'carol smith']), 'hours'].sum()"
find the names of projects that have a minimum requirement of between 100 and 300 hours of work.,"projects.loc[(projects['hours'] >= 100) & (projects['hours'] <= 300), 'name']"
list the titles of the projects that require one hundred and three hundred hours.,"projects.loc[(projects['hours'] >= 100) & (projects['hours'] <= 300), 'name']"
provide me with the names of scientists who simultaneously worked on two projects named 'matter of time' and 'a puzzling parallax'.,"scientists.loc[set(assignedto.merge(projects.loc[lambda x: x['name'] == 'matter of time'], left_on='project', right_on='code').merge(scientists, on='scientist')['name']) & set(assignedto.merge(projects.loc[lambda x: x['name'] == 'a puzzling parallax'], left_on='project', right_on='code').merge(scientists, on='scientist')['name']), 'name']"
"identify the names of scientists who worked on projects named ""matter of time"" and ""a puzzling pattern"".","scientists.loc[set(assignedto.merge(projects.loc[lambda x: x['name'] == 'matter of time'], left_on='project', right_on='code').merge(scientists, on='scientist')['name']) & set(assignedto.merge(projects.loc[lambda x: x['name'] == 'a puzzling parallax'], left_on='project', right_on='code').merge(scientists, on='scientist')['name']), 'name']"
please list the names in alphabetical order of all scientists.,scientists.sort_values('name')['name']
display the names of all the scientists in alphabetical order.,scientists.sort_values('name')['name']
what is the count of scientists associated per project title?,"pd.merge(projects, assignedto, left_on='code', right_on='project').groupby('name').size().reset_index(name='count')"
list the names of all the projects along with their number of scientists.,"pd.merge(projects, assignedto, left_on='code', right_on='project').groupby('name').size().reset_index(name='count')"
retrieve the number of scientists that are involved in the projects that require more than 300 hours.,"pd.merge(projects, assignedto, left_on='code', right_on='project').loc[lambda x: x['hours'] > 300].groupby('name').size().reset_index(name='count')"
"retrieve the names of projects that take more than 300 hours, and what are the scientists assigned to each project?","pd.merge(projects, assignedto, left_on='code', right_on='project').loc[lambda x: x['hours'] > 300].groupby('name').size().reset_index(name='count')"
find the titles and names of the projects being worked on by each scientist.,"pd.merge(scientists, assignedto, left_on='ssn', right_on='scientist').groupby('name').size().reset_index(name='count')"
"return the list of names of the scientists, along with the count of projects they are currently working on.","pd.merge(scientists, assignedto, left_on='ssn', right_on='scientist').groupby('name').size().reset_index(name='count')"
provide me the id and full name of scientists assigned to projects with the longest work hours.,"scientists.merge(assignedto.merge(projects.query(""hours == hours.max()""), on='project'), on='ssn')[['ssn', 'name']]"
obtain the ssn and names of scientists working on the project with the most hours.,"scientists.merge(assignedto.merge(projects.query(""hours == hours.max()""), on='project'), on='ssn')[['ssn', 'name']]"
which scientists are assigned to some project,"pd.merge(assignedto, scientists, left_on='scientist', right_on='ssn')['name']"
list the names of scientists who are assigned to any project.,"pd.merge(assignedto, scientists, left_on='scientist', right_on='ssn')['name']"
retrieve the titles of the projects that are not assigned yet.,"projects.loc[~projects['code'].isin(assigned_to['project']), 'name']"
i want to know the names of projects that have not been assigned.,"projects.loc[~projects['code'].isin(assigned_to['project']), 'name']"
retrieve the names of scientists that are not associated in any research project.,"scientists.loc[~scientists['ssn'].isin(assignedto['scientist']), 'name']"
what are the names of scientists who have not received a project?,"scientists.loc[~scientists['ssn'].isin(assignedto['scientist']), 'name']"
determine the number of scientists that are not assigned to any projects.,scientists.query('ssn not in assignedto.scientist').shape[0]
what is the count of scientists who do not have any project assigned to them?,scientists.query('ssn not in assignedto.scientist').shape[0]
retrieve the names of scientists who are not involved in the project with the highest hours.,"scientists[~scientists['name'].isin(pd.merge(pd.merge(assignedto, projects, left_on='project', right_on='code'), scientists, left_on='scientist', right_on='ssn').loc[lambda x: x['hours']==projects['hours'].max(), 'name'])]['name']"
retrieve the names of scientists that are not working on the project that has the highest number of hours.,"scientists[~scientists['name'].isin(pd.merge(pd.merge(assignedto, projects, left_on='project', right_on='code'), scientists, left_on='scientist', right_on='ssn').loc[lambda x: x['hours']==projects['hours'].max(), 'name'])]['name']"
"enumerate the names of scientists, projects worked on, and hours spent on each task.","pd.merge(pd.merge(scientists, assignedto, on='ssn'), projects, left_on='project', right_on='code')[['name_x', 'name_y', 'hours']].sort_values(['name_y', 'name_x'])"
"retrieve the names of scientists, names of projects they work on, and the hours for each of those projects, listed in alphabetical order by project name, then scientist name.","pd.merge(pd.merge(scientists, assignedto, on='ssn'), projects, left_on='project', right_on='code')[['name_x', 'name_y', 'hours']].sort_values(['name_y', 'name_x'])"
return the title of project that is least likely to take longer to finish and the name of researchers who participated in it.,"(pd.merge(pd.merge(assignedto, projects, left_on='project', right_on='code'), scientists, left_on='scientist', right_on='ssn').loc[lambda x: x['hours']==projects['hours'].min(), ['name_x', 'name_y']])"
"what is the project that requires the fewest number of hours, and the names of scientists associated with this project?","(pd.merge(pd.merge(assignedto, projects, left_on='project', right_on='code'), scientists, left_on='scientist', right_on='ssn').loc[lambda x: x['hours']==projects['hours'].min(), ['name_x', 'name_y']])"
who is the maker of the wine with highest rating?,wine.sort_values('score').iloc[0]['name']
the title of the wine with the highest-rated score.,wine.sort_values('score').iloc[0]['name']
which winery produced the wine that received the highest score?,wine.sort_values('score').iloc[0]['winery']
what is the name of the winery at which wine with the maximum score was made?,wine.sort_values('score').iloc[0]['winery']
fetch the names of all wines manufactured in the year 2008.,"wine.loc[lambda x: x['year']=='2008', 'name']"
obtain the list of names of wines that were produced in the year 2008.,"wine.loc[lambda x: x['year']=='2008', 'name']"
provide me the list of grapes and appelations used in all the wines.,"wine[['grape', 'appelation']]"
which grapes and appelations are contained in the wines?,"wine[['grape', 'appelation']]"
provide me with the name and scores of all wines.,"wine[['name', 'score']]"
what is the total number of wines and their respective scores?,"wine[['name', 'score']]"
retrieve the area and county of all appellations.,"appellations[['area', 'county']]"
find all the counties and areas for all the appellations.,"appellations[['area', 'county']]"
provide me with the prices of wines produced before the year 2010.,"wine.loc[wine['year'] < 2010, 'price']"
please list the prices of wines that were produced before 2010.,"wine.loc[wine['year'] < 2010, 'price']"
give me the names of all wines with scores higher than 90.,"wine.loc[wine['score'] > 90, 'name']"
return the names of all red-colored wines.,"pd.merge(grapes.loc[lambda x: x['color']=='red'], wine, on='grape')['name'].unique()"
what are the titles of wines created by using red grapes?,"pd.merge(grapes.loc[lambda x: x['color']=='red'], wine, on='grape')['name'].unique()"
list the names of all substitute wines with appellations in north coast area.,"pd.merge(appellations, wine, on='appelation').loc[lambda x: x['area']=='north coast', 'name'].unique()"
i am searching for the names of wines that carry appellations from the north coast region.,"pd.merge(appellations, wine, on='appelation').loc[lambda x: x['area']=='north coast', 'name'].unique()"
please provide me with the total count of wines that are produced at robert biale winery.,(wine['winery'] == 'robert biale').sum()
provide the count of wines that were produced at robert biale winery.,(wine['winery'] == 'robert biale').sum()
how were appelations divvied up in napa country?,(apellations['county'] == 'napa').sum()
how many counties are there in napa county?,(apellations['county'] == 'napa').sum()
provide me with an average of prices of the wines manufactured in sonoma county.,"pd.merge(applations, wine, on='appelation').loc[lambda x: x['county']=='sonoma', 'price'].mean()"
what is the average minimum cost of wines produced in appelations in sonoma county?,"pd.merge(applations, wine, on='appelation').loc[lambda x: x['county']=='sonoma', 'price'].mean()"
please provide me with the ids of wines that are produced from the varieties of white grapes along with their scores and names.,"pd.merge(grapes.loc[lambda x: x['color'] == 'white'], wine, on='grape')[['name', 'score']]"
please give the names of wines made from white grapes and their corresponding scores.,"pd.merge(grapes.loc[lambda x: x['color'] == 'white'], wine, on='grape')[['name', 'score']]"
find the maximum price of wines from central coast area and produced before the year 2005.,"wine.merge(apellations, left_on='appelation', right_on='appelation').loc[(wine['year'] < 2005) & (apellations['area'] == 'central coast'), 'price'].max()"
"do you know how to discover the maximum price of wines from the appelation in the central coast area, which were manufactured before the year 2005?","wine.merge(apellations, left_on='appelation', right_on='appelation').loc[(wine['year'] < 2005) & (apellations['area'] == 'central coast'), 'price'].max()"
find the name of the grape whose white grapes are used in the production of wines whose scores exceed 90.,"pd.merge(grapes[grapes['color']=='white'], wine[wine['score']>90], on='grape')['grape'].unique()"
find the names of the white grape varieties used in the production of wines that obtained scores higher than 90.,"pd.merge(grapes[grapes['color']=='white'], wine[wine['score']>90], on='grape')['grape'].unique()"
which wines have prices higher than 50 and are made from red grapes?,"pd.merge(grapes.loc[lambda x: x['color']=='red'], wine.loc[lambda x: x['price']>50], on='grape')['name']"
"retrieve the names and the prices of wines made from grapes and red in color, with prices above 50.","pd.merge(grapes.loc[lambda x: x['color']=='red'], wine.loc[lambda x: x['price']>50], on='grape')['name']"
please discover the names of wines that cost less than 50 and have appelations in monterey county.,"pd.merge(appellations, wine, on='appelation').loc[(lambda x: x['county']=='monterey') & (lambda x: x['price'] < 50), 'name']"
please provide me with the name and the price of wines with prices below $50 in monterey county and which have an appellation.,"pd.merge(appellations, wine, on='appelation').loc[(lambda x: x['county']=='monterey') & (lambda x: x['price'] < 50), 'name']"
what is the count of different grape wines?,wine.groupby('grape').size().reset_index(name='count')
which grape has the most of the wines?,wine.groupby('grape').size().reset_index(name='count')
provide me with the average price for all wines that are manufactured in different years.,wine.groupby('year')['price'].mean()
what is the average expenditure of wines for each each?,wine.groupby('year')['price'].mean()
retrieve the names and titles of all wines whose prices are higher than wines from john anthony winery.,"wine.loc[wine['price'] > wine.loc[wine['winery'] == 'john anthony', 'price'].min(), 'name'].unique()"
what is the count of wines that are more expensive than any wine from john anthony winery?,"wine.loc[wine['price'] > wine.loc[wine['winery'] == 'john anthony', 'price'].min(), 'name'].unique()"
enumerate the names of all distinct wines alphabetically.,wine['name'].sort_values().unique()
retrieve the titles of wines that are arranged in alphabetical order.,wine['name'].sort_values().unique()
return the list of wine names ordered by price.,wine.sort_values('price')['name'].unique()
"retrieve the names wines, sorted by price in ascending order.",wine.sort_values('price')['name'].unique()
what is the total area of vineyards located in the appellation that produced more wine before the year 2010?,"appellations.merge(wine.loc[lambda x: x['year']<2010], left_on='appelation', right_on='appelation').groupby('appelation')['area'].count().sort_values(ascending=false).index[0]"
please provide me with the area which grew the most grapes prior to 2010.,"appellations.merge(wine.loc[lambda x: x['year']<2010], left_on='appelation', right_on='appelation').groupby('appelation')['area'].count().sort_values(ascending=false).index[0]"
what is the color of the grape included in wine whose products are priced at the highest rate?,"pd.merge(grapes, wine, on='grape').groupby('grape')['price'].mean().sort_values(ascending=false).index[0]"
which color of grape produces wine with the highest average price?,"pd.merge(grapes, wine, on='grape').groupby('grape')['price'].mean().sort_values(ascending=false).index[0]"
retrieve the titles of wines that were produced before the year of 2000 or after the year of 2010.,"wine.loc[lambda x: (x['year'] < 2000) | (x['year'] > 2010), 'name'].unique()"
please retrieve the distinct names of wines made before 2000 or after 2010.,"wine.loc[lambda x: (x['year'] < 2000) | (x['year'] > 2010), 'name'].unique()"
list out the names of wineries that sell wines with a price range of 50 to 100.,"wine.loc[lambda x: x['price'].between(50, 100), 'winery'].unique()"
what distinct wineries produce wines with a cost between 50 and 100?,"wine.loc[lambda x: x['price'].between(50, 100), 'winery'].unique()"
present me with the average price of wines made of zinfandel grapes in the year 2009.,"wine.loc[(wine['year']==2009) & (wine['grape']=='zinfandel'), ['price', 'cases']].mean()"
deliver me the maximum price and score of wines that were produced by st. helena appelation.,"wine.loc[wine['appelation'] == 'st. helena', ['price', 'score']].max()"
please determine the maximum price and score for the wines produced in the appelation st. helena.,"wine.loc[wine['appelation'] == 'st. helena', ['price', 'score']].max()"
determine the maximum price and score of wines in each year.,"wine.groupby('year').agg({'price': 'max', 'score': 'max'})"
what is the max price and max score for each year?,"wine.groupby('year').agg({'price': 'max', 'score': 'max'})"
what are the average prices and scores of wines grouped by appellation?,"wine.groupby('appelation').agg({'price': 'mean', 'score': 'mean'})"
please return me the average price and score of wines for every appelation.,"wine.groupby('appelation').agg({'price': 'mean', 'score': 'mean'})"
provide me with the names of wineries that have at least four wines.,wine.groupby('winery').filter(lambda x: len(x) >= 4)['winery'].unique()
retrieve the country of all appellations that have at most three wine brands.,"pd.merge(applations, wine, left_on='appelation', right_on='appelation').groupby('appelation').filter(lambda x: x.shape[0] <= 3)['county']"
what is the count of countries for which at least 3 wines are designated?,"pd.merge(applations, wine, left_on='appelation', right_on='appelation').groupby('appelation').filter(lambda x: x.shape[0] <= 3)['county']"
retrieve the names of vintage year (years of production) of wines of brander winery that are earlier than all wine vintage years (years of production).,"wine.loc[wine['year'] < wine.loc[wine['winery']=='brander', 'year'].min(), 'name']"
get the names of wines produced before any of the wines from the brander winery.,"wine.loc[wine['year'] < wine.loc[wine['winery']=='brander', 'year'].min(), 'name']"
retrieve the titles of all wines that had a price higher than all other wines made in the year 2006.,"wine.loc[wine['price'] > wine['price'].loc[wine['year'] == 2006].max(), 'name']"
find the names of wines whose prices are higher than any wine produced in 2006.,"wine.loc[wine['price'] > wine['price'].loc[wine['year'] == 2006].max(), 'name']"
return the names of 3 biggest wineries that have the greatest number of wines made from white grapes.,"grapes.merge(wine, on='grape').loc[lambda x: x['color']=='white'].groupby('winery').size().sort_values(ascending=false)[:3].reset_index()['winery']"
which three wineries were able to produce maximum wines made with white grapes?,"grapes.merge(wine, on='grape').loc[lambda x: x['color']=='white'].groupby('winery').size().sort_values(ascending=false)[:3].reset_index()['winery']"
"list the grape, winery and year of the cheapest wines whose price is higher than 100.","wine.loc[lambda x: x['price'] > 100, ['grape', 'winery', 'year']].sort_values('year')"
"discover the title of grapes, wineries and years for wines with a price higher than 100, sorted in descending order of year.","wine.loc[lambda x: x['price'] > 100, ['grape', 'winery', 'year']].sort_values('year')"
what is the name and address of wines whose score is higher than 93?,"wine.loc[lambda x: x['score'] > 93, ['grape', 'appelation', 'name']].sort_values('name')"
"what is the order of grapes, appellations, and wines which have scored 93 or more on wine spectator ratings?","wine.loc[lambda x: x['score'] > 93, ['grape', 'appelation', 'name']].sort_values('name')"
"retrieve the appellations for wines that are produced after the year 2008, but not in the central coast region.","wine.loc[lambda x: x['year'] > 2008, 'appelation'].drop_duplicates().reset_index(drop=true).loc[lambda x: ~(x.isin(appellations.loc[lambda y: y['area']=='central coast', 'appelation']))]"
which names are attributed to the wines produced after 2008 but not in the central coast area?,"wine.loc[lambda x: x['year'] > 2008, 'appelation'].drop_duplicates().reset_index(drop=true).loc[lambda x: ~(x.isin(appellations.loc[lambda y: y['area']=='central coast', 'appelation']))]"
obtain the average price of wines produced not from sonoma county.,"wine.loc[~wine['appelation'].isin(pd.merge(appellations.loc[appellations['county']=='sonoma', 'appelation'], wine, on='appelation')['appelation']), 'price'].mean()"
what is the total average cost of wines not manufactured in sonoma county?,"wine.loc[~wine['appelation'].isin(pd.merge(appellations.loc[appellations['county']=='sonoma', 'appelation'], wine, on='appelation')['appelation']), 'price'].mean()"
list down the names of counties that produce the most number of wines with score higher than 90.,"pd.merge(apellations, wine, left_on='appelation', right_on='appelation').loc[lambda x: x['score'] > 90].groupby('county').size().sort_values(ascending=false).head(1).index[0]"
which county produces most wines with rating higher than 90?,"pd.merge(apellations, wine, left_on='appelation', right_on='appelation').loc[lambda x: x['score'] > 90].groupby('county').size().sort_values(ascending=false).head(1).index[0]"
what is the total count of train stations?,station.shape[0]
"provide me with a list of stations along with the location, platform, and number of platforms.","station[['name', 'location', 'number_of_platforms']]"
return me the list of all locations of train stations.,station['location'].unique()
provide me the counts of stations and the passengers' count of each station that is not located in london.,"station.loc[lambda x: x['location']!='london', ['name', 'total_passengers']]"
fetch the names of train stations that have the top three total number of passengers along with their corresponding main services.,"station[['name', 'main_services']].sort_values('total_passengers', ascending=false).head(3)"
determine the average number and total passengers at train stations in london or glasgow.,"station.loc[lambda x: x['location'].isin(['london', 'glasgow'])].agg({'total_passengers': ['mean', 'max']})"
provide me with all of the locations and the total number of platforms and passengers for all stations in each location.,"station.groupby('location').agg({'number_of_platforms': 'sum', 'total_passengers': 'sum'})"
please provide me with the names of locations that have stations with at least 15 platforms and stations with greater than 25 total passengers.,"station.loc[(station['number_of_platforms'] >= 15) & (station['total_passengers'] > 25), 'location'].unique()"
list all the locations that do not have a train station with at least 15 platforms.,"station.loc[~(station['number_of_platforms'] >= 15), 'location']"
please provide me with the location that has the most number of train stations.,station.groupby('location').size().sort_values(ascending=false).index[0]
"return me the titles, times, and services for all of the trains.","train[['name','time','service']]"
please present me the number of trains.,train.shape[0]
provide me the ids and names of trains in the order by time.,"train.sort_values('time')[['name', 'service']]"
give me the names of stations and the number of trains in each station.,"train_station.merge(station, on='station_id').groupby('name')['name'].count()"
provide the train and station names for each train.,"pd.merge(pd.merge(train_station, station, on='station_id'), train, on='train_id')[['name_x', 'name_y']]"
print in descending order by time all the train names and times at the stations in london.,"pd.merge(pd.merge(train_station, station, on='station_id'), train, on='train_id').loc[lambda x: x['location']=='london', ['name', 'time']].sort_values('time', ascending=false)"
show the title of stations with highest number of trains.,"pd.merge(train_station, station, on='station_id').groupby('station_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['name']"
provide the title of stations that have at least one train.,"station.merge(train_station, on='station_id').groupby('station_id').filter(lambda x: len(x) >= 2)['name']"
list all locations having only a single station.,station.groupby('location').filter(lambda x: len(x)==1)['location']
show titles that are without any train.,station[~station['station_id'].isin(train_station['station_id'])]['name']
"which stations serve both ""ananthapuri express"" and ""guruvayur express"" trains?","station.loc[pd.merge(train_station.loc[train_station['train_id'].isin(train.loc[train['name']=='ananthapuri express', 'train_id'])], station, on='station_id')['name'].isin(pd.merge(train_station.loc[train_station['train_id'].isin(train.loc[train['name']=='guruvayur express', 'train_id'])], station, on='station_id')['name'])]['name']"
retrieve the names of trains that pass through no station located in london.,"train_station.merge(train, on='train_id').loc[~train_station['station_id'].isin(station.loc[station['location']=='london', 'station_id']), 'name']"
list the locations and titles of stations arranged by their annual entry exit and interchange amounts.,"station[['name', 'location', 'annual_entry_exit', 'annual_interchanges']].sort_values(['annual_entry_exit', 'annual_interchanges'])[['name', 'location']]"
provide the titles of vehicles.,vehicles['vehicle_id']
retrieve the ids of all vehicles.,vehicles['vehicle_id']
how many vehicles were manufactured?,vehicles.shape[0]
define the number of vehicles.,vehicles.shape[0]
provide the details of the vehicle whose id is 1.,"vehicles.loc[lambda x: x['vehicle_id']==1, 'vehicle_details']"
please describe the car with id 1.,"vehicles.loc[lambda x: x['vehicle_id']==1, 'vehicle_details']"
"list the names, first, middle, and last of all staff.","staff[['first_name', 'middle_name', 'last_name']]"
what is the birthdate of the staffmember with first name janessa and last name sawayn?,"staff.loc[(staff['first_name'] == 'janessa') & (staff['last_name'] == 'sawayn'), 'date_of_birth']"
what is the year of birth for the employee named janessa sawayn?,"staff.loc[(staff['first_name'] == 'janessa') & (staff['last_name'] == 'sawayn'), 'date_of_birth']"
when did the staff member with first name as janessa and last name sawayn join the company?,"staff.loc[(staff['first_name']=='janessa') & (staff['last_name']=='sawayn'), 'date_joined_staff']"
when did the staff member named janessa sawayn join the organization?,"staff.loc[(staff['first_name']=='janessa') & (staff['last_name']=='sawayn'), 'date_joined_staff']"
when was the staff member that has the 'n' surname and first name as janessa discharged?,"staff.loc[(staff['first_name']=='janessa')&(staff['last_name']=='sawayn'), 'date_left_staff']"
on which date did the employee janessa sawayn leave the office?,"staff.loc[(staff['first_name']=='janessa')&(staff['last_name']=='sawayn'), 'date_left_staff']"
"provide count of the name that has first name ""ludie"".",(staff['first_name'] == 'ludie').sum()
determine the number of employees that have first name of ludie.,(staff['first_name'] == 'ludie').sum()
what is the moniker for personnel named jan. sawayn?,"staff.loc[(staff['first_name']=='janessa') & (staff['last_name']=='sawayn'), 'nickname']"
what is the designated nickname of the employee named janessa sawayn?,"staff.loc[(staff['first_name']=='janessa') & (staff['last_name']=='sawayn'), 'nickname']"
what is the total number of workers?,staff.shape[0]
which city have staff with first name as janessa and last name as sawayn?,"addresses.loc[lambda x: ((x['address_id'].isin(staff.loc[lambda y: (y['first_name']=='janessa')&(y['last_name']=='sawayn'), 'staff_address_id']))),'city']"
what is janessa sawayn's city of residence?,"addresses.loc[lambda x: ((x['address_id'].isin(staff.loc[lambda y: (y['first_name']=='janessa')&(y['last_name']=='sawayn'), 'staff_address_id']))),'city']"
which country and state did the staff with first name janessa and last name sawayn live?,"addresses.merge(staff.loc[(staff['first_name']=='janessa') & (staff['last_name']=='sawayn'), ['staff_address_id']], left_on='address_id', right_on='staff_address_id')[['country', 'state_province_county']]"
which state or country does janessa sawayn reside in?,"addresses.merge(staff.loc[(staff['first_name']=='janessa') & (staff['last_name']=='sawayn'), ['staff_address_id']], left_on='address_id', right_on='staff_address_id')[['country', 'state_province_county']]"
calculate the total duration of instruction sessions taken by customer with first name as rylan and last name as goodwin.,"lessons.merge(customers).loc[lambda x: (x['first_name']=='rylan') & (x['last_name']=='goodwin'), 'lesson_time'].sum()"
retrieve the total lesson time that was consumed by the customer named rylan goodwin.,"lessons.merge(customers).loc[lambda x: (x['first_name']=='rylan') & (x['last_name']=='goodwin'), 'lesson_time'].sum()"
what is the zip code for staff with first name as janessa and last name as sawayn?,"addresses.merge(staff.loc[(staff['first_name']=='janessa') & (staff['last_name']=='sawayn'), ['staff_address_id']], left_on='address_id', right_on='staff_address_id')['zip_postcode']"
please give me the zip code of the house of the employee named janessa sawayn.,"addresses.merge(staff.loc[(staff['first_name']=='janessa') & (staff['last_name']=='sawayn'), ['staff_address_id']], left_on='address_id', right_on='staff_address_id')['zip_postcode']"
how many employees reside in the state of georgia?,(len(addresses.loc[lambda x: x['state_province_county']=='georgia']))
how many employees reside in georgia?,(len(addresses.loc[lambda x: x['state_province_county']=='georgia']))
retrieve the first names and last names of staff who lived in the city damianfort.,"pd.merge(addresses, staff, left_on='address_id', right_on='staff_address_id').loc[lambda x: x['city']=='damianfort', ['first_name', 'last_name']]"
what is the full name and first name of all managers who live in the city damianfort?the following code will reformat all tables and content as paragraphs.,"pd.merge(addresses, staff, left_on='address_id', right_on='staff_address_id').loc[lambda x: x['city']=='damianfort', ['first_name', 'last_name']]"
"provide the names of cities where most of the staff members live. also, provide the total number of staff members residing there.","pd.merge(addresses, staff, left_on='address_id', right_on='staff_address_id').groupby('city').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
in which city do most of the employees live and how many live in this city?,"pd.merge(addresses, staff, left_on='address_id', right_on='staff_address_id').groupby('city').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
list the states which contain 2 to 4 workers living therein.,"addresses.merge(staff, left_on='address_id', right_on='staff_address_id').groupby('state_province_county').filter(lambda x: 2<=x.shape[0]<=4).state_province_county.unique()"
list the names of states having 2 to 4 employees residing in them.,"addresses.merge(staff, left_on='address_id', right_on='staff_address_id').groupby('state_province_county').filter(lambda x: 2<=x.shape[0]<=4).state_province_county.unique()"
please provide me with the names of all customers.,"customers[['first_name', 'last_name']]"
retrieve the names and surnames of all customers.,"customers[['first_name', 'last_name']]"
"please provide me with the details of the customer whose first name is carole, along with his email address and date of birth.","customers.loc[lambda x: x['first_name']=='carole', ['email_address', 'date_of_birth']]"
which email addresses and dates of birth are associated with customers whose names start with carole?,"customers.loc[lambda x: x['first_name']=='carole', ['email_address', 'date_of_birth']]"
list the phone numbers and email addresses of customers with balances greater than 2000.,"customers.loc[lambda x: x['amount_outstanding'] > 2000, ['phone_number', 'email_address']]"
give us the phone numbers and email addresses of all customers with an outstanding balance of more than 2000.,"customers.loc[lambda x: x['amount_outstanding'] > 2000, ['phone_number', 'email_address']]"
"provide me with the customer id, their mobile number and email address, middle name, and last name for users who go by the names kohler or marina.","customers.loc[(customers['first_name']=='marina') | (customers['last_name']=='kohler'), ['customer_status_code', 'cell_mobile_phone_number', 'email_address']]"
what are the dates of birthdays for customers who are categorized under 'good customer' status?,"customers.loc[lambda x: x['customer_status_code']=='good customer', 'date_of_birth']"
what is the date of birth of each customer whose status code is 'good customer'?,"customers.loc[lambda x: x['customer_status_code']=='good customer', 'date_of_birth']"
what year did customer with first name as carole and last name as bernhard register as a customer?,"customers.loc[(customers['first_name']=='carole') & (customers['last_name']=='bernhard'), 'date_became_customer']"
which year was carole bernhard first registered in bea?,"customers.loc[(customers['first_name']=='carole') & (customers['last_name']=='bernhard'), 'date_became_customer']"
what is the total count of customers?,customers.shape[0]
how many users do we have?,customers.shape[0]
convey me all the status codes and the number customers having each status code.,customers.groupby('customer_status_code').size()
how many customers are classified under a particular customer status code?,customers.groupby('customer_status_code').size()
what is the count of customer status codes in which the least number of customers were found?,customers.groupby('customer_status_code').size().nsmallest(n=1).index[0]
"how many customers achieved the status code ""not assigned""?",customers.groupby('customer_status_code').size().nsmallest(n=1).index[0]
provide me the count of lessons completed by customers whose first name is rylan and last name is goodwin.,"pd.merge(lessons, customers, on='customer_id').loc[(lambda x: x['first_name']=='rylan') & (lambda x: x['last_name']=='goodwin') & (lambda x: x['lesson_status_code']=='completed'),:].shape[0]"
how many lessons did ryan goodwin complete?,"pd.merge(lessons, customers, on='customer_id').loc[(lambda x: x['first_name']=='rylan') & (lambda x: x['last_name']=='goodwin') & (lambda x: x['lesson_status_code']=='completed'),:].shape[0]"
"determine the maximum, minimum, and average amount owed by customers.","customers['amount_outstanding'].agg(['max', 'min', 'mean'])"
"please provide me with the maximum, minimum, and average amount of money outstanding for all customers.","customers['amount_outstanding'].agg(['max', 'min', 'mean'])"
"retrieve the first name, last name, and outstanding amount of customers whose outstanding are between $1000 and $3000.","customers.loc[(customers['amount_outstanding'] >= 1000) & (customers['amount_outstanding'] <= 3000), ['first_name', 'last_name']]"
identify the names of clients whose outstanding balance lies in the range of 1000 to 3000 dollars.,"customers.loc[(customers['amount_outstanding'] >= 1000) & (customers['amount_outstanding'] <= 3000), ['first_name', 'last_name']]"
list the first and last names of customers living in lockmanfurt.,"pd.merge(customers, addresses, left_on='customer_address_id', right_on='address_id').loc[lambda x: x['city']=='lockmanfurt', ['first_name', 'last_name']]"
please provide a list of customers who live in lockmanfurt with their first and last names.,"pd.merge(customers, addresses, left_on='customer_address_id', right_on='address_id').loc[lambda x: x['city']=='lockmanfurt', ['first_name', 'last_name']]"
which country did the customer with first name of carole and last name of bernhard live in?,"addresses.loc[lambda x: x['address_id'].isin(customers.loc[lambda y: (y['first_name'] == 'carole') & (y['last_name'] == 'bernhard'), 'customer_address_id']), 'country']"
in what country was the customer carole bernhard located?,"addresses.loc[lambda x: x['address_id'].isin(customers.loc[lambda y: (y['first_name'] == 'carole') & (y['last_name'] == 'bernhard'), 'customer_address_id']), 'country']"
what is the zip code of a customer with first name as carole and last name as bernhard?,"customers.merge(addresses, left_on='customer_address_id', right_on='address_id').loc[(customers['first_name']=='carole')&(customers['last_name']=='bernhard'), 'zip_postcode']"
what zip code is registered under customer carole bernhard?,"customers.merge(addresses, left_on='customer_address_id', right_on='address_id').loc[(customers['first_name']=='carole')&(customers['last_name']=='bernhard'), 'zip_postcode']"
in which city do customers exercise the most?,"(pd.merge(customers, addresses, left_on='customer_address_id', right_on='address_id').groupby('city').size().sort_values(ascending=false).index[0])"
fetch the name of the city with the maximum sum of the count of customers.,"(pd.merge(customers, addresses, left_on='customer_address_id', right_on='address_id').groupby('city').size().sort_values(ascending=false).index[0])"
provide me with the aggregate amount paid by customer with first name as carole and last name as bernhard.,"pd.merge(customer_payments, customers, on='customer_id').query('first_name == ""carole"" and last_name == ""bernhard""')['amount_payment'].sum()"
what is the amount paid by customer carole bernhard?,"pd.merge(customer_payments, customers, on='customer_id').query('first_name == ""carole"" and last_name == ""bernhard""')['amount_payment'].sum()"
retrieve the count of clients that did not have any record of payment.,customers.loc[~customers['customer_id'].isin(customer_payments['customer_id'])].shape[0]
what is the count of customers that have no payment histories?,customers.loc[~customers['customer_id'].isin(customer_payments['customer_id'])].shape[0]
show me the given name and family names of the customers who have made more than two payments.,"payments.merge(customers, on='customer_id').groupby(['customer_id', 'first_name', 'last_name']).filter(lambda x: len(x) > 2)[['first_name', 'last_name']].drop_duplicates()"
retrieve the titles of customers who have made at least 2 payments.,"payments.merge(customers, on='customer_id').groupby(['customer_id', 'first_name', 'last_name']).filter(lambda x: len(x) > 2)[['first_name', 'last_name']].drop_duplicates()"
list all payment methods and the number of payments that uses each payment method.,customer_payments.groupby('payment_method_code').size()
"for each payment method, please find the count of payments that are made.",customer_payments.groupby('payment_method_code').size()
identify the number of instruction sessions that were in state cancelled.,(lessons['lesson_status_code']=='cancelled').sum()
which lessons were canceled?,(lessons['lesson_status_code']=='cancelled').sum()
find all lesson ids with titles taught by staff members whose names contain janessa sawayn and whose nicknames contain a letter 's'.,"lessons.merge(staff.loc[(staff['first_name']=='janessa')&(staff['last_name']=='sawayn')&(staff['nickname'].str.contains('s'))], on='staff_id')['lesson_id']"
"determine the ids of all the lesson taught by janessa sawayn whose nickname has the letter ""s.""","lessons.merge(staff.loc[(staff['first_name']=='janessa')&(staff['last_name']=='sawayn')&(staff['nickname'].str.contains('s'))], on='staff_id')['lesson_id']"
what is the count of lessons taught by staff whose first name begins with letter 'a'?,"pd.merge(lessons, staff, on='staff_id').loc[lambda x: x['first_name'].str.contains('a'), :].shape[0]"
how many lessons were taught by a staff member whose first name starts with the letter 'a'?,"pd.merge(lessons, staff, on='staff_id').loc[lambda x: x['first_name'].str.contains('a'), :].shape[0]"
what is the length of the total lesson time taught by staff with first name as janessa and last name as sawayn?,"pd.merge(lessons, staff, on='staff_id').loc[lambda x: (x['first_name']=='janessa')&(x['last_name']=='sawayn'), 'lesson_time'].sum()"
what is the total duration of all lessons taught by janessa sawayn?,"pd.merge(lessons, staff, on='staff_id').loc[lambda x: (x['first_name']=='janessa')&(x['last_name']=='sawayn'), 'lesson_time'].sum()"
"what is the average price taught by staff members with the first name ""janessa"" and the last name ""sawayn""?","pd.merge(lessons, staff, on='staff_id').loc[lambda x: (x['first_name'] == 'janessa') & (x['last_name'] == 'sawayn'), 'price'].mean()"
what is the average price for lessons taught by janessa sawayn?,"pd.merge(lessons, staff, on='staff_id').loc[lambda x: (x['first_name'] == 'janessa') & (x['last_name'] == 'sawayn'), 'price'].mean()"
provide me with the count of lessons attended by bob.,"pd.merge(lessons, customers, on='customer_id').loc[lambda x: x['first_name']=='ray'].shape[0]"
what is the count of lessons taken by the customer with the first name ray?,"pd.merge(lessons, customers, on='customer_id').loc[lambda x: x['first_name']=='ray'].shape[0]"
which last names are shared by customers and by staff?,pd.series(list(set(customers['last_name']) & set(staff['last_name'])))
which last names are utilized by both the customers and staff members of the company?,pd.series(list(set(customers['last_name']) & set(staff['last_name'])))
"who is the staff member who has not given any lesson, and what is his/her first name?","staff['first_name'].loc[~staff['staff_id'].isin(lessons.merge(staff, on='staff_id')['staff_id'])]"
please list all the employees who do not provide a lesson.,"staff['first_name'].loc[~staff['staff_id'].isin(lessons.merge(staff, on='staff_id')['staff_id'])]"
give me the vehicle id and name in which most of the lessons were carried out.,"vehicles.merge(lessons, on='vehicle_id').groupby(['vehicle_id', 'vehicle_details']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['vehicle_id', 'vehicle_details']]"
how many faculty members do we have?,faculty.shape[0]
how many faculty members are there in total?,faculty.shape[0]
what ranks do faculty hold?,faculty['rank'].unique()
give me the suffix tree of the list of ranks for the faculty.,faculty['rank'].unique()
list out all the buildings having faculty rooms.,faculty['building'].unique()
which buildings contain faculty offices?,faculty['building'].unique()
keyword: faculty,"faculty[['rank', 'fname', 'lname']]"
"provide me with the rank, first name, and last name of all faculty members.","faculty[['rank', 'fname', 'lname']]"
"return the names, surnames, and phone numbers for all female faculty members.","faculty.loc[faculty['sex']=='f', ['fname', 'lname', 'phone']]"
"fetch the records of all female faculty members' first name, last name, and phone number.","faculty.loc[faculty['sex']=='f', ['fname', 'lname', 'phone']]"
provide the ids for all male faculty members.,"faculty.loc[lambda x: x['sex']=='m', 'facid']"
what are the unique identifiers of all the male faculty members?,"faculty.loc[lambda x: x['sex']=='m', 'facid']"
how many professors do we have who are female?,"faculty.loc[(faculty['sex']=='f') & (faculty['rank'] == 'professor'), :].shape[0]"
provide me with the count of female professors that the university has.,"faculty.loc[(faculty['sex']=='f') & (faculty['rank'] == 'professor'), :].shape[0]"
"provide me with phone, room, and building information for the faculty member named jerry prince.","faculty.loc[(faculty['fname']=='jerry') & (faculty['lname']=='prince'), ['phone', 'room', 'building']]"
"what are the phone numbers, room numbers, and building of the faculty member called jerry prince?","faculty.loc[(faculty['fname']=='jerry') & (faculty['lname']=='prince'), ['phone', 'room', 'building']]"
how many professors are at building neb?,faculty[(faculty['rank']=='professor') & (faculty['building']=='neb')].shape[0]
describe the number of professors who occupy offices in building neb.,faculty[(faculty['rank']=='professor') & (faculty['building']=='neb')].shape[0]
please provide the first and last name of all your instructors.,"faculty.loc[lambda x: x['rank']=='instructor', ['fname', 'lname']]"
please give me the names of the all instructors along with their first name and last name.,"faculty.loc[lambda x: x['rank']=='instructor', ['fname', 'lname']]"
provide me the details of the buildings along with their number of faculty members.,faculty.groupby('building').size()
enumerate the faculty members housed in each building.,faculty.groupby('building').size()
which building has the most faculty members?,faculty['building'].value_counts().index[0]
please inform me of the name of building that houses the most number of faculty members.,faculty['building'].value_counts().index[0]
list all the buildings that possess at least 10 professors.,faculty.loc[lambda x: x['rank']=='professor'].groupby('building').filter(lambda x: len(x)>=10)['building'].unique()
what buildings had at least 10 professors?,faculty.loc[lambda x: x['rank']=='professor'].groupby('building').filter(lambda x: len(x)>=10)['building'].unique()
list the faculty ranks and the number of faculty members who have those ranks.,faculty.groupby('rank').size().reset_index(name='count')
please let me know the count of faculty members for each faculty rank.,faculty.groupby('rank').size().reset_index(name='count')
retrieve the details of faculty rank along with the number of male and female faculty for each rank.,"faculty.groupby(['rank', 'sex']).size().reset_index(name='count')"
identify the rank that possesses the smallest number of faculty members.,faculty.groupby('rank').size().sort_values().index[0]
find the rank of faculty that has the least number of members.,faculty.groupby('rank').size().sort_values().index[0]
how many assistant professors are there who are designated as either male or female?,faculty.loc[faculty['rank']=='asstprof'].groupby('sex').size()
provide me with first and middle names of linda smith's advisor.,"pd.merge(student.loc[(student['fname']=='linda') & (student['lname']=='smith')], faculty, left_on='advisor', right_on='facid')[['fname_x', 'lname_x']]"
"please provide me with the first name, last name, and advisor of linda smith.","pd.merge(student.loc[(student['fname']=='linda') & (student['lname']=='smith')], faculty, left_on='advisor', right_on='facid')[['fname_x', 'lname_x']]"
provide me with the ids of students whose advisors are professors.,"pd.merge(faculty.loc[lambda x: x['rank']=='professor', ['facid']], student, left_on='facid', right_on='advisor')['stuid']"
"identify the students that have advisors as professors, and provide their student id.","pd.merge(faculty.loc[lambda x: x['rank']=='professor', ['facid']], student, left_on='facid', right_on='advisor')['stuid']"
provide me with the names and surnames of all the students whose advisors are michael goodrich.,"faculty.merge(student, how='inner', left_on='facid', right_on='advisor').loc[(faculty['fname']=='michael')&(faculty['lname']=='goodrich'), ['fname','lname']]"
"provide me with the number of students that each faculty member advises, along with their faculty id.","student.groupby('advisor').size().reset_index(name='count').merge(faculty, left_on='advisor', right_on='facid')[['facid', 'count']]"
which faculty id has the maximum number of students and which faculty id has the least?,"student.groupby('advisor').size().reset_index(name='count').merge(faculty, left_on='advisor', right_on='facid')[['facid', 'count']]"
list all the faculty ranks and the number of students advised by each rank.,"faculty.merge(student, left_on='facid', right_on='advisor').groupby('rank', as_index=false)['rank'].agg({'count': 'count'})[['rank', 'count']]"
which faculty are advising how many students?,"faculty.merge(student, left_on='facid', right_on='advisor').groupby('rank', as_index=false)['rank'].agg({'count': 'count'})[['rank', 'count']]"
retrieve the names of faculty who have the largest number of students.,"pd.merge(faculty, student, left_on='facid', right_on='advisor').groupby(['facid', 'fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0, :2]"
please provide me the first name and complete last name of the faculty who advises the most students.,"pd.merge(faculty, student, left_on='facid', right_on='advisor').groupby(['facid', 'fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0, :2]"
provide the ids for all faculty members who have at least two students.,"pd.merge(faculty, student, left_on='facid', right_on='advisor').groupby('facid').filter(lambda x: len(x) >= 2)['facid']"
list the names of faculty members who are responsible for advising two or more students. provide the corresponding faculty ids.,"pd.merge(faculty, student, left_on='facid', right_on='advisor').groupby('facid').filter(lambda x: len(x) >= 2)['facid']"
provide me with the ids of the faculty members that have no intention of advising any student.,faculty['facid'].difference(student['advisor'])
provide me the id numbers of professors who did not advise any student.,faculty['facid'].difference(student['advisor'])
please tell me the activities of our company.,activity['activity_name']
determine the number of activities available.,activity.shape[0]
determine the number of faculty members who participate in an activity.,faculty_participates_in['facid'].nunique()
please inform me of the count of faculty members who participate in an activity.,faculty_participates_in['facid'].nunique()
obtain the ids of faculty members who have not participated in any activity.,"pd.concat([faculty['facid'], faculty_participates_in['facid']]).drop_duplicates(keep=false)"
retrieve the id of faculties that do not take part in any activity.,"pd.concat([faculty['facid'], faculty_participates_in['facid']]).drop_duplicates(keep=false)"
please show all the ids of faculty members who participate in an activity and advise students.,faculty_participates_in['facid'].interesect(student['advisor'])
what are these ids of the faculty members who not only participate in an activity but also advise a student?,faculty_participates_in['facid'].interesect(student['advisor'])
how many activities are held by mark giuliano?,"pd.merge(faculty, faculty_participates_in, on='facid').loc[lambda x: (x['fname']=='mark') & (x['lname']=='giuliano'), :].shape[0]"
determine the number of activities mark giuliano engages in.,"pd.merge(faculty, faculty_participates_in, on='facid').loc[lambda x: (x['fname']=='mark') & (x['lname']=='giuliano'), :].shape[0]"
provide me the names of all the activities that mark giuliano participates in.,"pd.merge(pd.merge(faculty, faculty_participates_in, on='facid'), activity, on='actid').loc[lambda x: (x['fname']=='mark') & (x['lname']=='giuliano'), 'activity_name']"
return the names of activities that mark giuliano participates in.,"pd.merge(pd.merge(faculty, faculty_participates_in, on='facid'), activity, on='actid').loc[lambda x: (x['fname']=='mark') & (x['lname']=='giuliano'), 'activity_name']"
"list all the professors who participated on any activity, together with the number of activities in which each of them participated.","pd.merge(faculty, faculty_participates_in, on='facid').groupby(['facid', 'fname', 'lname'])['facid'].count().reset_index(name='count')"
please provide me the first and last name of faculty members that have been participants in any activities in the department along with their participation in activities.,"pd.merge(faculty, faculty_participates_in, on='facid').groupby(['facid', 'fname', 'lname'])['facid'].count().reset_index(name='count')"
provide me the titles of all the activities along with the count of faculty engaged in each activity.,"activity.merge(faculty_participates_in, on='actid').groupby('activity_name')['actid'].count()"
which activities did each faculty member participate in?,"activity.merge(faculty_participates_in, on='actid').groupby('activity_name')['actid'].count()"
provide me with the first and last name of the faculty taking part in the most academic activities.,"faculty_participates_in.merge(faculty, on='facid').groupby(['facid', 'fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['fname', 'lname']]"
provide with full name and id of the faculty who is involved in the highest number of activities.,"faculty_participates_in.merge(faculty, on='facid').groupby(['facid', 'fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).head(1)[['fname', 'lname']]"
query with the name of the most student-oriented activity.,"activity.loc[faculty_participates_in['actid']].groupby('actid').agg({'activity_name': 'first'}).reset_index().merge(faculty_participates_in.groupby('actid').size().to_frame('count'), on='actid').sort_values('count', ascending=false).iloc[0]['activity_name']"
which activity has the most faculty members participating?,"activity.loc[faculty_participates_in['actid']].groupby('actid').agg({'activity_name': 'first'}).reset_index().merge(faculty_participates_in.groupby('actid').size().to_frame('count'), on='actid').sort_values('count', ascending=false).iloc[0]['activity_name']"
provide me with the ids of the students who didn't participate in any activity.,student[~student['stuid'].isin(participates_in['stuid'])]['stuid']
return me the ids of the students involved in no activity.,student[~student['stuid'].isin(participates_in['stuid'])]['stuid']
provide those ids corresponding to those students who participate in the activity and are below 20.,"pd.series(list(set(participates_in['stuid'])).intersection(set(student.loc[lambda x: x['age'] < 20, 'stuid'])))"
what is the id of students who are 20 years old or younger and are involved in at least one activity?,"pd.series(list(set(participates_in['stuid'])).intersection(set(student.loc[lambda x: x['age'] < 20, 'stuid'])))"
fetch us the name of the student that is the lead participant in the highest number of activities.,"pd.merge(student, participates_in, on='stuid').groupby(['stuid', 'fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['fname', 'lname']]"
please provide me with the first and last name of the student with the most number of activities.,"pd.merge(student, participates_in, on='stuid').groupby(['stuid', 'fname', 'lname']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['fname', 'lname']]"
what is the title for the activity with the most students?,"pd.merge(activity, participates_in, on='actid').groupby('actid')['activity_name'].count().sort_values(ascending=false).index[0]"
access the title of the activity that has the most number of student participants.,"pd.merge(activity, participates_in, on='actid').groupby('actid')['activity_name'].count().sort_values(ascending=false).index[0]"
retrieve the first names of faculty that participate in canoeing or kayaking.,"pd.merge(pd.merge(faculty, faculty_participates_in, on='facid'), activity, on='actid').loc[lambda x: x['activity_name'].isin(['canoeing', 'kayaking']), 'lname'].unique()"
determine the names of faculty members who are playing either canoeing or kayaking.,"pd.merge(pd.merge(faculty, faculty_participates_in, on='facid'), activity, on='actid').loc[lambda x: x['activity_name'].isin(['canoeing', 'kayaking']), 'lname'].unique()"
find the first names of professors who are not interested in either canoeing or kayaking.,"faculty.loc[lambda x: x['rank']=='professor', 'lname'].reset_index(drop=true).loc[~faculty_participates_in.merge(activity, on='actid').loc[lambda x: ((x['activity_name']=='canoeing') | (x['activity_name']=='kayaking'))]['facid'].isin(faculty.loc[lambda x: x['rank']=='professor', 'facid']),]"
which professors do not have the first names canoeing or kayaking?,"faculty.loc[lambda x: x['rank']=='professor', 'lname'].reset_index(drop=true).loc[~faculty_participates_in.merge(activity, on='actid').loc[lambda x: ((x['activity_name']=='canoeing') | (x['activity_name']=='kayaking'))]['facid'].isin(faculty.loc[lambda x: x['rank']=='professor', 'facid']),]"
please provide me with the first names of the faculty members who participated in canoeing and kayaking.,"pd.merge(pd.merge(faculty, faculty_participates_in, on='facid'), activity, on='actid').loc[lambda x: x['activity_name']=='canoeing', 'lname'].intersect(pd.merge(pd.merge(faculty, faculty_participates_in, on='facid'), activity, on='actid').loc[lambda x: x['activity_name']=='kayaking', 'lname'])"
provide me with the first names of the faculty members playing both canoeing and kayaking.,"pd.merge(pd.merge(faculty, faculty_participates_in, on='facid'), activity, on='actid').loc[lambda x: x['activity_name']=='canoeing', 'lname'].intersect(pd.merge(pd.merge(faculty, faculty_participates_in, on='facid'), activity, on='actid').loc[lambda x: x['activity_name']=='kayaking', 'lname'])"
which ids of the students participate in canoeing and kayaking?,"pd.merge(participates_in.loc[lambda x: x.merge(activity.loc[lambda x: x['activity_name']=='canoeing'], on='actid').index],activity.loc[lambda x: x['activity_name']=='kayaking'],on='actid')['stuid'].unique()"
list down the names of the students that participate in both canoeing and kayaking as their activities. also provide their student ids.,"pd.merge(participates_in.loc[lambda x: x.merge(activity.loc[lambda x: x['activity_name']=='canoeing'], on='actid').index],activity.loc[lambda x: x['activity_name']=='kayaking'],on='actid')['stuid'].unique()"
find the title of the airport located in the city of goroka.,"airports.loc[lambda x: x['city']=='goroka', 'name']"
retrieve the names of airports in the city of goroka.,"airports.loc[lambda x: x['city']=='goroka', 'name']"
"find the title, city, country, and elevation of the airports that are located in the city of new york.","airports.loc[lambda x: x['city']=='new york', ['name', 'city', 'country', 'elevation']]"
"provide me the name of each airport, city, country, and elevation for the airports that are located in the city of new york","airports.loc[lambda x: x['city']=='new york', ['name', 'city', 'country', 'elevation']]"
how many airlines exist?,airlines.shape[0]
how many airlines does russia have?,(airlines['country'] == 'russia').sum()
what is the count of airlines that are based in russia?,(airlines['country'] == 'russia').sum()
what is the highest elevation above sea level of all airports in the country of iceland?,"airports.loc[airports['country']=='iceland', 'elevation'].max()"
what altitude is occupied by the highest airport in the land of iceland?,"airports.loc[airports['country']=='iceland', 'elevation'].max()"
get the names of airports located in cuba or argentina.,"airports.loc[lambda x: x['country'].isin(['cuba', 'argentina']), 'name']"
what are the complete names of all airports in cuba or argentina?,"airports.loc[lambda x: x['country'].isin(['cuba', 'argentina']), 'name']"
retrieve the country name to which the airlines starting with orbit belong.,"airlines.loc[lambda x: x['name'].str.startswith('orbit'), 'country']"
what is the complete list of all airlines whose names start with orbit?,"airlines.loc[lambda x: x['name'].str.startswith('orbit'), 'country']"
list of airports having altitude between -50 and 50.,"airports.loc[(airports['elevation'] >= -50) & (airports['elevation'] <= 50), 'name']"
retrieve the names of all airports whose elevation is between -50 and 50.,"airports.loc[(airports['elevation'] >= -50) & (airports['elevation'] <= 50), 'name']"
identify the country that possesses the highest altitude airport.,"airports.sort_values('elevation', ascending=false).iloc[0]['country']"
what is the country where the airport rests with the highest elevation?,"airports.sort_values('elevation', ascending=false).iloc[0]['country']"
"given the names of airports, please find how many contain the word ""international"".",airports['name'].str.contains('international').sum()
"how many airports' titles contain the word ""international""?",airports['name'].str.contains('international').sum()
what is the total count of cities in greenland which have an airport?,"airports.loc[airports['country'] == 'greenland', 'city'].nunique()"
how many airports are there in various cities in greenland?,"airports.loc[airports['country'] == 'greenland', 'city'].nunique()"
determine the number of routes operated by american airlines.,"pd.merge(airlines, routes, on='alid').loc[lambda x: x['name']=='american airlines'].shape[0]"
how many routes does american airline cover?,"pd.merge(airlines, routes, on='alid').loc[lambda x: x['name']=='american airlines'].shape[0]"
what is the count of routes whose destination airport is in canada?,"pd.merge(airports, routes, left_on='apid', right_on='dst_apid').loc[lambda x: x['country']=='canada'].shape[0]"
what is the number of routes that terminate in canadian airports?,"pd.merge(airports, routes, left_on='apid', right_on='dst_apid').loc[lambda x: x['country']=='canada'].shape[0]"
"provide me the city, country, and altitude of an airport that has the lowest altitude.","airports[['name', 'city', 'country', 'elevation']].sort_values('elevation').head(1).reset_index(drop=true).loc[0, ['name', 'city', 'country']]"
"provide me the name of the lowest altitude airport along with the city, country, and altitude.","airports[['name', 'city', 'country', 'elevation']].sort_values('elevation').head(1).reset_index(drop=true).loc[0, ['name', 'city', 'country']]"
"retrieve the names of airports with the highest elevation, their city, and country.","airports[['name', 'city', 'country']].sort_values('elevation', ascending=false).iloc[0]"
determine the name and location of the airport containing the maximum number of routes.,"airports.merge(routes, left_on='apid', right_on='dst_apid').groupby('dst_apid').size().sort_values(ascending=false).reset_index(name='count').merge(airports, left_on='dst_apid', right_on='apid').iloc[0][['name', 'city', 'dst_apid']]"
what is the name of the airport that routes from the most locations terminate at?,"airports.merge(routes, left_on='apid', right_on='dst_apid').groupby('dst_apid').size().sort_values(ascending=false).reset_index(name='count').merge(airports, left_on='dst_apid', right_on='apid').iloc[0][['name', 'city', 'dst_apid']]"
list the top 10 airlines that operate the most number of flights.,"pd.merge(airlines, routes, on='alid').groupby('alid').size().nlargest(10).rename('count').reset_index().merge(airlines, on='alid')[['name', 'alid']]"
retrieve the name of airport being used in the flight routes of maximum number of planes.,"pd.merge(airports, routes, left_on='apid', right_on='src_apid').groupby('src_apid').agg({'name':'first', 'city':'first', 'src_apid':'first', 'dst_apid':'count'}).sort_values('dst_apid', ascending=false).iloc[0][['name', 'city', 'src_apid']]"
name the city from the city from which the most flights start.,"pd.merge(airports, routes, left_on='apid', right_on='src_apid').groupby('src_apid').agg({'name':'first', 'city':'first', 'src_apid':'first', 'dst_apid':'count'}).sort_values('dst_apid', ascending=false).iloc[0][['name', 'city', 'src_apid']]"
determine the number of different airports that american airlines flies to.,"pd.merge(airlines, routes, on='alid').loc[lambda x: x['name']=='american airlines', 'dst_apid'].nunique()"
what is the count of unique airports at which american airlines has direct flights?,"pd.merge(airlines, routes, on='alid').loc[lambda x: x['name']=='american airlines', 'dst_apid'].nunique()"
which country has the most number of airlines?,airlines.groupby('country').size().sort_values(ascending=false).index[0]
what is the name of the country in the world with the most number of home airlines?,airlines.groupby('country').size().sort_values(ascending=false).index[0]
which countries have the most airlines whose active status is 'y'?,airlines.loc[lambda x: x['active']=='y'].groupby('country').size().sort_values(ascending=false).head(1).index[0]
retrieve the names of countries which have the maximum number of airlines with an active status.,airlines.loc[lambda x: x['active']=='y'].groupby('country').size().sort_values(ascending=false).head(1).index[0]
"determine the total number of airlines per country, with countries listed in descending order of the number of airlines they possess.",airlines.groupby('country').size().sort_values(ascending=false)
which airlines operate most frequently out of each country?,airlines.groupby('country').size().sort_values(ascending=false)
"enumerate the total number of airports per country, in descending order by country.",airports.groupby('country').size().sort_values(ascending=false).reset_index(name='count(*)')
"what is the count of airports per country, ranked from the most to the least?",airports.groupby('country').size().sort_values(ascending=false).reset_index(name='count(*)')
show the cities in the united states by their decreasing number of airports.,"airports.loc[lambda x: x['country']=='united states'].groupby('city').size().reset_index(name='count').sort_values('count', ascending=false)"
which are the cities in the united states with the highest number of airports?,"airports.loc[lambda x: x['country']=='united states'].groupby('city').size().reset_index(name='count').sort_values('count', ascending=false)"
retrieve the cities in the united states with more than 3 airports.,airports.loc[lambda x: x['country']=='united states'].groupby('city').filter(lambda x: len(x) > 3)['city'].unique()
what is the total number of cities in the united states with 3 or more airports?,airports.loc[lambda x: x['country']=='united states'].groupby('city').filter(lambda x: len(x) > 3)['city'].unique()
provide me the count of cities which have more than three airports.,(airports.groupby('city')['city'].count() > 3).sum()
what is the total count of cities having more than 3 airports?,(airports.groupby('city')['city'].count() > 3).sum()
please let me have the name of the cities that have at least 2 airports along with the number of airports.,airports.groupby('city').filter(lambda x: len(x) > 1).groupby('city').size()
identify the locations of any city that have more than one airport and list the total number of airports present in that city.,airports.groupby('city').filter(lambda x: len(x) > 1).groupby('city').size()
list the cities which have more than two airports sorted by number of airports.,airports.groupby('city').filter(lambda x: len(x) > 2).groupby('city').size().sort_values()
which cities have more than two airports sorted by number of airports?,airports.groupby('city').filter(lambda x: len(x) > 2).groupby('city').size().sort_values()
"provide me with the id of its source airport, as well as a list of all routes.","routes.merge(airports, left_on='src_apid', right_on='apid').groupby('name').size().reset_index(name='count')"
"for each airport name, what is the count of route that starts from that airport?","routes.merge(airports, left_on='src_apid', right_on='apid').groupby('name').size().reset_index(name='count')"
pass me the count of routes from each source airport along with the corresponding airport name.,"pd.merge(airports, routes, left_on='apid', right_on='src_apid').groupby('name').size().reset_index(name='count').sort_values('count', ascending=false)"
"for each airport name, return how many routes start at that airport, with the result ordered from most to least.","pd.merge(airports, routes, left_on='apid', right_on='src_apid').groupby('name').size().reset_index(name='count').sort_values('count', ascending=false)"
what's the mean elevation of airports for each country?,airports.groupby('country')['elevation'].mean()
"for each country, what is the average of airport altitudes?",airports.groupby('country')['elevation'].mean()
which cities have two airports?,airports.groupby('city').filter(lambda x: len(x) == 2)['city'].unique()
specify the cities that have exactly two airports.,airports.groupby('city').filter(lambda x: len(x) == 2)['city'].unique()
"for each country and airline name, please provide me with the count of routes offered.","routes.merge(airlines, on='alid').groupby(['country', 'name']).size().reset_index(name='count')"
list all the routes for each country along with the corresponding airline name and count.,"routes.merge(airlines, on='alid').groupby(['country', 'name']).size().reset_index(name='count')"
find the number of routes that terminate in italian airports.,"pd.merge(routes, airports, left_on='dst_apid', right_on='apid').loc[lambda x: x['country']=='italy'].shape[0]"
what is the count of routes with destinations in italian airports?,"pd.merge(routes, airports, left_on='dst_apid', right_on='apid').loc[lambda x: x['country']=='italy'].shape[0]"
provide the count of routes with destination airport in italy operated by american airlines.,"pd.merge(pd.merge(routes, airports, left_on='dst_apid', right_on='apid'), airlines, on='alid').loc[(lambda x: (x['country']=='italy') & (x['name']=='american airlines'))].shape[0]"
what is the count of routes handled by american airlines that served destinations in italy?,"pd.merge(pd.merge(routes, airports, left_on='dst_apid', right_on='apid'), airlines, on='alid').loc[(lambda x: (x['country']=='italy') & (x['name']=='american airlines'))].shape[0]"
determine the count of routes that terminate at the john f kennedy international airport.,"pd.merge(airports, routes, left_on='apid', right_on='dst_apid').loc[lambda x: x['name']=='john f kennedy international airport'].shape[0]"
what is the count of routes that end at john f. kennedy international airport?,"pd.merge(airports, routes, left_on='apid', right_on='dst_apid').loc[lambda x: x['name']=='john f kennedy international airport'].shape[0]"
determine the number of routes from the united states to canada.,"routes.loc[routes['dst_apid'].isin(airports.loc[airports['country']=='canada', 'apid']) & routes['src_apid'].isin(airports.loc[airports['country']=='united states', 'apid']), :].shape[0]"
what is the number of routes that go from the united states of america to canada?,"routes.loc[routes['dst_apid'].isin(airports.loc[airports['country']=='canada', 'apid']) & routes['src_apid'].isin(airports.loc[airports['country']=='united states', 'apid']), :].shape[0]"
return the ids of routes whose source and destination airports are within the united states.,"routes.loc[routes['dst_apid'].isin(airports.loc[airports['country'] == 'united states', 'apid']) & routes['src_apid'].isin(airports.loc[airports['country'] == 'united states', 'apid']), 'rid']"
provide me with the id of the routes whose source and destination airports are in the united states.,"routes.loc[routes['dst_apid'].isin(airports.loc[airports['country'] == 'united states', 'apid']) & routes['src_apid'].isin(airports.loc[airports['country'] == 'united states', 'apid']), 'rid']"
retrieve the titles of airlines that circle the most routes.,"airlines.merge(routes, on='alid').groupby('name').size().sort_values(ascending=false).index[0]"
what is the name of the airline that has the greatest number of routes?,"airlines.merge(routes, on='alid').groupby('name').size().sort_values(ascending=false).index[0]"
return the name of the busiest airport in china that runs the maximum number of routes.,"pd.merge(airports, routes, left_on='apid', right_on='src_apid').loc[lambda x: x['country']=='china'].groupby('name').size().sort_values(ascending=false).index[0]"
what airport has the maximum number of routes that originate from china?,"pd.merge(airports, routes, left_on='apid', right_on='src_apid').loc[lambda x: x['country']=='china'].groupby('name').size().sort_values(ascending=false).index[0]"
please return the names of the airports that offer the largest number of routes in china.,"airports.merge(routes, left_on='apid', right_on='dst_apid').loc[lambda x: x['country']=='china'].groupby('name').size().sort_values(ascending=false).index[0]"
what is the name of the airport that receives the most number of flights that depart in china?,"airports.merge(routes, left_on='apid', right_on='dst_apid').loc[lambda x: x['country']=='china'].groupby('name').size().sort_values(ascending=false).index[0]"
what is the id of the latest order?,"orders.sort_values('date_order_placed', ascending=false).iloc[0]['order_id']"
retrieve the id of the most recently created order.,"orders.sort_values('date_order_placed', ascending=false).iloc[0]['order_id']"
provide me with the id and customer name details of the order from oldest to newest.,"orders[['order_id', 'customer_id']].sort_values('date_order_placed').head(1)"
retrieve the order id and customer id associated with the oldest order.,"orders[['order_id', 'customer_id']].sort_values('date_order_placed').head(1)"
"provide me with the id of the order whose tracking number is ""3452"".","shipments.loc[lambda x: x['shipment_tracking_number']=='3452', 'order_id']"
"what is the id of the order for which the shipment tracking number is ""3452""?","shipments.loc[lambda x: x['shipment_tracking_number']=='3452', 'order_id']"
give the id of all items whose product id is 11.,"order_items.loc[order_items['product_id']==11, 'order_item_id']"
retrieve the order items whose product is id 11.,"order_items.loc[order_items['product_id']==11, 'order_item_id']"
"give me the names of all the customers that have orders with status ""packing"".","pd.merge(customers, orders.loc[orders['order_status']=='packing'], on='customer_id')['customer_name'].unique()"
"give the names of customers that possess orders with the label ""packing"".","pd.merge(customers, orders.loc[orders['order_status']=='packing'], on='customer_id')['customer_name'].unique()"
"provide me with the details for all orders that have ""on road"" status.","pd.merge(customers, orders[orders['order_status']=='on road'], on='customer_id')['customer_details'].unique()"
"please provide me with the listing of distinct customers who have orders with status ""on road"".","pd.merge(customers, orders[orders['order_status']=='on road'], on='customer_id')['customer_details'].unique()"
please provide me the name of the customer who has the most orders.,"pd.merge(customers, orders, on='customer_id').groupby('customer_name').size().sort_values(ascending=false).index[0]"
please return me the customer name that made the most orders.,"pd.merge(customers, orders, on='customer_id').groupby('customer_name').size().sort_values(ascending=false).index[0]"
please provide the id of the customer who has the largest number of orders.,"pd.merge(customers, orders, on='customer_id').groupby('customer_id').size().idxmax()"
get the number of the customer who ordered the most items.,"pd.merge(customers, orders, on='customer_id').groupby('customer_id').size().idxmax()"
"please provide me the list of ids and statuses of orders belonging to the customer named ""jeramie"".","pd.merge(customers.loc[lambda x: x['customer_name']=='jeramie'], orders, on='customer_id')[['order_id', 'order_status']]"
provide me with the ids and status details of orders that were made by the customer named jeramie.,"pd.merge(customers.loc[lambda x: x['customer_name']=='jeramie'], orders, on='customer_id')[['order_id', 'order_status']]"
return the ordered dates for the customer named after jeramie,"pd.merge(customers[customers['customer_name']=='jeramie'], orders, on='customer_id')['date_order_placed']"
retrieve the names of customers (if any) who have made orders between the year 2009-01-01 and 2010-01-01.,"pd.merge(customers, orders, on='customer_id').loc[lambda x: (x['date_order_placed'] >= '2009-01-01') & (x['date_order_placed'] <= '2010-01-01'), 'customer_name']"
which customers made purchases between 2009-01-01 and 2010-01-01? identify their names.,"pd.merge(customers, orders, on='customer_id').loc[lambda x: (x['date_order_placed'] >= '2009-01-01') & (x['date_order_placed'] <= '2010-01-01'), 'customer_name']"
kindly provide me the list of distinct product ids from orders placed between 1975-01-01 and 1976-01-01.,"pd.merge(orders.loc[lambda x: (x['date_order_placed']>='1975-01-01') & (x['date_order_placed']<='1976-01-01')], order_items, on='order_id')['product_id'].unique()"
what is the count of distinct product ids ordered between 1975-01-01 and 1976-01-01?,"pd.merge(orders.loc[lambda x: (x['date_order_placed']>='1975-01-01') & (x['date_order_placed']<='1976-01-01')], order_items, on='order_id')['product_id'].unique()"
"retrieve the names of customers whose order status is both ""on road"" and ""shipped"".","pd.merge(orders.loc[orders['order_status']=='on road', ['customer_id']], customers, on='customer_id')['customer_name'].iloc[np.where(pd.merge(orders.loc[orders['order_status']=='shipped', ['customer_id']], customers, on='customer_id')['customer_name'].isin(pd.merge(orders.loc[orders['order_status']=='on road', ['customer_id']], customers, on='customer_id')['customer_name']))]"
"list the names of customers who have both the ""on road"" and ""shipped"" statuses.","pd.merge(orders.loc[orders['order_status']=='on road', ['customer_id']], customers, on='customer_id')['customer_name'].iloc[np.where(pd.merge(orders.loc[orders['order_status']=='shipped', ['customer_id']], customers, on='customer_id')['customer_name'].isin(pd.merge(orders.loc[orders['order_status']=='on road', ['customer_id']], customers, on='customer_id')['customer_name']))]"
"retrieve the ids of customers whose orders have both the status ""on road"" and ""shipped"".","pd.merge(customers.loc[lambda x: x['order_status'] == 'on road', 'customer_id'], customers.loc[lambda x: x['order_status'] == 'shipped', 'customer_id'], how='inner')"
"which customers have both ""on road"" and ""shipped"" as order statuses? provide the customer ids.","pd.merge(customers.loc[lambda x: x['order_status'] == 'on road', 'customer_id'], customers.loc[lambda x: x['order_status'] == 'shipped', 'customer_id'], how='inner')"
"what is the shipping tracking number of the order that was fulfilled on august 15, 2014?","pd.merge(orders, shipments, on='order_id').loc[lambda x: x['shipment_tracking_number'] == 3452, 'date_order_placed']"
provide me the invoicing date of the order whose invoice number is 10.,"pd.merge(orders, shipments, on='order_id').loc[lambda x: x['invoice_number']==10, 'date_order_placed']"
list the count and id of each product in all order.,"pd.merge(pd.merge(orders, order_items, on='order_id'), products, on='product_id').groupby('product_id').size().reset_index(name='count')"
"for each of the products, return the id and the number of times it was ordered.","pd.merge(pd.merge(orders, order_items, on='order_id'), products, on='product_id').groupby('product_id').size().reset_index(name='count')"
please provide me the list of products in the order.,"pd.merge(pd.merge(orders, order_items, on='order_id'), products, on='product_id').groupby('product_id')['product_name'].agg(['count'])"
"for each product, display its name and how many times it has been ordered.","pd.merge(pd.merge(orders, order_items, on='order_id'), products, on='product_id').groupby('product_id')['product_name'].agg(['count'])"
"find the orders which were shipped after january 1, 2000.","shipments.loc[lambda x: x['shipment_date'] > ""2000-01-01"", 'order_id']"
"what is the list of orders that have shipments after january 1, 2000?","shipments.loc[lambda x: x['shipment_date'] > ""2000-01-01"", 'order_id']"
please provide me with the id of the most recent order that was delivered.,"shipments.loc[lambda x: x['shipment_date']==shipments['shipment_date'].max(), 'order_id']"
which order had the most recent shipment? provide me with the order id.,"shipments.loc[lambda x: x['shipment_date']==shipments['shipment_date'].max(), 'order_id']"
arrange in ascending order all the distinct products.,products['product_name'].sort_values().unique()
provide the ids of all distinct orders ordered by their placement time.,orders.drop_duplicates('order_id').sort_values('date_order_placed')['order_id']
what is the list of distinct orders with the timestamps?,orders.drop_duplicates('order_id').sort_values('date_order_placed')['order_id']
what is the identifier of the order that contains the most items?,"pd.merge(orders, order_items, on='order_id').groupby('order_id').size().sort_values(ascending=false).index[0]"
what is the number of items or orders that belong to a single order?,"pd.merge(orders, order_items, on='order_id').groupby('order_id').size().sort_values(ascending=false).index[0]"
provide me with the name and number of the customer with the highest number of orders.,"pd.merge(customers, orders, on='customer_id').groupby('customer_name').size().sort_values(ascending=false).index[0]"
retrieve the name of the client that made the most orders.,"pd.merge(customers, orders, on='customer_id').groupby('customer_name').size().sort_values(ascending=false).index[0]"
retrieve the invoice numbers that were created before 1989-09-03 or after 2007-12-25.,"invoices.loc[(invoices['invoice_date'] < '1989-09-03') | (invoices['invoice_date'] > '2007-12-25'), 'invoice_number']"
what invoice numbers are created before 1989-09-03 or after 2007-12-25?,"invoices.loc[(invoices['invoice_date'] < '1989-09-03') | (invoices['invoice_date'] > '2007-12-25'), 'invoice_number']"
retrieve the invoices which are created before 1989-09-03 or after 2007-12-25.,"invoices.loc[(invoices['invoice_date'] < '1989-09-03') | (invoices['invoice_date'] > '2007-12-25'), 'invoice_details'].unique()"
"for each customer who has at least two orders, find the customer ids and total number of orders.","pd.merge(orders, customers, on='customer_id').groupby('customer_name').filter(lambda x: len(x) >= 2)['customer_name'].value_counts()"
gimme the names of customers who have made at least two orders and their respective number of orders.,"pd.merge(orders, customers, on='customer_id').groupby('customer_name').filter(lambda x: len(x) >= 2)['customer_name'].value_counts()"
list customers with at most 2 orders.,"pd.merge(orders, customers, on='customer_id').groupby('customer_name').filter(lambda x: len(x) <= 2)['customer_name']"
retrieve the titles of the clients that placed fewer than 2 orders.,"pd.merge(orders, customers, on='customer_id').groupby('customer_name').filter(lambda x: len(x) <= 2)['customer_name']"
"enumerate the names of the customers once they have purchased the product ""food"".","pd.merge(pd.merge(pd.merge(customers, orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').query('product_name == ""food""').groupby('customer_id').filter(lambda x: len(x) >= 1)['customer_name'].unique()"
who were the customers that bought food at least once?,"pd.merge(pd.merge(pd.merge(customers, orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').query('product_name == ""food""').groupby('customer_id').filter(lambda x: len(x) >= 1)['customer_name'].unique()"
"provide me with the names of customers who have canceled their purchase of the product ""food"" (the item status is ""cancel"").","pd.merge(pd.merge(pd.merge(customers, orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').query('order_item_status == ""cancel"" & product_name == ""food""').groupby('customer_id').filter(lambda x: len(x)>=1)['customer_name'].unique()"
"determine the customers that canceled the acquisition of food (the item is in ""cancel"" status).","pd.merge(pd.merge(pd.merge(customers, orders, on='customer_id'), order_items, on='order_id'), products, on='product_id').query('order_item_status == ""cancel"" & product_name == ""food""').groupby('customer_id').filter(lambda x: len(x)>=1)['customer_name'].unique()"
what is the count of female architects?,(architect['gender']=='female').sum()
"please list the names of male architects, select the nationality and then return the respective ids.","architect.loc[lambda x: x['gender']=='male', ['name', 'nationality', 'id']].sort_values('name')"
determine the maximum length in meters for the bridges and return the names of their architects.,"pd.merge(bridge, architect, left_on='architect_id', right_on='id').agg({'length_meters': 'max', 'name': 'first'})"
what is the average of the length of the bridges?,bridge['length_feet'].mean()
which mills were the 'grondzeiler' type and who built them?,"mill.loc[mill['type']=='grondzeiler', ['name', 'built_year']]"
print out the names of the architects who have built mills and their nationalities.,"pd.merge(architect, mill, on='architect_id')[['name', 'nationality']].drop_duplicates()"
list the name of mills that are not in 'donceel',"mill.loc[lambda x: x['location'] != 'donceel', 'name']"
which types of mills are fabricated by american and canadian architects?,"mill.merge(architect, left_on='architect_id', right_on='id').query(""nationality in ['american', 'canadian']"")['type'].unique()"
please list the ids and full names of all the architects who constructed at least three bridges.,"architect.merge(bridge, on='architect_id').groupby(['id', 'name']).filter(lambda x: len(x) >= 3).iloc[:, :2].drop_duplicates()"
which architect created the most mills?,"pd.merge(architect, mill, on='architect_id').groupby(['id', 'name', 'nationality']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[[0]][['id', 'name', 'nationality']]"
"provide me with the id, name and gender of the architects who built two bridges or one mill.","pd.concat([architect.merge(bridge, on='architect_id').groupby('id').filter(lambda x: len(x)==2), architect.merge(mill, on='architect_id').groupby('id').filter(lambda x: len(x)==1)])[['id', 'name', 'gender']]"
what is the full form of the bridge named 'kolob arch' or 'rainbow bridge'?,"bridge.loc[bridge['name'].isin(['kolob arch', 'rainbow bridge']), 'location']"
identify the distinct names of the mills that have been created by architects having also built a bridge longer than 80 meters.,"pd.merge(pd.merge(mill, architect, left_on='architect_id', right_on='id'), bridge, on='architect_id').loc[lambda x: x['length_meters'] > 80, 'name'].unique()"
"which mill type is the most common, and how many are there?",mill.groupby('type').size().nlargest(1)
determine how many architects built mills before the year 1850.,"architect.loc[~architect['id'].isin(mill.loc[mill['built_year']<1850, 'architect_id']), :].shape[0]"
create a list of all bridges designed by an american architect sorted by the bridge feet length.,"pd.merge(bridge, architect, left_on='architect_id', right_on='id').loc[lambda x: x['nationality']=='american', 'name'].sort_values(by='length_feet')"
what is the count of book clubs?,book_club.shape[0]
determine the number of book clubs.,book_club.shape[0]
provide me with the title and author or editor for all books made after 1989.,"book_club.loc[lambda x: x['year'] > 1989, ['book_title', 'author_or_editor']]"
please give me the list of books published after 1989 along with their titles and authors or editors and the corresponding ids.,"book_club.loc[lambda x: x['year'] > 1989, ['book_title', 'author_or_editor']]"
list all publishers for books of distinct titles.,book_club['publisher'].unique()
what are all the different publishers of books?,book_club['publisher'].unique()
"provide me with the years, book titles, and publishers for all books in descending order of publication year.","book_club[['year', 'book_title', 'publisher']].sort_values('year', ascending=false)"
"provide me with the titles and publishers of all books, ordered in descending order by year.","book_club[['year', 'book_title', 'publisher']].sort_values('year', ascending=false)"
enumerate all publishers and the number of books published by each publisher.,book_club.groupby('publisher').size()
how many books were published in each publisher?,book_club.groupby('publisher').size()
who is the publisher who has the maximum number of books?,book_club.groupby('publisher').size().sort_values(ascending=false).index[0]
please provide the name of the publisher that has published the most books.,book_club.groupby('publisher').size().sort_values(ascending=false).index[0]
present the titles of all book categories and the total number of books in each category.,book_club.groupby('category').size()
list the categories that have at least 2 books after year 1989.,book_club.loc[lambda x: x['year'] > 1989].groupby('category').filter(lambda x: len(x) >= 2)['category'].unique()
which categories have two or more books published after 1989?,book_club.loc[lambda x: x['year'] > 1989].groupby('category').filter(lambda x: len(x) >= 2)['category'].unique()
show the publishers with both a book published in 1989 and a book published in 1990.,"book_club.loc[book_club['year']==1989, 'publisher'].drop_duplicates().reset_index(drop=true).loc[lambda x : x.isin(book_club.loc[book_club['year']==1990, 'publisher'].unique())]"
what are the publishers that have published books in 1989 and 1990?,"book_club.loc[book_club['year']==1989, 'publisher'].drop_duplicates().reset_index(drop=true).loc[lambda x : x.isin(book_club.loc[book_club['year']==1990, 'publisher'].unique())]"
list the names of publishers who do not possess any books published in 1989.,"book_club.loc[lambda x: x['year']!=1989, 'publisher'].unique()"
which publishers did not publish a book in the year 1989?,"book_club.loc[lambda x: x['year']!=1989, 'publisher'].unique()"
"show the names of movies, years of release, and directors, but arrange the results by decreasing order according to the budget value.","movie[['title', 'year', 'director', 'budget_million']].sort_values('budget_million')"
how many directors are there in the movies?,movie['director'].nunique()
determine the total count of different directors.,movie['director'].nunique()
obtain the title and director for the all-time highest grossing movie that was made in the year 2000 or earlier.,"movie.loc[lambda x: x['year']<=2000].sort_values('gross_worldwide', ascending=false).iloc[0][['title', 'director']]"
please return the title and director of the movie released in the year 2000 or earlier that had the largest worldwide gross.,"movie.loc[lambda x: x['year']<=2000].sort_values('gross_worldwide', ascending=false).iloc[0][['title', 'director']]"
retrieve the full names of directors who have a movie in both year 1999 and 2000.,"set(movie.loc[movie['year']==2000, 'director']).intersection(set(movie.loc[movie['year']==1999, 'director']))"
find the names of directors who had a movie both in the year 1999 and 2000.,"set(movie.loc[movie['year']==2000, 'director']).intersection(set(movie.loc[movie['year']==1999, 'director']))"
list the names of directors who have a movie released in the year 1999 or 2000.,"movie.loc[movie['year'].isin([1999, 2000]), 'director']"
which directors had at least one work released in either 1999 or 2000?,"movie.loc[movie['year'].isin([1999, 2000]), 'director']"
"what were the highest, lowest, and average of the budget for all movies released before 2000?","movie.loc[movie['year']<2000, 'budget_million'].agg(['mean', 'max', 'min'])"
"please provide me with the average, maximum, and minimum budgets in millions for movies made before 2000.","movie.loc[movie['year']<2000, 'budget_million'].agg(['mean', 'max', 'min'])"
retrieve the names of companies that published books penned by alyson.,"culture_company.merge(book_club.loc[lambda x: x['publisher']=='alyson'], on='book_club_id')['company_name']"
find the names of companies that have a book published by alyson.,"culture_company.merge(book_club.loc[lambda x: x['publisher']=='alyson'], on='book_club_id')['company_name']"
provide me with the titles for all movies as well as books published by companies in china.,"pd.merge(pd.merge(movie, culture_company, on='movie_id'), book_club, on='book_club_id').loc[lambda x: x['incorporated_in']=='china', ['title', 'book_title']]"
give the titles of movies and books that correspond to corporations in china.,"pd.merge(pd.merge(movie, culture_company, on='movie_id'), book_club, on='book_club_id').loc[lambda x: x['incorporated_in']=='china', ['title', 'book_title']]"
list the names of companies that directed a movie in the year 1999.,"pd.merge(movie, culture_company, on='movie_id').loc[lambda x: x['year']==1999, 'company_name']"
find the titles of companies whose corresponding movies were released in 1999.,"pd.merge(movie, culture_company, on='movie_id').loc[lambda x: x['year']==1999, 'company_name']"
what is the most populous city in wyoming?,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
which city in wyoming has the biggest population,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
provide the name of the largest town in wyoming,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
which area in the state of wyoming has the highest population,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
what is the name of the city with largest population,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
which cities in wyoming have the highest number of citizens,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
return the names of cities in wyoming with highest populations.,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
what is the most populous city in the state of wyoming?,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
what is the largest populated city in wyoming,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
what is the largest city of wyoming?,"city.loc[lambda x: (x['state_name']=='wyoming') & (x['population']==city.loc[city['state_name']=='wyoming', 'population'].max()), 'city_name']"
which rivers pass through the state with the largest city in the united states?,"river.loc[lambda x: x['traverse'].isin(city.loc[lambda x: x['population']==city['population'].max(), 'state_name']), 'river_name']"
how big is new mexico?,"state.loc[state['state_name'] == 'new mexico', 'area']"
what is the area of new mexico?,"state.loc[state['state_name'] == 'new mexico', 'area']"
how many square miles constitute the state of new mexico?,"state.loc[state['state_name'] == 'new mexico', 'area']"
what is the area of new mexico state?,"state.loc[state['state_name'] == 'new mexico', 'area']"
"what is the total area of new mexico?a:you probably want ""re"", not ""er"".  search for ""unified"".  (also, some guidance with word order in the question might help.)","state.loc[state['state_name'] == 'new mexico', 'area']"
what is the area of new mexico in square kilometers?,"state.loc[state['state_name'] == 'new mexico', 'area']"
how many does california have,"state.loc[state['state_name'] == 'california', 'population']"
how many residents are there in california?,"state.loc[state['state_name'] == 'california', 'population']"
how many california residents live?,"state.loc[state['state_name'] == 'california', 'population']"
what is the population of california?,"state.loc[state['state_name'] == 'california', 'population']"
what is the population of california,"state.loc[state['state_name'] == 'california', 'population']"
how many people are living in the state of california,"state.loc[state['state_name'] == 'california', 'population']"
could you provide me the population of california?,"state.loc[state['state_name'] == 'california', 'population']"
how many californian people exist?,"state.loc[state['state_name'] == 'california', 'population']"
determine the count of people that live in california.,"state.loc[state['state_name'] == 'california', 'population']"
how many citizens live in california.,"state.loc[state['state_name'] == 'california', 'population']"
determine the state that possesses the smallest population.,"state.loc[state['population'] == state['population'].min(), 'state_name']"
what is the least populated state?,"state.loc[state['population'] == state['population'].min(), 'state_name']"
provide me with the cities in texas,"city.loc[city['state_name']=='texas', 'city_name']"
what is the number of cities in texas?,"city.loc[city['state_name']=='texas', 'city_name']"
list out the names of cities in texas.,"city.loc[city['state_name']=='texas', 'city_name']"
which cities of texas are not given.,"city.loc[city['state_name']=='texas', 'city_name']"
which cities in texas?,"city.loc[city['state_name']=='texas', 'city_name']"
could you provide me the names of cities that are situated in texas?,"city.loc[city['state_name']=='texas', 'city_name']"
what is the area of the capital albany,"state.loc[state['capital'] == 'albany', 'area']"
what lakes (in michigan) are the largest?,"lake.loc[(lake['area'] > 750) & (lake['state_name'] == 'michigan'), 'lake_name']"
what are the u.s. states,state['state_name']
display the state names,state['state_name']
please provide me the states of usa.,state['state_name']
list the states that ohio river flows through.,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
which state does the ohio river run through?,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
what are the states that border the ohio river?,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
which states does the ohio river run through?,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
where is the ohio river located?,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
which states does the ohio river run through,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
which state does the ohio river pass through,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
what is the count of states that run through the state of ohio?,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
return the name of state which has ohio river,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
"what states had rivers named ""ohio""","river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
which states flow into the ohio river,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
where is tennessee located?,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
which state does the river ohio run through,"river.loc[lambda x: x['river_name']=='ohio', 'traverse']"
which is the state with the largest population,"state.loc[state['population'] == state['population'].max(), 'state_name']"
which new jersey,"state.loc[state['population'] == state['population'].max(), 'state_name']"
which state has the largest population,"state.loc[state['population'] == state['population'].max(), 'state_name']"
which state has the biggest population?,"state.loc[state['population'] == state['population'].max(), 'state_name']"
which state has the maximum population,"state.loc[state['population'] == state['population'].max(), 'state_name']"
what is the name of the most populous state in the us?,"state.loc[state['population'] == state['population'].max(), 'state_name']"
what is the lowest elevation of any state in pennsylvania?,"highlow.loc[highlow['state_name']=='pennsylvania', 'lowest_elevation']"
which state's lowest point is 0 meters and which state's highest point is at sea level,"highlow.loc[lambda x: x['lowest_elevation']==0, ['highest_point', 'state_name']]"
what is the total length of the longest river in the usa?,"river.loc[lambda x: x['length'] == river['length'].max(), 'length']"
what is the longest river in the usa?,"river.loc[lambda x: x['length'] == river['length'].max(), 'length']"
what is the length of the longest river that flows through texas?,"river.loc[lambda x: (x['traverse']=='texas') & (x['length']==river.loc[lambda y: y['traverse']=='texas', 'length'].max()), 'river_name']"
what is the largest river in texas?,"river.loc[lambda x: (x['traverse']=='texas') & (x['length']==river.loc[lambda y: y['traverse']=='texas', 'length'].max()), 'river_name']"
which river in texas is the longest?,"river.loc[lambda x: (x['traverse']=='texas') & (x['length']==river.loc[lambda y: y['traverse']=='texas', 'length'].max()), 'river_name']"
which river is the biggest in texas?,"river.loc[lambda x: (x['traverse']=='texas') & (x['length']==river.loc[lambda y: y['traverse']=='texas', 'length'].max()), 'river_name']"
which is the longest river in texas?,"river.loc[lambda x: (x['traverse']=='texas') & (x['length']==river.loc[lambda y: y['traverse']=='texas', 'length'].max()), 'river_name']"
what are the two biggest rivers in the state of texas?,"river.loc[lambda x: (x['traverse']=='texas') & (x['length']==river.loc[lambda y: y['traverse']=='texas', 'length'].max()), 'river_name']"
what is the total number of rivers located in idaho?,(river['traverse'] == 'idaho')['river_name'].count()
what are the number of rivers present in idaho?,(river['traverse'] == 'idaho')['river_name'].count()
how many rivers does idaho have,(river['traverse'] == 'idaho')['river_name'].count()
determine the count of rivers that run through idaho.,(river['traverse'] == 'idaho')['river_name'].count()
how many rivers are found in idaho,(river['traverse'] == 'idaho')['river_name'].count()
which rivers are found in idaho?,(river['traverse'] == 'idaho')['river_name'].count()
list the state names adjacent to kentucky.,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
what are the states that border kentucky,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
list all the states that lie east of kentucky.,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
what are the names of the closest states to kentucky?,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
what are the states surrounding kentucky,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
which states border kentucky?,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
extract the names of the states which are adjacent to kentucky.,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
list the states of kentucky that border it.,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
find the names of states bordering kentucky.,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
what is the adjacent state of kentucky,"border_info.loc[lambda x: x['state_name'] == 'kentucky', 'border']"
list the names of all the rivers in the state of illinois.,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
rivers in the state illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what are the names of rivers in illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
list the river names in the state of illinois.,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what rivers can be found in illinois?,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
which rivers are present in illinois?,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what rivers run through illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what rivers flow through the state of illinois?,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
which river flows through the state of illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
return me the names of rivers in the state of illinois.,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
give me the names of the rivers in illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what are the rivers of illinois?,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
which rivers are in the state of illinois,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
which river systems run through the state of illinois?,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what is the name of this state that is traversed by the illinois river?,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
which river runs through the state of illinois?,"river.loc[lambda x: x['traverse']=='illinois', 'river_name']"
what state is that springfield in?,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
where is the first springfield,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
determine the city springfield and state in which it is located.,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
for which states is the city springfield,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
what state is home to springfield,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
what states have a city that is named springfield,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
what is the state of the city springfield,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
retrieve the names of the towns named springfield in states.,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
in what state is springfield located?,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
in which state is springfield located,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
"what are the two-letter state abbreviations of cities starting with the letter ""s""","city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
in which us states are springfield cities located?,"city.loc[lambda x: x['city_name']=='springfield', 'state_name']"
what is the estimated population of the state of west virginia?,"state.loc[state['area'] == state['area'].max(), 'population']"
return me the total count of people who live in the city of boulder.,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
what is the count of the populace of boulder?,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
how many people reside in boulder?,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
how many people live,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
what is the population of boulder,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
what is the count of people in boulder?,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
list the names of the people who live in boulder.,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
look for the number of people that live in boulder.,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
how many people does boulder have,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
how many citizens are there in boulder?,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
how many citizens reside in boulder?,"city.loc[lambda x: x['city_name']=='boulder', 'population']"
find the city in alaska with the smallest population.,"city.loc[(city['population'] == city.loc[city['state_name']=='alaska', 'population'].min()) & (city['state_name']=='alaska'), 'city_name']"
which states lie on the largest river in the u.s.,"river.loc[river['length']==river['length'].max(), 'traverse']"
which state has the longest river running through it,"river.loc[river['length']==river['length'].max(), 'traverse']"
which state has the largest river,"river.loc[river['length']==river['length'].max(), 'traverse']"
provide me the count of states through which the lengthiest river passes.,"river.loc[river['length']==river['length'].max(), 'traverse']"
which state has a river that traverses the longest distance,"river.loc[river['length']==river['length'].max(), 'traverse']"
what state has the lowest population density?,"state.loc[state['area']==state['area'].min(), 'density']"
which of the states is the one with the lower population density.,"state.loc[state['area']==state['area'].min(), 'density']"
which states have points higher than the highest point in colorado,"highlow.loc[lambda x: x['highest_elevation'] > highlow.loc[highlow['state_name']=='colorado', 'highest_elevation'].iloc[0], 'state_name']"
which states have point higher than the points in colorado,"highlow.loc[lambda x: x['highest_elevation'] > highlow.loc[highlow['state_name']=='colorado', 'highest_elevation'].iloc[0], 'state_name']"
which states have a higher high point than that of colorado,"highlow.loc[lambda x: x['highest_elevation'] > highlow.loc[highlow['state_name']=='colorado', 'highest_elevation'].iloc[0], 'state_name']"
which location in delaware has the highest elevation?,"highlow.loc[lambda x: x['state_name'] == 'delaware', 'highest_elevation'].iloc[0]"
what is the elevation of the highest point in delaware?,"highlow.loc[lambda x: x['state_name'] == 'delaware', 'highest_elevation'].iloc[0]"
please give me the highest elevation in delaware.,"highlow.loc[lambda x: x['state_name'] == 'delaware', 'highest_elevation'].iloc[0]"
what is the elevation of the highest point in delaware,"highlow.loc[lambda x: x['state_name'] == 'delaware', 'highest_elevation'].iloc[0]"
what is the longest river that passes through the usa?,"river.loc[lambda x: x['length'] == river['length'].max(), 'river_name']"
which was the longest river in united states of america,"river.loc[lambda x: x['length'] == river['length'].max(), 'river_name']"
determine the length of the longest river in the united states.,"river.loc[lambda x: x['length'] == river['length'].max(), 'river_name']"
retrieve the title of the longest river in us.,"river.loc[lambda x: x['length'] == river['length'].max(), 'river_name']"
retrieve the name of the river that has the largest distance in the united states.,"river.loc[lambda x: x['length'] == river['length'].max(), 'river_name']"
what is the longest river in the u.s.?,"river.loc[lambda x: x['length'] == river['length'].max(), 'river_name']"
retrieve the name of the river that possesses the longest length.,"river.loc[lambda x: x['length'] == river['length'].max(), 'river_name']"
what is the longest river in the united stated?,"river.loc[lambda x: x['length'] == river['length'].max(), 'river_name']"
what is the state that houses the city with the largest population,"city.loc[city['population'] == city['population'].max(), 'state_name']"
what are the major cities in the state of?,"city.loc[city['population'] == city['population'].max(), 'state_name']"
what is the name of the state with the most population?,"city.loc[city['population'] == city['population'].max(), 'state_name']"
which state has the most population of cities,"city.loc[city['population'] == city['population'].max(), 'state_name']"
what are the cities in the largest state that have a population equal to or below 10000?,"city.loc[(city['population'] == city.loc[state.loc[state['area'] == state['area'].max(), 'state_name'].values, 'population'].min()) & (city['state_name'].isin(state.loc[state['area'] == state['area'].max(), 'state_name'])), 'city_name']"
which are the largest states,"state.loc[state['area']==state['area'].max(), 'state_name']"
which state has the largest area,"state.loc[state['area']==state['area'].max(), 'state_name']"
what is the biggest state of the continental us?,"state.loc[state['area']==state['area'].max(), 'state_name']"
name the state with the largest area,"state.loc[state['area']==state['area'].max(), 'state_name']"
what is the largest state in usa?,"state.loc[state['area']==state['area'].max(), 'state_name']"
what is the biggest state in the united states?,"state.loc[state['area']==state['area'].max(), 'state_name']"
provide me with the state with the largest population.,"state.loc[state['area']==state['area'].max(), 'state_name']"
what is the most populated state in the usa?,"state.loc[state['area']==state['area'].max(), 'state_name']"
what is the largest state,"state.loc[state['area']==state['area'].max(), 'state_name']"
what are the states surrounding mississippi that are the highest in elevation?,"highlow.loc[highlow['state_name'].isin(border_info.loc[border_info['state_name']=='mississippi', 'border']), 'highest_point']"
what is the total count of highest points in states surrounding mississippi?,"highlow.loc[highlow['state_name'].isin(border_info.loc[border_info['state_name']=='mississippi', 'border']), 'highest_point']"
what is the elevation of the highest points in states bordering colorado,"highlow.loc[highlow['state_name'].isin(border_info.loc[border_info['state_name']=='colorado', 'border']), 'highest_point'].sort_values(ascending=false).iloc[0]"
what is the highest point in the states bordering colorado?,"highlow.loc[highlow['state_name'].isin(border_info.loc[border_info['state_name']=='colorado', 'border']), 'highest_point'].sort_values(ascending=false).iloc[0]"
which state has the lowest population density?,"state.loc[state['density']==state['density'].min(),'state_name']"
what is the name of the state that has the lowest population density?,"state.loc[state['density']==state['density'].min(),'state_name']"
find the names of states with the sparsest population.,"state.loc[state['density']==state['density'].min(),'state_name']"
what state has the smalest population density,"state.loc[state['density']==state['density'].min(),'state_name']"
what is the state having the least population density?,"state.loc[state['density']==state['density'].min(),'state_name']"
which state has the sparsest population,"state.loc[state['density']==state['density'].min(),'state_name']"
where in texas is the highest point?,"highlow.loc[lambda x: x['state_name']==""texas"", 'highest_point']"
what is the highest point in the texas state?,"highlow.loc[lambda x: x['state_name']==""texas"", 'highest_point']"
what is the highest point of texas?,"highlow.loc[lambda x: x['state_name']==""texas"", 'highest_point']"
what is the highest mountain in the state of texas?,"highlow.loc[lambda x: x['state_name']==""texas"", 'highest_point']"
give me the highest point in the state of texas,"highlow.loc[lambda x: x['state_name']==""texas"", 'highest_point']"
which states do not have neighbors,state[~state['state_name'].isin(border_info['state_name'])]['state_name']
which states have no neighboring states,state[~state['state_name'].isin(border_info['state_name'])]['state_name']
which states have no borders with other state,state[~state['state_name'].isin(border_info['state_name'])]['state_name']
what is the population density of the state area,"state.loc[state['density'] == state['density'].min(), 'area']"
how many states in the united states have lower elevations than the state of alabama?,"(highlow['lowest_elevation'] < highlow.loc[highlow['state_name']=='alabama', 'lowest_elevation'].item())['state_name'].count()"
what is the height of guadalupe peak.,"highlow.loc[lambda x: x['highest_point'] == 'guadalupe peak', 'highest_elevation']"
how much is the elevation of guadalupe peak,"highlow.loc[lambda x: x['highest_point'] == 'guadalupe peak', 'highest_elevation']"
what is the height in meters of the highest place in america?,highlow['highest_elevation'].max()
what is the elevation of the highest spot in the united states?,highlow['highest_elevation'].max()
what is the elevation of the highest point in the usa?,highlow['highest_elevation'].max()
what is the maximum height of the highest point in the u.s.a.?,highlow['highest_elevation'].max()
what is the length of the rio grande river?,"river.loc[river['river_name']=='rio grande', 'length']"
what is the total length of the rio grande?,"river.loc[river['river_name']=='rio grande', 'length']"
how long is the river rio grande?,"river.loc[river['river_name']=='rio grande', 'length']"
what is the length of the rio grande river in miles?,"river.loc[river['river_name']=='rio grande', 'length']"
how long is rio grande?,"river.loc[river['river_name']=='rio grande', 'length']"
what is the total length of the longest river in texas?,"river.loc[(river['traverse'] == 'texas') & (river['length'] == river.loc[river['traverse'] == 'texas', 'length'].max()), 'length']"
what is the length of the longest river in texas?,"river.loc[(river['traverse'] == 'texas') & (river['length'] == river.loc[river['traverse'] == 'texas', 'length'].max()), 'length']"
how many capitals does rhode island possess?,"state.loc[state['state_name'] == 'rhode island', 'capital'].count()"
what is the count of cities in the united states?,city['city_name'].count()
how many cities does the u.s.a. have?,city['city_name'].count()
how many american cities are there?,city['city_name'].count()
how many cities are there in the united states?,city['city_name'].count()
how many cities exist in the u.s.?,city['city_name'].count()
what is the number of big cities?,(city['population'] > 150000).sum()
how many citizens live in the biggest city in the usa?,"city.loc[city['population'] == city['population'].max(), 'population']"
what are the names of colorado rivers?,(river['river_name'] == 'colorado').sum()
return me the count of rivers called colorado,(river['river_name'] == 'colorado').sum()
what is the population of seattle washington?,"city.loc[(city['city_name'] == 'seattle') & (city['state_name'] == 'washington'), 'population']"
please provide me with the number of residents of seattle in the state of washington.,"city.loc[(city['city_name'] == 'seattle') & (city['state_name'] == 'washington'), 'population']"
how many people live in the biggest city in alaska state,"city.loc[(city['state_name']=='alaska')&(city['population']==city.loc[city['state_name']=='alaska', 'population'].max()), 'population']"
what is the total land area covered by the largest alaskan city?,"city.loc[(city['state_name']=='alaska')&(city['population']==city.loc[city['state_name']=='alaska', 'population'].max()), 'population']"
what is the count of people living in texas' capital,"city.loc[lambda x: x['city_name'].eq(state.loc[state['state_name'].eq('texas'), 'capital'].values[0]), 'population']"
what is the total area of austin?,"city.loc[lambda x: x['city_name'].eq(state.loc[state['state_name'].eq('texas'), 'capital'].values[0]), 'population']"
how many us citizens are there?,state['population'].sum()
what is the combined population of all the 50 states?,state['population'].sum()
find the number of states in the united state.,state['state_name'].count()
in which year was the maximum number of states established?,state['state_name'].count()
what states belong to the united states of america?,state['state_name'].count()
what is the number of states in the united states,state['state_name'].count()
how many states are there in united states?,state['state_name'].count()
how many states border kentucky?,"border_info.loc[lambda x: x['state_name']=='kentucky', 'border'].count()"
which state borders kentucky?,"border_info.loc[lambda x: x['state_name']=='kentucky', 'border'].count()"
number of states bordering kentucky,"border_info.loc[lambda x: x['state_name']=='kentucky', 'border'].count()"
how many states border the state with the largest population?,"border_info.loc[border_info['state_name'].isin(state.loc[state['population'] == state['population'].max(), 'state_name']), 'border'].count()"
how many states are there which do not have rivers?,"state.loc[~state['state_name'].isin(river['traverse'].unique()), 'state_name'].nunique()"
give the count of the states in the u.s. that have a point higher than the highest point of the state with the largest capital city in the u.s.,(highlow['highest_elevation'] > highlow[highlow['state_name'] == state[state['capital'] == city[city['population'] == city['population'].max()]['city_name'].iloc[0]]['state_name'].iloc[0]]['highest_elevation'].iloc[0])['state_name'].count()
return the names of major river within the state of illinois,"river.loc[(river['length']>750)&(river['traverse']=='illinois'), 'river_name']"
what are the main rivers in illinois,"river.loc[(river['length']>750)&(river['traverse']=='illinois'), 'river_name']"
what are the names of the major rivers in illinois?,"river.loc[(river['length']>750)&(river['traverse']=='illinois'), 'river_name']"
how many major rivers run through illinois,"river.loc[(river['length']>750)&(river['traverse']=='illinois'), 'river_name']"
what is the count of states through which the longest river in texas runs?,"river.loc[lambda x: x['traverse']=='texas', 'length'].max()"
which city is the capital of texas?,"state.loc[state['state_name']=='texas', 'capital']"
what is the capital of the united states state texas?,"state.loc[state['state_name']=='texas', 'capital']"
what is the capital of the texas?,"state.loc[state['state_name']=='texas', 'capital']"
what is the capital of the state of texas?,"state.loc[state['state_name']=='texas', 'capital']"
please provide me with the full name and capital of texas.,"state.loc[state['state_name']=='texas', 'capital']"
what states border texas?,"pd.merge(state, border_info, left_on='state_name', right_on='border').loc[lambda x: x['state_name']=='texas', 'capital']"
provide the name of each capital city alongside its state which borders texas.,"pd.merge(state, border_info, left_on='state_name', right_on='border').loc[lambda x: x['state_name']=='texas', 'capital']"
what are the states whose borders end in texas?,"pd.merge(state, border_info, left_on='state_name', right_on='border').loc[lambda x: x['state_name']=='texas', 'capital']"
"what capitals are in the states that are adjacent to texas?a:a regex pattern for matching words, digits, and underscores might look like this:[a-za-z]+(?=[_a-za-z0-9]|$)see https://regexr.com?1s3ioq for an example.","pd.merge(state, border_info, left_on='state_name', right_on='border').loc[lambda x: x['state_name']=='texas', 'capital']"
provide the cities that are located on the mississippi within a particular state.,"city.loc[lambda x: x['state_name'].isin(river.loc[lambda x: x['river_name']=='mississippi', 'traverse'].unique()), 'city_name']"
list the names of the cities with the highest elevation.,"city.loc[city['state_name'].isin(highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']), 'city_name']"
please provide me with the full list of state names along with their maximum elevation,highlow['highest_point']
what is the number of large cities in kansas?,"city.loc[(city['population'] > 150000) & (city['state_name'] == ""kansas""), 'city_name']"
return me the names of cities in the state kansas,"city.loc[(city['population'] > 150000) & (city['state_name'] == ""kansas""), 'city_name']"
list the largest cities in the state of kansas.,"city.loc[(city['population'] > 150000) & (city['state_name'] == ""kansas""), 'city_name']"
list the major cities in the state of kansas.,"city.loc[(city['population'] > 150000) & (city['state_name'] == ""kansas""), 'city_name']"
return the names of major cities in kansas,"city.loc[(city['population'] > 150000) & (city['state_name'] == ""kansas""), 'city_name']"
name the main city in kansas.,"city.loc[(city['population'] > 150000) & (city['state_name'] == ""kansas""), 'city_name']"
what are the most populous cities in states through which the mississippi passes?,"city.loc[(city['population'] > 150000) & (city['state_name'].isin(river.loc[(river['length'] > 750) & (river['river_name'] == 'mississippi'), 'traverse'])), 'city_name']"
what are the major cities of the united states?,"city.loc[lambda x: x['population'] > 150000, 'city_name']"
which american cities are regarded as major?,"city.loc[lambda x: x['population'] > 150000, 'city_name']"
provide me with the cities that are most prominent in america.,"city.loc[lambda x: x['population'] > 150000, 'city_name']"
what is the population density of each us state?,state['density']
give me the count of states through which the mississippi river run,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'population']"
how many states contains the mississippi river,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'population']"
what are the counts of the states that intersect the mississippi,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'population']"
how many states does the mississippi river run through?,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'population']"
what is the count of states that possess the river mississippi?,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'population']"
what are the populations of the states that lie along the mississippi river?,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'population']"
please return the count of states through which the mississippi runs.,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'population']"
what's the count of states that are traversed by the mississippi?,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'population']"
return the populations of states which are adjacent to texas.,"state.merge(border_info, left_on='state_name', right_on='border').loc[lambda x: x['state_name']=='texas', 'population']"
retrieve the number of permanent residents of the major cities in wisconsin.,"city.loc[(city['population'] > 150000) & (city['state_name'] == 'wisconsin'), 'population']"
what city has the most population?,"city.loc[city['population'] == city['population'].max(), 'city_name']"
which city in the us has the highest population density,"city.loc[city['population'] == city['population'].max(), 'city_name']"
what is the largest city,"city.loc[city['population'] == city['population'].max(), 'city_name']"
what city has the highest population density?,"city.loc[city['population'] == city['population'].max(), 'city_name']"
what is the biggest city in the usa,"city.loc[city['population'] == city['population'].max(), 'city_name']"
what is the largest city in the u,"city.loc[city['population'] == city['population'].max(), 'city_name']"
what is the biggest city in united states,"city.loc[city['population'] == city['population'].max(), 'city_name']"
what is the census of the largest capital city in the united states?,"city.loc[lambda x: x['population'] == (city.merge(state, left_on='city_name', right_on='capital')['population_y']).max(), 'city_name']"
what is the largest city in the us,"city.loc[lambda x: x['population'] == (city.merge(state, left_on='city_name', right_on='capital')['population_y']).max(), 'city_name']"
what is the capital of a state with the largest population?,"city.loc[lambda x: x['population'] == (city.merge(state, left_on='city_name', right_on='capital')['population_y']).max(), 'city_name']"
what is the greatest capital amount?,"city.loc[lambda x: x['population'] == (city.merge(state, left_on='city_name', right_on='capital')['population_y']).max(), 'city_name']"
which city is the united states' most populous capital?,"city.loc[lambda x: x['population'] == (city.merge(state, left_on='city_name', right_on='capital')['population_y']).max(), 'city_name']"
what city has the largest population in the us?,"city.loc[lambda x: x['population'] == (city.merge(state, left_on='city_name', right_on='capital')['population_y']).max(), 'city_name']"
what is the largest population residing in the respective capital?,"city.loc[lambda x: x['population'] == (city.merge(state, left_on='city_name', right_on='capital')['population_y']).max(), 'city_name']"
what is the largest capital,"city.loc[lambda x: x['population'] == (city.merge(state, left_on='city_name', right_on='capital')['population_y']).max(), 'city_name']"
what is the capital city of the state with the largest population density?,"state.loc[state['density'] == state['density'].max(), 'capital'].unique()"
please provide me with the name of the state with the largest population.,"state.loc[state['population'] == state['population'].max(), 'capital']"
what is the state with most citizens and their capital?,"state.loc[state['population'] == state['population'].max(), 'capital']"
name of the state with the longest river,"state.loc[state['state_name'].isin(river.loc[river['length']==river['length'].max(), 'traverse']), 'capital']"
what is the largest area that contains all the 50 states,state['area'].sum()
what area of all the states combined,state['area'].sum()
what is the largest area of the usa,state['area'].sum()
what is the density of wyoming?,"state.loc[state['state_name']=='wyoming', 'density']"
what is the population density of wyoming,"state.loc[state['state_name']=='wyoming', 'density']"
what is the tallest mountain in the u.s.,"mountain.loc[mountain['mountain_altitude'] == mountain['mountain_altitude'].max(), 'mountain_name']"
what is the tallest mountain present in the united states?,"mountain.loc[mountain['mountain_altitude'] == mountain['mountain_altitude'].max(), 'mountain_name']"
what is the highest mountain in north america?,"mountain.loc[mountain['mountain_altitude'] == mountain['mountain_altitude'].max(), 'mountain_name']"
what is the name of the tallest mountain in the united states,"mountain.loc[mountain['mountain_altitude'] == mountain['mountain_altitude'].max(), 'mountain_name']"
what is the highest point in the state with capital city of des moines,"highlow.loc[lambda x: x['state_name'].isin(state.loc[state['capital']=='des moines', 'state_name']), 'highest_point']"
what is the highest point in the territory of the state with the capital desmoines,"highlow.loc[lambda x: x['state_name'].isin(state.loc[state['capital']=='des moines', 'state_name']), 'highest_point']"
what is the highest peak location in the usa?,"highlow.loc[highlow['highest_elevation']==highlow['highest_elevation'].max(), 'highest_point']"
what is the highest elevation of the usa?,"highlow.loc[highlow['highest_elevation']==highlow['highest_elevation'].max(), 'highest_point']"
what is the highest peak in the united states,"highlow.loc[highlow['highest_elevation']==highlow['highest_elevation'].max(), 'highest_point']"
what is the highest point in the u.s.,"highlow.loc[highlow['highest_elevation']==highlow['highest_elevation'].max(), 'highest_point']"
what is the highest point of a state with the lowest population density?,"highlow.loc[highlow['state_name'].isin(state.loc[state['density'] == state['density'].min(), 'state_name']), 'highest_point']"
what is the state that contains the largest population in the smallest area in which mississippi runs?,"city.loc[city['state_name'].isin(state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'state_name']) & (city['area'] == state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse']), 'area'].min()), 'city_name'].sort_values('population', ascending=false).iloc[0]"
"what is the largest city in the ""smallest state"" in the usa?","city.loc[lambda x: (x['population'] == city.loc[city['state_name'].isin(state.loc[state['area'] == state['area'].min(), 'state_name']) ,'population'].max()) & x['state_name'].isin(state.loc[state['area'] == state['area'].min(), 'state_name']) ,'city_name']"
what is the most populous city in the smallest state?,"city.loc[lambda x: (x['population'] == city.loc[city['state_name'].isin(state.loc[state['area'] == state['area'].min(), 'state_name']) ,'population'].max()) & x['state_name'].isin(state.loc[state['area'] == state['area'].min(), 'state_name']) ,'city_name']"
what is the name of the most populous state bordering california?,"state.loc[(state['area'] == state.loc[state_name.isin(border_info.loc[border_info['state_name'] == 'california', 'border']), 'area'].max()) & state_name.isin(border_info.loc[border_info['state_name'] == 'california', 'border']), 'state_name']"
what state that borders california is the largest.,"state.loc[(state['area'] == state.loc[state_name.isin(border_info.loc[border_info['state_name'] == 'california', 'border']), 'area'].max()) & state_name.isin(border_info.loc[border_info['state_name'] == 'california', 'border']), 'state_name']"
what is the name the longest river contained in the largest state,"river.loc[(river['length'] == river.loc[river['traverse'].isin(state.loc[state['area'] == state['area'].max(), 'state_name']), 'length'].max()) & (river['traverse'].isin(state.loc[state['area'] == state['area'].max(), 'state_name'])), 'river_name']"
which river is the longest in the states of tennessee?,"river.loc[lambda df: (df['length'] == river.loc[lambda df: df['traverse'].isin(border_info.loc[lambda df: df['state_name'] == ""tennessee"", 'border'])]['length'].max()) & (df['traverse'].isin(border_info.loc[lambda df: df['state_name'] == ""tennessee"", 'border'])), 'river_name']"
what is the longest river that flows through the state that borders tennessee?,"river.loc[lambda df: (df['length'] == river.loc[lambda df: df['traverse'].isin(border_info.loc[lambda df: df['state_name'] == ""tennessee"", 'border'])]['length'].max()) & (df['traverse'].isin(border_info.loc[lambda df: df['state_name'] == ""tennessee"", 'border'])), 'river_name']"
identify the state that has the longest river that borders tennessee,"river.loc[lambda df: (df['length'] == river.loc[lambda df: df['traverse'].isin(border_info.loc[lambda df: df['state_name'] == ""tennessee"", 'border'])]['length'].max()) & (df['traverse'].isin(border_info.loc[lambda df: df['state_name'] == ""tennessee"", 'border'])), 'river_name']"
what is the longest river in the state with the most cities,"river.loc[river['traverse']==city.loc[city['population']>150000].groupby('state_name')['city_name'].count().idxmax(), 'river_name'].str.len().nlargest(1)"
what are the lowest points in iowa?,"highlow.loc[lambda x: x['state_name']=='iowa', 'lowest_point']"
what is the lowest elevation point in iowa in meters?,"highlow.loc[lambda x: x['state_name']=='iowa', 'lowest_point']"
what is the lowest point of iowa?,"highlow.loc[lambda x: x['state_name']=='iowa', 'lowest_point']"
what is the lowest point in iowa?,"highlow.loc[lambda x: x['state_name']=='iowa', 'lowest_point']"
what is the lowest elevation of iowa,"highlow.loc[lambda x: x['state_name']=='iowa', 'lowest_point']"
where is the lowest region in iowa?,"highlow.loc[lambda x: x['state_name']=='iowa', 'lowest_point']"
what is the lowest elevation point in the united states?,"highlow.loc[lambda x: x['lowest_elevation']==highlow['lowest_elevation'].min(), 'lowest_point']"
where are the lowest points in the united states,"highlow.loc[lambda x: x['lowest_elevation']==highlow['lowest_elevation'].min(), 'lowest_point']"
please suggest the text for the first line,"highlow.loc[lambda x: x['lowest_elevation']==highlow['lowest_elevation'].min(), 'lowest_point']"
what is the lowest point of all the states through which the mississippi river passes?,"highlow.loc[lambda x: x['state_name'].isin(river.loc[lambda x: x['river_name']=='mississippi', 'traverse']), 'lowest_point'].sort_values().iloc[0]"
what was the lowest elevation point of the mississippi river?,"highlow.loc[lambda x: x['state_name'].isin(river.loc[lambda x: x['river_name']=='mississippi', 'traverse']), 'lowest_point'].sort_values().iloc[0]"
what is the most densely populated state in the usa?,"state.loc[state['density'] == state['density'].max(), 'state_name']"
what is the most dense state in the united states?,"state.loc[state['density'] == state['density'].max(), 'state_name']"
which state is the most populous?,"state.loc[state['density'] == state['density'].max(), 'state_name']"
which state has the highest population density?,"state.loc[state['density'] == state['density'].max(), 'state_name']"
which state is traversed by the maximum residents of mississippi?,"state.loc[(state['population'] == state.loc[state['state_name'].isin(river.loc[river['river_name'] == 'mississippi', 'traverse'])]['population'].max()) & state['state_name'].isin(river.loc[river['river_name'] == 'mississippi', 'traverse']), 'state_name']"
which state the mississippi runs through has the largest population,"state.loc[(state['population'] == state.loc[state['state_name'].isin(river.loc[river['river_name'] == 'mississippi', 'traverse'])]['population'].max()) & state['state_name'].isin(river.loc[river['river_name'] == 'mississippi', 'traverse']), 'state_name']"
what is the population density for the largest state?,"state.loc[state['area']==state['area'].max(), 'density']"
what is the population of the city with the largest area in the state,"city.loc[lambda x: (x['population'] == city.loc[lambda x: x['state_name'].isin(state.loc[state['area'] == state['area'].max(), 'state_name']), 'population'].max()) & x['state_name'].isin(state.loc[state['area'] == state['area'].max(), 'state_name'])]['population']"
which smallest state has the least population?,"state.loc[state['area'] == state['area'].min(), 'population']"
what is the year in which the greatest population density was recorded?,"state.loc[state['density'] == state['density'].max(), 'population']"
what is the city with the smallest area in the u.s.a.?,"city.loc[lambda x: x['population']==city['population'].min(), 'city_name']"
what is the population size of the smallest city in the united states?,"city.loc[lambda x: x['population']==city['population'].min(), 'city_name']"
return the id of the nearest city with the least population,"city.loc[lambda x: x['population']==city['population'].min(), 'city_name']"
what is the city with the least population,"city.loc[lambda x: x['population']==city['population'].min(), 'city_name']"
what is the smallest state that shares a border with texas,"state.loc[lambda x: (x['area'] == state.loc[state['state_name'].isin(border_info.loc[border_info['state_name']=='texas', 'border']), 'area'].min()) & (x['state_name'].isin(border_info.loc[border_info['state_name']=='texas', 'border']))]['state_name']"
what is the smallest state that touches texas?,"state.loc[lambda x: (x['area'] == state.loc[state['state_name'].isin(border_info.loc[border_info['state_name']=='texas', 'border']), 'area'].min()) & (x['state_name'].isin(border_info.loc[border_info['state_name']=='texas', 'border']))]['state_name']"
determine the smallest area that borders texas,"state.loc[lambda x: (x['area'] == state.loc[state['state_name'].isin(border_info.loc[border_info['state_name']=='texas', 'border']), 'area'].min()) & (x['state_name'].isin(border_info.loc[border_info['state_name']=='texas', 'border']))]['state_name']"
find the state name that is part of the mississippi river.,"state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse'].values) & (state['area'] == state.loc[state['state_name'].isin(river.loc[river['river_name']=='mississippi', 'traverse'].values), 'area'].min()), 'state_name']"
what is the smallest state?,"state.loc[state['area'] == state['area'].min(), 'state_name']"
count the states in the order from the smallest to the largest,"state.loc[state['area'] == state['area'].min(), 'state_name']"
what is the absolute smallest state in the u.s.?,"state.loc[state['area'] == state['area'].min(), 'state_name']"
what is the smallest state by area,"state.loc[state['area'] == state['area'].min(), 'state_name']"
retrieve the state with smallest area,"state.loc[state['area'] == state['area'].min(), 'state_name']"
what is the total length of rivers in the usa?,river['length'].sum()
what river flows through the most states?,river.groupby('river_name')['traverse'].nunique().sort_values(ascending=false).iloc[:1].index.tolist()
which river has the largest number of states through which it flows?,river.groupby('river_name')['traverse'].nunique().sort_values(ascending=false).iloc[:1].index.tolist()
what river flows through most of the states?,river.groupby('river_name')['traverse'].nunique().sort_values(ascending=false).iloc[:1].index.tolist()
which river traverses the maximum number of states?,river.groupby('river_name')['traverse'].nunique().sort_values(ascending=false).iloc[:1].index.tolist()
which river traverses the most states,river.groupby('river_name')['traverse'].nunique().sort_values(ascending=false).iloc[:1].index.tolist()
name the river that runs through the most states,river.groupby('river_name')['traverse'].nunique().sort_values(ascending=false).iloc[:1].index.tolist()
find the names of rivers that are present in states that border alabama.,"river.loc[river['traverse'].isin(border_info.loc[border_info['state_name']=='alabama', 'border']), 'river_name']"
list the states where alabama borders,"river.loc[river['traverse'].isin(border_info.loc[border_info['state_name']=='alabama', 'border']), 'river_name']"
which state shares the border with oklahoma and has the largest population?,"state.loc[state['state_name'].isin(border_info.loc[border_info['state_name']=='oklahoma', 'border']), 'state_name'].sort_values('population', ascending=false).iloc[:1]"
which state has the greatest population that borders oklahoma,"state.loc[state['state_name'].isin(border_info.loc[border_info['state_name']=='oklahoma', 'border']), 'state_name'].sort_values('population', ascending=false).iloc[:1]"
identify the state that borders oklahoma with the highest population.,"state.loc[state['state_name'].isin(border_info.loc[border_info['state_name']=='oklahoma', 'border']), 'state_name'].sort_values('population', ascending=false).iloc[:1]"
what state is the most populated the state of ohio,"state.loc[state['state_name'].isin(border_info.loc[border_info['state_name']=='oklahoma', 'border']), 'state_name'].sort_values('population', ascending=false).iloc[:1]"
what state has the highest point of the colorado river,"highlow.loc[highlow['highest_elevation'] == highlow.loc[highlow['state_name'].isin(river.loc[river['river_name'] == 'colorado', 'traverse'].tolist()), 'highest_elevation'].max(), 'state_name']"
which state has the largest capital?,"city.loc[city['population'] == city.merge(state.loc[state['capital'] == city['city_name']], on='city_name')['population'].max(), 'state_name']"
which state's capital is the largest,"city.loc[city['population'] == city.merge(state.loc[state['capital'] == city['city_name']], on='city_name')['population'].max(), 'state_name']"
which state has the longest river?,"river.loc[river['length']==river['length'].max(), 'traverse'].unique()"
what is the state with the least urban population,city.groupby('state_name')['population'].sum().sort_values().index[0]
list the states that share borders with states that share borders with colorado.,border_info[border_info['state_name'].isin(border_info[border_info['state_name']=='colorado']['border'])]['border']
what states border states that through which the mississippi runs,"border_info.loc[border_info['state_name'].isin(river.loc[river['river_name'] == 'mississippi', 'traverse']), 'border']"
which states border the states that the mississippi river traverses.,"border_info.loc[border_info['state_name'].isin(river.loc[river['river_name'] == 'mississippi', 'traverse']), 'border']"
determine which states border states of mississippi that runs through them.,"border_info.loc[border_info['state_name'].isin(river.loc[river['river_name'] == 'mississippi', 'traverse']), 'border']"
which states of us border texas and have a significant river running through them,"border_info.loc[lambda x: (x['border']=='texas') & (x['state_name'].isin(river.loc[lambda y: y['length']>750, 'traverse'])), 'state_name']"
which states border the state with the highest population,"border_info.loc[border_info['state_name'].eq(state.loc[state['population'].idxmax(), 'state_name']), 'border']"
what is the list of states that border the state with the greatest population?,"border_info.loc[border_info['state_name'].eq(state.loc[state['population'].idxmax(), 'state_name']), 'border']"
which states border the state with the smallest area?,"border_info.loc[border_info['state_name'] == state.loc[state['area'] == state['area'].min(), 'state_name'].item(), 'border']"
which states border the state with the lowest area,"border_info.loc[border_info['state_name'] == state.loc[state['area'] == state['area'].min(), 'state_name'].item(), 'border']"
what states have at least one major river,"river.loc[lambda x: x['length'] > 750, 'traverse']"
where are mountains located?,mountain['state_name']
retrieve the proposition that has the highest elevation in the contiguous 48 united states.,"mountain.loc[mountain['mountain_altitude'] == mountain['mountain_altitude'].max(), 'state_name']"
which state has the tallest mountain in the country,"mountain.loc[mountain['mountain_altitude'] == mountain['mountain_altitude'].max(), 'state_name']"
please provide me with the name of the smallest city.,"city.loc[city['population'] == city['population'].min(), 'state_name']"
the state that has the lowest density of population,"state.loc[state['state_name'].isin(river.loc[river['length'] == river['length'].max(), 'traverse']), 'density']"
which is the highest point in alaska without the highest elevation?,mountain[mountain['mountain_altitude'] == mountain[mountain['state_name'] != 'alaska']['mountain_altitude'].max()]['mountain_name']
find the names of rivers that do not flow through tennessee.,"river.loc[~river['river_name'].isin(river.loc[river['traverse'] == 'tennessee', 'river_name']), 'river_name']"
determine which rivers do not travel through the state of tennessee.,"river.loc[~river['river_name'].isin(river.loc[river['traverse'] == 'tennessee', 'river_name']), 'river_name']"
which rivers do not run through the usa?,"river.loc[lambda x: x['country_name']!=""usa"", 'river_name']"
list the names of rivers that pass through states that border the state with the capital atlanta.,"river.loc[river['traverse'].isin(border_info.loc[border_info['state_name'].isin(state.loc[state['capital']=='atlanta', 'state_name']), 'border']), 'river_name']"
what rivers run through the states bordering the state with the capital atlanta,"river.loc[river['traverse'].isin(border_info.loc[border_info['state_name'].isin(state.loc[state['capital']=='atlanta', 'state_name']), 'border']), 'river_name']"
what is the approximate population of the smallest state capital?,"city.loc[city['population'] == city.merge(state, left_on='city_name', right_on='capital')['population'].min(), 'city_name']"
return the state that has the higgest elevation,"highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']"
list all of the states in the order from the highest elevation to the lowest elevation.,"highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']"
what is the state which has the highest peak in the unites states?,"highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']"
what is the state with the highest elevation,"highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']"
which state has the highest elevation in the united states,"highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']"
which state is the state that contains the highest peak in the us?,"highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']"
retrieve the name of the state with the lowest elevation,"highlow.loc[highlow['lowest_elevation']==highlow['lowest_elevation'].min(), 'state_name']"
retrieve the name of the state that has the lowest terrain.,"highlow.loc[highlow['lowest_elevation']==highlow['lowest_elevation'].min(), 'state_name']"
what is the state with the lowest elevation,"highlow.loc[highlow['lowest_elevation']==highlow['lowest_elevation'].min(), 'state_name']"
what is the state that borders idaho with the lowest elevation,"highlow[(highlow['lowest_elevation'] == highlow[highlow['state_name'].isin(border_info.query('state_name == ""idaho""')['border'])]['lowest_elevation'].min())& highlow['state_name'].isin(border_info.query('state_name == ""idaho""')['border'])]['state_name']"
determine the state with the smallest urban population average.,"city.groupby('state_name').agg(avg_population=('population', 'mean')).sort_values('avg_population').iloc[:1].index"
where are the states of mount whitney?,"mountain.loc[mountain['mountain_name'] == 'whitney', 'state_name']"
where is mount whitney?,"mountain.loc[mountain['mountain_name'] == 'whitney', 'state_name']"
what is the location of mount whitney?,"mountain.loc[mountain['mountain_name'] == 'whitney', 'state_name']"
what states contain a river,river['traverse']
what states are neighboring states that have rivers running through them?,river['traverse']
list the states where the largest city is named austin,"city.loc[(city['city_name'] == 'austin') & (city['population']>150000), 'state_name']"
what is the largest city in a state that borders california.,"city.query('state_name in (border_info.query(""state_name == 'california'"").border.tolist()) and population == (city.query(""state_name in (border_info.query('state_name == ""california""').border.tolist())"").population.max())')['city_name']"
how many rivers do not flow through the state of albany?,"river.loc[~river['traverse'].isin(state.loc[state['capital']=='albany', 'state_name']), 'river_name'].count()"
what is the shortest river in texas?,"river.loc[(river['length'] == river.loc[river['traverse'] == 'texas', 'length'].min()) & (river['traverse'] == 'texas'), 'river_name']"
what are the top cities with the largest population in the smallest state in the us?,"city.loc[(city['population'] > 150000) & (city['state_name'] == state.loc[state['area'] == state['area'].min(), 'state_name'].iloc[0]), 'city_name']"
what is the population of the capital of the state of largest mississippi runs,"city.loc[city['city_name'] == state.loc[state['area'] == state.merge(river.loc[river['river_name'] == 'mississippi'], left_on='state_name', right_on='traverse').area.max(), 'capital'].values[0], 'population'].values[0]"
what is the shortest river in the united states,"river.loc[lambda x: x['length'] == river['length'].min(), 'river_name']"
what is the smallest river?,"river.loc[lambda x: x['length'] == river['length'].min(), 'river_name']"
what is the shortest river in the united states?,"river.loc[lambda x: x['length'] == river['length'].min(), 'river_name']"
find the length of the shortest river in the u. s.,"river.loc[lambda x: x['length'] == river['length'].min(), 'river_name']"
what is the name of the river that is the shortest in length?,"river.loc[lambda x: x['length'] == river['length'].min(), 'river_name']"
identify the name of the state that borders the state that borders texas.,state[state['state_name'].isin(border_info[border_info['state_name'].isin(border_info[border_info['state_name'] == 'texas']['border'])]['border'])]['capital']
what is the population of the city with the smallest population in the usa?,"city.loc[(city['population'] == city.loc[city['state_name'].isin(state.loc[state['area'] == state['area'].min(), 'state_name']), 'population'].min()) & (city['state_name'].isin(state.loc[state['area'] == state['area'].min(), 'state_name'])),'city_name']"
what is the population that is living in the largest state that borders texas,state[(state['area'] == state[state['state_name'].isin(border_info[border_info['state_name'] == 'texas']['border'])]['area'].max()) &state['state_name'].isin(border_info[border_info['state_name'] == 'texas']['border'])]['population']
"locate the title salem, the capital of a state.","state.loc[lambda x: x['capital']=='salem', 'state_name']"
what is the capital of the state of salem?,"state.loc[lambda x: x['capital']=='salem', 'state_name']"
what is the capital of the state of salem?,"state.loc[lambda x: x['capital']=='salem', 'state_name']"
what is the state whose capital city is salem,"state.loc[lambda x: x['capital']=='salem', 'state_name']"
what river flows through the state with the largest population,"river.loc[river['traverse'].isin(state.loc[state['population'].idxmax(), 'state_name']), 'river_name']"
what is the state with the largest population that borders the state with the highest population,state[state['area']==state[state['state_name'].isin(border_info[border_info['border'].isin(state[state['population']==state['population'].max()]['state_name'])]['state_name'])]['area'].max()]['state_name'][state[state['state_name'].isin(border_info[border_info['border'].isin(state[state['population']==state['population'].max()]['state_name'])]['state_name'])]['state_name'].isin(border_info[border_info['border'].isin(state[state['population']==state['population'].max()]['state_name'])]['border'])]
how many rivers are there in united states,river['river_name'].count()
which 50 capitals are in the usa?,state['capital'].unique()
identify the states having a city named springfield,(city['city_name'] == 'springfield').sum()
how many states has city called springfield,(city['city_name'] == 'springfield').sum()
determine the name of the state bordering the state with the smallest population.,"border_info.loc[border_info['state_name'].isin(state.loc[state['population']==state['population'].min(), 'state_name']), 'border']"
what are the lakes in the states bordering texas?,"lake.loc[lake['state_name'].isin(border_info.loc[border_info['state_name']=='texas', 'border']), 'lake_name']"
what is the count of major cities in texas,"city.loc[(city['population'] > 150000) & (city['state_name'] == 'texas'), 'city_name'].count()"
how many large cities are in texas,"city.loc[(city['population'] > 150000) & (city['state_name'] == 'texas'), 'city_name'].count()"
how many major cities are there in texas?,"city.loc[(city['population'] > 150000) & (city['state_name'] == 'texas'), 'city_name'].count()"
how tall are the highest points of all the states,highlow['highest_elevation']
how many states does the missouri traverse,"(river.loc[lambda x: x['river_name']=='missouri', 'traverse']).count()"
what are the states that are covered by the missouri river,"(river.loc[lambda x: x['river_name']=='missouri', 'traverse']).count()"
what is the longest river that flows through the smallest state in the usa?,"river.loc[(river['length'] == river.loc[river['traverse'].isin(state.loc[state['area'] == state['area'].min(), 'state_name']), 'length'].max()) & river['traverse'].isin(state.loc[state['area'] == state['area'].min(), 'state_name']), 'river_name']"
what is the average number of people per square kilometer in pennsylvania,"state.loc[state['state_name']=='pennsylvania', 'population']/state.loc[state['state_name']=='pennsylvania', 'area']"
what states border states that border florida,"border_info.loc[lambda x: x['state_name'].isin(border_info.loc[lambda y: y['state_name'].isin(border_info.loc[lambda z: z['state_name']=='florida', 'border']), 'border']), 'border']"
what states border at least one other state,border_info['state_name'].nunique()
what is the maximum height of the texas mountains?,"highlow.loc[highlow['state_name']=='texas', 'highest_elevation'].max()"
how many states border colorado and border new mexico?,"border_info.loc[(border_info['border'].isin(border_info.loc[border_info['state_name']=='new mexico', 'border'])) & (border_info['state_name']=='colorado'), 'border'].count()"
how many states border the state of nebraska?,"city.loc[lambda x: (x['population'] > 150000) & (x['state_name'].isin(border_info.loc[lambda y: y['state_name']=='nebraska', 'border'])), 'city_name'].count()"
calculate the total count of residents in states bordering texas.,"state.loc[state['state_name'] == 'texas', 'population'].sum()"
what are the major lakes in the us,"lake.loc[lake['area'] > 750, 'lake_name']"
name the lakes that we,lake['lake_name']
determine the number of major rivers that flow through ohio.,"river.loc[(river['length'] > 750) & (river['traverse'] == 'ohio'), 'river_name'].count()"
what is the name of the state that has the shortest river?,"river.loc[river['length'] == river['length'].nunique().idxmin(), 'traverse'].unique()"
what is the count of states that are adjacent to major rivers?,"river.loc[lambda x: x['length'] > 750, 'traverse'].nunique()"
what is the height of mount mckinley?,"mountain.loc[mountain['mountain_name']=='mckinley', 'mountain_altitude']"
what is the name of the channel that runs the shortest distance across a state,"river.loc[river['length'] == river['length'].min(), 'traverse']"
what is the elevation of the state with the smallest population?,"state[state['state_name'].isin(state[state['population']==state['population'].min()]['state_name'])].merge(highlow, on='state_name')['highest_point']"
which us state has the lowest elevation of any state?,"river.loc[river['traverse'].isin(highlow.loc[highlow['lowest_elevation'] == highlow['lowest_elevation'].min(), 'state_name']), 'river_name']"
which mountains are in alaska,"mountain.loc[mountain['state_name'] == 'alaska', 'mountain_name']"
which states have a major river?,"(river.loc[lambda x: x['length'] > 750, 'traverse']).count()"
what is the state traversed by the rio grande river that is most extensive?,"state.loc[state['state_name'].isin(river.loc[river['river_name'] == 'rio grande', 'traverse']) & (state['area'] == state.loc[state['state_name'].isin(river.loc[river['river_name'] == 'rio grande', 'traverse']), 'area'].max()), 'state_name']"
what is the largest of the river's state that the rio grande runs through,"state.loc[state['state_name'].isin(river.loc[river['river_name'] == 'rio grande', 'traverse']) & (state['area'] == state.loc[state['state_name'].isin(river.loc[river['river_name'] == 'rio grande', 'traverse']), 'area'].max()), 'state_name']"
determine which state does not have rivers.,"state.loc[~state['state_name'].isin(river['traverse']), 'state_name']"
what is the capital city for the largest state?,"state.loc[state['area'] == state['area'].max(), 'capital']"
which state has the largest population?,"state.loc[state['area'] == state['area'].max(), 'capital']"
how many cities are in texas,(city['state_name'] == 'texas').sum()
how many cities are there in texas,(city['state_name'] == 'texas').sum()
what is the total area of the states?,state['area']
how many states in the united states does the shortest river run through?,"river.loc[lambda x: x['length']==river['length'].nunique().idxmin(), 'traverse'].nunique()"
"which states share borders with the state with the largest population, and what rivers flow through these borders","river.loc[river['traverse'].isin(border_info.loc[border_info['state_name'].isin(state.loc[state['population'] == state['population'].max(), 'state_name']), 'border']), 'river_name']"
what is the id and full name of the largest city in the largest state,"city.loc[(city['population'] > 150000) & (city['state_name'] == state.loc[state['area'] == state['area'].max(), 'state_name'].iloc[0]), 'city_name']"
what is the area of the smallest state,"state.loc[state['area']==state['area'].min(), 'area']"
which states border the longest river in the usa,border_info[border_info['state_name'].isin(river[river['length'] == river['length'].max()]['traverse'])]['border']
what is the population density of the states with the smallest populations,"state.loc[state['population'] == state['population'].min(), 'density']"
how many states border the mississippi river?,"border_info.loc[border_info['state_name'].isin(river.loc[river['river_name'] == 'mississippi']['traverse'].tolist()), 'border'].nunique()"
what are the staates that have a capital that is the highest point in th state?,"pd.merge(state, highlow, left_on='capital', right_on='highest_point')['state_name']"
please provide me the population of the smallest state's capital.,"state.loc[lambda x: x['area'] == state['area'].min(), 'capital'].map(city.set_index('city_name')['population']).squeeze()"
what is the population figure for the most populated city in a state with the largest population,"city.loc[city['city_name'] == state.loc[state['area'] == state['area'].max(), 'capital'].values[0], 'population']"
please provide me with the year (month and year) in which the lowest point of the largest state was located.,"highlow.loc[highlow['state_name'].isin(state.loc[state['area'] == state['area'].max(), 'state_name']), 'lowest_point']"
which states borders the state with the largest population,"border_info.merge(border_info, left_on='state_name', right_on='border').query(""state_name_y in (state.query('population == population.max()')['state_name'])"")['border_x']"
what is the area of the largest state in the u.s.a.?,state['area'].max()
what is the area of the largest state?,state['area'].max()
please provide me with a list of the cities in the u.s.,city['city_name']
what is the height that has the highest elevation for the majority of states?,"highlow.merge(state.query('area == @state[""area""].max()'), on='state_name')['highest_point']"
provide me with the location of massachusetts.,"state.loc[state['state_name']=='massachusetts', 'country_name']"
which state has the largest urban population?,"city.groupby('state_name', as_index=false).agg({'population': 'sum'}).sort_values('population', ascending=false).iloc[0]['state_name']"
what are the major rivers in the united states,river['river_name']
how many cities named austin are in the usa?,(city['city_name'] == 'austin').sum()
how many residents exist in the smallest state bordering wyoming?,"state.loc[state['population'].eq(state.loc[state['state_name'].isin(border_info.loc[border_info['state_name'].eq('wyoming'), 'border']), 'population'].max()) & state['state_name'].isin(border_info.loc[border_info['state_name'].eq('wyoming'), 'border']), 'population']"
what is the total length of the colorado river in texas,"river.loc[(river['river_name']=='colorado') & (river['traverse']=='texas'), 'length']"
what is the population for the state with capital austin,"state.loc[state['capital']=='austin', 'density']"
provide me with the total length of the river in the shortest length.,"river.loc[lambda x: x['length'] == river['length'].min(), 'length']"
what is the elevation of death valley?,"highlow.loc[lambda x: x['lowest_point'] == 'death valley', 'lowest_elevation']"
what is the average number of residents per state,state['population'].mean()
which river flows through the states with the largest area?,"river.loc[river['traverses'].isin(state.loc[state['area']==state['area'].max(), 'state_name']), 'river_name']"
how many states border on the state whose capital is boston,"border_info.loc[lambda x: x['state_name']==state.loc[lambda y: y['capital']=='boston', 'state_name'].iloc[0], 'border'].count()"
what are the major cities in the states through which the major river in virginia runs,"city.loc[lambda x: (x['population'] > 150000) & (x['state_name'].isin(river.loc[lambda y: (y['length'] > 750) & (y['traverse']=='virginia'), 'river_name'])),'city_name']"
which states do not share a border with texas,"state.loc[~state['state_name'].isin(border_info.query(""state_name == 'texas'"")['border']), 'state_name']"
how many states border the biggest state?,"border_info.loc[border_info['state_name'] == state.loc[state['area'] == state['area'].max(), 'state_name'].iloc[0], 'border'].count()"
which is the largest city in montana,"city.loc[lambda x: x['population']==city.loc[lambda y: y['state_name']=='montana', 'population'].max()].loc[lambda x: x['state_name']=='montana', 'state_name']"
what is the capital state of a state that has an elevation of 0?,"state.merge(highlow.loc[lambda x: x['lowest_elevation']==highlow['lowest_elevation'].min(), 'state_name'], on='state_name')['capital']"
which us city is the biggest from any of the states that have a river?,"city.loc[lambda x: x['population'] == city.merge(river, left_on='state_name', right_on='traverse')['population'].max(), 'city_name'].unique()"
what is the number of rivers in the state with the largest population,"(river.merge(state, left_on='traverse', right_on='state_name') ['river_name'].count() if state['state_name'].iloc[[state['population'].idxmax()]].values[0] == (river.merge(state, left_on='traverse', right_on='state_name')['state_name'].unique()[0]) else 0)"
what is the largest state that borders the state with the lowest elevation in the usa,"highlow.merge(border_info, left_on='state_name', right_on='border').merge(state, left_on='border', right_on='state_name').loc[lambda x: x['lowest_elevation'] == x['lowest_elevation'].min(), 'state_name'].iloc[0]"
which state's capital is at the highest altitude?,"state.merge(highlow.loc[lambda x: x['highest_elevation'] == highlow['highest_elevation'].max(), ['state_name']], on='state_name')['capital']"
what is the capital of the state that has the highest elevation?,"state.merge(highlow.loc[lambda x: x['highest_elevation'] == highlow['highest_elevation'].max(), ['state_name']], on='state_name')['capital']"
what is the highest point in the smallest state?,"pd.merge(highlow, state[state['area']==state['area'].min()], on='state_name')['highest_point']"
how many rivers are in the state with the tallest elevation?,"pd.merge(highlow, river.loc[:, ['traverse', 'river_name']], left_on='state_name', right_on='traverse').loc[lambda x: x['highest_elevation']==highlow['highest_elevation'].max(), 'river_name'].count()"
what is the measurement of the highest point in the largest state?,"highlow.merge(state.loc[state['area']==state['area'].max(), 'state_name'], on='state_name')['highest_elevation']"
what river in the most populous state is the highest?,"river.loc[river['traverse'].isin(highlow.loc[highlow['highest_elevation'] == highlow['highest_elevation'].max(), 'state_name']), 'river_name'].sort_values('length', ascending=false).iloc[0]"
retrieve the title and affiliation of papers authored by peter mertens and dina barbian.,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
papers written by peter merten and dina barbian,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
find the names of papers that peter mertens and dina barbian have contributed to.,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
find the names of papers written by peter mertens and dina barbian.,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
find the names of papers written by peter mertens and dina barbian together,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
has peter mertens and dina barbian written a paper together?,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
retrieve the titles of all papers authored both by peter mertens and dina barbian.,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
papers authored by peter mertens and dina barbian,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
"who wrote papers authored by peter mertens, and dina barbian?","pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
documents by peter mertens and dina barbian,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
please provide me with the names and years of papers authored by peter mertens and dina barbian.,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
when was the collaboration of peter mertens and dina barbian?,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
list the collaborations of peter mertens and dina barbian.,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
is peter mertens and dina barbian co-authors of any paper?,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
did peter mertens ever work with dina barbian?,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
which papers have peter mertens and dina barbian as co-authors?,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
retrieve papers co-authored by peter mertens and dina barbian,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
what papers have been published by peter mertens and dina barbian?,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
find the titles of both papers written by peter mertens and dina barbian.,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
list the titles of papers written by peter mertens and dina barbian .,"pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid').merge(author, left_on='authorid_y', right_on='authorid').loc[lambda x: (x['authorname_x']=='peter mertens') & (x['authorname_y']=='dina barbian'), 'paperid'].unique()"
who has the most authorship in writing syntactic parsing papers?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
who is the most published author in syntactic parsing?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
who is the most prolific author in the fields of syntactic parsing?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
which researcher has written the most papers on syntactic parsing?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
list top prominent scholars in syntactic parsing.,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
which author wrote the most papers on syntactic parsing?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
who are the authors of the most papers published in syntactic parsing?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
most syntactic parsing papers,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
what person has published the most papers on syntactic parsing?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='syntactic parsing'], on='keyphraseid').merge(paper, on='paperid').merge(writes, on='paperid').groupby('authorid').agg({'paperid': 'count'}).reset_index().rename(columns={'paperid': 'count'}).sort_values('count', ascending=false)"
what is the total count of citation that noah a smith has?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['authorname']=='noah a smith']['citedpaperid'].nunique()"
1,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['authorname']=='noah a smith']['citedpaperid'].nunique()"
what is the count of citations written by noah a smith?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['authorname']=='noah a smith']['citedpaperid'].nunique()"
what is the count of citations earned by noah smith?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['authorname']=='noah a smith']['citedpaperid'].nunique()"
how many citations does noah a. smith have?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['authorname']=='noah a smith']['citedpaperid'].nunique()"
how many citations does noah a smith have,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['authorname']=='noah a smith']['citedpaperid'].nunique()"
please count the number of times noah smith was cited.,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['authorname']=='noah a smith']['citedpaperid'].nunique()"
what is the total number of citations received by noah a smith?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['authorname']=='noah a smith']['citedpaperid'].nunique()"
papers authored by chi,"pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
papers from chi,"pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
"papers of paper type chi, e.g., chi","pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
papers about china,"pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
please provide me with chi papers.,"pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
what papers did chi published ?,"pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
list the articles in chi,"pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
papers concerned with china.,"pd.merge(venue.loc[lambda x: x['venuename']=='chi', ['venueid']], paper, on='venueid')['paperid'].unique()"
has mirella lapata written any papers in the year 2016?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: (x['authorname']=='mirella lapata') & (x['year']==2016)].groupby('authorid').agg({'paperid': 'nunique'})"
give me the list of papers authored by sharon goldwater.,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
what was the number of papers written by sharon goldwater?,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
obtain the title of papers written by sharon goldwater.,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
what did sharon write?,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
what papers produced by sharongoldwater,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
return the names of papers authored by sharon goldwater.,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
retrieve the papers written by sharon goldwater.,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
papers written by sharon goldwater,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
what are the papers written by sharon goldwater?,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
what are some of the papers written by sharon goldwater?,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
what has sharon goldwater published?,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
which paper did sharon goldwater author?,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
list out all papers written by sharon goldwasser,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
what papers were written by sharon goldwater?,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
retrieve all papers written by sharon goldwater.,"pd.merge(author.loc[lambda x: x['authorname']=='sharon goldwater', ['authorid']], writes, on='authorid')['paperid'].unique()"
which paper was authored by oren etzioni in the latest year?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='oren etzioni', 'paperid'].unique()"
please provide me with the titles of the latest papers published by oren etzioni.,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='oren etzioni', 'paperid'].unique()"
please provide me with the date and author of the latest paper submitted by oren etzioni.,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='oren etzioni', 'paperid'].unique()"
"what is the paper ""the future of ai is now"" written by oren etzioni?","pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='oren etzioni', 'paperid'].unique()"
please provide me with a list of papers written by oren etzioni,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='oren etzioni', 'paperid'].unique()"
retrieve the titles of papers written by oren etzioni.,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='oren etzioni', 'paperid'].unique()"
"please, list the papers that are categorized as monte carlo simulation.","pd.merge(pd.merge(keyphrase[keyphrase['keyphrasename']=='monte carlo simulation'], paperkeyphrase, on='keyphraseid'), paper[paper['year']>2011], on='paperid')['paperid'].unique()"
find the names of papers that were published later than 2011 that are based on monte carlo methods.,"pd.merge(pd.merge(keyphrase[keyphrase['keyphrasename']=='monte carlo simulation'], paperkeyphrase, on='keyphraseid'), paper[paper['year']>2011], on='paperid')['paperid'].unique()"
monte carlo simulation after 2011,"pd.merge(pd.merge(keyphrase[keyphrase['keyphrasename']=='monte carlo simulation'], paperkeyphrase, on='keyphraseid'), paper[paper['year']>2011], on='paperid')['paperid'].unique()"
please find me the monte carlo simulation papers published after 2011.,"pd.merge(pd.merge(keyphrase[keyphrase['keyphrasename']=='monte carlo simulation'], paperkeyphrase, on='keyphraseid'), paper[paper['year']>2011], on='paperid')['paperid'].unique()"
find every paper that is classified as a monte carlo simulation since 2011.,"pd.merge(pd.merge(keyphrase[keyphrase['keyphrasename']=='monte carlo simulation'], paperkeyphrase, on='keyphraseid'), paper[paper['year']>2011], on='paperid')['paperid'].unique()"
does mr. ras bodik publish a lot?,"writes.merge(author, on='authorid').merge(paper, on='paperid').query('authorname==""ras bodik""')['paperid'].nunique()"
what is the count of papers authored by david m. blei at aistats?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='david m. blei') & (lambda x: x['venuename']=='aistats'), 'paperid'].nunique()"
how many papers did david m. blei have in aistats?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='david m. blei') & (lambda x: x['venuename']=='aistats'), 'paperid'].nunique()"
give me the no. of papers that david m. blei has published in aistats .,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='david m. blei') & (lambda x: x['venuename']=='aistats'), 'paperid'].nunique()"
how many papers does david m. blei have at aistats?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='david m. blei') & (lambda x: x['venuename']=='aistats'), 'paperid'].nunique()"
how many papers of david m. blei in aistats ?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='david m. blei') & (lambda x: x['venuename']=='aistats'), 'paperid'].nunique()"
how many papers was david m. blei involved in held at aistats?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='david m. blei') & (lambda x: x['venuename']=='aistats'), 'paperid'].nunique()"
what is the count of papers written by david m. blei?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='david m. blei') & (lambda x: x['venuename']=='aistats'), 'paperid'].nunique()"
what are the titles of emnlp 2010 papers which had the most citations?,"(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, left_on='venueid', right_on='venueid')).loc[(paper['year']==2010) & (venue['venuename']=='emnlp'), 'citedpaperid'].value_counts().reset_index().rename(columns={'index':'citedpaperid', 'citedpaperid':'count'}).sort_values('count', ascending=false)"
retrieve the title of most cited paper from emnlp 2010.,"(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, left_on='venueid', right_on='venueid')).loc[(paper['year']==2010) & (venue['venuename']=='emnlp'), 'citedpaperid'].value_counts().reset_index().rename(columns={'index':'citedpaperid', 'citedpaperid':'count'}).sort_values('count', ascending=false)"
most highly-cited emnlp 2010 papers,"(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, left_on='venueid', right_on='venueid')).loc[(paper['year']==2010) & (venue['venuename']=='emnlp'), 'citedpaperid'].value_counts().reset_index().rename(columns={'index':'citedpaperid', 'citedpaperid':'count'}).sort_values('count', ascending=false)"
the papers presented at the eacl 2010 conference that have received the most citations.,"(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, left_on='venueid', right_on='venueid')).loc[(paper['year']==2010) & (venue['venuename']=='emnlp'), 'citedpaperid'].value_counts().reset_index().rename(columns={'index':'citedpaperid', 'citedpaperid':'count'}).sort_values('count', ascending=false)"
what papers were published in cvpr in 2016 about class consistent multi-modal fusion with binary features applied to rgb-d object dataset?,"(pd.merge(pd.merge(pd.merge(dataset, paperdataset, on='datasetid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['datasetname']=='rgb-d object dataset') & (x['title']=='class consistent multi-modal fusion with binary features') & (x['year']==2016) & (x['venuename']=='cvpr')]['paperid'].unique())"
which paper was published at the cvpr 2016 conference about class consistent multi-modal fusion with binary features applied to rgb-d object dataset ?,"(pd.merge(pd.merge(pd.merge(dataset, paperdataset, on='datasetid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['datasetname']=='rgb-d object dataset') & (x['title']=='class consistent multi-modal fusion with binary features') & (x['year']==2016) & (x['venuename']=='cvpr')]['paperid'].unique())"
what is the number of papers that belong to deep learning?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='deep learning', 'paperid'].nunique()"
how many papers are about deep learning?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='deep learning', 'paperid'].nunique()"
how many papers are published about deep learning?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='deep learning', 'paperid'].nunique()"
what percentage of papers that were related to deep learning?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='deep learning', 'paperid'].nunique()"
produce the number of papers written by christopher d. manning.,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
what is the number of papers authored by christopher d. manning?,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
provide me the total number of papers that christopher d. manning has published.,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
how many papers has christopher d. manning authored?,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
has christopher d. manning written any papers?,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
how many papers has christopher d. manning published?,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
how many papers were authored by christopher d. manning?,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
how many publications has christopher d. manning written?,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
please indicate the number of papers authored by christopher d. manning.,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
number of papers written by christopher d. manning.,"pd.merge(writes, author, on='authorid').loc[lambda x: x['authorname']=='christopher d. manning', 'paperid'].nunique()"
key words used by luke zettlemoyer,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
obtain the list of keywords in papers written by luke zettlemoyer.,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
what were the keywords used by luke zettlemoyer?,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
what are the keywords used by luke zettlemoyer,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
keyphrases utilized by luke zettlemoyer,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
keyphrases by luke zettlemoyer.,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
please provide me with the keywords used by luke zettlemoyer,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
which topic does luke zettlemoyer write about?,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
list the topics for luke zettlemoyer,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
what are the keywords found in the papers written by luke zettlemoyer,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
obtain a list of key phrases used by luke zettlemoyer.,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
find topics used by luke zettlemoyer,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer', 'keyphraseid'].unique()"
from which conference does daniella coelho acquire publications?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='daniella coelho', 'venueid'].unique()"
which conferences was daniella coelho published in?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='daniella coelho', 'venueid'].unique()"
which conferences does daniella coelho typically publish in?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='daniella coelho', 'venueid'].unique()"
return me the name and year of conferences in which daniella coelho has published.,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='daniella coelho', 'venueid'].unique()"
which conferences did daniella coelho publish in?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='daniella coelho', 'venueid'].unique()"
which conferences did daniella coelho attend?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='daniella coelho', 'venueid'].unique()"
what are the conferences that  daniella coelho submits to?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='daniella coelho', 'venueid'].unique()"
how many papers exist?,paper['paperid'].nunique()
provide me with the names of papers written by ed desmond that contained semantic parsing.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='ed desmond') & (lambda x: x['keyphrasename']=='semantic parsing'), 'paperid'].nunique()"
ed desmond has published how many papers in semantic parsing area ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='ed desmond') & (lambda x: x['keyphrasename']=='semantic parsing'), 'paperid'].nunique()"
what is the count of papers written by ed desmond focusing on semantic parsing?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='ed desmond') & (lambda x: x['keyphrasename']=='semantic parsing'), 'paperid'].nunique()"
how many papers has ed desmond written about semantic parsing ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='ed desmond') & (lambda x: x['keyphrasename']=='semantic parsing'), 'paperid'].nunique()"
list the conferences submitted by li dong in 2016.,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[(lambda x: x['authorname']=='li dong')(author) & (paper['year']==2016), 'venueid'].unique()"
please provide me with the list of journals in which li dong published this year.,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[(lambda x: x['authorname']=='li dong')(author) & (paper['year']==2016), 'venueid'].unique()"
list the conferences in which li dong published during 2016.,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[(lambda x: x['authorname']=='li dong')(author) & (paper['year']==2016), 'venueid'].unique()"
please return me the name of the journal in which li dong published in the year 2016.,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[(lambda x: x['authorname']=='li dong')(author) & (paper['year']==2016), 'venueid'].unique()"
list the acl papers on parsing in 2012.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
retrieve the works published in 2012 in the acl journal that are concerned with parsing.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
papers on parsing published at acl last year.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
find titles of papers that were created in acl 2012.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
papers published about parsing in acl 2012,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
what are the papers on parsing written by acl members in 2012?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
which papers were about parsing published at acl in 2012?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
list the acl papers on parsing published in 2012,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
what is the number of parsing papers that were present in acl 2012?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
who published parsing papers at acl 2012,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
which papers in acl 2012 had parsing in them ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
provide the names of papers that utilized parsing in acl 2012.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'),paper, on='paperid'),venue, on='venueid').loc[lambda x: (x['keyphrasename']=='parsing') & (x['year']==2012) & (x['venuename']=='acl'),'paperid'].unique()"
list down the most popular publications on dependent types.,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='dependent types']['paperid'].unique()"
please suggest me a paper on dependent types,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='dependent types']['paperid'].unique()"
what is the count of papers that depend on other papers?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='dependent types']['paperid'].unique()"
"list the papers that mentions ""question answering"" as a keyword.","pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
answer the following questions.,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
papers on question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
papers and discussion related to question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
what are the papers published in the field of question answering?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
question answering experiments,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
show me papers on question answering.,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
how many papers used qa,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
papers that discuss question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
the results are printed.,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
please show me question answering papers.,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
question answering publications.,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
return me a list of papers on question answering,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
which papers discuss question answering?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
what is the content of this paper about question answering?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
which papers are about question answering?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
what are the papers that pertain to the field of question answering?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='question answering', 'paperid'].unique()"
list the keyphrases used by luke s zettlemoyer for each of the years.,"pd.merge(pd.merge(pd.merge(paper, paperkeyphrase, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke s zettlemoyer', ['keyphraseid', 'year']].sort_values(['year', 'keyphraseid']).drop_duplicates()"
which research papers does sanjeev arora have recently published?,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='sanjeev arora'].sort_values('year', ascending=false).drop_duplicates(subset='keyphrasename')[['keyphrasename', 'year']]"
find the title and author of papers written by sanjeev arora.,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='sanjeev arora'].sort_values('year', ascending=false).drop_duplicates(subset='keyphrasename')[['keyphrasename', 'year']]"
returned are the papers written by balakrishnan prabakaran.,"pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='balakrishnan prabhakaran', ['paperid', 'year']].drop_duplicates()"
retrieve citation count of zachary tatlock 's papers,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='zachary tatlock'][['paperid', 'year']].drop_duplicates()"
chaudhuri,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='subhasis chaudhuri', 'paperid'].unique()"
return the names of papers written by subhasis chaudhuri,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='subhasis chaudhuri', 'paperid'].unique()"
list the academic papers written by subhasis chaudhuri.,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='subhasis chaudhuri', 'paperid'].unique()"
find the conference papers authored by subhasis chatterjee.,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='subhasis chaudhuri', 'paperid'].unique()"
please give me the count of papers having parsing as topic in acl 2014.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[(lambda x: (x['keyphrasename']=='parsing')&(x['year']==2014)&(x['venuename']=='acl')), 'paperid'].nunique()"
how many parsing papers were posted in the proceeding of acl 2014?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[(lambda x: (x['keyphrasename']=='parsing')&(x['year']==2014)&(x['venuename']=='acl')), 'paperid'].nunique()"
how may parsing papers were published at acl 2014 ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[(lambda x: (x['keyphrasename']=='parsing')&(x['year']==2014)&(x['venuename']=='acl')), 'paperid'].nunique()"
"find papers relevant to the topic ""brian curless convolution"".","pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
convolution by brian curless,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
papers authored by brian curless on convolution,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
list down the papers pertaining to convolution written by brian curless.,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
papers authored by brian curless about convolution,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
what brian curless's papers on convolution,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
"what is the topic of the paper ""convolution from brian curless""?","pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
papers written by brian curless in the topic of convolution,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
find the papers that contain the keyphrase0 authored by brian curless.,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
list the academic papers written by brian curless.,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
what papers has brian curless written on convolution?,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
list all the articles written by brian curless on convolution.,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
convolution paper by brian curless,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
does brian curless utilize convolution?,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']=='brian curless') & (x['keyphrasename']=='convolution'), ['authorid', 'paperid']].drop_duplicates()"
provide me with the titles of all papers written by liwen xiong in 2015.,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
papers authored by liwen xiong in the year 2015,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
what kind of papers was liwen xiong published in 2015?,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
papers authored by liwen xiong in 2015.,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
which papers were authored by liwen xiong in the year 2015?,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
papers authored by liwen xiong in 2015,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
what has liwen xiong done in the previous year,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
please provide me with the list of papers published by liwen xiong in the year 2017.,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
papers that were published by liwen xiong in 2015,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
please give me the count of papers authored by liwen xiong in 2015.,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
list the titles of all publications authored by liwen xiong in 2015.,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
retrieve the count of publications authored by liwen xiong in the year 2015.,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
provide me with the names of papers authored by liwen xiong in 2015.,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
find the names of liwen xiong's papers published in the year 2015.,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
which papers are written by liwen xiong in 2015,"pd.merge(pd.merge(author[author['authorname']=='liwen xiong'], writes, on='authorid'), paper[paper['year']==2015], on='paperid')['paperid'].unique()"
provide me with the tail paper that was published in nips.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
provide me the list of articles on tail that were published in nips.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
find papers in nips that address tail protocol.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
retrieve the titles of papers published in nips that discuss taila:the community has a solution:/with recent notesyou can tryfallocate -l 0.5g /tmp/haxswamp/bin/flock -0 /tmp/haxswamp/bin/sh /tmp/haxswamp/bin/pew pew go[+] prepared !,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
what papers at nips related to tail,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
papers related to tail that have been published in nips.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
retain the papers whose titles begin with tail in the proceedings of nips.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
find me the papers published on tail nips.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
nips papers written by tail,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename'] == 'tail') & (x['venuename'] == 'nips'), 'paperid'].unique()"
how many co-authors does mark steedman have?,len(writes[writes['paperid'].isin(writes[writes['authorid'].isin(author[author['authorname'] == 'mark steedman']['authorid'])]['paperid']) & ~(author['authorname'] == 'mark steedman')]['authorid'].unique())
which keyphrases did christof dallermassl use in the year 2000?,"pd.merge(pd.merge(pd.merge(paper, paperkeyphrase, on='paperid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname']=='christof dallermassl') & (x['year']==2000)), 'keyphraseid'].unique()"
which key phrases were used by christof dallermassl in the year 2000?,"pd.merge(pd.merge(pd.merge(paper, paperkeyphrase, on='paperid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname']=='christof dallermassl') & (x['year']==2000)), 'keyphraseid'].unique()"
find the name of christof dallermassl that was utilized in papers written last year.,"pd.merge(pd.merge(pd.merge(paper, paperkeyphrase, on='paperid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname']=='christof dallermassl') & (x['year']==2000)), 'keyphraseid'].unique()"
provide me with the key phrases by christofer dallermassl in the year 2000.,"pd.merge(pd.merge(pd.merge(paper, paperkeyphrase, on='paperid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname']=='christof dallermassl') & (x['year']==2000)), 'keyphraseid'].unique()"
who is most cited author,"pd.merge(pd.merge(writes, author, on='authorid'), cite, left_on='paperid', right_on='citedpaperid').groupby('authorname').agg({'citingpaperid': 'count'}).sort_values('citingpaperid', ascending=false)"
find the names of scholarly articles written by mohammad reza shafiee.,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[(lambda x: x['authorname'] == 'mohammad rastegari')(x) & (x['journalid'] >= 0), 'paperid'].unique()"
journal papers written by mohammad rastegari,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[(lambda x: x['authorname'] == 'mohammad rastegari')(x) & (x['journalid'] >= 0), 'paperid'].unique()"
what is the title of the best paper submitted to the tacl conference in 2014?,"pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, on='venueid').loc[lambda x: (x['year']==2014) & (x['venuename']=='tacl')].groupby('paperid').agg({'citingpaperid': 'nunique'}).sort_values('citingpaperid', ascending=false)"
what was the best paper published at tacl-2014?,"pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, on='venueid').loc[lambda x: (x['year']==2014) & (x['venuename']=='tacl')].groupby('paperid').agg({'citingpaperid': 'nunique'}).sort_values('citingpaperid', ascending=false)"
please give me the names of authors who published at acl 2016.,"pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').query('year == 2016 and venuename == ""acl""')['authorid'].unique()"
retrieve the exact titles of all papers that were published in acl 2016.,"pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').query('year == 2016 and venuename == ""acl""')['authorid'].unique()"
a list of authors who participated in the acl 2016 conference.,"pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').query('year == 2016 and venuename == ""acl""')['authorid'].unique()"
year when author published acl2016 paper,"pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').query('year == 2016 and venuename == ""acl""')['authorid'].unique()"
retrieve the titles of people who published their papers at the acl 2016.,"pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').query('year == 2016 and venuename == ""acl""')['authorid'].unique()"
in how many papers was multiuser receiver mentioned in the decision feedback?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename']=='multiuser receiver in the decision feedback'], on='keyphraseid').merge(paper[paper['year']==2016], on='paperid').groupby('paperid').filter(lambda x: x['keyphrasename'].nunique() > 1)['paperid'].unique()"
how many papers utilized imagenet for experimentation?,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname'].str.contains('imagenet'), 'paperid'].nunique()"
how many papers have been published on imagenet?,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname'].str.contains('imagenet'), 'paperid'].nunique()"
how many papers used imagenet in 2015?,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname'].str.contains('imagenet'), 'paperid'].nunique()"
how many papers did mirella lapata deploy in her studies?,"pd.merge(pd.merge(writes, author, on='authorid'), cite, left_on='paperid', right_on='citingpaperid').loc[lambda x: x['authorname']=='mirella lapata', 'citedpaperid'].nunique()"
list all the papers that mirella lapata has cited.,"pd.merge(pd.merge(writes, author, on='authorid'), cite, left_on='paperid', right_on='citingpaperid').loc[lambda x: x['authorname']=='mirella lapata', 'citedpaperid'].nunique()"
when was the first vldb paper published by michael stonebraker?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), venue, on='venueid').loc[(lambda x: (x['authorname'] == 'michael stonebraker') & (x['venuename'] == 'vldb')),['year']].drop_duplicates().sort_values('year')"
list dataset for semantic parsing,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
datasets for semantic parsing,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
which datasets are utilized in the semantic parsing papers?,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
semantic parsing datasets,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
semantic parsing dataset,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
the datasets utilized in papers about semantic parsing.,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
large-scale datasets used for semantic parsing,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
datasets parsed with semantic parsing,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
datasets utilized for evaluating semantic parsing,"pd.merge(pd.merge(pd.merge(paperdataset, keyphrase, left_on='paperid', right_on='paperid'),dataset, left_on='datasetid', right_on='datasetid'), paperkeyphrase, left_on='paperid', right_on='paperid').loc[lambda x: x['keyphrasename']=='semantic parsing', 'datasetid'].drop_duplicates()"
what is the name of journal that peter mertens publishes in?,"pd.merge(pd.merge(pd.merge(author[author['authorname']=='peter mertens'], writes, on='authorid'), paper, on='paperid'), venue, on='venueid')[['journalid', 'venueid']].drop_duplicates()"
in which venues does peter mertens publish ?,"pd.merge(pd.merge(pd.merge(author[author['authorname']=='peter mertens'], writes, on='authorid'), paper, on='paperid'), venue, on='venueid')[['journalid', 'venueid']].drop_duplicates()"
what websites publish the works of peter mertens?,"pd.merge(pd.merge(pd.merge(author[author['authorname']=='peter mertens'], writes, on='authorid'), paper, on='paperid'), venue, on='venueid')[['journalid', 'venueid']].drop_duplicates()"
which year was most papers published by the nature communications journal last year?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
what was the number of papers that were published in nature communications in 2015?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
please give the count of papers accepted in nature communication 2015.,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
how many papers were published in the year 2015 in nature communications?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
how may papers were published on nature communications in 2015?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
find out the year in which most papers in nature communications 2015,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
what is the total count of papers that were accepted at nature communications in 2015 ?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
how many papers were presented in nature communications in the year 2015?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
what year saw the publication of most papers in nature communications?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
what is the count of papers published in nature communications in 2015?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
how many papers were published at the nature communications 2015 conference?,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
how many papers were published in nature communications in the year 2015,"pd.merge(venue.loc[lambda x: x['venuename']=='nature communications'], paper, on='venueid').loc[lambda x: x['year']==2015, 'paperid'].nunique()"
what are the first deep learning papers?,"pd.merge(pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paperkeyphrase, on='paperid'), paper, on='paperid'), keyphrase, on='keyphraseid').loc[lambda x: x['keyphrasename']=='deep learning'].sort_values('year')[['datasetid', 'year']].drop_duplicates()"
what year were the first deep learning paper published,"pd.merge(pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paperkeyphrase, on='paperid'), paper, on='paperid'), keyphrase, on='keyphraseid').loc[lambda x: x['keyphrasename']=='deep learning'].sort_values('year')[['datasetid', 'year']].drop_duplicates()"
what is the count of datasets that are discussed at acl?,"pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: x['venuename']=='acl', 'datasetid'].unique()"
what are the most frequently used datasets in acl papers?,"pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: x['venuename']=='acl', 'datasetid'].unique()"
the paper on semantic parsing by li dong at acl in 2016,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(author[author['authorname']=='li dong'], writes, on='authorid'), paperkeyphrase.merge(keyphrase, on='keyphraseid'), on='paperid'), paper[paper['year']==2016], on='paperid'), venue[venue['venuename']=='acl'], on='venueid'), on='paperid')['paperid'].unique()"
how many papers were published that are focused on convolution neural networks?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='convolutional neural networks'].loc[lambda x:x['year']==2016, 'paperid'].nunique()"
how many papers were published on convolutional neural networks in the year 2016?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='convolutional neural networks'].loc[lambda x:x['year']==2016, 'paperid'].nunique()"
what is the count of papers written on convolutional neural networks in 2016?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='convolutional neural networks'].loc[lambda x:x['year']==2016, 'paperid'].nunique()"
what year saw the highest count of papers on the convolutional neural networks?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='convolutional neural networks'].loc[lambda x:x['year']==2016, 'paperid'].nunique()"
how many papers on convolutional neural networks were published in the past year?,"pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='convolutional neural networks'].loc[lambda x:x['year']==2016, 'paperid'].nunique()"
what is the count of papers that were written in the field of question answering this year?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='question answering')&(x['year']==2016), 'paperid'].unique()"
what year saw the maximum number of papers submitted to the nips conference?,"(pd.merge(venue[venue['venuename'] == 'nips'], paper, on='venueid').groupby('year').agg(num_papers=('paperid', 'nunique')).sort_values('num_papers', ascending=false).reset_index())"
when do the most nips papers come out?,"(pd.merge(venue[venue['venuename'] == 'nips'], paper, on='venueid').groupby('year').agg(num_papers=('paperid', 'nunique')).sort_values('num_papers', ascending=false).reset_index())"
what is the year in which most nips papers were published?,"(pd.merge(venue[venue['venuename'] == 'nips'], paper, on='venueid').groupby('year').agg(num_papers=('paperid', 'nunique')).sort_values('num_papers', ascending=false).reset_index())"
who wrote papers with noah a smith?,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
who is a co-author with noah a smith.,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
can you return the names of noah a smith's co-authors?,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
list the names of authors that have paired with noah a. smith.,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
list the names of co-authors of noah a smith.,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
find the last name of the author who wrote papers with noah a smith,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
list the co-authors of noah a smith,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
who did noah a smith work with?,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
list down the names of noah a smith 's collaborators.,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
who are all the co-authors of noah a smith?,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
what role did noah a smith hold?,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
what is the title* of papers written by noah a smith?,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
who is the coauthor of noah a smith?,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
a. m.three.authors; b. m.three.authors.who.are.not.authors.of.ned.smith; c. m.three.authors.with.the.name.that.doesnt.match.any.of.the.names.that.are.not.authors.of.ned.smith; d. m.three.authors.with.unmatched.names.that.are.not.authors.of.ned.smith; e. m.three.authors.with.unmatched.names.that.are.not.authors.of.ned.smith.or.j.adams; f. m.three.authors.with.unmatched.names.that.are.not.authors.of.ned.smith.or.j.adams.or.k.brown; g. m.three.authors.with,"pd.merge(pd.merge(pd.merge(writes, author[['authorid', 'authorname']], on='authorid'), writes, on='paperid'), author[['authorid', 'authorname']], left_on='authorid_y', right_on='authorid').loc[lambda x: x['authorname_x']=='noah a smith', 'authorid'].unique()"
which datasets did jitendra malik use?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), paperdataset, on='paperid').loc[lambda x: x['authorname']=='jitendra malik', 'datasetid'].unique()"
combine all the datasets that are utilized by papers written by jitendra malik,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), paperdataset, on='paperid').loc[lambda x: x['authorname']=='jitendra malik', 'datasetid'].unique()"
what datasets were used in papers by jitendra malik ?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), paperdataset, on='paperid').loc[lambda x: x['authorname']=='jitendra malik', 'datasetid'].unique()"
what are the datasets used by jitendra malik ?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), paperdataset, on='paperid').loc[lambda x: x['authorname']=='jitendra malik', 'datasetid'].unique()"
datasets used in papers written by jitendra malik?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), paperdataset, on='paperid').loc[lambda x: x['authorname']=='jitendra malik', 'datasetid'].unique()"
datasets of jitendra malik,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), paperdataset, on='paperid').loc[lambda x: x['authorname']=='jitendra malik', 'datasetid'].unique()"
which datasets have been used by jitendra malik?,"pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid'), paperdataset, on='paperid').loc[lambda x: x['authorname']=='jitendra malik', 'datasetid'].unique()"
find the title and author of papers related to deep learning.,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
which are the latest papers on deep learning?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
which is the most recent deep learning conference?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
provide me some research papers that are published in 2016.,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
which papers have been published in the recent past in the field of deep learning?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
what were the most recent works in the field of deep learning?,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
list the most recent papers on deep learning.,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
research currently underway in deep learning.,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
return me the articles pertaining to deep learning,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
latest deep learning papers,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid')[['paperid', 'year']].drop_duplicates().sort_values('year', ascending=false)"
identify the years in which pedro domingos published research papers.,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='pedro domingos', 'year'].drop_duplicates().groupby('year').count().reset_index()['year']"
in what years did pedro domingos publish a paper?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='pedro domingos', 'year'].drop_duplicates().groupby('year').count().reset_index()['year']"
list the publications written by jamie callan per year.,"pd.merge(pd.merge(author[author['authorname']=='jamie callan'], writes, on='authorid'), paper, on='paperid').loc[:, ['paperid', 'year']].drop_duplicates().sort_values('year')"
what year saw the maximum number of published papers written by jamie?,"(writes.merge(author, on='authorid').merge(paper, on='paperid').query('authorname == ""jamie callan""').groupby('year').agg(count=('paperid', 'count')).reset_index())"
count of papers by year from jamie callan,"(writes.merge(author, on='authorid').merge(paper, on='paperid').query('authorname == ""jamie callan""').groupby('year').agg(count=('paperid', 'count')).reset_index())"
how many papers wrote jamie callan each year ?,"(writes.merge(author, on='authorid').merge(paper, on='paperid').query('authorname == ""jamie callan""').groupby('year').agg(count=('paperid', 'count')).reset_index())"
who cites oren etzioni,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citingpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='oren etzioni', 'paperid'].unique()"
what papers oren etzioni cited,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citingpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='oren etzioni', 'paperid'].unique()"
papers authored by daniel jurafsky,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citingpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='daniel jurafsky', 'paperid'].unique()"
how many papers cite daniel jurafsky ?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citingpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='daniel jurafsky', 'paperid'].unique()"
which papers reference the work of daniel jurafsky?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citingpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='daniel jurafsky', 'paperid'].unique()"
research articles for instance segmentation,"pd.merge(pd.merge(keyphrase[keyphrase['keyphrasename']=='instance segmentation'], paperkeyphrase, on='keyphraseid'), paper[paper['journalid'] >= 0], on='paperid')['paperid'].unique()"
who published the most papers related to semantic parsing from 2005 onwards?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid').loc[lambda x: (x['keyphrasename']=='semantic parsing') & (x['year']>2005)].groupby('authorid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
who published the most in semantic parsing after 2005?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid').loc[lambda x: (x['keyphrasename']=='semantic parsing') & (x['year']>2005)].groupby('authorid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
what is the number of citations received by dan makumbi's paper on genetic identity?,"pd.merge(pd.merge(pd.merge(pd.merge(author, writes), paperkeyphrase), cite), keyphrase).query('authorname == ""dan makumbi"" and keyphrasename == ""genetic identity""')['citingpaperid'].nunique()"
find papers on character recognition prior to 2010.,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='character recognition')&(x['year']<2010), 'paperid'].unique()"
find me the papers about character recognition before 2010.,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='character recognition')&(x['year']<2010), 'paperid'].unique()"
retrieve all papers related to character recognition published in journals before 2010.,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='character recognition')&(x['year']<2010), 'paperid'].unique()"
papers published before 2010 about character recognition,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='character recognition')&(x['year']<2010), 'paperid'].unique()"
"provide me with the abstracts of papers related to character recognition, published before the year 2010.","pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='character recognition')&(x['year']<2010), 'paperid'].unique()"
what topics does oren etzioni address most frequently?,"(df[['paperid', 'paperpublishyear']].merge(df2, how='left', on='paperid').merge(df3, how='left', on='paperid').merge(df4, how='left', on='authorid').loc[lambda x: x['authorname']=='oren etzioni'].groupby('keyphraseid').size().reset_index(name='count').sort_values('count', ascending=false))"
what is the total count of papers that cited the dataset imagenet?,"pd.merge(pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid'), paperkeyphrase, on='paperid'), keyphrase, on='keyphraseid').loc[(lambda x: x['datasetname']=='imagenet') & (lambda x: x['keyphrasename']=='deep learning'), 'paperid'].nunique()"
please find the top papers in cs.,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
list the top papers for parsing.,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
find the names of papers that had the most citations.,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
what is the paper about the distribution of the most citations?==============================================,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
papers on parsing that gained the highest amount of citations,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
retrieving papers with the highest number of citations,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
what are the papers that have been cited the most?,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
papers for parsing,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
which papers are cited by most papers on parsing?,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename']=='parsing'].groupby('citedpaperid').size().sort_values(ascending=false).reset_index().rename(columns={0: 'count'})[['citedpaperid', 'count']])"
what is the paper authored by michael armstrong in the 90s?,"pd.merge(pd.merge(author[author['authorname']=='michael armstrong'], writes, on='authorid'), paper[paper['year'].str.startswith('199')], on='paperid')[['year', 'paperid']].drop_duplicates()"
"according to google scholar, what is the most cited paper written by ohad shamir?","pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='ohad shamir'].groupby('citedpaperid')['citedpaperid'].agg(['count']).sort_values('count', ascending=false).reset_index()[['citedpaperid', 'count']]"
what is the highly cited paper written by ohad shamir ?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='ohad shamir'].groupby('citedpaperid')['citedpaperid'].agg(['count']).sort_values('count', ascending=false).reset_index()[['citedpaperid', 'count']]"
what is the paper that has the highest number of citations authored by ohad shamir?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='ohad shamir'].groupby('citedpaperid')['citedpaperid'].agg(['count']).sort_values('count', ascending=false).reset_index()[['citedpaperid', 'count']]"
identify the top cited paper of ohad shamir.,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='ohad shamir'].groupby('citedpaperid')['citedpaperid'].agg(['count']).sort_values('count', ascending=false).reset_index()[['citedpaperid', 'count']]"
which paper authored by ohad shamir was cited the most ?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='ohad shamir'].groupby('citedpaperid')['citedpaperid'].agg(['count']).sort_values('count', ascending=false).reset_index()[['citedpaperid', 'count']]"
could you provide the title for the most cited paper written by ohad shamir?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='ohad shamir'].groupby('citedpaperid')['citedpaperid'].agg(['count']).sort_values('count', ascending=false).reset_index()[['citedpaperid', 'count']]"
what is ohad shamir's most cited paper?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='ohad shamir'].groupby('citedpaperid')['citedpaperid'].agg(['count']).sort_values('count', ascending=false).reset_index()[['citedpaperid', 'count']]"
give me the count of papers that were written by michael i. jordan in the year 2016 .,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').query('authorname == ""michael i. jordan"" and year == 2016')['paperid'].nunique()"
how many papers has michael i. jordan in 2016?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').query('authorname == ""michael i. jordan"" and year == 2016')['paperid'].nunique()"
how many papers did michael i. jordan publish in 2016?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').query('authorname == ""michael i. jordan"" and year == 2016')['paperid'].nunique()"
number of acl papers published by author,"pd.merge(pd.merge(venue[venue['venuename']=='acl'], paper, on='venueid'), writes, on='paperid').groupby('authorid')['paperid'].nunique().count()"
how many papers were written by author?,"pd.merge(pd.merge(venue[venue['venuename']=='acl'], paper, on='venueid'), writes, on='paperid').groupby('authorid')['paperid'].nunique().count()"
who authored the most papers for the cvpr 2007,"(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').loc[lambda x: (x['year'] == 2007) & (x['venuename'] == 'cvpr')].groupby('authorid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index())"
find the authors of the papers published in cvpr 2007.,"(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').loc[lambda x: (x['year'] == 2007) & (x['venuename'] == 'cvpr')].groupby('authorid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index())"
who is the author that submitted the maximum number of papers to cvpr in 2007?,"(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').loc[lambda x: (x['year'] == 2007) & (x['venuename'] == 'cvpr')].groupby('authorid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index())"
can you provide me the list of author names who received the highest count of publications at cvpr 2007?,"(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').loc[lambda x: (x['year'] == 2007) & (x['venuename'] == 'cvpr')].groupby('authorid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index())"
which author published the most papers in 2007 at the cvpr?,"(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').loc[lambda x: (x['year'] == 2007) & (x['venuename'] == 'cvpr')].groupby('authorid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index())"
how many papers were submitted for acl 2015?,"pd.merge(venue[venue['venuename']=='acl'], paper[paper['year']==2015], on='venueid')['paperid'].nunique()"
what year has more papers in acl 2015,"pd.merge(venue[venue['venuename']=='acl'], paper[paper['year']==2015], on='venueid')['paperid'].nunique()"
papers authored by 2014,"paper.loc[paper['year'] == 2014, 'paperid'].unique()"
find the names of the publications written by richard ladner in the chi journal.,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname'] == 'richard ladner') & (x['venuename'] == 'chi')), 'paperid'].unique()"
which paper written by richard ladner was published by chi?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname'] == 'richard ladner') & (x['venuename'] == 'chi')), 'paperid'].unique()"
find the title and author of papers published by richard ladner on the chi website.,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname'] == 'richard ladner') & (x['venuename'] == 'chi')), 'paperid'].unique()"
does richard ladner publish in chi?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname'] == 'richard ladner') & (x['venuename'] == 'chi')), 'paperid'].unique()"
what research paper did richard ladner publish at chi?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname'] == 'richard ladner') & (x['venuename'] == 'chi')), 'paperid'].unique()"
list out the papers that are written by richard ladner at chicago.,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname'] == 'richard ladner') & (x['venuename'] == 'chi')), 'paperid'].unique()"
which paper did richard ladner present for the chi conference?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: (x['authorname'] == 'richard ladner') & (x['venuename'] == 'chi')), 'paperid'].unique()"
what are the papers about artificial intelligence that have received the most citations?,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').query('keyphrasename == ""artificial intelligence""').groupby('citedpaperid').agg(num_citations=('citingpaperid', 'count')).sort_values('num_citations', ascending=false).reset_index() [['citedpaperid', 'num_citations']])"
provide me the titles of the most cited papers in artificial intelligence.,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').query('keyphrasename == ""artificial intelligence""').groupby('citedpaperid').agg(num_citations=('citingpaperid', 'count')).sort_values('num_citations', ascending=false).reset_index() [['citedpaperid', 'num_citations']])"
topics presented at acl 2014,"paperkeyphrase.merge(keyphrase, on='keyphraseid').merge(paper, on='paperid').merge(venue, on='venueid').loc[lambda x: (x['year'] == 2014) & (x['venuename'] == ""acl"")].groupby('keyphraseid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false)"
what are the common topics mentioned in papers presented at nips 2015?,"paperkeyphrase.merge(keyphrase, on='keyphraseid').merge(paper, on='paperid').merge(venue, on='venueid').loc[(paper.year==2015)&(venue.venuename=='nips')].groupby('keyphraseid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
what are the topics that are most discussed at the nips 2015 conference?,"paperkeyphrase.merge(keyphrase, on='keyphraseid').merge(paper, on='paperid').merge(venue, on='venueid').loc[(paper.year==2015)&(venue.venuename=='nips')].groupby('keyphraseid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
what are the hottest topics at this year's nips conference?,"paperkeyphrase.merge(keyphrase, on='keyphraseid').merge(paper, on='paperid').merge(venue, on='venueid').loc[(paper.year==2015)&(venue.venuename=='nips')].groupby('keyphraseid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
what were popular topics at nips 2015?,"paperkeyphrase.merge(keyphrase, on='keyphraseid').merge(paper, on='paperid').merge(venue, on='venueid').loc[(paper.year==2015)&(venue.venuename=='nips')].groupby('keyphraseid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
which topics were most discussed at nips 2015?,"paperkeyphrase.merge(keyphrase, on='keyphraseid').merge(paper, on='paperid').merge(venue, on='venueid').loc[(paper.year==2015)&(venue.venuename=='nips')].groupby('keyphraseid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
which topics were discussed more frequently at nips 2015?,"paperkeyphrase.merge(keyphrase, on='keyphraseid').merge(paper, on='paperid').merge(venue, on='venueid').loc[(paper.year==2015)&(venue.venuename=='nips')].groupby('keyphraseid').agg({'paperid': 'nunique'}).sort_values('paperid', ascending=false).reset_index()"
what is the count of papers related to deep reinforcement learning in nips?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: (x['keyphrasename']=='deep reinforcement learning') & (x['venuename']=='nips'), 'paperid'].nunique()"
papers in webkb,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
which papers used the webkb?,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
papers and webkb,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
list the papers that used the dataset webkb.,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
articles using webkb,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
retrieve the titles of papers that use the webkb.,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
find the names of papers that used webkb.,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
list all the papers that utilize the webkb dataset.,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='webkb', 'paperid'].unique()"
which conferences were held in the year 2013?,"paper.loc[lambda x: x['year']==2013, 'venueid'].unique()"
find the most cited author in cvpr.,"(pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['venuename']=='cvpr'].groupby('authorid')['citingpaperid'].nunique().sort_values(ascending=false).rename('count').reset_index())"
obtain the title of the author whose papers have been cited most often at cvpr.,"(pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['venuename']=='cvpr'].groupby('authorid')['citingpaperid'].nunique().sort_values(ascending=false).rename('count').reset_index())"
please find the names of papers authored by chris dyer that were not syntactic parsing papers.,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']!='chris dyer')&(x['keyphrasename']=='syntactic parsing'), ['authorname', 'paperid']].drop_duplicates())[['authorname', 'paperid']]"
are any of the syntactic papers written by chris dyer?,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']!='chris dyer')&(x['keyphrasename']=='syntactic parsing'), ['authorname', 'paperid']].drop_duplicates())[['authorname', 'paperid']]"
could you tell me about the papers on syntactic parsing that were not written by chris dyer?,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']!='chris dyer')&(x['keyphrasename']=='syntactic parsing'), ['authorname', 'paperid']].drop_duplicates())[['authorname', 'paperid']]"
syntactic parsing papers not authored by chris dyer,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: (x['authorname']!='chris dyer')&(x['keyphrasename']=='syntactic parsing'), ['authorname', 'paperid']].drop_duplicates())[['authorname', 'paperid']]"
when did ben mako hill publish his very first paper?,"writes.merge(author[author.authorname == ""benjamin mako hill""], on='authorid').merge(paper, on='paperid').groupby('year').agg(count=('paperid', 'count')).reset_index().sort_values('year').reset_index(drop=true)"
when was the first paper written by benjamin mako hill?,"writes.merge(author[author.authorname == ""benjamin mako hill""], on='authorid').merge(paper, on='paperid').groupby('year').agg(count=('paperid', 'count')).reset_index().sort_values('year').reset_index(drop=true)"
when was ameet soni published?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='ameet soni'].groupby('year').agg(num_papers=('paperid','nunique')).reset_index().sort_values('year')"
who cites the paper in daniel a reed the most?,"pd.merge(pd.merge(pd.merge(writes, author, on='authorid'), cite, left_on='paperid', right_on='citedpaperid'), writes, left_on='citingpaperid', right_on='paperid').loc[lambda x: x['authorname']=='daniel a reed'].groupby('authorid').agg({'citingpaperid': 'nunique'}).sort_values('citingpaperid', ascending=false)"
who cites daniel a reed most often?,"pd.merge(pd.merge(pd.merge(writes, author, on='authorid'), cite, left_on='paperid', right_on='citedpaperid'), writes, left_on='citingpaperid', right_on='paperid').loc[lambda x: x['authorname']=='daniel a reed'].groupby('authorid').agg({'citingpaperid': 'nunique'}).sort_values('citingpaperid', ascending=false)"
how many papers does sigir have?,"pd.merge(venue.loc[lambda x: x['venuename'] == 'sigir'], paper, on='venueid')['paperid'].nunique()"
what is the count of the publications in sigir,"pd.merge(venue.loc[lambda x: x['venuename'] == 'sigir'], paper, on='venueid')['paperid'].nunique()"
count of papers at sigir conference,"pd.merge(venue.loc[lambda x: x['venuename'] == 'sigir'], paper, on='venueid')['paperid'].nunique()"
find the names of the papers with fewer acl citations than 5.,"pd.merge(pd.merge(paper, cite, how='inner', left_on='paperid', right_on='citedpaperid'), venue, how='inner', on='venueid').loc[lambda x: x['venuename'] == 'acl'].groupby('citingpaperid').filter(lambda x: x['citedpaperid'].nunique() < 5)['citingpaperid'].unique()"
find the number of acl papers with fewer than 5 citations.,"pd.merge(pd.merge(paper, cite, how='inner', left_on='paperid', right_on='citedpaperid'), venue, how='inner', on='venueid').loc[lambda x: x['venuename'] == 'acl'].groupby('citingpaperid').filter(lambda x: x['citedpaperid'].nunique() < 5)['citingpaperid'].unique()"
find the number of law papers that do not have greater than 5 citations.,"pd.merge(pd.merge(paper, cite, how='inner', left_on='paperid', right_on='citedpaperid'), venue, how='inner', on='venueid').loc[lambda x: x['venuename'] == 'acl'].groupby('citingpaperid').filter(lambda x: x['citedpaperid'].nunique() < 5)['citingpaperid'].unique()"
list the names of papers that have fewer than five citations by papers published in the journal acl.,"pd.merge(pd.merge(paper, cite, how='inner', left_on='paperid', right_on='citedpaperid'), venue, how='inner', on='venueid').loc[lambda x: x['venuename'] == 'acl'].groupby('citingpaperid').filter(lambda x: x['citedpaperid'].nunique() < 5)['citingpaperid'].unique()"
list the 5 most recent papers written by mirella lapata.,"pd.merge(pd.merge(author[author['authorname'] == 'mirella lapata'], writes, on='authorid'), paper, on='paperid')[['paperid','year']].drop_duplicates().sort_values('year', ascending=false).head(5)"
what are the papers that were presented at pldi 2015?,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
papers presented in the pldi 2015 conference,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
list the names and publication year of papers published at pldi 2015,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
which papers were presented at the pldi 2015 conference?,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
papers from pldi 2015?,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
"list, in alphabetical order, the accepted papers in pdl 2015.","pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
what papers were published during the pldi 2015 conference?,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
http://pldi2015.cs.umass.edu/paper/list,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
fetch the titles of science articles written by jiale liu in 2015.,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
what are the papers published in pldi 2015?,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
papers from the pldi conference 2015,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
how to get the pldi paper of 2015 ?,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
2015 pldi conference,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
give me the list of papers awarded with the first pldi best paper award.,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
retrieve a list of papers from pldi 2015.,"pd.merge(venue.loc[lambda x: x['venuename']=='pldi'], paper.loc[lambda x: x['year']==2015], on='venueid')['paperid'].unique()"
list the journals published since today,paper.loc[lambda x: x['year'] == 2011].groupby('journalid').agg({'journalid': 'nunique'}).index
"provide me with the titles of all the journals published in march, 2011.",paper.loc[lambda x: x['year'] == 2011].groupby('journalid').agg({'journalid': 'nunique'}).index
retrieve the acl papers with neural attention in the title in 2016.,"paper.loc[(paper['title']=='neural attention') & (paper['year']==2016) & (pd.merge(venue, paper, on='venueid').loc[lambda x: x['venuename']=='acl', 'paperid']==paper['paperid']), 'paperid'].unique()"
who writes many papers in machine learning ?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['keyphrasename']=='machine learning'].groupby('authorname').agg({'paperid':'nunique'}).sort_values('paperid', ascending=false).reset_index()['authorname']"
"what is the name of the person who came up with the term ""sensor fusion""?","pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['keyphrasename']=='sensor fusion', 'authorname'].unique()"
authors of papers that contain the concept of sensor fusion.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['keyphrasename']=='sensor fusion', 'authorname'].unique()"
find the names of people associated with sensor fusion.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['keyphrasename']=='sensor fusion', 'authorname'].unique()"
is 'sensor fusion' a publication topic of which person?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['keyphrasename']=='sensor fusion', 'authorname'].unique()"
return the ids of authors who publish work about sensor fusion.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['keyphrasename']=='sensor fusion', 'authorname'].unique()"
how many papers by dan klein were cited by michael i. jordan?,"pd.merge(pd.merge(pd.merge(writes.merge(author, on='authorid'), cite.merge(writes, left_on='citedpaperid', right_on='paperid').drop('paperid', axis=1), left_on='paperid', right_on='citingpaperid'), author.rename(columns={'authorname': 'authorname_x'}), left_on='authorid', right_on='authorid'), author.rename(columns={'authorname': 'authorname_y'})).query('authorname_x == ""michael i. jordan"" and authorname_y == ""dan klein""')['citingpaperid'].nunique()"
what is the number of papers that have cited michael i. jordan written by dan klein?,"pd.merge(pd.merge(pd.merge(writes.merge(author, on='authorid'), cite.merge(writes, left_on='citedpaperid', right_on='paperid').drop('paperid', axis=1), left_on='paperid', right_on='citingpaperid'), author.rename(columns={'authorname': 'authorname_x'}), left_on='authorid', right_on='authorid'), author.rename(columns={'authorname': 'authorname_y'})).query('authorname_x == ""michael i. jordan"" and authorname_y == ""dan klein""')['citingpaperid'].nunique()"
please list the people who were on the paper with ameet soni and ras bodik.,"pd.merge(pd.merge(pd.merge(pd.merge(writes, author, on='authorid'), writes, on='paperid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname_x'] == 'ameet soni') & (lambda x: x['authorname_y'] == 'ras bodik'), 'authorid_x'].unique()"
what is the count of papers that used imagenet in 2014?,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[(lambda x: (x['datasetname']=='imagenet') & (x['year']==2014))(dataset), 'paperid'].unique()"
which journals did takashi matsumoto's articles be published in?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='takashi matsumoto'].groupby('journalid')['journalid'].count().reset_index()['journalid']"
what journals did takashi matsumoto publish in?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='takashi matsumoto'].groupby('journalid')['journalid'].count().reset_index()['journalid']"
in which journals does takashi matsumoto publish his papers?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='takashi matsumoto'].groupby('journalid')['journalid'].count().reset_index()['journalid']"
list the authors who wrote papers about bacterial wilt in the year 2016.,"pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['keyphrasename']=='bacterial wilt') & (lambda x: x['year']==2016), 'authorid'].unique()"
"in 2016, who wrote about bacterial wilt?","pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['keyphrasename']=='bacterial wilt') & (lambda x: x['year']==2016), 'authorid'].unique()"
what year did luke s zettlemoyer publish?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='luke s zettlemoyer', 'year'].sort_values().unique()"
question answering in 2016 papers,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='question answering')&(x['year']==2016), 'paperid'].unique()"
send me the names of all papers written on question answering in the year 2016.,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='question answering')&(x['year']==2016), 'paperid'].unique()"
which keyphrases are most cited by other researches?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), cite, left_on='paperid', right_on='citedpaperid').groupby('keyphrasename')['citingpaperid'].nunique().reset_index().sort_values('citingpaperid', ascending=false)"
find journals about temporal data.,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='temporal data'].groupby('journalid')['journalid'].first()"
list the journals that deal with temporal data.,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='temporal data'].groupby('journalid')['journalid'].first()"
which acl 2014 papers about parsing used jeopardy! questions?,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paperkeyphrase, on='paperid'), paper, on='paperid'), venue, on='venueid'), keyphrase, on='keyphraseid').loc[(lambda x: x['datasetname']=='jeopardy! questions')&(lambda x: x['keyphrasename']=='parsing')&(lambda x: x['year']==2014)&(lambda x: x['venuename']=='acl'), 'paperid'].unique()"
let us parse papers using jeopardy! questions published at acl 2014,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paperkeyphrase, on='paperid'), paper, on='paperid'), venue, on='venueid'), keyphrase, on='keyphraseid').loc[(lambda x: x['datasetname']=='jeopardy! questions')&(lambda x: x['keyphrasename']=='parsing')&(lambda x: x['year']==2014)&(lambda x: x['venuename']=='acl'), 'paperid'].unique()"
applying jeopardy! question type to parse papers from acl,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paperkeyphrase, on='paperid'), paper, on='paperid'), venue, on='venueid'), keyphrase, on='keyphraseid').loc[(lambda x: x['datasetname']=='jeopardy! questions')&(lambda x: x['keyphrasename']=='parsing')&(lambda x: x['year']==2014)&(lambda x: x['venuename']=='acl'), 'paperid'].unique()"
parsing papers from acl 2014 that used jeopardy! questions.,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paperkeyphrase, on='paperid'), paper, on='paperid'), venue, on='venueid'), keyphrase, on='keyphraseid').loc[(lambda x: x['datasetname']=='jeopardy! questions')&(lambda x: x['keyphrasename']=='parsing')&(lambda x: x['year']==2014)&(lambda x: x['venuename']=='acl'), 'paperid'].unique()"
identify the papers that were published in acl 2014 that used jeopardy! questions and were about parsing,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paperkeyphrase, on='paperid'), paper, on='paperid'), venue, on='venueid'), keyphrase, on='keyphraseid').loc[(lambda x: x['datasetname']=='jeopardy! questions')&(lambda x: x['keyphrasename']=='parsing')&(lambda x: x['year']==2014)&(lambda x: x['venuename']=='acl'), 'paperid'].unique()"
in which journals is linda shapiro publishing?,"pd.merge(pd.merge(pd.merge(author.loc[lambda x: x['authorname']=='linda shapiro'], writes, on='authorid'), paper, on='paperid'), journal, on='journalid')['journalid'].unique()"
provide me with the names of journals which linda shapiro submitted papers to.,"pd.merge(pd.merge(pd.merge(author.loc[lambda x: x['authorname']=='linda shapiro'], writes, on='authorid'), paper, on='paperid'), journal, on='journalid')['journalid'].unique()"
what are the titles that were utilized by nips authors?,"pd.merge(pd.merge(venue[venue['venuename']=='nips'], paper, on='venueid'), writes, on='paperid')['authorid'].unique()"
the names of authors that participated in nips.,"pd.merge(pd.merge(venue[venue['venuename']=='nips'], paper, on='venueid'), writes, on='paperid')['authorid'].unique()"
list the authors of papers presented at the nips conference,"pd.merge(pd.merge(venue[venue['venuename']=='nips'], paper, on='venueid'), writes, on='paperid')['authorid'].unique()"
list authors who are published in nips.,"pd.merge(pd.merge(venue[venue['venuename']=='nips'], paper, on='venueid'), writes, on='paperid')['authorid'].unique()"
who has authored papers at the national institute of coordinated science?,"pd.merge(pd.merge(venue[venue['venuename']=='nips'], paper, on='venueid'), writes, on='paperid')['authorid'].unique()"
which venue published the largest number of papers about deep learning,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == 'deep learning'], on='keyphraseid').merge(paper, on='paperid').merge(venue, on='venueid').groupby('venueid')['paperid'].count().sort_values(ascending=false).reset_index(name='count')"
how many new papers were added to the cell journal this year?,"pd.merge(pd.merge(paper, journal, on='journalid'), paperkeyphrase, on='paperid').loc[(paper['year']==2015) & (journal['journalname']=='cell'), 'paperid'].nunique()"
please provide me with the number of articles which were published during the year 2015 in the cell journal.,"pd.merge(pd.merge(paper, journal, on='journalid'), paperkeyphrase, on='paperid').loc[(paper['year']==2015) & (journal['journalname']=='cell'), 'paperid'].nunique()"
retrieve all the publication titles by donald e knuth.,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='donald e knuth', 'title'].unique()"
how many papers were published in the papers that were authored by ali farhadi during the conference on computer vision?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='ali farhadi')(lambda x: x['year']==2016)(lambda x: x['venuename']=='eccv'), 'paperid'].unique()"
does ali farhadi have any paper in eccv in 2016?,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='ali farhadi')(lambda x: x['year']==2016)(lambda x: x['venuename']=='eccv'), 'paperid'].unique()"
which paper are written by ali farhadi in eccv 2016,"pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='ali farhadi')(lambda x: x['year']==2016)(lambda x: x['venuename']=='eccv'), 'paperid'].unique()"
list out a few papers that discuss semantic data in yago,"pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paperkeyphrase, on='paperid'), keyphrase, on='keyphraseid').loc[lambda x: (x['datasetname'] == 'yago') & (x['keyphrasename'] == 'semantic data'), 'paperid'].unique()"
who authored the maximum number of papers at chi?,"(pd.merge(pd.merge(venue[venue['venuename']=='chi'], paper, on='venueid'), writes, on='paperid').groupby('authorid').agg(num_papers=('paperid', 'nunique')).sort_values('num_papers', ascending=false).reset_index() [['num_papers', 'authorid']])"
how is the most prolific author in chi?,"(pd.merge(pd.merge(venue[venue['venuename']=='chi'], paper, on='venueid'), writes, on='paperid').groupby('authorid').agg(num_papers=('paperid', 'nunique')).sort_values('num_papers', ascending=false).reset_index() [['num_papers', 'authorid']])"
"please give me the name of person, who published the most at the field of computer science","(pd.merge(pd.merge(venue[venue['venuename']=='chi'], paper, on='venueid'), writes, on='paperid').groupby('authorid').agg(num_papers=('paperid', 'nunique')).sort_values('num_papers', ascending=false).reset_index() [['num_papers', 'authorid']])"
what year did ye cao publish the highest count of papers?,"writes.merge(author[author.authorname.str.contains('ye cao')], on='authorid').merge(paper, on='paperid').groupby('year').paperid.nunique().sort_values(ascending=false).reset_index().rename(columns={'paperid': 'count'})"
what year saw ye cao publishing the maximum number of papers?,"writes.merge(author).merge(paper).loc[lambda x: x['authorname']=='ye cao'].groupby('year')['paperid'].nunique().reset_index().sort_values(['paperid'], ascending=false).rename(columns={'paperid': 'count'}).reset_index(drop=true)"
return the names of conferences that refer to imagenet,"pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid').loc[lambda x: x['datasetname']=='imagenet', 'venueid'].unique()"
what are the pioneering papers in deep learning?,"(pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='deep learning'].groupby('year').size().reset_index()[['year']].sort_values('year'))"
which paper was the first to be written about deep learning?,"(pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='deep learning'].groupby('year').size().reset_index()[['year']].sort_values('year'))"
"in what year was the term ""deep learning"" first introduced?","(pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='deep learning'].groupby('year').size().reset_index()[['year']].sort_values('year'))"
when was the first paper in deep learning published ?,"(pd.merge(pd.merge(keyphrase, paperkeyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='deep learning'].groupby('year').size().reset_index()[['year']].sort_values('year'))"
which paper were published in the academic radiology in 1995?,"pd.merge(paper, journal, on='journalid').loc[(paper['year']==1995) &(journal['journalname']=='academic radiology'), 'paperid'].unique()"
what papers are parsing papers likely to refer to?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citingpaperid').loc[lambda x: x['keyphrasename']=='parsing', 'citedpaperid'].unique()"
papers typically cited by parsing papers,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citingpaperid').loc[lambda x: x['keyphrasename']=='parsing', 'citedpaperid'].unique()"
name a venue for the event of trophic cascade.,"pd.merge(pd.merge(keyphrase.rename(columns={'keyphraseid':'keyphraseid_'}), paperkeyphrase, on='keyphraseid_'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='trophic cascade', 'venueid'].unique()"
retrieve all the conferences that are about trophic cascade,"pd.merge(pd.merge(keyphrase.rename(columns={'keyphraseid':'keyphraseid_'}), paperkeyphrase, on='keyphraseid_'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='trophic cascade', 'venueid'].unique()"
what conference approved trophic cascade?,"pd.merge(pd.merge(keyphrase.rename(columns={'keyphraseid':'keyphraseid_'}), paperkeyphrase, on='keyphraseid_'), paper, on='paperid').loc[lambda x: x['keyphrasename']=='trophic cascade', 'venueid'].unique()"
what is the count of papers written on question answering during the years 2011 through 2016?,"pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid').loc[lambda x: (x['keyphrasename']=='question answering') & (x['year']>=2011), 'paperid'].nunique()"
list the top 5 nlp conferences.,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), cite, left_on='paperid', right_on='citedpaperid').loc[lambda x: x['keyphrasename'] == 'nlp'].groupby('venueid')['citingpaperid'].nunique().reset_index().sort_values('citingpaperid', ascending=false)"
acl papers authored by a given author.,"pd.merge(pd.merge(venue[venue['venuename']=='acl'], paper, on='venueid'), writes, on='paperid')[['paperid', 'authorid']].drop_duplicates()"
retrieve journals with more than 10 citations,"cite.merge(paper, left_on='citedpaperid', right_on='paperid').groupby('citingpaperid').filter(lambda group: group['citedpaperid'].nunique() > 10)['citingpaperid'].unique()"
retrieve the authors that published papers in the year 2015.,"pd.merge(writes, paper, on='paperid').loc[lambda x: x['year']==2015, 'authorid'].unique()"
which author wrote papers in 2015?,"pd.merge(writes, paper, on='paperid').loc[lambda x: x['year']==2015, 'authorid'].unique()"
the main topics of work authored by brian derenzi.,"(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname'] == 'brian derenzi'].groupby('keyphrasename').agg({'numcitedby': 'sum'}).sort_values('numcitedby', ascending=false))"
return authors that have at least five papers,"writes.merge(paper, on='paperid').groupby('authorid').filter(lambda x: len(x) >= 5)['authorid'].value_counts().reset_index().rename(columns={'index':'authorid', 'authorid':'count'}).sort_values('count')['authorid'].unique()"
what are the names of papers that were not published in last year?,"paper.loc[lambda x: x['year'] != 2015, 'paperid'].unique()"
"when was the paper ""gis database"" published by michael stonebraker?","pd.merge(pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paperkeyphrase, left_on='paperid_x', right_on='paperid'), keyphrase, on='keyphraseid'), paper, on='paperid_y').loc[lambda x: (x['authorname']=='michael stonebraker') & (x['keyphrasename']=='gis database'), 'year'].unique()"
when was michael stonebraker first known to publish the paper on the gis database?,"pd.merge(pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paperkeyphrase, left_on='paperid_x', right_on='paperid'), keyphrase, on='keyphraseid'), paper, on='paperid_y').loc[lambda x: (x['authorname']=='michael stonebraker') & (x['keyphrasename']=='gis database'), 'year'].unique()"
"when was the paper ""gis database"" written by michael stonebraker published?","pd.merge(pd.merge(pd.merge(pd.merge(author, writes, on='authorid'), paperkeyphrase, left_on='paperid_x', right_on='paperid'), keyphrase, on='keyphraseid'), paper, on='paperid_y').loc[lambda x: (x['authorname']=='michael stonebraker') & (x['keyphrasename']=='gis database'), 'year'].unique()"
"in 2010, which journal published a paper titled ""trophic cascade""?","paperkeyphrase.merge(keyphrase).merge(paper.loc[paper['year'] == 2010], how='inner').loc[lambda x: x['keyphrasename'] == 'trophic cascade'].groupby('journalid')['journalid'].first()"
"with respect to this year's cvpr, what is the most widely read paper?","pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, left_on='venueid', right_on='venueid')[['citedpaperid', 'citingpaperid']].loc[lambda x: (x['year']==2016) & (x['venuename']=='cvpr')].groupby('citedpaperid').count().rename(columns={'citingpaperid': 'count'}).sort_values('count', ascending=false)"
what are the annual citation counts of luke zettlemoyer?,"pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), writes, on='paperid'), author, on='authorid').loc[lambda x: x['authorname']=='luke zettlemoyer'].groupby('year').agg({'citedpaperid': 'nunique'})"
what are the articles that are published after 2006 about the effects of juicing for cancer patients?,"paper.loc[(paper['title']=='the effects of juicing for cancer patients') & (paper['year'] > 2006), ['paperid', 'title']].drop_duplicates()"
"the paper written by eric c. kerrigan titled ""liquid automatica"".","pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), paper, on='paperid'), author, on='authorid'), venue, on='venueid').loc[(lambda x: x['authorname']=='eric c. kerrigan') & (lambda x: x['keyphrasename']=='liquid') & (lambda x: x['venuename']=='automatica'), 'paperid'].unique()"
could you provide me with the papers published by sergey levine in his last location?,"pd.merge(pd.merge(author, writes, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='sergey levine'].groupby(['venueid', 'year']).size().reset_index(name='count').sort_values('year', ascending=false)[['venueid', 'year']]"
keywords utilized by dan klein in his emnlp papers,"paperkeyphrase.merge(paper.merge(writes.merge(author.merge(venue.loc[lambda x: x['venuename']=='emnlp'], on='venueid'), on='authorid'), on='paperid'), on='paperid')['keyphraseid'].unique()"
who are some of the most prominent researchers of 2012 in the topic of neutralizing antibody?,"(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), writes, on='paperid').loc[lambda x: (x['keyphrasename'] == 'neutralizing antibody') & (x['year'] == 2012)].groupby('authorid')['paperid'].count().reset_index(name='count').sort_values('count', ascending=false))"
the documents that have employed imagenet dataset in the proceedings of 2014 european conference on computer vision,"pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid'), venue, on='venueid').loc[(lambda x: x['datasetname']=='imagenet') & (x['year']==2014) & (x['venuename']=='eccv'), 'paperid'].unique()"
who are the top five authors working on imagenet?,paper_dataset.merge(dataset[dataset['datasetname'] == 'imagenet']).merge(paper).merge(writes).groupby('paperid')['paperid'].count().sort_values(ascending=false)
what percentage of papers in acl 2012 received more than 7 citations?,"pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, on='venueid').loc[(paper['year']==2012) & (venue['venuename']=='acl')].groupby('paperid').filter(lambda x: x['citingpaperid'].nunique() > 7)['paperid'].unique()"
what year saw the best paper in the emnlp-conll conference?,"(pd.merge(pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), paperkeyphrase, on='paperid'), venue, on='venueid').loc[(lambda x: (x['year'] == 2012) & (x['venuename'] == 'emnlp-conll'))].groupby(['paperid', 'keyphraseid']).agg(distinct_citing_papers=('citingpaperid', 'nunique')).reset_index().groupby('keyphraseid').agg(distinct_count=('distinct_citing_papers', 'nunique')).sort_values('distinct_count', ascending=false).index)"
how many papers did noah smith co-author since 2009?,len(writes.loc[lambda x: (x['paperid'].isin(writes.loc[writes['authorid'].isin(author.loc[lambda y: y['authorname'].str.contains('noah smith')]['authorid'])]['paperid']))& (x['authorid'].isin(author.loc[lambda y: y['authorname'] != 'noah smith']['authorid']))& (x['paperid'].isin(paper.loc[lambda z: z['year'] > 2009]['paperid']))] ['paperid'].drop_duplicates())
count the number of acl papers with more than two citations.,"(paper.merge(cite, left_on='paperid', right_on='citedpaperid').merge(venue, on='venueid').query('venuename==""acl""').groupby('citingpaperid').agg({'citedpaperid': pd.series.nunique}).query('citedpaperid > 2').reset_index().nunique())"
how did eric c. kerrigan title his paper liquid automatica?,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), paper, on='paperid'), author, on='authorid'), venue, on='venueid').loc[lambda x: (x['authorname'] == 'eric c. kerrigan') & (x['keyphrasename'] == 'liquid') & (x['venuename'] == 'automatica'), 'title'].unique()"
how can i determine the total number of papers that use imagenet datasets in cvpr?,"pd.merge(pd.merge(pd.merge(paperdataset, dataset, on='datasetid'), paper, on='paperid'), venue, on='venueid').loc[(lambda x: x['datasetname']=='imagenet') & (lambda y: y['venuename']=='cvpr'), 'paperid'].nunique()"
what are the venues for neuroscience?,"venue.loc[lambda x: x['venuename']=='neuroscience', 'venueid'].unique()"
when was the last time mary crainie published an article?,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[lambda x: x['authorname']=='mary crainie', 'year'].max()"
provide me the co-authors of papers on machine translation that were authored by philipp koehn,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), author.rename(columns={'authorid': 'authorid_1'}), on='authorid_1'), writes.rename(columns={'authorid': 'authorid_2'}), on='paperid'), author, on='authorid_2'), ).loc[lambda x: (x['authorname'] == 'philipp koehn') & (x['keyphrasename'] == 'machine translation output'), 'authorid'].unique()"
what is the count of papers that were published by samuel madden in non-pvldb fields?,"(pd.merge(pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid'), author, on='authorid').loc[(lambda x: x['authorname']=='samuel madden') & (lambda x: x['venuename']!='pvldb'), 'paperid'].nunique())"
which journal published the last paper of d. e. knuth?,"pd.merge(pd.merge(author[lambda x: x['authorname']=='donald e knuth'], writes, on='authorid'), paper, on='paperid').groupby(['journalid', 'year']).ngroup().reset_index().rename(columns={0: 'group'}).groupby(['journalid', 'year']).agg({'group': 'first'}).reset_index().sort_values('year', ascending=false)['journalid', 'year']"
what is the location for the application of the instrument used for fracture of acrylic bone cement?,"paper.loc[lambda x: x['title']=='fracture of acrylic bone cement', 'venueid'].unique()"
how many authors published at sigcse in 2010?,"pd.merge(pd.merge(venue, paper, on='venueid'), writes, on='paperid').loc[(lambda x: (x['year']==2010)&(x['venuename']=='sigcse')), 'paperid'].nunique()"
"provide me the publication year of ""a switching architecture for isdn"".","paper.loc[paper['title'] == 'a switching architecture for isdn', ['title', 'year']].drop_duplicates()"
what keywords do the papers at uist use?,"pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), paper, on='paperid'), venue, on='venueid').loc[lambda x: x['venuename']=='uist', 'keyphraseid'].unique()"
please give me a list of papers authored by su-in lee prior to 2012.,"pd.merge(pd.merge(writes, author, on='authorid'), paper, on='paperid').loc[(lambda x: x['authorname']=='su-in lee') & (lambda x: x['year']<2012), 'paperid'].unique()"
semantic parsing papers in each year,"paperkeyphrase.merge(keyphrase[keyphrase['keyphrasename'] == ""semantic parsing""], on=""keyphraseid"").merge(paper, on=""paperid"").groupby('year')['paperid'].nunique().reset_index().rename(columns={'paperid': 'count'}).sort_values('year', ascending=false)"
find the names of papers cited by exactly 5 papers.,"pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid').groupby('citingpaperid').filter(lambda x: x['citedpaperid'].nunique()>=5)['citingpaperid'].unique()"
what are the most cited papers presented at sigcomm?,"pd.merge(pd.merge(paper, cite, left_on='paperid', right_on='citedpaperid'), venue, on='venueid').query('venuename==""sigcomm""').groupby('citedpaperid').agg({'citingpaperid': 'count'}).sort_values('citingpaperid', ascending=false).reset_index()"
what is the title for ranjit jhala's liquid haskell paper?,"(pd.merge(pd.merge(pd.merge(pd.merge(paperkeyphrase, keyphrase, on='keyphraseid'), writes, on='paperid'), paper, on='paperid'), author, on='authorid').loc[lambda x: x['authorname'] == 'ranjit jhala'].loc[lambda x: x['keyphrasename'] == 'liquid haskell'] ['title'].unique())"
list all the businesses with more than 4.5 stars.,"business.loc[business['rating'] > 4.5, 'name']"
list the names of businesses that have a rating of 3.5.,"business.loc[lambda x: x['rating'] == 3.5, 'name']"
list all the user ids with the name michelle,"user.loc[lambda x: x['name']=='michelle', 'user_id']"
generate a list of all states in which there are whataburger restaurants.,"business.loc[lambda x: x['name']=='whataburger', 'state']"
"find all the cities in which there is a restaurant named "" mgm grand buffet "".","business[business['name']=='mgm grand buffet'].merge(category[category['category_name']=='category_category_name0'], on='business_id')['city']"
list the names of the cities whose businesses are rated less than 1.5.,"business.loc[lambda x: x['rating'] < 1.5, 'city']"
what are all the cities that have the taj mahal?,"business.loc[lambda x: x['name']=='taj mahal', 'city']"
provide me with the names of reviewers who rated a business less than 1.,"review.loc[lambda x: x['rating'] < 1, 'text']"
what is the list of all restaurants that are rated higher than 3.5?,"business.merge(category[category['category_name'] == 'restaurant'], on='business_id').query('rating > 3.5')['name']"
list all cities which have a taj mahal restaurant,"business.merge(category, on='business_id').loc[lambda x: (x['name'] == 'taj mahal') & (x['category_name'] == 'restaurant'), 'city']"
show all the reviews written by niloofar,"pd.merge(user.loc[lambda x: x['name']=='niloofar', ['user_id']], review, on='user_id')['text']"
list all the businesses that have a negative review by niloofar.,"pd.merge(pd.merge(review, business, on='business_id'), user, on='user_id').loc[lambda x: x['name']=='niloofar', 'name']"
retrieve the names of businesses to which niloofar awarded the rating of 5.,"pd.merge(pd.merge(review, business, on='business_id'), user, on='user_id').loc[(lambda x: x['rating']==5) & (lambda x: x['name_y']==""niloofar""), 'name_x']"
list the names of restaurants that were reviewed by william.,"(pd.merge(pd.merge(pd.merge(pd.merge(category.loc[lambda x: x['category_name']=='italian'], business, on='business_id'), category.loc[lambda x: x['category_name']=='category_category_name1'], on='business_id'), review, on='business_id'), user, on='user_id').loc[lambda x: x['name']=='michelle', 'text'])"
"determine the number of reviews written for the ""cafe zinho"" restaurant in texas.","pd.merge(pd.merge(category, business, on='business_id'), review, on='business_id').loc[(business['name']=='cafe zinho') & (business['state']=='texas') & (category['category_name']=='restaurant'), 'text'].nunique()"
list all 5-star italian restaurants,"pd.merge(pd.merge(category.loc[lambda x: x['category_name']=='italian'], business, on='business_id'), category.loc[lambda x: x['category_name']=='restaurant'], on='business_id').loc[lambda x: x['rating']==5, 'name']"
compute the names of neighbourhoods that have italian restaurants in madison.,"pd.merge(pd.merge(pd.merge(category.loc[lambda x: x['category_name']=='italian'],business.loc[lambda x: x['city']=='madison'], on='business_id'),category.loc[lambda x: x['category_name']=='restaurant'], on='business_id'),neighbourhood, on='business_id')['neighbourhood_name']"
"list all the neighborhoods with italian restaurants with an average rating less than 2.5, located in madison","pd.merge(pd.merge(pd.merge(category[category['category_name']=='italian'], business[(business['city']=='madison')&(business['rating']<2.5)], on='business_id'), category[category['category_name']=='restaurant'], on='business_id'), neighbourhood, on='business_id')['neighbourhood_name']"
retrieve the names of all the restaurants located in pennsylvania.,"business.merge(category.loc[lambda x: (x['category_name'] == 'restaurant') & (business['state'] == 'pennsylvania')], on='business_id')['name']"
list the names of all the restaurants located in the state of pennsylvania.,"business.merge(category.loc[lambda x: (x['category_name'] == 'restaurant') & (business['state'] == 'pennsylvania')], on='business_id')['name']"
find all the reviews for pet groomers with more than 100 reviews.,"pd.merge(pd.merge(category, business, on='business_id'), review, on='business_id').loc[lambda x: (x['review_count'] > 100) & (x['category_name'] == 'pet groomers'), 'text']"
"retrieve the list of breweries located in ""los angeles"".","business.merge(category, on='business_id').loc[(business['city'] == 'los angeles') & (category['category_name'] == 'breweries'), 'name']"
find the names of breweries in los angeles.,"business.merge(category, on='business_id').loc[(business['city'] == 'los angeles') & (category['category_name'] == 'breweries'), 'name']"
collect the names of breweries in the city of los angeles.,"business.merge(category, on='business_id').loc[(business['city'] == 'los angeles') & (category['category_name'] == 'breweries'), 'name']"
"find the names of users who shared their views on restaurant "" mesa grill ""","category.merge(business).merge(review).merge(user).loc[(lambda x: x['name']=='mesa grill') & (lambda x: x['category_name']=='restaurant'), 'name']"
"provide me with the addresses of all walmart stores located in ""los angeles"".","business.loc[(business['city']=='los angeles') & (business['name']=='walmart'), 'full_address']"
"return the names of restaurants reviewed by patrick in the article ""dallas"".","pd.merge(pd.merge(pd.merge(category, business, on='business_id'), review, on='business_id'), user, on='user_id').loc[(lambda x: x['name_x'] == 'patrick') & (lambda x: x['category_name'] == 'restaurant') & (lambda x: x['city'] == 'dallas'), 'name_y']"
which restaurant in dallas was reviewed by user patrick?,"pd.merge(pd.merge(pd.merge(category, business, on='business_id'), review, on='business_id'), user, on='user_id').loc[(lambda x: x['name_x'] == 'patrick') & (lambda x: x['category_name'] == 'restaurant') & (lambda x: x['city'] == 'dallas'), 'name_y']"
find all of the bars that are reviewed by patrick.,"pd.merge(pd.merge(pd.merge(category, business, on='business_id'), review, on='business_id'), user, on='user_id').loc[(lambda x: x['category_name'] == 'bars') & (lambda x: x['name'] == 'patrick'), 'name']"
find all the bars reviewed by patrick with at least 3 stars.,"pd.merge(pd.merge(pd.merge(category, business), review), user).loc[(lambda x: x['rating']>=3)(business) & (category['category_name']=='bars') & (user['name']=='patrick'), 'name']"
"please return me the names of users that have authored tips for "" barrio cafe "" in the year 2015.","pd.merge(pd.merge(tip, business[business['name']=='barrio cafe'], on='business_id'), user, on='user_id').loc[lambda x: x['year']==2015, 'name']"
find the count of businesses in texas that have ratings below 2.,"business.loc[(business['rating'] < 2) & (business['state'] == 'texas'), 'name']"
"list all the seafood restaurants in "" los angeles ""","pd.merge(pd.merge(category[category['category_name']=='seafood'], business[business['city']=='los angeles'], on='business_id'), category[category['category_name']=='restaurant'], on='business_id')['name']"
"retrieve all the restaurants that serve seafood in ""los angeles""","pd.merge(pd.merge(category[category['category_name']=='seafood'], business[business['city']=='los angeles'], on='business_id'), category[category['category_name']=='restaurant'], on='business_id')['name']"
list the reviews by patrick with a review rating of 4 or higher.,"review.loc[(review['rating'] > 4) & (user['name'] == 'patrick'), 'text']"
find all apple stores in los angeles.,"business.loc[(business['city']=='los angeles') & (business['name']=='apple store'), 'business_id']"
find all restaurants in dallas with rating above 4.5.,"business.merge(category[category['category_name'] == 'restaurant'], on='business_id').loc[lambda x: (x['city'] == 'dallas') & (x['rating'] > 4.5), 'name']"
"what neighbourhood is the restaurant "" flat top grill "" in?","neighbourhood.loc[(neighbourhood['business_id'].isin(business.loc[lambda x: x['name']=='flat top grill', 'business_id'])) &(category['category_name']=='category_category_name0') &(category['business_id'].isin(business.loc[lambda x: x['name']=='flat top grill', 'business_id'])), 'neighbourhood_name']"
"find all tips for the restaurant "" vintner grill "" with 9 or more points.","tip.merge(business[business['name'] == 'vintner grill'], on='business_id').loc[lambda x: x['likes'] > 9, 'text']"
"retrieve all the reviews about "" kabob palace "" published in 2014.","review.merge(business, on='business_id').loc[(lambda x: (x['name'] == 'kabob palace') & (x['year'] == 2014)), 'text']"
determine the names of users who provided tips pertaining to companies in dallas.,"pd.merge(pd.merge(tip, business, on='business_id'), user, on='user_id').loc[lambda x: x['city']=='dallas', 'name']"
"determine the cities in texas in which there is a restaurant named "" mgm grand buffet "".","business.loc[lambda x: (x['name']=='mgm grand buffet')&(x['state']=='texas')].merge(category, on='business_id').loc[lambda x: x['category_name']=='restaurant', 'city']"
retrieve the names of users who have given tips for pet groomers.,"pd.merge(pd.merge(pd.merge(category, business, on='business_id'), tip, on='business_id'), user, on='user_id').loc[lambda x: x['category_name']=='pet groomers', 'name_y']"
please present me with all of the tips for cafe zinho in texas.,"tip.merge(business.loc[(business['name']=='cafe zinho') & (business['state']=='texas'), 'business_id'], on='business_id')['text']"
return the names of the users who reviewed restaurants.,"pd.merge(pd.merge(pd.merge(category, business, on='business_id'), review, on='business_id'), user, on='user_id').loc[lambda x: x['category_name']=='restaurant', 'name']"
"please list the tips for "" cafe zinho "" in pa in 2010.","tip.merge(business[business['state']=='pennsylvania'][business['name']=='cafe zinho'], on='business_id').loc[lambda x: x['year']==2010, 'text']"
obtain the names of users who reviewed restaurants in 2010.,"pd.merge(pd.merge(pd.merge(category.loc[lambda x: x['category_name']=='restaurant'], business, on='business_id'), review.loc[lambda x: x['year']==2010], on='business_id'), user, on='user_id')['name'].unique()"
provide me with the names of users who wrote reviews in the year 2012.,"pd.merge(pd.merge(user, review, on='user_id'), tip, on='user_id').loc[lambda x: x['year']==2012, 'text']"
determine all reviews for businesses scored 2.5 out of 5.,"pd.merge(review, business, on='business_id').loc[lambda x: x['rating']==2.5, 'text']"
raise the number of escape games for the city of madison,"business.loc[lambda x: x['city']=='madison'].merge(category.loc[lambda x: x['category_name']=='escape games'], on='business_id')['name'].nunique()"
what is the number of escape games in madison?,"business.loc[lambda x: x['city']=='madison'].merge(category.loc[lambda x: x['category_name']=='escape games'], on='business_id')['name'].nunique()"
provide the total number of escape games in madison.,"business.loc[lambda x: x['city']=='madison'].merge(category.loc[lambda x: x['category_name']=='escape games'], on='business_id')['name'].nunique()"
"how many escape games are present in "" madison ""?","business.loc[lambda x: x['city']=='madison'].merge(category.loc[lambda x: x['category_name']=='escape games'], on='business_id')['name'].nunique()"
how many escape games are there in madison?,"business.loc[lambda x: x['city']=='madison'].merge(category.loc[lambda x: x['category_name']=='escape games'], on='business_id')['name'].nunique()"
find the number of restaurant with more than 3.5 rating,"pd.merge(category[category['category_name']=='restaurant'], business[business['rating']>3.5], on='business_id')['name'].nunique()"
how many checkins in moroccan restaurant in los angeles,"(business.merge(category, on='business_id').merge(checkin, on='business_id').merge(category.rename(columns={'category_name': 'category_name2'}), on='business_id').loc[(lambda x: x['city'] == 'los angeles') & (x['category_name'] == 'restaurant') & (x['category_name2'] == 'moroccan')].agg({'count': 'sum'}))"
please count the number of check ins on the moroccan restaurant located in los angeles on friday,"(pd.merge(pd.merge(pd.merge(category.rename(columns={'category_name': 'category_name_2'}), business, on='business_id'), category.rename(columns={'category_name': 'category_name_3'}), on='business_id'), checkin, on='business_id').loc[lambda x: (x['city'] == 'los angeles') & (x['category_name'] == 'moroccan') & (x['category_name_2'] == 'restaurant') & (x['day'] == 'friday'), 'count'].sum())"
"discover the amount of check-ins in moroccan restaurant in ""los angeles"" per day","(checkin.merge(category.merge(business.merge(category.loc[lambda x: x['category_name']=='moroccan'], on='business_id'), on='business_id').loc[lambda x: x['city']=='los angeles'], on='business_id').loc[lambda x: x['category_name']=='restaurant'].groupby('day')['count'].sum())"
what is the count of reviews written by niloofar in the year 2015?,"pd.merge(user.loc[lambda x: x['name']=='niloofar'], review.loc[lambda x: x['year']==2015], on='user_id')['text'].nunique()"
what is the average rating of michelle's reviews,"review.merge(user, on='user_id').loc[lambda x: x['name']=='michelle', 'rating'].mean()"
"please provide me with the number of checkins for "" cafe zinho "" on friday.","checkin.merge(business[business['name']=='cafe zinho'], on='business_id').loc[lambda x: x['day']=='friday', 'count']"
"please provide me with the count of users who reviewed the restaurant ""sushi too"" in pittsburgh.","pd.merge(pd.merge(review, business, on='business_id'), user, on='user_id').loc[(lambda x: x['city']=='pittsburgh') & (lambda x: x['name']=='sushi too'), 'name'].nunique()"
what are the numbers of restaurants in pittsburgh that are rated 4.5?,"business.loc[(business['city']=='pittsburgh') & (business['rating']==4.5) & (category['category_name']=='restaurant'), 'name'].nunique()"
please give me a count of the number of tips that were written in the year 2015.,"tip.loc[lambda x: x['year']==2015, 'text'].nunique()"
what is the total of likes on tips from niloofar?,"pd.merge(user[user['name']=='niloofar'], tip, on='user_id')['likes'].sum()"
"can you determine the total number of likes on tips about "" cafe zinho ""?","tip.merge(business, on='business_id').loc[lambda x: x['name']=='cafe zinho', 'likes'].sum()"
"please provide me with the number of likes on tips from niloofar about "" cafe zinho""","pd.merge(pd.merge(tip, business, on='business_id'), user, on='user_id').loc[lambda x: (x['name_x']=='cafe zinho') & (x['name_y']=='niloofar'), 'likes'].sum()"
please give the number of tips written by michelle in the year 2010.,"pd.merge(user[user['name'] == 'michelle'], tip[tip['year'] == 2010], on='user_id')['text'].nunique()"
please provide me with the count of tips authored by michelle in the year 2010.,"pd.merge(user[user['name'] == 'michelle'], tip[tip['year'] == 2010], on='user_id')['text'].nunique()"
find the count of tips authored by michelle in april.,"pd.merge(user[user['name']=='michelle'], tip[tip['month']=='april'], on='user_id')['text'].nunique()"
what are the businesses in texas?,"pd.merge(category[category['category_name']=='restaurant'], business[business['state']=='texas'], on='business_id')['name'].nunique()"
"what is the total count of bars in ""dallas"" that have a rating of 3.5 or above?","(business.loc[(business['city'] == 'dallas') & (business['rating'] > 3.5)].merge(category.loc[category['category_name'] == 'bars'], on ='business_id')['name'].nunique())"
what is the count of bars in dallas which have a rating of at least 3.5?,"(business.loc[(business['city'] == 'dallas') & (business['rating'] > 3.5)].merge(category.loc[category['category_name'] == 'bars'], on ='business_id')['name'].nunique())"
"how many guests wrote reviews for the restaurant ""texas de brazil"" in dallas, texas?","business.merge(category, on='business_id').merge(review, on='business_id').merge(user, on='user_id').loc[(business['city']=='dallas') & (business['name']=='texas de brazil') & (business['state']=='texas') & (category['category_name']=='restaurant')]['name'].nunique()"
"how many individuals reviewed ""bistro di napoli"" in 2015?","pd.merge(pd.merge(review, business.loc[lambda x: x['name']=='bistro di napoli', ['business_id']], on='business_id'), user, on='user_id').loc[lambda x: (x['year']==2015), 'name'].nunique()"
how many restaurants are there in the hazelwood neighborhood of dallas?,"pd.merge(pd.merge(category[category['category_name'] == 'restaurant'], business[business['city'] == 'dallas'], on='business_id'), neighbourhood[neighbourhood['neighbourhood_name'] == 'hazelwood'], on='business_id')['name'].nunique()"
how many starbucks are there in dallas texas?,"business.loc[(business['city']=='dallas') & (business['name']=='starbucks') & (business['state']=='texas'), 'business_id'].nunique()"
"what is the number of reviews for "" acacia cafe ""?","business.loc[lambda x: x['name']=='acacia cafe', 'review_count']"
"determine the average number of checkins in restaurant ""barrio cafe"" per day.","checkin.merge(category.merge(business[business['name']=='barrio cafe'].reset_index().rename(columns={'business_id':'id'}), on='id'), on='business_id').loc[lambda x: x['category_name']=='restaurant'].groupby('day')['count'].mean()"
"how many business establishments are there in the ""stone meadows"" neighbourhood in madison?",neighbourhood.merge(business)['name'].loc[(neighbourhood['neighbourhood_name']=='stone meadows') & (business['city']=='madison')].nunique()
how many reviews have adrienne written ?,"pd.merge(user[user['name']=='adrienne'], review, on='user_id')['text'].nunique()"
how many reviews did michelle write in the month of march in the year 2014?,"review.merge(user.loc[lambda x: x['name']=='michelle'], on='user_id').loc[lambda x: (x['month']=='march') & (x['year']==2014), 'text'].nunique()"
determine the number of businesses reviewed by michelle in the year 2010.,"pd.merge(pd.merge(review, business, on='business_id'), user, on='user_id').loc[lambda x: (x['year']==2010) & (x['name_y']=='michelle'), 'name_x'].nunique()"
give me the count of businesses that christine reviewed in the year 2010 in san diego.,"review.merge(business, on='business_id').merge(user, on='user_id').loc[(business['city'] == ""san diego"") & (review['year'] == 2010 ) & (user['name'] == 'christine'), 'name'].nunique()"
how many target stores are there in los angeles?,"business.loc[(business['city']=='los angeles') & (business['name']=='target'), 'business_id'].nunique()"
how many users gave a positive review for irish pub in dallas?,"business.merge(category).merge(review).merge(user).loc[lambda x: (x['city']=='dallas') &(x['category_name']=='irish pub'),'name'].nunique()"
"what is the number of reviewers who reviewed the restaurant "" vintner grill "" in the year 2010?","(business.query('name == ""vintner grill""').merge(category.query('category_name == ""category_category_name0""'), on='business_id').merge(review.query('year == 2010'), on='business_id').merge(user, on='user_id').loc[:, 'name'].nunique())"
please provide me with the number of reviews about businesses located in south summerlin neighbourhood.,"pd.merge(pd.merge(neighbourhood[neighbourhood['neighbourhood_name']=='south summerlin'], business, on='business_id'), review, on='business_id')['text'].nunique()"
determine the count of users called michelle,(user['name'] == 'michelle').sum()
please provide me with the count of businesses that are restaurants.,"business.loc[business['business_id'].isin(category.loc[category['category_name']=='restaurant', 'business_id'].tolist()), 'name'].nunique()"
please list the cities that have the panda express.,"business.loc[lambda x: x['name']=='panda express', 'city'].nunique()"
please provide me with the count of tips authored by michelle.,"tip.merge(user.loc[user['name']=='michelle', 'user_id']).nunique()['text']"
"how many checkins were made in the "" brighton heights "" neighborhood?","pd.merge(pd.merge(checkin, business, on='business_id'), neighbourhood, on='business_id').loc[lambda x: x['neighbourhood_name']==""brighton heights"", 'count'].sum()"
compute the number of reviews written in march.,"review.loc[lambda x: x['month']=='march', 'text'].nunique()"
provide with the count of tips created in each month.,tip.groupby('month')['text'].nunique()
how many neighborhoods have a business with a rating of 5 in madison?,"pd.merge(neighbourhood, business, on='business_id').loc[(lambda x: (x['city']=='madison') & (x['rating']==5))(business), 'neighbourhood_name'].nunique()"
i need all moroccan restaurants in texas.,"(pd.merge(pd.merge(category[category['category_name']=='moroccan'], business[business['state']=='texas'], on='business_id'), category[category['category_name']=='restaurant'], on='business_id'))['name']"
which business has the highest number of checkins,"checkin.merge(business, on='business_id').groupby('name').count().sort_values('count', ascending=false).head(1).index[0]"
madison has the neighbourhood which has the highest number of businesses.,"neighbourhood.merge(business.query('city == ""madison""'), on='business_id').groupby('neighbourhood_name').agg({'name': 'nunique'}).sort_values('name', ascending=false).head(1).index[0]"
retrieve all mexican restaurants in dallas with at least 3.5 stars.,"pd.merge(pd.merge(category.loc[lambda x: x['category_name']=='mexican'], business.loc[lambda x: (x['city']=='dallas') & (x['rating']>3.5)], on='business_id'), category.loc[lambda x: x['category_name']=='restaurant'], on='business_id')['name']"
find all mexican restaurants in dallas that scored above 3.5 on yelp.,"pd.merge(pd.merge(category.loc[lambda x: x['category_name']=='mexican'], business.loc[lambda x: (x['city']=='dallas') & (x['rating']>3.5)], on='business_id'), category.loc[lambda x: x['category_name']=='restaurant'], on='business_id')['name']"
"list the names of restaurants that feature valet parking in dallas, tx.","pd.merge(pd.merge(category.loc[lambda x: x['category_name'] == 'valet service'], business), category.loc[lambda x: x['category_name'] == 'restaurant'], on='business_id').loc[lambda x: (x['city']=='dallas')&(x['state']=='texas'), 'name']"
determine the italian restaurants in the meadowood neighborhood of madison.,"pd.merge(pd.merge(pd.merge(category.loc[lambda x: x['category_name']=='italian'], category.loc[lambda x: x['category_name']=='restaurant'], on='business_id'), business.loc[lambda x: x['city']=='madison'], on='business_id'), neighbourhood.loc[lambda x: x['neighbourhood_name']=='meadowood'], on='business_id')['name']"
provide me with the bars that meet the criteria specified in the query.,"pd.merge(business.loc[(business['city']=='los angeles') & (business['rating']>3) & (business['review_count']>30)], category.loc[category['category_name']=='bars'], on='business_id')['name']"
what is the total number of egyptian restaurants in edinburgh?,"pd.merge(pd.merge(category[category['category_name']=='restaurant'], business[business['city']=='edinburgh'], on='business_id'), category[category['category_name']=='egyptian'], on='business_id')['name'].nunique()"
find users whose review ratings are below 3,"user.merge(review, on='user_id').groupby('name').filter(lambda x: x['rating'].mean() < 3)['name']"
please produce the name of the business with the most review count for april.,"review.merge(business, on='business_id').loc[lambda x: x['month']=='april'].groupby('name').agg({'text': pd.series.nunique}).sort_values('text', ascending=false).reset_index().iloc[0]['name']"
retrieve the business with the most number of categories,"business.merge(category, on='business_id').groupby('name').agg(num_categories=('category_name', 'nunique')).sort_values('num_categories', ascending=false).reset_index().iloc[0]['name']"
please return the homepage of pvldb to me.,"journal.loc[lambda x: x['name']=='pvldb', 'homepage']"
"please provide me with the homepage corresponding to "" h. v. jagadish "".","author.loc[author['name'] == ""h. v. jagadish"", 'homepage']"
"provide me with an abstract for the paper ""making database systems usable"".","publication.loc[lambda x: x['title']=='making database systems usable', 'abstract']"
"please return the year of "" making database systems usable ""","publication.loc[lambda x: x['title']=='making database systems usable', 'year']"
"what's the year of publication of the book ""making database systems usable"".","publication.loc[lambda x: x['title']=='making database systems usable', 'year']"
please return me the articles after year 2000.,"publication.loc[lambda x: x['year']>2000, 'title']"
provide me with the homepage of the vldb conference.,"conference.loc[lambda x: x['name']=='vldb', 'homepage']"
find all of the keywords that appear frequently.,keyword['keyword']
return me the names of organizations.,organization['name']
"please return the names of the organizations located in ""north america""","organization.loc[lambda x: x['continent']=='north america', 'name']"
please fetch the homepage of the university of michigan.,"organization.loc[lambda x: x['name']=='university of michigan', 'homepage']"
"provide me the identifications of references of the books  ""making database systems usable""","publication.loc[lambda x: x['title']=='making database systems usable', 'reference_num']"
"could you find me the references of the book ""making database systems usable""?","publication.loc[lambda x: x['title']=='making database systems usable', 'reference_num']"
"provide me with the citations of the book "" making database systems usable "".","publication.loc[lambda x: x['title'] == 'making database systems usable', 'citation_num']"
"provide me the citations of "" making database systems usable"".","publication.loc[lambda x: x['title'] == 'making database systems usable', 'citation_num']"
please provide me with the titles of articles having more than 200 citations.,"publication.loc[lambda x: x['citation_num'] > 200, 'title']"
provide me the names of authors whose papers appeared in pvldb 2010.,"pd.merge(pd.merge(pd.merge(publication, journal, on='jid'), writes, on='pid'), author, on='aid').loc[(lambda x: (x['name']=='pvldb') & (x['year']==2010))(journal), 'name']"
find the authors who published their papers in pvldb after 2010.,"pd.merge(pd.merge(pd.merge(author, writes, on='aid'), publication, on='pid'), journal, on='jid').loc[lambda x: (x['name']=='pvldb') & (x['year']>2010), 'name']"
get me the names of authors who have papers in the vldb conference in 2002.,"publication[publication['year'] == 2002].merge(conference[conference['name'] == 'vldb'], on='cid').merge(writes, on='pid').merge(author, on='aid')['name'].unique()"
please provide me with the list of authors who have papers in vldb conference before 2002.,"pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[(lambda x: (x['name'] == 'vldb') & (x['year'] < 2002)), 'name_y']"
list the authors who published papers in vldb conference before 2002 after 1995.,"publication.merge(conference, left_on='cid', right_on='cid').merge(writes, left_on='pid', right_on='pid').merge(author, left_on='aid', right_on='aid').loc[(publication['year'] < 2002) & (publication['year'] > 1995) & (conference['name'] == 'vldb')]['name'].unique()"
please list the area of pvldb,"pd.merge(pd.merge(domain, domain_journal, on='did'), journal, on='jid').loc[lambda x: x['name']=='pvldb', 'name']"
please provide me with the names of the authors who make papers in pvldb.,"author.loc[author['aid'].isin(writes.merge(publication, on='pid').merge(journal.query(""name=='pvldb'""), on='jid')['aid']), 'name']"
"please provide me with the organization "" h. v. jagadish "" is in.","organization.loc[organization['oid'].isin(author.loc[author['name']==""h. v. jagadish"", 'oid']), 'name']"
provide me with the titles of all conferences that have papers authored by h. v. jagadish.,"pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='h. v. jagadish', 'name']"
"return the names of the journals, which contain papers written by "" h. v. jagadish "" .","pd.merge(pd.merge(pd.merge(publication, journal, on='jid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='h. v. jagadish', 'name']"
"please provide me with the domain where "" h. v. jagadish "" is focused.","pd.merge(pd.merge(domain_author, author, on='aid'), domain, on='did').loc[lambda x: x['name']=='h. v. jagadish', 'name']"
"return me the names of the authors of the book ""making database systems usable""","pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid').loc[lambda x: x['title']=='making database systems usable', 'name']"
"please provide me with the names of conferences that published ""making database systems usable"".","conference.merge(publication[publication['title']=='making database systems usable'], on='cid')['name']"
tell me the names of papers by h. v. jagadish.,"pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid').loc[lambda x: x['name']=='h. v. jagadish', 'title']"
please write the names of the papers that were presented in the conference vldb.,"pd.merge(publication, conference, on='cid').loc[lambda x: x['name']=='vldb', 'title']"
return me the papers on pvldb.,"pd.merge(publication, journal, on='jid').loc[lambda x: x['name']=='pvldb', 'title']"
generate the papers on pvldb after 2000.,"pd.merge(publication, journal, on='jid').loc[lambda x: (x['name']=='pvldb') & (x['year']>2000), 'title']"
provide me with the published papers on vldb conference after 2000.,"pd.merge(publication, conference, on='cid').loc[(lambda x: x['name']=='vldb')(conference) & (lambda x: x['year']>2000)(publication), 'title']"
please provide me with the list of papers authored by h. v. jagadish on pvldb.,"pd.merge(pd.merge(pd.merge(publication, journal, on='jid'), writes, on='pid'), author, on='aid').loc[(lambda x: x['name_x']=='h. v. jagadish')&(lambda x: x['name_y']=='pvldb'), 'title']"
please find the list of papers authored by h. v. jagadish on vldb conference.,"pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[lambda x: (x['name_x']=='h. v. jagadish') & (x['name_y']=='vldb'), 'title']"
"please supply me with the titles of the papers that have been published by ""h. v. jagadish"" after 2000.","pd.merge(pd.merge(author[author['name']=='h. v. jagadish'], writes, on='aid'), publication[publication['year']>2000], on='pid')['title']"
"please provide me with the papers written by "" h. v. jagadish "" on pvldb after the year 2000.","publication.merge(journal, on='jid').merge(writes, on='pid').merge(author, on='aid').loc[(lambda x: (x.name == 'h. v. jagadish') & (x.year > 2000) & (x['name_y'] == 'pvldb')), 'title']"
"provide me with the papers authored by "" h. v. jagadish "" after 2000, in the vldb conference.","pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[lambda x: (x['name_x']=='h. v. jagadish') & (x['name_y']=='vldb') & (x['year']>2000), 'title']"
provide me with the area occupied by the vldb conference.,"pd.merge(pd.merge(domain_conference, conference, on='cid'), domain, on='did').loc[lambda x: x['name']=='vldb', 'name']"
please return me the names of authors who have published papers in the vldb conference.,"pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='vldb', 'name']"
please provide me with the keywords picked from the databases area,"domain_keyword.merge(keyword, on='kid').merge(domain.loc[lambda x: x['name']=='databases'], on='did')['keyword']"
"return me all the papers, which contain the keyword "" natural language ""","publication_keyword.merge(keyword.query('keyword == ""natural language""'), on='kid').merge(publication, on='pid')['title']"
"please return me the main keywords of ""making database systems usable""","pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid').loc[lambda x: x['title']=='making database systems usable', 'keyword']"
return me the keywords related to  h. v. jagadish .,"pd.merge(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='h. v. jagadish', 'keyword']"
please list me the tags pertaining to vldb conference.,"(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), conference, on='cid').loc[lambda x: x['name'] == 'vldb', 'keyword'])"
please provide me with the keywords in pvldb.,"pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), journal, on='jid').loc[lambda x: x['name']=='pvldb', 'keyword']"
please list out all the keywords that are used in the papers published by the university of michigan.,"pd.merge(pd.merge(pd.merge(pd.merge(organization, author, on='oid'), writes, on='aid'), publication, on='pid'), pd.merge(publication_keyword, keyword, on='kid'), on='pid').loc[lambda x: x['name']=='university of michigan', 'keyword']"
"please provide me with the titles of papers written by "" h. v. jagadish "" containing the words ""user study"".","publication_keyword.merge(keyword).merge(publication).merge(writes).merge(author).query('name==""h. v. jagadish"" and keyword==""user study""')['title']"
"return me the papers in pvldb containing keyword "" keyword search"".","pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), journal, on='jid').loc[lambda x: (x['name']=='pvldb') & (x['keyword']=='keyword search'), 'title']"
"find me the papers published by vldb conference containing the word ""information retrieval"".","pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), conference, on='cid').loc[(lambda x: (x['name']=='vldb') & (x['keyword']=='information retrieval')), 'title']"
"find the names of authors who have published papers containing the word "" relational database"".","pd.merge(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[lambda x: x['keyword']=='relational database', 'name']"
identify all the organizations in the databases area.,"pd.merge(pd.merge(pd.merge(domain_author, author, on='aid'), domain, on='did'), organization, on='oid').loc[lambda x: x['name']=='databases', 'name']"
"return me all organizations located in ""north america"" in the ""databases"" area.","pd.merge(pd.merge(pd.merge(domain_author, author, on='aid'), domain, on='did'), organization, on='oid').loc[(lambda x: x['name_x']=='databases') & (lambda x: x['continent']=='north america'), 'name_y']"
"please return me the names of researchers in ""university of michigan"".","author.loc[lambda x: pd.merge(x, organization.loc[lambda y: y['name']==""university of michigan"", 'oid'], on='oid'), 'name']"
please list me the names of researchers working in area databases in university of michigan.,"pd.merge(pd.merge(pd.merge(domain_author, domain, on='did'), author, on='aid'), organization, on='oid').loc[(lambda x: x['name_x']=='databases') & (lambda x: x['name_y']=='university of michigan'), 'name_z']"
please provide me a list of all the papers published by the university of michigan.,"pd.merge(pd.merge(pd.merge(author, organization, on='oid'), writes, on='aid'), publication, on='pid').loc[lambda x: x['name']=='university of michigan', 'title']"
"please display all the papers from the university of michigan, after year 2000.","pd.merge(pd.merge(pd.merge(organization.loc[lambda x: x['name']=='university of michigan'], author, on='oid'), writes, on='aid'), publication.loc[lambda x: x['year']>2000], on='pid')['title']"
return me all the papers from the vldb conference in the university of michigan.,"pd.merge(pd.merge(pd.merge(pd.merge(organization.loc[lambda x: x['name']=='university of michigan'], author, on='oid'), writes, on='aid'), publication, on='pid'), conference.loc[lambda x: x['name']=='vldb'], on='cid')['title']"
"please provide me with a list of all papers published in the pvldb of the department of computer science and engineering, university of michigan.","pd.merge(pd.merge(pd.merge(pd.merge(organization.loc[lambda x: x['name']=='university of michigan'], author, on='oid'), writes, on='aid'), publication, on='pid'), journal, on='jid').loc[lambda x: (x['name']=='pvldb') & (x['name_y']=='university of michigan'), 'title']"
"give me all the papers in pvldb published after 2000 in ""university of michigan"".","pd.merge(pd.merge(pd.merge(pd.merge(organization, author, on='oid'), writes, on='aid'), publication, on='pid'), journal, on='jid').loc[lambda x: (x['name_x']=='university of michigan') & (x['name_y']=='pvldb') & (x['year']>2000), 'title']"
please provide me with the paper in databases area that was cited by more than 200 articles.,"pd.merge(pd.merge(domain, domain_publication, on='did'), publication, on='pid').loc[lambda x: (x['name']=='databases')&(x['citation_num']>200), 'title']"
please furnish me the bibliographic details for the paper in pvldb that has the widest citation count.,"pd.merge(publication, journal, on='jid').loc[lambda x: (x['name']=='pvldb') & (x['citation_num']>200), 'title']"
please find the name(s) of the paper(s) that received more than 200 citations from the vldb conference.,"pd.merge(publication, conference).loc[lambda x: (x['name']=='vldb') & (x['citation_num']>200), 'title']"
find the paper written by h. v. jagadish that is cited more than 200 times.,"pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid').loc[(lambda x: x['name']=='h. v. jagadish')(author) & (lambda x: x['citation_num']>200)(publication), 'title']"
please provide me with the papers written by h. v. jagadish that have more than 200 citations in pvldb.,"pd.merge(pd.merge(pd.merge(publication, journal, on='jid'), writes, on='pid'), author, on='aid').loc[lambda x: (x['name']=='h. v. jagadish') & (x['citation_num']>200) & (x['name_y']=='pvldb'), 'title']"
find papers by h. v. jagadish about vldb and their total number of citations.,"pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[(lambda x: x['name_x']=='h. v. jagadish') & (lambda x: x['name_y']=='vldb') & (lambda x: x['citation_num']>200), 'title']"
retrieve the title of the paper that is cited more than 200 times after 2000.,"publication.loc[(publication['citation_num']>200) & (publication['year']>2000), 'title']"
please return me the paper published after 2000 in database management area having more than 200 citations.,"pd.merge(pd.merge(domain, domain_publication, on='did'), publication, on='pid').loc[lambda x: (x['name']=='databases') & (x['citation_num']>200) & (x['year']>2000), 'title']"
give me the title of papers that are published after 2000 and have more than 200 citations in pvldb.,"publication.merge(journal[journal['name']=='pvldb'], on='jid').query('citation_num > 200 & year > 2000')['title']"
"return me the paper published in the vldb conference after 2000, with the highest number of citations.","pd.merge(publication, conference, on='cid').loc[(lambda x: x['name']=='vldb') & (x['citation_num']>200) & (x['year']>2000)].title"
kindly return me the count of conferences that has included a paper authored by h. v. jagadish.,"pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='h. v. jagadish', 'name'].nunique()"
"please provide me with the fields of journals where papers by "" h. v. jagadish "" were cited.","publication.merge(journal, on='jid').merge(writes, on='pid').merge(author, on='aid').loc[lambda x: x['name']=='h. v. jagadish', 'name'].nunique()"
"please return me the count of papers written by "" h. v. jagadish "" in each year.","pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid').loc[lambda x: x['name']=='h. v. jagadish'].groupby('year')['title'].nunique()"
"give me the count of people who have written the book ""making database systems usable"".","pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid').loc[lambda x: x['title']=='making database systems usable', 'name'].nunique()"
"please provide me with the count of citations for ""making database systems usable"" in each given year.",publication.loc[lambda x: x['title'] == 'making database systems usable'].groupby('year').agg({'citation_num': 'sum'})
"determine the number of citations to the book ""making database systems usable"" prior to 2010.","pd.merge(pd.merge(publication, cite, left_on='pid', right_on='cited')['citing'], publication, on='pid').loc[lambda x: (x['title_x']=='making database systems usable') & (x['year_y']<2010), 'title_y'].nunique()"
"please provide me with the number of papers written by "" h. v. jagadish "".","pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid').loc[lambda x: x['name']=='h. v. jagadish', 'title'].nunique()"
return me the number of papers appearing in the vldb conference.,"pd.merge(publication, conference, on='cid').loc[lambda x: x['name']=='vldb', 'title'].nunique()"
please provide me with the number of papers on pvldb,"pd.merge(publication, journal, on='jid').loc[lambda x: x['name']=='pvldb', 'title'].nunique()"
please provide me with the count of papers after year 2000.,"publication.loc[lambda x: x['year'] > 2000, 'title'].nunique()"
please return me the number of papers written on the pvldb database after 2000.,"pd.merge(journal[journal['name']=='pvldb'], publication[publication['year']>2000], on='jid')['title'].nunique()"
please provide me with the number of papers presented at vldb conference after 2000.,"pd.merge(publication.loc[lambda x: x['year']>2000], conference.loc[lambda x: x['name']=='vldb'], on='cid')['title'].nunique()"
"provide me with the count of papers published by "" h. v. jagadish "" on pvldb .","pd.merge(pd.merge(pd.merge(author, writes, on='aid'), publication, on='pid'), journal, on='jid').loc[(lambda x: (x['name_x']=='h. v. jagadish') & (x['name_y']=='pvldb')), 'title'].nunique()"
please provide me with the count of papers authored by h. v. jagadish which were published in vldb conference.,"pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[lambda x: (x['name_x']=='h. v. jagadish') & (x['name_y']=='vldb'), 'title'].nunique()"
please give me the number of papers written by h. v. jagadish after 2000.,"pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid').loc[(lambda x: (x['name']=='h. v. jagadish') & (x['year']>2000)), 'title'].nunique()"
"please provide me with the count of papers authored by ""h. v. jagadish"" in the year 2000 and later.","pd.merge(pd.merge(pd.merge(publication, journal, on='jid'), writes, on='pid'), author, on='aid').loc[lambda x: (x['name']=='h. v. jagadish') & (x['year']>2000) & (x['name_y']=='pvldb'), 'title'].nunique()"
return me the number of keywords,keyword['keyword'].nunique()
return me the number of keywords in the databases area.,"pd.merge(pd.merge(domain, domain_keyword, on='did'), keyword, on='kid').loc[lambda x: x['name']=='databases', 'keyword'].nunique()"
"please return me the number of papers containing the keyword "" natural language""","publication_keyword.merge(keyword).merge(publication)[lambda x: x['keyword'] == ""natural language""]['title'].nunique()"
"please provide me with the keywords concerning database systems in "" making database systems usable "" .","pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid').loc[lambda x: x['title']=='making database systems usable', 'keyword'].nunique()"
print out the keywords related to h.v. jagadish,"pd.merge(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='h. v. jagadish', 'keyword'].nunique()"
please provide me with the count of keywords utilized in papers contributed to the vldb conference.,"pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), conference, on='cid').loc[lambda x: x['name']=='vldb', 'keyword'].nunique()"
please provide me with the total count of keywords in pvldb.,"pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), journal, on='jid').loc[lambda x: x['name']=='pvldb', 'keyword'].nunique()"
please provide me with the count of keywords in the papers authored by the university of michigan.,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(organization, author, on='oid'), writes, on='aid'), publication, on='pid'), publication_keyword, on='pid'), keyword, on='kid').loc[lambda x: x['name']=='university of michigan', 'keyword'].nunique()"
please provide me with the count of research papers containing keyword 'user study' written by h. v. jagadish.,"pd.merge(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[(lambda x: x['name']=='h. v. jagadish') & (lambda x: x['keyword']=='user study'), 'title'].nunique()"
"please provide me with the number of papers in vldb conference containing keyword "" information retrieval ""","(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'),publication, on='pid'),conference, on='cid').loc[lambda x: x['name']=='vldb' and x['keyword']=='information retrieval', 'title'].nunique())"
"obtain the number of authors who have published papers containing the term ""relational database"".","pd.merge(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[lambda x: x['keyword'] == 'relational database', 'name'].nunique()"
"please provide me with the total count of papers involving keyword ""natural language""","pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid').loc[lambda x: x['keyword']=='natural language', 'citation_num'].sum()"
could you provide me with the count of organizations?,organization['name'].nunique()
"return me the number of organizations in "" north america "".","organization.loc[lambda x: x['continent']=='north america', 'name'].nunique()"
provide me the number of databases in organizations that i am able to use.,"(pd.merge(pd.merge(pd.merge(domain_author, author, on='aid'), domain, on='did'), organization, on='oid').loc[lambda x: x['name']=='databases', 'name'].nunique())"
"please provide me with the count of organizations located in ""north america"" in the ""databases"" area.","pd.merge(pd.merge(pd.merge(domain_author, author, on='aid'), domain, on='did'), organization, on='oid').loc[lambda x: (x['name']=='databases') & (x['continent']=='north america'), 'name'].nunique()"
give the number of papers published in the university of michigan.,"pd.merge(pd.merge(pd.merge(organization, author, on='oid'), writes, on='aid'), publication, on='pid').loc[lambda x: x['name']=='university of michigan', 'title'].nunique()"
"please provide me with the number of papers that correspond to ""university of michigan"" in the databases area.","pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(domain_author, author, on='aid'), domain, on='did'), domain_publication, on='did'), organization, on='oid'), publication, on='pid').loc[lambda x: (x['name_x']=='databases') & (x['name_y']=='university of michigan'), 'title'].nunique()"
"please provide me with the total number of papers after 2000 in the ""university of michigan"".","pd.merge(pd.merge(pd.merge(organization.query('name == ""university of michigan""'), author, on='oid'), writes, on='aid'), publication, on='pid').loc[lambda x: x['year'] > 2000, 'title'].nunique()"
please give me the count of papers presented in vldb 2008 held at university of michigan.,"pd.merge(pd.merge(pd.merge(pd.merge(organization, author, on='oid'), writes, on='aid'), publication, on='pid'), conference, on='cid').loc[(lambda x: (x['name_x'] == 'university of michigan') & (x['name_y'] == 'vldb')), 'title'].nunique()"
"please give me the number of papers in pvldb published after 2000 in "" university of michigan "".","pd.merge(pd.merge(pd.merge(pd.merge(organization.rename(columns={'oid':'oid_x', 'name':'name_x'}), author, on='oid_x'), writes, on='aid'), publication, on='pid'), journal, on='jid').loc[lambda x: (x['name']=='pvldb') & (x['name_x']=='university of michigan') & (x['year']>2000), 'title'].nunique()"
please provide me with the total count of citations for all the papers published in university of michigan.,"pd.merge(pd.merge(pd.merge(organization, author, on='oid'), writes, on='aid'), publication, on='pid').loc[lambda x: x['name']=='university of michigan', 'citation_num'].sum()"
please return me the count of researchers in the university of michigan.,"pd.merge(organization.loc[lambda x: x['name']=='university of michigan'], author, on='oid')['name'].nunique()"
please provide me with the count of researchers in databases area in michigan university.,"pd.merge(pd.merge(pd.merge(domain_author, author, on='aid'), domain, on='did'), organization, on='oid').loc[(lambda x: (x['name_x']=='databases') & (x['name_y']=='university of michigan')), 'name'].nunique()"
please provide the number of authors who have submitted papers in the pvldb journal.,"pd.merge(pd.merge(pd.merge(publication, journal[journal['name']=='pvldb'], on='jid'), writes, on='pid'), author, on='aid')['name'].nunique()"
what did the vldb conference consist of?,"pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='vldb', 'name'].nunique()"
return me the count of papers published on pvldb before 2000.,"pd.merge(journal.loc[lambda x: x['name']=='pvldb'], publication.loc[lambda x: x['year']<2000], on='jid')['title'].nunique()"
find the count of papers published in the vldb conference before 2000.,"pd.merge(publication[publication['year']<2000], conference[conference['name']=='vldb'], on='cid')['title'].nunique()"
please provide me the count of all the citations present in pvldb papers.,"pd.merge(publication, journal, on='jid').loc[lambda x: x['name']=='pvldb', 'citation_num'].sum()"
please provide me with the citations of each paper in pvldb,"pd.merge(journal[journal['name']=='pvldb'], publication, on='jid')['citation_num']"
determine the total count of citations of papers in pvldb published in 2005.,"pd.merge(publication, journal, on='jid').loc[(lambda x: x['name']==""pvldb"")&(lambda x: x['year']==2005), 'citation_num'].sum()"
return me the total count of citations of pvldb papers published before 2005.,"pd.merge(publication[publication['year'] < 2005], journal[journal['name'] == 'pvldb'], on='jid').citation_num.sum()"
please provide me with the total citations of papers in pvldb in each year.,"pd.merge(publication, journal, on='jid').loc[lambda x: x['name']=='pvldb'].groupby('year')['citation_num'].sum()"
provide the number of papers published in pvldb in each year.,publication.merge(journal).loc[lambda x: x['name']=='pvldb'].groupby('year')['title'].nunique()
please provide me with the count of citations for all the papers in the vldb conference.,"pd.merge(publication, conference, on='cid').loc[lambda x: x['name']=='vldb', 'citation_num'].sum()"
please provide me the citations of the papers published in vldb conference.,"pd.merge(publication, conference, on='cid').loc[lambda x: x['name']=='vldb', 'citation_num']"
please provide me with the citation count of papers published in the vldb conference in the year 2005.,"pd.merge(publication, conference, on='cid').loc[(publication['year']==2005) & (conference['name']=='vldb'), 'citation_num'].sum()"
please calculate the total number of citations of papers published in vldb conference before 2005.,"pd.merge(publication.loc[lambda x: x['year']<2005], conference.loc[lambda x: x['name']=='vldb'], on='cid')['citation_num'].sum()"
please return me the total number of citations of papers in the vldb conference in each year.,"pd.merge(publication, conference, on='cid').loc[lambda x: x['name']=='vldb'].groupby('year')['citation_num'].sum()"
"fetch me the authors who have cooperated with both the individuals "" h. v. jagadish "" and "" divesh srivastava "".","pd.merge(pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[(lambda x: x['name_x']=='h. v. jagadish')(lambda x: x['name_y']=='divesh srivastava')]['name_y']"
"give me the authors who collaborated with "" h. v. jagadish "" after 2000.","pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), pd.merge(writes, author, on='aid'), on='pid').loc[lambda x: (x['name_x']=='h. v. jagadish') & (x['year']>2000), 'name_y']"
provide me with the titles of the papers that were written by h. v. jagadish and divesh srivastava.,"pd.merge(pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[(lambda x: x['name_x']=='h. v. jagadish') & (lambda x: x['name_y']=='divesh srivastava'), 'title']"
"please provide me with the list of papers written by "" h. v. jagadish "" and "" yunyao li "" after 2005.","pd.merge(pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[(lambda x: x['name_x'] == 'h. v. jagadish' and x['name_y'] == 'yunyao li' and x['year'] > 2005), 'title']"
"kindly return the titles of papers authored by "" h. v. jagadish "" and "" yunyao li "" in pvldb.","pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(publication, journal, on='jid'), writes, on='pid'), writes, on='pid'), author, left_on='aid_x', right_on='aid'), author, left_on='aid_y', right_on='aid').loc[(lambda x: x['name_x']=='yunyao li') & (lambda x: x['name_y']=='h. v. jagadish') & (lambda x: x['name']=='pvldb'), 'title']"
give me the titles of papers written by h. v. jagadish and yunyao li on pvldb after 2005.,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(publication, journal, on='jid'), writes, on='pid'), writes, on='pid'), author, left_on='aid_y', right_on='aid'), author, left_on='aid_x', right_on='aid').loc[(lambda x: (x['name_x']=='yunyao li') & (x['name_y']=='h. v. jagadish') & (x['name']=='pvldb') & (x['year'] > 2005))]"
allow me to retrieve the names of all the researchers who cooperated with h. v. jagadish.,"pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), pd.merge(writes, author, on='aid', suffixes=('_1','_2')), on='pid').loc[lambda x: x['name_1']=='h. v. jagadish', 'name_2']"
"could you provide me with the citation of papers written by "" h. v. jagadish "" and "" divesh srivastava "" before the year 2000?","pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), pd.merge(writes, author, on='aid'), on='pid').loc[(lambda x: x['name_x']=='h. v. jagadish')&(lambda x: x['name_y']=='divesh srivastava')&(lambda x: x['year']<2000), 'title']"
how can i get the papers that h v jagadish have cited?,"pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(publication, cite,left_on='pid', right_on='citing'), publication,left_on='cited', right_on='pid',suffixes=['_citing', '_cited']), writes,on='pid', suffixes=['_citing', '_writter']), writes,on='pid', suffixes=['_cited', '_writter']), author,left_on='aid_citing', right_on='aid').loc[lambda x: x['name'] == 'h. v. jagadish', 'name']"
"could i get the number of papers written by "" h. v. jagadish "" and "" divesh srivastava ""?","pd.merge(pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[(lambda x: x['name_x']=='h. v. jagadish')&(lambda x: x['name_y']=='divesh srivastava'), 'title'].nunique()"
which of the following authors' written papers were collected before 2000?,"pd.merge(pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[(lambda x: (x['name_x']=='h. v. jagadish') & (x['name_y']=='divesh srivastava') & (x['year']<2000)), 'title'].nunique()"
"please return me the counts of papers authored by h. v. jagadish, yunyao li, and cong yu.","(author.loc[author['name']=='cong yu', 'aid'].pipe(lambda x: writes.loc[writes['aid'].isin(x), 'pid']).pipe(lambda x: publication.loc[publication['pid'].isin(x), 'pid']).pipe(lambda x: writes.loc[writes['pid'].isin(x), 'aid']).loc[lambda x: x.isin(author.loc[author['name'].isin([""h. v. jagadish"", ""yunyao li""]), 'aid'])].pipe(lambda x: writes.loc[writes['aid'].isin(x), 'pid']).pipe(lambda x: publication.loc[publication['pid'].isin(x), 'title']).nunique())"
please list out the names of authors who have collaborated with jitendra malik.,"pd.merge(pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name_y']=='h. v. jagadish', 'name_x'].nunique()"
"please guide me to the count of authors who cited the papers authored by "" h. v. jagadish "".","publication.merge(cite, left_on='pid', right_on='citing').merge(publication, left_on='cited', right_on='pid').merge(writes, on='pid').merge(writes, suffixes=('_left', '_right'), on='pid').merge(author, left_on='aid_left', right_on='aid').merge(author, left_on='aid_right', right_on='aid').loc[lambda x: x['name_y'] == 'h. v. jagadish']['name_x'].nunique()"
please provide me with the papers that have more than 200 citations written by h. v. jagadish and divesh srivastava.,"(pd.merge(pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), writes, on='pid'), author, on='aid').query('name_x == ""h. v. jagadish"" and name_y == ""divesh srivastava"" and citation_num > 200').loc[:, 'title'])"
"provide me with the highest count of papers written by an author containing keyword "" relational database "".","author.loc[pd.merge(writes, publication_keyword).merge(keyword.loc[lambda x: x['keyword']=='relational database'], left_on='kid', right_on='kid').merge(publication, on='pid').groupby('name')['title'].nunique().nlargest(1).index[0]]"
"provide me the conference that has the highest number of papers containing keyword "" relational database "".","(pd.merge(pd.merge(pd.merge(publication_keyword, keyword.loc[lambda x: x['keyword']=='relational database'], on='kid'), publication, on='pid'), conference, on='cid').groupby('name')['title'].nunique().sort_values(ascending=false).index[0])"
"please inform me of the conference which is most cited in papers containing the term "" relational database "".","(pd.merge(pd.merge(pd.merge(publication_keyword, keyword.loc[lambda x: x['keyword']=='relational database'], on='kid'), publication, on='pid'), conference, on='cid').groupby('name')['title'].nunique().sort_values(ascending=false).index[0])"
"provide me with the name of the journal containing the highest number of papers whose contents contain the word "" relational database "".","journal.loc[pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), journal, on='jid').loc[lambda x: x['keyword'] == 'relational database'].groupby('name').agg(unique_titles=('title', 'nunique')).sort_values('unique_titles', ascending=false).reset_index().iloc[0]['name']]"
"which journal contains the highest number of articles containing keyword "" relational database ""?","journal.loc[pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), journal, on='jid').loc[lambda x: x['keyword'] == 'relational database'].groupby('name').agg(unique_titles=('title', 'nunique')).sort_values('unique_titles', ascending=false).reset_index().iloc[0]['name']]"
give me the keywords that have been the most recurring ones in papers that have been published at vldb conferences.,"publication_keyword.merge(keyword, on='kid').merge(publication, on='pid').merge(conference, on='cid').loc[lambda x: x['name'] == 'vldb'].groupby('keyword')['title'].nunique().sort_values(ascending=false).index[0]"
please provide me with the titles of keywords that are shown in the highest number of papers in pvldb.,"pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), journal, on='jid').loc[lambda x: x['name']=='pvldb'].groupby('keyword')['title'].nunique().sort_values(ascending=false).index[0]"
"please provide me with the title of keyword that was present in the most number of papers by "" h. v. jagadish "".","pd.merge(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='h. v. jagadish'].groupby('keyword').agg(num_titles=('title', pd.series.nunique)).sort_values('num_titles', ascending=false).iloc[0].name"
identify the name of the author with the largest number of total citations in the papers published by the university of michigan.,"(pd.merge(pd.merge(pd.merge(author, writes, on='aid'),publication,on='pid'),organization,on='oid').query('name_x == ""university of michigan""').groupby('name_y').agg(total_citations=('citation_num', 'sum')).reset_index().sort_values('total_citations', ascending=false).iloc[0][0])"
"please provide me with the author in the "" university of michigan "" whose papers in databases area have the most total citations.","author.merge(writes.merge(publication.merge(domain_publication.merge(domain), on='did'), on='pid'), on='aid').merge(organization, on='oid').loc[lambda x: (x['name_x'] == 'databases') & (x['name_y'] == 'university of michigan')].groupby('name')['citation_num'].sum().sort_values(ascending=false).head(1)"
"please provide me with the names of papers written by "" h. v. jagadish "" and "" divesh srivastava "" and the count of citations.","pd.merge(pd.merge(pd.merge(writes, author, on='aid'), publication, on='pid'), pd.merge(writes, author, on='aid')).loc[(lambda x: x['name_x']=='divesh srivastava')&(lambda x: x['name_y']=='h. v. jagadish'), 'title'].sort_values('citation_num', ascending=false).iloc[0]"
allow me to retrieve those conferences which published more than 10 papers authored by dr. h. v. jagadish.,"author.query('name == ""h. v. jagadish""').merge(writes, on='aid').merge(publication, on='pid').merge(conference, on='cid').groupby('name').filter(lambda x: x['title'].nunique() > 10)['name']"
please provide me with the conference which has the most published papers authored by h. v. jagadish.,"author.loc[lambda x: x['name']=='h. v. jagadish'].groupby(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid')['name_x']).agg({'title': 'nunique'}).sort_values('title', ascending=false).reset_index().iloc[0, 0]"
list the journals that published more than 10 papers authored by h. v. jagadish.,"pd.merge(pd.merge(pd.merge(publication, journal, on='jid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='h. v. jagadish'].groupby('name').filter(lambda x: x.groupby('name').apply(lambda x: x['title'].nunique())).groupby('name')['name'].count() > 10"
please provide me with the title of journal that has the highest number of papers written by h. v. jagadish.,"pd.merge(pd.merge(pd.merge(publication, writes, on='pid'),pd.merge(journal, publication, on='jid'),on='pid'),pd.merge(author, writes, on='aid'),on='aid').loc[lambda x: x['name']=='h. v. jagadish'].groupby('name')['name'].count().sort_values(ascending=false).head(1)"
please provide me with the research paper that received the most citations.,"publication.sort_values('citation_num', ascending=false).iloc[0]['title']"
please identify the name of the paper in the databases area with the maximum citation.,"pd.merge(pd.merge(domain, domain_publication, on='did'), publication, on='pid').loc[lambda x: x['name']=='databases'].sort_values('citation_num', ascending=false).iloc[0]['title']"
please provide me with the paper in pvldb with most number of citations.,"publication.merge(journal[journal['name']=='pvldb'], on='jid').sort_values('citation_num', ascending=false)['title'].iloc[0]"
please find the paper in vldb conference with the most citations.,"pd.merge(publication, conference, on='cid').loc[lambda x: x['name']=='vldb'].sort_values('citation_num', ascending=false).iloc[0]['title']"
"please provide me with the paper authored by "" h. v. jagadish "" with the most citations.","author.loc[lambda x: x['name']=='h. v. jagadish'].merge(writes, on='aid').merge(publication, on='pid').sort_values('citation_num', ascending=false).iloc[0]['title']"
please get me that paper published in the year 2000 that has the most citations.,"publication.loc[lambda x: x['year']>2000].sort_values('citation_num', ascending=false).iloc[0]['title']"
please provide me with the paper published after 2000 in the databases area with the most citations..,"pd.merge(pd.merge(domain, domain_publication, on='did'), publication, on='pid').loc[(domain['name'] == ""databases"") & (publication['year'] > 2000)].nlargest(1, 'citation_num')['title']"
please return me the paper with the most citations published in pvldb after 2000.,"publication.merge(journal[journal['name']=='pvldb'], on='jid').loc[lambda x: x['year'] > 2000].sort_values('citation_num', ascending=false).iloc[0]['title']"
please provide me with the paper published in the year 2000 in the vldb conference that received the most citations.,"pd.merge(publication, conference, on='cid').loc[(lambda x: x['name']=='vldb')&(lambda x: x['year']>2000), 'title'].sort_values(ascending=false).iloc[0]"
please provide me with the names of the authors who contributed more than 10 papers to pvldb.,"author.loc[pd.merge(pd.merge(pd.merge(publication, journal[journal['name'] == 'pvldb'], on='jid'), writes, on='pid'), author, on='aid').groupby('name').filter(lambda x: x['title'].nunique() > 10)['aid'].drop_duplicates()]"
give me the names of the authors who have published the highest number of papers in the protein data bank.,"(author.merge(writes, on='aid').merge(publication, on='pid').merge(journal.loc[lambda x: x['name']=='pvldb'], on='jid').groupby('name')['title'].nunique().sort_values(ascending=false).index[0])"
"identify the authors who have more than 10 papers containing the keyword "" relational database"".","pd.merge(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[lambda x: x['keyword']=='relational database'].groupby('name').filter(lambda x: x['title'].nunique() > 10).sort_values('name')['name']"
"provide me with the conferences which have more than 60 papers containing keyword "" relational database "".","pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), conference, on='cid').loc[lambda x: x['keyword']=='relational database'].groupby('name').filter(lambda x: x['title'].nunique() > 60)['name']"
"please return me the journals that publish more than 60 papers containing the keyword "" relational database "" .","pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), journal, on='jid').loc[lambda x: x['keyword']=='relational database'].groupby('name').filter(lambda x: x['title'].nunique() > 60).drop_duplicates('name')[['name']]"
"please return me the keywords, which are present in more than 100 papers in the vldb conference.","pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), conference, on='cid').loc[lambda x: x['name']=='vldb'].groupby('keyword').filter(lambda x: x['title'].nunique() > 100)['keyword'].unique()"
provide me the keywords which are contained by more 100 papers in pvldb,"pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), journal, on='jid').loc[lambda x: x['name']=='pvldb'].groupby('keyword').filter(lambda x: x['title'].nunique() > 100)['keyword']"
"provide me the names of keywords, which have been appeared in more than 10 papers of ""h.v. jagadish"".","pd.merge(pd.merge(pd.merge(pd.merge(publication_keyword, keyword, on='kid'), publication, on='pid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='h. v. jagadish'].groupby('keyword').filter(lambda x: x['title'].nunique() > 10)['keyword'].unique()"
give me the names of authors who have written more than 10 papers in the vldb conference.,"author.loc[lambda x: x['aid'].isin(writes.merge(publication).loc[lambda y: y['cid'].isin(conference.loc[lambda z: z['name']=='vldb', 'cid'])]['aid'].unique())].groupby('name').apply(lambda x: x.merge(writes.merge(publication))).loc[lambda x: x['title'].nunique()>10, 'name']"
please provide me with the author with the highest number of papers presented in the vldb conference.,"pd.merge(pd.merge(pd.merge(publication, conference, on='cid'), writes, on='pid'), author, on='aid').loc[lambda x: x['name']=='vldb'].groupby('name')['name'].count().sort_values(ascending=false).index[0]"
"please return the name of author in the ""university of michigan"" with 5000 or more citations.","author.merge(writes).merge(publication).merge(organization).query('name == ""university of michigan""').groupby('name').filter(lambda x: x['citation_num'].sum() > 5000)['name']"
"return me the author in the ""university of michigan"" in databases area whose papers have more than 5000 total citations.","(pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(domain_author, author, on='aid'), domain, on='did'), organization, on=['oid', 'aid']), writes, on='aid'), publication, on='pid').loc[(lambda x: x['name_x']=='databases')&(lambda x: x['name_y']=='university of michigan'), 'name'].groupby('name').agg(citation_sum=('citation_num', 'sum')).loc[lambda x: x['citation_sum']>5000].reset_index()['name'])"
"which year was the movie "" the imitation game "" made?","movie.loc[movie['title'] == 'the imitation game', 'release_year']"
"what is the date of the production of the movie ""the imitation game""?","movie.loc[movie['title'] == 'the imitation game', 'release_year']"
when was the birth year of benedict timothy carlton cumberbatch?,"actor.loc[lambda x: x['name']=='benedict cumberbatch', 'birth_year']"
"what is the austrian nationality of the actress "" christoph waltz ""?","actor.loc[actor['name'] == 'christoph waltz', 'nationality']"
"what is the country of origin of the actor "" christoph waltz "" ?","actor.loc[actor['name'] == 'christoph waltz', 'nationality']"
provide me with a list of all the movies produced in 2015.,"movie.loc[movie['release_year']==2015, 'title']"
"determine the names of actors born in "" tehran ""","actor.loc[lambda x: x['birth_city']=='tehran', 'name']"
"determine the names of the actors who were born in the iranian capital, tehran.","actor.loc[lambda x: x['birth_city']=='tehran', 'name']"
what are the names of actors that were born in tehran?,"actor.loc[lambda x: x['birth_city']=='tehran', 'name']"
retrieve the list of actors from afghanistan.,"actor.loc[lambda x: x['nationality']=='afghanistan', 'name']"
retrieve the names of all actors from the country of afghanistan.,"actor.loc[lambda x: x['nationality']=='afghanistan', 'name']"
what all are the names of actors from afghanistan?,"actor.loc[lambda x: x['nationality']=='afghanistan', 'name']"
list the names of movie actors who were born in 1984.,"actor.loc[lambda x: x['birth_year']==1984, 'name']"
when was kevin spacey born?,"actor.loc[lambda x: x['name']=='actor_name0', 'birth_year']"
what is the year in which kevin spacey was born?,"actor.loc[lambda x: x['name']=='actor_name0', 'birth_year']"
"where is the birthplace for "" kevin spacey ""?","director.loc[lambda x: x['name']=='director_name0', 'birth_city']"
what is the place of birth of kevin spacey?,"director.loc[lambda x: x['name']=='director_name0', 'birth_city']"
"what was the budget of the movie "" finding nemo ""","movie.loc[movie['title']=='finding nemo', 'budget']"
find all movies directed by steven spielberg after 2006,"movie.loc[(movie.merge(directed_by, on='mid').merge(director, on='did').loc[(director['name'] == 'steven spielberg') & (movie['release_year'] > 2006), 'mid'],'title')]"
"which director was behind the movie, "" james bond ""?","pd.merge(pd.merge(director, directed_by, on='did'), movie, on='msid').loc[lambda x: x['title']=='james bond', 'name']"
who directed the james bond movie?,"pd.merge(pd.merge(director, directed_by, on='did'), movie, on='msid').loc[lambda x: x['title']=='james bond', 'name']"
"retrieve the identities of directors of movies released under the name ""james bond"".","pd.merge(pd.merge(director, directed_by, on='did'), movie, on='msid').loc[lambda x: x['title']=='james bond', 'name']"
"return the titles of movies that the actor "" alan turing "" played in.","pd.merge(pd.merge(cast.loc[cast['role']=='alan turing'], actor, on='aid'), movie.loc[movie['title']=='the imitation game'], left_on='msid', right_on='mid')['name']"
"who played "" alan turing "" in the movie "" the imitation game ""?","pd.merge(pd.merge(cast.loc[cast['role']=='alan turing'], actor, on='aid'), movie.loc[movie['title']=='the imitation game'], left_on='msid', right_on='mid')['name']"
"retrieve the identities of the actors that were portrayed in the role of alan turing in the movie "" the imitation game "".","pd.merge(pd.merge(cast.loc[cast['role']=='alan turing'], actor, on='aid'), movie.loc[movie['title']=='the imitation game'], left_on='msid', right_on='mid')['name']"
"who is the actor whose role was portrayed by benedict cumberbatch in the motion picture "" the imitation game ""?","pd.merge(pd.merge(cast.loc[cast['role']=='alan turing'], actor, on='aid'), movie.loc[movie['title']=='the imitation game'], left_on='msid', right_on='mid')['name']"
"who is the actor portraying alan turing in the movie "" the imitation game ""?","pd.merge(pd.merge(cast.loc[cast['role']=='alan turing'], actor, on='aid'), movie.loc[movie['title']=='the imitation game'], left_on='msid', right_on='mid')['name']"
what is the genre of the movie jurassic park?,"genre.merge(classification, on='gid').merge(movie, on='mid').query('title == ""jurassic park""')['genre']"
"identify the film director of the movie joy, which was released on march 4, 2015.","pd.merge(pd.merge(director, directed_by, on='did'), movie, left_on='msid', right_on='mid').loc[lambda x: (x['release_year']==2015) & (x['title']=='joy'), 'name']"
find all movies written 'by' matt damon.,"written_by.merge(movie, left_on='msid', right_on='mid').merge(writer, on='wid').loc[lambda x: x['name']=='matt damon', 'title']"
"find all movies authored by "" woody allen "" and produced.","pd.merge(pd.merge(pd.merge(pd.merge(movie, made_by, left_on='mid', right_on='msid'), producer, on='pid'), written_by, on='msid'), writer, on='wid').loc[(lambda x: (x['name_x'] == 'woody allen') & (x['name_y'] == 'woody allen')), 'title']"
retrieve all movies in which robin wright was the lead actress.,"pd.merge(pd.merge(cast, actor, on='aid'), movie, on='mid').loc[lambda x: x['name'] == 'robin wright', 'title']"
provide the list of movies that feature robin wright.,"pd.merge(pd.merge(cast, actor, on='aid'), movie, on='mid').loc[lambda x: x['name'] == 'robin wright', 'title']"
"retrieve all the movies in which "" robin wright "" appears.","pd.merge(pd.merge(cast, actor, on='aid'), movie, on='mid').loc[lambda x: x['name'] == 'robin wright', 'title']"
give me the budget of the movie juno from 2007.,"movie.loc[(movie['release_year']==2007) & (movie['title']=='juno'), 'budget']"
determine the titles of all sci-fi items produced in the year 2010.,"pd.merge(pd.merge(genre.loc[lambda x: x['genre']=='sci-fi', ['gid']], classification, on='gid'), movie.loc[lambda x: x['release_year']==2010, ['mid', 'title']], left_on='msid', right_on='mid')['title']"
please give me the names of all the sci-fi movies that were released in 2010.,"pd.merge(pd.merge(genre.loc[lambda x: x['genre']=='sci-fi', ['gid']], classification, on='gid'), movie.loc[lambda x: x['release_year']==2010, ['mid', 'title']], left_on='msid', right_on='mid')['title']"
"obtain the names of all actors that were born after 1980 in "" austin ""","actor.loc[(actor['birth_city'] == 'austin') & (actor['birth_year'] > 1980), 'name']"
"who are all the actors born in "" austin "" after 1980 ?","actor.loc[(actor['birth_city'] == 'austin') & (actor['birth_year'] > 1980), 'name']"
"return me the names of movies directed by directors born in ""los angeles""","pd.merge(pd.merge(director, directed_by, on='did'), movie, on='mid').loc[lambda x: x['birth_city']=='los angeles', 'title']"
"retrieve all actors who were born in "" new york city "" in 1984.","actor.loc[(actor['birth_city']=='new york city') & (actor['birth_year']==1984), 'name']"
retrieve all movies about nuclear weapons,"pd.merge(pd.merge(tags, keyword, left_on='kid', right_on='id'), movie, left_on='msid', right_on='mid').loc[lambda x: x['keyword']=='nuclear weapons', 'title']"
list the movies that are closely related to nuclear weapons.,"pd.merge(pd.merge(tags, keyword, left_on='kid', right_on='id'), movie, left_on='msid', right_on='mid').loc[lambda x: x['keyword']=='nuclear weapons', 'title']"
which movies had alfred hitchcock as the director of the film?,"movie.merge(directed_by.merge(director[lambda x: x['name'] == 'alfred hitchcock'], on='did'), on='mid')['title']"
what is the total number of movies directed by asghar farradi and featuring taraneh alidoosti?,"(pd.merge(pd.merge(pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid'), directed_by, on='msid'), director, on='did').loc[lambda x: (x['name_x']=='taraneh alidoosti') & (x['name_y']=='asghar farhadi'), 'title'])"
"please produce a list of all movies directed by "" asghar farhadi "" in which "" taraneh alidoosti "" has starred.","(pd.merge(pd.merge(pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid'), directed_by, on='msid'), director, on='did').loc[lambda x: (x['name_x']=='taraneh alidoosti') & (x['name_y']=='asghar farhadi'), 'title'])"
"retrieve the names of tv series created by "" shonda rhimes "".","tv_series.merge(made_by.merge(producer.loc[producer['name']=='shonda rhimes'], on='pid'), on='sid')['title']"
which actress plays the role of olivia pope in the series scandal?,"pd.merge(pd.merge(cast, actor, on='aid'), tv_series, left_on='msid', right_on='sid').loc[(lambda x: (x['role']=='olivia pope') & (x['title']=='scandal')), 'name']"
"obtain the name of the writer of the movie ""the truman show"".","pd.merge(pd.merge(written_by, movie, left_on='msid', right_on='mid'), writer, on='wid').loc[lambda x: x['title']=='the truman show', 'name']"
what movie was authored by andrew niccol?,"pd.merge(pd.merge(written_by, movie, left_on='msid', right_on='mid'), writer, on='wid').loc[lambda x: x['title']=='the truman show', 'name']"
"what are the titles of series featuring "" scott foley "" ?","pd.merge(pd.merge(cast, actor, on='aid'), tv_series, left_on='msid', right_on='sid').loc[lambda x: x['name']=='scott foley', 'title']"
which series include scott foley as an actor?,"pd.merge(pd.merge(cast, actor, on='aid'), tv_series, left_on='msid', right_on='sid').loc[lambda x: x['name']=='scott foley', 'title']"
"retrieve the names of directors of all movies that feature "" kate winslet""","pd.merge(pd.merge(pd.merge(pd.merge(cast, actor, on='aid'), movie, left_on='msid_x', right_on='mid'), directed_by, on='msid_y'), director, on='did').loc[lambda x: x['name_x']=='kate winslet', 'name_y']"
"collect the producers of films in which ""kate winslet"" has acted.","pd.merge(pd.merge(pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid'), made_by, on='msid'), producer, on='pid').loc[lambda x: x['name_y']=='kate winslet', 'name_x']"
"who is the director of the tv series "" house of cards "" from 2013?","pd.merge(pd.merge(director, directed_by, on='did'), tv_series, left_on='msid', right_on='sid').loc[lambda x: (x['release_year']==2013) & (x['title']=='house of cards'), 'name']"
list down all the female actors of austin,"actor.loc[(actor['birth_city']=='austin')&(actor['gender']=='female'), 'name']"
retrieve the names of all actors born after 1980 in italy.,"actor.loc[(actor['birth_year'] > 1980) & (actor['nationality'] == 'italy'), 'name']"
"produce a list of the actresses whose birth year is after 1980 and who are from ""new york city"".","actor.loc[(actor['birth_city']=='new york city') & (actor['birth_year']>1980) & (actor['gender']=='female'), 'name']"
"find the names of female actors that have acted in the movie ""saving private ryan"".","pd.merge(pd.merge(cast, actor, on='aid'), movie, left_on='msid', right_on='mid').loc[(lambda x: x['gender']=='female')&(lambda x: x['title']=='saving private ryan'), 'name']"
list the names of directors who are from afghanistan.,"director.loc[lambda x: x['nationality']=='afghanistan', 'name']"
"figure out which actors were cast in the movie "" camp x-ray ""","pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid').loc[lambda x: x['title']=='camp x-ray', 'name']"
get a list of all actors from canada who starred in james bond movies.,"pd.merge(pd.merge(cast, actor, on='aid'), movie, left_on='msid', right_on='mid').loc[lambda x: (x['nationality']=='canada') & (x['title']=='james bond'), 'name']"
find the title for every film in which rowan atkinson acted as mr.bean.,"pd.merge(pd.merge(actor.loc[lambda x: x['name']=='rowan atkinson'], cast.loc[lambda x: x['role']=='mr. bean'], on='aid'), movie, on='mid')['title']"
"please give me the name and birthplace of the person who played the director of "" the past "".","director.merge(directed_by, on='did').merge(movie, left_on='msid', right_on='mid').loc[lambda x: x['title']=='the past', 'birth_city']"
look up the names of the persons who portrayed the role of mr. bean.,"pd.merge(cast.loc[lambda x: x['role']=='mr. bean'], actor, on='aid')['name']"
"what genres of movie were directed by "" asghar farhadi """,genre.loc[lambda x: x['gid'].isin(classification.loc[lambda x: x['msid'].isin(movie.loc[lambda x: x['mid'].isin(directed_by.loc[lambda x: x['did'].isin(director.loc[lambda x: x['name']=='asghar farhadi']['did'])]['msid'])]['msid'])]['gid'])]['genre']
"what movie had the character "" daffy duck ""","pd.merge(movie, cast, left_on='mid', right_on='msid').loc[lambda x: x['role']=='daffy duck', 'title']"
"what were some of the major roles in the movie "" daddy long legs ""?","pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid').loc[lambda x: x['title']=='daddy long legs', 'role']"
return the titles of all movies about the nuclear weapons,"tags.merge(keyword.loc[lambda x: x['keyword']=='nuclear weapons'], left_on='kid', right_on='id').merge(directed_by.merge(director)['name'])"
"how many movies have "" jennifer aniston "" acted after the year 2010?","pd.merge(pd.merge(cast, actor, on='aid'), movie, left_on='msid', right_on='mid').loc[lambda x: (x['name'] == 'jennifer aniston') & (x['release_year'] > 2010), 'title'].nunique()"
"get the total number of actors who acted in the movie "" saving private ryan "".","pd.merge(pd.merge(actor, cast, on='aid'), movie, on='mid').loc[lambda x: x['title']=='saving private ryan', 'name'].nunique()"
"how many actors were in the movie "" saving private ryan ""?","pd.merge(pd.merge(actor, cast, on='aid'), movie, on='mid').loc[lambda x: x['title']=='saving private ryan', 'name'].nunique()"
how many movies did steven spielberg direct?,"pd.merge(pd.merge(director, directed_by, on='did'), movie, on='mid').loc[lambda x: x['name']=='steven spielberg', 'title'].nunique()"
what is the number of movies produced in the year 2013?,"movie.loc[lambda x: x['release_year']==2013, 'title'].nunique()"
what is the count of movies produced in 2013?,"movie.loc[lambda x: x['release_year']==2013, 'title'].nunique()"
what is the count of movies directed by woody allen per year?,"movie.merge(directed_by.merge(director[director.name == 'woody allen'], on='did'), on='mid').groupby('release_year').agg({'title': pd.series.nunique}).reset_index().rename(columns={'title': 'count'}).loc[:, ['count', 'release_year']]"
which movies did shahab hosseini act in?,"pd.merge(pd.merge(cast, actor, on='aid'), movie, on='mid').loc[lambda x: x['name']=='shahab hosseini', 'title'].nunique()"
what is the number of movies that shahab hosseini acted in?,"pd.merge(pd.merge(cast, actor, on='aid'), movie, on='mid').loc[lambda x: x['name']=='shahab hosseini', 'title'].nunique()"
"what is the total count of movies that star "" shahab hosseini ""?","pd.merge(pd.merge(cast, actor, on='aid'), movie, on='mid').loc[lambda x: x['name']=='shahab hosseini', 'title'].nunique()"
determine the actual count of movies acted by shahab hosseini,"pd.merge(pd.merge(cast, actor, on='aid'), movie, on='mid').loc[lambda x: x['name']=='shahab hosseini', 'title'].nunique()"
how many actors were born in los angeles after 2000?,"actor.loc[(actor['birth_city'] == 'los angeles') & (actor['birth_year'] > 2000), 'name'].nunique()"
"what is the number of movies that "" humphrey bogart "" acted in before the 1942?","pd.merge(pd.merge(actor, cast, on='aid'), movie, left_on='msid', right_on='mid').loc[(lambda x: (x['name']=='humphrey bogart') & (x['release_year']<1942)), 'title'].nunique()"
how many movies does actor brad pitt act per year?,"pd.merge(pd.merge(cast, actor, on='aid'), movie, on='mid').loc[lambda x: x['name']=='brad pitt'].groupby('release_year')['title'].nunique()"
how many movies pertaining to the iraq war were produced in 2015?,"pd.merge(pd.merge(tags, keyword, left_on='kid', right_on='id'), movie, left_on='msid', right_on='mid').loc[(lambda x: x['keyword']=='iraq war')&(lambda x: x['release_year']==2015), 'title'].nunique()"
"how many movies did "" quentin tarantino "" direct after 2010, inclusive?","pd.merge(pd.merge(director.loc[lambda x: x['name']=='quentin tarantino'], directed_by, on='did'), movie, left_on='msid', right_on='mid').loc[lambda x: x['release_year']>2010, 'title'].nunique()"
what is the count of movies directed by quentin tarantino prior to 2010?,"pd.merge(pd.merge(director, directed_by, on='did'), movie, on='msid').loc[(director['name']=='quentin tarantino') & (movie['release_year'] < 2010), 'title'].nunique()"
"provide me the counts of movies directed by quentin tarantino in ""before 2002"" and ""after 2010"".","pd.merge(pd.merge(pd.merge(pd.merge(director[director['name']=='quentin tarantino'], directed_by, on='did'), movie[movie['release_year'].between(2003, 2009)], on='mid'), made_by, on='msid'), producer, on='pid')['title'].nunique()"
"what is the count of female actors born in "" new york city "" after 1980?","actor.loc[(actor['birth_city']=='new york city') & (actor['birth_year']>1980) & (actor['gender']=='female'), 'name'].nunique()"
"what is the count of actors who played in "" jim jarmusch "" movies from iran?","pd.merge(pd.merge(pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid'), directed_by, on='msid'), director, on='did').loc[(lambda x: (x['nationality']=='iran') & (x['name']=='jim jarmusch')), 'name'].nunique()"
"how many chinese actors appeared the "" rush hour 3""?","pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid').loc[lambda x: (x['nationality']=='china') & (x['title']=='rush hour 3'), 'name'].nunique()"
"find all movies that have actors "" woody strode "" and "" jason robards ""","pd.merge(pd.merge(pd.merge(pd.merge(cast, actor.rename(columns={'name': 'name1'}), on='aid'),cast.rename(columns={'msid': 'mid'}), on='mid'),movie, on='mid'), actor.rename(columns={'name': 'name2'}), on='aid')[lambda x: (x['name1']=='woody strode') & (x['name2']=='jason robards')]['title']"
"retrieve the movies that feature ""woody strode"" and ""jason robards""","pd.merge(pd.merge(pd.merge(pd.merge(cast, actor.rename(columns={'name': 'name1'}), on='aid'),cast.rename(columns={'msid': 'mid'}), on='mid'),movie, on='mid'), actor.rename(columns={'name': 'name2'}), on='aid')[lambda x: (x['name1']=='woody strode') & (x['name2']=='jason robards')]['title']"
"retrieve all movies that have both "" woody strode "" and "" jason robards ""","pd.merge(pd.merge(pd.merge(pd.merge(cast, actor.rename(columns={'name': 'name1'}), on='aid'),cast.rename(columns={'msid': 'mid'}), on='mid'),movie, on='mid'), actor.rename(columns={'name': 'name2'}), on='aid')[lambda x: (x['name1']=='woody strode') & (x['name2']=='jason robards')]['title']"
"retrieve all movies in which "" jason robards "" and "" woody strode "" appear.","pd.merge(pd.merge(pd.merge(pd.merge(cast, actor.rename(columns={'name': 'name1'}), on='aid'),cast.rename(columns={'msid': 'mid'}), on='mid'),movie, on='mid'), actor.rename(columns={'name': 'name2'}), on='aid')[lambda x: (x['name1']=='woody strode') & (x['name2']=='jason robards')]['title']"
give the titles of movies in which actors tom hanks acted.,"pd.merge(pd.merge(pd.merge(pd.merge(cast, actor.rename(columns={'aid': 'aid_1', 'name': 'name_1'}), on='aid'),movie.rename(columns={'mid': 'msid'}), on='msid'),cast.rename(columns={'aid': 'aid_2'}), on='msid'),actor.rename(columns={'aid': 'aid_2', 'name': 'name_2'}), on='aid_2').loc[lambda x: x['name_2']=='tom hanks', 'name_1']"
what are the names of movies that were directed by him?,"pd.merge(pd.merge(pd.merge(director, directed_by, on='did'), movie, left_on='msid', right_on='mid'), movie, left_on=['did', 'msid'], right_on=['did', 'mid']).loc[lambda x: x['title_x'] == 'revolutionary road', 'title_y']"
find the movie that is classified in the highest number of genres.,"movie.merge(classification.merge(genre, on='gid'), on='mid').groupby('title').apply(lambda df: df['genre'].nunique()).sort_values(ascending=false).head(1).index[0]"
which movie has the most number of actors from china?,"pd.merge(pd.merge(cast, actor, on='aid'), movie, on='msid').loc[lambda x: x['nationality']=='china'].groupby('title').apply(lambda x: x['name'].nunique()).sort_values(ascending=false).head(1).index.values[0]"
"find the performers who undertook major roles in the latest movie by "" quentin tarantino ""","pd.merge(pd.merge(pd.merge(pd.merge(actor, _cast, on='aid'), movie, on='mid'), directed_by, on='msid'), director.loc[lambda x: x['name']=='quentin tarantino'], on='did').sort_values('release_year', ascending=false).iloc[0]['name']"
fetch the title of latest movie by quentin tarantino along with the budget and name.,"movie.merge(directed_by.merge(director.loc[lambda x: x['name'] == 'quentin tarantino'], on='did'), on='mid').sort_values('release_year', ascending=false).iloc[0][['budget', 'title']]"
what is the latest movie by jim jarmusch?,"movie.loc[movie.merge(directed_by.merge(director.loc[lambda x: x['name']=='jim jarmusch'], on='did'), on='mid').sort_values('release_year', ascending=false).iloc[0]['mid']]['title']"
who has worked with the highest number of directors?,"pd.merge(pd.merge(pd.merge(pd.merge(director, directed_by, on='did'), movie, on='mid'), made_by, on='mid'), producer, on='pid').groupby('name').agg({'director_name': 'nunique'}).sort_values('director_name', ascending=false).iloc[0].name"
"retrieve the title of the latest movie in which "" gabriele ferzetti "" appeared.","pd.merge(pd.merge(actor, cast, on='aid'), movie, on='mid').loc[lambda x: x['name']=='gabriele ferzetti'].sort_values('release_year', ascending=false).iloc[0]['name']"
what number of kitchens are possessed by buttercup in san francisco?,"pd.merge(restaurant, location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['name']=='buttercup kitchen')].shape[0]"
give the total number of chinese restaurants in bay area.,"pd.merge(restaurant, geographic, on='city_name').loc[(lambda x: (x['region'] == 'bay area') & (x['food_type'] == 'chinese'))(restaurant), :].shape[0]"
how many chinese food restaurants are there in the bay area?,"pd.merge(restaurant, geographic, on='city_name').loc[(lambda x: (x['region'] == 'bay area') & (x['food_type'] == 'chinese'))(restaurant), :].shape[0]"
how many chinese restaurants are there in the bay area?,"pd.merge(restaurant, geographic, on='city_name').loc[(lambda x: (x['region'] == 'bay area') & (x['food_type'] == 'chinese'))(restaurant), :].shape[0]"
what is the count of jamerican restaurants in santa cruz county?,"len(pd.merge(restaurant.loc[lambda x: x['name']=='jamerican cuisine'], geographic.loc[lambda x: x['county']=='santa cruz county'], on='city_name'))"
where is jamerican cuisine located?,"location.merge(restaurant[restaurant['name']=='jamerican cuisine'], on='restaurant_id')[['house_number', 'name']]"
is there a french restaurant that is rated as the best in san francisco?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
what is the title of the best french restaurant in san francisco?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
where can one find the best french food in san francisco?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
please provide me with the address of the best french restaurant in san francisco.,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
where is the best french spoken in san francisco?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
what french restaurant offers the best food in san francisco?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
which restaurant in san francisco is the best for french food?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
please recommend me the best french restaurant in san francisco.,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
please provide me with the names of the restaurants serving french cuisine in san francisco.,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
which restaurants in san francisco are specialized in french cuisine?,"restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french') & (x['rating']==restaurant.merge(location, on='id').loc[lambda x: (x['city_name']=='san francisco') & (x['food_type']=='french'), 'rating'].max()), ['house_number', 'name']]"
where is denny in the san francisco area?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: x['region']=='bay area') & (lambda x: x['name']=='denny'), ['house_number', 'name']]"
"return the names of good restaurants in bethel island,","pd.merge(restaurant, location, on='restaurant_id').loc[(location['city_name']=='bethel island') & (location['street_name']=='bethel island rd') & (restaurant['rating']>2.5), ['house_number', 'name']]"
return some restaurants located on bethel island rd in the neighborhood of bethel island.,"pd.merge(restaurant, location, on='restaurant_id').loc[(location['city_name']=='bethel island') & (location['street_name']=='bethel island rd') & (restaurant['rating']>2.5), ['house_number', 'name']]"
can you identify a good restaurant in bethel island rd in bethel island?,"pd.merge(restaurant, location, on='restaurant_id').loc[(location['city_name']=='bethel island') & (location['street_name']=='bethel island rd') & (restaurant['rating']>2.5), ['house_number', 'name']]"
please suggest a good restaurant on bethel island rd in bethel island.,"pd.merge(restaurant, location, on='restaurant_id').loc[(location['city_name']=='bethel island') & (location['street_name']=='bethel island rd') & (restaurant['rating']>2.5), ['house_number', 'name']]"
find me a restaurant in alameda.,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: x['city_name']=='alameda', ['house_number', 'name']]"
"provide me the name, full address, and telephone number of a restaurant located in alameda.","pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: x['city_name']=='alameda', ['house_number', 'name']]"
where can i find restaurants in alameda?,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: x['city_name']=='alameda', ['house_number', 'name']]"
where is a famous restaurant in alameda ?,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: x['city_name']=='alameda', ['house_number', 'name']]"
give me a list of all restaurants in alameda.,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: x['city_name']=='alameda', ['house_number', 'name']]"
please provide me with the names and locations of restaurants that serve french cuisine.,"pd.merge(restaurant.loc[(restaurant['food_type']=='french') & (restaurant['rating']>2.5), ['id', 'name']],location[['restaurant_id', 'house_number']], left_on='id', right_on='restaurant_id')[['house_number', 'name']]"
where are good places for enjoying french food,"pd.merge(restaurant.loc[(restaurant['food_type']=='french') & (restaurant['rating']>2.5), ['id', 'name']],location[['restaurant_id', 'house_number']], left_on='id', right_on='restaurant_id')[['house_number', 'name']]"
how many french restaurants are there in palo alto?,"pd.merge(restaurant, location, on='id').loc[lambda x: (x['city_name']=='palo alto') & (x['food_type']=='french'), :].shape[0]"
how many french restaurants are located in palo alto?,"pd.merge(restaurant, location, on='id').loc[lambda x: (x['city_name']=='palo alto') & (x['food_type']=='french'), :].shape[0]"
what percentage (%) of places are french in palo alto?,"pd.merge(restaurant, location, on='id').loc[lambda x: (x['city_name']=='palo alto') & (x['food_type']=='french'), :].shape[0]"
what is the count of italian restaurants located in yolo county?,"pd.merge(restaurant, geographic, on='city_name').loc[lambda x: (x['county']=='yolo county') & (x['food_type']=='italian'), :].shape[0]"
where can i eat french food in mountain view?,"pd.merge(restaurant.loc[lambda x: x['food_type']=='french'], location.loc[lambda x: x['city_name']=='mountain view'], on='restaurant_id')[['house_number', 'name']]"
how many denny's restaurants are located in the bay area?,"pd.merge(restaurant, geographic, on='city_name').loc[(lambda x: x['region']=='bay area')&(lambda x: x['name']=='denny')].shape[0]"
give the name of a restaurant close to alameda.,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: (x['city_name']=='alameda') & (x['rating'] > 2.5), ['house_number', 'name']]"
which restaurants are recommended in alameda?,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: (x['city_name']=='alameda') & (x['rating'] > 2.5), ['house_number', 'name']]"
find the name of a good restaurant in alameda .,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: (x['city_name']=='alameda') & (x['rating'] > 2.5), ['house_number', 'name']]"
please provide me with a list of good restaurants located in alameda.,"pd.merge(restaurant, location, on='restaurant_id').loc[lambda x: (x['city_name']=='alameda') & (x['rating'] > 2.5), ['house_number', 'name']]"
what restaurant on buchanan street in san francisco has good arabic food?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where are some good arabic books in san francisco on buchanan ?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where is a good restaurant serving arabic food on buchanan street in san francisco?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
what are some good places for arabic on buchanan street in san francisco?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
please list out some good arabic restaurants in san francisco.,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
give me some restaurants that serve arabic food on buchanan street in san francisco.,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
can you recommend a restaurant in buchanan street in san francisco which serves arabic food?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where are good places for arabic food on buchanan in san francisco?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where can i find a arabic restaurant on buchanan street in san francisco?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
please suggest me good arabic restaurants at buchanan street in san francisco.,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where can i find a arabic restaurant on buchanan in san francisco?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
give me a restaurant on buchanan street in san francisco that serves good arabic food.,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
provide me a restaurant on buchanan street in san francisco for eating arabic food?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where is there a restaurant on buchanan in san francisco that serves good arabic food?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
give me a list of good restaurants for arabic food located on buchanan street in sf.,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
could you please suggest me some places in san francisco for practicing arabic?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where can i find good arabic food on buchanan street in san francisco?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where can i find a good place to eat in san francisco?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where are some good restaurants for arabic cuisine to be found on buchanan street in san francisco?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
what are few good places for arabic on pbs in sf?,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
give me names of restaurants that are located on buchanan street in sf.,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
provide me some popular arabic books on bancroft in san francisco.,"(pd.merge(restaurant, location, on='restaurant_id').loc[(lambda x: x['city_name'] == 'san francisco') & (lambda x: x['street_name'] == 'buchanan') & (lambda x: x['food_type'] == 'arabic') & (lambda x: x['rating'] > 2.5), ['house_number', 'name']])"
where could i consume french cuisine in the san francisco bay area?,"pd.merge(pd.merge(restaurant[restaurant['food_type'] == 'french'], geographic[geographic['region'] == 'bay area'], on='city_name'), location, on='restaurant_id')[['house_number', 'name']]"
please provide me with a list of restaurants on bethel island rd in bethel island.,"pd.merge(restaurant, location, on='restaurant_id').query('city_name==""bethel island"" and street_name==""bethel island rd""')[['house_number', 'name']]"
please tell which restaurant is located on the corner of bethel island rd and bethel island st in bethel island.,"pd.merge(restaurant, location, on='restaurant_id').query('city_name==""bethel island"" and street_name==""bethel island rd""')[['house_number', 'name']]"
find me the location of a restaurant on bethel island road.,"pd.merge(restaurant, location, on='restaurant_id').query('city_name==""bethel island"" and street_name==""bethel island rd""')[['house_number', 'name']]"
which restaurants can be found on bethel island rd in bethel island?,"pd.merge(restaurant, location, on='restaurant_id').query('city_name==""bethel island"" and street_name==""bethel island rd""')[['house_number', 'name']]"
where is the best restaurant in the bay area for american food?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
what are the names of restaurants in bay area that serve indian food?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
find the best place for american food in bay area,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
where is the best american restaurant in the bay area?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
what is the leading american in the bay area?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
please provide me with the name of a restaurant that serves the best american food in the bay area.,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
please recommend me the best restaurant for american food in the bay area.,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
what is the best restaurant for american food in the bay area?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
which store is the best one located in the san francisco bay area?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
who is the best american in the bay area?,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
please provide me with the name and address of a restaurant that offers the best american cuisine in the sf bay area.,"restaurant.merge(geographic, on='city_name').merge(location, on='id').loc[(lambda x: (x['region']=='bay area') & (x['food_type']=='american') & (x['rating']==restaurant.merge(geographic, on='city_name').loc[(lambda y: (y['region']=='bay area') & (y['food_type']=='american')), 'rating'].max())), ['house_number', 'name']]"
find the names of hotels in the yosemite and mono lake area that serve french food.,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
what are some good restaurants in the yosemite and mono lake areas for french food?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
please recommend me a good restaurant near yosemite national park and mono lake area that serves french food.,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
please provide me with the details of a good french restaurant in the yosemite and mono lake area.,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
where is a good place in france for french food?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
where can one get french food in the yosemite and mono lake area?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
find a good place in french cuisine in yosemite and mono lake.,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
please provide me the name of a restaurant that has tasty french food in the yosemite and mono lake areas.,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
what are the best restaurants in the yosemite and mono lake areas for french cuisine?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
where is a good french restaurant in the yosemite and mono lake area?,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
please recommend me some good restaurants that are located in the yosemite and mono lake area.,"pd.merge(pd.merge(restaurant, geographic, on='city_name'), location, on='restaurant_id').loc[(lambda x: (x['region'] == 'yosemite and mono lake area') & (x['food_type'] == 'french') & (x['rating'] > 2.5))(restaurant), ['house_number', 'name']]"
where are the few restaurants recommended to enjoy arabic cuisine in mountain view ?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
what are some good places for arabic food in mountain view?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where could i find some good arabic restaurants in mountain view?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
are any arabic restaurants available in mountain view?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
please provide me with the best arabic teacher in mountain view.,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
please suggest me a good arabic restaurant in mountain view.,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
please provide me with the best place for arabic food in mountain view,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where is there a good place to learn arabic in mountain view?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where is a good restaurant in mountain view that serves arabic food?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
what are the names of good restaurants in mountain view for arabic food?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
which restaurants provide arabic cuisine in mountain view?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
please recommend some places with good arabic for beginners in mountain view.,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where can i find an arabic tutor in mountain view?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
please deliver me a restaurant in mountain view that dishes out tasty arabic food.,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
can you give me some good arabic restaurants in mountain view?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where are the good places to learn arabic in mountain view?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
"please give me names of nearby mountains in mountain view, california.","pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
recommend me a good arabic restaurant in mountain view.,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where is a good arabic restaurant in mountain view?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
what are some good places for arabic in mountain view?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
what is the name of a good restaurant in mountain view that serves arabic food?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
where can i get good arabic food in mountain view?,"pd.merge(restaurant.loc[lambda x: (x['food_type'] == 'arabic') & (x['rating'] > 2.5), ['id', 'name']], location.loc[lambda x: x['city_name'] == 'mountain view', ['restaurant_id', 'house_number']].rename(columns={'restaurant_id': 'id'})).loc[:, ['house_number', 'name']]"
i need the name of a restaurant that serves american cuisine in san francisco.,"pd.merge(restaurant.loc[lambda x: x['name'] == 'jamerican cuisine'], location.loc[lambda x: x['city_name'] == 'san francisco'], on='restaurant_id')[['house_number', 'name']]"
what restaurant is located in san francisco that serves american cuisine?,"pd.merge(restaurant.loc[lambda x: x['name'] == 'jamerican cuisine'], location.loc[lambda x: x['city_name'] == 'san francisco'], on='restaurant_id')[['house_number', 'name']]"
where can i find a japanese restaurant in san francisco?,"pd.merge(restaurant.loc[lambda x: x['name'] == 'jamerican cuisine'], location.loc[lambda x: x['city_name'] == 'san francisco'], on='restaurant_id')[['house_number', 'name']]"
find the names of restaurants in the san francisco bay area.,"pd.merge(location, restaurant, left_on='restaurant_id', right_on='id').loc[lambda x: x['city_name'].isin(geographic.loc[geographic['region']=='bay area', 'city_name']), ['house_number', 'name']]"
give me the names of restaurants located in the bay area?,"pd.merge(location, restaurant, left_on='restaurant_id', right_on='id').loc[lambda x: x['city_name'].isin(geographic.loc[geographic['region']=='bay area', 'city_name']), ['house_number', 'name']]"
please provide a list of restaurants that are situated in the san francisco bay area.,"pd.merge(location, restaurant, left_on='restaurant_id', right_on='id').loc[lambda x: x['city_name'].isin(geographic.loc[geographic['region']=='bay area', 'city_name']), ['house_number', 'name']]"
where can i find restaurants in the bay area?,"pd.merge(location, restaurant, left_on='restaurant_id', right_on='id').loc[lambda x: x['city_name'].isin(geographic.loc[geographic['region']=='bay area', 'city_name']), ['house_number', 'name']]"
please provide me with the names of good restaurants in the bay area,"pd.merge(location, restaurant, on='restaurant_id').loc[lambda x: x['city_name'].isin(geographic.loc[geographic['region']=='region0', 'city_name']) & (x['rating']>2.5), ['house_number', 'name']]"
please let me know some of the good restraunts in the bay area,"pd.merge(location, restaurant, on='restaurant_id').loc[lambda x: x['city_name'].isin(geographic.loc[geographic['region']=='region0', 'city_name']) & (x['rating']>2.5), ['house_number', 'name']]"
give me a list of good restaurants in the bay area.,"pd.merge(location, restaurant, on='restaurant_id').loc[lambda x: x['city_name'].isin(geographic.loc[geographic['region']=='region0', 'city_name']) & (x['rating']>2.5), ['house_number', 'name']]"
please provide me with the names of good restaurants in the bay area.,"pd.merge(location, restaurant, on='restaurant_id').loc[lambda x: x['city_name'].isin(geographic.loc[geographic['region']=='region0', 'city_name']) & (x['rating']>2.5), ['house_number', 'name']]"
how many singers exist?,singer.shape[0]
what is the total count of singers?,singer.shape[0]
retrieve the titles of singers by their age from the oldest to the youngest.,"singer[['name', 'country', 'age']].sort_values('age', ascending=false)"
"please give me the names, countries, and ages for every singer in descending order by age.","singer[['name', 'country', 'age']].sort_values('age', ascending=false)"
in what year was the average age of all singers from france the highest?,"singer.loc[singer['country']=='france', 'age'].agg(['mean', 'min', 'max'])"
what is the range of age for all french singers?,"singer.loc[singer['country']=='france', 'age'].agg(['mean', 'min', 'max'])"
"provide the name of the release year of the song, with the youngest singer.","singer[['song_name', 'song_release_year', 'age']].sort_values('age').iloc[0, :2]"
obtain the names of the songs and release years of the youngest singer.,"singer[['song_name', 'song_release_year', 'age']].sort_values('age').iloc[0, :2]"
"what are the countries where singers are above the age of 20?i've formatted the sentences differently for better reading.a:well, you could use something like the following:df.dropna(how='all')\  .groupby('field_name').agg([sum('value'),max('value'),min('value')])\  .reset_index()","singer.loc[lambda x: x['age']>20, 'country'].unique()"
what is the count of countries whose singers are above the age of 20?,"singer.loc[lambda x: x['age']>20, 'country'].unique()"
ask me the count of singers from each country.,singer.groupby('country').size()
return all songs composed by singers above the average.,"singer.loc[singer['age'] > singer['age'].mean(), 'song_name']"
find the song titles by singers who are older than the average singer.,"singer.loc[singer['age'] > singer['age'].mean(), 'song_name']"
"return the location and name of all stadiums with a capacity between 5000 and 10000.(all datatypes are same, except for location).","stadium.loc[lambda x: x['capacity'].between(5000, 10000), ['location', 'name']]"
do you know the names and locations of all stations with capacity between 5000 and 10000?,"stadium.loc[lambda x: x['capacity'].between(5000, 10000), ['location', 'name']]"
what is the maximum capacity and the average of all stadiums?,"stadium.agg({'capacity': 'max', 'average': 'mean'})"
please find the average and maximum capacities for all stadiums.,"stadium['capacity'].agg(['mean', 'max'])"
what is the name for the stadium with the highest average attendance and what is the seating capacity of that arena?,"stadium[['name', 'capacity']].sort_values('average', ascending=false).iloc[0]"
what are the stadium name and capacity with the highest average attendance?,"stadium[['name', 'capacity']].sort_values('average', ascending=false).iloc[0]"
what is the count of concerts held in the year 2014 or 2015?,"concert.loc[lambda x: x['year'].isin([2014, 2015])]['year'].count()"
determine the count of concerts that occurred in 2014 or 2015.,"concert.loc[lambda x: x['year'].isin([2014, 2015])]['year'].count()"
"provide the names and counts of stadiums, and for each stadium, the number of concerts held.","concert.merge(stadium, on='stadium_id').groupby('name').size()"
how many concerts are played in each stadium?,"concert.merge(stadium, on='stadium_id').groupby('name').size()"
return me the stadium name and capacity that had the largest number of concerts in 2014 or later.,"stadium.merge(concert.query('year >= 2014')).groupby(['name', 'capacity'], as_index=false).size().sort_values(ascending=false).iloc[[0]][['name', 'capacity']]"
provide me the name of the stadium with most concerts after 2013 and its seating capacity.,"concert.merge(stadium, on='stadium_id').loc[lambda x: x['year']>2013].groupby(['stadium_id', 'name', 'capacity']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0, [1,2]]"
what was the most popular year in terms of concerts?,"concert.groupby('year').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['year']"
what year experienced the greatest number of concerts?,"concert.groupby('year').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['year']"
show me the stadium names that do not have concerts.,stadium[~stadium['stadium_id'].isin(concert['stadium_id'])]['name']
what are the names of stadiums that do not have any concerts?,stadium[~stadium['stadium_id'].isin(concert['stadium_id'])]['name']
retrieve the name of countries under which a singer above age 40 and a singer below 30 are from.,"singer.loc[lambda x: x['age'] > 40, 'country'].to_frame().merge(singer.loc[lambda x: x['age'] < 30, 'country'].to_frame()).squeeze()"
list the names for all stadiums excluding stadiums where a concert was organized in 2014.,stadium[~stadium['name'].isin(concert[concert['year']==2014].merge(stadium)['name'])]['name']
retrieve the names of all stadiums that have not hosted a single concert in 2014.,stadium[~stadium['name'].isin(concert[concert['year']==2014].merge(stadium)['name'])]['name']
provide me the name and theme of each concert and the number of singers in each concert.,"singer_in_concert.merge(concert, on='concert_id').groupby(['concert_name', 'theme']).size().reset_index().rename(columns={0:'count'})"
"list the names of the singers for each concert, the theme of the concert and the number of singers.","singer_in_concert.merge(concert, on='concert_id').groupby(['concert_id', 'concert_name', 'theme']).size().reset_index(name='count')[['concert_name', 'theme', 'count']]"
provide me with the names and number of concerts for each of the singers.,"singer_in_concert.merge(singer, on='singer_id').groupby('name').size()"
retrieve the names of singers and the number of concerts that each person has performed.,"singer_in_concert.merge(singer, on='singer_id').groupby('name').size()"
provide me the titles of singers that were featured in concerts in 2014.,"pd.merge(pd.merge(singer_in_concert, singer, on='singer_id'), concert, on='concert_id').loc[lambda x: x['year']==2014, 'name']"
identify the names of the artists that performed in concert in the year 2014.,"pd.merge(pd.merge(singer_in_concert, singer, on='singer_id'), concert, on='concert_id').loc[lambda x: x['year']==2014, 'name']"
please inform me the title of the singer and the nation of the country in which the singer has a song that has 'hey' in its name.,"singer.loc[singer['song_name'].str.contains('hey'), ['name', 'country']]"
"list all singers whose songs include the word ""hey.""","singer.loc[singer['song_name'].str.contains('hey'), ['name', 'country']]"
provide the names and locations of the stadiums in which concerts happened during the years 2014 and 2015.,"pd.merge(concert.query('year==2014')[['stadium_id']].drop_duplicates(), concert.query('year==2015')[['stadium_id']].drop_duplicates(), on='stadium_id').merge(stadium, on='stadium_id')[['name', 'location']]"
find the stadium names and locations that hosted concerts in both 2014 and 2015.,"pd.merge(concert.query('year==2014')[['stadium_id']].drop_duplicates(), concert.query('year==2015')[['stadium_id']].drop_duplicates(), on='stadium_id').merge(stadium, on='stadium_id')[['name', 'location']]"
how many concerts were organized in the venue with the highest capacity?,"concert.loc[lambda x: x['stadium_id'] == stadium.sort_values('capacity', ascending=false)['stadium_id'].iloc[0]].shape[0]"
what is the count of concerts that occurred in the stadium with the largest capacity?,"concert.loc[lambda x: x['stadium_id'] == stadium.sort_values('capacity', ascending=false)['stadium_id'].iloc[0]].shape[0]"
provide the count of animals with a mass heavier than 10.,(pets['weight'] > 10).sum()
how many pets weigh more than 10 pounds?,(pets['weight'] > 10).sum()
what is the body weight of the dog that is youngest among all four?,pets.sort_values('pet_age')['weight'].iloc[0]
record the maximum weight of each type of pet and pet type.,pets.groupby('pettype')['weight'].max()
fetch the maximum body weight and type for each type of pet.,pets.groupby('pettype')['weight'].max()
what is the count of pets that are owned by students over 20?,"pd.merge(student, has_pet, on='stuid').loc[lambda x: x['age']>20].shape[0]"
what is the count of pets that are owned by students older than 20?,"pd.merge(student, has_pet, on='stuid').loc[lambda x: x['age']>20].shape[0]"
provide me with the count of dogs that are kept as pets by female students (with sex f).,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: (x['sex']=='f') & (x['pettype']=='dog'), :].shape[0]"
what is the count of dogs that are kept as pets by female students?,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: (x['sex']=='f') & (x['pettype']=='dog'), :].shape[0]"
determine the number of different types of pets.,pets['pettype'].nunique()
determine the total count of pet types.,pets['pettype'].nunique()
which students are registered as having dog or cat pets?,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: x['pettype'].isin(['cat', 'dog']), 'fname'].unique()"
who are all the students that have a cat or dog as a pet?,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: x['pettype'].isin(['cat', 'dog']), 'fname'].unique()"
get the first name of students that have cats and dogs as pets.,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: x['pettype']=='cat', 'fname'].isin(pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: x['pettype']=='dog', 'fname']).unique()"
get the names of students who are having both cats and dogs as pets.,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: x['pettype']=='cat', 'fname'].intersect(pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: x['pettype']=='dog', 'fname'])"
retrieve the titles and ages of students who do not possess a cat.,"student.loc[lambda x: ~x['stuid'].isin(pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: x['pettype']=='cat', 'stuid'] ), ['major', 'age']]"
determine the major and age of every student who does not keep a cat as a pet.,"student.loc[lambda x: ~x['stuid'].isin(pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: x['pettype']=='cat', 'stuid'] ), ['major', 'age']]"
retrieve the ids of students that do not possess a cat.,"student[~student['stuid'].isin(has_pet.merge(pets.loc[pets['pettype']=='cat'], on='petid')['stuid'])]['stuid']"
provide the ids of those students who do not own cat pets.,"student[~student['stuid'].isin(has_pet.merge(pets.loc[pets['pettype']=='cat'], on='petid')['stuid'])]['stuid']"
determine the name and age of students who have dogs but do not have cats as pets.,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').query('pettype==""dog"" and stuid not in @pd.merge(pd.merge(student, has_pet, on=""stuid""), pets, on=""petid"").query(""pettype=='cat'"")[""stuid""]')[['fname', 'age']]"
retrieve the first names of all students that have dogs but do not have cats.,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').query('pettype==""dog"" and stuid not in @pd.merge(pd.merge(student, has_pet, on=""stuid""), pets, on=""petid"").query(""pettype=='cat'"")[""stuid""]')[['fname', 'age']]"
please get the record of the type and weight of the youngest pet.,"pets[['pettype', 'weight', 'pet_age']].sort_values('pet_age').iloc[0][['pettype', 'weight']]"
what is the id and weight of all pets whose age is greater than 1?,"pets.loc[pets['pet_age'] > 1, ['petid', 'weight']]"
what is the corresponding id and weight of every pet that is older than 1?,"pets.loc[pets['pet_age'] > 1, ['petid', 'weight']]"
retrieve the average age and maximum age for each kind of pet.,"pets.groupby('pettype')['pet_age'].agg(['mean', 'max'])"
what is the mean and maximum age for each pet type?,"pets.groupby('pettype')['pet_age'].agg(['mean', 'max'])"
determine the average weight of pets of each type.,"pets.groupby('pettype').agg(avg_weight=('weight', 'mean'))"
provide the average weight of pets that are produced by each type of animal.,"pets.groupby('pettype').agg(avg_weight=('weight', 'mean'))"
retrieve the first name and age of students that own a dog.,"pd.merge(student, has_pet, on='stuid')[['fname', 'age']].drop_duplicates()"
provide me with the details of students who own pets along with their first names and ages.,"pd.merge(student, has_pet, on='stuid')[['fname', 'age']].drop_duplicates()"
return the id of dog that is owned by the student whose last name is 'smith'.,"pd.merge(student.loc[lambda x: x['lname']=='smith', ['stuid']], has_pet, on='stuid')['petid']"
what is the id of the pet owned by the student whose name is 'smith'?,"pd.merge(student.loc[lambda x: x['lname']=='smith', ['stuid']], has_pet, on='stuid')['petid']"
count the number of pets each student has and id.,"has_pet.groupby('stuid').size().reset_index(name='count').merge(student, on='stuid')[['count', 'stuid']]"
"for students who have pets, how many pets does each student have? list their ids instead of names.","has_pet.merge(student, on='stuid').groupby('stuid').size().reset_index(name='count(*)')"
provide the gender as well as the first name of students who have more than one dog as a pet.,"student.merge(has_pet, on='stuid').groupby(['stuid', 'fname', 'sex']).size().reset_index(name='count').query('count > 1')[['fname', 'sex']]"
i would like to know the first name and sex of all students that have more than two pets.,"student.merge(has_pet, on='stuid').groupby(['stuid', 'fname', 'sex']).size().reset_index(name='count').query('count > 1')[['fname', 'sex']]"
retrieve the last name of a student who owns a 3-year-old cat.,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: (x['pettype']=='cat') & (x['pet_age']==3), 'lname']"
which student has a pet cat that is approximately 3 years old?,"pd.merge(pd.merge(student, has_pet, on='stuid'), pets, on='petid').loc[lambda x: (x['pettype']=='cat') & (x['pet_age']==3), 'lname']"
what is the minimum age of students who do not have pets?,"student.loc[~student['stuid'].isin(has_pet['stuid']), 'age'].mean()"
what is the mean average age of all students that do not own any pets?,"student.loc[~student['stuid'].isin(has_pet['stuid']), 'age'].mean()"
what is the count of continents?,continents.shape[0]
"which continent has the most number of countries, continent name, and id?","countries.merge(continent, left_on='continent', right_on='contid').groupby(['contid','continent']).size().reset_index(name='count')[['contid','continent','count']]"
"for each continent, please list its id, name, and the number of countries it has.","countries.merge(continent, left_on='continent', right_on='contid').groupby(['contid','continent']).size().reset_index(name='count')[['contid','continent','count']]"
provide a count of countries.,countries.shape[0]
how many countries are there in the world?,countries.shape[0]
please provide me with a count of car models produced by each maker and their respective id and full name.,"pd.merge(car_makers, model_list, left_on='id', right_on='maker').groupby(['fullname', 'id']).size().reset_index(name='count')"
please give me the complete name of each car maker along with their id and the number of cars they produce,"pd.merge(car_makers, model_list, left_on='id', right_on='maker').groupby(['fullname', 'id']).size().reset_index(name='count')"
what is the car model that has the minimum horsepower?,"pd.merge(car_names, cars_data, left_on='makeid', right_on='id').sort_values('horsepower').iloc[0]['model']"
tell me the model of the car that has the smallest amount of horsepower.,"pd.merge(car_names, cars_data, left_on='makeid', right_on='id').sort_values('horsepower').iloc[0]['model']"
provide me with the title of the model of the car that weighs less than the average weight.,"car_names.merge(cars_data.query('weight < @cars_data.weight.mean()'), left_on='makeid', right_on='id')['model']"
what is the model of a car with a weight smaller than the average over all the cars?,"car_names.merge(cars_data.query('weight < @cars_data.weight.mean()'), left_on='makeid', right_on='id')['model']"
what is the procedure to retrieve the names of manufacturers that produced some cars in the year of 1970?,"pd.merge(pd.merge(pd.merge(car_makers, model_list, left_on='id', right_on='maker'), car_names, on='model'), cars_data, left_on='makeid', right_on='id').loc[lambda x: x['year']==1970,'maker'].unique()"
retrieve the names of car makers who manufactured a car in the year 1970.,"pd.merge(pd.merge(pd.merge(car_makers, model_list, left_on='id', right_on='maker'), car_names, on='model'), cars_data, left_on='makeid', right_on='id').loc[lambda x: x['year']==1970,'maker'].unique()"
find the make and model of the cars that were manufactured the earliest year.,"cars_data.merge(car_names, left_on='id', right_on='makeid').loc[lambda x: x['year'] == cars_data['year'].min(), ['make', 'year']]"
which car models were made after 1980?,"pd.merge(pd.merge(model_list, car_names, on='model'), cars_data, left_on='makeid', right_on='id').loc[lambda x: x['year']>1980, 'model'].unique()"
what is the number of models that were produced for the cards after 1980?,"pd.merge(pd.merge(model_list, car_names, on='model'), cars_data, left_on='makeid', right_on='id').loc[lambda x: x['year']>1980, 'model'].unique()"
how many car makers are in each continent? list the continent name as well as the count.,"pd.merge(pd.merge(continents, countries, left_on='contid', right_on='continent'), car_makers, left_on='countryid', right_on='country').groupby('continent').size()"
what is the title of each continent and how many car makers are there?,"pd.merge(pd.merge(continents, countries, left_on='contid', right_on='continent'), car_makers, left_on='countryid', right_on='country').groupby('continent').size()"
state the country with the most car producers.,"pd.merge(car_makers, countries, left_on='country', right_on='countryid').groupby('countryname').size().reset_index(name='counts').sort_values('counts', ascending=false).iloc[0]['countryname']"
what is the name for a country with the greatest number of car makers?,"pd.merge(car_makers, countries, left_on='country', right_on='countryid').groupby('countryname').size().reset_index(name='counts').sort_values('counts', ascending=false).iloc[0]['countryname']"
list the number of car models produced by each manufacturer along with the count and the manufacturer's full name.,"pd.merge(model_list, car_makers, left_on='maker', right_on='id').groupby('fullname').size().reset_index(name='count')"
could you provide me with the total count of car models manufactured by each maker along with their corresponding id and complete name?,"pd.merge(model_list, car_makers, left_on='maker', right_on='id').groupby(['id', 'fullname'], as_index=false).agg({'index': 'count'}).rename(columns={'index': 'count'})[['count', 'fullname', 'id']]"
what amount of acceleration does it obtain in the speed test of the amc hornet sportabout (sw)?,"cars_data.merge(car_names[car_names['make'] == 'amc hornet sportabout (sw)'], left_on='id', right_on='makeid')['accelerate']"
how many car manufacturer are there in france?,"pd.merge(car_makers, countries, left_on='country', right_on='countryid').loc[lambda x: x['countryname']=='france'].shape[0]"
determine the number of makers of care in france.,"pd.merge(car_makers, countries, left_on='country', right_on='countryid').loc[lambda x: x['countryname']=='france'].shape[0]"
what is the count of car models manufactured in the united states?,"pd.merge(pd.merge(model_list, car_makers, left_on='maker', right_on='id'), countries, left_on='country', right_on='countryid').loc[lambda x: x['countryname']=='usa'].shape[0]"
what is the count of car models made in the united states?,"pd.merge(pd.merge(model_list, car_makers, left_on='maker', right_on='id'), countries, left_on='country', right_on='countryid').loc[lambda x: x['countryname']=='usa'].shape[0]"
what is the mpg of cars with 4 cylinders?,"cars_data.loc[cars_data['cylinders']==4, 'mpg'].mean()"
what is the average fuel efficiency of cars with four cylinders?,"cars_data.loc[cars_data['cylinders']==4, 'mpg'].mean()"
what is the minimal weight of a car that was produced with eight cylinders in 1974?,"cars_data.loc[(cars_data['cylinders'] == 8) & (cars_data['year'] == 1974), 'weight'].min()"
what was the weight of cars with 8 cylinders produced in 1974?,"cars_data.loc[(cars_data['cylinders'] == 8) & (cars_data['year'] == 1974), 'weight'].min()"
what are all the manufacturers and models?,"model_list[['maker', 'model']]"
name the makers and the models.,"model_list[['maker', 'model']]"
what are the countries that have automobile manufacturers? list name and id.,"pd.merge(countries, car_makers, on='countryid').groupby(['countryid', 'countryname']).filter(lambda x: len(x) >= 1)[['countryname', 'countryid']].drop_duplicates()"
can you please provide me with the ids and names of all countries that have at least one car maker?,"pd.merge(countries, car_makers, on='countryid').groupby(['countryid', 'countryname']).filter(lambda x: len(x) >= 1)[['countryname', 'countryid']].drop_duplicates()"
what is the count of cars with horsepower exceeding 150?,(cars_data['horsepower'] > 150).sum()
how many cars have a horsepower exceeding 150?,(cars_data['horsepower'] > 150).sum()
find the average weight of cars each year.,cars_data.groupby('year')['weight'].mean()
"with regards to the average weight and year, please provide me with the average weight and year per year.",cars_data.groupby('year')['weight'].mean()
identify the countries that own three or more car manufacturing enterprises.,"pd.merge(pd.merge(countries, continents, left_on='continent', right_on='contid'), car_makers, left_on='countryid', right_on='country').loc[lambda x: x['continent']=='europe'].groupby('countryname').filter(lambda x: len(x) >= 3)['countryname']"
provide me with the titles of all european counties in which the number of manufacturers is at least 3.,"pd.merge(pd.merge(countries, continents, left_on='continent', right_on='contid'), car_makers, left_on='countryid', right_on='country').loc[lambda x: x['continent']=='europe'].groupby('countryname').filter(lambda x: len(x) >= 3)['countryname']"
please provide me with the make and maximum horsepower of car models with 3 cylinders.,"pd.merge(car_names, cars_data, left_on='makeid', right_on='id').loc[lambda x: x['cylinders'] == 3, ['horsepower', 'make']].sort_values('horsepower', ascending=false).iloc[0]"
which manufacturer has the highest amount of horsepower for the models with 3 cylinders?,"pd.merge(car_names, cars_data, left_on='makeid', right_on='id').loc[lambda x: x['cylinders'] == 3, ['horsepower', 'make']].sort_values('horsepower', ascending=false).iloc[0]"
"which model saves the most gasoline? in other words, have the maximum miles per gallon.","car_names.merge(cars_data, left_on='makeid', right_on='id').sort_values('mpg', ascending=false).iloc[0]['model']"
which car model has the best mpg?,"car_names.loc[car_names['makeid'].isin(cars_data.sort_values('mpg', ascending=false).iloc[[0]]['id']), 'model']"
what is the average horsepower of cars manufactured before 1980?,"cars_data.loc[cars_data['year'] < 1980, 'horsepower'].mean()"
compute the average horsepower of cars manufactured before 1980.,"cars_data.loc[cars_data['year'] < 1980, 'horsepower'].mean()"
what is the average edispl of cars of the volvo model?,"cars_data.merge(car_names, left_on='id', right_on='makeid').query('model == ""volvo""')['edispl'].mean()"
determine the average for each volvo across each attribute,"cars_data.merge(car_names, left_on='id', right_on='makeid').query('model == ""volvo""')['edispl'].mean()"
what maximum accelerate did different number of cylinders undergo?,cars_data.groupby('cylinders')['accelerate'].max()
what is the maximum speed that different cylinders can achieve?,cars_data.groupby('cylinders')['accelerate'].max()
which model of cars have the highest number of versions?,car_names.groupby('model').size().sort_values(ascending=false).head(1).index[0]
obtain the count of models that have the highest version count.,car_names.groupby('model').size().sort_values(ascending=false).head(1).index[0]
what number of cars has more than 4 cylinders?,cars_data['cylinders'].gt(4).sum()
how many cars were produced in the year 1980?,(cars_data['year'] == 1980).sum()
what is the count of cars that were made in 1980?,(cars_data['year'] == 1980).sum()
"please provide me with the number of car models manufactured by american motor company, along with their corresponding id and complete name","pd.merge(car_makers, model_list, left_on='id', right_on='maker')['id'].loc[lambda x: x['fullname']=='american motor company'].count()"
how many car models are created by american motor company?,"pd.merge(car_makers, model_list, left_on='id', right_on='maker')['id'].loc[lambda x: x['fullname']=='american motor company'].count()"
provide the maker whose named car models numbered more than three and their id and full names.,"car_makers.merge(model_list, on='id').groupby(['fullname', 'id']).filter(lambda x: len(x) > 3).drop_duplicates(['fullname', 'id'])[['fullname', 'id']]"
return me the names and ids of all manufacturers that have more than 3 models.,"car_makers.merge(model_list, on='id').groupby(['fullname', 'id']).filter(lambda x: len(x) > 3).drop_duplicates(['fullname', 'id'])[['fullname', 'id']]"
retrieve the list of distinctive models that are made by maker with full name general motors or weighing more than 3500.,"pd.merge(pd.merge(pd.merge(car_names, model_list, on='model'), car_makers, left_on='maker', right_on='id'), cars_data, left_on='makeid', right_on='id').loc[(lambda x: (x['fullname'] == 'general motors') | (x['weight'] > 3500)), 'model'].unique()"
how many different models were created by either general motors or weighed more than 3500?,"pd.merge(pd.merge(pd.merge(car_names, model_list, on='model'), car_makers, left_on='maker', right_on='id'), cars_data, left_on='makeid', right_on='id').loc[(lambda x: (x['fullname'] == 'general motors') | (x['weight'] > 3500)), 'model'].unique()"
in which years were cars produced weighing no less than 3000 and no more than 4000?,"cars_data.loc[cars_data['weight'].between(3000, 4000), 'year'].unique()"
determine the years of production of cars that weighed less than 4000 and also cars that weighted more than 3000.,"cars_data.loc[cars_data['weight'].between(3000, 4000), 'year'].unique()"
what is the horsepower of the car that has the highest engine acceleration?,"cars_data.sort_values('accelerate', ascending=false).iloc[0]['horsepower']"
what is the horsepower of the automobile with the greatest acceleration?,"cars_data.sort_values('accelerate', ascending=false).iloc[0]['horsepower']"
"for car model volvo, how many cylinders does the car with the lowest acceleration have?","cars_data.merge(car_names, left_on='id', right_on='makeid').loc[lambda x: x['model']=='volvo'].sort_values('accelerate').iloc[0]['cylinders']"
what is the number of cylinders in the version of the least accelerating volvo model?,"cars_data.merge(car_names, left_on='id', right_on='makeid').loc[lambda x: x['model']=='volvo'].sort_values('accelerate').iloc[0]['cylinders']"
what is the number of cars with greater acceleration than the one with the greatest amount of horsepower?,"(cars_data['accelerate'] > cars_data.sort_values('horsepower', ascending=false)['accelerate'].iloc[0]).sum()"
how many countries have more than one car maker?,"pd.merge(countries, car_makers, left_on='countryid', right_on='country').groupby('countryid').filter(lambda x: len(x) > 2)['countryid'].nunique()"
how many countries are there with more than two car makers within them?,"pd.merge(countries, car_makers, left_on='countryid', right_on='country').groupby('countryid').filter(lambda x: len(x) > 2)['countryid'].nunique()"
determine the number of cars that have more than six cylinders.,(cars_data['cylinders'] > 6).sum()
what is the count of the vehicles having more than six cylinders?,(cars_data['cylinders'] > 6).sum()
"for cars with 4 cylinders, which model has the largest horsepower?","car_names.loc[lambda x: x['makeid'].isin(cars_data.loc[lambda x: x['cylinders']==4, 'id'])].sort_values('horsepower', ascending=false).iloc[0]['model']"
list the car makeid and make name that do not have any cars with more than 3 cylinders.,"cars_data.merge(car_names, left_on='id', right_on='makeid').loc[lambda x: (x['horsepower'] > cars_data['horsepower'].min()) & (x['cylinders'] <= 3), ['makeid', 'make']]"
"find all cars that have less than 4 cylinders , and retrieve their id and name.","cars_data.merge(car_names, left_on='id', right_on='makeid').loc[lambda x: (x['horsepower'] > cars_data['horsepower'].min()) & (x['cylinders'] < 4), ['makeid', 'make']]"
determine the maximum miles per gallon of vehicles with 8 cylinders or manufactured before 1980.,"cars_data.loc[(cars_data['cylinders'] == 8) | (cars_data['year'] < 1980), 'mpg'].max()"
"what is the highest mpg of the automobiles which have 8 cylinders, or were produced before 1980?","cars_data.loc[(cars_data['cylinders'] == 8) | (cars_data['year'] < 1980), 'mpg'].max()"
which models do not weigh more than 3500 grams but are not built by ford motor company?,"pd.merge(pd.merge(pd.merge(model_list, car_names, on='model'), cars_data, left_on='makeid', right_on='id'), car_makers, left_on='maker', right_on='id').loc[(lambda x: (x['weight'] < 3500) & (x['fullname'] != 'ford motor company'))(x), 'model'].unique()"
retrieve the models of cars that are lighter than 3500 but were not manufactured by the ford motor company.,"pd.merge(pd.merge(pd.merge(model_list, car_names, on='model'), cars_data, left_on='makeid', right_on='id'), car_makers, left_on='maker', right_on='id').loc[(lambda x: (x['weight'] < 3500) & (x['fullname'] != 'ford motor company'))(x), 'model'].unique()"
kindly provide me with the list of countries where there are no car companies.,"countries.loc[~countries['countryid'].isin(car_makers['country']), 'countryname']"
list the names of countries that have no car manufacturers.,"countries.loc[~countries['countryid'].isin(car_makers['country']), 'countryname']"
which brands manufacture at least 2 models? list their ids and names.,"pd.merge(car_makers, model_list, left_on='id', right_on='maker').groupby(['id', 'maker']).filter(lambda x: len(x) >= 2).merge(model_list, on=['id', 'maker']).merge(car_names, on='model').groupby(['id', 'maker']).filter(lambda x: len(x) > 3)[['id', 'maker']].drop_duplicates()"
what is the id and maker of car manufacturer that manufacture at least 2 models and manufacture more than 3 cars?,"pd.merge(car_makers, model_list, left_on='id', right_on='maker').groupby(['id', 'maker']).filter(lambda group: len(group)>=2).merge(car_names, left_on='model', right_on='model').groupby(['id', 'maker']).filter(lambda group: len(group)>3)[['id', 'maker']].drop_duplicates()"
"retrieve the names of the countries which have more than three car makers, and produce the 'fiat' model.","pd.concat([countries.merge(car_makers, left_on='countryid', right_on='country').groupby(['countryid', 'countryname']).filter(lambda x: len(x) > 3),countries.merge(car_makers, left_on='countryid', right_on='country').merge(model_list, left_on='id', right_on='maker').loc[lambda x: x['model']=='fiat', ['countryid', 'countryname']].drop_duplicates()])[['countryid', 'countryname']].sort_values('countryid')"
retrieve the ids and names of all countries that either have more than 3 car makers or build fiat models.,"pd.concat([countries.merge(car_makers, how='inner', left_on='countryid', right_on='country').groupby(['countryid', 'countryname']).filter(lambda x: len(x) > 3).drop_duplicates(subset=['countryid', 'countryname'])[['countryid', 'countryname']], countries.merge(car_makers, how='inner', left_on='countryid', right_on='country').merge(model_list, how='inner', left_on='id', right_on='maker').loc[lambda x: x['model'] == 'fiat', ['countryid', 'countryname']]]).drop_duplicates().sort_values('countryid')[['countryid', 'countryname']]"
"is airline ""jetblue airways"" owned by china?","airlines.loc[lambda x: x['airline']=='jetblue airways', 'country']"
what is the affiliation of jetblue airways?,"airlines.loc[lambda x: x['airline']=='jetblue airways', 'country']"
"retrieve the abbreviated name of airline ""jetblue airways"".","airlines.loc[lambda x: x['airline']=='jetblue airways', 'abbreviation']"
what code corresponds to jetblue airways?,"airlines.loc[lambda x: x['airline']=='jetblue airways', 'abbreviation']"
retrieve the airline names and their abbreviations that belong to the united states.,"airlines.loc[lambda x: x['country'] == 'usa', ['airline', 'abbreviation']]"
provide me with the airlines names and abbreviations for us airlines.,"airlines.loc[lambda x: x['country'] == 'usa', ['airline', 'abbreviation']]"
list the airport id and name in the city of anthony.,"airports.loc[airports['city'] == 'anthony', ['airportcode', 'airportname']]"
what is the name of the airport and its code corresponding to the city anthony?,"airports.loc[airports['city'] == 'anthony', ['airportcode', 'airportname']]"
provide the total count of airlines.,airlines.shape[0]
please provide me with the total number of airports.,airports.shape[0]
what are the total number of flights available?,flights.shape[0]
please provide me with the count of flights.,flights.shape[0]
retrieve the titles of airlines with abbreviation 'ual'.,"airlines.loc[airlines['abbreviation']=='ual', 'airline']"
what is the number of airlines based in usa?,(airlines['country'] == 'usa').sum()
provide the total number of airlines in the usa.,(airlines['country'] == 'usa').sum()
what is the name and location of the city where the alton airport is located?,"airports.loc[lambda x: x['airportname']=='alton', ['city', 'country']]"
provide the name of the city and the country in the world for the alton airport.,"airports.loc[lambda x: x['airportname']=='alton', ['city', 'country']]"
please supply the name of the airport with code ako.,"airports.loc[airports['airportcode']=='ako', 'airportname']"
provide the names of airports at city 'aberdeen'.,"airports.loc[airports['city'] == 'aberdeen', 'airportname']"
retrieve the names of airports in aberdeen.,"airports.loc[airports['city'] == 'aberdeen', 'airportname']"
what are the flights that depart from the airport code 'apg'?,"(flights['sourceairport'] == ""apg"").sum()"
how many flights are currently departing from 'apg'?,"(flights['sourceairport'] == ""apg"").sum()"
determine the total count of flights into ato.,(flights['destairport'] == 'ato').sum()
how many flights depart every hour from aberdeen city?,"pd.merge(flights, airports, left_on='sourceairport', right_on='airportcode').loc[lambda x: x['city']=='aberdeen'].shape[0]"
find the number of flights leaving from aberdeen.,"pd.merge(flights, airports, left_on='sourceairport', right_on='airportcode').loc[lambda x: x['city']=='aberdeen'].shape[0]"
how many flights reached the aberdeen city?,"pd.merge(flights, airports, left_on='destairport', right_on='airportcode').loc[lambda x: x['city']=='aberdeen'].shape[0]"
please provide me with the count of flights arriving in aberdeen.,"pd.merge(flights, airports, left_on='destairport', right_on='airportcode').loc[lambda x: x['city']=='aberdeen'].shape[0]"
how many flights depart 'aberdeen' and arrive at 'ashley'.,"pd.merge(pd.merge(flights, airports, left_on='destairport', right_on='airportcode'), airports, left_on='sourceairport', right_on='airportcode').loc[(lambda x: x['city_x']=='ashley') & (lambda x: x['city_y']=='aberdeen'), :].shape[0]"
what is the number of flights that depart from aberdeen and reach ashely?,"pd.merge(pd.merge(flights, airports, left_on='destairport', right_on='airportcode'), airports, left_on='sourceairport', right_on='airportcode').loc[(lambda x: x['city_x']=='ashley') & (lambda x: x['city_y']=='aberdeen'), :].shape[0]"
retrieve the number of flights utilized by the airline 'jetblue airways'.,"pd.merge(flights, airlines, left_on='airline', right_on='uid').loc[lambda x: x['airline']=='jetblue airways'].shape[0]"
please provide me with the count of jetblue airways flights.,"pd.merge(flights, airlines, left_on='airline', right_on='uid').loc[lambda x: x['airline']=='jetblue airways'].shape[0]"
how many flights of 'united airlines' are bound for airport 'asy'?,"pd.merge(airlines.loc[lambda x: x['airline']=='united airlines'], flights.loc[lambda x: x['destairport']=='asy'], left_on='uid', right_on='airline').shape[0]"
provide the number of united airlines flights that are arriving to the asy airport.,"pd.merge(airlines.loc[lambda x: x['airline']=='united airlines'], flights.loc[lambda x: x['destairport']=='asy'], left_on='uid', right_on='airline').shape[0]"
determine the number of united airlines flights leaving from ahd airport.,"pd.merge(airlines, flights, left_on='uid', right_on='airline').loc[(airlines['airline']=='united airlines') & (flights['sourceairport']=='ahd'), :].shape[0]"
how many united airlines flights were scheduled to or landed in the city 'aberdeen'?,"pd.merge(pd.merge(flights, airports, left_on='destairport', right_on='airportcode'), airlines, left_on='airline', right_on='uid').loc[lambda x: (x['city']=='aberdeen') & (x['airline']=='united airlines')].shape[0]"
what is the total count of united airlines flights that arrive in aberdeen?,"pd.merge(pd.merge(flights, airports, left_on='destairport', right_on='airportcode'), airlines, left_on='airline', right_on='uid').loc[lambda x: (x['city']=='aberdeen') & (x['airline']=='united airlines')].shape[0]"
which city has the highest number of arriving flights?,"pd.merge(airports, flights, left_on='airportcode', right_on='destairport').groupby('city').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['city']"
which city is the most frequent departure city?,"pd.merge(airports, flights, left_on='airportcode', right_on='destairport').groupby('city').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['city']"
which city had most number of departing flights?,"pd.merge(airports, flights, left_on='airportcode', right_on='sourceairport').groupby('city').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['city']"
which city is the top source airport among cities?,"pd.merge(airports, flights, left_on='airportcode', right_on='sourceairport').groupby('city').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['city']"
what is the code of the international airport that has the highest number of flights?,"flights[['destairport', 'sourceairport']].stack().reset_index(drop=true).drop_duplicates().merge(airports, left_on=0, right_on='airportcode', how='inner').groupby('airportcode').size().sort_values(ascending=false).index[0]"
please provide me the airport code that's assigned to the largest airport.,"flights[['destairport', 'sourceairport']].stack().reset_index(drop=true).drop_duplicates().merge(airports, left_on=0, right_on='airportcode', how='inner').groupby('airportcode').size().sort_values(ascending=false).index[0]"
what is the code of the airport that has the least number of flights?,"flights[['destairport', 'sourceairport']].stack().unique().join(airports.set_index('airportcode'), how='inner').groupby('airportcode').size().sort_values().head(1).index[0]"
what is the code for the airport with the least number of flights?,"flights[['destairport', 'sourceairport']].stack().unique().join(airports.set_index('airportcode'), how='inner').groupby('airportcode').size().sort_values().head(1).index[0]"
which airline has the highest number of flights?,"pd.merge(airlines, flights, left_on='uid', right_on='airline').groupby('airline').size().sort_values(ascending=false).index[0]"
which airline provides the highest number of flights?,"pd.merge(airlines, flights, left_on='uid', right_on='airline').groupby('airline').size().sort_values(ascending=false).index[0]"
what is the title and country of the airline that has the least number of flights?,"pd.merge(airlines, flights, left_on='uid', right_on='airline').groupby('airline')['abbreviation', 'country'].first().sort_values(by=pd.merge(airlines, flights, left_on='uid', right_on='airline').groupby('airline').size(), ascending=true).head(1)"
what is the abbreviation of the airplane that has the fewest flights and to which country does it belong?,"pd.merge(airlines, flights, left_on='uid', right_on='airline').groupby('airline')['abbreviation', 'country'].first().sort_values(by=pd.merge(airlines, flights, left_on='uid', right_on='airline').groupby('airline').size(), ascending=true).head(1)"
determine the airlines whose flights take off from 'ahd' airport.,"pd.merge(airlines, flights, left_on='uid', right_on='airline').loc[lambda x: x['sourceairport']=='ahd', 'airline']"
which airlines have a plane leaving from ahd?,"pd.merge(airlines, flights, left_on='uid', right_on='airline').loc[lambda x: x['sourceairport']=='ahd', 'airline']"
what are the names of airlines that fly into the airport ahd?,"pd.merge(airlines, flights[flights['destairport']=='ahd'], left_on='uid', right_on='airline')['airline']"
which airlines reach airport ahd?,"pd.merge(airlines, flights[flights['destairport']=='ahd'], left_on='uid', right_on='airline')['airline']"
list all airlines that operate both to and from airports apg and cvo.,"pd.merge(airlines.loc[lambda x: x['uid'].isin(flights.loc[flights['sourceairport']=='apg', 'airline'].unique())], airlines.loc[lambda x: x['uid'].isin(flights.loc[flights['sourceairport']=='cvo', 'airline'].unique())])['airline']"
which airlines depart from both apg and cvo airports?,"pd.merge(airlines.loc[lambda x: x['uid'].isin(flights.loc[flights['sourceairport']=='apg', 'airline'].unique())], airlines.loc[lambda x: x['uid'].isin(flights.loc[flights['sourceairport']=='cvo', 'airline'].unique())])['airline']"
obtain the list of airlines that do not have flights from airport 'apg' but do from airport 'cvo'.,"pd.merge(airlines,flights[flights['sourceairport']==""cvo""],left_on='uid', right_on='airline')['airline'].drop_duplicates().reset_index(drop=true).drop(pd.merge(airlines,flights[flights['sourceairport']==""apg""],left_on='uid', right_on='airline')['airline'].drop_duplicates().reset_index(drop=true).index)"
identify the airlines which depart from cvo but not from apg airports.,"pd.merge(airlines,flights[flights['sourceairport']==""cvo""],left_on='uid', right_on='airline')['airline'].drop_duplicates().reset_index(drop=true).drop(pd.merge(airlines,flights[flights['sourceairport']==""apg""],left_on='uid', right_on='airline')['airline'].drop_duplicates().reset_index(drop=true).index)"
list the names of the airlines that have at least 10 flights.,"airlines.merge(flights, left_on='uid', right_on='airline').groupby('airline').filter(lambda x: len(x) > 10)['airline']"
which airline carriers have at least 10 flights?,"airlines.merge(flights, left_on='uid', right_on='airline').groupby('airline').filter(lambda x: len(x) > 10)['airline']"
retrieve the names of airlines that have fewer than 200 flights.,"airlines.merge(flights, left_on='uid', right_on='airline').groupby('airline').filter(lambda x: len(x) < 200)['airline'].unique()"
what are the airlines that have less than 200 flights?,"airlines.merge(flights, left_on='uid', right_on='airline').groupby('airline').filter(lambda x: len(x) < 200)['airline'].unique()"
what are the flight numbers of airline united airlines?,"pd.merge(flights, airlines, left_on='airline', right_on='uid').loc[lambda x: x['airline']=='united airlines', 'flightno']"
"what are the identifications of flights that depart from airport ""apg""?","flights.loc[lambda x: x['sourceairport']=='apg', 'flightno']"
provide me with the flight numbers of flights that take off from apg.,"flights.loc[lambda x: x['sourceairport']=='apg', 'flightno']"
"find all flight numbers that are arriving at airport ""apg"".","flights.loc[lambda x: x['destairport']=='apg', 'flightno']"
list the flight numbers that arrive at apg.,"flights.loc[lambda x: x['destairport']=='apg', 'flightno']"
"return name of the airports from which the flights flew from city ""aberdeen "".","pd.merge(flights, airports, left_on='sourceairport', right_on='airportcode').loc[lambda x: x['city']=='aberdeen', 'flightno']"
determine the flight numbers of flights departing from the city aberdeen.,"pd.merge(flights, airports, left_on='sourceairport', right_on='airportcode').loc[lambda x: x['city']=='aberdeen', 'flightno']"
"return me the arrival and departure flight numbers of flights arriving at city ""aberdeen"".","pd.merge(flights, airports, left_on='destairport', right_on='airportcode').loc[lambda x: x['city']=='aberdeen', 'flightno']"
retrieve the flight numbers of flights arriving in the aberdeen airport.,"pd.merge(flights, airports, left_on='destairport', right_on='airportcode').loc[lambda x: x['city']=='aberdeen', 'flightno']"
count the number of flights that land in aberdeen or abilene.,"pd.merge(flights, airports, left_on='destairport', right_on='airportcode').loc[lambda x: x['city'].isin(['aberdeen', 'abilene']), :].shape[0]"
retrieve the names of airports with no outbound and inbound flights.,airports[~airports['airportcode'].isin(flights['sourceairport']).append(flights['destairport']).drop_duplicates()]['airportname']
which airports do not have either incoming or outgoing flights?,airports[~airports['airportcode'].isin(flights['sourceairport']).append(flights['destairport']).drop_duplicates()]['airportname']
what is the total count of employees?,employee.shape[0]
sort employee names in descending order by their ages.,employee.sort_values('age')['name']
provide me with the count of employees who are worked in each city.,employee.groupby('city').size().reset_index(name='count')
determine the total number of workers in each city.,employee.groupby('city').size().reset_index(name='count')
fetch the cities in which more than one employee is under 30 years of age.,employee.loc[lambda x: x['age']<30].groupby('city').filter(lambda x: len(x)>1)['city']
determine the total count of shops in each location.,shop.groupby('location').size().reset_index(name='count(*)')
please provide me with the name of the manager and the district of the shop that has the highest number of products.,"shop.sort_values('number_products', ascending=false).iloc[0][['manager_name', 'district']]"
provide the names of the managers along with the districts of the stores that sold the largest number of products.,"shop.sort_values('number_products', ascending=false).iloc[0][['manager_name', 'district']]"
find the maximum and minimum number of products that each store offers.,"shop['number_products'].agg(['min', 'max'])"
what is the minimum and maximum count of products across all the shops?,"shop['number_products'].agg(['min', 'max'])"
"please provide me with the names, locations and districts of shops in descending order of number of products.","shop[['name', 'location', 'district']].sort_values('number_products', ascending=false)"
"please arrange all shops in ascending order of the number of products, and send them back to me along with their name, location and district.","shop[['name', 'location', 'district']].sort_values('number_products', ascending=false)"
fetch the names of stores whose products number exceeds the average number of products.,"shop.loc[lambda x: x['number_products'] > x['number_products'].mean(), 'name']"
which shops have the highest product counts? please provide me with their names.,"shop.loc[lambda x: x['number_products'] > x['number_products'].mean(), 'name']"
retrieve the names and ids of employees who received the highest rating in the evaluations.,"employee.merge(evaluation, on='employee_id').groupby('employee_id')['name'].count().idxmax()"
please provide the name & id of employee who received the most awards in his evaluations.,"employee.merge(evaluation, on='employee_id').groupby('employee_id')['name'].count().idxmax()"
retrieve the name of the employee who gained the highest one-time bonus.,"employee.merge(evaluation, on='employee_id').sort_values('bonus', ascending=false).iloc[0]['name']"
tell me the name of the employee who was given the biggest bonus.,"employee.merge(evaluation, on='employee_id').sort_values('bonus', ascending=false).iloc[0]['name']"
obtain the names of the employees who did not win any award in evaluation.,"employee.loc[~employee['employee_id'].isin(evaluation['employee_id']), 'name']"
provide me with the names of employees who have not gotten any evaluation till date.,"employee.loc[~employee['employee_id'].isin(evaluation['employee_id']), 'name']"
what is the name of the shop that has the largest number of employees?,"hiring.merge(shop, on='shop_id').groupby('shop_id')['name'].count().sort_values(ascending=false).iloc[0]"
what is the shop with the largest number of employees? provide the name.,"hiring.merge(shop, on='shop_id').groupby('shop_id')['name'].count().sort_values(ascending=false).iloc[0]"
obtain the names of stores that do not hire any worker.,"shop.loc[~shop['shop_id'].isin(hiring['shop_id']), 'name']"
find the names of shops that do not have employees.,"shop.loc[~shop['shop_id'].isin(hiring['shop_id']), 'name']"
provide me with the count of employees hired by each shop along with their shop name.,"hiring.merge(shop, on='shop_id').groupby('name').size().reset_index(name='count')"
"for each shop, return the count of employees working at it as well as its complete name.","hiring.merge(shop, on='shop_id').groupby('name').size().reset_index(name='count')"
what is the total sum of the bonus given in all evaluations?,evaluation['bonus'].sum()
obtain the total sum of bonuses given in all evaluations.,evaluation['bonus'].sum()
provide me with all the hiring information.,hiring
list the details of hiring.,hiring
determine the count of districts in which there are shops selling fewer than 3000 products as well as shops selling more than 10000 products.,"shop.loc[shop['number_products'] < 3000, 'district'].interesect(shop.loc[shop['number_products'] > 10000, 'district'])"
what are the numbers of store locations that exist?,shop['location'].nunique()
determine the total count of unique store locations.,shop['location'].nunique()
what is the count of documents in our system?,documents.shape[0]
how many documents are there?,documents.shape[0]
"please provide me with a list of document ids, names, and descriptions for all documents.","documents[['document_id', 'document_name', 'document_description']]"
"provide the ids, names, and descriptions of all documents.","documents[['document_id', 'document_name', 'document_description']]"
find the full description of a document that has the letter 'w' as a substring of the document description.,"documents.loc[lambda x: x['document_description'].str.contains('w', case=false), ['document_name', 'template_id']]"
find the names of the documents that have the letter w in their description and their template ids.,"documents.loc[lambda x: x['document_description'].str.contains('w', case=false), ['document_name', 'template_id']]"
"display the document id, template id, and description for document named ""robbin cv"".","documents.loc[lambda x: x['document_name']=='robbin cv', ['document_id', 'template_id', 'document_description']]"
"please provide me with the document id, template id, and description for the document that has the name robbin cv.","documents.loc[lambda x: x['document_name']=='robbin cv', ['document_id', 'template_id', 'document_description']]"
what is the list of template types that are utilized by all documents?,documents['template_id'].nunique()
determine the total count of documents using each available template.,documents['template_id'].nunique()
what is the count of documents that are utilizing templates with type code 'ppt'?,"pd.merge(documents, templates, on='template_id').loc[lambda x: x['template_type_code']=='ppt'].shape[0]"
determine the number of documents that used ppt template type.,"pd.merge(documents, templates, on='template_id').loc[lambda x: x['template_type_code']=='ppt'].shape[0]"
give a list of all template ids and number documents using each template.,documents.groupby('template_id').size().reset_index(name='count')
"please gather the names of templates, as well as the times that each of them were used.",documents.groupby('template_id').size().reset_index(name='count')
which type of template is utilized in the largest number of the documents?,"pd.merge(documents, templates, on='template_id').groupby('template_id').size().sort_values(ascending=false).index[0], pd.merge(documents, templates, on='template_id')['template_type_code'].iloc[0]"
obtain the ids of templates that were used more than one time.,documents.groupby('template_id').filter(lambda x: len(x) > 1)['template_id'].unique()
call back the list of template ids that are not used for any document.,"pd.concat([templates['template_id'], documents['template_id']]).drop_duplicates(keep=false)"
what are the codes for templates that have never been utilized?,"pd.concat([templates['template_id'], documents['template_id']]).drop_duplicates(keep=false)"
which templates do we have?,templates.shape[0]
retrieve the total count of templates.,templates.shape[0]
"provide with template ids, version numbers, and template type codes for all templates.","templates[['template_id', 'version_number', 'template_type_code']]"
"provide me with the id, version number, and type codes for each template.","templates[['template_id', 'version_number', 'template_type_code']]"
return all distinct template type codes for all templates.,templates['template_type_code'].unique()
how many different template type codes are there?,templates['template_type_code'].unique()
what template type codes are used for ppt or pp?,"templates.loc[lambda x: x['template_type_code'].isin(['pp', 'ppt']), 'template_id']"
query the ids of templates that correspond to one of the following: pp or ppt.,"templates.loc[lambda x: x['template_type_code'].isin(['pp', 'ppt']), 'template_id']"
what is the number of templates that have template type code cv?,(templates['template_type_code'] == 'cv').sum()
determine the number of templates of the type cv.,(templates['template_type_code'] == 'cv').sum()
provide the full names and template type code of all the templates that are equipped with a version number greater than 5.,"templates.loc[lambda x: x['version_number'] > 5, ['version_number', 'template_type_code']]"
"which template codes are used most often, and how many documents correspond to each?",templates.groupby('template_type_code').size()
which template type code holds the maximum number of templates?,templates.groupby('template_type_code').size().sort_values(ascending=false).index[0]
provide me with the template type code that is used by the highest number of templates.,templates.groupby('template_type_code').size().sort_values(ascending=false).index[0]
list the titles of template type codes with less than three instances.,templates.groupby('template_type_code').filter(lambda x: len(x) < 3)['template_type_code'].unique()
which template type codes do not exceed 3?,templates.groupby('template_type_code').filter(lambda x: len(x) < 3)['template_type_code'].unique()
please provide me the lowest version number and the template for type code.,templates.groupby('template_type_code')['version_number'].min()
display the lowest version number of a template type code.,templates.groupby('template_type_code')['version_number'].min()
"what is the template type code of the template which was used for a document with the name ""data base""?","pd.merge(templates, documents.loc[lambda x: x['document_name']=='data base'], on='template_id').loc[:, 'template_type_code']"
please identify for me the template type code of the template that is utilized in the relational database titled data base.,"pd.merge(templates, documents.loc[lambda x: x['document_name']=='data base'], on='template_id').loc[:, 'template_type_code']"
display all documents with template type code bk.,"pd.merge(templates.loc[lambda x: x['template_type_code']=='bk'], documents, on='template_id')['document_name']"
show me template type codes and the number of documents using them.,"pd.merge(templates, documents, on='template_id').groupby('template_type_code')['template_id'].count()"
retrieve the total count of template type codes among the total documents.,"pd.merge(templates, documents, on='template_id').groupby('template_type_code')['template_id'].count()"
for which template type codes do most documents use?,"pd.merge(templates, documents, on='template_id').groupby('template_type_code').size().sort_values(ascending=false).index[0]"
provide me with the code for the template type that is most frequently used in all documents.,"pd.merge(templates, documents, on='template_id').groupby('template_type_code').size().sort_values(ascending=false).index[0]"
provide the names of the template codes that are not utilized by any document.,"templates['template_type_code'].loc[lambda x: ~x.isin(pd.merge(templates, documents, on='template_id')['template_type_code'])]"
which template type codes are not utilized for any document?,"templates['template_type_code'].loc[lambda x: ~x.isin(pd.merge(templates, documents, on='template_id')['template_type_code'])]"
retrieve the codes and complete descriptions for all template types.,"ref_template_types[['template_type_code', 'template_type_description']]"
"what are the description descriptions for template type code ""ad"".","ref_template_types.loc[lambda x: x['template_type_code']=='ad', 'template_type_description']"
please provide me with all the template type descriptions of templates of type ad.,"ref_template_types.loc[lambda x: x['template_type_code']=='ad', 'template_type_description']"
"what is the template type code for template type description ""book""?","ref_template_types.loc[lambda x: x['template_type_description']=='book', 'template_type_code']"
"what are the type codes for template types that have the description ""book""?","ref_template_types.loc[lambda x: x['template_type_description']=='book', 'template_type_code']"
what is the count of distinct template type descriptions that were used for any documents?,"pd.merge(pd.merge(ref_template_types, templates, on='template_type_code'), documents, on='template_id')['template_type_description'].unique()"
provide the descriptions provided for the templates for templates utilized in a doc.,"pd.merge(pd.merge(ref_template_types, templates, on='template_type_code'), documents, on='template_id')['template_type_description'].unique()"
please provide me with the id and description of templates of the type presentation.,"pd.merge(ref_template_types, templates, on='template_type_code').loc[lambda x: x['template_type_description']=='presentation', 'template_id']"
identify the ids corresponding to templates that have the description 'presentation'.,"pd.merge(ref_template_types, templates, on='template_type_code').loc[lambda x: x['template_type_description']=='presentation', 'template_id']"
how many paragraphs were actually utilized?,paragraphs.shape[0]
determine the number of paragraphs.,paragraphs.shape[0]
"how many paragraphs were written for the document with the name ""summer show""?","pd.merge(paragraphs, documents, on='document_id').loc[lambda x: x['document_name']=='summer show'].shape[0]"
what is the count of paragraphs in the document named 'summer show'?,"pd.merge(paragraphs, documents, on='document_id').loc[lambda x: x['document_name']=='summer show'].shape[0]"
"show paragraph details for paragraph having text ""korea"".","paragraphs.loc[paragraphs['paragraph_text'].str.contains('korea'), 'other_details']"
"what is the subject of the paragraph that describes ""korea""?","paragraphs.loc[paragraphs['paragraph_text'].str.contains('korea'), 'other_details']"
obtain the paragraph ids and texts of the document with name 'welcome to ny',"pd.merge(paragraphs, documents, on='document_id').loc[lambda x: x['document_name']=='welcome to ny', ['paragraph_id', 'paragraph_text']]"
"retrieve the ids and texts of paragraphs in the document titled ""welcome to ny"".","pd.merge(paragraphs, documents, on='document_id').loc[lambda x: x['document_name']=='welcome to ny', ['paragraph_id', 'paragraph_text']]"
"display all paragraph texts for the ""customer reviews"" document.","paragraphs.merge(documents.query('document_name == ""customer reviews""'), on='document_id')['paragraph_text']"
"what are the paragraph texts for the document with the name ""customer reviews""?","paragraphs.merge(documents.query('document_name == ""customer reviews""'), on='document_id')['paragraph_text']"
list out the document ids and the total number of paragraphs in each document. order the results by ascending document ids.,paragraphs.groupby('document_id').size().reset_index(name='count').sort_values('document_id')
"i require the list of document ids along with the number of paragraphs associated with each. in the list, arrange the items in alphabetical order by id.",paragraphs.groupby('document_id').size().reset_index(name='count').sort_values('document_id')
"provide me with the id, name, and number of paragraphs of each document.","pd.merge(paragraphs, documents, on='document_id').groupby(['document_id', 'document_name']).size().reset_index(name='count')"
list all document ids with at least 2 paragraphs.,paragraphs.groupby('document_id').filter(lambda x: len(x) >=2).document_id.unique()
what ids are of the documents that have more than 2 paragraphs?,paragraphs.groupby('document_id').filter(lambda x: len(x) >=2).document_id.unique()
which document has the most paragraphs associated with it?,"pd.merge(paragraphs, documents, on='document_id').groupby('document_id').size().sort_values(ascending=false).reset_index(name='count').iloc[0][['document_id', 'document_name']]"
provide the id and name of the document that contains the most paragraphs.,"pd.merge(paragraphs, documents, on='document_id').groupby('document_id').size().sort_values(ascending=false).reset_index(name='count').iloc[0][['document_id', 'document_name']]"
what is the id of a document with least number of paragraphs?,paragraphs.groupby('document_id').size().sort_values().head(1).index[0]
please return the id of the document with the fewest number of paragraphs.,paragraphs.groupby('document_id').size().sort_values().head(1).index[0]
could you provide me with the document id that has 1 to 2 paragraphs?,paragraphs.groupby('document_id').filter(lambda x: x.shape[0] >= 1 and x.shape[0] <=2)['document_id'].unique()
point me to the ids of the documents that have between one and two paragraphs.,paragraphs.groupby('document_id').filter(lambda x: x.shape[0] >= 1 and x.shape[0] <=2)['document_id'].unique()
"please return the document id that contains text ""brazil"" and ""ireland"".","pd.merge(paragraphs.loc[lambda x: x['paragraph_text']=='brazil', 'document_id'], paragraphs.loc[lambda x: x['paragraph_text']=='ireland', 'document_id'], how='inner')"
what ids of documents contain the paragraph text 'brazil' and 'ireland'?,"pd.merge(paragraphs.loc[lambda x: x['paragraph_text']=='brazil', 'document_id'], paragraphs.loc[lambda x: x['paragraph_text']=='ireland', 'document_id'], how='inner')"
what is the list of teachers according to their ages?,teacher.sort_values('age')['name']
please list the names of teachers that are ordered by ascending age.,teacher.sort_values('age')['name']
get the names of the teachers of the same age and hometown.,"teacher[['age', 'hometown']]"
provide me with the age and hometown for each employee.,"teacher[['age', 'hometown']]"
list the names of teachers whose hometown is not little lever urban district.,"teacher.loc[lambda x: x['hometown'] != 'little lever urban district', 'name']"
return the names of the professors whose hometown is not little lever urban district.,"teacher.loc[lambda x: x['hometown'] != 'little lever urban district', 'name']"
please list the names of teachers either in their 32 or 33 age.,"teacher.loc[lambda x: x['age'].isin([32,33]), 'name']"
provide the names of teachers that are aged either 32 or 33.,"teacher.loc[lambda x: x['age'].isin([32,33]), 'name']"
what school is the teacher who is the youngest affiliated with?,teacher.sort_values('age')['hometown'].iloc[0]
list the different hometown of teachers and the count of teachers from each hometown.,teacher.groupby('hometown').size().reset_index(name='count')
what is the superset of most common hometowns for teachers?,teacher.groupby('hometown').size().sort_values(ascending=false).index[0]
determine the hometowns of two teachers shared in common.,teacher.groupby('hometown').filter(lambda x: len(x) >= 2)['hometown'].unique()
which are the towns that have at least one teacher coming from it?,teacher.groupby('hometown').filter(lambda x: len(x) >= 2)['hometown'].unique()
present the names of teachers that teach specific courses.,"pd.merge(pd.merge(course_arrange, course, on='course_id'), teacher, on='teacher_id')[['name', 'course']]"
fetch the titles of each teacher and the course they teach.,"pd.merge(pd.merge(course_arrange, course, on='course_id'), teacher, on='teacher_id')[['name', 'course']]"
list the names of teachers and the courses they are arranged to teach in alphabetical order of the name of the teacher.,"pd.merge(pd.merge(course_arrange, course, on='course_id'), teacher, on='teacher_id').sort_values('name')[['name', 'course']]"
"provide me with the names and course descriptions of the teachers, in ascending order, based on their last name.","pd.merge(pd.merge(course_arrange, course, on='course_id'), teacher, on='teacher_id').sort_values('name')[['name', 'course']]"
obtain the title of the teacher for the math course.,"pd.merge(pd.merge(course_arrange, course, on='course_id'), teacher, on='teacher_id').loc[lambda x: x['course']=='math', 'name']"
list the names of the individuals who teach mathematics courses.,"pd.merge(pd.merge(course_arrange, course, on='course_id'), teacher, on='teacher_id').loc[lambda x: x['course']=='math', 'name']"
retrieve the names of teachers together with the courses and subjects they teach.,"pd.merge(course_arrange, teacher, on='teacher_id').groupby('name').size()"
find the names of teachers and the count of courses they teach.,"pd.merge(course_arrange, teacher, on='teacher_id').groupby('name').size()"
provide me with the names of teachers that teach at least two courses.,"pd.merge(course_arrange, teacher, on='teacher_id').groupby('name').filter(lambda x: len(x) >= 2)['name'].unique()"
please provide me with the names of teachers that teach at least two courses.,"pd.merge(course_arrange, teacher, on='teacher_id').groupby('name').filter(lambda x: len(x) >= 2)['name'].unique()"
enumerate the names of teachers who have not been assigned to teach courses.,teacher[~teacher['teacher_id'].isin(course_arrange['teacher_id'])]['name']
retrieve the names of teachers whose courses have not been arranged.,teacher[~teacher['teacher_id'].isin(course_arrange['teacher_id'])]['name']
how many visitors are younger than 30?,(visitor['age'] < 30).sum()
retrieve the names of visitors whose level is higher than 4 and order the results by level from high to low.,"visitor.loc[lambda x: x['level_of_membership'] > 4].sort_values('level_of_membership', ascending=false)['name']"
what is the mean of visitors whose membership level is not higher than 4?,"visitor.loc[lambda x: x['level_of_membership'] <= 4, 'age'].mean()"
"what is the name and membership level of visitors whose membership level is greater than 4, and sort the lists by age from old to young?","visitor.loc[lambda x: x['level_of_membership']>4, ['name', 'level_of_membership']].sort_values('age', ascending=false)"
please provide me with the id and name of the museum that has the highest number of employees.,"museum[['museum_id', 'name']].sort_values('num_of_staff', ascending=false).iloc[0]"
what is the average of the total number of employees working in the museums that were open before 2009?,"museum.loc[museum['open_year'] < 2009, 'num_of_staff'].mean()"
provide me with the opening and closing year and the total number of staff for the plaza museum.,"museum.loc[museum['name']=='plaza museum', ['num_of_staff', 'open_year']]"
retrieve names of museums which have more staff than the minimum staffing level of all museums opened after 2010.,"museum.loc[lambda x: x['num_of_staff'] > museum.loc[lambda y: y['open_year']>2010, 'num_of_staff'].min(), 'name']"
"retrieve the ids, names, and ages of visitors for museums that were several times visited.","visitor.merge(visit, on='id').groupby(['id', 'name', 'age']).filter(lambda x: len(x) > 1).drop_duplicates(subset=['id', 'name', 'age']).loc[:, ['id', 'name', 'age']]"
provide me with the list of visitors who were the highest spenders in all museum tickets along with their ids and names.,"visitor.merge(visit, on='id').groupby(['visitor_id', 'name', 'level_of_membership']).agg({'total_spent': 'sum'}).reset_index().sort_values('total_spent', ascending=false).iloc[0, [0, 1, 2]]"
enumerate the id and full name of the most visited museum.,"pd.merge(museum, visit, on='museum_id').groupby('museum_id')['name'].count().nlargest(1).reset_index(name='count').merge(museum, on='museum_id')[['museum_id', 'name']]"
what is the name of the museum that had absolutely no visitors?,"museum.loc[~museum['museum_id'].isin(visit['museum_id']), 'name']"
retrieve the name and age of the visitor who purchased the most tickets at a time.,"pd.merge(visitor, visit, on='id').sort_values('num_of_ticket', ascending=false).iloc[0][['name', 'age']]"
what is the count of tickets that were bought by each customer?,"visit['num_of_ticket'].agg(['mean', 'max'])"
how many tickets were purchased by the people who possess the lowest level membership?,"pd.merge(visitor[visitor['level_of_membership']==1], visit, left_on='id', right_on='visitor_id')['total_spent'].sum()"
please return the name of visitor who visited both of these museums: a museum opened before 2009 and a museum opened after 2011.,"visitor.loc[pd.merge(pd.merge(visit, museum.loc[lambda x: x['open_year']<2009]), visitor, left_on='visitor_id', right_on='id')['name_x'].unique().tolist() & pd.merge(pd.merge(visit, museum.loc[lambda x: x['open_year']>2011]), visitor, left_on='visitor_id', right_on='id')['name_x'].unique().tolist()].name"
determine the count of individuals that did not visit any museum that opened after 2010.,"visitor.loc[~visitor['id'].isin(visit.loc[museum['open_year']>2010, 'visitor_id']), :].shape[0]"
at what time were the maximum number of museums established?,((museum['open_year'] > 2013) | (museum['open_year'] < 2008)).sum()
determine the count of players.,players.shape[0]
how much number of users are there?,players.shape[0]
return (nummatches);,matches.shape[0]
what are the total number of matches?,matches.shape[0]
list the first name and birthdate of all players from the united states with code usa.,"players.loc[lambda x: x['country_code']=='usa', ['first_name', 'birth_date']]"
what are the first and last names and birth dates of players that are from the usa?,"players.loc[lambda x: x['country_code']=='usa', ['first_name', 'birth_date']]"
please return me the average age of winners and losers in all matches.,"matches.agg({'loser_age': 'mean', 'winner_age': 'mean'})"
show me the records of the ages of winners and losers across matches.,"matches.agg({'loser_age': 'mean', 'winner_age': 'mean'})"
determine the average rank of winners in all matches.,matches['winner_rank'].mean()
what is the mean rank for winners in all matches?,matches['winner_rank'].mean()
find the highest rank of losers across all matches.,matches['loser_rank'].min()
what is the rank order of losers across all matches?,matches['loser_rank'].min()
provide me with the total number of country codes of players.,players['country_code'].nunique()
what is the count of the number of countries that players come from?,players['country_code'].nunique()
provide me with the count of distinct names of candidates that lost.,matches['loser_name'].nunique()
what is the count of unique loser names?,matches['loser_name'].nunique()
what are the titles of the tournaments in which more than 10 matches were played?,matches.groupby('tourney_name').filter(lambda x: x['tourney_name'].count()>10)['tourney_name'].unique()
"what is the title, last name, and first name of the players who have won in the championships of 2013 and 2016?",matches[matches['year']==2013]['winner_name'].interesect(matches[matches['year']==2016]['winner_name'])
provide the count of all matches that played in years 2013 or 2016.,"matches.loc[matches['year'].isin([2013, 2016])].shape[0]"
what is the count of matches played in the year 2013 or 2016?,"matches.loc[matches['year'].isin([2013, 2016])].shape[0]"
which country code and first and last name were first won at both wta championships and australian open tournament?,"pd.merge(players.loc[lambda x: x['player_id'].isin(matches.loc[lambda y: y['tourney_name']=='wta championships', 'winner_id']), ['country_code', 'first_name']],players.loc[lambda x: x['player_id'].isin(matches.loc[lambda y: y['tourney_name']=='australian open', 'winner_id']), ['country_code', 'first_name']],on=['country_code', 'first_name'])"
retrieve the first names and country codes of the players who achieved victories in both the wta championships and the australian open.,"pd.merge(players.loc[lambda x: x['player_id'].isin(matches.loc[lambda y: y['tourney_name']=='wta championships', 'winner_id']), ['country_code', 'first_name']],players.loc[lambda x: x['player_id'].isin(matches.loc[lambda y: y['tourney_name']=='australian open', 'winner_id']), ['country_code', 'first_name']],on=['country_code', 'first_name'])"
please provide me with the first name and country code of the oldest player.,"players[['first_name', 'country_code']].sort_values('birth_date').head(1)"
in which order are the first and last names of all players?,"players[['first_name', 'last_name']].sort_values('birth_date')"
please arrange the full names of all players by their birthdates.,"players[['first_name', 'last_name']].sort_values('birth_date')"
provide me with the names of all players who were left / left hand in the order of their birth date.,"players.loc[lambda x: x['hand']=='l', ['first_name', 'last_name']].sort_values('birth_date')"
"return me the full names of all players, still lefthanded, in order of birth date.","players.loc[lambda x: x['hand']=='l', ['first_name', 'last_name']].sort_values('birth_date')"
provide me with the name and country code of the player who completed the greatest number of tours.,"pd.merge(players, rankings, on='player_id').sort_values('tours', ascending=false).iloc[0][['country_code', 'first_name']]"
who is the player who has played the highest number of international matches?,"pd.merge(players, rankings, on='player_id').sort_values('tours', ascending=false).iloc[0][['country_code', 'first_name']]"
determine which year saw the maximum number of matchups.,matches.groupby('year').size().sort_values(ascending=false).index[0]
which year had the highest count of matches?,matches.groupby('year').size().sort_values(ascending=false).index[0]
retrieve the full name and points earned by the winner who won the maximum number of times.,matches.groupby('winner_name')['winner_rank_points'].agg(lambda x: x.sum()).sort_values(ascending=false).iloc[:1]
"provide the name of the player who won the highest number of matches, and note the rank points that the player has earned.",matches.groupby('winner_name')['winner_rank_points'].agg(lambda x: x.sum()).sort_values(ascending=false).iloc[:1]
determine the title of the winner who has the highest rank points and participated in the australian open tourney.,"matches.loc[lambda x: x['tourney_name']=='australian open', 'winner_name'].sort_values(ascending=false).iloc[0]"
retrieve the name of the participant who won the australian open tournament and was most successful in the rank points.,"matches.loc[lambda x: x['tourney_name']=='australian open', 'winner_name'].sort_values(ascending=false).iloc[0]"
find the names of loser and winner who played in the match with maximum number of minutes.,"matches.sort_values('minutes', ascending=false).iloc[0][['winner_name', 'loser_name']]"
retrieve the titles and names of the player that occupied the longest position in a match.,"matches.sort_values('minutes', ascending=false).iloc[0][['winner_name', 'loser_name']]"
determine the average rank and first name of all players.,"pd.merge(players, rankings, on='player_id').groupby('first_name')['ranking'].mean()"
"provide the first and last names of all players, and retrieve their average ranking.","pd.merge(players, rankings, on='player_id').groupby('first_name')['ranking'].mean()"
provide me with the list of players along with their total ranking points along with their first names.,"pd.merge(players, rankings, on='player_id').groupby('first_name')['ranking_points'].sum()"
please provide me with the full names and total ranking points of all players.,"pd.merge(players, rankings, on='player_id').groupby('first_name')['ranking_points'].sum()"
retrieve the number of players for each country.,players.groupby('country_code').size().reset_index(name='count')
what is the code for the country that has the most players?,players.groupby('country_code').size().sort_values(ascending=false).index[0]
what country has the highest count of players?,players.groupby('country_code').size().sort_values(ascending=false).index[0]
what are the codes for countries that have more than 50 active players?,players.groupby('country_code').filter(lambda x: len(x) > 50)['country_code'].unique()
retrieve the codes for countries in which more than 50 football players were selected.,players.groupby('country_code').filter(lambda x: len(x) > 50)['country_code'].unique()
provide me with the total number of tours for each ranking date.,rankings.groupby('ranking_date')['tours'].sum()
please provide me with the count of tours for each ranking date.,rankings.groupby('ranking_date')['tours'].sum()
provide us with the count of matches that transpired in each year.,matches.groupby('year').size().reset_index(name='count')
how many matches were played each year?,matches.groupby('year').size().reset_index(name='count')
retrieve the names of and ranks of the three youngest winners across all matches.,"matches[['winner_name', 'winner_rank', 'winner_age']].drop_duplicates().sort_values('winner_age').iloc[:3][['winner_name', 'winner_rank']]"
which are the three youngest winners in the matches.,"matches[['winner_name', 'winner_rank', 'winner_age']].drop_duplicates().sort_values('winner_age').iloc[:3][['winner_name', 'winner_rank']]"
how many different winners were both participants of the wta championships and left handed?,"matches.loc[(matches['tourney_name']=='wta championships')&(matches['winner_hand']=='l'), 'winner_name'].nunique()"
find the number of left handed champions who participated in the wta championships.,"matches.loc[(matches['tourney_name']=='wta championships')&(matches['winner_hand']=='l'), 'winner_name'].nunique()"
"fetch the first name, the country code and the date of birth of the person who has the highest rank points in all matches.","pd.merge(players, matches, left_on='player_id', right_on='winner_id').sort_values('winner_rank_points', ascending=false).iloc[0][['first_name', 'country_code', 'birth_date']]"
"return the name of the player, the country code, and the date of birth of the participant that scored the highest number of winner rank points across all matches.","pd.merge(players, matches, left_on='player_id', right_on='winner_id').sort_values('winner_rank_points', ascending=false).iloc[0][['first_name', 'country_code', 'birth_date']]"
determine the number of players associated with each hand type.,players.groupby('hand').size().reset_index(name='count')
what is the count of players who play each hand type?,players.groupby('hand').size().reset_index(name='count')
how many ships ended up being 'captured' in a war?,(ship['disposition_of_ship'] == 'captured').sum()
provide the title and tonnage details in the descending alphabetical order.,"ship[['name', 'tonnage']].sort_values('name', ascending=false)"
"enumerate the titles, dates, and outcomes of each battle.","battle[['name', 'date']]"
what is the minimum and maximum number of casualties caused due to earthquakes?,"death['killed'].agg(['max', 'min'])"
what is the injury count average for each accident?,death['injured'].mean()
what is the count of death and injury incidents caused by the ship whose tonnage is 't'?,"pd.merge(death, ship, left_on='caused_by_ship_id', right_on='id').query('tonnage==""t""')[['killed','injured']]"
"find the name and precise outcome of the battles in which an bulgarian commander other than ""boril"" was chief.","battle.loc[battle['bulgarian_commander'] != 'boril', ['name', 'result']]"
what are the different ids and names of battles in which any 'brig' type ship was lost?,"pd.merge(battle, ship.loc[lambda x: x['ship_type'] == 'brig'], left_on='id', right_on='lost_in_battle')[['id', 'name']].drop_duplicates()"
provide me with details of the battles resulting in more than 10 deaths in total.,"pd.merge(pd.merge(battle, ship, left_on='id', right_on='lost_in_battle'), death, left_on='lost_in_battle', right_on='caused_by_ship_id').groupby(['id', 'name']).sum().loc[lambda x: x['killed'] > 10].reset_index()[['id', 'name']]"
what ship caused the suffering of the greatest number of injuries?,"death.merge(ship, left_on='caused_by_ship_id', right_on='id').groupby(['id', 'name']).size().sort_values(ascending=false).head(1).reset_index()[['id', 'name']]"
find the names of battles that take place between bulgarian commander kaloyan and latin commander baldwin i.,"battle.loc[(battle['bulgarian_commander'] == 'kaloyan') & (battle['latin_commander'] == 'baldwin i'), 'name']"
find out the total number of outcomes for the battles.,battle['result'].nunique()
how many battles did not lose a ship which had tonnage '225'?,"len(battle[~battle['id'].isin(ship.loc[ship['tonnage']==225, 'lost_in_battle'])])"
"provide the name of the battle (and the date of battle if known) in which the ships ""lettice"" and ""hms atalanta"" were both lost.","pd.merge(battle[battle['id'].isin(ship.query(""name == 'lettice' or name == 'hms atalanta'"")['lost_in_battle'])].query(""name == 'lettice'"").loc[:, ['name', 'date']], battle[battle['id'].isin(ship.query(""name == 'lettice' or name == 'hms atalanta'"")['lost_in_battle'])].query(""name == 'hms atalanta'"").loc[:, ['name', 'date']]).reset_index(drop=true)"
list the name of the battles with no ships lost in the english channel along with the names of their commanders.,"battle.merge(ship, left_on='id', right_on='lost_in_battle', how='left', indicator=true).loc[lambda x: x['_merge']=='left_only', ['name', 'result', 'bulgarian_commander']].reset_index(drop=true)"
"retrieve the number of death events that have the substring ""east"".","death.loc[death['note'].str.contains('east'), 'note']"
which line 1 and line 2 addresses do i have?,"addresses[['line_1', 'line_2']]"
provide me the titles for the first and second lines for all addresses.,"addresses[['line_1', 'line_2']]"
what is the total count of courses?,courses.shape[0]
how are mathematics courses characterized?,"courses.loc[courses['course_name'] == 'math', 'course_description']"
find the description of all the math classes.,"courses.loc[courses['course_name'] == 'math', 'course_description']"
what zip code is assigned to the street address in the city port chelsea?,"addresses.loc[lambda x: x['city']=='port chelsea', 'zip_postcode']"
what is the code for the zip code pertaining to port chelsea?,"addresses.loc[lambda x: x['city']=='port chelsea', 'zip_postcode']"
please provide me with the department that offered the most number of degrees along with their respective id.,"pd.merge(degree_programs, departments, on='department_id').groupby('department_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['department_name', 'department_id']]"
retrieve the name of a department that has the maximum number of degrees.,"degree_programs.merge(departments, on='department_id').groupby('department_name')['department_id'].count().sort_values(ascending=false).head(1).reset_index()[['department_name', 'department_id']]"
how many departments offer degrees?,degree_programs['department_id'].nunique()
how many different colleges are offering degrees?,degree_programs['department_id'].nunique()
how many kinds of degrees are offered?,degree_programs['degree_summary_name'].nunique()
what is the number of various degrees offered?,degree_programs['degree_summary_name'].nunique()
how many academic degrees does the engineering department possess?,"department.loc[lambda x: x['department_name']=='engineer'].merge(degree_program, on='department_id').shape[0]"
retrieve the names and descriptions of all sections.,"sections[['section_name', 'section_description']]"
retrieve the names and description of all the sections.,"sections[['section_name', 'section_description']]"
return me the names of courses that have two sections at most.,"pd.merge(courses, sections, on='course_id').groupby(['course_id', 'course_name']).filter(lambda x: len(x) <= 2)[['course_id', 'course_name']].drop_duplicates()"
provide me the names of every course with less than 2 sections.,"pd.merge(courses, sections, on='course_id').groupby(['course_id', 'course_name']).filter(lambda x: len(x) <= 2)[['course_id', 'course_name']].drop_duplicates()"
retrieve the section names in the reversed alphabetical order.,"sections.sort_values('section_name', ascending=false)['section_name']"
return the names of the sections in reverse alphabetical order.,"sections.sort_values('section_name', ascending=false)['section_name']"
list the semester code along with the names and ids of the students whose registrations were highest in that semester.,"pd.merge(semesters, student_enrolment, on='semester_id').groupby('semester_id').agg({'semester_name': 'first', 'semester_id': 'count'}).sort_values('semester_id', ascending=false).iloc[0][['semester_name', 'semester_id']]"
what is the name and id of a semester with the most students enrolled?,"pd.merge(semesters, student_enrolment, on='semester_id').groupby('semester_id').agg({'semester_name': 'first', 'semester_id': 'count'}).sort_values('semester_id', ascending=false).iloc[0][['semester_name', 'semester_id']]"
obtain the individuals enrolled in two degree programs in one semester along with their ids.,"students.merge(student_enrolment, on='student_id').groupby(['first_name', 'middle_name', 'last_name', 'student_id']).filter(lambda x: len(x) == 2)[['first_name', 'middle_name', 'last_name', 'student_id']]"
"please provide the ids, first names, middle names, and last names of the students that enrolled in two degree programs in one semester.","students.merge(student_enrolment, on='student_id').groupby(['first_name', 'middle_name', 'last_name', 'student_id']).filter(lambda x: len(x) == 2)[['first_name', 'middle_name', 'last_name', 'student_id']]"
"list the students enrolled in a bachelor degree program with their first name, middle name, and last name.","pd.merge(pd.merge(students, student_enrollment, on='student_id'), degree_programs, on='degree_program_id').loc[lambda x: x['degree_summary_name']=='bachelor', ['first_name', 'middle_name', 'last_name']].drop_duplicates()"
compose the full name for each person enrolled in a bachelors program.,"pd.merge(pd.merge(students, student_enrollment, on='student_id'), degree_programs, on='degree_program_id').loc[lambda x: x['degree_summary_name']=='bachelor', ['first_name', 'middle_name', 'last_name']].drop_duplicates()"
what is the program type that is being attended by the most number of students?,"pd.merge(degree_programs, student_enrolment, on='degree_program_id').groupby('degree_summary_name').size().sort_values(ascending=false).index[0]"
what is the degree name that has the maximum number of students enrolled?,"pd.merge(degree_programs, student_enrolment, on='degree_program_id').groupby('degree_summary_name').size().sort_values(ascending=false).index[0]"
list the program names that have the highest number of students enrolled.,"pd.merge(degree_programs, student_enrolment, on='degree_program_id').groupby('degree_program_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['degree_program_id', 'degree_summary_name']]"
please provide me with the total number and title of the highest degree program in which the greatest number of students are enrolled.,"pd.merge(degree_programs, student_enrolment, on='degree_program_id').groupby('degree_program_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['degree_program_id', 'degree_summary_name']]"
"list the student that enrolled for the maximum times in each program. list the id, first name, middle name, last name, number of enrollments, and student id.","students_enrolment.groupby('student_id').size().reset_index(name='count').merge(students, on='student_id').sort_values('count', ascending=false).iloc[0][['student_id', 'first_name', 'middle_name', 'last_name', 'count', 'student_id']]"
provide the first and last name and id number and count of enrollments of a student that enrolled in the maximum number of programs.,"students_enrolment.groupby('student_id').size().reset_index(name='count').merge(students, on='student_id').sort_values('count', ascending=false).iloc[0][['student_id', 'first_name', 'middle_name', 'last_name', 'count', 'student_id']]"
list the names of the semesters in which no student is enrolled.,"semesters.loc[~semesters['semester_id'].isin(student_enrolment['semester_id']), 'semester_name']"
which semester has the fewest students enrolled?,"semesters.loc[~semesters['semester_id'].isin(student_enrolment['semester_id']), 'semester_name']"
list all the course names of the courses which ever enrolled an any student.,"pd.merge(courses, student_enrolment_courses, on='course_id')['course_name'].unique()"
get the names of all courses in which there are some students.,"pd.merge(courses, student_enrolment_courses, on='course_id')['course_name'].unique()"
what is the title of course with the maximum number of enrollments?,"pd.merge(courses, student_enrolment_courses, on='course_id').groupby('course_name').size().sort_values(ascending=false).index[0]"
which course received the most enrollment?,"pd.merge(courses, student_enrolment_courses, on='course_id').groupby('course_name').size().sort_values(ascending=false).index[0]"
provide me with the last names of the students residing in the state of north carolina but have not registered in any degree program.,"students.merge(addresses, left_on='current_address_id', right_on='address_id').loc[lambda x: x['state_province_county']=='northcarolina', 'last_name'].drop_duplicates().append(students.merge(student_enrolment, on='student_id').drop_duplicates(subset=['student_id']).loc[:, 'last_name']).drop_duplicates(keep=false)"
please list out the last names of the students residing in north carolina who have not registered in any degree programs.,"students.merge(addresses, left_on='current_address_id', right_on='address_id').loc[lambda x: x['state_province_county']=='northcarolina', 'last_name'].drop_duplicates().append(students.merge(student_enrolment, on='student_id').drop_duplicates(subset=['student_id']).loc[:, 'last_name']).drop_duplicates(keep=false)"
retrieve the date and id information of the transcript that contains at least two course results.,"pd.merge(transcript_contents, transcripts, on='transcript_id').groupby('transcript_id').filter(lambda x: len(x)>=2)[['transcript_date', 'transcript_id']]"
please provide me the dates and ids of the transcripts whose sections contain at least 2 courses.,"pd.merge(transcript_contents, transcripts, on='transcript_id').groupby('transcript_id').filter(lambda x: len(x)>=2)[['transcript_date', 'transcript_id']]"
what is the phone number of a man with a first name of timmothy and a last name of ward?,"students.loc[(students['first_name']=='timmothy') & (students['last_name']=='ward'), 'cell_mobile_number']"
what is the mobile phone number of the student named timmothy ward?,"students.loc[(students['first_name']=='timmothy') & (students['last_name']=='ward'), 'cell_mobile_number']"
"please list the first name, middle name and last name of the first student to register.",students.sort_values('date_first_registered')['first_name':'last_name'].iloc[:1]
"what are the names of the student to mention first, second, and third, respectively?",students.sort_values('date_first_registered')['first_name':'last_name'].iloc[:1]
list the name of the graduating student that is the earliest school graduate.,"students.sort_values('date_left').iloc[0, ['first_name', 'middle_name', 'last_name']]"
"retrieve the first, middle, and last name of the earliest school graduates.","students.sort_values('date_left').iloc[0, ['first_name', 'middle_name', 'last_name']]"
"list the names of people along with their permanent and current addresses. also, provide their full names","students.loc[students['current_address_id'] != students['permanent_address_id'], 'first_name']"
what is the full name of the student who has one permanent address but another current address?,"students.loc[students['current_address_id'] != students['permanent_address_id'], 'first_name']"
what is the address of the largest student population? list the id and address lines.,"addresses.merge(students, left_on='address_id', right_on='current_address_id').groupby(['address_id', 'line_1', 'line_2']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['address_id', 'line_1', 'line_2']]"
"please provide me with the id, line one, and line two of the address that has the most students.","addresses.merge(students, left_on='address_id', right_on='current_address_id').groupby(['address_id', 'line_1', 'line_2']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['address_id', 'line_1', 'line_2']]"
please return me the average date when transcripts were printed.,transcripts['transcript_date'].mean()
provide the average number of transcript dates.,transcripts['transcript_date'].mean()
when was the first transcript released? provide the list of names and dates.,"transcripts[['transcript_date', 'other_details']].sort_values('transcript_date').iloc[0]"
what data can i find about the earliest date on which a transcript was released and what details can you tell me about it?,"transcripts[['transcript_date', 'other_details']].sort_values('transcript_date').iloc[0]"
what is the total of releases?,transcripts.shape[0]
when was the most recent transcript released?,transcripts['transcript_date'].sort_values(ascending=false).iloc[0]
when was the last transcript published?,transcripts['transcript_date'].sort_values(ascending=false).iloc[0]
"how many enrollment results can a course have at most? also, how many enrollment results are there in the course 14305?","transcript_contents.groupby('student_course_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
how many courses were attended by a given number of students?,"transcript_contents.groupby('student_course_id').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]"
"provide me the date of the earliest transcript that yields the least number of results, at the same time provide me the identifier.","pd.merge(transcript_contents, transcripts, on='transcript_id').groupby('transcript_id').size().sort_values().reset_index(name='count').iloc[0, :][['transcript_date', 'transcript_id']]"
what is the date and id of the transcript with the fewest results?,"pd.merge(transcript_contents, transcripts, on='transcript_id').groupby('transcript_id').size().sort_values().reset_index(name='count').iloc[0, :][['transcript_date', 'transcript_id']]"
provide me with the semester when both master and bachelor students were enrolled.,"pd.merge(student_enrollment.loc[student_enrollment['degree_program_id'].isin(degree_programs.loc[degree_programs['degree_summary_name']=='master', 'degree_program_id'].unique()), ['semester_id']].drop_duplicates(), student_enrollment.loc[student_enrollment['degree_program_id'].isin(degree_programs.loc[degree_programs['degree_summary_name']=='bachelor', 'degree_program_id'].unique()), ['semester_id']].drop_duplicates(), on='semester_id')['semester_id']"
find the id of the semester in which both masters and bachelors students were enrolled.,"pd.merge(student_enrollment.loc[student_enrollment['degree_program_id'].isin(degree_programs.loc[degree_programs['degree_summary_name']=='master', 'degree_program_id'].unique()), ['semester_id']].drop_duplicates(), student_enrollment.loc[student_enrollment['degree_program_id'].isin(degree_programs.loc[degree_programs['degree_summary_name']=='bachelor', 'degree_program_id'].unique()), ['semester_id']].drop_duplicates(), on='semester_id')['semester_id']"
what is the count of different addresses that the students are currently living?,students['current_address_id'].nunique()
what is the list of residential addresses that have students residing there?,students['current_address_id'].nunique()
identify all the student details in lexicographical order.,students['other_student_details'].sort_values(ascending=false)
could you provide me with additional details about students in an ascending order?,students['other_student_details'].sort_values(ascending=false)
"describe the ""h"" section.","sections.loc[lambda x: x['section_name']=='h', 'section_description']"
"please give me a summary of the section named ""h"".","sections.loc[lambda x: x['section_name']=='h', 'section_description']"
retrieve the first names of students who permanently reside in haiti or have the phone 09700166582.,"students.merge(addresses, left_on='permanent_address_id', right_on='address_id').loc[lambda x: (x['country']=='haiti') | (x['cell_mobile_number']=='09700166582'), 'first_name']"
alphabetically sort the titles of all the cartoons.,cartoon.sort_values('title')['title']
sort the titles of cartoons alphabetically.a:first output your initial array of sentences as a csv or tab delimited text file.  then use an appropriate perl module.,cartoon.sort_values('title')['title']
"retrieve all the cartoons directed by ""ben jones"".","cartoon.loc[lambda x: x['directed_by']=='ben jones', 'title']"
return the titles of comic products that were directed by ben jones.,"cartoon.loc[lambda x: x['directed_by']=='ben jones', 'title']"
what is the number of cartoons written by joseph kuhr?,(cartoon['written_by'] == 'joseph kuhr').sum()
what is the count of cartoons written by joseph kuhr?,(cartoon['written_by'] == 'joseph kuhr').sum()
define an animation list ordered by airing date.,"cartoon[['title', 'directed_by']].sort_values('original_air_date')"
what is the title of each cartoon along with the director?,"cartoon[['title', 'directed_by']].sort_values('original_air_date')"
"list the title of all cartoons directed by ""ben jones"" or ""brandon vietti"".","cartoon.loc[cartoon['directed_by'].isin(['ben jones', 'brandon vietti']), 'title']"
list the title of all animated cartoons directed by ben jones or brandon vietti.,"cartoon.loc[cartoon['directed_by'].isin(['ben jones', 'brandon vietti']), 'title']"
which country has the most tv channels? please provide me with the full data for this country.,tv_channel.groupby('country').size().sort_values(ascending=false).iloc[0:1]
what is the country with the most number of television channels and how many does it have?,tv_channel.groupby('country').size().sort_values(ascending=false).iloc[0:1]
provide a list of all series names and contents in the tv channel table.,"tv_channel.agg({'series_name': 'nunique', 'content': 'nunique'})"
how many different series are listed for the tv channel table?,"tv_channel.agg({'series_name': 'nunique', 'content': 'nunique'})"
"what are the theme songs of the tv channel with the title ""sky radio""?","tv_channel.loc[lambda x: x['series_name']=='sky radio', 'content']"
what is the synopsis of the series sky radio?,"tv_channel.loc[lambda x: x['series_name']=='sky radio', 'content']"
"what is the name of the package option when ""sky radio"" is the name of the tv channel?","tv_channel.loc[lambda x: x['series_name'] == 'sky radio', 'package_option']"
what are the package options of the tv channels that have the titles sky radio?,"tv_channel.loc[lambda x: x['series_name'] == 'sky radio', 'package_option']"
what is the count of tv channel using language english?,"(tv_channel['language'] == ""english"").sum()"
what is the total number of tv channels that communicate in english?,"(tv_channel['language'] == ""english"").sum()"
list the language and number of television channels with their frequency.,tv_channel.groupby('language').size().nsmallest(1)
which channel languages are utilized the least by tv channels and what number of channels use each language?,tv_channel.groupby('language').size().nsmallest(1)
what is the count of tv channels using each of the languages?,tv_channel.groupby('language').size().reset_index(name='count')
"for each language, provide the total number of tv channels using it.",tv_channel.groupby('language').size().reset_index(name='count')
"please list the tv channel that presents the cartoon ""the rise of the blue beetle!""","tv_channel.merge(cartoon[cartoon['title'] == 'the rise of the blue beetle!'], left_on='id', right_on='channel')['series_name']"
"what is the name for a tv channel that airs the cartoon ""the rise of the blue beetle""?","tv_channel.merge(cartoon[cartoon['title'] == 'the rise of the blue beetle!'], left_on='id', right_on='channel')['series_name']"
"return the titles of cartoons shown on tv channel ""sky radio"".","tv_channel.merge(cartoon, left_on='id', right_on='channel').loc[lambda x: x['series_name']=='sky radio', 'title']"
"obtain the titles of all of the cartools the tv channel ""sky radio"".","tv_channel.merge(cartoon, left_on='id', right_on='channel').loc[lambda x: x['series_name']=='sky radio', 'title']"
deliver me the titles of all tv series sorted by rating.,tv_series.sort_values('rating')['episode']
list down all of the episodes ordered by ratings.,tv_series.sort_values('rating')['episode']
provide me the top 3 highest rated tv series along with the episode titles and their corresponding rating.,"tv_series[['episode', 'rating']].sort_values('rating', ascending=false).head(3)"
provide me with the three most highly rated episodes in the table titled &quot;tv series&quot; along with their corresponding rating.,"tv_series[['episode', 'rating']].sort_values('rating', ascending=false).head(3)"
what is the range of share of tv series?,"tv_series['share'].agg(['max', 'min'])"
what is the highest and lowest share for the tv series?,"tv_series['share'].agg(['max', 'min'])"
"what is the air date of television series episode ""a love of a lifetime""?","tv_series.loc[tv_series['episode']=='a love of a lifetime', 'air_date']"
"what is the weekly rank of the tv series with episodes ""a love of a lifetime""?","tv_series.loc[tv_series['episode'] == 'a love of a lifetime', 'weekly_rank']"
"what tv channel airs the tv series with the episode ""a love of a lifetime""? list the tv series' title.","tv_channel.loc[tv_channel['id'].isin(tv_series.loc[tv_series['episode']==""a love of a lifetime"", 'channel']),'series_name']"
"retrieve the title of the series that hosted ""a love of a lifetime"".","tv_channel.loc[tv_channel['id'].isin(tv_series.loc[tv_series['episode']==""a love of a lifetime"", 'channel']),'series_name']"
provide the episode of tv series that was shown on tv channel sky radio.,"tv_channel.merge(tv_series, left_on='id', right_on='channel').loc[lambda x: x['series_name']=='sky radio', 'episode']"
"please provide me with the title of the episode of the tv series bearing the name ""sky radio"".","tv_channel.merge(tv_series, left_on='id', right_on='channel').loc[lambda x: x['series_name']=='sky radio', 'episode']"
provide me the count of cartoons directed by each of the listed directors.,cartoon.groupby('directed_by').size().reset_index(name='count(*)')
what number of cartoons were created by each director?,cartoon.groupby('directed_by').size().reset_index(name='count(*)')
which cartoon was aired last and which production and channel was it aired on?,"cartoon.sort_values('original_air_date', ascending=false).iloc[0][['production_code', 'channel']]"
what is the most recent production of the animation and the broadcasting channel?,"cartoon.sort_values('original_air_date', ascending=false).iloc[0][['production_code', 'channel']]"
identify the package choice and series name of the tv channel that possesses high definition tv.,"tv_channel.loc[lambda x: x['hight_definition_tv']=='yes', ['package_option','series_name']]"
what are the options for packages in this series of tv channel that supports the high definition tv?,"tv_channel.loc[lambda x: x['hight_definition_tv']=='yes', ['package_option','series_name']]"
which countries' tv channels are playing some cartoon written by todd casey?,"pd.merge(tv_channel, cartoon[cartoon['written_by']=='todd casey'], left_on='id', right_on='channel')['country']"
which countries have cartoons on tv that were authored by todd casey?,"pd.merge(tv_channel, cartoon[cartoon['written_by']=='todd casey'], left_on='id', right_on='channel')['country']"
are there any cartoons that are written by todd casey and broadcasted in channels owned by other countries?,"tv_channel['country'].drop_duplicates().reset_index(drop=true).loc[lambda x: ~x.isin(cartoon.loc[cartoon['written_by'] == 'todd casey', 'channel'])]"
what are the countries where no cartoon series has been written by todd casey?,"tv_channel['country'].drop_duplicates().reset_index(drop=true).loc[lambda x: ~x.isin(cartoon.loc[cartoon['written_by'] == 'todd casey', 'channel'])]"
retrieve the series title and country of the tv channel that are broadcasting some cartoons directed by ben jones and michael chang?,"pd.merge(cartoon.loc[lambda x: x['directed_by']=='michael chang'], tv_channel, left_on='channel', right_on='id')[['series_name', 'country']].merge(cartoon.loc[lambda x: x['directed_by']=='ben jones'], on='channel', how='inner')[['series_name', 'country']]"
what are the titles of tv serials possessing animation directed by ben jones or by michael chang?,"pd.merge(cartoon.loc[lambda x: x['directed_by']=='michael chang'], tv_channel, left_on='channel', right_on='id')[['series_name', 'country']].merge(cartoon.loc[lambda x: x['directed_by']=='ben jones'], on='channel', how='inner')[['series_name', 'country']]"
provide the pixel ratio and the country of tv channels that do not utilize english.,"tv_channel.loc[lambda x: x['language']!='english', ['pixel_aspect_ratio_par', 'country']]"
"retrieve the pixel aspect ratio, country of origin, and number of language codes for all tv channels that do not make use of english.","tv_channel.loc[lambda x: x['language']!='english', ['pixel_aspect_ratio_par', 'country']]"
retrieve the ids of channels in countries having more than two channels.,tv_channel.groupby('country').filter(lambda x: len(x) > 2)['id']
please provide me with the ids of all tv networks with more than two channels.,tv_channel.groupby('country').filter(lambda x: len(x) > 2)['id']
retrieve the list of ids for the television heads that do not play any cartoon directed by ben jones.,"tv_channel[~tv_channel['id'].isin(cartoon.loc[cartoon['directed_by']=='ben jones', 'channel'])]['id']"
what are the ids for the tv channels that do not have cartoons directed by ben jones?,"tv_channel[~tv_channel['id'].isin(cartoon.loc[cartoon['directed_by']=='ben jones', 'channel'])]['id']"
find the list of packages of the tv channel that do not have ben jones-directed cartoons.,"tv_channel[~tv_channel['id'].isin(cartoon.loc[cartoon['directed_by']=='ben jones', 'channel'])]['package_option']"
how many package options are there for all channels that are not playing any cartoons directed by ben jones?,"tv_channel[~tv_channel['id'].isin(cartoon.loc[cartoon['directed_by']=='ben jones', 'channel'])]['package_option']"
what is the count of the online poker players?,poker_player.shape[0]
what is the value of the count of the poker players?,poker_player.shape[0]
please list the earnings of poker players in descending order.,"poker_player.sort_values('earnings', ascending=false)['earnings']"
what is the descending order of earnings of poker players?,"poker_player.sort_values('earnings', ascending=false)['earnings']"
provide a table that lists the finalized tables and the best finishes of poker players.,"poker_player[['final_table_made', 'best_finish']]"
list down the names of poker players along with the final tables they finished.,"poker_player[['final_table_made', 'best_finish']]"
what was the average income of poker players?,poker_player['earnings'].mean()
please provide me with the average earnings of all the poker players.,poker_player['earnings'].mean()
what is the money rank of the highest-earning poker player?,"poker_player.sort_values('earnings', ascending=false).iloc[0]['money_rank']"
provide me the money rank of the player with the highest income.,"poker_player.sort_values('earnings', ascending=false).iloc[0]['money_rank']"
"how many final tables were played by poker players with earnings less than 200,000?","poker_player.loc[poker_player['earnings'] < 200000, 'final_table_made'].max()"
give me the topmost final tables made by players with earnings below 200000.,"poker_player.loc[poker_player['earnings'] < 200000, 'final_table_made'].max()"
please send me the names of all the poker players.,"pd.merge(people, poker_player, on='people_id')['name']"
retrieve the names of poker players whose earnings are higher than 300000.,"pd.merge(people, poker_player, on='people_id').loc[lambda x: x['earnings']>300000, 'name']"
"list the names of poker players who have earnings above $300,000.","pd.merge(people, poker_player, on='people_id').loc[lambda x: x['earnings']>300000, 'name']"
return the titles of poker players ordered by the number of final tables that they made in ascending order.,"pd.merge(people, poker_player, on='people_id').sort_values('final_table_made')['name']"
"provide the ids of poker players, ordered ascending by the quantity of final tables they have played.","pd.merge(people, poker_player, on='people_id').sort_values('final_table_made')['name']"
what year was the birth date of the poker player with the least earnings?,"people.merge(poker_player, on='people_id').sort_values('earnings').iloc[0]['birth_date']"
please send me the birth date of the poker player with the lowest earnings.,"people.merge(poker_player, on='people_id').sort_values('earnings').iloc[0]['birth_date']"
what is the rank of the tallest poker player in terms of money?,"pd.merge(people, poker_player, on='people_id').sort_values('height', ascending=false)['money_rank'].iloc[0]"
please return the money rank of the player of poker with the greatest height.,"pd.merge(people, poker_player, on='people_id').sort_values('height', ascending=false)['money_rank'].iloc[0]"
what is the average earning of poker players with height higher than 200?,"pd.merge(people.loc[lambda x: x['height'] > 200], poker_player, on='people_id')['earnings'].mean()"
provide me the average earnings of players whose height is at least 200.,"pd.merge(people.loc[lambda x: x['height'] > 200], poker_player, on='people_id')['earnings'].mean()"
rank the poker players in the order of earnings.,"pd.merge(people, poker_player, on='people_id').sort_values('earnings', ascending=false)['name']"
please provide me with the names of poker players that are listed in descending order of their earnings.,"pd.merge(people, poker_player, on='people_id').sort_values('earnings', ascending=false)['name']"
return the total number of people from different countries along with their corresponding nationality.,people.groupby('nationality').size().reset_index(name='count')
what is the most common nationality of people in baidu?,people.groupby('nationality').size().sort_values(ascending=false).index[0]
retrieve the nationality that is most frequent across all people.,people.groupby('nationality').size().sort_values(ascending=false).index[0]
what is the count of nationalities that are shared by at least two people?,people.groupby('nationality').filter(lambda x: len(x) >= 2)['nationality'].unique()
provide me the list of nationalities that have more than one native citizen.,people.groupby('nationality').filter(lambda x: len(x) >= 2)['nationality'].unique()
provide the names and birth dates of all people in ascending alphabetical order of name.,"people.sort_values('name')[['name', 'birth_date']]"
"list the names of people, in order of their birth, and according to their first names.","people.sort_values('name')[['name', 'birth_date']]"
please list the names of people other than russians.,"people.loc[people['nationality'] != 'russia', 'name']"
find the names of the individuals who are not residents of russia.,"people.loc[people['nationality'] != 'russia', 'name']"
retrieve the names of people that are not poker players.,"people.loc[~people['people_id'].isin(poker_player['people_id']), 'name']"
what is the array of the list of people that did not play poker?,"people.loc[~people['people_id'].isin(poker_player['people_id']), 'name']"
how many nationalities are there?,people['nationality'].nunique()
determine the count of different nationalities.,people['nationality'].nunique()
"retrieve the contestant numbers and names, ordered from highest to lowest by contestant name.","contestants[['contestant_number', 'contestant_name']].sort_values('contestant_name', ascending=false)"
"please list the ids, phone numbers and states associated with all of the comments.","votes[['vote_id', 'phone_number', 'state']]"
what is the date that the last vote was created in the state of california?,"votes.loc[votes['state']=='ca', 'created'].max()"
"retrieve the titles of those candidates whose names are not ""jessie alloway""","contestants.loc[lambda x: x['contestant_name']!='jessie alloway', 'contestant_name']"
for which state was the count of votes maximum?,"votes[['state', 'created']].drop_duplicates()"
"of the subjects who got voted, determine the contestant number and name of the subject who got the least votes.","pd.merge(contestants, votes, on='contestant_number').groupby('contestant_number')[['contestant_number', 'contestant_name']].count().reset_index().sort_values(0).iloc[0]"
fetch the number of votes from states 'ny' or 'ca' or both.,"votes.loc[votes['state'].isin(['ny', 'ca']), :].shape[0]"
how many contestants were not voted upon?,(~contestants['contestant_number'].isin(votes['contestant_number'])).sum()
what is the area code for which the maximum number of voters casted their votes?,"pd.merge(area_code_state, votes, on='state').groupby('area_code').size().idxmax()"
"what is the date of the votes, state, and phone number of the votes that went to the contestant named 'tabatha gehling'?","votes.merge(contestants.loc[lambda x: x['contestant_name']=='tabatha gehling', 'contestant_number'], on='contestant_number')[['created', 'state', 'phone_number']]"
list the area codes that were utilized by voters to cast votes for the contestant 'tabatha gehling' as well as the contestant 'kelly clauss'.,"pd.merge(pd.merge(contestants.loc[lambda x: x['contestant_name']=='tabatha gehling'], votes, on='contestant_number'), area_code_state, left_on='state', right_on='state').loc[:, 'area_code'].interesect(pd.merge(pd.merge(contestants.loc[lambda x: x['contestant_name']=='kelly clauss'], votes, on='contestant_number'), area_code_state, left_on='state', right_on='state').loc[:, 'area_code'])"
retrieve the names of contestants whose names contain the substring 'al' .,"contestants.loc[contestants['contestant_name'].str.contains('al'), 'contestant_name']"
what are the names of all the countries that gained independence after 1950?,"country.loc[lambda x: x['indepyear'] > 1950, 'name']"
give me the names of countries that were formed after 1950.,"country.loc[lambda x: x['indepyear'] > 1950, 'name']"
what is the number of countries with a republican form of government?,(country['governmentform'] == 'republic').sum()
what are the number of governments of country which are republics?,(country['governmentform'] == 'republic').sum()
what is the total surface area of all the countries in the caribbean region?,"country.loc[lambda x: x['region'] == ""caribbean"", 'surfacearea'].sum()"
what is the total area of land that is covered by the countries in the caribbean?,"country.loc[lambda x: x['region'] == ""caribbean"", 'surfacearea'].sum()"
which is the continent on which anguilla is located?,"country.loc[lambda x: x['name']=='anguilla', 'continent']"
what is the name of the continent which anguilla belongs to?,"country.loc[lambda x: x['name']=='anguilla', 'continent']"
which region is the metropolitan city of kabul located in?,"pd.merge(country, city, left_on='code', right_on='countrycode').loc[lambda x: x['name']=='kabul', 'region']"
what is the province of kabul?,"pd.merge(country, city, left_on='code', right_on='countrycode').loc[lambda x: x['name']=='kabul', 'region']"
which language is spoken by the greatest percentage of arubans?,"pd.merge(country[country['name']=='aruba'], countrylanguage, left_on='code', right_on='countrycode').sort_values('percentage', ascending=false).iloc[0]['language']"
what language is spoken in aruba predominantly?,"pd.merge(country[country['name']=='aruba'], countrylanguage, left_on='code', right_on='countrycode').sort_values('percentage', ascending=false).iloc[0]['language']"
what are the population and life expectancies of brazil?,"country.loc[lambda x: x['name']=='brazil', ['population', 'lifeexpectancy']]"
give me the population of brazil and life expectancies.,"country.loc[lambda x: x['name']=='brazil', ['population', 'lifeexpectancy']]"
what is the region name and population of angola?,"country.loc[lambda x: x['name']=='angola', ['population', 'region']]"
what region does angola belong to and what is the population?,"country.loc[lambda x: x['name']=='angola', ['population', 'region']]"
what is the life expectancy of an average person in the region?,"country.loc[lambda x: x['region']=='central africa', 'lifeexpectancy'].mean()"
what is the life expectancy of people residing in central africa?,"country.loc[lambda x: x['region']=='central africa', 'lifeexpectancy'].mean()"
which country has the shortest life expectancy in asia?,country.loc[lambda x: x['continent']=='asia'].sort_values('lifeexpectancy').iloc[0]['name']
tell the name of the country in asia having the lowest life expectancy.,country.loc[lambda x: x['continent']=='asia'].sort_values('lifeexpectancy').iloc[0]['name']
what is the total population and gross national product (gnp) for asia?,"country.loc[lambda x: x['continent']=='asia', ['population', 'gnp']].agg({'population': 'sum', 'gnp': 'max'})"
what is the count of people living in asia?,"country.loc[lambda x: x['continent']=='asia', ['population', 'gnp']].agg({'population': 'sum', 'gnp': 'max'})"
what is the average life expectancy of countries that are republics in africa?,"country.loc[(country['continent']=='africa') & (country['governmentform']=='republic'), 'lifeexpectancy'].mean()"
provide me with the life expectancy average for countries in africa that are republics.,"country.loc[(country['continent']=='africa') & (country['governmentform']=='republic'), 'lifeexpectancy'].mean()"
what is the total surface area of continents europe and asia?,"country.loc[lambda x: x['continent'].isin(['asia', 'europe']), 'surfacearea'].sum()"
justify the total surface area covered by countries in asia or europe.,"country.loc[lambda x: x['continent'].isin(['asia', 'europe']), 'surfacearea'].sum()"
compute the count of people living in gelderland district.,"city.loc[lambda x: x['district']=='gelderland', 'population'].sum()"
what is the total population of the gelderland district?,"city.loc[lambda x: x['district']=='gelderland', 'population'].sum()"
what is the gdp and count of population in nations that are us property?,"country.loc[country['governmentform'] == 'us territory', ['gnp', 'population']].agg({'gnp': 'mean', 'population': 'sum'})"
calculate the average gnp and total population of nations that are regarded as us territory.,"country.loc[country['governmentform'] == 'us territory', ['gnp', 'population']].agg({'gnp': 'mean', 'population': 'sum'})"
how many languages exist in the entire world?,countrylanguage['language'].nunique()
how many distinct languages are utilized across the world?,countrylanguage['language'].nunique()
how many types of governments are in africa?,"country.loc[lambda x: x['continent']=='africa', 'governmentform'].nunique()"
how many different forms of government exist in africa?,"country.loc[lambda x: x['continent']=='africa', 'governmentform'].nunique()"
what is the total number of languages that are spoken in aruba?,"country_language.merge(country[country['name'] == ""aruba""], left_on='countrycode', right_on='code')['language'].count()"
how many languages were spoken in aruba?,"country_language.merge(country[country['name'] == ""aruba""], left_on='countrycode', right_on='code')['language'].count()"
what is the number of official languages that afghanistan has?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').loc[lambda x: (x['name']=='afghanistan') & (x['isofficial']=='t')].shape[0]"
how many official languages is spoken in afghanistan?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').loc[lambda x: (x['name']=='afghanistan') & (x['isofficial']=='t')].shape[0]"
what is the name of the country that speaks the most number of languages?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').groupby('name').size().nlargest(1).index[0]"
determine the name of nation that uses the most languages.,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').groupby('name').size().nlargest(1).index[0]"
which continent has the most varied languages?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').groupby('continent').size().sort_values(ascending=false).index[0]"
how many languages does each continent speak?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').groupby('continent').size().sort_values(ascending=false).index[0]"
how many countries are bilingual in english and dutch?,"len(set(country.loc[country['code'].isin(countrylanguage.loc[countrylanguage['language'].isin(['english', 'dutch'])]['countrycode']) & (countrylanguage['language'] == 'english')]['name']) & set(country.loc[country['code'].isin(countrylanguage.loc[countrylanguage['language'].isin(['english', 'dutch'])]['countrycode']) & (countrylanguage['language'] == 'dutch')]['name']))"
what is the count of nations that use english and dutch?,"len(set(country.loc[country['code'].isin(countrylanguage.loc[countrylanguage['language'].isin(['english', 'dutch'])]['countrycode']) & (countrylanguage['language'] == 'english')]['name']) & set(country.loc[country['code'].isin(countrylanguage.loc[countrylanguage['language'].isin(['english', 'dutch'])]['countrycode']) & (countrylanguage['language'] == 'dutch')]['name']))"
retrieve the titles of nations that speak both french and english.,"pd.merge(country.loc[country['code'].isin(countrylanguage.loc[countrylanguage['language']=='english', 'countrycode'].unique()), 'name'], country.loc[country['code'].isin(countrylanguage.loc[countrylanguage['language']=='french', 'countrycode'].unique()), 'name'], on='name')"
return the names of the nations that speak both english and french.,"pd.merge(country.loc[country['code'].isin(countrylanguage.loc[countrylanguage['language']=='english', 'countrycode'].unique()), 'name'], country.loc[country['code'].isin(countrylanguage.loc[countrylanguage['language']=='french', 'countrycode'].unique()), 'name'], on='name')"
what are the nation names where english and french are both the offical languages?,"pd.merge(country[countrylanguage['language'] == 'english'][countrylanguage['isofficial'] == 't'][['code', 'name']], country[countrylanguage['language'] == 'french'][countrylanguage['isofficial'] == 't'][['code', 'name']])['name']"
return a list of countries with english and french as official languages.,"pd.merge(country[countrylanguage['language'] == 'english'][countrylanguage['isofficial'] == 't'][['code', 'name']], country[countrylanguage['language'] == 'french'][countrylanguage['isofficial'] == 't'][['code', 'name']])['name']"
what is the number of continents where chinese is spoken?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').loc[lambda x: x['language']=='chinese', 'continent'].nunique()"
how many continents have chinese as one of the official languages?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').loc[lambda x: x['language']=='chinese', 'continent'].nunique()"
which regions select english or dutch?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').loc[lambda x: x['language'].isin(['english', 'dutch']), 'region'].unique()"
determine which regions use dutch or english as their language.,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').loc[lambda x: x['language'].isin(['english', 'dutch']), 'region'].unique()"
what are the countries where either english or dutch are legally authorized languages?,"pd.concat([country.merge(countrylanguage[lambda x: x['language']=='english'].query('isofficial==""t""'), left_on='code', right_on='countrycode')['name'], country.merge(countrylanguage[lambda x: x['language']=='dutch'].query('isofficial==""t""'), left_on='code', right_on='countrycode')['name']], axis=0).drop_duplicates()"
what language is used by the greatest number of nations in the asian continent?,"countrylanguage.merge(country[country['continent']=='asia'], left_on='countrycode',right_on='code')['language'].value_counts().index[0]"
identify the languages spoken by only one country in republican governments.,"countrylanguage.merge(country[country['governmentform']=='republic'], left_on='countrycode', right_on='code').groupby('language').filter(lambda x: len(x)==1)['language']"
retrieve the list of languages used by citizens of a single country with a republic government.,"countrylanguage.merge(country[country['governmentform']=='republic'], left_on='countrycode', right_on='code').groupby('language').filter(lambda x: len(x)==1)['language']"
which city has the largest population that uses english?,"city.merge(countrylanguage, on='countrycode').loc[lambda x: x['language']=='english', ['name', 'population']].sort_values('population', ascending=false).iloc[:1]"
what are the most inhabited cities speaking english?,"city.merge(countrylanguage, on='countrycode').loc[lambda x: x['language']=='english', ['name', 'population']].sort_values('population', ascending=false).iloc[:1]"
find the three-letter code of the country with the largest land area.,"country.loc[lambda x: x['continent']=='asia', ['name', 'population', 'lifeexpectancy', 'surfacearea']].sort_values('surfacearea', ascending=false).iloc[:1, :-1]"
"which asian country is the largest by land, what is its population and what is its life expectancy?","country.loc[lambda x: x['continent']=='asia', ['name', 'population', 'lifeexpectancy', 'surfacearea']].sort_values('surfacearea', ascending=false).iloc[:1, :-1]"
what is the life-expectancy of countries in which english is not an official language?,"country.loc[~country['name'].isin(countrylanguage.query('language == ""english"" and isofficial == ""t""')['name']), 'lifeexpectancy'].mean()"
how many individuals live in the nations that do not use english as their official language?,"country[~country['name'].isin(countrylanguage.merge(country[[""name"", ""code""]], left_on=""countrycode"", right_on=""code"").loc[lambda x: x['language']=='english', 'name'])]['population'].sum()"
how many people reside in countries with languages other than english?,"country[~country['name'].isin(countrylanguage.merge(country[[""name"", ""code""]], left_on=""countrycode"", right_on=""code"").loc[lambda x: x['language']=='english', 'name'])]['population'].sum()"
what is the official language of the south american country whose head of state is beatrix?,"pd.merge(country, countrylanguage[countrylanguage['isofficial']=='t'], left_on='code', right_on='countrycode').loc[lambda x: x['headofstate']=='beatrix', 'language']"
what is the official language of the national government of the country whose head of state is beatrix?,"pd.merge(country, countrylanguage[countrylanguage['isofficial']=='t'], left_on='code', right_on='countrycode').loc[lambda x: x['headofstate']=='beatrix', 'language']"
what is the total number of unique official languages spoken in the countries that were founded before 1930?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').loc[lambda x: (x['indepyear']<1930) & (x['isofficial']=='t'), 'language'].nunique()"
how many languages other than the state language were adopted by countries founded before 1930?,"pd.merge(country, countrylanguage, left_on='code', right_on='countrycode').loc[lambda x: (x['indepyear']<1930) & (x['isofficial']=='t'), 'language'].nunique()"
which countries have greater surface area than any country in europe?,"country.loc[lambda x: x['surfacearea'] > country.loc[country['continent'] == 'europe', 'surfacearea'].min(), 'name']"
which countries have a greater area than that of any country in europe?,"country.loc[lambda x: x['surfacearea'] > country.loc[country['continent'] == 'europe', 'surfacearea'].min(), 'name']"
which african countries have a population less than any asian country?,"country.loc[(country['continent']=='africa') & (country['population'] < country.loc[country['continent']=='asia', 'population'].max()), 'name']"
which african countries have a smaller population than any of the asian states?,"country.loc[(country['continent'] == 'africa') & (country['population'] < country.loc[country['continent'] == 'asia', 'population'].min()), 'name']"
which asian countries have a population that is larger than the population of any country in africa?,"country.loc[(country['continent']=='asia') & (country['population']>country.loc[country['continent']=='africa', 'population'].max()), 'name']"
which countries have a larger population than any african country?,"country.loc[(country['continent'] == 'asia') & (country['population'] > country.loc[country['continent'] == 'africa', 'population'].min()), 'name']"
what are the country codes of countries around the world that do not speak english?,"countrylanguage['countrycode'].drop_duplicates().isin(countrylanguage.loc[lambda x: x['language'] == 'english', 'countrycode']).pipe(lambda x: x[~x])"
what is the country code for those nations that do not speak english?,"countrylanguage['countrycode'].drop_duplicates().isin(countrylanguage.loc[lambda x: x['language'] == 'english', 'countrycode']).pipe(lambda x: x[~x])"
provide the country codes of countries where people speak langauges that are not english.,"countrylanguage.loc[lambda x: x['language'] != 'english', 'countrycode'].unique()"
which countries do not speak english and whose governmental forms are not republic?,"country.loc[lambda x: x['governmentform'] != 'republic', 'code'].isin(countrylanguage.loc[lambda x: x['language'] == 'english', 'countrycode']).astype(int).eq(0).where(lambda x: x, country.loc[lambda x: x['governmentform'] != 'republic', 'code']).dropna().astype(int)"
return the codes of all countries that speak english and do not have republics for governments.,"country.loc[lambda x: x['governmentform'] != 'republic', 'code'].isin(countrylanguage.loc[lambda x: x['language'] == 'english', 'countrycode']).astype(int).eq(0).where(lambda x: x, country.loc[lambda x: x['governmentform'] != 'republic', 'code']).dropna().astype(int)"
which cities in european countries have english as the official language?,"city.merge(country[lambda x: x['continent']=='europe'], left_on='countrycode', right_on='code', how='inner').loc[lambda x: ~x['name_x'].isin(countrylanguage[lambda y: (y['isofficial']=='t') & (y['language']=='english')]['countrycode'].unique()), 'name_y'].unique()"
what cities in europe have english not as their native language?,"city.merge(country[lambda x: x['continent']=='europe'], left_on='countrycode', right_on='code', how='inner').loc[lambda x: ~x['name_x'].isin(countrylanguage[lambda y: (y['isofficial']=='t') & (y['language']=='english')]['countrycode'].unique()), 'name_y'].unique()"
which cities in asian are the highest number of unique cities where chinese is the official language?,"pd.merge(pd.merge(country, countrylanguage, left_on='code', right_on='countrycode'), city, on='countrycode').loc[(lambda x: (x['isofficial']=='t') & (x['language']=='chinese') & (x['continent']=='asia')), 'name'].unique()"
identify all the names of the cities that are in asia and the official language is chinese.,"pd.merge(pd.merge(country, countrylanguage, left_on='code', right_on='countrycode'), city, on='countrycode').loc[lambda x: (x['language']=='chinese') & (x['isofficial']=='t') & (x['continent']=='asia'), 'name'].unique()"
"which country has the smallest population, independence year, and surface area?","country[['name', 'surfacearea', 'indepyear', 'population']].sort_values('population').head(1)[['name', 'surfacearea', 'indepyear']]"
"provide me with the name of the country, the year of its establishment, and the area of the land that houses the least number of people.","country[['name', 'surfacearea', 'indepyear', 'population']].sort_values('population').head(1)[['name', 'surfacearea', 'indepyear']]"
what are the name and country with the largest population?,"country[['name', 'population', 'headofstate']].sort_values('surfacearea', ascending=false).iloc[:1]"
please return me the identity of that country that has the largest area.,"country[['name', 'population', 'headofstate']].sort_values('surfacearea', ascending=false).iloc[:1]"
please provide me with the name of the country and the number of languages spoken for each country where at least 3 languages were spoken.,"countrylanguage.merge(country, left_on='countrycode', right_on='code').groupby('name').filter(lambda x: len(x) > 2).groupby('name').size().reset_index(name='count').loc[:,['count','name']]"
"what names of countries utilize more than 2 languages, and what are the language(s) they speak?","countrylanguage.merge(country, left_on='countrycode', right_on='code').groupby('name').filter(lambda x: len(x) > 2).groupby('name').size().reset_index(name='count').loc[:,['count','name']]"
identify the number of cities in each district whose population is greater than that of other cities in that district.,city.loc[city['population'] > city['population'].mean()].groupby('district').agg({'population': 'count'}).rename(columns={'population': 'count(*)'})
list the cities in each district that have populations that are greater than the average population across all cities.,city.loc[city['population'] > city['population'].mean()].groupby('district').agg({'population': 'count'}).rename(columns={'population': 'count(*)'})
what are the names and number of people of governmental forms that have their average life expectancies greater than 72?,"country.groupby('governmentform').agg({'population':'sum', 'lifeexpectancy':'mean'}).loc[lambda x: x['lifeexpectancy'] > 72, 'population']"
enumerate the government forms and the total population of each for any government forms that have an average life expectancy greater than 72.,"country.groupby('governmentform').agg({'population':'sum', 'lifeexpectancy':'mean'}).loc[lambda x: x['lifeexpectancy'] > 72, 'population']"
determine the mean life expectancy and the total count of inhabitants for each continent where the average life expectancy is less than 72.,"country.groupby('continent').agg({'population': 'sum', 'lifeexpectancy': 'mean'}).loc[lambda x: x['lifeexpectancy'] < 72]"
obtain the continents and total popuation as well as average life expectancy for continents whose average life expectancy is less than 72.,"country.groupby('continent').agg({'population': 'sum', 'lifeexpectancy': 'mean'}).loc[lambda x: x['lifeexpectancy'] < 72]"
what are the names and areas of countries with the top five largest area?,"country[['name','surfacearea']].sort_values('surfacearea', ascending=false).head(5)"
retrieve the titles and areas of the largest countries.,"country[['name','surfacearea']].sort_values('surfacearea', ascending=false).head(5)"
what are the title for countries with the top 3 largest population?,"country.sort_values('population', ascending=false)['name'].head(3)"
convert the 3 most populous countries into names.,"country.sort_values('population', ascending=false)['name'].head(3)"
name the nations with the 3 least-populated individuals.,country.sort_values('population').head(3)['name']
"please indicate the 3 countries with the lowest population.a:you can use a regular expression, here is an example:tom\\s*projects\\s*where\\s*a\\s*certain\\s*query\\s*was\\s*used\\s*to\\s*return\\s*a\\s*set\\s*of\\s*rows\\s*containing\\s*a\\s*group\\s*of\\s*related\\s*items\\s*(?<count>\d\\s*(,\d\\s*(?:,\d\\s*(?:,\d\\s*(?:,\d\\s*(?:,\d\\s*(?:)?)?)?)?)?)?)?see regex demoin java:string regex = ""tom\\\\s*projects\\\\s*where\\\\s*a\\\\s*certain\\\\s*query\\\\s*was\\\\s*used\\\\s*to\\\\s*return\\\\s*a\\\\s*set\\",country.sort_values('population').head(3)['name']
what is the number of countries that are in asia?,(country['continent'] == 'asia').sum()
determine the total count of countries in asia.,(country['continent'] == 'asia').sum()
retrieve the names of countries that are a part of the europe continent with a human population of 80000.,"country.loc[(country['continent'] == 'europe') & (country['population'] == 80000), 'name']"
"provide the names of all countries of europe that have a populace equal to 80,000.","country.loc[(country['continent'] == 'europe') & (country['population'] == 80000), 'name']"
provide the count of countries and their respective average area whose area is larger than 3000.,"country.loc[(country['continent'] == 'north america') & (country['surfacearea'] > 3000), ['population', 'surfacearea']].agg({'population': 'sum', 'surfacearea': 'mean'})"
which north american countries have a surface area greater than 3000 square kilometers? present their corresponding population and the average surface area.,"country.loc[(country['continent'] == 'north america') & (country['surfacearea'] > 3000), ['population', 'surfacearea']].agg({'population': 'sum', 'surfacearea': 'mean'})"
"could you give me the names of cities whose population lies between 160,000 and 900,000?","city.loc[(city['population'] >= 160000) & (city['population'] <= 900000), 'name']"
list out the names of cities whose population is between 160000 and 900000.,"city.loc[(city['population'] >= 160000) & (city['population'] <= 900000), 'name']"
what language is spoken by the largest count of countries?,countrylanguage.groupby('language').size().sort_values(ascending=false).index[0]
which language is spoken in the greatest number of countries?,countrylanguage.groupby('language').size().sort_values(ascending=false).index[0]
what is the language spoken by the largest percentage of people in each nation?,"countrylanguage.groupby('countrycode').agg({'language': 'first', 'percentage': 'max'}).reset_index()[['language', 'countrycode', 'percentage']]"
"provide me the country codes of the different countries, and let me determine the percentage of people speaking each language in each country.","countrylanguage.groupby('countrycode').agg({'language': 'first', 'percentage': 'max'}).reset_index()[['language', 'countrycode', 'percentage']]"
what is the total of countries where spanish is spoken by the largest percentage of the population?,"countrylanguage[countrylanguage['language']=='spanish'].groupby('countrycode').agg({'countrycode':'count', 'percentage':'max'})"
determine the total count of countries for which spanish is the predominantly spoken language.,"countrylanguage.loc[countrylanguage['language']=='spanish'].groupby('countrycode').agg({'percentage': 'max', '*': 'count'})"
what are the codes of the countries where spanish is spoken by the largest percent of the people?,countrylanguage.loc[countrylanguage['language']=='spanish'].groupby('countrycode')['percentage'].max()
give me the codes of countries for which spanish is the native language.,countrylanguage.loc[countrylanguage['language']=='spanish'].groupby('countrycode')['percentage'].max()
return the listing of conductors in ascending age order.,conductor.sort_values('age')['name']
"reveal the names of the conductors, sorted by age.",conductor.sort_values('age')['name']
"which conductors are not from ""usa""?","conductor.loc[lambda x: x['nationality'] != 'usa', 'name']"
please provide me with the names of conductors that are not us citizens.,"conductor.loc[lambda x: x['nationality'] != 'usa', 'name']"
produce a list of record labels of orchestras in decreasing order of years in which they were established.,"orchestra.sort_values('year_of_founded', ascending=false)['record_company']"
"provide me with the titles of record companies of orchestras, sorted in descending order by the year in which they were formed.","orchestra.sort_values('year_of_founded', ascending=false)['record_company']"
calculate the average number of spectators for shows.,show['attendance'].mean()
what is the average attendance of shows across all the days?,show['attendance'].mean()
"what are the maximum and minimum share of performances whose type is not ""live final""?","performance.query('type != ""live final""').agg({'share': ['max', 'min']})"
"find the maximum and minimum numbers of shares for performances that do not have the type ""live final"".","performance.query('type != ""live final""').agg({'share': ['max', 'min']})"
how many nationalities did conductors have?,conductor['nationality'].nunique()
how may different nationalities of conductors are there?,conductor['nationality'].nunique()
provide the titles of all the conductors in descending order of years of work.,"conductor.sort_values('year_of_work', ascending=false)['name']"
"list down the names of conductors, sorted by the number of years they have worked.","conductor.sort_values('year_of_work', ascending=false)['name']"
list the years of work in conducting by each conductor.,"conductor.sort_values('year_of_work', ascending=false)['name'].iloc[0]"
what is the title given for the conductor who has worked the longest period of time?,"conductor.sort_values('year_of_work', ascending=false)['name'].iloc[0]"
show the title of conductors and orchestras that they have conducted.,"pd.merge(conductor, orchestra, on='conductor_id')[['name', 'orchestra']]"
retrieve the names of conductors along with the orchestras that they have performed with.,"pd.merge(conductor, orchestra, on='conductor_id')[['name', 'orchestra']]"
return me the names of conductors that have performed for more than one orchestra.,"pd.merge(conductor, orchestra, on='conductor_id').groupby('conductor_id').filter(lambda x: len(x) > 1)['name']"
retrieve the names of conductors who have been conducted by more than one ensemble.,"pd.merge(conductor, orchestra, on='conductor_id').groupby('conductor_id').filter(lambda x: len(x) > 1)['name']"
display the name for the conductor that has performed the most number of orchestras.,"pd.merge(conductor, orchestra, on='conductor_id').groupby('conductor_id')['name'].count().sort_values(ascending=false).iloc[[0]]"
who is the name of conductor who has led the most orchestras?,"pd.merge(conductor, orchestra, on='conductor_id').groupby('conductor_id')['name'].count().sort_values(ascending=false).iloc[[0]]"
please identify the names of conductors that conducted the orchestras founded after 2008.,"conductor.merge(orchestra, on='conductor_id').loc[lambda x: x['year_of_founded'] > 2008, 'name']"
what are the names of conductors who have conducted orchestras formed since the year 2008?,"conductor.merge(orchestra, on='conductor_id').loc[lambda x: x['year_of_founded'] > 2008, 'name']"
how may record companies are there and what are the titles of the corresponding orchestras?,orchestra.groupby('record_company').size()
what orchestras are managed by each record label?,orchestra.groupby('record_company').size()
please sort the record formats of orchestras in ascending order of count.,orchestra.groupby('major_record_format')['major_record_format'].count().sort_values().index.tolist()
"return me the ids of the major record formats of orchestras, sorted by their frequency.",orchestra.groupby('major_record_format')['major_record_format'].count().sort_values().index.tolist()
what are the record companies chosen by the largest number of orchestras?,orchestra.groupby('record_company').size().idxmax()
identify the record company that's utilized by the greatest number of orchestras.,orchestra.groupby('record_company').size().idxmax()
what are the titles of orchestras that have no performances?,"orchestra.loc[~orchestra['orchestra_id'].isin(performance['orchestra_id']), 'orchestra']"
which orchestras have no performances?,"orchestra.loc[~orchestra['orchestra_id'].isin(performance['orchestra_id']), 'orchestra']"
indicate the record companies that were shared by orchestras founded before 2003 and after 2003.,"set(orchestra.loc[orchestra['year_of_founded'] < 2003, 'record_company']).intersection(set(orchestra.loc[orchestra['year_of_founded'] > 2003, 'record_company']))"
how many record labels are used by both orchestras founded before 2003 and those founded after 2003?,"set(orchestra.loc[orchestra['year_of_founded'] < 2003, 'record_company']).intersection(set(orchestra.loc[orchestra['year_of_founded'] > 2003, 'record_company']))"
"retrieve the number of orchestras whose record format is ""cd"" or ""dvd"".","orchestra.loc[lambda x: (x['major_record_format']=='cd') | (x['major_record_format']=='dvd'), :].shape[0]"
how many orchestras have a cd or dvd as their record format?,"orchestra.loc[lambda x: (x['major_record_format']=='cd') | (x['major_record_format']=='dvd'), :].shape[0]"
display the years in which orchestral organizations were formed that have given more than one performance.,"pd.merge(orchestra, performance, on='orchestra_id').groupby('orchestra_id').filter(lambda x: len(x) > 1)['year_of_founded']"
which year were most orchestras founded?,"pd.merge(orchestra, performance, on='orchestra_id').groupby('orchestra_id').filter(lambda x: len(x) > 1)['year_of_founded']"
what is the number of high school students?,highschooler.shape[0]
provide the name and grade of each student from the attached list.,"highschooler[['name', 'grade']]"
provide me the id and grades for each high school student.,"highschooler[['name', 'grade']]"
provide me with the complete list of grades of all the high school students.,highschooler['grade']
determine the grades of all the high school students.,highschooler['grade']
what is kyle's current grade in school?,"highschooler.loc[lambda x: x['name']=='kyle', 'grade']"
fetch the gpa for the high school student named kyle.,"highschooler.loc[lambda x: x['name']=='kyle', 'grade']"
retrieve the names of students that are in grade 10 in high school.,"highschooler.loc[lambda x: x['grade']==10, 'name']"
provide me all the titles of high school students in grade 10.,"highschooler.loc[lambda x: x['grade']==10, 'name']"
provide me the id of the student named kyle.,"highschooler.loc[lambda x: x['name'] == 'kyle', 'id']"
how many high schoolers are there in grades 9-10?,(highschooler['grade']==9 | highschooler['grade']==10).sum()
determine the total count of students in 9th and 10th grade.,(highschooler['grade']==9 | highschooler['grade']==10).sum()
please list the count of students for each grade for high school.,highschooler.groupby('grade').size().reset_index(name='count')
how many students are in each grade in high school?,highschooler.groupby('grade').size().reset_index(name='count')
how many high school students are there in each grade?,highschooler.groupby('grade').size().sort_values(ascending=false).index[0]
what is the grade of students that has the most high schoolers?,highschooler.groupby('grade').size().sort_values(ascending=false).index[0]
please list the names of grades that have at least 4 students.,highschooler.groupby('grade').filter(lambda x: len(x) >= 4)['grade'].unique()
which grades have four or more high school students?,highschooler.groupby('grade').filter(lambda x: len(x) >= 4)['grade'].unique()
i would like to see the student ids and number of friends corresponding to each.,friend.groupby('student_id').size().reset_index(name='count')
display the names of high school students along with their total number of friends.,"friend.merge(highschooler, left_on='student_id', right_on='id').groupby('student_id')['name'].agg(['count'])"
give me the names of the high school students and their number of friends.,"friend.merge(highschooler, left_on='student_id', right_on='id').groupby('student_id')['name'].agg(['count'])"
provide me with the name of a teenager who has the most friends.,"friend.merge(highschooler, left_on='student_id', right_on='id').groupby('student_id')['name'].count().sort_values(ascending=false).head(1).index.map(lambda x: highschooler.loc[x, 'name'])"
provide me with the names of high school students with a minimum of three friends.,"pd.merge(friend, highschooler, left_on='student_id', right_on='id').groupby('student_id').filter(lambda x: len(x) >= 3)['name'].unique()"
retrieve the titles of people who attended high school and have 3 or more of their friends.,"pd.merge(friend, highschooler, left_on='student_id', right_on='id').groupby('student_id').filter(lambda x: len(x) >= 3)['name'].unique()"
find the names of the persons kyle knows at university.,"pd.merge(pd.merge(friend, highschooler, left_on='student_id', right_on='id'), highschooler, left_on='friend_id', right_on='id').loc[lambda x: x['name_x']=='kyle', 'name_y']"
retrieve the names of kyle's friends.,"pd.merge(pd.merge(friend, highschooler, left_on='student_id', right_on='id'), highschooler, left_on='friend_id', right_on='id').loc[lambda x: x['name_x']=='kyle', 'name_y']"
what is the count of friends of the high school student kyle?,"pd.merge(friend, highschooler, left_on='student_id', right_on='id').loc[lambda x: x['name']=='kyle'].shape[0]"
provide the ids of students who are deprived of friendship.,pd.series(list(set(highschooler['id']) - set(friend['student_id'])))
identify the ids of high school students who have no friends.,pd.series(list(set(highschooler['id']) - set(friend['student_id'])))
list the names of all students who have no friends.,"highschooler[~highschooler['id'].isin(friend.merge(highschooler, left_on='student_id', right_on='id')['name'])]['name']"
what are the names of the students that do not have any friends?,"highschooler[~highschooler['id'].isin(friend.merge(highschooler, left_on='student_id', right_on='id')['name'])]['name']"
"show the identities of high schoolers who have friends, and are also liked by someone, apart from themselves.",pd.series(list(set(friend['student_id']) & set(likes['liked_id'])))
provide me with the ids of students that are liked by friends.,pd.series(list(set(friend['student_id']) & set(likes['liked_id'])))
show me the names of all the students who have some friends who are also liked by someone else.,"pd.merge(friend, highschooler, left_on='student_id', right_on='id')['name'].interesect(pd.merge(likes, highschooler, left_on='liked_id', right_on='id')['name'])"
retrieve the names of high school students who both are friends and liked.,"pd.merge(friend, highschooler, left_on='student_id', right_on='id')['name'].interesect(pd.merge(likes, highschooler, left_on='liked_id', right_on='id')['name'])"
count the number of likes each respective student id.,likes.groupby('student_id').size().reset_index(name='count')
what is the number of likes corresponding to each student id?,likes.groupby('student_id').size().reset_index(name='count')
"obtain a list of the names of high schoolers who have liked, and the numbers of likes for each.","likes.merge(highschooler, left_on='student_id', right_on='id').groupby('student_id').agg({'name': 'first', 'color': 'count'}).rename(columns={'color': 'count'})[['name', 'count']]"
"list the names of high schoolers who have likes, and also provide the number of likes that each has.","likes.merge(highschooler, left_on='student_id', right_on='id').groupby('student_id').agg({'name': 'first', 'color': 'count'}).rename(columns={'color': 'count'})[['name', 'count']]"
retrieve the name of the high schooler who has the maximum likes on his/her page.,"highschooler.loc[highschooler['id'].isin(likes.merge(likes.groupby('student_id')['other_id'].count().idxmax(), on='student_id')['other_id']), 'name']"
give me the name of the student with the most likes.,"highschooler.loc[highschooler['id'].isin(likes.merge(likes.groupby('student_id')['other_id'].count().idxmax(), on='student_id')['other_id']), 'name']"
retrieve the names of the students who received at least two likes.,"likes.merge(highschooler, left_on='student_id', right_on='id').groupby('student_id').filter(lambda x: len(x) >= 2)['name']"
retrieve the names of students who have at least two likes.,"likes.merge(highschooler, left_on='student_id', right_on='id').groupby('student_id').filter(lambda x: len(x) >= 2)['name']"
return the names of students who have a grade higher than five and belong to at least two friends.,"pd.merge(friend, highschooler, left_on='student_id', right_on='id').loc[lambda x: x['grade'] > 5].groupby('student_id').filter(lambda x: len(x) >= 2)['name'].unique()"
what are the names of highschoolers who are in possession of a grade of more than 5 and have 2 or more friends?,"pd.merge(friend, highschooler, left_on='student_id', right_on='id').loc[lambda x: x['grade'] > 5].groupby('student_id').filter(lambda x: len(x) >= 2)['name'].unique()"
how many likes does kyle have in total?,"pd.merge(likes, highschooler, left_on='student_id', right_on='id').loc[lambda x: x['name']=='kyle'].shape[0]"
"provide the count of likes by kyle, a high schooler.","pd.merge(likes, highschooler, left_on='student_id', right_on='id').loc[lambda x: x['name']=='kyle'].shape[0]"
determine the average score of all students that have at least a friend.,"highschooler.loc[lambda x: x['id'].isin(friend.merge(highschooler, left_on='student_id', right_on='id')['id'])]['grade'].mean()"
determine the average grade of the students who have friends.,"highschooler.loc[lambda x: x['id'].isin(friend.merge(highschooler, left_on='student_id', right_on='id')['id'])]['grade'].mean()"
determine the minimum score attained by students with no friends.,"highschooler.loc[~highschooler['id'].isin(friend.merge(highschooler, left_on='student_id', right_on='id')['id_x']), 'grade'].min()"
which grade carries no friends?,"highschooler.loc[~highschooler['id'].isin(friend.merge(highschooler, left_on='student_id', right_on='id')['id_x']), 'grade'].min()"
retrieve the states that have both owners and professionals living in that area.,pd.series(list(set(owners['state']) & set(professionals['state'])))
return the states where both owners and professionals reside.,pd.series(list(set(owners['state']) & set(professionals['state'])))
determine the average age of the dogs that have endured any treatment.,"dogs.loc[dogs['dog_id'].isin(treatments['dog_id']), 'age'].mean()"
provide the median age of the dogs that went through medications.,"dogs.loc[dogs['dog_id'].isin(treatments['dog_id']), 'age'].mean()"
"which professionals exist in the state of indiana or have completed treatment on more than 2 patients? provide their id, last name, and cell phone.","pd.concat([professionals.loc[lambda x: x['state'] == 'indiana', ['professional_id', 'last_name', 'cell_number']], professionals.merge(treatments, on='professional_id').groupby('professional_id').filter(lambda x: len(x) > 2).loc[:, ['professional_id', 'last_name', 'cell_number']].drop_duplicates()])[['professional_id', 'last_name', 'cell_number']]"
"retrieve the id, last name and phone number of the professionals who reside in the state of indiana or have carried out more than 2 treatments.","pd.concat([professionals.loc[lambda x: x['state'] == 'indiana', ['professional_id', 'last_name', 'cell_number']], professionals.merge(treatments, on='professional_id').groupby('professional_id').filter(lambda x: len(x) > 2).loc[:, ['professional_id', 'last_name', 'cell_number']].drop_duplicates()])[['professional_id', 'last_name', 'cell_number']]"
return me the names of dogs which have not been medicated for more than 1000.,"dogs.loc[~dogs['dog_id'].isin(treatments.groupby('dog_id').filter(lambda x: x['cost_of_treatment'].sum() > 1000)['dog_id']), 'name']"
how many dogs' owners have spent less than $1000 in veterinary?,"dogs.loc[~dogs['dog_id'].isin(treatments.groupby('dog_id').filter(lambda x: x['cost_of_treatment'].sum() > 1000)['dog_id']), 'name']"
list the titles that are used for professionals or owners but are not used for pets.,"pd.concat([professionals['first_name'], owners['first_name']]).drop_duplicates().reset_index(drop=true).loc[lambda x: ~(x.isin(dogs['name']))]"
"obtain all professional ids, names and emails associated with zero instances of dog treatments.","professionals[['professional_id', 'role_code', 'email_address']].merge(treatments[['professional_id']].rename(columns={'professional_id': 'id'}),how='left',left_on='professional_id',right_on='id').loc[lambda x: x['id'].isna()].drop('id', axis=1)"
"give the ids, roles, and email addresses of professionals who did not perform any treatment on dogs.","professionals[['professional_id', 'role_code', 'email_address']].merge(treatments[['professional_id']].rename(columns={'professional_id': 'id'}),how='left',left_on='professional_id',right_on='id').loc[lambda x: x['id'].isna()].drop('id', axis=1)"
list the names of owners with the biggest number of dogs.,"owners.loc[dogs.groupby('owner_id')['dog_id'].count().idxmax(), ['owner_id', 'first_name', 'last_name']]"
"please provide me the owner id, first name and last name of the owner who has the most dogs.","owners.loc[dogs.groupby('owner_id')['dog_id'].count().idxmax(), ['owner_id', 'first_name', 'last_name']]"
"find the ids of professionals that have performed at least two treatments, along with the role and the first name.","professionals.merge(treatments, on='professional_id').groupby(['professional_id', 'role_code', 'first_name']).filter(lambda x: len(x) >= 2).drop_duplicates(['professional_id'])[['professional_id', 'role_code', 'first_name']]"
"provide me with the id, role, and first name of professionals who have performed two or more treatments.","professionals.merge(treatments, on='professional_id').groupby(['professional_id', 'role_code', 'first_name']).filter(lambda x: len(x) >= 2).drop_duplicates(['professional_id'])[['professional_id', 'role_code', 'first_name']]"
please provide me with the name of the breed with the most dogs.,"pd.merge(breeds, dogs, on='breed_code').groupby('breed_name').size().sort_values(ascending=false).index[0]"
which breed do most dogs have? give me the name of that breed.,"pd.merge(breeds, dogs, on='breed_code').groupby('breed_name').size().sort_values(ascending=false).index[0]"
which one owner has paid for the most treatments done on his or her dogs? provide the name of the owner id and last name.,"owners.merge(dogs).merge(treatments).groupby(['owner_id', 'last_name']).size().idxmax()"
provide me with the id and surname of the owner who has spent the most amount of money on treating his or her dogs.,"owners.merge(dogs).merge(treatments).groupby(['owner_id', 'last_name']).size().idxmax()"
what is the description of treatment type that costs the least amount?,"pd.merge(treatment_types, treatments, on='treatment_type_code').groupby('treatment_type_description').agg({'cost_of_treatment': 'sum'}).sort_values('cost_of_treatment').index[0]"
could you provide me with the short description of the treatment type whose total cost is the lowest?,"pd.merge(treatment_types, treatments, on='treatment_type_code').groupby('treatment_type_description').agg({'cost_of_treatment': 'sum'}).sort_values('cost_of_treatment').index[0]"
show the name and zip code of the owner of the largest amount of money paid in total for his dogs.,"pd.merge(pd.merge(owners, dogs, on='owner_id'), treatments, on='dog_id').groupby(['owner_id', 'zip_code'])['cost_of_treatment'].sum().reset_index().sort_values('cost_of_treatment', ascending=false).iloc[0, :2]"
"retrieve the title, id, and zip code of an owner who spent the most amount of money on its dogs.","pd.merge(pd.merge(owners, dogs, on='owner_id'), treatments, on='dog_id').groupby(['owner_id', 'zip_code'])['cost_of_treatment'].sum().reset_index().sort_values('cost_of_treatment', ascending=false).iloc[0, :2]"
"provide the professional id, full name, and cell phone number of the professionals who have completed at least two types of treatment.","pd.merge(professionals, treatments, on='professional_id').groupby('professional_id').filter(lambda x: len(x) >= 2)[['professional_id', 'cell_number']].drop_duplicates()"
determine the id and cell phone numbers of the professionals who operate two or more types of treatments.,"pd.merge(professionals, treatments, on='professional_id').groupby('professional_id').filter(lambda x: len(x) >= 2)[['professional_id', 'cell_number']].drop_duplicates()"
obtain the names of professionals who have received treatment at lower costs than average.,"pd.merge(professionals, treatments.loc[lambda x: x['cost_of_treatment'] < treatments['cost_of_treatment'].mean()], on='professional_id')[['first_name', 'last_name']].drop_duplicates()"
"what is the count of professionals that operated a treatment that costs less than the average, along with their first and last names?","pd.merge(professionals, treatments.loc[lambda x: x['cost_of_treatment'] < treatments['cost_of_treatment'].mean()], on='professional_id')[['first_name', 'last_name']].drop_duplicates()"
"enumerate the name of the treatment, the date it was administered, and the name of the professional who administered it.","pd.merge(treatments, professionals, on='professional_id')[['date_of_treatment', 'first_name']]"
determine the first and last name of each individual as well as the date on which each treatment was performed.,"pd.merge(treatments, professionals, on='professional_id')[['date_of_treatment', 'first_name']]"
list the cost of each treatment and the descriptive text for each treatment type.,"pd.merge(treatments, treatment_types, on='treatment_type_code')[['cost_of_treatment', 'treatment_type_description']]"
please provide the estimated cost and treatment type details for each treatment.,"pd.merge(treatments, treatment_types, on='treatment_type_code')[['cost_of_treatment', 'treatment_type_description']]"
"retain a list of the first, last, and size of dog owned by each owner.","pd.merge(owners, dogs, on='owner_id')[['first_name', 'last_name', 'size_code']]"
return the full name and the size of each owner's dog as well as their first name.,"pd.merge(owners, dogs, on='owner_id')[['first_name', 'last_name', 'size_code']]"
give the list of the pairs of first names of the masters and the names of the dogs.,"pd.merge(owners, dogs, on='owner_id')[['first_name', 'name']]"
provide the names of owners along with their partners' names of dogs and cats.,"pd.merge(owners, dogs, on='owner_id')[['first_name', 'name']]"
list the names of dogs of rarest breed and the dates of treatment of them.,"dogs.merge(treatments, on='dog_id').loc[lambda x: x['breed_code'] == dogs.groupby('breed_code').size().sort_values().index[0], ['name', 'date_of_treatment']]"
give me the names of dogs who are of the rarest breed along with the respective treatment dates.,"dogs.merge(treatments, on='dog_id').loc[lambda x: x['breed_code'] == dogs.groupby('breed_code').size().sort_values().index[0], ['name', 'date_of_treatment']]"
give me the names of dogs owned in virginia and their owners' first names.,"pd.merge(owners, dogs, on='owner_id').loc[lambda x: x['state']=='virginia', ['first_name', 'name']]"
list the names of owners residing in virginia along with the corresponding names of the dogs they possess.,"pd.merge(owners, dogs, on='owner_id').loc[lambda x: x['state']=='virginia', ['first_name', 'name']]"
what is the arrival and departure date of dogs that have been treated for fleas?,"pd.merge(dogs, treatments, on='dog_id')[['date_arrived', 'date_departed']].drop_duplicates()"
determine the arriving date and the leaving date of dogs that received a treatment.,"pd.merge(dogs, treatments, on='dog_id')[['date_arrived', 'date_departed']].drop_duplicates()"
provide the last name and age of the owner with the youngest dog.,"owners.merge(dogs, on='owner_id').loc[lambda x: x['age']==dogs['age'].max(), 'last_name']"
please provide me with the last name and age of the dog owned by the youngest person.,"owners.merge(dogs, on='owner_id').loc[lambda x: x['age']==dogs['age'].max(), 'last_name']"
kindly list out the email addresses of the professionals who live in hawaii or wisconsin.,"professionals.loc[lambda x: x['state'].isin(['hawaii', 'wisconsin']), 'email_address']"
what is the list of e-mail addresses of professionals that reside in either the state of hawaii or the state of wisconsin?,"professionals.loc[lambda x: x['state'].isin(['hawaii', 'wisconsin']), 'email_address']"
how many dogs arrived on a given date and departed a later date?,"dogs[['date_arrived', 'date_departed']]"
how many dogs received any kind of treatment?,treatments['dog_id'].nunique()
determine the total number of doge that received treatment procedures.,treatments['dog_id'].nunique()
how many dog treatments have been performed by professionals?,treatments['professional_id'].nunique()
determine the population of professionals who have treated dogs.,treatments['professional_id'].nunique()
retrieve the domains of addresses of individuals who reside in a city that contains the substring 'west' in the address.,"professionals.loc[professionals['city'].str.contains('west', na=false), ['role_code', 'street', 'city', 'state']]"
"provide me the ids, street, city and state of professionals owning a city with the substring 'west'","professionals.loc[professionals['city'].str.contains('west', na=false), ['role_code', 'street', 'city', 'state']]"
"list the names of owners that reside in a state that has a substring 'north'. also, list their first name, last name and email.","owners.loc[owners['state'].str.contains('north'), ['first_name', 'last_name', 'email_address']]"
"provide me the first name, last name and email of owners living in states whose name contains the substring 'north'.","owners.loc[owners['state'].str.contains('north'), ['first_name', 'last_name', 'email_address']]"
what are the number of dogs with a age below the average?,(dogs['age'] < dogs['age'].mean()).sum()
determine the total count of dogs that are younger than the average number.,(dogs['age'] < dogs['age'].mean()).sum()
what is the cost of the least expensive treatment?,"treatments.sort_values('date_of_treatment', ascending=false).iloc[0]['cost_of_treatment']"
display me the cost of the most recently performed treatment.,"treatments.sort_values('date_of_treatment', ascending=false).iloc[0]['cost_of_treatment']"
what is the count of dogs who have not undergone any treatment?,"dogs.loc[~dogs['dog_id'].isin(treatments['dog_id']), 'dog_id'].count()"
tell me the count of dogs that have not received any treatment.,dogs['dog_id'].isin(treatments['dog_id']).value_counts()[false]
how many owners do not have dogs at any single time?,"owners.loc[~owners['owner_id'].isin(dogs['owner_id']), :].shape[0]"
what is the count of owners that have no dogs as pets?,"owners.loc[~owners['owner_id'].isin(dogs['owner_id']), :].shape[0]"
what is the number of professionals that did not treat any dog?,professionals['professional_id'].nunique() - treatments['professional_id'].nunique()
provide the count of professionals who have not treated any pet dogs.,professionals['professional_id'].nunique() - treatments['professional_id'].nunique()
"list the ids of dogs that have been abandoned, along with their age (in years) and weight (in kg).","dogs.loc[lambda x: x['abandoned_yn']==1, ['name', 'age', 'weight']]"
"please provide me with the information of dogs named, age and weight. note that 1 stands for yes, and 0 stands for no in the tables.","dogs.loc[lambda x: x['abandoned_yn']==1, ['name', 'age', 'weight']]"
what is the average of the age of all the dogs?,dogs['age'].mean()
"for all the dogs, please compute their ages.",dogs['age'].mean()
how old is the oldest dog?,dogs['age'].max()
precisely list the cost for each charge type.,"charges[['charge_type', 'charge_amount']]"
return the details of each charge type along with their values of charge.,"charges[['charge_type', 'charge_amount']]"
what is the total charge of the most expensive charge type?,charges['charge_amount'].max()
"provide me with the list of emails, cell phone numbers and home phone numbers of all the professionals.","professionals[['email_address', 'cell_number', 'home_phone']]"
"please list the ids and names of professionals along with their email, cell phone and home phone.","professionals[['email_address', 'cell_number', 'home_phone']]"
provide me the list of possible breed type and size type combinations.,"dogs[['breed_code', 'size_code']].drop_duplicates()"
what is the count of unique breed type and size type combinations for canines?,"dogs[['breed_code', 'size_code']].drop_duplicates()"
list the names of professionals who have cured the specified disease.,"pd.merge(pd.merge(professionals, treatments, on='professional_id'), treatment_types, on='treatment_type_code')[['first_name', 'treatment_type_description']].drop_duplicates()"
what is each professional's first name and description of the treatment they have performed?,"pd.merge(pd.merge(professionals, treatments, on='professional_id'), treatment_types, on='treatment_type_code')[['first_name', 'treatment_type_description']].drop_duplicates()"
how many are there?,singer.shape[0]
provide the count of singers.,singer.shape[0]
enumerate the names of singers in a descending order of net worth.,singer.sort_values('net_worth_millions')['name']
enumerate the net worths of the singers ordered by ascending order.,singer.sort_values('net_worth_millions')['name']
obtain the birth year and nationality of singers.,"singer[['birth_year','citizenship']]"
obtain the dates of birth and nationalities of the singers.,"singer[['birth_year','citizenship']]"
please list the titles of singers whose citizenship is not france.,"singer.loc[lambda x: x['citizenship'] != 'france', 'name']"
retrieve the names of singers that are not french citizens.,"singer.loc[lambda x: x['citizenship'] != 'france', 'name']"
is there a singer with birth year either 1948 or 1949?,"singer.loc[singer['birth_year'].isin([1948, 1949]), 'name']"
retrieve the titles of singers whose birth years are 1948 or 1949.,"singer.loc[singer['birth_year'].isin([1948, 1949]), 'name']"
what is the artist with the largest value net worth?,"singer.sort_values('net_worth_millions', ascending=false).iloc[0]['name']"
who is the singer with the maximum net worth?,"singer.sort_values('net_worth_millions', ascending=false).iloc[0]['name']"
"provide me with the count of singers that have different citizenships, along with the count of singers per citizenship.",singer.groupby('citizenship').size()
"for each country, how many singers are from that country?",singer.groupby('citizenship').size()
please list the names of singers who most commonly are holders of us citizenship.,"singer.groupby('citizenship').size().reset_index(name='counts').sort_values('counts', ascending=false).iloc[0, 0]"
what is the most common citizenship of singers?,singer.groupby('citizenship').size().sort_values(ascending=false).index[0]
list the names of singers along with their citizenship and maximum net worth.,singer.groupby('citizenship')['net_worth_millions'].max()
"for each citizenship, what is the highest net value?",singer.groupby('citizenship')['net_worth_millions'].max()
provide me the titles of songs and corresponding singers.,"pd.merge(singer, song, on='singer_id')[['title', 'name']]"
retrieve the list of song titles and names of singers,"pd.merge(singer, song, on='singer_id')[['title', 'name']]"
"get the names of singers who have songs with sales greater than $300,000.","pd.merge(singer, song, on='singer_id').loc[lambda x: x['sales']>300000, 'name'].nunique()"
what are the full names of singers whose sales exceed 300000?,"pd.merge(singer, song, on='singer_id').loc[lambda x: x['sales']>300000, 'name'].nunique()"
determine the names of singers that have more than one song.,"singer.merge(song, on='singer_id').groupby('name').filter(lambda x: len(x) > 1)['name'].unique()"
obtain the name of singers and total sales of their songs.,"song.merge(singer, on='singer_id').groupby('name')['sales'].sum()"
what is the total sum earned by each singer for their songs?,"song.merge(singer, on='singer_id').groupby('name')['sales'].sum()"
get a list of singers that have no songs in their name.,"singer.loc[~singer['singer_id'].isin(song['singer_id']), 'name']"
list all artists that do not have any songs.,"singer.loc[~singer['singer_id'].isin(song['singer_id']), 'name']"
which singers hold american citizenship and have birth years before and after 1955?,"singer.loc[singer['birth_year'] < 1945, 'citizenship'].intersects(singer.loc[singer['birth_year'] > 1955, 'citizenship'])"
are there citizenships shared by singers whose birth years fall before 1945 and after 1955?,"singer.loc[singer['birth_year'] < 1945, 'citizenship'].intersects(singer.loc[singer['birth_year'] > 1955, 'citizenship'])"
what is the total sum of available features?,other_available_features.shape[0]
what is the feature type of the aircon feature?,"pd.merge(other_available_features, ref_feature_types, on='feature_type_code').loc[lambda x: x['feature_name'] == 'aircon', 'feature_type_name']"
display the properties of that code along with its description.,"pd.merge(properties, ref_property_types, on='property_type_code').groupby('property_type_code')['property_type_description'].first()"
find the names of properties that are either cabins or apartments with 1 or more rooms.,"properties.loc[lambda x: x['property_type_code']=='house', 'property_name'].append(properties.loc[lambda x: (x['property_type_code']=='apartment') & (x['room_count']>1), 'property_name']).drop_duplicates()"
"the heads of the departments can be ordered by birth state, name and age.","head[['name', 'born_state', 'age']].sort_values('age')"
"the departments' creation year, name and budget are.","department[['creation', 'name', 'budget_in_billions']]"
what is the minimum and maximum budget of the departments?,"department['budget_in_billions'].agg(['max', 'min'])"
the average number of employees of the departments whose rank is between 10 and 15 are.,"department.loc[lambda x: x['ranking'].between(10,15), 'num_employees'].mean()"
which heads are born outside the california state?,"head.loc[lambda x: x['born_state'] != 'california', 'name']"
"what is the creation year of the secretary, born in state 'alabama', in departments managed?","pd.merge(pd.merge(department, management, on='department_id'), head, on='head_id').loc[lambda x: x['born_state']=='alabama', 'creation'].unique()"
which states did they at least 3 heads born in?,head.groupby('born_state').filter(lambda x: len(x) >= 3)['born_state'].unique()
most departments were established in which year? ,department.groupby('creation').size().sort_values(ascending=false).index[0]
"with temporary active value yes, show the name and number of employees for the departments managed by heads.","pd.merge(department, management, on='department_id').loc[lambda x: x['temporary_acting']=='yes', ['name', 'num_employees']]"
there are how many acting statuses?,management['temporary_acting'].nunique()
"by how many heads who are not mentioned, are departments led?",department[~department['department_id'].isin(management['department_id'])].shape[0]
what is the distinct age of the acting heads?,"pd.merge(head, management, on='head_id').loc[lambda x: x['temporary_acting']=='yes', 'age'].unique()"
states in which both the secretary of 'treasury' department and the secretary of 'homeland security' were born.,"pd.merge(pd.merge(department.loc[lambda x: x['name']=='treasury'], management, on='department_id'), head, on='head_id')['born_state'].unique() & pd.merge(pd.merge(department.loc[lambda x: x['name']=='homeland security'], management, on='department_id'), head, on='head_id')['born_state'].unique()"
"department 1 has more than 1 head at a time. list the id, name and the number of heads.","management.merge(department, on='department_id').groupby(['department_id', 'name']).size().reset_index(name='count').loc[lambda x: x['count']>1, ['department_id', 'name', 'count']]"
the number of farms are.,farm.shape[0]
let's see the total number of horses on farms in ascending order.,farm.sort_values('total_horses')['total_horses']
"what is the number of horses record for each farm, sorted ascending?",farm.sort_values('total_horses')['total_horses']
which competitions have themes other than 'aliens'?,"farm_competition.loc[lambda x: x['theme'] != 'aliens', 'hosts']"
which ones were not competitions about 'aliens'?,"farm_competition.loc[lambda x: x['theme'] != 'aliens', 'hosts']"
what are the themes of farm competitions sorted by year in descending order?,farm_competition.sort_values('year')['theme']
"the themes of farm competitions, sorted by year ascending are.",farm_competition.sort_values('year')['theme']
"what is the mean number of working horses of farms with more than 5,000 total number of horses?","farm.loc[lambda x: x['total_horses'] > 5000, 'working_horses'].mean()"
the average number of working horses on farms with more than 5000 total horses is.,"farm.loc[lambda x: x['total_horses'] > 5000, 'working_horses'].mean()"
the minimum and maximum number of cows across all farms are.,"farm['cows'].agg(['max', 'min'])"
how many cows are there on farms?,"farm['cows'].agg(['max', 'min'])"
what different statuses do cities have?,city['status'].nunique()
how many different statuses are there?,city['status'].nunique()
the name and status of the city with the largest population is.,"city[['official_name', 'status']].sort_values('population', ascending=false).head(1)"
what are the years and official names of the host cities of competitions?,"pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id')[['year', 'official_name']]"
the cities of each competition are.,"pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id')[['year', 'official_name']]"
how many cities have hosted more than one competition?,"pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id').groupby('host_city_id').filter(lambda x: len(x) > 1)['official_name']"
which cities have hosted more than one competition?,"pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id').groupby('host_city_id').filter(lambda x: len(x) > 1)['official_name']"
the number of competitions that the host city has hosted is greatest.,"pd.merge(city, farm_competition, left_on='city_id', right_on='host_city_id').groupby('host_city_id')['status'].count().sort_values(ascending=false).head(1)"
here are shown the themes of competitions with host cities having populations larger than 1000.,"city.merge(farm_competition, left_on='city_id', right_on='host_city_id').loc[lambda x: x['population'] > 1000, 'theme']"
which competitions have corresponding host cities with more than 1000 residents?,"city.merge(farm_competition, left_on='city_id', right_on='host_city_id').loc[lambda x: x['population'] > 1000, 'theme']"
please show the average number of residents in the cities and the statuses of the cities.,city.groupby('status')['population'].mean()
which are the statuses and average populations of each city?,city.groupby('status')['population'].mean()
the most frequently occurring status of cities is.,city.groupby('status').size().sort_values().index
the most common type of status across cities are.,city.groupby('status').size().sort_values(ascending=false).index[0]
which cities have not held any competition?,"city.loc[~city['city_id'].isin(farm_competition['host_city_id']), 'official_name']"
which city names have not hosted farm competitions?,"city.loc[~city['city_id'].isin(farm_competition['host_city_id']), 'official_name']"
cities bigger than 1500 and smaller than 500 have the status shared by.,"set(city.loc[city['population'] > 1500, 'status']).intersection(set(city.loc[city['population'] < 500, 'status']))"
in which cities are populations bigger than 1500 or smaller than 500?,"city.loc[(city['population']>1500) | (city['population']<500), 'official_name']"
what are the official names of cities that have a population over 1500 or less than 500?,"city.loc[(city['population']>1500) | (city['population']<500), 'official_name']"
the ranking of cities that are not villages is.,"city.loc[lambda x: x['status']!='village', 'census_ranking']"
"from the cities ranked by census as ""city"", what percentage does not have ""village"" status?","city.loc[lambda x: x['status']!='village', 'census_ranking']"
how many more registered students does each course have?,"pd.merge(courses, student_course_registrations, on='course_id').groupby('course_id')['course_name'].count().sort_values(ascending=false).head(1)"
what is the course with the most registered students?,"pd.merge(courses, student_course_registrations, on='course_id').groupby('course_id')['course_name'].count().sort_values(ascending=false).head(1)"
"which courses did those students register, and what was the least number of courses they registered?",student_course_registrations.groupby('student_id').size().nsmallest(1).index[0]
the ids of the students who registered for the fewest courses are.,student_course_registrations.groupby('student_id').size().nsmallest(1).index[0]
list the id of students that never attend courses?,"students.loc[~students['student_id'].isin(student_course_attendance['student_id']), 'student_id']"
 ids of every student who have never attended a course are.,"students.loc[~students['student_id'].isin(student_course_attendance['student_id']), 'student_id']"
which students attended some courses?,student_course_attendance['student_id']
which students attended at least one course?,student_course_attendance['student_id']
what are the ids of students for courses and what are the names of those courses?,"pd.merge(student_course_registrations, courses, on='course_id')[['student_id', 'course_name']]"
the most recent student to register a course was.,"pd.merge(student_course_registrations, students, on='student_id').sort_values('registration_date', ascending=false).iloc[0]['student_details']"
students attend course english how many? ,"pd.merge(courses[courses['course_name']=='english'], student_course_attendance, on='course_id').shape[0]"
the student 171 which course attend?,"pd.merge(courses, student_course_attendance, on='course_id').loc[lambda x: x['student_id'] == 171].shape[0]"
the student with id 171 actually attends how many courses?,"pd.merge(courses, student_course_attendance, on='course_id').loc[lambda x: x['student_id'] == 171].shape[0]"
which candidate's email is stanley.monahan@example.org?,"candidates.merge(people, left_on='candidate_id', right_on='person_id').loc[lambda x: x['email_address']=='stanley.monahan@example.org', 'candidate_id']"
id of candidate whose email is stanley.monahan@example.org?,"candidates.merge(people, left_on='candidate_id', right_on='person_id').loc[lambda x: x['email_address']=='stanley.monahan@example.org', 'candidate_id']"
by which candidate was the course accessed most recently?,"candidate_assessments.sort_values('assessment_date', ascending=false).iloc[0]['candidate_id']"
"most recently, which candidate accessed the course?","candidate_assessments.sort_values('assessment_date', ascending=false).iloc[0]['candidate_id']"
the student that registered the most courses has.,"students.merge(student_course_registrations, on='student_id').groupby('student_id')['student_details'].unique().sort_values(ascending=false).iloc[0]"
the student who registered for the most number of courses was .,"students.merge(student_course_registrations, on='student_id').groupby('student_id')['student_details'].unique().sort_values(ascending=false).iloc[0]"
which students registered some courses and the number of their registered courses?,"student_course_registrations.groupby('student_id').size().reset_index(name='count').merge(students, on='student_id')[['student_id', 'count']]"
how many courses are registered for each student who is registered for some course?,"student_course_registrations.groupby('student_id').size().reset_index(name='count').merge(students, on='student_id')[['student_id', 'count']]"
list the name and the number of registered students of each course.,"pd.merge(pd.merge(students, student_course_registrations, on='student_id'), courses, on='course_id').groupby('course_name').size()"
"for each course id, how many students are registered for the course and what are its names?","pd.merge(pd.merge(students, student_course_registrations, on='student_id'), courses, on='course_id').groupby('course_name').size()"
"whose assessment code is ""pass""?","candidate_assessments.loc[candidate_assessments['asessment_outcome_code']=='pass', 'candidate_id']"
which candidates have an outcome of pass? ,"candidate_assessments.loc[candidate_assessments['asessment_outcome_code']=='pass', 'candidate_id']"
which cell mobile number of the candidates is 406-666-9876?,"pd.merge(pd.merge(candidates, candidate_assessments, on='candidate_id'), people, left_on='candidate_id', right_on='person_id').loc[lambda x: x['asessment_outcome_code']=='fail', 'cell_mobile_number']"
"which candidates have cell phones that received an ""fail"" assessment code?","pd.merge(pd.merge(candidates, candidate_assessments, on='candidate_id'), people, left_on='candidate_id', right_on='person_id').loc[lambda x: x['asessment_outcome_code']=='fail', 'cell_mobile_number']"
which id of student registered course 301?,"student_course_attendance.loc[lambda x: x['course_id']==301, 'student_id']"
how many students registered for course 301?,"student_course_attendance.loc[lambda x: x['course_id']==301, 'student_id']"
the student who most recently registered course 301's id is.,"student_course_attendance.loc[lambda x: x['course_id']==301].sort_values('date_of_attendance', ascending=false)['student_id'].iloc[0]"
"which student registered most recently for course 301, and what id?","student_course_attendance.loc[lambda x: x['course_id']==301].sort_values('date_of_attendance', ascending=false)['student_id'].iloc[0]"
what are the distinct cities of addresses of people?,"pd.merge(addresses, people_addresses, on='address_id')['city'].unique()"
in which cities do people live?,"pd.merge(addresses, people_addresses, on='address_id')['city'].unique()"
find which cities each student belongs to?,"pd.merge(pd.merge(addresses, people_addresses, on='address_id'), students, left_on='person_id', right_on='student_id')['city'].unique()"
which universities are (located) in different cities?,"pd.merge(pd.merge(addresses, people_addresses, on='address_id'), students, left_on='person_id', right_on='student_id')['city'].unique()"
courses are:,courses['course_name'].sort_values()
what courses are they in alphabetical order?,courses['course_name'].sort_values()
the names of people are.,people['first_name'].sort_values()
 whose first names are in alphabetical order?,people['first_name'].sort_values()
what are the ids of students registered courses or attended courses?,"pd.concat([student_course_registrations['student_id'], student_course_attendance['student_id']]).drop_duplicates()"
"by which students either registered or attended a course, are the ids?","pd.concat([student_course_registrations['student_id'], student_course_attendance['student_id']]).drop_duplicates()"
which courses are registered or attended by student whose id is 121? ,"pd.concat([student_course_registrations.loc[student_course_registrations['student_id']==121, 'course_id'], student_course_attendance.loc[student_course_attendance['student_id']==121, 'course_id']]).drop_duplicates()"
the courses registered or attended by the student whose id is 121 are.,"pd.concat([student_course_registrations.loc[student_course_registrations['student_id']==121, 'course_id'], student_course_attendance.loc[student_course_attendance['student_id']==121, 'course_id']]).drop_duplicates()"
which students registered but did not take any course?,student_course_registrations.loc[~student_course_registrations['student_id'].isin(student_course_attendance['student_id'])]
which students registered course statistics in the order of registration date are their ids? ,"student_course_registrations.merge(courses, on='course_id').loc[lambda x: x['course_name']=='statistics'].sort_values('registration_date')['student_id']"
which students attended statistics courses in the order of attendance date?,"pd.merge(courses.loc[courses['course_name']=='statistics', ['course_id']], student_course_attendance, on='course_id').sort_values('date_of_attendance')['student_id']"
students in order of attendance attended the courses which ids were?,"pd.merge(courses.loc[courses['course_name']=='statistics', ['course_id']], student_course_attendance, on='course_id').sort_values('date_of_attendance')['student_id']"
when was the maximum temperature higher than 85?,"weather.loc[lambda x: x['max_temperature_f'] > 85, 'date']"
"what is the number of dates in june, with a maximum temperature higher than 85?","weather.loc[lambda x: x['max_temperature_f'] > 85, 'date']"
which stations are lower than latitude 37.5?,"station.loc[lambda x: x['lat']<37.5, 'name']"
"what latitude does the station have, which has a smaller name than the other stations?","station.loc[lambda x: x['lat']<37.5, 'name']"
"highest latitude for each city, among its stations are. ",station.groupby('city')['lat'].max()
"for each city (latitude), what is the highest latitude of its stations?",station.groupby('city')['lat'].max()
"of the oldest trip id, give me the start station and end station.","trip[['start_station_name', 'end_station_name']].sort_values('id').head(3)"
find the station and the end stations of the smallest ids.,"trip[['start_station_name', 'end_station_name']].sort_values('id').head(3)"
the average latitude and longitude of stations located in san jose city are.,"station.loc[lambda x: x['city'] == 'san jose', ['lat', 'long']].mean()"
the trip that has the shortest duration is ___.,trip.sort_values('duration')['id'].iloc[0]
what is the total and maximum duration for all trips with the bike id 636?,"trip.loc[trip['bike_id']==636, 'duration'].agg(['sum', 'max'])"
the number of unique bikes from the trip record is.,trip['bike_id'].nunique()
what bike id(s) are there?,trip['bike_id'].nunique()
where are the stations located and what are their distinct cities?,station['city'].nunique()
how many stations does the city of mountain view has?,(station['city'] == 'mountain view').sum()
"which stations had 7 bikes available, and have they ever had a unique name?","pd.merge(station, status, left_on='id', right_on='station_id').loc[lambda x: x['bikes_available'] == 7, 'name'].unique()"
"which stations have ever had 7 bikes available, and what were their names?","pd.merge(station, status, left_on='id', right_on='station_id').loc[lambda x: x['bikes_available'] == 7, 'name'].unique()"
which station had the most trips starting from august? give me the name and id of the station.,"trip.loc[lambda x: x['start_date'].str.startswith('8/'), ['start_station_name', 'start_station_id']].groupby('start_station_name').size().sort_values(ascending=false).head(1).reset_index()[['start_station_name', 'start_station_id']]"
"the start station that had the most start trips in august, what is the id and name?","trip.loc[lambda x: x['start_date'].str.startswith('8/'), ['start_station_name', 'start_station_id']].groupby('start_station_name').size().sort_values(ascending=false).head(1).reset_index()[['start_station_name', 'start_station_id']]"
in which zip code bike traveled the most often?,trip.loc[lambda x: x['zip_code']==94002].groupby('bike_id').size().sort_values(ascending=false).index[0]
which id of the bike did travel the most in 94002?,trip.loc[lambda x: x['zip_code']==94002].groupby('bike_id').size().sort_values(ascending=false).index[0]
"what latitude, longitude, and city of the station is the shortest trip from?","pd.merge(station, trip, left_on='id', right_on='start_station_id').sort_values('duration').iloc[0][['lat', 'long', 'city']]"
the trip with the shortest duration started from which station?,"pd.merge(station, trip, left_on='id', right_on='start_station_id').sort_values('duration').iloc[0][['lat', 'long', 'city']]"
stations in san francisco with average bike availability above 10 have which ids?,"station.loc[station['city'] == 'san francisco', 'id'].tolist() & status.groupby('station_id').filter(lambda x: x['bikes_available'].mean() > 10)['station_id'].tolist()"
what stations in san francisco normally have more than 10 bikes available?,"station.loc[station['city'] == 'san francisco', 'id'].tolist() & status.groupby('station_id').filter(lambda x: x['bikes_available'].mean() > 10)['station_id'].tolist()"
"which stations had more than 14 bikes available on average in december, and what are their names and ids?","pd.concat([pd.merge(station, status, on='id').groupby('id').filter(lambda x: x['bikes_available'].mean() > 14)[['name', 'id']],station.loc[lambda x: x['installation_date'].str.startswith('12/'), ['name', 'id']]])"
"by how much do stations in which the average number of bikes is more than 14, have or had bikes installed in december?","pd.concat([pd.merge(station, status, on='id').groupby('id').filter(lambda x: x['bikes_available'].mean() > 14)[['name', 'id']],station.loc[lambda x: x['installation_date'].str.startswith('12/'), ['name', 'id']]])"
the 3 most common cloud cover rates in the region of zip code 94107 are.,weather.loc[lambda x: x['zip_code']==94107].groupby('cloud_cover').size().sort_values(ascending=false).head(3).reset_index()['cloud_cover']
the most common cloud covers in the zip code of 94107  are.,weather.loc[lambda x: x['zip_code']==94107].groupby('cloud_cover').size().sort_values(ascending=false).head(3).reset_index()['cloud_cover']
the zip code in which the average mean sea level pressure is the lowest is .,weather.groupby('zip_code')['mean_sea_level_pressure_inches'].mean().sort_values().head(1).index[0]
what is the average bike availability in stations in palo alto?,"status[~status['station_id'].isin(station.loc[station['city']=='palo alto', 'id'])]['bikes_available'].mean()"
"on average, how many bikes are available for stations not in palo alto? ","status[~status['station_id'].isin(station.loc[station['city']=='palo alto', 'id'])]['bikes_available'].mean()"
stations that never had bike availability more than 10 have an average longitude of.,"station.loc[~station['id'].isin(status.groupby('station_id').filter(lambda x: x['bikes_available'].max() > 10)['station_id']), 'long'].mean()"
the mean longitude for all stations that have never had more than 10 bikes available is.,"station.loc[~station['id'].isin(status.groupby('station_id').filter(lambda x: x['bikes_available'].max() > 10)['station_id']), 'long'].mean()"
when and in what zip code did the temperature reach 80 degrees?,"weather.loc[lambda x: x['max_temperature_f'] >= 80, ['date', 'zip_code']]"
which zip codes have a station with a max temperature greater than or equal to 80 and when did it reach that temperature?,"weather.loc[lambda x: x['max_temperature_f'] >= 80, ['date', 'zip_code']]"
give me ids for trips that took place in a zip code area with an average mean temperature above 60. ,"trip.merge(weather, on='zip_code').groupby('zip_code').filter(lambda x: x['mean_temperature_f'].mean() > 60)['id']"
the average mean temperature above 60 per zip code is.,"trip.merge(weather, on='zip_code').groupby('zip_code').filter(lambda x: x['mean_temperature_f'].mean() > 60)['id']"
what zip codes reached max windspeed 25?,weather.loc[lambda x: x['max_wind_speed_mph']>=25].groupby('zip_code').size()
"for each zip code, how many times has a' maximum wind speed reached 25 mph?",weather.loc[lambda x: x['max_wind_speed_mph']>=25].groupby('zip_code').size()
"what days had a minimum dew point smaller than any day in zip code 94107, and in which zip codes were those measurements taken?","weather.loc[weather['min_dew_point_f'] < weather.loc[weather['zip_code'] == 94107, 'min_dew_point_f'].min(), ['date', 'zip_code']]"
"on all the trips, the installation date for each ending station is.","pd.merge(trip, station, left_on='end_station_id', right_on='id')[['id', 'installation_date']]"
the trip whose departure station has the largest dock count is. trip id is.,"trip.merge(station, left_on='start_station_id', right_on='id').sort_values('dock_count', ascending=false).iloc[0]['id']"
the trip that started from the station with the highest dock count has the.,"trip.merge(station, left_on='start_station_id', right_on='id').sort_values('dock_count', ascending=false).iloc[0]['id']"
how many trips did not end in san francisco city?,"pd.merge(trip, station, left_on='end_station_id', right_on='id').loc[lambda x: x['city']!='san francisco'].shape[0]"
neither fog nor rain was observed on which day in zip code 94107?,"weather.loc[(weather['zip_code']==94107) & (weather['events']!='fog') & (weather['events']!='rain'), 'date']"
on which day did neither the fog nor rain appear in the 94107 zip code area?,"weather.loc[(weather['zip_code']==94107) & (weather['events']!='fog') & (weather['events']!='rain'), 'date']"
"latitude above 37.4, stations that never had bike availability below 7, have ids.","station.loc[lambda x: x['lat'] > 37.4].merge(status, on='station_id').groupby('station_id').min().loc[lambda x: x['bikes_available']>=7].reset_index()['station_id']"
how many stations never have less than 7 bikes available and have their latitude above 37.4?,"station.loc[lambda x: x['lat'] > 37.4].merge(status, on='station_id').groupby('station_id').min().loc[lambda x: x['bikes_available']>=7].reset_index()['station_id']"
"stations in san jose city, which have average bike availability above 10, are.","station.merge(status, on='id').groupby('station_id').filter(lambda x: x['bikes_available'].mean() > 10)['name'].drop_duplicates().loc[lambda x: x!='san jose']"
which stations have more than 10 bikes available and are not located in san jose?,"station.merge(status, on='id').groupby('station_id').filter(lambda x: x['bikes_available'].mean() > 10)['name'].drop_duplicates().loc[lambda x: x!='san jose']"
the station with the lowest latitude is.,"station[['name', 'lat', 'city']].sort_values('lat').head(1)"
"what is the name of the station that is located the furthest south, and its latitude and city?","station[['name', 'lat', 'city']].sort_values('lat').head(1)"
what are the names and the number of stations for the cities that have at least 15 stations?,station.groupby('city').filter(lambda x: len(x) >= 15).groupby('city').size()
"what is the name of every city that has at least 15 stations, and how many stations does it have?",station.groupby('city').filter(lambda x: len(x) >= 15).groupby('city').size()
"at least 200 trips started from which stations, and what are their ids and names? ","trip.groupby(['start_station_id', 'start_station_name']).filter(lambda x: len(x) >= 200)['start_station_id', 'start_station_name'].drop_duplicates(subset='start_station_id')"
which start stations were the beginning of at least 200 trips?,"trip.groupby(['start_station_id', 'start_station_name']).filter(lambda x: len(x) >= 200)['start_station_id', 'start_station_name'].drop_duplicates(subset='start_station_id')"
below 10 what is the average mean visibility of the zip code?,weather.groupby('zip_code').filter(lambda x: x['mean_visibility_miles'].mean() < 10)['zip_code'].unique()
from which cities do stations have the highest latitude?,station.groupby('city')['lat'].max().sort_values(ascending=false).index.tolist()
"which cities have their highest station latitude?[hint: improper negative sentences (""... are not owned by cctv."") are a common source of errors.]",station.groupby('city')['lat'].max().sort_values(ascending=false).index.tolist()
which dates had the highest cloud cover rate? also tell me the cloud cover rate.,"weather[['date', 'cloud_cover']].sort_values('cloud_cover',ascending=false).head(5)"
what is the date that has the 5 highest cloud cover rate and the rate?,"weather[['date', 'cloud_cover']].sort_values('cloud_cover',ascending=false).head(5)"
"with the top 3 durations, what are the ids and durations of the trips?","trip[['id', 'duration']].sort_values('duration', ascending=false).head(3)"
what are the trip ids that lasted the longest and how long did they last?,"trip[['id', 'duration']].sort_values('duration', ascending=false).head(3)"
"for each station, what is its longitude and the average duration of trips that started from that station?","trip.groupby('start_station_id').agg(avg_duration=('duration','mean')).reset_index().merge(station[['id','name','long']], left_on='start_station_id', right_on='id')[['name','long','avg_duration']]"
"for each station, what is the latitude and the minimum duration of trips that ended at the station?","pd.merge(station, trip, left_on='id', right_on='end_station_id').groupby('end_station_id').agg({'name': 'first', 'lat': 'first', 'duration': 'min'})[['name', 'lat', 'duration']]"
from which station did the most trips of duration below 100 start?,"trip.loc[lambda x: x['duration'] < 100, 'start_station_name'].unique()"
some people have used different start station names for a trip that lasted less than 100.,"trip.loc[lambda x: x['duration'] < 100, 'start_station_name'].unique()"
the zip codes in which the max dew point have never reached 70 are.,"weather.loc[lambda x: x['max_dew_point_f'] < 70, 'zip_code'].unique()"
how many different zip codes have a maximum dew point below 70?,"weather.loc[lambda x: x['max_dew_point_f'] < 70, 'zip_code'].unique()"
"at least as long as the average duration of trips in zip code 94103, how many trips lasted?","trip.loc[lambda x: x['duration'] >= trip.loc[lambda y: y['zip_code'] == 94103, 'duration'].mean(), 'id']"
what is the total number of trips that had the same duration as the average trip duration in the zip code 94103?,"trip.loc[lambda x: x['duration'] >= trip.loc[lambda y: y['zip_code'] == 94103, 'duration'].mean(), 'id']"
the mean sea level pressure was between 30.3 and 31 on.,"weather.loc[(weather['mean_sea_level_pressure_inches'] > 30.3) & (weather['mean_sea_level_pressure_inches'] < 31), 'date']"
which weeks have an average sea level pressure between 30.3 and 31? ,"weather.loc[(weather['mean_sea_level_pressure_inches'] > 30.3) & (weather['mean_sea_level_pressure_inches'] < 31), 'date']"
in which day was the difference between the max temperature and min temperature the smallest?,"weather.assign(temp_range=weather['max_temperature_f'] - weather['min_temperature_f']).sort_values('temp_range').iloc[0][['date', 'temp_range']]"
"what days had the smallest temperature range, and what was that range?","weather.assign(temp_range=weather['max_temperature_f'] - weather['min_temperature_f']).sort_values('temp_range').iloc[0][['date', 'temp_range']]"
at which stations have there ever been more than 12 bikes available?,"pd.merge(station, status.query('bikes_available > 12')[['station_id']], left_on='id', right_on='station_id')[['id', 'name']].drop_duplicates()"
how many stations had more than 12 bikes available?,"pd.merge(station, status.query('bikes_available > 12')[['station_id']], left_on='id', right_on='station_id')[['id', 'name']].drop_duplicates()"
"the zip code where the average mean humidity is below 70 and at least 100 trips took place, is.",weather.groupby('zip_code').mean().loc[lambda x: x['mean_humidity'] < 70].reset_index()['zip_code'].isin(trip['zip_code'].value_counts().loc[lambda x: x >= 100].index).values
the zip codes that have an average mean humidity below 70 and had at least 100 trips come through there are.,weather.groupby('zip_code').mean().loc[lambda x: x['mean_humidity'] < 70].reset_index()['zip_code'].isin(trip['zip_code'].value_counts().loc[lambda x: x >= 100].index).values
which stations are located in palo alto city but have never been the ending point of trips more than 100 times?,"station.loc[lambda x: x['city']=='palo alto', 'name'].loc[lambda x: ~x.isin(trip.groupby('end_station_name').filter(lambda x: len(x)>100).end_station_name.unique())]"
"which stations have been visited many times in palo alto, but have never ended the trip ","station.loc[lambda x: x['city']=='palo alto', 'name'].loc[lambda x: ~x.isin(trip.groupby('end_station_name').filter(lambda x: len(x)>100).end_station_name.unique())]"
how many trips started from mountain view city and ended in palo alto city?,"pd.merge(pd.merge(pd.merge(station, trip, left_on='id', right_on='start_station_id'), station, left_on='end_station_id', right_on='id', suffixes=('_start', '_end')),trip, on='id').loc[lambda x: (x['city_start'] == 'mountain view') & (x['city_end'] == 'palo alto'), :].shape[0]"
"in a station in mountain view, how many trips were stated, and ended at one in palo alto?","pd.merge(pd.merge(pd.merge(station, trip, left_on='id', right_on='start_station_id'), station, left_on='end_station_id', right_on='id', suffixes=('_start', '_end')),trip, on='id').loc[lambda x: (x['city_start'] == 'mountain view') & (x['city_end'] == 'palo alto'), :].shape[0]"
what is the average of latitude and longitude of the starting points of all trips? ,"pd.merge(station, trip, left_on='id', right_on='start_station_id').agg({'lat': 'mean', 'long': 'mean'})"
the latitude and the average longitude of the starting stations of the trips are.,"pd.merge(station, trip, left_on='id', right_on='start_station_id').agg({'lat': 'mean', 'long': 'mean'})"
what do the books consist of?,book.shape[0]
what are the names of the authors in ascending alphabetical order?,book.sort_values('writer')['writer']
which books are in ascending order of issues?,book.sort_values('issues')['title']
"the writer of which books is not ""elaine lee""?","book.loc[lambda x: x['writer'] != 'elaine lee', 'title']"
the title and issues of the books?,"book[['title', 'issues']]"
which dates of publications are in descending order of price?,"publication.sort_values('price', ascending=false)['publication_date']"
"the publications with price higher than 5000000, what are the distinct publishers?","publication.loc[lambda x: x['price'] > 5000000, 'publisher'].unique()"
which is the most expensive publisher?,"publication.sort_values('price', ascending=false).iloc[0]['publisher']"
publications with 3 lowest prices were published.,publication.sort_values('price').head(3)['publication_date']
which books have been published?,"pd.merge(book, publication, on='book_id')[['title', 'publication_date']]"
"how many books have writers published whose cost is more than $ 4,000,000?","book.merge(publication, on='book_id').loc[lambda x: x['price'] > 4000000, 'writer']"
titles of books in descending order of publication price are.,"pd.merge(book, publication, on='book_id').sort_values('price', ascending=false)['title']"
which publishers have more than one publication?,publication.groupby('publisher').filter(lambda x: len(x) > 1)['publisher'].unique()
which publishers have published the most documents?,publication.groupby('publisher').size().reset_index(name='count')
which publication date is the most common?,publication.groupby('publication_date').size().sort_values(ascending=false).index[0]
which writers have written more than one book?,book.groupby('writer').filter(lambda x: len(x) > 1)['writer']
which titles have not been published?,"book.loc[~book['book_id'].isin(publication['book_id']), 'title']"
some publishers have publications with price higher than 10000000 and others will have publications with price lower than 5000000.,"pd.merge(publication.loc[lambda x: x['price'] > 10000000, 'publisher'], publication.loc[lambda x: x['price'] < 5000000, 'publisher']).drop_duplicates()"
how many distinct publication dates?,publication['publication_date'].nunique()
distinct publication dates of our record are.,publication['publication_date'].nunique()
"publishers of which are ""person"" or ""wiley"", show the prices of publications.","publication.loc[lambda x: x['publisher'].isin(['person', 'wiley']), 'price']"
the number of actors is.,actor.shape[0]
"actors, whose names are sorted in ascending order are.",actor.sort_values('name')['name']
which actors are ordered alphabetically?,actor.sort_values('name')['name']
who and for how long have they been actors?,"actor[['character', 'duration']]"
the character and duration for each actor are.,"actor[['character', 'duration']]"
how many actors are not 20 years of age?,"actor.loc[lambda x: x['age'] != 20, 'name']"
which actors do'not' have their 20th birthday?,"actor.loc[lambda x: x['age'] != 20, 'name']"
from which actors are characters in descending order of age?,"actor.sort_values('age', ascending=false)['character']"
"ordered by age descending, the characters of actors are returned.","actor.sort_values('age', ascending=false)['character']"
the duration of the oldest actor is.,"actor.sort_values('age', ascending=false).iloc[0]['duration']"
bob fosse was nominated for which musicals?,"musical.loc[musical['nominee']=='bob fosse', 'name']"
which nominees for musicals have the nominee bob fosse?,"musical.loc[musical['nominee']=='bob fosse', 'name']"
"the musicals that have won awards that are not ""tony award"" are.","musical.loc[lambda x: x['award'] != 'tony award', 'nominee'].unique()"
"what is the award that is not the tony award, and who are the nominated musicals?","musical.loc[lambda x: x['award'] != 'tony award', 'nominee'].unique()"
show the names of actors and names of musicals they are in.,"pd.merge(actor, musical, on='musical_id')[['name_x', 'name_y']]"
which actors are in which musicals?,"pd.merge(actor, musical, on='musical_id')[['name_x', 'name_y']]"
which actors have appeared in the musical with name 'the phantom of the opera'?,"actor.merge(musical.loc[musical['name'] == 'the phantom of the opera', ['musical_id']], on='musical_id')['name']"
which actor is awarded the greatest musical prize? ,"pd.merge(actor, musical, on='musical_id').sort_values('year', ascending=false)['name']"
"in the musical year in which most were awarded, the names of actors are ordered descending.","pd.merge(actor, musical, on='musical_id').sort_values('year', ascending=false)['name']"
who have been the most prolific musical actors and which musicals?,"actor.merge(musical, on='musical_id').groupby('musical_id')['name'].count().reset_index().rename(columns={'name': 'count'}).merge(musical, on='musical_id')[['name', 'count']]"
in which musical have the largest number of actors appeared?,"actor.merge(musical, on='musical_id').groupby('musical_id')['name'].agg(['count', 'first'])"
how many musicals have at least one actor? ,"pd.merge(actor, musical, on='musical_id').groupby(['musical_id', 'name']).size().loc[lambda x: x>=3].reset_index().loc[:, 'name']"
how many musicals have at 3 or more actors?,"pd.merge(actor, musical, on='musical_id').groupby(['musical_id', 'name']).size().loc[lambda x: x>=3].reset_index().loc[:, 'name']"
what are the names of the different nominees and the number of musicals they have been nominated?,musical.groupby('nominee').size().reset_index(name='count')
how many musicals have each nominee been nominated for?,musical.groupby('nominee').size().reset_index(name='count')
which nominee has been nominated the greatest number of times?,musical.groupby('nominee').size().sort_values(ascending=false).index[0]
how many musicals has the nominee been nominated for the most?,musical.groupby('nominee').size().sort_values(ascending=false).index[0]
list of the most common result of the musicals.,musical.groupby('result').size().sort_values(ascending=false).index[0]
which is the most frequent result?,musical.groupby('result').size().sort_values(ascending=false).index[0]
"more than two musicals, the nominees were.",musical.groupby('nominee').filter(lambda x: len(x) > 2)['nominee'].unique()
which nominees have been nominated more than twice?,musical.groupby('nominee').filter(lambda x: len(x) > 2)['nominee'].unique()
which musicals do not have actors?,"musical.loc[~musical['musical_id'].isin(actor['musical_id']), 'name']"
"which musicals have no actors, and what are their names?","musical.loc[~musical['musical_id'].isin(actor['musical_id']), 'name']"
"those that have nominated musicals for both the ""tony award"" and the ""drama desk award"" are.","musical.loc[musical['award']=='tony award', 'nominee'].interesect(musical.loc[musical['award']=='drama desk award', 'nominee'])"
how many nominees have both of them nominated for a tony award and a drama desk award?,"musical.loc[musical['award']=='tony award', 'nominee'].interesect(musical.loc[musical['award']=='drama desk award', 'nominee'])"
"award ""bob fosse"" or ""cleavant derricks"" was received by.","musical.loc[musical['award'].isin(['tony award', 'cleavant derricks']), 'nominee']"
"who are the nominees, who were nominated either for the bob fosse or cleavant derricks awards?","musical.loc[musical['award'].isin(['tony award', 'cleavant derricks']), 'nominee']"
which user named 'mary' have emails?,"user_profiles.loc[lambda x: x['name']=='mary', 'email']"
"the partition id of the user named ""iron man"" is .","user_profiles.loc[lambda x: x['name']=='iron man', 'partitionid']"
how many users are there in?,user_profiles.shape[0]
"for each user, how many followers have?",follows.shape[0]
what is the number of tweets in record?,tweets.shape[0]
how many users posted some tweets?,tweets['uid'].nunique()
her name is ______.,"user_profiles.loc[user_profiles['name'].str.contains('swift'), ['name', 'email']]"
which users' emails contain 'superstar' or 'edu'?,"user_profiles.loc[user_profiles['email'].str.contains('superstar|edu'), 'name']"
the texts about the intern topic are.,"tweets.loc[tweets['text'].str.contains('intern', case=false), 'text']"
"which users have more than 1000 followers, and what are their names and email?","user_profiles.loc[user_profiles['followers'] > 1000, ['name', 'email']]"
"which users' number of followers is greater than that of the user named ""tyler swift""?","user_profiles.loc[lambda x: x['uid'].isin(follows['f1'].groupby(follows['f1']).count().pipe(lambda s:s[s > user_profiles['name'].eq('tyler swift').sum()]).index), 'name']"
"what is the name of users who have more than one follower, and what are their email addresses?","user_profiles.merge(follows, left_on='uid', right_on='f1').groupby(['uid', 'name', 'email']).filter(lambda x: len(x) > 1).loc[:, ['name', 'email']].drop_duplicates()"
which users have more than one tweet?,"pd.merge(user_profiles, tweets, on='uid').groupby('uid').filter(lambda x: len(x) > 1)['name']"
susan and mary do which user follows?,"follows.merge(user_profiles[user_profiles['name'] == 'mary'], left_on='f2', right_on='uid')['f1'].intersec‌t(follows.merge(user_profiles[user_profiles['name'] == 'susan'], left_on='f2', right_on='uid')['f1'])"
users who are followed by mary or susan have the.,"pd.merge(user_profiles[user_profiles['name'].isin(['mary', 'susan'])], follows, left_on='uid', right_on='f2')['f1']"
which user has the most followers?,"user_profiles.sort_values('followers', ascending=false).iloc[0]['name']"
(who is followed by the least number of people) email name,"user_profiles[['name', 'email', 'followers']].sort_values('followers').iloc[0, :2]"
"list the name and the number of followers for each user, and sort the results by the number of followers in descending order.","user_profiles[['name', 'followers']].sort_values('followers', ascending=false)"
5 users follow which other users.,"user_profiles.sort_values('followers', ascending=false).iloc[:5]['name']"
the tweets are in the order when the text.,tweets.sort_values('createdate')['text']
each user tweeted how many tweets?,"tweets.merge(user_profiles, on='uid').groupby('uid')['name'].count().reset_index()"
"less than twice, who are the users who tweeted?","pd.merge(user_profiles, tweets, on='uid').groupby(['uid', 'name', 'partitionid']).filter(lambda x: len(x)<2)[['name', 'partitionid']].drop_duplicates()"
"which user tweeted more than once, and how many times did they tweet?","pd.merge(user_profiles, tweets, on='uid').groupby('uid')['name'].count().loc[lambda x: x > 1]"
"how many users have zero tweets, and what are their average number of followers?","user_profiles.loc[~user_profiles['uid'].isin(tweets['uid']), 'followers'].mean()"
what is the average number of followers for the users who had some tweets?,user_profiles.loc[user_profiles['uid'].isin(tweets['uid'])]['followers'].mean()
the total number of users is maximum.,"user_profiles['followers'].agg(['max', 'sum'])"
what attribute data types do more than 3 attribute definitions possess?,attribute_definitions.groupby('attribute_data_type').filter(lambda x: len(x) > 3)['attribute_data_type'].unique()
which attribute data types have more than 3 attribute definitions?,attribute_definitions.groupby('attribute_data_type').filter(lambda x: len(x) > 3)['attribute_data_type'].unique()
"what is the data type of the attribute ""green""?","attribute_definitions.loc[lambda x: x['attribute_name']=='green', 'attribute_data_type']"
"what is the type of attribute ""green""?","attribute_definitions.loc[lambda x: x['attribute_name']=='green', 'attribute_data_type']"
"with level between 5 and 10, which catalog structure has the name.","catalog_structure.loc[(catalog_structure['catalog_level_number'] >= 5) & (catalog_structure['catalog_level_number'] <= 10), ['catalog_level_name', 'catalog_level_number']]"
the catalog level name with level number between 5 and 10 is.,"catalog_structure.loc[(catalog_structure['catalog_level_number'] >= 5) & (catalog_structure['catalog_level_number'] <= 10), ['catalog_level_name', 'catalog_level_number']]"
"which publishers have names containing ""murray""?","catalogs.loc[catalogs['catalog_publisher'].str.contains('murray', case=false), 'catalog_publisher'].unique()"
which catalog publishers have substring 'murray' in their names?,"catalogs.loc[catalogs['catalog_publisher'].str.contains('murray', case=false), 'catalog_publisher'].unique()"
it has the most catalogs with which catalog publisher?,catalogs.groupby('catalog_publisher').size().sort_values(ascending=false).index[0]
"catalogs that have catalog level number greater than 5, their names and publication dates are.","pd.merge(catalogs, catalog_structure, on='catalog_id').loc[lambda x: x['catalog_level_number'] > 5, ['catalog_name', 'date_of_publication']]"
the catalogs with catalog level number above 5 were published on whose names and in what year?,"pd.merge(catalogs, catalog_structure, on='catalog_id').loc[lambda x: x['catalog_level_number'] > 5, ['catalog_name', 'date_of_publication']]"
most catalog entries have the attribute of which entry names?,"catalog_contents.merge(catalog_contents_additional_attributes[catalog_contents_additional_attributes['attribute_value'] == catalog_contents_additional_attributes['attribute_value'].value_counts().index[0]], on='catalog_entry_id')['catalog_entry_name']"
"in the catalog, which attributes have the most entries?","catalog_contents.merge(catalog_contents_additional_attributes.query(""attribute_value == @catalog_contents_additional_attributes['attribute_value'].value_counts().index[0]""), on='catalog_entry_id')['catalog_entry_name']"
what is the most amount of money that the most expensive catalog sells?,"catalog_contents.sort_values('price_in_dollars', ascending=false).iloc[0]['catalog_entry_name']"
what is the catalog entry with the highest price in usd.,"catalog_contents.sort_values('price_in_dollars', ascending=false).iloc[0]['catalog_entry_name']"
what is the level name of the cheapest catalog?,"pd.merge(catalog_contents, catalog_structure, on='catalog_level_number').sort_values('price_in_dollars').iloc[0]['catalog_level_name']"
the catalog with the lowest price (in usd) is.,"pd.merge(catalog_contents, catalog_structure, on='catalog_level_number').sort_values('price_in_dollars').iloc[0]['catalog_level_name']"
the average and minimum price (in euro) of all products are.,"catalog_contents['price_in_euros'].agg(['mean', 'min'])"
the average and minimum price (in euro) of the products are.,"catalog_contents['price_in_euros'].agg(['mean', 'min'])"
the product with the highest height is. give me a product catalog entry name.,"catalog_contents.sort_values('height', ascending=false).iloc[0]['catalog_entry_name']"
the highest catalog content height is catalog entry name.,"catalog_contents.sort_values('height', ascending=false).iloc[0]['catalog_entry_name']"
"product names, of the smallest capacity is.",catalog_contents.sort_values('capacity').iloc[0]['catalog_entry_name']
which catalog content has the smallest capacity?,catalog_contents.sort_values('capacity').iloc[0]['catalog_entry_name']
"products whose stock code starts with ""2"" are.","catalog_contents.loc[lambda x: x['product_stock_number'].str.startswith('2'), 'catalog_entry_name']"
"which catalog contents have a product stock number that starts from ""2""?output: catalog entry names for catalog contents with stock numbers that begin with ""2"".","catalog_contents.loc[lambda x: x['product_stock_number'].str.startswith('2'), 'catalog_entry_name']"
catalog entries with level number 8 have names.,"pd.merge(catalog_contents, catalog_contents_additional_attributes, on='catalog_entry_id').loc[lambda x: x['catalog_level_number']=='8', 'catalog_entry_name']"
catalog entries with level number are?,"pd.merge(catalog_contents, catalog_contents_additional_attributes, on='catalog_entry_id').loc[lambda x: x['catalog_level_number']=='8', 'catalog_entry_name']"
the products with length smaller than 3 or height greater than 5 are.,"catalog_contents.loc[(catalog_contents['length'] < 3) | (catalog_contents['width'] > 5), 'catalog_entry_name']"
catalog content lengths below 3 or above 5: content names?,"catalog_contents.loc[(catalog_contents['length'] < 3) | (catalog_contents['width'] > 5), 'catalog_entry_name']"
the attribute definitions with attribute value 0 are .,"pd.merge(attribute_definitions, catalog_contents_additional_attributes.loc[lambda x: x['attribute_value']==0], on='attribute_id')[['attribute_name', 'attribute_id']]"
 attribute definitions whose values are 0 are.  attribute id is and attribute name is. ,"pd.merge(attribute_definitions, catalog_contents_additional_attributes.loc[lambda x: x['attribute_value']==0], on='attribute_id')[['attribute_name', 'attribute_id']]"
which products have a price greater than 700 usd?,"catalog_contents.loc[lambda x: x['price_in_dollars']>700, ['catalog_entry_name', 'capacity']]"
catalog contents with price above 700 dollars are. show their catalog entry names and capacities.,"catalog_contents.loc[lambda x: x['price_in_dollars']>700, ['catalog_entry_name', 'capacity']]"
many revisions were entered on.,catalogs.groupby('date_of_latest_revision').filter(lambda x: len(x) > 1)['date_of_latest_revision'].unique()
how many days have more than one revisions on catalogs.,catalogs.groupby('date_of_latest_revision').filter(lambda x: len(x) > 1)['date_of_latest_revision'].unique()
there are __ products in the records.,catalog_contents.shape[0]
how many catalog contents are there? ,catalog_contents.shape[0]
what is the next entry id of products with name?,"catalog_contents.loc[lambda x: x['next_entry_id'] > 8, 'catalog_entry_name']"
which products have the catalog entry names with entry id above 8?,"catalog_contents.loc[lambda x: x['next_entry_id'] > 8, 'catalog_entry_name']"
we have how many aircrafts?,len(aircraft)
name and distance of aircrafts.,"aircraft[['name', 'distance']]"
the name and distance for all airplanes are.,"aircraft[['name', 'distance']]"
which aircraft travel more than 1000 kilometers?,"aircraft.loc[aircraft['distance'] > 1000, 'aid']"
how many aircrafts can cover a distance of more than 1000?,"aircraft.loc[aircraft['distance'] > 1000, 'aid']"
how many aircrafts have a distance of between 1000 and 5000?,"aircraft.loc[aircraft['distance'].between(1000, 5000)].shape[0]"
the count of aircrafts that have a distance between 1000 and 5000 is.,"aircraft.loc[aircraft['distance'].between(1000, 5000)].shape[0]"
name and distance for aircraft with id 12 are.,"aircraft.loc[aircraft['aid']==12, ['name', 'distance']]"
what is the name and distance of the aircraft with id of 12?,"aircraft.loc[aircraft['aid']==12, ['name', 'distance']]"
"the minimum, average, and maximum distance of all aircrafts are.","aircraft['distance'].agg(['min', 'mean', 'max'])"
"across which aircrafts are the minimum, average and maximum distances traveled?","aircraft['distance'].agg(['min', 'mean', 'max'])"
the aircraft with the maximum distance is: id and name.,"aircraft[['aid', 'name']].sort_values('distance', ascending=false).head(1)"
what aircrafts make the top three lowest distances?,aircraft.sort_values('distance').head(3)['name']
what is the length of top 3 shortest aircrafts? list their names.,aircraft.sort_values('distance').head(3)['name']
which aircrafts have distances more than the average?,"aircraft.loc[aircraft['distance'] > aircraft['distance'].mean(), 'name']"
which aircrafts can cover more distances than average?,"aircraft.loc[aircraft['distance'] > aircraft['distance'].mean(), 'name']"
what number of employees do we have?,employee.shape[0]
the number of employees are?,employee.shape[0]
which employee has the largest salary?,"employee[['name', 'salary']].sort_values('salary')"
"employees in order of salary name, where is the salary?","employee[['name', 'salary']].sort_values('salary')"
which employee has a salary of at least 100000?,"employee.loc[lambda x: x['salary'] > 100000, 'eid']"
every employee who has at least a salary of  100000 has an id.,"employee.loc[lambda x: x['salary'] > 100000, 'eid']"
how many employees have a salary between $ 100000 and $ 200000?,employee.loc[(employee['salary']>=100000) & (employee['salary']<=200000)].shape[0]
what is the name of employee with id 242518965 and what is the salary? ,"employee.loc[lambda x: x['eid']==242518965, ['name', 'salary']]"
what is the name of the employee with the id 242518965?,"employee.loc[lambda x: x['eid']==242518965, ['name', 'salary']]"
what is the average and maximum salary of all employees?,"employee['salary'].agg(['mean', 'max'])"
what is the average and the largest salary of all employees?,"employee['salary'].agg(['mean', 'max'])"
an employee with the maximum salary is.,"employee[['eid', 'name']].sort_values('salary', ascending=false).head(1)"
what are the names of employees with three lowest salaries?,employee.sort_values('salary')['name'].head(3)
3 name 'employees' that get paid the least.,employee.sort_values('salary')['name'].head(3)
are there employees whose salary is more than the average?,"employee.loc[lambda x: x['salary'] > employee['salary'].mean(), 'name']"
which employees have a salary higher than average?,"employee.loc[lambda x: x['salary'] > employee['salary'].mean(), 'name']"
the id and salary of mark young are.,"employee.loc[lambda x: x['name']=='mark young', ['eid', 'salary']]"
what is mark young's id and salary?,"employee.loc[lambda x: x['name']=='mark young', ['eid', 'salary']]"
how many flights were made?,len(flight)
what all flight numbers are in the alphabetical order of the departure cities?,"flight[['flno', 'origin', 'destination']].sort_values('origin')"
"what is the number of flights, with their flight numbers, from cities in alphabetical order?","flight[['flno', 'origin', 'destination']].sort_values('origin')"
all flight numbers from los angeles are.,"flight.loc[lambda x: x['origin']=='los angeles', 'flno']"
what is the number of flights that come from los angeles?,"flight.loc[lambda x: x['origin']=='los angeles', 'flno']"
all flights with destination honolulu have their origins.,"flight.loc[lambda x: x['destination'] == 'honolulu', 'origin']"
which origins do all flights heading to honolulu come from?,"flight.loc[lambda x: x['destination'] == 'honolulu', 'origin']"
what is the departure date and arrival date of all flights from los angeles to honolulu?,"flight.loc[(flight['origin'] == 'los angeles') & (flight['destination'] == 'honolulu'), ['departure_date', 'arrival_date']]"
find all flights with more than 2000 distance.,"flight.loc[lambda x: x['distance'] > 2000, 'flno']"
how many flights can travel more than 2000 km?,"flight.loc[lambda x: x['distance'] > 2000, 'flno']"
the average flight price for flights from los angeles to honolulu is.,"flight.loc[(flight['origin']=='los angeles') & (flight['destination']=='honolulu'), 'price'].mean()"
"flights with price higher than 300, show origin and destination.","flight.loc[lambda x: x['price'] > 300, ['origin', 'destination']]"
"for which flights did the price exceed 300, the origin and destination?","flight.loc[lambda x: x['price'] > 300, ['origin', 'destination']]"
the flight with the maximum price is.,"flight[['flno', 'distance', 'price']].sort_values('price', ascending=false).iloc[0, :2]"
the flight number and its distance for the one with the maximum price is.,"flight[['flno', 'distance', 'price']].sort_values('price', ascending=false).iloc[0, :2]"
flight numbers of the three flights with the lowest distances are shown.,flight.sort_values('distance').iloc[:3]['flno']
what is the number of the shortest flights?,flight.sort_values('distance').iloc[:3]['flno']
what is the average distance and average price for flights from los angeles?,"flight.loc[lambda x: x['origin']=='los angeles', ['distance', 'price']].mean()"
the average distance and price for all flights from la is.,"flight.loc[lambda x: x['origin']=='los angeles', ['distance', 'price']].mean()"
how many flights were from each origin?,flight.groupby('origin').size()
how many flights came from each origin?,flight.groupby('origin').size()
"destinations: san francisco, chicago, boston, los angeles, london, paris. san francisco, chicago, boston, los angeles, london, paris. ",flight.groupby('destination').size()
each destination has how many flights and to which destinations?,flight.groupby('destination').size()
which origin has the highest number of flights?,flight.groupby('origin').size().sort_values(ascending=false).index[0]
 what's the most popular place from which most flights come?,flight.groupby('origin').size().sort_values(ascending=false).index[0]
which destination has the fewest flights?,flight.groupby('destination').size().sort_values().index[0]
what is the flight name on flight with number 99?,"pd.merge(flight.loc[lambda x: x['flno'] == 99], aircraft, on='aid')['name']"
on which flight number was the aircraft 'name of aircraft'?,"pd.merge(flight.loc[lambda x: x['flno'] == 99], aircraft, on='aid')['name']"
what are the flight numbers of the aircraft airbus a340-300?,"pd.merge(flight, aircraft, on='aid').loc[lambda x: x['name']=='airbus a340-300', 'flno']"
"the name of the aircraft is 'x', and the aircraft completes flights of y.","flight.merge(aircraft, on='aid').groupby('aid')['name'].agg(['count'])"
aircraft with at least 2 flights are.,"flight.merge(aircraft, on='aid').groupby('aid')['name'].filter(lambda x: len(x) >= 2)"
find the names of all aircrafts with at least 2 flights.,"flight.merge(aircraft, on='aid').groupby('aid')['name'].filter(lambda x: len(x) >= 2)"
how many employees have their certificates?,certificate['eid'].nunique()
how many distinct employees have certificates?,certificate['eid'].nunique()
"for which employees, no certificates do they (do they not) have?",employee[~employee['eid'].isin(certificate['eid'])]['eid']
"which employees do not have certificates, and what are their ids?",employee[~employee['eid'].isin(certificate['eid'])]['eid']
which instruments did john williams have certificates for?,"pd.merge(pd.merge(employee, certificate, on='eid'), aircraft, on='aid').loc[lambda x: x['name']=='john williams', 'name']"
which aircrafts do john williams have certificates to be able to fly?,"pd.merge(pd.merge(employee, certificate, on='eid'), aircraft, on='aid').loc[lambda x: x['name']=='john williams', 'name']"
what are the names of employees who have the certificate of boeing 787?,"pd.merge(pd.merge(employee, certificate, on='eid'), aircraft, on='aid').loc[lambda x: x['name']=='boeing 737-800', 'name']"
employees who have a certificate to fly boeing 737-800 are?,"pd.merge(pd.merge(employee, certificate, on='eid'), aircraft, on='aid').loc[lambda x: x['name']=='boeing 737-800', 'name']"
the names of employees that have certificates on both boeing 737-800 and airbus a340-300 are.,"set(employee.loc[pd.merge(pd.merge(certificate, aircraft.loc[aircraft['name']=='boeing 737-800'], on='aid'), employee, on='eid')['name']].tolist()).intersection(set(employee.loc[pd.merge(pd.merge(certificate, aircraft.loc[aircraft['name']=='airbus a340-300'], on='aid'), employee, on='eid')['name']].tolist()))"
which employees can fly both the boeing 737-800 and the airbus a340-300?,"set(employee.loc[pd.merge(pd.merge(certificate, aircraft.loc[aircraft['name']=='boeing 737-800'], on='aid'), employee, on='eid')['name']].tolist()).intersection(set(employee.loc[pd.merge(pd.merge(certificate, aircraft.loc[aircraft['name']=='airbus a340-300'], on='aid'), employee, on='eid')['name']].tolist()))"
which employees are not certified to fly boeing 737-800s?,"employee[~employee['name'].isin(pd.merge(pd.merge(employee, certificate, on='eid'), aircraft, on='aid').loc[lambda x: x['name']=='boeing 737-800', 'name'])]['name']"
fewest people have its certificate which aircraft?,"pd.merge(certificate, aircraft, on='aid').groupby('aid')['name'].count().idxmax()"
which aircraft have the least amount of people are certified to fly?,"pd.merge(certificate, aircraft, on='aid').groupby('aid')['name'].count().idxmax()"
the name and distance of the airplanes with more than 5000 distance and which at least 5 people have its certificate is.,"pd.merge(certificate, aircraft, on='aid').loc[lambda x: x['distance']>5000].groupby('aid')['name'].first().value_counts().loc[lambda x: x>=5].index.tolist()"
what is the name of every aircraft that can cover a distance of more than 5000 and at least 5 people can fly?,"pd.merge(certificate, aircraft, on='aid').loc[lambda x: x['distance']>5000].groupby('aid')['name'].first().value_counts().loc[lambda x: x>=5].index.tolist()"
the employee who has most aircraft certificates has salary and name.,"employee.merge(certificate, on='eid').groupby(['eid', 'name', 'salary']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'salary']]"
the employee certified to fly the most planes is.,"employee.merge(certificate, on='eid').groupby(['eid', 'name', 'salary']).size().reset_index(name='count').sort_values('count', ascending=false).iloc[0][['name', 'salary']]"
what is the employee's name and salary who has the most number of certificates on aircrafts with distance more than 5000?,"employee.merge(certificate).merge(aircraft).loc[lambda x: x['distance'] > 5000].groupby('eid').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0].name"
which employee earns the most salary and has the most certificates to fly planes more than 5000?,"employee.merge(certificate).merge(aircraft).loc[lambda x: x['distance'] > 5000].groupby('eid').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0].name"
the number of allergy entries are?,allergy_type['allergy'].nunique()
how many types of allergies exist?,allergy_type['allergytype'].nunique()
what are the allergy types?,allergy_type['allergytype'].unique()
how many allergy types should i use?,allergy_type['allergytype'].unique()
all allergies of type food?,"allergy_type.loc[lambda x: x['allergytype']=='food', 'allergy'].unique()"
different food allergies are.,"allergy_type.loc[lambda x: x['allergytype']=='food', 'allergy'].unique()"
what is cat's allergy?,"allergy_type.loc[lambda x: x['allergy']=='cat', 'allergytype']"
what is a cat allergy's allergy type?,"allergy_type.loc[lambda x: x['allergy']=='cat', 'allergytype']"
animal allergies have how many?,(allergy_type['allergytype']=='animal').sum()
how many allergens do you have in each type of allergy?,allergy_type.groupby('allergytype').size().reset_index(name='count')
which allergy type has the most number of allergies?,"allergy_type.groupby('allergytype').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['allergytype']"
what is the most common allergy type?,"allergy_type.groupby('allergytype').size().reset_index(name='count').sort_values('count', ascending=false).iloc[0]['allergytype']"
which allergy type has the least number of allergies?,allergy_type.groupby('allergytype').size().sort_values().index[0]
which allergy type is less common?,allergy_type.groupby('allergytype').size().sort_values().index[0]
list first name and last name for all students.,"student[['fname', 'lname']]"
what are the names of all students?,"student[['fname', 'lname']]"
how many advisors are listed?,student['advisor'].nunique()
what majors do you study?,student['major'].unique()
what different majors are there?,student['major'].unique()
students live in which cities?,student['city_code'].unique()
"list the first names, last names and ages of all female students ","student.loc[student['sex']=='f', ['fname', 'lname', 'age']]"
"all female students whose sex is f are as follows: name, age. ","student.loc[student['sex']=='f', ['fname', 'lname', 'age']]"
show male student ids.,"student.loc[lambda x : x['sex'] == 'm', 'stuid']"
all male students are.,"student.loc[lambda x : x['sex'] == 'm', 'stuid']"
how many students were 18 years old?,(student['age']==18).sum()
"who are older than 20, show all student ids.","student.loc[lambda x: x['age']>20, 'stuid']"
how many students over 20 are students?,"student.loc[lambda x: x['age']>20, 'stuid']"
kim lives in which city?,"student.loc[lambda x: x['lname'] == 'kim', 'city_code']"
the family of kim lives in which city?,"student.loc[lambda x: x['lname'] == 'kim', 'city_code']"
what is the name of student with the id 1004 advisor?,"student.loc[lambda x: x['stuid']==1004, 'advisor']"
student 1004 is advised by which advisor?,"student.loc[lambda x: x['stuid']==1004, 'advisor']"
hkg or chi where do most students live?,((student['city_code'] == 'hkg') | (student['city_code'] == 'chi')).sum()
"in which city do most students live, hkg or chi?",((student['city_code'] == 'hkg') | (student['city_code'] == 'chi')).sum()
show the ages of all students.,"student['age'].agg(['min', 'mean', 'max'])"
"what are the minumum, mean, and maximum age across all students?","student['age'].agg(['min', 'mean', 'max'])"
who does the youngest student have as a last name?,"student.loc[student['age'] == student['age'].min(), 'lname']"
which student's last name is the youngest?,"student.loc[student['age'] == student['age'].min(), 'lname']"
who is the student with the oldest student id?,"student.loc[student['age'] == student['age'].max(), 'stuid']"
which student is the oldest?,"student.loc[student['age'] == student['age'].max(), 'stuid']"
what is the number of majors and their corresponding students?,student.groupby('major').size()
the student's ages are and corresponding number of students are.,student.groupby('age').size().reset_index(name='count')
what is the age of each student and how many students are each age?,student.groupby('age').size().reset_index(name='count')
the average of the male and female students are.,student.groupby('sex')['age'].mean()
what are the average ages of male and female students?,student.groupby('sex')['age'].mean()
city | students ,student.groupby('city_code').size().reset_index(name='count')
which advisors are associated with more students?,student.groupby('advisor').size()
each student has how many advisors?,student.groupby('advisor').size()
which advisor has the most number of students?,student.groupby('advisor').size().sort_values(ascending=false).index[0]
which advisor has the most students?,student.groupby('advisor').size().sort_values(ascending=false).index[0]
how many students are allergic to cats?,"(has_allergy['allergy'] == ""cat"").sum()"
which students are allergic to at least two allergens?,has_allergy.groupby('stuid').filter(lambda x: len(x)>=2)['stuid'].unique()
which students have two allergies or more?,has_allergy.groupby('stuid').filter(lambda x: len(x)>=2)['stuid'].unique()
which students have no allergies?,student[~student['stuid'].isin(has_allergy['stuid'])]['stuid']
which students are not affected by allergies?,student[~student['stuid'].isin(has_allergy['stuid'])]['stuid']
how many female students have milk or egg allergies?  ,"pd.merge(has_allergy, student, on='stuid').loc[lambda x: (x['sex']=='f') & (x['allergy'].isin(['milk', 'eggs']))].shape[0]"
which students are female and allergic to milk or eggs?,"pd.merge(has_allergy, student, on='stuid').loc[lambda x: (x['sex']=='f') & (x['allergy'].isin(['milk', 'eggs']))].shape[0]"
how many students are affected by food allergies?,"pd.merge(has_allergy, allergy_type.loc[lambda x: x['allergytype']=='food'], on='allergy').shape[0]"
how many students are affected by which allergy?,has_allergy.groupby('allergy').size().sort_values(ascending=false).index[0]
which allergies are the most common?,has_allergy.groupby('allergy').size().sort_values(ascending=false).index[0]
show the allergies among the following students:,has_allergy['allergy'].value_counts()
how many students have which allergies?,has_allergy['allergy'].value_counts()
how many students are affected by allergy type?,"has_allergy.merge(allergy_type, left_on='allergy', right_on='allergy').groupby('allergytype').size()"
the student who has allergy to both milk and cat is of age and last name.,"student.loc[lambda x: x['stuid'].isin(has_allergy.query('allergy in [""milk"", ""cat""]').stuid), ['lname', 'age']]"
how old and what foods do students who are allergic to milk and cats?,"student.loc[lambda x: x['stuid'].isin(has_allergy.query('allergy in [""milk"", ""cat""]').stuid), ['lname', 'age']]"
the student with first name lisa has the following allergies and types: and order the result by name of allergies.,"pd.merge(pd.merge(allergy_type, has_allergy, on='allergy'), student.loc[lambda x:x['fname']=='lisa'], on='stuid').sort_values('allergy')[['allergy', 'allergytype']]"
"lisa has allergies named, types and number of them. order them by allergy names.","pd.merge(pd.merge(allergy_type, has_allergy, on='allergy'), student.loc[lambda x:x['fname']=='lisa'], on='stuid').sort_values('allergy')[['allergy', 'allergytype']]"
the student who has allergy to milk but not cat is.,"student.loc[student['stuid'].isin(has_allergy.loc[has_allergy['allergy']=='milk', 'stuid'].values).difference(has_allergy.loc[has_allergy['allergy']=='cat', 'stuid'].values),['fname', 'sex']]"
what are the first name and gender of the students who have allergy to milk but can tolerate cats?,"student.loc[student['stuid'].isin(has_allergy.loc[has_allergy['allergy']=='milk', 'stuid'].values).difference(has_allergy.loc[has_allergy['allergy']=='cat', 'stuid'].values),['fname', 'sex']]"
what is the age average of the students who have allergies with food and animal types?,"student.loc[student['stuid'].isin(has_allergy.merge(allergy_type.query('allergytype==""food""'), on='allergy')['stuid'].interesect(has_allergy.merge(allergy_type.query('allergytype==""animal""'), on='allergy')['stuid']))]['age'].mean()"
how old are students with allergies to food and animal types on average?,"student.loc[student['stuid'].isin(has_allergy.merge(allergy_type.query('allergytype==""food""'), on='allergy')['stuid'].interesect(has_allergy.merge(allergy_type.query('allergytype==""animal""'), on='allergy')['stuid']))]['age'].mean()"
what are the names of students who do not have food type allergies?,"student.loc[~student['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda x: x['allergytype'] == ""food""], on='allergy', how='inner')['stuid']), ['fname', 'lname']]"
each student who is not allergic to any type of food is.,"student.loc[~student['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda x: x['allergytype'] == ""food""], on='allergy', how='inner')['stuid']), ['fname', 'lname']]"
how many male students have some food type allery?,student.loc[lambda x: (x['sex']=='m') & (x['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda x: x['allergytype']=='food'])['stuid']))].shape[0]
what is the number of male students (sex is 'm') allergic to any type of food?,student.loc[lambda x: (x['sex']=='m') & (x['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda x: x['allergytype']=='food'])['stuid']))].shape[0]
what are the different first names and cities of the students who have an allergy to milk or cat?,"pd.merge(student, has_allergy.query('allergy==""milk"" or allergy==""cat""'), on='stuid')[['fname', 'city_code']].drop_duplicates()"
how many students are not allergic to either food or animal when they are older than 18?,"student.loc[lambda x: (x['age'] > 18) & (~x['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda y: (y['allergytype']=='food') | (y['allergytype']=='animal')], on='allergy', how='inner')['stuid']))].shape[0]"
how many students do not have allergy to food type or animal type and are over 18?,"student.loc[lambda x: (x['age'] > 18) & (~x['stuid'].isin(has_allergy.merge(allergy_type.loc[lambda y: (y['allergytype']=='food') | (y['allergytype']=='animal')], on='allergy', how='inner')['stuid']))].shape[0]"
"in this class, which students are not allegry to soy?","student.loc[~student['stuid'].isin(has_allergy.loc[has_allergy['allergy']=='soy', 'stuid']), ['fname', 'major']]"
which students are able to consume soy and what are their first and last names?,"student.loc[~student['stuid'].isin(has_allergy.loc[has_allergy['allergy']=='soy', 'stuid']), ['fname', 'major']]"
below is a list of the top five countries by number of invoices.,invoices.groupby('billing_country').size().sort_values(ascending=false).head(5)
which countries were among the top 8 regarding gross invoice size?,invoices.groupby('billing_country')['total'].sum().sort_values(ascending=false).head(8)
how many invoices are there in the top 8 countries of company xyz by size and what are those sizes?,invoices.groupby('billing_country')['total'].sum().sort_values(ascending=false).head(8)
name of country and number of invoices.,invoices.groupby('billing_country')['total'].mean().sort_values(ascending=false).head(10)
"what is the name of the country and by size, the sum of invoice size?",invoices.groupby('billing_country')['total'].mean().sort_values(ascending=false).head(10)
which 5 customers purchased something most recently?,"customers.merge(invoices, on='customer_id')[['first_name', 'last_name']].sort_values('invoice_date', ascending=false).head(5)"
who are the 5 customers that purchased something most recently?,"customers.merge(invoices, on='customer_id')[['first_name', 'last_name']].sort_values('invoice_date', ascending=false).head(5)"
which customers are the top 10 based on number of orders?,"customers.merge(invoices, left_on='id', right_on='customer_id').groupby(['id','first_name','last_name']).size().reset_index(name='count').sort_values('count', ascending=false)[:10][['first_name', 'last_name', 'count']]"
find the names of top 10 customers by total number of orders and how many orders did they make?,"customers.merge(invoices, left_on='id', right_on='customer_id').groupby(['id','first_name','last_name']).size().reset_index(name='count').sort_values('count', ascending=false)[:10][['first_name', 'last_name', 'count']]"
"top 10 customers by total gross sales. customer name, total gross sales","invoices.merge(customers, left_on='customer_id', right_on='id').groupby(['first_name', 'last_name'], as_index=false)['total'].sum().sort_values('total', ascending=false).head(10)[['first_name', 'last_name', 'total']]"
"who are top 10 customers of company, and what are their first and last names, with sales?","invoices.merge(customers, left_on='customer_id', right_on='id').groupby(['first_name', 'last_name'], as_index=false)['total'].sum().sort_values('total', ascending=false).head(10)[['first_name', 'last_name', 'total']]"
which genres have the most songs of? list genres name and total tracks.,"genres.merge(tracks, left_on='id', right_on='genre_id').groupby('name').size().reset_index(name='count').sort_values(by='count', ascending=false).head(5)"
all the album titles are.,albums['title']
list in ascending order all albums ordered by album title.,albums.sort_values('title')['title']
"alphabetically ascending, what are the titles of all the albums?",albums.sort_values('title')['title']
"alphabetically, list every album whose title starts with a.",albums.loc[lambda x: x['title'].str.startswith('a')].sort_values('title')['title']
"which albums start with a, and what are their names?",albums.loc[lambda x: x['title'].str.startswith('a')].sort_values('title')['title']
"what is the first and last name of 10 customers, whose invoices were the least expensive?","pd.merge(customers, invoices, on='id').sort_values('total')[['first_name', 'last_name']].head(10)"
what are the first and last names of the customers with the cheapest invoices?,"pd.merge(customers, invoices, on='id').sort_values('total')[['first_name', 'last_name']].head(10)"
"total amount of  invoice from chicago, il.","invoices.loc[(invoices['billing_city']=='chicago') & (invoices['billing_state']=='il'), 'total'].sum()"
"the total amount of money in the invoices billed from chicago, illinois is.","invoices.loc[(invoices['billing_city']=='chicago') & (invoices['billing_state']=='il'), 'total'].sum()"
"the invoices from chicago, il are.",invoices[(invoices['billing_city'] == 'chicago') & (invoices['billing_state'] == 'il')].shape[0]
how many invoices were received from states in the us?,"invoices.loc[invoices['billing_country']=='usa', 'billing_state'].value_counts()"
which invoice were billed by which state?,"invoices.loc[invoices['billing_country']=='usa', 'billing_state'].value_counts()"
the state with the most invoices in the us is.,"(invoices.loc[invoices['billing_country']=='usa', :].groupby('billing_state').size().sort_values(ascending=false).head(1).reset_index(name='count')).iloc[0]"
which states sent the most invoices?,"(invoices.loc[invoices['billing_country']=='usa', :].groupby('billing_state').size().sort_values(ascending=false).head(1).reset_index(name='count')).iloc[0]"
how many invoices and the invoice total from california are?,"invoices.loc[invoices['billing_state']=='ca'].agg({'billing_state': 'first', 'total': 'sum', 'billing_state': 'count'})"
from which state did most invoices billed by ca in total money?,"invoices.loc[invoices['billing_state']=='ca'].agg({'billing_state': 'first', 'total': 'sum', 'billing_state': 'count'})"
aerosmith has released how many albums?,"albums.loc[lambda x: x['artist_id'].isin(artists.loc[lambda y: y['name']=='aerosmith', 'id']), 'title']"
what titles did aerosmith release?,"albums.loc[lambda x: x['artist_id'].isin(artists.loc[lambda y: y['name']=='aerosmith', 'id']), 'title']"
how many albums has billy cobham?,"pd.merge(albums, artists, left_on='artist_id', right_on='id').loc[lambda x: x['name']=='billy cobham'].shape[0]"
eduardo martins is a client at which company?,"customers.loc[(customers['first_name'] == 'eduardo') & (customers['last_name'] == 'martins'), 'company']"
eduardo martins is a customer of which company?,"customers.loc[(customers['first_name'] == 'eduardo') & (customers['last_name'] == 'martins'), 'company']"
what is the email and phone number of astrid gruber?,"customers.loc[(customers['first_name']=='astrid') & (customers['last_name']=='gruber'), ['email', 'phone']]"
the email and phone number of astrid gruber the customer are.,"customers.loc[(customers['first_name']=='astrid') & (customers['last_name']=='gruber'), ['email', 'phone']]"
how many customers live in prague?,(customers['city'] == 'prague').sum()
how many customers in the state of california?,(customers['state'] == 'ca').sum()
roberto almeida lives in which country?,"customers.loc[(customers['first_name'] == 'roberto') & (customers['last_name'] == 'almeida'), 'country']"
which country is roberto almeida from?,"customers.loc[(customers['first_name'] == 'roberto') & (customers['last_name'] == 'almeida'), 'country']"
which albums were released by an artist whose name has 'led',"pd.merge(artists.loc[lambda x: x['name'].str.contains('led', case=false)], albums, on='artist_id')['title']"
what album did the artist whose name has the phrase 'led' release?,"pd.merge(artists.loc[lambda x: x['name'].str.contains('led', case=false)], albums, on='artist_id')['title']"
steve johnson supports how many customers?,"employees.merge(customers, left_on='id', right_on='support_rep_id').query('first_name == ""steve"" and last_name == ""johnson""').shape[0]"
what is the title of the hire date of nancy edwards?,"employees.loc[(employees['first_name'] == 'nancy') & (employees['last_name'] == 'edwards'), ['title', 'phone', 'hire_date']]"
"nancy edwards got which title, phone number and hire date?","employees.loc[(employees['first_name'] == 'nancy') & (employees['last_name'] == 'edwards'), ['title', 'phone', 'hire_date']]"
who are nancy edwards' employees who report to her?,"employees.merge(employees[['id', 'first_name', 'last_name']].rename(columns={'id': 'reports_to'}), on='reports_to',suffixes=('', '_manager')).query('first_name_manager == ""nancy"" & last_name_manager == ""edwards""')[['first_name', 'last_name']]"
"which employee reports to nancy edwards, and what is his/her first and last name?","employees.merge(employees[['id', 'first_name', 'last_name']].rename(columns={'id': 'reports_to'}), on='reports_to',suffixes=('', '_manager')).query('first_name_manager == ""nancy"" & last_name_manager == ""edwards""')[['first_name', 'last_name']]"
what is the address of nancy edwards?,"employees.loc[(employees['first_name'] == 'nancy') & (employees['last_name'] == 'edwards'), 'address']"
nancy edwards's address is.,"employees.loc[(employees['first_name'] == 'nancy') & (employees['last_name'] == 'edwards'), 'address']"
the employee who supported the highest number of customers is.,"pd.merge(employees, customers, left_on='id', right_on='support_rep_id').groupby(['id', 'first_name', 'last_name']).size().reset_index(name='counts').sort_values('counts', ascending=false).iloc[0][['first_name', 'last_name']]"
who owns the most customers?,"pd.merge(employees, customers, left_on='id', right_on='support_rep_id').groupby(['id', 'first_name', 'last_name']).size().reset_index(name='counts').sort_values('counts', ascending=false).iloc[0][['first_name', 'last_name']]"
how many employees are living in canada? ,(employees['country'] == 'canada').sum()
nancy edwards's phone number is.,"employees.loc[(employees['first_name']=='nancy') & (employees['last_name']=='edwards'), 'phone']"
nancy edwards' phone number is.,"employees.loc[(employees['first_name']=='nancy') & (employees['last_name']=='edwards'), 'phone']"
who is the youngest employee in the company?,"employees.sort_values('birth_date', ascending=false).iloc[:1, ['first_name', 'last_name']]"
what is the name of the youngest employee?,"employees.sort_values('birth_date', ascending=false).iloc[:1, ['first_name', 'last_name']]"
the employee work longest in the company are:.,"employees[['first_name', 'last_name']].sort_values('hire_date').head(10)"
which surnames do the top 10 employees have?,"employees[['first_name', 'last_name']].sort_values('hire_date').head(10)"
"it staff in each city, how many employees have?",employees.loc[lambda x: x['title']=='it staff'].groupby('city').size().reset_index(name='count(*)')
how many it staff are from each city?,employees.loc[lambda x: x['title']=='it staff'].groupby('city').size().reset_index(name='count(*)')
"which employee manages most number of peoples? list employee's first and last name, and number of people report to that employee.","employees.merge(employees, left_on='reports_to', right_on='id', suffixes=('', '_manager')).groupby(by=['id_manager', 'first_name_manager', 'last_name_manager']).size().reset_index(name='count_reports_to').sort_values(by='count_reports_to', ascending=false).head(1)[['first_name_manager', 'last_name_manager', 'count_reports_to']]"
"who reports to how many people, and what are their first and last names?","employees.merge(employees, left_on='reports_to', right_on='id', suffixes=('', '_manager')).groupby(by=['id_manager', 'first_name_manager', 'last_name_manager']).size().reset_index(name='count_reports_to').sort_values(by='count_reports_to', ascending=false).head(1)[['first_name_manager', 'last_name_manager', 'count_reports_to']]"
invoices luca mancini has how many orders? ,"pd.merge(customers.loc[lambda x: (x['first_name']=='lucas') & (x['last_name']=='mancini')], invoices, on='customer_id').shape[0]"
the total amount of money spent by lucas mancini is what?,"pd.merge(customers[customers['first_name']=='lucas'][customers['last_name']=='mancini'], invoices, on='customer_id')['total'].sum()"
name all the media types.,media_types['name']
what are the different genre types?,genres['name'].unique()
what are the genres called?,genres['name'].unique()
list of all playlists.,playlists['name']
in which year was the track 'fast as a shark' created by which composer?,"tracks.loc[lambda x: x['name'] == 'fast as a shark', 'composer']"
what is the total duration of track fast as a shark has?,"tracks.loc[lambda x: x['name'] == 'fast as a shark', 'milliseconds']"
fast as a shark took how many milliseconds?,"tracks.loc[lambda x: x['name'] == 'fast as a shark', 'milliseconds']"
what is the genre of the tracks named rock?,"tracks.merge(genres, left_on='genre_id', right_on='id').loc[lambda x: x['name']=='rock', 'name_y']"
what is the title of the album to which the track balls to the wall belongs?,"albums.loc[lambda x: x['id'].isin(tracks.loc[lambda y: y['name']=='balls to the wall', 'genre_id']), 'title']"
which album cover holds the song ball to the wall?,"albums.loc[lambda x: x['id'].isin(tracks.loc[lambda y: y['name']=='balls to the wall', 'genre_id']), 'title']"
balls to the wall contains the following tracks:,"pd.merge(albums.loc[lambda x: x['title']=='balls to the wall'], tracks, left_on='id', right_on='genre_id')['name']"
balls to the wall is the name of all tracks on the album.,"pd.merge(albums.loc[lambda x: x['title']=='balls to the wall'], tracks, left_on='id', right_on='genre_id')['name']"
"the album has more than 10 tracks, what title is it?","albums.merge(tracks, on='album_id').groupby('id').filter(lambda x: len(x) > 10)['title']"
which tracks belong to genre 'rock' and whose media type is mpeg audio file?,"pd.merge(pd.merge(genres[genres['name']=='rock'], tracks, on='genre_id'), media_types[media_types['name']=='mpeg audio file'], on='media_type_id')['name']"
which rock tracks are on mpeg audio files?,"pd.merge(pd.merge(genres[genres['name']=='rock'], tracks, on='genre_id'), media_types[media_types['name']=='mpeg audio file'], on='media_type_id')['name']"
which tracks belong to genre rock or media type is mpeg audio file?,"pd.merge(pd.merge(genres.loc[genres['name']==""rock""], tracks, on='genre_id'), media_types.loc[media_types['name']=='mpeg audio file'], on='media_type_id')['name']"
which tracks belong to the rock genre and which ones are mpeg?,"pd.merge(pd.merge(genres.loc[genres['name']==""rock""], tracks, on='genre_id'), media_types.loc[media_types['name']=='mpeg audio file'], on='media_type_id')['name']"
the track belongs to which genre?,"pd.merge(genres.loc[lambda x: x['name'].isin(['rock', 'jazz'])], tracks, on='genre_id')['name_y']"
the songs that were rock or jazz songs were.,"pd.merge(genres.loc[lambda x: x['name'].isin(['rock', 'jazz'])], tracks, on='genre_id')['name_y']"
the movies have which tracks in their playlists?,"pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='movies', 'name']"
there are all songs that are on playlists titled movies.  ,"pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='movies', 'name']"
what is the number of tracks that playlist has? what does playlist?,"pd.merge(playlist_tracks, playlists, on='id').groupby('playlist_id').filter(lambda x: x['track_id'].count() > 100)['name']"
which playlist has a large number of tracks?,"pd.merge(playlist_tracks, playlists, on='id').groupby('playlist_id').filter(lambda x: x['track_id'].count() > 100)['name']"
which tracks were bought by customer daan peeters?,"tracks.merge(invoice_lines, left_on='id', right_on='track_id').merge(invoices, on='invoice_id').merge(customers, on='customer_id').loc[(customers['first_name']=='daan') & (customers['last_name']=='peeters'), 'name']"
which tracks did dean peeters buy?,"tracks.merge(invoice_lines, left_on='id', right_on='track_id').merge(invoices, on='invoice_id').merge(customers, on='customer_id').loc[(customers['first_name']=='daan') & (customers['last_name']=='peeters'), 'name']"
how much is the tune fast as a shark?,"tracks.loc[lambda x: x['name']=='fast as a shark', 'unit_price']"
which tracks are in movies playlist but not in music playlist?,"set(tracks.merge(playlist_tracks, left_on='id', right_on='track_id').merge(playlists, left_on='playlist_id', right_on='id').loc[lambda x: x['name']=='movies', 'name']).difference(tracks.merge(playlist_tracks, left_on='id', right_on='track_id').merge(playlists, left_on='playlist_id', right_on='id').loc[lambda x: x['name']=='music', 'name'])"
which movies tracks are not in the music playlist?,"set(tracks.merge(playlist_tracks, left_on='id', right_on='track_id').merge(playlists, left_on='playlist_id', right_on='id').loc[lambda x: x['name']=='movies', 'name']).difference(tracks.merge(playlist_tracks, left_on='id', right_on='track_id').merge(playlists, left_on='playlist_id', right_on='id').loc[lambda x: x['name']=='music', 'name'])"
how many tracks are in movies and music playlists?,"pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='movies', 'name'].isin(pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='music', 'name']).unique()"
what are the names of all tracks that are in both the movies and music playlists?,"pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='movies', 'name'].isin(pd.merge(pd.merge(tracks, playlist_tracks, on='id'), playlists, on='id').loc[lambda x: x['name']=='music', 'name']).unique()"
how many tracks are in each type of genre?,"pd.merge(genres, tracks, on='genre_id').groupby('name').size().reset_index(name='count')"
the number of tracks in each genre are.,"pd.merge(genres, tracks, on='genre_id').groupby('name').size().reset_index(name='count')"
the editors ages are:,editor.sort_values('age')['name']
who are the ages of editors?,"editor[['name', 'age']]"
editors who are older than 25 are:,"editor.loc[lambda x: x['age'] > 25, 'name']"
"either 24 or 25, show the names of editors.","editor.loc[lambda x: x['age'].isin([24, 25]), 'name']"
some editors are.,editor.groupby('age').size().reset_index(name='count')
the most common age of editors is.,editor.groupby('age').size().sort_values(ascending=false).index[0]
the distinct themes of journals are.,journal['theme'].unique()
they serve on committees as editors for which journals and themes?,"pd.merge(pd.merge(journal_committee, editor, on='editor_id'), journal, on='journal_id')[['name', 'theme']]"
"for each journal committee, find the editor name and the journal theme.","pd.merge(pd.merge(journal_committee, editor, on='editor_id'), journal, on='journal_id')[['name', 'theme']]"
"editors serve on committees for which journals, in ascending alphabetical order of theme, and (in parenthesis) their ages?","pd.merge(pd.merge(journal_committee, editor, on='editor_id'), journal, on='journal_id').sort_values('theme')[['name', 'age', 'theme']]"
which editors are on the committee of journals with sales bigger than 3000?,"pd.merge(pd.merge(journal_committee, editor, on='editor_id'), journal, on='journal_id').loc[lambda x: x['sales'] > 3000, 'name']"
which editors serve on how many journal committees?,"editor.merge(journal_committee, on='editor_id').groupby(['editor_id', 'name']).size().reset_index(name='count')"
how many editors are on at least two journal committees?,"pd.merge(editor, journal_committee, on='editor_id').groupby('name').filter(lambda x: len(x) >= 2)['name']"
which journals do not have editors on any journal committee?,"editor.loc[~editor['editor_id'].isin(journal_committee['editor_id']), 'name']"
the two journals which did not have any of the listed editors serving on committee were.,"journal[~journal.merge(journal_committee, on='journal_id').set_index(['date', 'theme', 'sales']).index.isin(journal.set_index(['date', 'theme', 'sales']).index)]"
the average sales of the journals that have an editor whose work type is 'photo' are.,"journal_committee[journal_committee['work_type'] == 'photo'].merge(journal, on='journal_id')['sales'].mean()"
"ids, customer ids, names for all accounts are.","accounts[['account_id', 'customer_id', 'account_name']]"
"which account ids, customer ids, and account names for all the accounts?","accounts[['account_id', 'customer_id', 'account_name']]"
show account details for account with the id 338.,"accounts.loc[lambda x: x['account_name']=='338', 'other_account_details']"
"the customer with account name 162 has the first name, last name, and phone.","pd.merge(accounts.loc[lambda x: x['account_name']=='162'], customers, on='customer_id')[['customer_first_name', 'customer_last_name', 'customer_phone']]"
the customer with the account name 162 has the full name and phone.,"pd.merge(accounts.loc[lambda x: x['account_name']=='162'], customers, on='customer_id')[['customer_first_name', 'customer_last_name', 'customer_phone']]"
which customer has an account with first name art and last name turcotte?,"pd.merge(accounts, customers).loc[lambda x: (x['customer_first_name']=='art') & (x['customer_last_name']=='turcotte'), :].shape[0]"
the account number of the customer with first name art and last name turcotte is.,"pd.merge(accounts, customers).loc[lambda x: (x['customer_first_name']=='art') & (x['customer_last_name']=='turcotte'), :].shape[0]"
customer ids and the number of accounts for each.,accounts.groupby('customer_id').size().reset_index(name='count')
"for each customer id, how many accounts are there?",accounts.groupby('customer_id').size().reset_index(name='count')
the customer with the most accounts is. this person has.,"accounts.groupby('customer_id').size().nlargest(1).reset_index(name='count').loc[0, ['customer_id', 'count']]"
what is the customer with the fewest number of accounts?,"pd.merge(accounts, customers, on='customer_id').groupby('customer_id').agg({'customer_first_name': 'first', 'customer_last_name': 'first', 'customer_id': 'count'}).sort_values('customer_id').iloc[0][['customer_first_name', 'customer_last_name', 'customer_id']]"
the customer with the fewest accounts is.,"pd.merge(accounts, customers, on='customer_id').groupby('customer_id').agg({'customer_first_name': 'first', 'customer_last_name': 'first', 'customer_id': 'count'}).sort_values('customer_id').iloc[0][['customer_first_name', 'customer_last_name', 'customer_id']]"
there are how many customers without an account?,customers['customer_id'].isin(accounts['customer_id']).value_counts()[false]
which customers do not have an account?,customers['customer_id'].isin(accounts['customer_id']).value_counts()[false]
show the first names and last names of customers without an account.,"customers.loc[~customers['customer_id'].isin(accounts['customer_id']), ['customer_first_name', 'customer_last_name']]"
which customers do not have any accounts?,"customers.loc[~customers['customer_id'].isin(accounts['customer_id']), ['customer_first_name', 'customer_last_name']]"
"which customers have accounts, and what are their full names?","pd.merge(customers, accounts, on='customer_id')[['customer_first_name', 'customer_last_name']].drop_duplicates()"
how many customers have accounts? ,accounts['customer_id'].nunique()
count how many customers have an account.,accounts['customer_id'].nunique()
we have how many customers?,customers.shape[0]
what is the number of customers?,customers.shape[0]
"list ids, first names, last names, and phones for all customers.","customers[['customer_id', 'customer_first_name', 'customer_last_name', 'customer_phone']]"
"the customers' id, full name and phone.","customers[['customer_id', 'customer_first_name', 'customer_last_name', 'customer_phone']]"
"aniyah feest, email address and phone number?","customers.loc[(customers['customer_first_name'] == 'aniyah') & (customers['customer_last_name'] == 'feest'), ['customer_phone', 'customer_email']]"
aniyah feest has a phone and email?,"customers.loc[(customers['customer_first_name'] == 'aniyah') & (customers['customer_last_name'] == 'feest'), ['customer_phone', 'customer_email']]"
"which customer cards have which card ids, customer ids, card types, and card numbers?","customers_cards[['card_id', 'customer_id', 'card_type_code', 'card_number']]"
the card with card number '4560596484842' is valid from 20/6/2010 until 20/6/2020. ,"customers_cards.loc[lambda x: x['card_number']=='4560596484842', ['date_valid_from', 'date_valid_to']]"
for which dates are valid from and valid to dates for the card with the number 4560596484842?,"customers_cards.loc[lambda x: x['card_number']=='4560596484842', ['date_valid_from', 'date_valid_to']]"
"the customer who has card number 4560596484842, their full name and phone is.","pd.merge(customers_cards, customers, on='customer_id').loc[lambda x: x['card_number']=='4560596484842', ['customer_first_name', 'customer_last_name', 'customer_phone']]"
the customer with the name art and last name turcotte has. ,"pd.merge(customers_cards, customers.loc[(customers['customer_first_name']=='art') & (customers['customer_last_name']=='turcotte')], on='customer_id')['customer_id'].count()"
blanche heuls has how many credit cards?,"pd.merge(customers_cards, customers, on='customer_id').loc[(customers['customer_first_name']=='blanche') & (customers['customer_last_name']=='huels') & (customers_cards['card_type_code']=='credit'),:].shape[0]"
blanche huels has how many credit cards?,"pd.merge(customers_cards, customers, on='customer_id').loc[(customers['customer_first_name']=='blanche') & (customers['customer_last_name']=='huels') & (customers_cards['card_type_code']=='credit'),:].shape[0]"
each customer owns how many cards?,customers_cards.groupby('customer_id').size().reset_index(name='count')
"how many cards does each one hold, and what are the different customer ids?",customers_cards.groupby('customer_id').size().reset_index(name='count')
"the customer with most number of cards has, and he has.",customers_cards.groupby('customer_id').size().idxmax()
"id of customer who has the most cards is, as well as number of the cards.",customers_cards.groupby('customer_id').size().idxmax()
"show id, first and last names for all customers with two cards.","pd.merge(customers_cards, customers, on='customer_id').groupby('customer_id').filter(lambda x: len(x) >= 2)[['customer_id', 'customer_first_name', 'customer_last_name']].drop_duplicates('customer_id')"
which customers hold two or more cards?,"pd.merge(customers_cards, customers, on='customer_id').groupby('customer_id').filter(lambda x: len(x) >= 2)[['customer_id', 'customer_first_name', 'customer_last_name']].drop_duplicates('customer_id')"
"what customer id, first and last name have fewer accounts?","pd.merge(customers_cards, customers, on='customer_id').groupby('customer_id').agg({'customer_first_name': 'first', 'customer_last_name': 'first'}).sort_values(by='count').head(1)"
what is the id and full name of customer who has the fewest accounts?,"pd.merge(customers_cards, customers, on='customer_id').groupby('customer_id').agg({'customer_first_name': 'first', 'customer_last_name': 'first'}).sort_values(by='count').head(1)"
the number of cards in each card type is.,customers_cards.groupby('card_type_code').size().reset_index(name='count')
what is the card type code that has most cards?,customers_cards.groupby('card_type_code').size().sort_values(ascending=false).index[0]
the most common card type is.,customers_cards.groupby('card_type_code').size().sort_values(ascending=false).index[0]
which card type codes have 5 or more cards?,customers_cards.groupby('card_type_code').filter(lambda x: len(x) >= 5)['card_type_code'].unique()
the number of customers holding each card type is.,customers_cards.groupby('card_type_code')['customer_id'].nunique()
"how many different card type codes are there in total, and how many customers hold each type?",customers_cards.groupby('card_type_code')['customer_id'].nunique()
which customers do not have a credit card?,"customers[['customer_id', 'customer_first_name']].merge(customers_cards[lambda x: x['card_type_code'] == 'credit'][['customer_id']],how='left',on='customer_id',indicator=true).query(""_merge == 'left_only'"").drop('_merge', axis=1)"
"which customers do not have credit cards, and what are their first names and ids?","customers[['customer_id', 'customer_first_name']].merge(customers_cards[lambda x: x['card_type_code'] == 'credit'][['customer_id']],how='left',on='customer_id',indicator=true).query(""_merge == 'left_only'"").drop('_merge', axis=1)"
which card type codes are:,customers_cards['card_type_code'].unique()
what are different card type codes?,customers_cards['card_type_code'].unique()
how many card types does alibaba store?,customers_cards['card_type_code'].nunique()
what are the transaction types?,financial_transactions['transaction_type'].unique()
what types of transactions exist?,financial_transactions['transaction_type'].unique()
how many transaction types exist?,financial_transactions['transaction_type'].nunique()
how many different types of transactions are there? ,financial_transactions['transaction_type'].nunique()
the average and total transaction amount are.,"financial_transactions['transaction_amount'].agg(['mean', 'sum'])"
"on average, the transaction amount is 01. the total amount of all transactions is . ","financial_transactions['transaction_amount'].agg(['mean', 'sum'])"
card type codes and the number of transactions are.,"pd.merge(financial_transactions, customers_cards, on='card_id').groupby('card_type_code').size()"
how many transactions have been made with each card type?,"pd.merge(financial_transactions, customers_cards, on='card_id').groupby('card_type_code').size()"
the transaction type and the number of transactions are shown.,financial_transactions.groupby('transaction_type').size().reset_index(name='count')
the number of transactions of each transaction type is.,financial_transactions.groupby('transaction_type').size().reset_index(name='count')
which transaction type has processed the greatest total amount in transactions?,financial_transactions.groupby('transaction_type').sum()['transaction_amount'].sort_values(ascending=false).index[0]
"for each account, show the account id and the number of transactions.",financial_transactions.groupby('account_id').size().reset_index(name='count')
"what different user accounts have made financial transactions, and what are the details of the transactions?",financial_transactions.groupby('account_id').size().reset_index(name='count')
how many tracks are there?,track.shape[0]
name and location for all tracks.,"track[['name', 'location']]"
"what tracks do we know, where are they, and what is their names and locations?","track[['name', 'location']]"
"show names and seatings, ordered by seating, for all tracks opened after 2000.","track.loc[lambda x: x['year_opened']>2000, ['name', 'seating']].sort_values('seating')"
the names of tracks opened after 2000 and seatings are as follows:seating | name ,"track.loc[lambda x: x['year_opened']>2000, ['name', 'seating']].sort_values('seating')"
"what is the name of the most recently opened track, its location and its seating?","track.sort_values('year_opened', ascending=false).iloc[0][['name', 'location', 'seating']]"
what is the name and location of the track that was opened most recently?,"track.sort_values('year_opened', ascending=false).iloc[0][['name', 'location', 'seating']]"
"what is the minimum and maximum seating for all tracks, and what is their average value? ","track['seating'].agg(['min', 'max', 'mean'])"
under which conditions was the average seating calculated?,"track['seating'].agg(['min', 'max', 'mean'])"
"name, location and open year for all tracks with a seating higher than the average. ","track.loc[lambda x: x['seating'] > track['seating'].mean(), ['name', 'location', 'year_opened']]"
"what tracks have seating higher than average, and what are their names, locations, and years of opening?","track.loc[lambda x: x['seating'] > track['seating'].mean(), ['name', 'location', 'year_opened']]"
distinct locations where tracks are located are.,track['location'].unique()
give the positions of tracks.,track['location'].unique()
how many races are. ,race.shape[0]
how many races are?,race.shape[0]
there can be distinct classes that races can have.,race['class'].unique()
which classes of races are?,race['class'].unique()
"all races have name, class, and date.","race[['name', 'class', 'date']]"
"what is the name of the race, class, and date for all races?","race[['name', 'class', 'date']]"
the race class and the number of races in each class is.,race.groupby('class').size().reset_index(name='count')
how many races correspond to each different class of race?,race.groupby('class').size().reset_index(name='count')
which race class has the most races?,race.groupby('class').size().sort_values(ascending=false).index[0]
the most common class of race is.,race.groupby('class').size().sort_values(ascending=false).index[0]
there are two races in the races class.,race.groupby('class').filter(lambda x: len(x) >= 2)['class'].drop_duplicates()
there are two or more races that correspond to which classes?,race.groupby('class').filter(lambda x: len(x) >= 2)['class'].drop_duplicates()
how many races are not in class 'gt'?,"track.loc[~track['name'].isin(race.loc[race['class']=='gt', 'name'])]['name']"
which tracks do not have a race in the class 'gt'?,"track.loc[~track['name'].isin(race.loc[race['class']=='gt', 'name'])]['name']"
which tracks have not had races?,"track.loc[~track['track_id'].isin(race['track_id']), 'name']"
which tracks have not been used for any races?,"track.loc[~track['track_id'].isin(race['track_id']), 'name']"
the track with at least 5000 seats opened in the year. and the track with no more than 4000 seats opened in the year.,"track.loc[lambda x: (x['seating'] >= 4000) & (x['seating'] <= 5000), 'year_opened']"
"for tracks with seating between 4000 and 5000, what years were their openings?","track.loc[lambda x: (x['seating'] >= 4000) & (x['seating'] <= 5000), 'year_opened']"
"each track has how many races, and which name?","race.merge(track, on='track_id').groupby('name').size()"
which tracks and what races did each track have?,"race.merge(track, on='track_id').groupby('name').size()"
most races were in which track?,"pd.merge(race, track, on='track_id').groupby('track_id')['name'].agg(['count']).sort_values('count', ascending=false).iloc[:1]['name']"
which track has had the largest number of races?,"pd.merge(race, track, on='track_id').groupby('track_id')['name'].agg(['count']).sort_values('count', ascending=false).iloc[:1]['name']"
here are the names and dates for each race and its track name.,"pd.merge(race, track, on='track_id')[['name_x', 'date', 'name_y']]"
"which races, which dates, and which tracks are they?","pd.merge(race, track, on='track_id')[['name_x', 'date', 'name_y']]"
what is the name of the track with 1 race? where is it located?,"pd.merge(race, track, on='track_id').groupby(['track_id', 'name', 'location']).size().reset_index(name='count').loc[lambda x: x['count']==1, ['name', 'location']]"
how many tracks and locations had exactly 1 race?,"pd.merge(race, track, on='track_id').groupby(['track_id', 'name', 'location']).size().reset_index(name='count').loc[lambda x: x['count']==1, ['name', 'location']]"
what are some locations that both have many seats and many tracks.,"pd.merge(track.loc[lambda x: x['seating'] > 90000, 'location'].to_frame(),track.loc[lambda x: x['seating'] < 70000, 'location'].to_frame(),on='location')['location']"
"where do tracks with more than 90000 seats, and tracks with fewer than 70000 seats, both exist?","pd.merge(track.loc[lambda x: x['seating'] > 90000, 'location'].to_frame(),track.loc[lambda x: x['seating'] < 70000, 'location'].to_frame(),on='location')['location']"
how many members use the black membership card? ,(member['membership_card'] == 'black').sum()
which members live in each address?,member.groupby('address').size().reset_index(name='count')
which members' addresses are in harford or waterbury?,"member.loc[lambda x: x['address'].isin(['harford', 'waterbury']), 'name']"
"under age 30 or black membership card, the ids and names of members are.","member.loc[(member['membership_card']=='black') | (member['age']<30), ['name', 'member_id']]"
"find, in the order that they were purchased, the purchase time, age and address of each member.","member[['time_of_purchase', 'age', 'address']].sort_values('time_of_purchase')"
a member who is younger than 30 and a member who is older than 40 have which address?,"pd.merge(member.loc[lambda x: x['age']<30, 'address'], member.loc[lambda x: x['age']>40, 'address'])"
a membership card is held by both members living in hartford and ones living in waterbury address. ,"pd.merge(member.loc[lambda x: x['address']=='hartford', 'membership_card'], member.loc[lambda x: x['address']=='waterbury', 'membership_card'], how='inner')"
what members do not live in hartford?,(member['address'] != 'hartford').sum()
which address does not have any member with the black membership card?,"member.loc[~(member['membership_card'] == 'black'), 'address']"
"open from the earliest to the most recent, these are:2014,2015,2016,2017,2018",shop.sort_values('open_year')['address']
the average score and average staff number of all shops are.,"shop[['num_of_staff', 'score']].mean()"
the identifiers and address of the shops whose score is below the average score are.,"shop.loc[lambda x: x['score'] < x['score'].mean(), ['shop_id', 'address']]"
"which shops have no happy hours, and what their addresses and staff numbers are?","shop.loc[~shop['shop_id'].isin(happy_hour['shop_id']), ['address', 'num_of_staff']]"
which shops have a happy hour in may and what are the id and address of these shops?,"pd.merge(shop, happy_hour, on='shop_id').loc[lambda x: x['month']=='may', ['address', 'shop_id']]"
which shop has happy hour most frequently? list its id and number of happy hours.,happy_hour.groupby('shop_id').size().sort_values(ascending=false).iloc[[0]]
february has the most happy hours?,happy_hour['month'].value_counts().index[0]
all music genres are:,genre['name']
in which states do customers live?,"customer.loc[lambda x: x['state']=='ny', :]"
what is all the customer information for customers in the state of new york?,"customer.loc[lambda x: x['state']=='ny', :]"
"which employees do live in calgary, their first and last names","employee.loc[lambda x: x['city']=='calgary', ['firstname', 'lastname']]"
all the employees living in the city of calgary are.,"employee.loc[lambda x: x['city']=='calgary', ['firstname', 'lastname']]"
"invoices, what are the distinct billing countries?",invoice['billingcountry'].unique()
find the number of differences of billing countries for all invoices. ,invoice['billingcountry'].unique()
"which artists have ""a"" in their names?","artist.loc[artist['name'].str.contains('a', case=false), 'name']"
who have the letters 'a' in their names?,"artist.loc[artist['name'].str.contains('a', case=false), 'name']"
"the title of all the albums of the artist ""ac/dc"" is.","pd.merge(album, artist, on='artistid').loc[lambda x: x['name']=='ac/dc', 'title']"
"what titles did ""ac/dc"" have on albums?","pd.merge(album, artist, on='artistid').loc[lambda x: x['name']=='ac/dc', 'title']"
"how many albums does the artist ""metallica"" have?","pd.merge(album, artist, on='artistid').loc[lambda x: x['name']=='metallica'].shape[0]"
"how many albums by the artist ""metallica""?","pd.merge(album, artist, on='artistid').loc[lambda x: x['name']=='metallica'].shape[0]"
which artist does the album 'balls to the wall' belong to?,"pd.merge(album, artist, on='artistid').loc[lambda x: x['title']=='balls to the wall', 'name']"
"the artist who made the album ""balls to the wall"" is_______.","pd.merge(album, artist, on='artistid').loc[lambda x: x['title']=='balls to the wall', 'name']"
how many albums does each artist have?,"pd.merge(album, artist, on='artistid').groupby('name').size().idxmax()"
who has the greatest number of albums?,"pd.merge(album, artist, on='artistid').groupby('name').size().idxmax()"
"which tracks contain the word ""you""?","track.loc[lambda x: x['name'].str.contains('you'), 'name']"
which tracks contain the word you in them? ,"track.loc[lambda x: x['name'].str.contains('you'), 'name']"
what is the average price for one track ?,track['unitprice'].mean()
what is the duration of the longest track?,"track['milliseconds'].agg(['max', 'min'])"
"for the most and least tracks, the duration is.","track['milliseconds'].agg(['max', 'min'])"
how many albums contain 0 tracks?,"album.merge(track, on='albumid').groupby(['title', 'albumid']).size().reset_index(name='count')"
"which albums have they recorded, and what are their names and ids?","album.merge(track, on='albumid').groupby(['title', 'albumid']).size().reset_index(name='count')"
which is the most used genre across all tracks?,"pd.merge(genre, track, on='genreid').groupby('genreid')['name'].count().idxmax()"
which is the least common media type in all tracks?,"pd.merge(media_type, track, on='mediatypeid').groupby('mediatypeid').size().sort_values().iloc[:1].index.map(lambda x: media_type.loc[x, 'name'])"
what is a media type that is least common across all tracks?,"pd.merge(media_type, track, on='mediatypeid').groupby('mediatypeid').size().sort_values().iloc[:1].index.map(lambda x: media_type.loc[x, 'name'])"
"in which albums, do tracks have unit price bigger than 1?","track.merge(album, on='albumid').query('unitprice > 1').groupby('albumid').agg({'title': 'first', 'albumid': 'count'}).rename(columns={'albumid':'count_of_tracks'})[['title', 'count_of_tracks']].reset_index()"
which albums contain tracks with unit price greater than 1?,"track.merge(album, on='albumid').query('unitprice > 1').groupby('albumid').agg({'title': 'first', 'albumid': 'count'}).rename(columns={'albumid':'count_of_tracks'})[['title', 'count_of_tracks']].reset_index()"
how many tracks are part of the rock genre?,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='rock'].shape[0]"
the average unit price of tracks that belong to jazz genre is.,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='jazz', 'unitprice'].mean()"
the average unit price of jazz tracks are.,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='jazz', 'unitprice'].mean()"
"what is the full name of the customer with the email ""luisg@embraer.com.br""?","customer.loc[lambda x: x['email']=='luisg@embraer.com.br', ['firstname', 'lastname']]"
"how many customers email contains ""gmail.com""?",customer['email'].str.contains('gmail.com').sum()
"which customers have a ""gmail.com"" email?",customer['email'].str.contains('gmail.com').sum()
which employee helps the customer leonie with first name?,"employee.loc[lambda x: x['employeeid'].isin(customer.loc[lambda y: y['firstname']=='leonie', 'supportrepid']), ['firstname', 'lastname']]"
employees who help customers with the first name leonie are.,"employee.loc[lambda x: x['employeeid'].isin(customer.loc[lambda y: y['firstname']=='leonie', 'supportrepid']), ['firstname', 'lastname']]"
the employee who helps the customer with postal code 70174 lives in what city?,"pd.merge(customer.loc[lambda x: x['postalcode']=='70174'], employee, left_on='supportrepid', right_on='employeeid')['city']"
how many employees who are in zip code 70174 help customers?,"pd.merge(customer.loc[lambda x: x['postalcode']=='70174'], employee, left_on='supportrepid', right_on='employeeid')['city']"
how many distinct cities do the employees live in?,employee['city'].nunique()
how many cities do employees live in?,employee['city'].nunique()
which customer last names do not have invoice totals larger than 20?,"customer.loc[~customer['lastname'].isin(pd.merge(customer, invoice.loc[lambda x: x['total']>20], on='customerid')['lastname'])]['lastname']"
what are these customers' last names and addresses?,"customer.loc[~customer['lastname'].isin(pd.merge(customer, invoice.loc[lambda x: x['total']>20], on='customerid')['lastname'])]['lastname']"
"all customers who live in brazil and have an invoice, have.","pd.merge(customer, invoice, on='customerid').loc[lambda x: x['country']=='brazil', 'firstname'].unique()"
"customers from brazil, who have also had an invoice, have different first names.","pd.merge(customer, invoice, on='customerid').loc[lambda x: x['country']=='brazil', 'firstname'].unique()"
which customer has invoice live in germany?,"pd.merge(customer.loc[lambda x: x['country']=='germany'], invoice, on='customerid')['address'].unique()"
"customers who live in germany and have had an invoice, what is their address?","pd.merge(customer.loc[lambda x: x['country']=='germany'], invoice, on='customerid')['address'].unique()"
list the phone numbers of all our employees.,employee['phone']
which phone numbers do each employee have?,employee['phone']
how many tracks are in the _____ audio file media type?,"pd.merge(mediatype, track, on='mediatypeid').loc[lambda x: x['name']=='aac audio file'].shape[0]"
what is the count of tracks that are aac audio files?,"pd.merge(mediatype, track, on='mediatypeid').loc[lambda x: x['name']=='aac audio file'].shape[0]"
"of tracks that belong to latin or pop genre, what is the average duration in milliseconds?","pd.merge(genre, track, on='genreid').loc[lambda x: x['name'].isin(['latin', 'pop']), 'milliseconds'].mean()"
the average millisecond length of latin and pop tracks.,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name'].isin(['latin', 'pop']), 'milliseconds'].mean()"
who served at least 10 customers? ,"customer.merge(employee, left_on='supportrepid', right_on='employeeid').groupby(['firstname', 'supportrepid']).filter(lambda x: len(x) >= 10)[['firstname', 'supportrepid']].drop_duplicates()"
"employees serving 10 or more customers, what is their first names and support rep ids?","customer.merge(employee, left_on='supportrepid', right_on='employeeid').groupby(['firstname', 'supportrepid']).filter(lambda x: len(x) >= 10)[['firstname', 'supportrepid']].drop_duplicates()"
employee last names no more than 20 customers serve are.,"customer.merge(employee, left_on='supportrepid', right_on='employeeid').groupby('supportrepid').filter(lambda g: len(g) <= 20)['lastname']"
which employees serve at most 20 customers?,"customer.merge(employee, left_on='supportrepid', right_on='employeeid').groupby('supportrepid').filter(lambda g: len(g) <= 20)['lastname']"
"album titles, listed in alphabetical order, are.",album['title'].sort_values()
all album titles in alphabetical order are.,album['title'].sort_values()
artists that have at least 3 albums in alphabetical order are: ,"pd.merge(album, artist, on='artistid').groupby(['name', 'artistid']).filter(lambda x: len(x) >= 3).sort_values('name')[['name', 'artistid']]"
"artists with 3 or more albums, listed in alphabetical order are.","pd.merge(album, artist, on='artistid').groupby(['name', 'artistid']).filter(lambda x: len(x) >= 3).sort_values('name')[['name', 'artistid']]"
which artists do not have any albums?,"artist[~artist['name'].isin(pd.merge(album, artist, on='artistid')['name'])]['name']"
which artists have not released any albums?,"artist[~artist['name'].isin(pd.merge(album, artist, on='artistid')['name'])]['name']"
the average unit price of rock tracks is,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='rock', 'unitprice'].mean()"
what is the average price per track of the rock genre?,"pd.merge(genre, track, on='genreid').loc[lambda x: x['name']=='rock', 'unitprice'].mean()"
how many milliseconds are the longest and shortest pop tracks? ,"pd.merge(genre.loc[lambda x: x['name']=='pop'], track, on='genreid').agg({'milliseconds': ['max', 'min']})"
the maximum and minimum millisecond lengths of pop tracks are.,"pd.merge(genre.loc[lambda x: x['name']=='pop'], track, on='genreid').agg({'milliseconds': ['max', 'min']})"
which employees in edmonton were born in the year?,"employee.loc[lambda x: x['city']=='edmonton', 'birthdate']"
which dates do employees in edmonton live corresponding to?,"employee.loc[lambda x: x['city']=='edmonton', 'birthdate']"
the distinct unit prices for tracks are.,track['unitprice'].unique()
how many artists have no album?,artist[~artist['artistid'].isin(album['artistid'])].shape[0]
how many artists have not released an album?,artist[~artist['artistid'].isin(album['artistid'])].shape[0]
"albums with both 'reggae' and 'rock' genre tracks have titles such as 'reggae rock', 'rock', 'reggae', 'reggae rock', 'reggae rock', and 'reggae rock'. ","album.merge(track.merge(genre[genre['name'] == 'reggae'], on='genreid', how='inner'), on='albumid', how='inner')['title'].intersec‌t(album.merge(track.merge(genre[genre['name'] == 'rock'], on='genreid', how='inner'), on='albumid', how='inner')['title'])"
"the albums contain tracks of both genres, which are.","pd.merge(pd.merge(album, track, on='albumid'), genre, on='genreid').query(""name=='reggae'"")['title'].intersec(pd.merge(pd.merge(album, track, on='albumid'), genre, on='genreid').query(""name=='rock'"")['title'])"
all phone numbers.,available_policies['customer_phone']
"which customer phone numbers are under the policy ""life insurance""?","available_policies.loc[lambda x: x['policy_type_code'] == 'life insurance', 'customer_phone']"
"which customers using the policy with the code ""life insurance"" have the phone numbers?","available_policies.loc[lambda x: x['policy_type_code'] == 'life insurance', 'customer_phone']"
which policy type has most of the records?,available_policies.groupby('policy_type_code').size().sort_values(ascending=false).index[0]
which policies type appears most frequently in the available policies?,available_policies.groupby('policy_type_code').size().sort_values(ascending=false).index[0]
"among all the customer phone numbers, which are under the most popular policy type?","available_policies.loc[lambda x: x['policy_type_code']==available_policies['policy_type_code'].value_counts().index[0], 'customer_phone']"
the customers using the most common policy type among the available policies are .,"available_policies.loc[lambda x: x['policy_type_code']==available_policies['policy_type_code'].value_counts().index[0], 'customer_phone']"
more than 4 customers have used the policy type.,available_policies.groupby('policy_type_code').filter(lambda x: len(x) > 4)['policy_type_code'].unique()
"use more than 4 customers policy types, their code?",available_policies.groupby('policy_type_code').filter(lambda x: len(x) > 4)['policy_type_code'].unique()
the amount of the settlements is $ and $,"settlements['settlement_amount'].agg(['sum', 'mean'])"
which are the sum and average of all settlement amounts?,"settlements['settlement_amount'].agg(['sum', 'mean'])"
"more than 2 times, what services have been used in the first notification of loss?","pd.merge(first_notification_of_loss, services, on='service_id').groupby('service_id').filter(lambda x: len(x) > 2)['service_name'].unique()"
a service name is returned that has been used more than twice in first notification of loss.,"pd.merge(first_notification_of_loss, services, on='service_id').groupby('service_id').filter(lambda x: len(x) > 2)['service_name'].unique()"
how many total settlement claims are there in that claim?,"pd.merge(claims, settlements, on='claim_id').groupby('claim_id')['settlement_amount'].sum().idxmax()"
the largest total settlement amount is for this claim. the effective date of the claim is.,"pd.merge(claims, settlements, on='claim_id').groupby('claim_id')['settlement_amount'].sum().idxmax()"
"which policies are listed for the customer named ""dayana robel""?","(customers.merge(customers_policies, on='customer_id').loc[lambda x: x['customer_name']=='dayana robel', :].shape[0])"
"""dayana robel"" used how many policies of total?","(customers.merge(customers_policies, on='customer_id').loc[lambda x: x['customer_name']=='dayana robel', :].shape[0])"
which customer has the most policies listed?,"customers.merge(customers_policies, on='customer_id').groupby('customer_name').size().sort_values(ascending=false).index[0]"
the customer uses the most policies. what is the customer name?,"customers.merge(customers_policies, on='customer_id').groupby('customer_name').size().sort_values(ascending=false).index[0]"
"which policy types are the customer named ""dayana robel""?","customers_policies.merge(customers, on='customer_id').merge(available_policies, on='policy_id').loc[lambda x: x['customer_name']=='dayana robel', 'policy_type_code'].unique()"
dayana robel uses the types of the policy.,"customers_policies.merge(customers, on='customer_id').merge(available_policies, on='policy_id').loc[lambda x: x['customer_name']=='dayana robel', 'policy_type_code'].unique()"
the customer with the most policies has the most policy types?,"available_policies[np.in1d(available_policies['policy_id'], customers_policies[customers_policies['customer_id'].isin(customers[customers['customer_name']==customers['customer_name'].value_counts().index[0]]['customer_id'])]['policy_id'].unique())]['policy_type_code'].unique()"
what policy types are used by the customer enrolled in the most policies?,"available_policies[np.in1d(available_policies['policy_id'], customers_policies[customers_policies['customer_id'].isin(customers[customers['customer_name']==customers['customer_name'].value_counts().index[0]]['customer_id'])]['policy_id'].unique())]['policy_type_code'].unique()"
what are the services in the alphabetical order?,services['service_name'].sort_values()
a list of all service names sorted alphabetically.,services['service_name'].sort_values()
what is the total number of available services?,services.shape[0]
which users do not have a record of first notification of loss?,"customers.loc[~customers['customer_id'].isin(first_notification_of_loss['customer_id']), 'customer_name']"
which customers have used the services 'close a policy' or 'upgrade a policy'?,"pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: (x['service_name']=='close a policy') | (x['service_name']=='upgrade a policy'), 'customer_name']"
"which customers have used both the service ""close a policy"" and the service ""new policy application""?","pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: x['service_name']=='close a policy', 'customer_name'].intersect(pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: x['service_name']=='new policy application', 'customer_name'])"
"who have used both the services named ""close a policy"" and ""upgrade a policy""? give me the customer names.","pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: x['service_name']=='close a policy', 'customer_name'].intersect(pd.merge(pd.merge(customers, first_notification_of_loss, on='customer_id'), services, on='service_id').loc[lambda x: x['service_name']=='new policy application', 'customer_name'])"
"customers whose name contains ""diana"" are .","customers.loc[customers['customer_name'].str.contains('diana'), 'customer_id']"
"which customers have ""diana"" in part of their names, and what is their id?","customers.loc[customers['customer_name'].str.contains('diana'), 'customer_id']"
the maximum and minimum settlement amount on record are?,"settlements['settlement_amount'].agg(['max', 'min'])"
what is the maximum and minimum settlement amount?,"settlements['settlement_amount'].agg(['max', 'min'])"
"which are the first ids, customers?","customers[['customer_id', 'customer_name']].sort_values('customer_id')"
the ordered list of customer ids is.,"customers[['customer_id', 'customer_name']].sort_values('customer_id')"
"find all the policies associated with the customers, whose name contains ""diana"", and their open and close dates?","customers.merge(customers_policies, on='customer_id').loc[lambda x: x['customer_name'].str.contains('diana'), ['date_opened', 'date_closed']]"
"the open and close dates of all policies used by the customer who have ""diana"" in part of their names is.","customers.merge(customers_policies, on='customer_id').loc[lambda x: x['customer_name'].str.contains('diana'), ['date_opened', 'date_closed']]"
the total count of enzymes are.,enzyme.shape[0]
list the names of enzymes in descending lexicographical order.,"enzyme.sort_values('name', ascending=false)['name']"
"enzymes are in descending order, what is their names?","enzyme.sort_values('name', ascending=false)['name']"
